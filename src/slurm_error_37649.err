2025-04-20 16:56:00.573472: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-04-20 16:56:02.005977: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 0/10. Loss: 1.5916:   0%|[36m          [0m| 0/26 [00:01<?, ?it/s]Epoch: 0/10. Loss: 1.5916:   4%|[36m▍         [0m| 1/26 [00:01<00:49,  1.98s/it]Epoch: 0/10. Loss: 9.0681:   4%|[36m▍         [0m| 1/26 [00:02<00:49,  1.98s/it]Epoch: 0/10. Loss: 9.0681:   8%|[36m▊         [0m| 2/26 [00:02<00:32,  1.37s/it]Epoch: 0/10. Loss: 8.7978:   8%|[36m▊         [0m| 2/26 [00:03<00:32,  1.37s/it]Epoch: 0/10. Loss: 8.7978:  12%|[36m█▏        [0m| 3/26 [00:03<00:26,  1.15s/it]Epoch: 0/10. Loss: 4.1139:  12%|[36m█▏        [0m| 3/26 [00:04<00:26,  1.15s/it]Epoch: 0/10. Loss: 4.1139:  15%|[36m█▌        [0m| 4/26 [00:04<00:24,  1.11s/it]Epoch: 0/10. Loss: 8.1099:  15%|[36m█▌        [0m| 4/26 [00:06<00:24,  1.11s/it]Epoch: 0/10. Loss: 8.1099:  19%|[36m█▉        [0m| 5/26 [00:06<00:24,  1.18s/it]Epoch: 0/10. Loss: 2.9173:  19%|[36m█▉        [0m| 5/26 [00:07<00:24,  1.18s/it]Epoch: 0/10. Loss: 2.9173:  23%|[36m██▎       [0m| 6/26 [00:07<00:23,  1.19s/it]Epoch: 0/10. Loss: 2.0439:  23%|[36m██▎       [0m| 6/26 [00:08<00:23,  1.19s/it]Epoch: 0/10. Loss: 2.0439:  27%|[36m██▋       [0m| 7/26 [00:08<00:20,  1.08s/it]Epoch: 0/10. Loss: 1.2896:  27%|[36m██▋       [0m| 7/26 [00:09<00:20,  1.08s/it]Epoch: 0/10. Loss: 1.2896:  31%|[36m███       [0m| 8/26 [00:09<00:18,  1.04s/it]Epoch: 0/10. Loss: 2.3460:  31%|[36m███       [0m| 8/26 [00:10<00:18,  1.04s/it]Epoch: 0/10. Loss: 2.3460:  35%|[36m███▍      [0m| 9/26 [00:10<00:17,  1.02s/it]Epoch: 0/10. Loss: 1.2476:  35%|[36m███▍      [0m| 9/26 [00:11<00:17,  1.02s/it]Epoch: 0/10. Loss: 1.2476:  38%|[36m███▊      [0m| 10/26 [00:11<00:16,  1.01s/it]Epoch: 0/10. Loss: 1.5924:  38%|[36m███▊      [0m| 10/26 [00:12<00:16,  1.01s/it]Epoch: 0/10. Loss: 1.5924:  42%|[36m████▏     [0m| 11/26 [00:12<00:15,  1.03s/it]Epoch: 0/10. Loss: 1.1917:  42%|[36m████▏     [0m| 11/26 [00:13<00:15,  1.03s/it]Epoch: 0/10. Loss: 1.1917:  46%|[36m████▌     [0m| 12/26 [00:13<00:13,  1.03it/s]Epoch: 0/10. Loss: 1.2138:  46%|[36m████▌     [0m| 12/26 [00:13<00:13,  1.03it/s]Epoch: 0/10. Loss: 1.2138:  50%|[36m█████     [0m| 13/26 [00:13<00:12,  1.07it/s]Epoch: 0/10. Loss: 1.8214:  50%|[36m█████     [0m| 13/26 [00:14<00:12,  1.07it/s]Epoch: 0/10. Loss: 1.8214:  54%|[36m█████▍    [0m| 14/26 [00:14<00:11,  1.05it/s]Epoch: 0/10. Loss: 1.3878:  54%|[36m█████▍    [0m| 14/26 [00:15<00:11,  1.05it/s]Epoch: 0/10. Loss: 1.3878:  58%|[36m█████▊    [0m| 15/26 [00:15<00:09,  1.11it/s]Epoch: 0/10. Loss: 1.1920:  58%|[36m█████▊    [0m| 15/26 [00:16<00:09,  1.11it/s]Epoch: 0/10. Loss: 1.1920:  62%|[36m██████▏   [0m| 16/26 [00:16<00:09,  1.02it/s]Epoch: 0/10. Loss: 1.0746:  62%|[36m██████▏   [0m| 16/26 [00:17<00:09,  1.02it/s]Epoch: 0/10. Loss: 1.0746:  65%|[36m██████▌   [0m| 17/26 [00:17<00:08,  1.00it/s]Epoch: 0/10. Loss: 1.3616:  65%|[36m██████▌   [0m| 17/26 [00:18<00:08,  1.00it/s]Epoch: 0/10. Loss: 1.3616:  69%|[36m██████▉   [0m| 18/26 [00:18<00:07,  1.08it/s]Epoch: 0/10. Loss: 1.2185:  69%|[36m██████▉   [0m| 18/26 [00:19<00:07,  1.08it/s]Epoch: 0/10. Loss: 1.2185:  73%|[36m███████▎  [0m| 19/26 [00:19<00:06,  1.06it/s]Epoch: 0/10. Loss: 1.0380:  73%|[36m███████▎  [0m| 19/26 [00:20<00:06,  1.06it/s]Epoch: 0/10. Loss: 1.0380:  77%|[36m███████▋  [0m| 20/26 [00:20<00:05,  1.03it/s]Epoch: 0/10. Loss: 1.4762:  77%|[36m███████▋  [0m| 20/26 [00:21<00:05,  1.03it/s]Epoch: 0/10. Loss: 1.4762:  81%|[36m████████  [0m| 21/26 [00:21<00:04,  1.04it/s]Epoch: 0/10. Loss: 1.3374:  81%|[36m████████  [0m| 21/26 [00:22<00:04,  1.04it/s]Epoch: 0/10. Loss: 1.3374:  85%|[36m████████▍ [0m| 22/26 [00:22<00:03,  1.02it/s]Epoch: 0/10. Loss: 1.0237:  85%|[36m████████▍ [0m| 22/26 [00:23<00:03,  1.02it/s]Epoch: 0/10. Loss: 1.0237:  88%|[36m████████▊ [0m| 23/26 [00:23<00:03,  1.00s/it]Epoch: 0/10. Loss: 1.1799:  88%|[36m████████▊ [0m| 23/26 [00:24<00:03,  1.00s/it]Epoch: 0/10. Loss: 1.1799:  92%|[36m█████████▏[0m| 24/26 [00:24<00:01,  1.04it/s]Epoch: 0/10. Loss: 1.0668:  92%|[36m█████████▏[0m| 24/26 [00:25<00:01,  1.04it/s]Epoch: 0/10. Loss: 1.0668:  96%|[36m█████████▌[0m| 25/26 [00:25<00:01,  1.03s/it]Epoch: 0/10. Loss: 1.0956:  96%|[36m█████████▌[0m| 25/26 [00:26<00:01,  1.03s/it]Epoch: 0/10. Loss: 1.0956: 100%|[36m██████████[0m| 26/26 [00:26<00:00,  1.10it/s]Epoch: 0/10. Loss: 1.0956: 100%|[36m██████████[0m| 26/26 [00:26<00:00,  1.01s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:05,  1.13it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:06,  1.39s/it] 43%|[33m████▎     [0m| 3/7 [00:03<00:04,  1.02s/it] 57%|[33m█████▋    [0m| 4/7 [00:04<00:03,  1.17s/it] 71%|[33m███████▏  [0m| 5/7 [00:05<00:01,  1.09it/s] 86%|[33m████████▌ [0m| 6/7 [00:05<00:00,  1.09it/s]100%|[33m██████████[0m| 7/7 [00:06<00:00,  1.37it/s]100%|[33m██████████[0m| 7/7 [00:06<00:00,  1.10it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 1/10. Loss: 1.0177:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 1/10. Loss: 1.0177:   4%|[36m▍         [0m| 1/26 [00:00<00:20,  1.24it/s]Epoch: 1/10. Loss: 1.1125:   4%|[36m▍         [0m| 1/26 [00:01<00:20,  1.24it/s]Epoch: 1/10. Loss: 1.1125:   8%|[36m▊         [0m| 2/26 [00:01<00:18,  1.28it/s]Epoch: 1/10. Loss: 1.0511:   8%|[36m▊         [0m| 2/26 [00:03<00:18,  1.28it/s]Epoch: 1/10. Loss: 1.0511:  12%|[36m█▏        [0m| 3/26 [00:03<00:25,  1.11s/it]Epoch: 1/10. Loss: 1.0558:  12%|[36m█▏        [0m| 3/26 [00:03<00:25,  1.11s/it]Epoch: 1/10. Loss: 1.0558:  15%|[36m█▌        [0m| 4/26 [00:03<00:22,  1.03s/it]Epoch: 1/10. Loss: 0.9835:  15%|[36m█▌        [0m| 4/26 [00:05<00:22,  1.03s/it]Epoch: 1/10. Loss: 0.9835:  19%|[36m█▉        [0m| 5/26 [00:05<00:24,  1.19s/it]Epoch: 1/10. Loss: 1.1012:  19%|[36m█▉        [0m| 5/26 [00:06<00:24,  1.19s/it]Epoch: 1/10. Loss: 1.1012:  23%|[36m██▎       [0m| 6/26 [00:06<00:21,  1.07s/it]Epoch: 1/10. Loss: 1.0851:  23%|[36m██▎       [0m| 6/26 [00:07<00:21,  1.07s/it]Epoch: 1/10. Loss: 1.0851:  27%|[36m██▋       [0m| 7/26 [00:07<00:19,  1.03s/it]Epoch: 1/10. Loss: 1.1250:  27%|[36m██▋       [0m| 7/26 [00:07<00:19,  1.03s/it]Epoch: 1/10. Loss: 1.1250:  31%|[36m███       [0m| 8/26 [00:07<00:16,  1.08it/s]Epoch: 1/10. Loss: 1.2556:  31%|[36m███       [0m| 8/26 [00:08<00:16,  1.08it/s]Epoch: 1/10. Loss: 1.2556:  35%|[36m███▍      [0m| 9/26 [00:09<00:16,  1.03it/s]Epoch: 1/10. Loss: 0.9452:  35%|[36m███▍      [0m| 9/26 [00:09<00:16,  1.03it/s]Epoch: 1/10. Loss: 0.9452:  38%|[36m███▊      [0m| 10/26 [00:09<00:15,  1.04it/s]Epoch: 1/10. Loss: 0.9352:  38%|[36m███▊      [0m| 10/26 [00:10<00:15,  1.04it/s]Epoch: 1/10. Loss: 0.9352:  42%|[36m████▏     [0m| 11/26 [00:10<00:14,  1.02it/s]Epoch: 1/10. Loss: 1.0245:  42%|[36m████▏     [0m| 11/26 [00:12<00:14,  1.02it/s]Epoch: 1/10. Loss: 1.0245:  46%|[36m████▌     [0m| 12/26 [00:12<00:14,  1.02s/it]Epoch: 1/10. Loss: 1.3265:  46%|[36m████▌     [0m| 12/26 [00:12<00:14,  1.02s/it]Epoch: 1/10. Loss: 1.3265:  50%|[36m█████     [0m| 13/26 [00:13<00:12,  1.01it/s]Epoch: 1/10. Loss: 1.3414:  50%|[36m█████     [0m| 13/26 [00:16<00:12,  1.01it/s]Epoch: 1/10. Loss: 1.3414:  54%|[36m█████▍    [0m| 14/26 [00:16<00:19,  1.65s/it]Epoch: 1/10. Loss: 1.1974:  54%|[36m█████▍    [0m| 14/26 [00:17<00:19,  1.65s/it]Epoch: 1/10. Loss: 1.1974:  58%|[36m█████▊    [0m| 15/26 [00:17<00:15,  1.41s/it]Epoch: 1/10. Loss: 1.1602:  58%|[36m█████▊    [0m| 15/26 [00:18<00:15,  1.41s/it]Epoch: 1/10. Loss: 1.1602:  62%|[36m██████▏   [0m| 16/26 [00:18<00:13,  1.31s/it]Epoch: 1/10. Loss: 1.0465:  62%|[36m██████▏   [0m| 16/26 [00:18<00:13,  1.31s/it]Epoch: 1/10. Loss: 1.0465:  65%|[36m██████▌   [0m| 17/26 [00:18<00:10,  1.16s/it]Epoch: 1/10. Loss: 1.1565:  65%|[36m██████▌   [0m| 17/26 [00:19<00:10,  1.16s/it]Epoch: 1/10. Loss: 1.1565:  69%|[36m██████▉   [0m| 18/26 [00:19<00:08,  1.09s/it]Epoch: 1/10. Loss: 1.0108:  69%|[36m██████▉   [0m| 18/26 [00:20<00:08,  1.09s/it]Epoch: 1/10. Loss: 1.0108:  73%|[36m███████▎  [0m| 19/26 [00:20<00:07,  1.04s/it]Epoch: 1/10. Loss: 1.1355:  73%|[36m███████▎  [0m| 19/26 [00:21<00:07,  1.04s/it]Epoch: 1/10. Loss: 1.1355:  77%|[36m███████▋  [0m| 20/26 [00:21<00:06,  1.09s/it]Epoch: 1/10. Loss: 1.2035:  77%|[36m███████▋  [0m| 20/26 [00:23<00:06,  1.09s/it]Epoch: 1/10. Loss: 1.2035:  81%|[36m████████  [0m| 21/26 [00:23<00:05,  1.12s/it]Epoch: 1/10. Loss: 1.1377:  81%|[36m████████  [0m| 21/26 [00:24<00:05,  1.12s/it]Epoch: 1/10. Loss: 1.1377:  85%|[36m████████▍ [0m| 22/26 [00:24<00:04,  1.09s/it]Epoch: 1/10. Loss: 1.3482:  85%|[36m████████▍ [0m| 22/26 [00:25<00:04,  1.09s/it]Epoch: 1/10. Loss: 1.3482:  88%|[36m████████▊ [0m| 23/26 [00:25<00:03,  1.08s/it]Epoch: 1/10. Loss: 1.2153:  88%|[36m████████▊ [0m| 23/26 [00:26<00:03,  1.08s/it]Epoch: 1/10. Loss: 1.2153:  92%|[36m█████████▏[0m| 24/26 [00:26<00:02,  1.08s/it]Epoch: 1/10. Loss: 1.1445:  92%|[36m█████████▏[0m| 24/26 [00:27<00:02,  1.08s/it]Epoch: 1/10. Loss: 1.1445:  96%|[36m█████████▌[0m| 25/26 [00:27<00:01,  1.03s/it]Epoch: 1/10. Loss: 1.2103:  96%|[36m█████████▌[0m| 25/26 [00:27<00:01,  1.03s/it]Epoch: 1/10. Loss: 1.2103: 100%|[36m██████████[0m| 26/26 [00:27<00:00,  1.06it/s]Epoch: 1/10. Loss: 1.2103: 100%|[36m██████████[0m| 26/26 [00:27<00:00,  1.08s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:05,  1.15it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:06,  1.22s/it] 43%|[33m████▎     [0m| 3/7 [00:02<00:03,  1.08it/s] 57%|[33m█████▋    [0m| 4/7 [00:04<00:03,  1.12s/it] 71%|[33m███████▏  [0m| 5/7 [00:04<00:01,  1.13it/s] 86%|[33m████████▌ [0m| 6/7 [00:05<00:00,  1.12it/s]100%|[33m██████████[0m| 7/7 [00:06<00:00,  1.31it/s]100%|[33m██████████[0m| 7/7 [00:06<00:00,  1.13it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 2/10. Loss: 1.1790:   0%|[36m          [0m| 0/26 [00:01<?, ?it/s]Epoch: 2/10. Loss: 1.1790:   4%|[36m▍         [0m| 1/26 [00:01<00:36,  1.44s/it]Epoch: 2/10. Loss: 1.0065:   4%|[36m▍         [0m| 1/26 [00:02<00:36,  1.44s/it]Epoch: 2/10. Loss: 1.0065:   8%|[36m▊         [0m| 2/26 [00:02<00:30,  1.27s/it]Epoch: 2/10. Loss: 1.2135:   8%|[36m▊         [0m| 2/26 [00:03<00:30,  1.27s/it]Epoch: 2/10. Loss: 1.2135:  12%|[36m█▏        [0m| 3/26 [00:03<00:25,  1.10s/it]Epoch: 2/10. Loss: 1.0740:  12%|[36m█▏        [0m| 3/26 [00:04<00:25,  1.10s/it]Epoch: 2/10. Loss: 1.0740:  15%|[36m█▌        [0m| 4/26 [00:04<00:22,  1.04s/it]Epoch: 2/10. Loss: 1.0823:  15%|[36m█▌        [0m| 4/26 [00:05<00:22,  1.04s/it]Epoch: 2/10. Loss: 1.0823:  19%|[36m█▉        [0m| 5/26 [00:05<00:21,  1.03s/it]Epoch: 2/10. Loss: 1.1668:  19%|[36m█▉        [0m| 5/26 [00:06<00:21,  1.03s/it]Epoch: 2/10. Loss: 1.1668:  23%|[36m██▎       [0m| 6/26 [00:06<00:19,  1.01it/s]Epoch: 2/10. Loss: 1.0661:  23%|[36m██▎       [0m| 6/26 [00:07<00:19,  1.01it/s]Epoch: 2/10. Loss: 1.0661:  27%|[36m██▋       [0m| 7/26 [00:07<00:18,  1.01it/s]Epoch: 2/10. Loss: 0.9983:  27%|[36m██▋       [0m| 7/26 [00:08<00:18,  1.01it/s]Epoch: 2/10. Loss: 0.9983:  31%|[36m███       [0m| 8/26 [00:08<00:17,  1.03it/s]Epoch: 2/10. Loss: 1.0264:  31%|[36m███       [0m| 8/26 [00:09<00:17,  1.03it/s]Epoch: 2/10. Loss: 1.0264:  35%|[36m███▍      [0m| 9/26 [00:09<00:15,  1.07it/s]Epoch: 2/10. Loss: 1.1383:  35%|[36m███▍      [0m| 9/26 [00:10<00:15,  1.07it/s]Epoch: 2/10. Loss: 1.1383:  38%|[36m███▊      [0m| 10/26 [00:10<00:15,  1.03it/s]Epoch: 2/10. Loss: 1.1734:  38%|[36m███▊      [0m| 10/26 [00:10<00:15,  1.03it/s]Epoch: 2/10. Loss: 1.1734:  42%|[36m████▏     [0m| 11/26 [00:10<00:13,  1.09it/s]Epoch: 2/10. Loss: 0.9770:  42%|[36m████▏     [0m| 11/26 [00:11<00:13,  1.09it/s]Epoch: 2/10. Loss: 0.9770:  46%|[36m████▌     [0m| 12/26 [00:11<00:13,  1.07it/s]Epoch: 2/10. Loss: 1.0019:  46%|[36m████▌     [0m| 12/26 [00:12<00:13,  1.07it/s]Epoch: 2/10. Loss: 1.0019:  50%|[36m█████     [0m| 13/26 [00:12<00:12,  1.07it/s]Epoch: 2/10. Loss: 1.0510:  50%|[36m█████     [0m| 13/26 [00:13<00:12,  1.07it/s]Epoch: 2/10. Loss: 1.0510:  54%|[36m█████▍    [0m| 14/26 [00:13<00:11,  1.08it/s]Epoch: 2/10. Loss: 0.9034:  54%|[36m█████▍    [0m| 14/26 [00:15<00:11,  1.08it/s]Epoch: 2/10. Loss: 0.9034:  58%|[36m█████▊    [0m| 15/26 [00:15<00:11,  1.08s/it]Epoch: 2/10. Loss: 1.1454:  58%|[36m█████▊    [0m| 15/26 [00:16<00:11,  1.08s/it]Epoch: 2/10. Loss: 1.1454:  62%|[36m██████▏   [0m| 16/26 [00:16<00:11,  1.14s/it]Epoch: 2/10. Loss: 1.1604:  62%|[36m██████▏   [0m| 16/26 [00:17<00:11,  1.14s/it]Epoch: 2/10. Loss: 1.1604:  65%|[36m██████▌   [0m| 17/26 [00:17<00:10,  1.16s/it]Epoch: 2/10. Loss: 1.0747:  65%|[36m██████▌   [0m| 17/26 [00:18<00:10,  1.16s/it]Epoch: 2/10. Loss: 1.0747:  69%|[36m██████▉   [0m| 18/26 [00:18<00:08,  1.10s/it]Epoch: 2/10. Loss: 1.0079:  69%|[36m██████▉   [0m| 18/26 [00:19<00:08,  1.10s/it]Epoch: 2/10. Loss: 1.0079:  73%|[36m███████▎  [0m| 19/26 [00:19<00:07,  1.04s/it]Epoch: 2/10. Loss: 1.1254:  73%|[36m███████▎  [0m| 19/26 [00:20<00:07,  1.04s/it]Epoch: 2/10. Loss: 1.1254:  77%|[36m███████▋  [0m| 20/26 [00:20<00:06,  1.03s/it]Epoch: 2/10. Loss: 1.1031:  77%|[36m███████▋  [0m| 20/26 [00:21<00:06,  1.03s/it]Epoch: 2/10. Loss: 1.1031:  81%|[36m████████  [0m| 21/26 [00:21<00:05,  1.01s/it]Epoch: 2/10. Loss: 0.9968:  81%|[36m████████  [0m| 21/26 [00:22<00:05,  1.01s/it]Epoch: 2/10. Loss: 0.9968:  85%|[36m████████▍ [0m| 22/26 [00:22<00:04,  1.02s/it]Epoch: 2/10. Loss: 0.9994:  85%|[36m████████▍ [0m| 22/26 [00:23<00:04,  1.02s/it]Epoch: 2/10. Loss: 0.9994:  88%|[36m████████▊ [0m| 23/26 [00:23<00:02,  1.01it/s]Epoch: 2/10. Loss: 0.9263:  88%|[36m████████▊ [0m| 23/26 [00:24<00:02,  1.01it/s]Epoch: 2/10. Loss: 0.9263:  92%|[36m█████████▏[0m| 24/26 [00:24<00:01,  1.07it/s]Epoch: 2/10. Loss: 0.9713:  92%|[36m█████████▏[0m| 24/26 [00:25<00:01,  1.07it/s]Epoch: 2/10. Loss: 0.9713:  96%|[36m█████████▌[0m| 25/26 [00:25<00:01,  1.05s/it]Epoch: 2/10. Loss: 0.8918:  96%|[36m█████████▌[0m| 25/26 [00:26<00:01,  1.05s/it]Epoch: 2/10. Loss: 0.8918: 100%|[36m██████████[0m| 26/26 [00:26<00:00,  1.04it/s]Epoch: 2/10. Loss: 0.8918: 100%|[36m██████████[0m| 26/26 [00:26<00:00,  1.01s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:05,  1.00it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:06,  1.25s/it] 43%|[33m████▎     [0m| 3/7 [00:02<00:03,  1.08it/s] 57%|[33m█████▋    [0m| 4/7 [00:04<00:03,  1.31s/it] 71%|[33m███████▏  [0m| 5/7 [00:05<00:01,  1.01it/s] 86%|[33m████████▌ [0m| 6/7 [00:06<00:00,  1.04it/s]100%|[33m██████████[0m| 7/7 [00:06<00:00,  1.32it/s]100%|[33m██████████[0m| 7/7 [00:06<00:00,  1.07it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 3/10. Loss: 1.0081:   0%|[36m          [0m| 0/26 [00:01<?, ?it/s]Epoch: 3/10. Loss: 1.0081:   4%|[36m▍         [0m| 1/26 [00:01<00:29,  1.19s/it]Epoch: 3/10. Loss: 1.0410:   4%|[36m▍         [0m| 1/26 [00:02<00:29,  1.19s/it]Epoch: 3/10. Loss: 1.0410:   8%|[36m▊         [0m| 2/26 [00:02<00:23,  1.00it/s]Epoch: 3/10. Loss: 0.9800:   8%|[36m▊         [0m| 2/26 [00:03<00:23,  1.00it/s]Epoch: 3/10. Loss: 0.9800:  12%|[36m█▏        [0m| 3/26 [00:03<00:23,  1.01s/it]Epoch: 3/10. Loss: 0.9325:  12%|[36m█▏        [0m| 3/26 [00:04<00:23,  1.01s/it]Epoch: 3/10. Loss: 0.9325:  15%|[36m█▌        [0m| 4/26 [00:04<00:21,  1.02it/s]Epoch: 3/10. Loss: 1.2074:  15%|[36m█▌        [0m| 4/26 [00:05<00:21,  1.02it/s]Epoch: 3/10. Loss: 1.2074:  19%|[36m█▉        [0m| 5/26 [00:05<00:20,  1.01it/s]Epoch: 3/10. Loss: 0.9703:  19%|[36m█▉        [0m| 5/26 [00:05<00:20,  1.01it/s]Epoch: 3/10. Loss: 0.9703:  23%|[36m██▎       [0m| 6/26 [00:05<00:18,  1.06it/s]Epoch: 3/10. Loss: 1.0039:  23%|[36m██▎       [0m| 6/26 [00:06<00:18,  1.06it/s]Epoch: 3/10. Loss: 1.0039:  27%|[36m██▋       [0m| 7/26 [00:06<00:18,  1.00it/s]Epoch: 3/10. Loss: 1.0694:  27%|[36m██▋       [0m| 7/26 [00:08<00:18,  1.00it/s]Epoch: 3/10. Loss: 1.0694:  31%|[36m███       [0m| 8/26 [00:08<00:18,  1.04s/it]Epoch: 3/10. Loss: 0.9269:  31%|[36m███       [0m| 8/26 [00:09<00:18,  1.04s/it]Epoch: 3/10. Loss: 0.9269:  35%|[36m███▍      [0m| 9/26 [00:09<00:18,  1.08s/it]Epoch: 3/10. Loss: 0.9317:  35%|[36m███▍      [0m| 9/26 [00:11<00:18,  1.08s/it]Epoch: 3/10. Loss: 0.9317:  38%|[36m███▊      [0m| 10/26 [00:11<00:20,  1.29s/it]Epoch: 3/10. Loss: 0.9782:  38%|[36m███▊      [0m| 10/26 [00:12<00:20,  1.29s/it]Epoch: 3/10. Loss: 0.9782:  42%|[36m████▏     [0m| 11/26 [00:12<00:19,  1.30s/it]Epoch: 3/10. Loss: 0.9460:  42%|[36m████▏     [0m| 11/26 [00:13<00:19,  1.30s/it]Epoch: 3/10. Loss: 0.9460:  46%|[36m████▌     [0m| 12/26 [00:13<00:18,  1.29s/it]Epoch: 3/10. Loss: 0.8786:  46%|[36m████▌     [0m| 12/26 [00:14<00:18,  1.29s/it]Epoch: 3/10. Loss: 0.8786:  50%|[36m█████     [0m| 13/26 [00:14<00:15,  1.22s/it]Epoch: 3/10. Loss: 0.9661:  50%|[36m█████     [0m| 13/26 [00:15<00:15,  1.22s/it]Epoch: 3/10. Loss: 0.9661:  54%|[36m█████▍    [0m| 14/26 [00:15<00:14,  1.17s/it]Epoch: 3/10. Loss: 1.0565:  54%|[36m█████▍    [0m| 14/26 [00:16<00:14,  1.17s/it]Epoch: 3/10. Loss: 1.0565:  58%|[36m█████▊    [0m| 15/26 [00:16<00:12,  1.10s/it]Epoch: 3/10. Loss: 0.9726:  58%|[36m█████▊    [0m| 15/26 [00:19<00:12,  1.10s/it]Epoch: 3/10. Loss: 0.9726:  62%|[36m██████▏   [0m| 16/26 [00:19<00:16,  1.67s/it]Epoch: 3/10. Loss: 1.0032:  62%|[36m██████▏   [0m| 16/26 [00:20<00:16,  1.67s/it]Epoch: 3/10. Loss: 1.0032:  65%|[36m██████▌   [0m| 17/26 [00:20<00:13,  1.54s/it]Epoch: 3/10. Loss: 1.1988:  65%|[36m██████▌   [0m| 17/26 [00:24<00:13,  1.54s/it]Epoch: 3/10. Loss: 1.1988:  69%|[36m██████▉   [0m| 18/26 [00:24<00:17,  2.22s/it]Epoch: 3/10. Loss: 0.9987:  69%|[36m██████▉   [0m| 18/26 [00:26<00:17,  2.22s/it]Epoch: 3/10. Loss: 0.9987:  73%|[36m███████▎  [0m| 19/26 [00:26<00:14,  2.07s/it]Epoch: 3/10. Loss: 0.9268:  73%|[36m███████▎  [0m| 19/26 [00:27<00:14,  2.07s/it]Epoch: 3/10. Loss: 0.9268:  77%|[36m███████▋  [0m| 20/26 [00:27<00:10,  1.76s/it]Epoch: 3/10. Loss: 0.9162:  77%|[36m███████▋  [0m| 20/26 [00:28<00:10,  1.76s/it]Epoch: 3/10. Loss: 0.9162:  81%|[36m████████  [0m| 21/26 [00:28<00:07,  1.50s/it]Epoch: 3/10. Loss: 1.0306:  81%|[36m████████  [0m| 21/26 [00:30<00:07,  1.50s/it]Epoch: 3/10. Loss: 1.0306:  85%|[36m████████▍ [0m| 22/26 [00:30<00:06,  1.58s/it]Epoch: 3/10. Loss: 1.0442:  85%|[36m████████▍ [0m| 22/26 [00:31<00:06,  1.58s/it]Epoch: 3/10. Loss: 1.0442:  88%|[36m████████▊ [0m| 23/26 [00:31<00:04,  1.40s/it]Epoch: 3/10. Loss: 0.9903:  88%|[36m████████▊ [0m| 23/26 [00:32<00:04,  1.40s/it]Epoch: 3/10. Loss: 0.9903:  92%|[36m█████████▏[0m| 24/26 [00:32<00:02,  1.36s/it]Epoch: 3/10. Loss: 1.0346:  92%|[36m█████████▏[0m| 24/26 [00:33<00:02,  1.36s/it]Epoch: 3/10. Loss: 1.0346:  96%|[36m█████████▌[0m| 25/26 [00:33<00:01,  1.20s/it]Epoch: 3/10. Loss: 1.1340:  96%|[36m█████████▌[0m| 25/26 [00:35<00:01,  1.20s/it]Epoch: 3/10. Loss: 1.1340: 100%|[36m██████████[0m| 26/26 [00:35<00:00,  1.58s/it]Epoch: 3/10. Loss: 1.1340: 100%|[36m██████████[0m| 26/26 [00:35<00:00,  1.37s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:01<00:08,  1.37s/it] 29%|[33m██▊       [0m| 2/7 [00:03<00:09,  1.84s/it] 43%|[33m████▎     [0m| 3/7 [00:04<00:05,  1.26s/it] 57%|[33m█████▋    [0m| 4/7 [00:05<00:04,  1.33s/it] 71%|[33m███████▏  [0m| 5/7 [00:06<00:02,  1.01s/it] 86%|[33m████████▌ [0m| 6/7 [00:07<00:01,  1.04s/it]100%|[33m██████████[0m| 7/7 [00:07<00:00,  1.17it/s]100%|[33m██████████[0m| 7/7 [00:07<00:00,  1.08s/it]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 4/10. Loss: 0.9341:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 4/10. Loss: 0.9341:   4%|[36m▍         [0m| 1/26 [00:00<00:20,  1.22it/s]Epoch: 4/10. Loss: 0.8906:   4%|[36m▍         [0m| 1/26 [00:01<00:20,  1.22it/s]Epoch: 4/10. Loss: 0.8906:   8%|[36m▊         [0m| 2/26 [00:01<00:23,  1.03it/s]Epoch: 4/10. Loss: 1.0059:   8%|[36m▊         [0m| 2/26 [00:02<00:23,  1.03it/s]Epoch: 4/10. Loss: 1.0059:  12%|[36m█▏        [0m| 3/26 [00:02<00:22,  1.02it/s]Epoch: 4/10. Loss: 0.9351:  12%|[36m█▏        [0m| 3/26 [00:03<00:22,  1.02it/s]Epoch: 4/10. Loss: 0.9351:  15%|[36m█▌        [0m| 4/26 [00:03<00:21,  1.03it/s]Epoch: 4/10. Loss: 0.8995:  15%|[36m█▌        [0m| 4/26 [00:04<00:21,  1.03it/s]Epoch: 4/10. Loss: 0.8995:  19%|[36m█▉        [0m| 5/26 [00:04<00:20,  1.03it/s]Epoch: 4/10. Loss: 0.9831:  19%|[36m█▉        [0m| 5/26 [00:05<00:20,  1.03it/s]Epoch: 4/10. Loss: 0.9831:  23%|[36m██▎       [0m| 6/26 [00:05<00:18,  1.10it/s]Epoch: 4/10. Loss: 0.8991:  23%|[36m██▎       [0m| 6/26 [00:06<00:18,  1.10it/s]Epoch: 4/10. Loss: 0.8991:  27%|[36m██▋       [0m| 7/26 [00:06<00:18,  1.03it/s]Epoch: 4/10. Loss: 0.9436:  27%|[36m██▋       [0m| 7/26 [00:07<00:18,  1.03it/s]Epoch: 4/10. Loss: 0.9436:  31%|[36m███       [0m| 8/26 [00:07<00:17,  1.04it/s]Epoch: 4/10. Loss: 0.9792:  31%|[36m███       [0m| 8/26 [00:09<00:17,  1.04it/s]Epoch: 4/10. Loss: 0.9792:  35%|[36m███▍      [0m| 9/26 [00:09<00:20,  1.20s/it]Epoch: 4/10. Loss: 0.8784:  35%|[36m███▍      [0m| 9/26 [00:10<00:20,  1.20s/it]Epoch: 4/10. Loss: 0.8784:  38%|[36m███▊      [0m| 10/26 [00:10<00:20,  1.31s/it]Epoch: 4/10. Loss: 1.0070:  38%|[36m███▊      [0m| 10/26 [00:11<00:20,  1.31s/it]Epoch: 4/10. Loss: 1.0070:  42%|[36m████▏     [0m| 11/26 [00:11<00:17,  1.16s/it]Epoch: 4/10. Loss: 0.9103:  42%|[36m████▏     [0m| 11/26 [00:13<00:17,  1.16s/it]Epoch: 4/10. Loss: 0.9103:  46%|[36m████▌     [0m| 12/26 [00:13<00:19,  1.42s/it]Epoch: 4/10. Loss: 0.9516:  46%|[36m████▌     [0m| 12/26 [00:14<00:19,  1.42s/it]Epoch: 4/10. Loss: 0.9516:  50%|[36m█████     [0m| 13/26 [00:14<00:16,  1.28s/it]Epoch: 4/10. Loss: 0.8964:  50%|[36m█████     [0m| 13/26 [00:15<00:16,  1.28s/it]Epoch: 4/10. Loss: 0.8964:  54%|[36m█████▍    [0m| 14/26 [00:15<00:14,  1.17s/it]Epoch: 4/10. Loss: 0.9102:  54%|[36m█████▍    [0m| 14/26 [00:16<00:14,  1.17s/it]Epoch: 4/10. Loss: 0.9102:  58%|[36m█████▊    [0m| 15/26 [00:16<00:12,  1.12s/it]Epoch: 4/10. Loss: 1.0127:  58%|[36m█████▊    [0m| 15/26 [00:17<00:12,  1.12s/it]Epoch: 4/10. Loss: 1.0127:  62%|[36m██████▏   [0m| 16/26 [00:17<00:10,  1.06s/it]Epoch: 4/10. Loss: 1.0243:  62%|[36m██████▏   [0m| 16/26 [00:19<00:10,  1.06s/it]Epoch: 4/10. Loss: 1.0243:  65%|[36m██████▌   [0m| 17/26 [00:19<00:11,  1.33s/it]Epoch: 4/10. Loss: 0.9013:  65%|[36m██████▌   [0m| 17/26 [00:22<00:11,  1.33s/it]Epoch: 4/10. Loss: 0.9013:  69%|[36m██████▉   [0m| 18/26 [00:22<00:14,  1.82s/it]Epoch: 4/10. Loss: 0.9370:  69%|[36m██████▉   [0m| 18/26 [00:24<00:14,  1.82s/it]Epoch: 4/10. Loss: 0.9370:  73%|[36m███████▎  [0m| 19/26 [00:24<00:14,  2.03s/it]Epoch: 4/10. Loss: 1.0618:  73%|[36m███████▎  [0m| 19/26 [00:26<00:14,  2.03s/it]Epoch: 4/10. Loss: 1.0618:  77%|[36m███████▋  [0m| 20/26 [00:26<00:11,  1.84s/it]Epoch: 4/10. Loss: 0.9203:  77%|[36m███████▋  [0m| 20/26 [00:27<00:11,  1.84s/it]Epoch: 4/10. Loss: 0.9203:  81%|[36m████████  [0m| 21/26 [00:27<00:07,  1.55s/it]Epoch: 4/10. Loss: 1.0523:  81%|[36m████████  [0m| 21/26 [00:28<00:07,  1.55s/it]Epoch: 4/10. Loss: 1.0523:  85%|[36m████████▍ [0m| 22/26 [00:28<00:05,  1.42s/it]Epoch: 4/10. Loss: 1.0578:  85%|[36m████████▍ [0m| 22/26 [00:29<00:05,  1.42s/it]Epoch: 4/10. Loss: 1.0578:  88%|[36m████████▊ [0m| 23/26 [00:29<00:03,  1.31s/it]Epoch: 4/10. Loss: 0.9445:  88%|[36m████████▊ [0m| 23/26 [00:30<00:03,  1.31s/it]Epoch: 4/10. Loss: 0.9445:  92%|[36m█████████▏[0m| 24/26 [00:30<00:02,  1.22s/it]Epoch: 4/10. Loss: 0.9507:  92%|[36m█████████▏[0m| 24/26 [00:31<00:02,  1.22s/it]Epoch: 4/10. Loss: 0.9507:  96%|[36m█████████▌[0m| 25/26 [00:31<00:01,  1.12s/it]Epoch: 4/10. Loss: 0.9923:  96%|[36m█████████▌[0m| 25/26 [00:31<00:01,  1.12s/it]Epoch: 4/10. Loss: 0.9923: 100%|[36m██████████[0m| 26/26 [00:31<00:00,  1.05it/s]Epoch: 4/10. Loss: 0.9923: 100%|[36m██████████[0m| 26/26 [00:31<00:00,  1.23s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:01<00:06,  1.04s/it] 29%|[33m██▊       [0m| 2/7 [00:03<00:08,  1.62s/it] 43%|[33m████▎     [0m| 3/7 [00:03<00:04,  1.15s/it] 57%|[33m█████▋    [0m| 4/7 [00:06<00:05,  1.89s/it] 71%|[33m███████▏  [0m| 5/7 [00:07<00:02,  1.39s/it] 86%|[33m████████▌ [0m| 6/7 [00:08<00:01,  1.24s/it]100%|[33m██████████[0m| 7/7 [00:08<00:00,  1.06it/s]100%|[33m██████████[0m| 7/7 [00:08<00:00,  1.21s/it]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 5/10. Loss: 0.9811:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 5/10. Loss: 0.9811:   4%|[36m▍         [0m| 1/26 [00:00<00:20,  1.22it/s]Epoch: 5/10. Loss: 0.8980:   4%|[36m▍         [0m| 1/26 [00:01<00:20,  1.22it/s]Epoch: 5/10. Loss: 0.8980:   8%|[36m▊         [0m| 2/26 [00:01<00:24,  1.01s/it]Epoch: 5/10. Loss: 0.9388:   8%|[36m▊         [0m| 2/26 [00:02<00:24,  1.01s/it]Epoch: 5/10. Loss: 0.9388:  12%|[36m█▏        [0m| 3/26 [00:02<00:22,  1.03it/s]Epoch: 5/10. Loss: 1.0569:  12%|[36m█▏        [0m| 3/26 [00:04<00:22,  1.03it/s]Epoch: 5/10. Loss: 1.0569:  15%|[36m█▌        [0m| 4/26 [00:04<00:26,  1.21s/it]Epoch: 5/10. Loss: 0.9230:  15%|[36m█▌        [0m| 4/26 [00:05<00:26,  1.21s/it]Epoch: 5/10. Loss: 0.9230:  19%|[36m█▉        [0m| 5/26 [00:05<00:22,  1.06s/it]Epoch: 5/10. Loss: 0.9398:  19%|[36m█▉        [0m| 5/26 [00:06<00:22,  1.06s/it]Epoch: 5/10. Loss: 0.9398:  23%|[36m██▎       [0m| 6/26 [00:06<00:20,  1.04s/it]Epoch: 5/10. Loss: 1.0045:  23%|[36m██▎       [0m| 6/26 [00:07<00:20,  1.04s/it]Epoch: 5/10. Loss: 1.0045:  27%|[36m██▋       [0m| 7/26 [00:07<00:19,  1.02s/it]Epoch: 5/10. Loss: 0.9812:  27%|[36m██▋       [0m| 7/26 [00:08<00:19,  1.02s/it]Epoch: 5/10. Loss: 0.9812:  31%|[36m███       [0m| 8/26 [00:08<00:17,  1.02it/s]Epoch: 5/10. Loss: 1.0319:  31%|[36m███       [0m| 8/26 [00:09<00:17,  1.02it/s]Epoch: 5/10. Loss: 1.0319:  35%|[36m███▍      [0m| 9/26 [00:09<00:20,  1.23s/it]Epoch: 5/10. Loss: 0.9454:  35%|[36m███▍      [0m| 9/26 [00:11<00:20,  1.23s/it]Epoch: 5/10. Loss: 0.9454:  38%|[36m███▊      [0m| 10/26 [00:11<00:19,  1.20s/it]Epoch: 5/10. Loss: 1.0048:  38%|[36m███▊      [0m| 10/26 [00:11<00:19,  1.20s/it]Epoch: 5/10. Loss: 1.0048:  42%|[36m████▏     [0m| 11/26 [00:11<00:16,  1.12s/it]Epoch: 5/10. Loss: 0.9232:  42%|[36m████▏     [0m| 11/26 [00:13<00:16,  1.12s/it]Epoch: 5/10. Loss: 0.9232:  46%|[36m████▌     [0m| 12/26 [00:13<00:19,  1.37s/it]Epoch: 5/10. Loss: 0.9834:  46%|[36m████▌     [0m| 12/26 [00:15<00:19,  1.37s/it]Epoch: 5/10. Loss: 0.9834:  50%|[36m█████     [0m| 13/26 [00:15<00:17,  1.32s/it]Epoch: 5/10. Loss: 0.9297:  50%|[36m█████     [0m| 13/26 [00:16<00:17,  1.32s/it]Epoch: 5/10. Loss: 0.9297:  54%|[36m█████▍    [0m| 14/26 [00:16<00:14,  1.20s/it]Epoch: 5/10. Loss: 0.9190:  54%|[36m█████▍    [0m| 14/26 [00:16<00:14,  1.20s/it]Epoch: 5/10. Loss: 0.9190:  58%|[36m█████▊    [0m| 15/26 [00:16<00:12,  1.10s/it]Epoch: 5/10. Loss: 0.8413:  58%|[36m█████▊    [0m| 15/26 [00:20<00:12,  1.10s/it]Epoch: 5/10. Loss: 0.8413:  62%|[36m██████▏   [0m| 16/26 [00:20<00:19,  1.92s/it]Epoch: 5/10. Loss: 0.7548:  62%|[36m██████▏   [0m| 16/26 [00:21<00:19,  1.92s/it]Epoch: 5/10. Loss: 0.7548:  65%|[36m██████▌   [0m| 17/26 [00:21<00:14,  1.64s/it]Epoch: 5/10. Loss: 0.8993:  65%|[36m██████▌   [0m| 17/26 [00:22<00:14,  1.64s/it]Epoch: 5/10. Loss: 0.8993:  69%|[36m██████▉   [0m| 18/26 [00:22<00:12,  1.50s/it]Epoch: 5/10. Loss: 0.9026:  69%|[36m██████▉   [0m| 18/26 [00:23<00:12,  1.50s/it]Epoch: 5/10. Loss: 0.9026:  73%|[36m███████▎  [0m| 19/26 [00:23<00:09,  1.37s/it]Epoch: 5/10. Loss: 1.0780:  73%|[36m███████▎  [0m| 19/26 [00:24<00:09,  1.37s/it]Epoch: 5/10. Loss: 1.0780:  77%|[36m███████▋  [0m| 20/26 [00:24<00:07,  1.25s/it]Epoch: 5/10. Loss: 0.8724:  77%|[36m███████▋  [0m| 20/26 [00:25<00:07,  1.25s/it]Epoch: 5/10. Loss: 0.8724:  81%|[36m████████  [0m| 21/26 [00:26<00:05,  1.19s/it]Epoch: 5/10. Loss: 0.9129:  81%|[36m████████  [0m| 21/26 [00:26<00:05,  1.19s/it]Epoch: 5/10. Loss: 0.9129:  85%|[36m████████▍ [0m| 22/26 [00:26<00:04,  1.13s/it]Epoch: 5/10. Loss: 0.9941:  85%|[36m████████▍ [0m| 22/26 [00:28<00:04,  1.13s/it]Epoch: 5/10. Loss: 0.9941:  88%|[36m████████▊ [0m| 23/26 [00:28<00:03,  1.11s/it]Epoch: 5/10. Loss: 0.8345:  88%|[36m████████▊ [0m| 23/26 [00:29<00:03,  1.11s/it]Epoch: 5/10. Loss: 0.8345:  92%|[36m█████████▏[0m| 24/26 [00:29<00:02,  1.07s/it]Epoch: 5/10. Loss: 1.0036:  92%|[36m█████████▏[0m| 24/26 [00:29<00:02,  1.07s/it]Epoch: 5/10. Loss: 1.0036:  96%|[36m█████████▌[0m| 25/26 [00:29<00:01,  1.00s/it]Epoch: 5/10. Loss: 0.8665:  96%|[36m█████████▌[0m| 25/26 [00:30<00:01,  1.00s/it]Epoch: 5/10. Loss: 0.8665: 100%|[36m██████████[0m| 26/26 [00:30<00:00,  1.09it/s]Epoch: 5/10. Loss: 0.8665: 100%|[36m██████████[0m| 26/26 [00:30<00:00,  1.18s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:05,  1.13it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:06,  1.22s/it] 43%|[33m████▎     [0m| 3/7 [00:02<00:03,  1.08it/s] 57%|[33m█████▋    [0m| 4/7 [00:04<00:03,  1.17s/it] 71%|[33m███████▏  [0m| 5/7 [00:05<00:01,  1.03it/s] 86%|[33m████████▌ [0m| 6/7 [00:06<00:00,  1.04it/s]100%|[33m██████████[0m| 7/7 [00:06<00:00,  1.33it/s]100%|[33m██████████[0m| 7/7 [00:06<00:00,  1.10it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 6/10. Loss: 0.9091:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 6/10. Loss: 0.9091:   4%|[36m▍         [0m| 1/26 [00:00<00:19,  1.26it/s]Epoch: 6/10. Loss: 0.9939:   4%|[36m▍         [0m| 1/26 [00:01<00:19,  1.26it/s]Epoch: 6/10. Loss: 0.9939:   8%|[36m▊         [0m| 2/26 [00:01<00:19,  1.22it/s]Epoch: 6/10. Loss: 0.8605:   8%|[36m▊         [0m| 2/26 [00:02<00:19,  1.22it/s]Epoch: 6/10. Loss: 0.8605:  12%|[36m█▏        [0m| 3/26 [00:02<00:20,  1.15it/s]Epoch: 6/10. Loss: 0.8928:  12%|[36m█▏        [0m| 3/26 [00:03<00:20,  1.15it/s]Epoch: 6/10. Loss: 0.8928:  15%|[36m█▌        [0m| 4/26 [00:03<00:18,  1.20it/s]Epoch: 6/10. Loss: 0.9746:  15%|[36m█▌        [0m| 4/26 [00:04<00:18,  1.20it/s]Epoch: 6/10. Loss: 0.9746:  19%|[36m█▉        [0m| 5/26 [00:04<00:19,  1.09it/s]Epoch: 6/10. Loss: 0.8964:  19%|[36m█▉        [0m| 5/26 [00:05<00:19,  1.09it/s]Epoch: 6/10. Loss: 0.8964:  23%|[36m██▎       [0m| 6/26 [00:05<00:18,  1.09it/s]Epoch: 6/10. Loss: 0.9010:  23%|[36m██▎       [0m| 6/26 [00:06<00:18,  1.09it/s]Epoch: 6/10. Loss: 0.9010:  27%|[36m██▋       [0m| 7/26 [00:06<00:17,  1.07it/s]Epoch: 6/10. Loss: 0.8887:  27%|[36m██▋       [0m| 7/26 [00:07<00:17,  1.07it/s]Epoch: 6/10. Loss: 0.8887:  31%|[36m███       [0m| 8/26 [00:07<00:17,  1.04it/s]Epoch: 6/10. Loss: 0.9288:  31%|[36m███       [0m| 8/26 [00:08<00:17,  1.04it/s]Epoch: 6/10. Loss: 0.9288:  35%|[36m███▍      [0m| 9/26 [00:08<00:16,  1.03it/s]Epoch: 6/10. Loss: 1.0047:  35%|[36m███▍      [0m| 9/26 [00:10<00:16,  1.03it/s]Epoch: 6/10. Loss: 1.0047:  38%|[36m███▊      [0m| 10/26 [00:10<00:19,  1.23s/it]Epoch: 6/10. Loss: 0.8843:  38%|[36m███▊      [0m| 10/26 [00:11<00:19,  1.23s/it]Epoch: 6/10. Loss: 0.8843:  42%|[36m████▏     [0m| 11/26 [00:11<00:17,  1.14s/it]Epoch: 6/10. Loss: 0.9403:  42%|[36m████▏     [0m| 11/26 [00:12<00:17,  1.14s/it]Epoch: 6/10. Loss: 0.9403:  46%|[36m████▌     [0m| 12/26 [00:12<00:17,  1.25s/it]Epoch: 6/10. Loss: 0.9092:  46%|[36m████▌     [0m| 12/26 [00:13<00:17,  1.25s/it]Epoch: 6/10. Loss: 0.9092:  50%|[36m█████     [0m| 13/26 [00:13<00:16,  1.25s/it]Epoch: 6/10. Loss: 0.8720:  50%|[36m█████     [0m| 13/26 [00:14<00:16,  1.25s/it]Epoch: 6/10. Loss: 0.8720:  54%|[36m█████▍    [0m| 14/26 [00:14<00:13,  1.15s/it]Epoch: 6/10. Loss: 0.8850:  54%|[36m█████▍    [0m| 14/26 [00:15<00:13,  1.15s/it]Epoch: 6/10. Loss: 0.8850:  58%|[36m█████▊    [0m| 15/26 [00:15<00:11,  1.09s/it]Epoch: 6/10. Loss: 0.9295:  58%|[36m█████▊    [0m| 15/26 [00:16<00:11,  1.09s/it]Epoch: 6/10. Loss: 0.9295:  62%|[36m██████▏   [0m| 16/26 [00:16<00:10,  1.06s/it]Epoch: 6/10. Loss: 0.8758:  62%|[36m██████▏   [0m| 16/26 [00:17<00:10,  1.06s/it]Epoch: 6/10. Loss: 0.8758:  65%|[36m██████▌   [0m| 17/26 [00:17<00:09,  1.04s/it]Epoch: 6/10. Loss: 0.8068:  65%|[36m██████▌   [0m| 17/26 [00:18<00:09,  1.04s/it]Epoch: 6/10. Loss: 0.8068:  69%|[36m██████▉   [0m| 18/26 [00:18<00:08,  1.00s/it]Epoch: 6/10. Loss: 0.8735:  69%|[36m██████▉   [0m| 18/26 [00:19<00:08,  1.00s/it]Epoch: 6/10. Loss: 0.8735:  73%|[36m███████▎  [0m| 19/26 [00:19<00:06,  1.04it/s]Epoch: 6/10. Loss: 0.8314:  73%|[36m███████▎  [0m| 19/26 [00:20<00:06,  1.04it/s]Epoch: 6/10. Loss: 0.8314:  77%|[36m███████▋  [0m| 20/26 [00:20<00:05,  1.04it/s]Epoch: 6/10. Loss: 0.9969:  77%|[36m███████▋  [0m| 20/26 [00:21<00:05,  1.04it/s]Epoch: 6/10. Loss: 0.9969:  81%|[36m████████  [0m| 21/26 [00:21<00:04,  1.10it/s]Epoch: 6/10. Loss: 0.8247:  81%|[36m████████  [0m| 21/26 [00:22<00:04,  1.10it/s]Epoch: 6/10. Loss: 0.8247:  85%|[36m████████▍ [0m| 22/26 [00:22<00:03,  1.06it/s]Epoch: 6/10. Loss: 0.9162:  85%|[36m████████▍ [0m| 22/26 [00:23<00:03,  1.06it/s]Epoch: 6/10. Loss: 0.9162:  88%|[36m████████▊ [0m| 23/26 [00:23<00:03,  1.07s/it]Epoch: 6/10. Loss: 0.9299:  88%|[36m████████▊ [0m| 23/26 [00:25<00:03,  1.07s/it]Epoch: 6/10. Loss: 0.9299:  92%|[36m█████████▏[0m| 24/26 [00:25<00:02,  1.26s/it]Epoch: 6/10. Loss: 0.9010:  92%|[36m█████████▏[0m| 24/26 [00:26<00:02,  1.26s/it]Epoch: 6/10. Loss: 0.9010:  96%|[36m█████████▌[0m| 25/26 [00:26<00:01,  1.15s/it]Epoch: 6/10. Loss: 1.0625:  96%|[36m█████████▌[0m| 25/26 [00:26<00:01,  1.15s/it]Epoch: 6/10. Loss: 1.0625: 100%|[36m██████████[0m| 26/26 [00:26<00:00,  1.05s/it]Epoch: 6/10. Loss: 1.0625: 100%|[36m██████████[0m| 26/26 [00:26<00:00,  1.04s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:05,  1.13it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:06,  1.32s/it] 43%|[33m████▎     [0m| 3/7 [00:03<00:03,  1.03it/s] 57%|[33m█████▋    [0m| 4/7 [00:04<00:03,  1.26s/it] 71%|[33m███████▏  [0m| 5/7 [00:05<00:01,  1.03it/s] 86%|[33m████████▌ [0m| 6/7 [00:06<00:00,  1.03it/s]100%|[33m██████████[0m| 7/7 [00:06<00:00,  1.31it/s]100%|[33m██████████[0m| 7/7 [00:06<00:00,  1.07it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 7/10. Loss: 0.8894:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 7/10. Loss: 0.8894:   4%|[36m▍         [0m| 1/26 [00:00<00:23,  1.06it/s]Epoch: 7/10. Loss: 0.9032:   4%|[36m▍         [0m| 1/26 [00:02<00:23,  1.06it/s]Epoch: 7/10. Loss: 0.9032:   8%|[36m▊         [0m| 2/26 [00:02<00:25,  1.08s/it]Epoch: 7/10. Loss: 0.8837:   8%|[36m▊         [0m| 2/26 [00:03<00:25,  1.08s/it]Epoch: 7/10. Loss: 0.8837:  12%|[36m█▏        [0m| 3/26 [00:03<00:23,  1.02s/it]Epoch: 7/10. Loss: 0.9575:  12%|[36m█▏        [0m| 3/26 [00:04<00:23,  1.02s/it]Epoch: 7/10. Loss: 0.9575:  15%|[36m█▌        [0m| 4/26 [00:04<00:22,  1.00s/it]Epoch: 7/10. Loss: 0.8749:  15%|[36m█▌        [0m| 4/26 [00:05<00:22,  1.00s/it]Epoch: 7/10. Loss: 0.8749:  19%|[36m█▉        [0m| 5/26 [00:05<00:22,  1.05s/it]Epoch: 7/10. Loss: 0.9150:  19%|[36m█▉        [0m| 5/26 [00:06<00:22,  1.05s/it]Epoch: 7/10. Loss: 0.9150:  23%|[36m██▎       [0m| 6/26 [00:06<00:20,  1.03s/it]Epoch: 7/10. Loss: 0.9032:  23%|[36m██▎       [0m| 6/26 [00:08<00:20,  1.03s/it]Epoch: 7/10. Loss: 0.9032:  27%|[36m██▋       [0m| 7/26 [00:08<00:25,  1.36s/it]Epoch: 7/10. Loss: 0.9040:  27%|[36m██▋       [0m| 7/26 [00:10<00:25,  1.36s/it]Epoch: 7/10. Loss: 0.9040:  31%|[36m███       [0m| 8/26 [00:10<00:28,  1.57s/it]Epoch: 7/10. Loss: 0.9110:  31%|[36m███       [0m| 8/26 [00:11<00:28,  1.57s/it]Epoch: 7/10. Loss: 0.9110:  35%|[36m███▍      [0m| 9/26 [00:11<00:23,  1.36s/it]Epoch: 7/10. Loss: 0.8858:  35%|[36m███▍      [0m| 9/26 [00:12<00:23,  1.36s/it]Epoch: 7/10. Loss: 0.8858:  38%|[36m███▊      [0m| 10/26 [00:12<00:20,  1.25s/it]Epoch: 7/10. Loss: 0.9506:  38%|[36m███▊      [0m| 10/26 [00:13<00:20,  1.25s/it]Epoch: 7/10. Loss: 0.9506:  42%|[36m████▏     [0m| 11/26 [00:13<00:17,  1.17s/it]Epoch: 7/10. Loss: 0.8532:  42%|[36m████▏     [0m| 11/26 [00:14<00:17,  1.17s/it]Epoch: 7/10. Loss: 0.8532:  46%|[36m████▌     [0m| 12/26 [00:14<00:15,  1.12s/it]Epoch: 7/10. Loss: 0.9055:  46%|[36m████▌     [0m| 12/26 [00:15<00:15,  1.12s/it]Epoch: 7/10. Loss: 0.9055:  50%|[36m█████     [0m| 13/26 [00:15<00:13,  1.07s/it]Epoch: 7/10. Loss: 0.7957:  50%|[36m█████     [0m| 13/26 [00:16<00:13,  1.07s/it]Epoch: 7/10. Loss: 0.7957:  54%|[36m█████▍    [0m| 14/26 [00:16<00:12,  1.07s/it]Epoch: 7/10. Loss: 0.7669:  54%|[36m█████▍    [0m| 14/26 [00:17<00:12,  1.07s/it]Epoch: 7/10. Loss: 0.7669:  58%|[36m█████▊    [0m| 15/26 [00:17<00:11,  1.03s/it]Epoch: 7/10. Loss: 0.8546:  58%|[36m█████▊    [0m| 15/26 [00:18<00:11,  1.03s/it]Epoch: 7/10. Loss: 0.8546:  62%|[36m██████▏   [0m| 16/26 [00:18<00:10,  1.05s/it]Epoch: 7/10. Loss: 0.9149:  62%|[36m██████▏   [0m| 16/26 [00:19<00:10,  1.05s/it]Epoch: 7/10. Loss: 0.9149:  65%|[36m██████▌   [0m| 17/26 [00:19<00:08,  1.00it/s]Epoch: 7/10. Loss: 0.8070:  65%|[36m██████▌   [0m| 17/26 [00:20<00:08,  1.00it/s]Epoch: 7/10. Loss: 0.8070:  69%|[36m██████▉   [0m| 18/26 [00:20<00:08,  1.02s/it]Epoch: 7/10. Loss: 0.8300:  69%|[36m██████▉   [0m| 18/26 [00:21<00:08,  1.02s/it]Epoch: 7/10. Loss: 0.8300:  73%|[36m███████▎  [0m| 19/26 [00:21<00:07,  1.05s/it]Epoch: 7/10. Loss: 0.9123:  73%|[36m███████▎  [0m| 19/26 [00:22<00:07,  1.05s/it]Epoch: 7/10. Loss: 0.9123:  77%|[36m███████▋  [0m| 20/26 [00:22<00:06,  1.01s/it]Epoch: 7/10. Loss: 0.8082:  77%|[36m███████▋  [0m| 20/26 [00:23<00:06,  1.01s/it]Epoch: 7/10. Loss: 0.8082:  81%|[36m████████  [0m| 21/26 [00:23<00:05,  1.02s/it]Epoch: 7/10. Loss: 0.8640:  81%|[36m████████  [0m| 21/26 [00:24<00:05,  1.02s/it]Epoch: 7/10. Loss: 0.8640:  85%|[36m████████▍ [0m| 22/26 [00:24<00:04,  1.02s/it]Epoch: 7/10. Loss: 0.8391:  85%|[36m████████▍ [0m| 22/26 [00:25<00:04,  1.02s/it]Epoch: 7/10. Loss: 0.8391:  88%|[36m████████▊ [0m| 23/26 [00:25<00:03,  1.02s/it]Epoch: 7/10. Loss: 0.8873:  88%|[36m████████▊ [0m| 23/26 [00:26<00:03,  1.02s/it]Epoch: 7/10. Loss: 0.8873:  92%|[36m█████████▏[0m| 24/26 [00:26<00:02,  1.01s/it]Epoch: 7/10. Loss: 1.0539:  92%|[36m█████████▏[0m| 24/26 [00:27<00:02,  1.01s/it]Epoch: 7/10. Loss: 1.0539:  96%|[36m█████████▌[0m| 25/26 [00:27<00:00,  1.05it/s]Epoch: 7/10. Loss: 0.9214:  96%|[36m█████████▌[0m| 25/26 [00:27<00:00,  1.05it/s]Epoch: 7/10. Loss: 0.9214: 100%|[36m██████████[0m| 26/26 [00:27<00:00,  1.16it/s]Epoch: 7/10. Loss: 0.9214: 100%|[36m██████████[0m| 26/26 [00:27<00:00,  1.07s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:05,  1.16it/s] 29%|[33m██▊       [0m| 2/7 [00:03<00:10,  2.13s/it] 43%|[33m████▎     [0m| 3/7 [00:05<00:08,  2.05s/it] 57%|[33m█████▋    [0m| 4/7 [00:07<00:05,  1.83s/it] 71%|[33m███████▏  [0m| 5/7 [00:07<00:02,  1.40s/it] 86%|[33m████████▌ [0m| 6/7 [00:08<00:01,  1.24s/it]100%|[33m██████████[0m| 7/7 [00:09<00:00,  1.06it/s]100%|[33m██████████[0m| 7/7 [00:09<00:00,  1.32s/it]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 8/10. Loss: 0.8620:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 8/10. Loss: 0.8620:   4%|[36m▍         [0m| 1/26 [00:01<00:25,  1.00s/it]Epoch: 8/10. Loss: 0.8722:   4%|[36m▍         [0m| 1/26 [00:02<00:25,  1.00s/it]Epoch: 8/10. Loss: 0.8722:   8%|[36m▊         [0m| 2/26 [00:02<00:26,  1.09s/it]Epoch: 8/10. Loss: 0.9009:   8%|[36m▊         [0m| 2/26 [00:03<00:26,  1.09s/it]Epoch: 8/10. Loss: 0.9009:  12%|[36m█▏        [0m| 3/26 [00:03<00:27,  1.18s/it]Epoch: 8/10. Loss: 0.9425:  12%|[36m█▏        [0m| 3/26 [00:04<00:27,  1.18s/it]Epoch: 8/10. Loss: 0.9425:  15%|[36m█▌        [0m| 4/26 [00:04<00:22,  1.03s/it]Epoch: 8/10. Loss: 0.8676:  15%|[36m█▌        [0m| 4/26 [00:05<00:22,  1.03s/it]Epoch: 8/10. Loss: 0.8676:  19%|[36m█▉        [0m| 5/26 [00:05<00:23,  1.11s/it]Epoch: 8/10. Loss: 0.9811:  19%|[36m█▉        [0m| 5/26 [00:06<00:23,  1.11s/it]Epoch: 8/10. Loss: 0.9811:  23%|[36m██▎       [0m| 6/26 [00:06<00:23,  1.15s/it]Epoch: 8/10. Loss: 0.8487:  23%|[36m██▎       [0m| 6/26 [00:08<00:23,  1.15s/it]Epoch: 8/10. Loss: 0.8487:  27%|[36m██▋       [0m| 7/26 [00:08<00:27,  1.47s/it]Epoch: 8/10. Loss: 0.8679:  27%|[36m██▋       [0m| 7/26 [00:09<00:27,  1.47s/it]Epoch: 8/10. Loss: 0.8679:  31%|[36m███       [0m| 8/26 [00:09<00:22,  1.27s/it]Epoch: 8/10. Loss: 0.8881:  31%|[36m███       [0m| 8/26 [00:10<00:22,  1.27s/it]Epoch: 8/10. Loss: 0.8881:  35%|[36m███▍      [0m| 9/26 [00:10<00:18,  1.11s/it]Epoch: 8/10. Loss: 0.9023:  35%|[36m███▍      [0m| 9/26 [00:11<00:18,  1.11s/it]Epoch: 8/10. Loss: 0.9023:  38%|[36m███▊      [0m| 10/26 [00:11<00:19,  1.20s/it]Epoch: 8/10. Loss: 0.8273:  38%|[36m███▊      [0m| 10/26 [00:13<00:19,  1.20s/it]Epoch: 8/10. Loss: 0.8273:  42%|[36m████▏     [0m| 11/26 [00:13<00:18,  1.21s/it]Epoch: 8/10. Loss: 0.8103:  42%|[36m████▏     [0m| 11/26 [00:14<00:18,  1.21s/it]Epoch: 8/10. Loss: 0.8103:  46%|[36m████▌     [0m| 12/26 [00:14<00:16,  1.16s/it]Epoch: 8/10. Loss: 0.9658:  46%|[36m████▌     [0m| 12/26 [00:15<00:16,  1.16s/it]Epoch: 8/10. Loss: 0.9658:  50%|[36m█████     [0m| 13/26 [00:15<00:14,  1.12s/it]Epoch: 8/10. Loss: 0.8649:  50%|[36m█████     [0m| 13/26 [00:17<00:14,  1.12s/it]Epoch: 8/10. Loss: 0.8649:  54%|[36m█████▍    [0m| 14/26 [00:17<00:18,  1.58s/it]Epoch: 8/10. Loss: 0.8123:  54%|[36m█████▍    [0m| 14/26 [00:19<00:18,  1.58s/it]Epoch: 8/10. Loss: 0.8123:  58%|[36m█████▊    [0m| 15/26 [00:19<00:18,  1.69s/it]Epoch: 8/10. Loss: 0.8610:  58%|[36m█████▊    [0m| 15/26 [00:21<00:18,  1.69s/it]Epoch: 8/10. Loss: 0.8610:  62%|[36m██████▏   [0m| 16/26 [00:21<00:18,  1.84s/it]Epoch: 8/10. Loss: 0.8285:  62%|[36m██████▏   [0m| 16/26 [00:24<00:18,  1.84s/it]Epoch: 8/10. Loss: 0.8285:  65%|[36m██████▌   [0m| 17/26 [00:24<00:18,  2.06s/it]Epoch: 8/10. Loss: 0.9583:  65%|[36m██████▌   [0m| 17/26 [00:26<00:18,  2.06s/it]Epoch: 8/10. Loss: 0.9583:  69%|[36m██████▉   [0m| 18/26 [00:26<00:15,  1.98s/it]Epoch: 8/10. Loss: 0.9265:  69%|[36m██████▉   [0m| 18/26 [00:27<00:15,  1.98s/it]Epoch: 8/10. Loss: 0.9265:  73%|[36m███████▎  [0m| 19/26 [00:27<00:11,  1.63s/it]Epoch: 8/10. Loss: 0.8873:  73%|[36m███████▎  [0m| 19/26 [00:28<00:11,  1.63s/it]Epoch: 8/10. Loss: 0.8873:  77%|[36m███████▋  [0m| 20/26 [00:28<00:08,  1.48s/it]Epoch: 8/10. Loss: 0.8564:  77%|[36m███████▋  [0m| 20/26 [00:28<00:08,  1.48s/it]Epoch: 8/10. Loss: 0.8564:  81%|[36m████████  [0m| 21/26 [00:28<00:06,  1.26s/it]Epoch: 8/10. Loss: 0.8224:  81%|[36m████████  [0m| 21/26 [00:29<00:06,  1.26s/it]Epoch: 8/10. Loss: 0.8224:  85%|[36m████████▍ [0m| 22/26 [00:29<00:04,  1.16s/it]Epoch: 8/10. Loss: 0.8384:  85%|[36m████████▍ [0m| 22/26 [00:31<00:04,  1.16s/it]Epoch: 8/10. Loss: 0.8384:  88%|[36m████████▊ [0m| 23/26 [00:31<00:03,  1.21s/it]Epoch: 8/10. Loss: 0.8141:  88%|[36m████████▊ [0m| 23/26 [00:32<00:03,  1.21s/it]Epoch: 8/10. Loss: 0.8141:  92%|[36m█████████▏[0m| 24/26 [00:32<00:02,  1.18s/it]Epoch: 8/10. Loss: 1.0199:  92%|[36m█████████▏[0m| 24/26 [00:33<00:02,  1.18s/it]Epoch: 8/10. Loss: 1.0199:  96%|[36m█████████▌[0m| 25/26 [00:33<00:01,  1.10s/it]Epoch: 8/10. Loss: 0.8967:  96%|[36m█████████▌[0m| 25/26 [00:33<00:01,  1.10s/it]Epoch: 8/10. Loss: 0.8967: 100%|[36m██████████[0m| 26/26 [00:33<00:00,  1.03it/s]Epoch: 8/10. Loss: 0.8967: 100%|[36m██████████[0m| 26/26 [00:33<00:00,  1.30s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:05,  1.14it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:06,  1.22s/it] 43%|[33m████▎     [0m| 3/7 [00:02<00:03,  1.09it/s] 57%|[33m█████▋    [0m| 4/7 [00:04<00:03,  1.12s/it] 71%|[33m███████▏  [0m| 5/7 [00:04<00:01,  1.14it/s] 86%|[33m████████▌ [0m| 6/7 [00:05<00:00,  1.11it/s]100%|[33m██████████[0m| 7/7 [00:06<00:00,  1.39it/s]100%|[33m██████████[0m| 7/7 [00:06<00:00,  1.16it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 9/10. Loss: 0.7512:   0%|[36m          [0m| 0/26 [00:01<?, ?it/s]Epoch: 9/10. Loss: 0.7512:   4%|[36m▍         [0m| 1/26 [00:01<00:26,  1.06s/it]Epoch: 9/10. Loss: 0.8610:   4%|[36m▍         [0m| 1/26 [00:03<00:26,  1.06s/it]Epoch: 9/10. Loss: 0.8610:   8%|[36m▊         [0m| 2/26 [00:03<00:42,  1.78s/it]Epoch: 9/10. Loss: 0.8613:   8%|[36m▊         [0m| 2/26 [00:04<00:42,  1.78s/it]Epoch: 9/10. Loss: 0.8613:  12%|[36m█▏        [0m| 3/26 [00:04<00:36,  1.60s/it]Epoch: 9/10. Loss: 0.8508:  12%|[36m█▏        [0m| 3/26 [00:05<00:36,  1.60s/it]Epoch: 9/10. Loss: 0.8508:  15%|[36m█▌        [0m| 4/26 [00:05<00:30,  1.41s/it]Epoch: 9/10. Loss: 0.8842:  15%|[36m█▌        [0m| 4/26 [00:06<00:30,  1.41s/it]Epoch: 9/10. Loss: 0.8842:  19%|[36m█▉        [0m| 5/26 [00:06<00:27,  1.29s/it]Epoch: 9/10. Loss: 0.8899:  19%|[36m█▉        [0m| 5/26 [00:09<00:27,  1.29s/it]Epoch: 9/10. Loss: 0.8899:  23%|[36m██▎       [0m| 6/26 [00:09<00:34,  1.74s/it]Epoch: 9/10. Loss: 0.8222:  23%|[36m██▎       [0m| 6/26 [00:11<00:34,  1.74s/it]Epoch: 9/10. Loss: 0.8222:  27%|[36m██▋       [0m| 7/26 [00:11<00:33,  1.76s/it]Epoch: 9/10. Loss: 0.9746:  27%|[36m██▋       [0m| 7/26 [00:12<00:33,  1.76s/it]Epoch: 9/10. Loss: 0.9746:  31%|[36m███       [0m| 8/26 [00:12<00:27,  1.50s/it]Epoch: 9/10. Loss: 0.9975:  31%|[36m███       [0m| 8/26 [00:13<00:27,  1.50s/it]Epoch: 9/10. Loss: 0.9975:  35%|[36m███▍      [0m| 9/26 [00:13<00:23,  1.39s/it]Epoch: 9/10. Loss: 0.8647:  35%|[36m███▍      [0m| 9/26 [00:15<00:23,  1.39s/it]Epoch: 9/10. Loss: 0.8647:  38%|[36m███▊      [0m| 10/26 [00:15<00:24,  1.53s/it]Epoch: 9/10. Loss: 0.9191:  38%|[36m███▊      [0m| 10/26 [00:16<00:24,  1.53s/it]Epoch: 9/10. Loss: 0.9191:  42%|[36m████▏     [0m| 11/26 [00:16<00:21,  1.42s/it]Epoch: 9/10. Loss: 0.8310:  42%|[36m████▏     [0m| 11/26 [00:17<00:21,  1.42s/it]Epoch: 9/10. Loss: 0.8310:  46%|[36m████▌     [0m| 12/26 [00:17<00:18,  1.33s/it]Epoch: 9/10. Loss: 0.8757:  46%|[36m████▌     [0m| 12/26 [00:18<00:18,  1.33s/it]Epoch: 9/10. Loss: 0.8757:  50%|[36m█████     [0m| 13/26 [00:18<00:15,  1.21s/it]Epoch: 9/10. Loss: 0.8923:  50%|[36m█████     [0m| 13/26 [00:19<00:15,  1.21s/it]Epoch: 9/10. Loss: 0.8923:  54%|[36m█████▍    [0m| 14/26 [00:19<00:13,  1.13s/it]Epoch: 9/10. Loss: 0.8330:  54%|[36m█████▍    [0m| 14/26 [00:20<00:13,  1.13s/it]Epoch: 9/10. Loss: 0.8330:  58%|[36m█████▊    [0m| 15/26 [00:20<00:11,  1.03s/it]Epoch: 9/10. Loss: 0.8611:  58%|[36m█████▊    [0m| 15/26 [00:21<00:11,  1.03s/it]Epoch: 9/10. Loss: 0.8611:  62%|[36m██████▏   [0m| 16/26 [00:21<00:09,  1.02it/s]Epoch: 9/10. Loss: 0.8424:  62%|[36m██████▏   [0m| 16/26 [00:21<00:09,  1.02it/s]Epoch: 9/10. Loss: 0.8424:  65%|[36m██████▌   [0m| 17/26 [00:21<00:08,  1.07it/s]Epoch: 9/10. Loss: 0.7823:  65%|[36m██████▌   [0m| 17/26 [00:23<00:08,  1.07it/s]Epoch: 9/10. Loss: 0.7823:  69%|[36m██████▉   [0m| 18/26 [00:23<00:07,  1.02it/s]Epoch: 9/10. Loss: 0.8433:  69%|[36m██████▉   [0m| 18/26 [00:23<00:07,  1.02it/s]Epoch: 9/10. Loss: 0.8433:  73%|[36m███████▎  [0m| 19/26 [00:23<00:06,  1.09it/s]Epoch: 9/10. Loss: 0.9116:  73%|[36m███████▎  [0m| 19/26 [00:24<00:06,  1.09it/s]Epoch: 9/10. Loss: 0.9116:  77%|[36m███████▋  [0m| 20/26 [00:24<00:05,  1.08it/s]Epoch: 9/10. Loss: 0.8779:  77%|[36m███████▋  [0m| 20/26 [00:25<00:05,  1.08it/s]Epoch: 9/10. Loss: 0.8779:  81%|[36m████████  [0m| 21/26 [00:25<00:04,  1.06it/s]Epoch: 9/10. Loss: 0.8683:  81%|[36m████████  [0m| 21/26 [00:26<00:04,  1.06it/s]Epoch: 9/10. Loss: 0.8683:  85%|[36m████████▍ [0m| 22/26 [00:26<00:03,  1.05it/s]Epoch: 9/10. Loss: 0.8008:  85%|[36m████████▍ [0m| 22/26 [00:27<00:03,  1.05it/s]Epoch: 9/10. Loss: 0.8008:  88%|[36m████████▊ [0m| 23/26 [00:27<00:02,  1.10it/s]Epoch: 9/10. Loss: 1.0161:  88%|[36m████████▊ [0m| 23/26 [00:28<00:02,  1.10it/s]Epoch: 9/10. Loss: 1.0161:  92%|[36m█████████▏[0m| 24/26 [00:28<00:01,  1.13it/s]Epoch: 9/10. Loss: 0.8618:  92%|[36m█████████▏[0m| 24/26 [00:29<00:01,  1.13it/s]Epoch: 9/10. Loss: 0.8618:  96%|[36m█████████▌[0m| 25/26 [00:29<00:01,  1.08s/it]Epoch: 9/10. Loss: 0.8229:  96%|[36m█████████▌[0m| 25/26 [00:30<00:01,  1.08s/it]Epoch: 9/10. Loss: 0.8229: 100%|[36m██████████[0m| 26/26 [00:30<00:00,  1.06it/s]Epoch: 9/10. Loss: 0.8229: 100%|[36m██████████[0m| 26/26 [00:30<00:00,  1.17s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:05,  1.16it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:05,  1.19s/it] 43%|[33m████▎     [0m| 3/7 [00:02<00:03,  1.15it/s] 57%|[33m█████▋    [0m| 4/7 [00:04<00:03,  1.05s/it] 71%|[33m███████▏  [0m| 5/7 [00:04<00:01,  1.24it/s] 86%|[33m████████▌ [0m| 6/7 [00:05<00:00,  1.22it/s]100%|[33m██████████[0m| 7/7 [00:07<00:00,  1.24s/it]100%|[33m██████████[0m| 7/7 [00:07<00:00,  1.06s/it]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 0/10. Loss: 1.3320:   0%|[36m          [0m| 0/26 [00:01<?, ?it/s]Epoch: 0/10. Loss: 1.3320:   4%|[36m▍         [0m| 1/26 [00:01<00:29,  1.17s/it]Epoch: 0/10. Loss: 3.3166:   4%|[36m▍         [0m| 1/26 [00:02<00:29,  1.17s/it]Epoch: 0/10. Loss: 3.3166:   8%|[36m▊         [0m| 2/26 [00:02<00:23,  1.01it/s]Epoch: 0/10. Loss: 3.2925:   8%|[36m▊         [0m| 2/26 [00:03<00:23,  1.01it/s]Epoch: 0/10. Loss: 3.2925:  12%|[36m█▏        [0m| 3/26 [00:03<00:22,  1.01it/s]Epoch: 0/10. Loss: 1.9432:  12%|[36m█▏        [0m| 3/26 [00:03<00:22,  1.01it/s]Epoch: 0/10. Loss: 1.9432:  15%|[36m█▌        [0m| 4/26 [00:03<00:19,  1.10it/s]Epoch: 0/10. Loss: 1.4412:  15%|[36m█▌        [0m| 4/26 [00:04<00:19,  1.10it/s]Epoch: 0/10. Loss: 1.4412:  19%|[36m█▉        [0m| 5/26 [00:04<00:18,  1.12it/s]Epoch: 0/10. Loss: 1.1500:  19%|[36m█▉        [0m| 5/26 [00:05<00:18,  1.12it/s]Epoch: 0/10. Loss: 1.1500:  23%|[36m██▎       [0m| 6/26 [00:05<00:16,  1.18it/s]Epoch: 0/10. Loss: 1.2376:  23%|[36m██▎       [0m| 6/26 [00:07<00:16,  1.18it/s]Epoch: 0/10. Loss: 1.2376:  27%|[36m██▋       [0m| 7/26 [00:07<00:23,  1.24s/it]Epoch: 0/10. Loss: 1.2664:  27%|[36m██▋       [0m| 7/26 [00:08<00:23,  1.24s/it]Epoch: 0/10. Loss: 1.2664:  31%|[36m███       [0m| 8/26 [00:08<00:20,  1.16s/it]Epoch: 0/10. Loss: 1.0285:  31%|[36m███       [0m| 8/26 [00:09<00:20,  1.16s/it]Epoch: 0/10. Loss: 1.0285:  35%|[36m███▍      [0m| 9/26 [00:09<00:21,  1.27s/it]Epoch: 0/10. Loss: 0.9814:  35%|[36m███▍      [0m| 9/26 [00:11<00:21,  1.27s/it]Epoch: 0/10. Loss: 0.9814:  38%|[36m███▊      [0m| 10/26 [00:11<00:20,  1.28s/it]Epoch: 0/10. Loss: 1.0450:  38%|[36m███▊      [0m| 10/26 [00:12<00:20,  1.28s/it]Epoch: 0/10. Loss: 1.0450:  42%|[36m████▏     [0m| 11/26 [00:12<00:17,  1.15s/it]Epoch: 0/10. Loss: 1.4556:  42%|[36m████▏     [0m| 11/26 [00:13<00:17,  1.15s/it]Epoch: 0/10. Loss: 1.4556:  46%|[36m████▌     [0m| 12/26 [00:13<00:15,  1.10s/it]Epoch: 0/10. Loss: 1.1274:  46%|[36m████▌     [0m| 12/26 [00:14<00:15,  1.10s/it]Epoch: 0/10. Loss: 1.1274:  50%|[36m█████     [0m| 13/26 [00:14<00:13,  1.06s/it]Epoch: 0/10. Loss: 1.2675:  50%|[36m█████     [0m| 13/26 [00:14<00:13,  1.06s/it]Epoch: 0/10. Loss: 1.2675:  54%|[36m█████▍    [0m| 14/26 [00:14<00:11,  1.04it/s]Epoch: 0/10. Loss: 1.3500:  54%|[36m█████▍    [0m| 14/26 [00:15<00:11,  1.04it/s]Epoch: 0/10. Loss: 1.3500:  58%|[36m█████▊    [0m| 15/26 [00:15<00:10,  1.05it/s]Epoch: 0/10. Loss: 1.1982:  58%|[36m█████▊    [0m| 15/26 [00:16<00:10,  1.05it/s]Epoch: 0/10. Loss: 1.1982:  62%|[36m██████▏   [0m| 16/26 [00:16<00:09,  1.07it/s]Epoch: 0/10. Loss: 1.3062:  62%|[36m██████▏   [0m| 16/26 [00:17<00:09,  1.07it/s]Epoch: 0/10. Loss: 1.3062:  65%|[36m██████▌   [0m| 17/26 [00:17<00:08,  1.10it/s]Epoch: 0/10. Loss: 1.0156:  65%|[36m██████▌   [0m| 17/26 [00:18<00:08,  1.10it/s]Epoch: 0/10. Loss: 1.0156:  69%|[36m██████▉   [0m| 18/26 [00:18<00:06,  1.16it/s]Epoch: 0/10. Loss: 1.2444:  69%|[36m██████▉   [0m| 18/26 [00:19<00:06,  1.16it/s]Epoch: 0/10. Loss: 1.2444:  73%|[36m███████▎  [0m| 19/26 [00:19<00:06,  1.16it/s]Epoch: 0/10. Loss: 1.1089:  73%|[36m███████▎  [0m| 19/26 [00:19<00:06,  1.16it/s]Epoch: 0/10. Loss: 1.1089:  77%|[36m███████▋  [0m| 20/26 [00:19<00:05,  1.16it/s]Epoch: 0/10. Loss: 1.3126:  77%|[36m███████▋  [0m| 20/26 [00:20<00:05,  1.16it/s]Epoch: 0/10. Loss: 1.3126:  81%|[36m████████  [0m| 21/26 [00:20<00:04,  1.15it/s]Epoch: 0/10. Loss: 1.2827:  81%|[36m████████  [0m| 21/26 [00:22<00:04,  1.15it/s]Epoch: 0/10. Loss: 1.2827:  85%|[36m████████▍ [0m| 22/26 [00:22<00:03,  1.04it/s]Epoch: 0/10. Loss: 1.1878:  85%|[36m████████▍ [0m| 22/26 [00:22<00:03,  1.04it/s]Epoch: 0/10. Loss: 1.1878:  88%|[36m████████▊ [0m| 23/26 [00:22<00:02,  1.05it/s]Epoch: 0/10. Loss: 1.1091:  88%|[36m████████▊ [0m| 23/26 [00:23<00:02,  1.05it/s]Epoch: 0/10. Loss: 1.1091:  92%|[36m█████████▏[0m| 24/26 [00:23<00:01,  1.06it/s]Epoch: 0/10. Loss: 1.0273:  92%|[36m█████████▏[0m| 24/26 [00:24<00:01,  1.06it/s]Epoch: 0/10. Loss: 1.0273:  96%|[36m█████████▌[0m| 25/26 [00:24<00:00,  1.04it/s]Epoch: 0/10. Loss: 1.1230:  96%|[36m█████████▌[0m| 25/26 [00:25<00:00,  1.04it/s]Epoch: 0/10. Loss: 1.1230: 100%|[36m██████████[0m| 26/26 [00:25<00:00,  1.06it/s]Epoch: 0/10. Loss: 1.1230: 100%|[36m██████████[0m| 26/26 [00:25<00:00,  1.01it/s]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:01<00:07,  1.22s/it] 29%|[33m██▊       [0m| 2/7 [00:02<00:06,  1.31s/it] 43%|[33m████▎     [0m| 3/7 [00:03<00:03,  1.08it/s] 57%|[33m█████▋    [0m| 4/7 [00:04<00:03,  1.07s/it] 71%|[33m███████▏  [0m| 5/7 [00:04<00:01,  1.24it/s] 86%|[33m████████▌ [0m| 6/7 [00:05<00:00,  1.20it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.53it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.19it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 1/10. Loss: 1.3494:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 1/10. Loss: 1.3494:   4%|[36m▍         [0m| 1/26 [00:00<00:20,  1.20it/s]Epoch: 1/10. Loss: 1.0446:   4%|[36m▍         [0m| 1/26 [00:01<00:20,  1.20it/s]Epoch: 1/10. Loss: 1.0446:   8%|[36m▊         [0m| 2/26 [00:01<00:22,  1.08it/s]Epoch: 1/10. Loss: 1.2278:   8%|[36m▊         [0m| 2/26 [00:03<00:22,  1.08it/s]Epoch: 1/10. Loss: 1.2278:  12%|[36m█▏        [0m| 3/26 [00:03<00:24,  1.05s/it]Epoch: 1/10. Loss: 1.0205:  12%|[36m█▏        [0m| 3/26 [00:03<00:24,  1.05s/it]Epoch: 1/10. Loss: 1.0205:  15%|[36m█▌        [0m| 4/26 [00:03<00:20,  1.07it/s]Epoch: 1/10. Loss: 1.0166:  15%|[36m█▌        [0m| 4/26 [00:04<00:20,  1.07it/s]Epoch: 1/10. Loss: 1.0166:  19%|[36m█▉        [0m| 5/26 [00:04<00:19,  1.09it/s]Epoch: 1/10. Loss: 0.9600:  19%|[36m█▉        [0m| 5/26 [00:05<00:19,  1.09it/s]Epoch: 1/10. Loss: 0.9600:  23%|[36m██▎       [0m| 6/26 [00:05<00:17,  1.15it/s]Epoch: 1/10. Loss: 1.0978:  23%|[36m██▎       [0m| 6/26 [00:06<00:17,  1.15it/s]Epoch: 1/10. Loss: 1.0978:  27%|[36m██▋       [0m| 7/26 [00:06<00:17,  1.07it/s]Epoch: 1/10. Loss: 1.1175:  27%|[36m██▋       [0m| 7/26 [00:07<00:17,  1.07it/s]Epoch: 1/10. Loss: 1.1175:  31%|[36m███       [0m| 8/26 [00:07<00:16,  1.07it/s]Epoch: 1/10. Loss: 1.0353:  31%|[36m███       [0m| 8/26 [00:08<00:16,  1.07it/s]Epoch: 1/10. Loss: 1.0353:  35%|[36m███▍      [0m| 9/26 [00:08<00:16,  1.04it/s]Epoch: 1/10. Loss: 1.0426:  35%|[36m███▍      [0m| 9/26 [00:09<00:16,  1.04it/s]Epoch: 1/10. Loss: 1.0426:  38%|[36m███▊      [0m| 10/26 [00:09<00:15,  1.06it/s]Epoch: 1/10. Loss: 1.0295:  38%|[36m███▊      [0m| 10/26 [00:10<00:15,  1.06it/s]Epoch: 1/10. Loss: 1.0295:  42%|[36m████▏     [0m| 11/26 [00:10<00:14,  1.03it/s]Epoch: 1/10. Loss: 1.2167:  42%|[36m████▏     [0m| 11/26 [00:11<00:14,  1.03it/s]Epoch: 1/10. Loss: 1.2167:  46%|[36m████▌     [0m| 12/26 [00:11<00:14,  1.05s/it]Epoch: 1/10. Loss: 1.2438:  46%|[36m████▌     [0m| 12/26 [00:12<00:14,  1.05s/it]Epoch: 1/10. Loss: 1.2438:  50%|[36m█████     [0m| 13/26 [00:12<00:13,  1.07s/it]Epoch: 1/10. Loss: 1.2149:  50%|[36m█████     [0m| 13/26 [00:13<00:13,  1.07s/it]Epoch: 1/10. Loss: 1.2149:  54%|[36m█████▍    [0m| 14/26 [00:13<00:11,  1.01it/s]Epoch: 1/10. Loss: 1.1376:  54%|[36m█████▍    [0m| 14/26 [00:16<00:11,  1.01it/s]Epoch: 1/10. Loss: 1.1376:  58%|[36m█████▊    [0m| 15/26 [00:16<00:16,  1.47s/it]Epoch: 1/10. Loss: 1.0617:  58%|[36m█████▊    [0m| 15/26 [00:17<00:16,  1.47s/it]Epoch: 1/10. Loss: 1.0617:  62%|[36m██████▏   [0m| 16/26 [00:17<00:15,  1.53s/it]Epoch: 1/10. Loss: 1.0619:  62%|[36m██████▏   [0m| 16/26 [00:18<00:15,  1.53s/it]Epoch: 1/10. Loss: 1.0619:  65%|[36m██████▌   [0m| 17/26 [00:18<00:11,  1.28s/it]Epoch: 1/10. Loss: 1.1007:  65%|[36m██████▌   [0m| 17/26 [00:19<00:11,  1.28s/it]Epoch: 1/10. Loss: 1.1007:  69%|[36m██████▉   [0m| 18/26 [00:19<00:09,  1.19s/it]Epoch: 1/10. Loss: 1.0854:  69%|[36m██████▉   [0m| 18/26 [00:21<00:09,  1.19s/it]Epoch: 1/10. Loss: 1.0854:  73%|[36m███████▎  [0m| 19/26 [00:21<00:10,  1.53s/it]Epoch: 1/10. Loss: 1.1452:  73%|[36m███████▎  [0m| 19/26 [00:24<00:10,  1.53s/it]Epoch: 1/10. Loss: 1.1452:  77%|[36m███████▋  [0m| 20/26 [00:24<00:11,  1.85s/it]Epoch: 1/10. Loss: 0.9700:  77%|[36m███████▋  [0m| 20/26 [00:25<00:11,  1.85s/it]Epoch: 1/10. Loss: 0.9700:  81%|[36m████████  [0m| 21/26 [00:25<00:07,  1.56s/it]Epoch: 1/10. Loss: 1.0451:  81%|[36m████████  [0m| 21/26 [00:26<00:07,  1.56s/it]Epoch: 1/10. Loss: 1.0451:  85%|[36m████████▍ [0m| 22/26 [00:26<00:05,  1.34s/it]Epoch: 1/10. Loss: 0.9984:  85%|[36m████████▍ [0m| 22/26 [00:27<00:05,  1.34s/it]Epoch: 1/10. Loss: 0.9984:  88%|[36m████████▊ [0m| 23/26 [00:27<00:03,  1.22s/it]Epoch: 1/10. Loss: 1.1468:  88%|[36m████████▊ [0m| 23/26 [00:27<00:03,  1.22s/it]Epoch: 1/10. Loss: 1.1468:  92%|[36m█████████▏[0m| 24/26 [00:27<00:02,  1.09s/it]Epoch: 1/10. Loss: 1.0726:  92%|[36m█████████▏[0m| 24/26 [00:28<00:02,  1.09s/it]Epoch: 1/10. Loss: 1.0726:  96%|[36m█████████▌[0m| 25/26 [00:28<00:01,  1.03s/it]Epoch: 1/10. Loss: 1.1354:  96%|[36m█████████▌[0m| 25/26 [00:29<00:01,  1.03s/it]Epoch: 1/10. Loss: 1.1354: 100%|[36m██████████[0m| 26/26 [00:29<00:00,  1.02it/s]Epoch: 1/10. Loss: 1.1354: 100%|[36m██████████[0m| 26/26 [00:29<00:00,  1.14s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:05,  1.03it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:06,  1.23s/it] 43%|[33m████▎     [0m| 3/7 [00:02<00:03,  1.11it/s] 57%|[33m█████▋    [0m| 4/7 [00:04<00:03,  1.07s/it] 71%|[33m███████▏  [0m| 5/7 [00:04<00:01,  1.21it/s] 86%|[33m████████▌ [0m| 6/7 [00:05<00:00,  1.19it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.50it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.21it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 2/10. Loss: 1.0289:   0%|[36m          [0m| 0/26 [00:01<?, ?it/s]Epoch: 2/10. Loss: 1.0289:   4%|[36m▍         [0m| 1/26 [00:01<00:28,  1.13s/it]Epoch: 2/10. Loss: 0.9945:   4%|[36m▍         [0m| 1/26 [00:02<00:28,  1.13s/it]Epoch: 2/10. Loss: 0.9945:   8%|[36m▊         [0m| 2/26 [00:02<00:24,  1.03s/it]Epoch: 2/10. Loss: 1.0020:   8%|[36m▊         [0m| 2/26 [00:03<00:24,  1.03s/it]Epoch: 2/10. Loss: 1.0020:  12%|[36m█▏        [0m| 3/26 [00:03<00:23,  1.02s/it]Epoch: 2/10. Loss: 1.0214:  12%|[36m█▏        [0m| 3/26 [00:04<00:23,  1.02s/it]Epoch: 2/10. Loss: 1.0214:  15%|[36m█▌        [0m| 4/26 [00:04<00:22,  1.01s/it]Epoch: 2/10. Loss: 0.9922:  15%|[36m█▌        [0m| 4/26 [00:06<00:22,  1.01s/it]Epoch: 2/10. Loss: 0.9922:  19%|[36m█▉        [0m| 5/26 [00:06<00:29,  1.42s/it]Epoch: 2/10. Loss: 0.9428:  19%|[36m█▉        [0m| 5/26 [00:07<00:29,  1.42s/it]Epoch: 2/10. Loss: 0.9428:  23%|[36m██▎       [0m| 6/26 [00:07<00:25,  1.26s/it]Epoch: 2/10. Loss: 0.9819:  23%|[36m██▎       [0m| 6/26 [00:08<00:25,  1.26s/it]Epoch: 2/10. Loss: 0.9819:  27%|[36m██▋       [0m| 7/26 [00:08<00:21,  1.13s/it]Epoch: 2/10. Loss: 0.9579:  27%|[36m██▋       [0m| 7/26 [00:08<00:21,  1.13s/it]Epoch: 2/10. Loss: 0.9579:  31%|[36m███       [0m| 8/26 [00:09<00:19,  1.07s/it]Epoch: 2/10. Loss: 1.0466:  31%|[36m███       [0m| 8/26 [00:10<00:19,  1.07s/it]Epoch: 2/10. Loss: 1.0466:  35%|[36m███▍      [0m| 9/26 [00:10<00:18,  1.10s/it]Epoch: 2/10. Loss: 1.1459:  35%|[36m███▍      [0m| 9/26 [00:11<00:18,  1.10s/it]Epoch: 2/10. Loss: 1.1459:  38%|[36m███▊      [0m| 10/26 [00:11<00:16,  1.06s/it]Epoch: 2/10. Loss: 1.0840:  38%|[36m███▊      [0m| 10/26 [00:12<00:16,  1.06s/it]Epoch: 2/10. Loss: 1.0840:  42%|[36m████▏     [0m| 11/26 [00:12<00:15,  1.02s/it]Epoch: 2/10. Loss: 0.9675:  42%|[36m████▏     [0m| 11/26 [00:12<00:15,  1.02s/it]Epoch: 2/10. Loss: 0.9675:  46%|[36m████▌     [0m| 12/26 [00:12<00:13,  1.02it/s]Epoch: 2/10. Loss: 0.9721:  46%|[36m████▌     [0m| 12/26 [00:14<00:13,  1.02it/s]Epoch: 2/10. Loss: 0.9721:  50%|[36m█████     [0m| 13/26 [00:14<00:16,  1.27s/it]Epoch: 2/10. Loss: 0.9990:  50%|[36m█████     [0m| 13/26 [00:15<00:16,  1.27s/it]Epoch: 2/10. Loss: 0.9990:  54%|[36m█████▍    [0m| 14/26 [00:15<00:14,  1.17s/it]Epoch: 2/10. Loss: 0.9861:  54%|[36m█████▍    [0m| 14/26 [00:16<00:14,  1.17s/it]Epoch: 2/10. Loss: 0.9861:  58%|[36m█████▊    [0m| 15/26 [00:16<00:11,  1.06s/it]Epoch: 2/10. Loss: 1.0226:  58%|[36m█████▊    [0m| 15/26 [00:17<00:11,  1.06s/it]Epoch: 2/10. Loss: 1.0226:  62%|[36m██████▏   [0m| 16/26 [00:17<00:11,  1.13s/it]Epoch: 2/10. Loss: 1.0586:  62%|[36m██████▏   [0m| 16/26 [00:19<00:11,  1.13s/it]Epoch: 2/10. Loss: 1.0586:  65%|[36m██████▌   [0m| 17/26 [00:19<00:10,  1.13s/it]Epoch: 2/10. Loss: 0.9928:  65%|[36m██████▌   [0m| 17/26 [00:19<00:10,  1.13s/it]Epoch: 2/10. Loss: 0.9928:  69%|[36m██████▉   [0m| 18/26 [00:20<00:08,  1.08s/it]Epoch: 2/10. Loss: 0.9162:  69%|[36m██████▉   [0m| 18/26 [00:22<00:08,  1.08s/it]Epoch: 2/10. Loss: 0.9162:  73%|[36m███████▎  [0m| 19/26 [00:22<00:10,  1.45s/it]Epoch: 2/10. Loss: 0.9499:  73%|[36m███████▎  [0m| 19/26 [00:23<00:10,  1.45s/it]Epoch: 2/10. Loss: 0.9499:  77%|[36m███████▋  [0m| 20/26 [00:23<00:07,  1.31s/it]Epoch: 2/10. Loss: 0.9859:  77%|[36m███████▋  [0m| 20/26 [00:24<00:07,  1.31s/it]Epoch: 2/10. Loss: 0.9859:  81%|[36m████████  [0m| 21/26 [00:24<00:07,  1.42s/it]Epoch: 2/10. Loss: 1.0022:  81%|[36m████████  [0m| 21/26 [00:27<00:07,  1.42s/it]Epoch: 2/10. Loss: 1.0022:  85%|[36m████████▍ [0m| 22/26 [00:27<00:06,  1.74s/it]Epoch: 2/10. Loss: 1.0227:  85%|[36m████████▍ [0m| 22/26 [00:28<00:06,  1.74s/it]Epoch: 2/10. Loss: 1.0227:  88%|[36m████████▊ [0m| 23/26 [00:28<00:04,  1.60s/it]Epoch: 2/10. Loss: 0.9479:  88%|[36m████████▊ [0m| 23/26 [00:29<00:04,  1.60s/it]Epoch: 2/10. Loss: 0.9479:  92%|[36m█████████▏[0m| 24/26 [00:29<00:02,  1.38s/it]Epoch: 2/10. Loss: 0.9150:  92%|[36m█████████▏[0m| 24/26 [00:30<00:02,  1.38s/it]Epoch: 2/10. Loss: 0.9150:  96%|[36m█████████▌[0m| 25/26 [00:30<00:01,  1.34s/it]Epoch: 2/10. Loss: 0.9817:  96%|[36m█████████▌[0m| 25/26 [00:31<00:01,  1.34s/it]Epoch: 2/10. Loss: 0.9817: 100%|[36m██████████[0m| 26/26 [00:31<00:00,  1.16s/it]Epoch: 2/10. Loss: 0.9817: 100%|[36m██████████[0m| 26/26 [00:31<00:00,  1.22s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:05,  1.05it/s] 29%|[33m██▊       [0m| 2/7 [00:03<00:08,  1.72s/it] 43%|[33m████▎     [0m| 3/7 [00:03<00:04,  1.16s/it] 57%|[33m█████▋    [0m| 4/7 [00:05<00:03,  1.23s/it] 71%|[33m███████▏  [0m| 5/7 [00:05<00:01,  1.07it/s] 86%|[33m████████▌ [0m| 6/7 [00:06<00:01,  1.07s/it]100%|[33m██████████[0m| 7/7 [00:07<00:00,  1.22it/s]100%|[33m██████████[0m| 7/7 [00:07<00:00,  1.01s/it]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 3/10. Loss: 0.8939:   0%|[36m          [0m| 0/26 [00:01<?, ?it/s]Epoch: 3/10. Loss: 0.8939:   4%|[36m▍         [0m| 1/26 [00:01<00:34,  1.38s/it]Epoch: 3/10. Loss: 0.9037:   4%|[36m▍         [0m| 1/26 [00:02<00:34,  1.38s/it]Epoch: 3/10. Loss: 0.9037:   8%|[36m▊         [0m| 2/26 [00:02<00:29,  1.23s/it]Epoch: 3/10. Loss: 0.9557:   8%|[36m▊         [0m| 2/26 [00:03<00:29,  1.23s/it]Epoch: 3/10. Loss: 0.9557:  12%|[36m█▏        [0m| 3/26 [00:03<00:27,  1.18s/it]Epoch: 3/10. Loss: 0.9525:  12%|[36m█▏        [0m| 3/26 [00:04<00:27,  1.18s/it]Epoch: 3/10. Loss: 0.9525:  15%|[36m█▌        [0m| 4/26 [00:04<00:25,  1.16s/it]Epoch: 3/10. Loss: 1.0468:  15%|[36m█▌        [0m| 4/26 [00:05<00:25,  1.16s/it]Epoch: 3/10. Loss: 1.0468:  19%|[36m█▉        [0m| 5/26 [00:05<00:23,  1.12s/it]Epoch: 3/10. Loss: 0.8697:  19%|[36m█▉        [0m| 5/26 [00:06<00:23,  1.12s/it]Epoch: 3/10. Loss: 0.8697:  23%|[36m██▎       [0m| 6/26 [00:06<00:20,  1.03s/it]Epoch: 3/10. Loss: 0.8867:  23%|[36m██▎       [0m| 6/26 [00:07<00:20,  1.03s/it]Epoch: 3/10. Loss: 0.8867:  27%|[36m██▋       [0m| 7/26 [00:07<00:19,  1.04s/it]Epoch: 3/10. Loss: 0.9393:  27%|[36m██▋       [0m| 7/26 [00:08<00:19,  1.04s/it]Epoch: 3/10. Loss: 0.9393:  31%|[36m███       [0m| 8/26 [00:08<00:17,  1.02it/s]Epoch: 3/10. Loss: 0.9889:  31%|[36m███       [0m| 8/26 [00:11<00:17,  1.02it/s]Epoch: 3/10. Loss: 0.9889:  35%|[36m███▍      [0m| 9/26 [00:11<00:25,  1.48s/it]Epoch: 3/10. Loss: 0.8988:  35%|[36m███▍      [0m| 9/26 [00:12<00:25,  1.48s/it]Epoch: 3/10. Loss: 0.8988:  38%|[36m███▊      [0m| 10/26 [00:12<00:20,  1.29s/it]Epoch: 3/10. Loss: 0.8867:  38%|[36m███▊      [0m| 10/26 [00:12<00:20,  1.29s/it]Epoch: 3/10. Loss: 0.8867:  42%|[36m████▏     [0m| 11/26 [00:12<00:16,  1.10s/it]Epoch: 3/10. Loss: 0.8927:  42%|[36m████▏     [0m| 11/26 [00:13<00:16,  1.10s/it]Epoch: 3/10. Loss: 0.8927:  46%|[36m████▌     [0m| 12/26 [00:13<00:14,  1.05s/it]Epoch: 3/10. Loss: 1.0008:  46%|[36m████▌     [0m| 12/26 [00:14<00:14,  1.05s/it]Epoch: 3/10. Loss: 1.0008:  50%|[36m█████     [0m| 13/26 [00:14<00:13,  1.00s/it]Epoch: 3/10. Loss: 0.9372:  50%|[36m█████     [0m| 13/26 [00:16<00:13,  1.00s/it]Epoch: 3/10. Loss: 0.9372:  54%|[36m█████▍    [0m| 14/26 [00:16<00:13,  1.16s/it]Epoch: 3/10. Loss: 0.8768:  54%|[36m█████▍    [0m| 14/26 [00:16<00:13,  1.16s/it]Epoch: 3/10. Loss: 0.8768:  58%|[36m█████▊    [0m| 15/26 [00:16<00:11,  1.07s/it]Epoch: 3/10. Loss: 0.9403:  58%|[36m█████▊    [0m| 15/26 [00:17<00:11,  1.07s/it]Epoch: 3/10. Loss: 0.9403:  62%|[36m██████▏   [0m| 16/26 [00:17<00:10,  1.01s/it]Epoch: 3/10. Loss: 0.9220:  62%|[36m██████▏   [0m| 16/26 [00:19<00:10,  1.01s/it]Epoch: 3/10. Loss: 0.9220:  65%|[36m██████▌   [0m| 17/26 [00:19<00:10,  1.11s/it]Epoch: 3/10. Loss: 0.9453:  65%|[36m██████▌   [0m| 17/26 [00:19<00:10,  1.11s/it]Epoch: 3/10. Loss: 0.9453:  69%|[36m██████▉   [0m| 18/26 [00:19<00:08,  1.03s/it]Epoch: 3/10. Loss: 0.9354:  69%|[36m██████▉   [0m| 18/26 [00:20<00:08,  1.03s/it]Epoch: 3/10. Loss: 0.9354:  73%|[36m███████▎  [0m| 19/26 [00:20<00:07,  1.02s/it]Epoch: 3/10. Loss: 0.9582:  73%|[36m███████▎  [0m| 19/26 [00:21<00:07,  1.02s/it]Epoch: 3/10. Loss: 0.9582:  77%|[36m███████▋  [0m| 20/26 [00:21<00:05,  1.02it/s]Epoch: 3/10. Loss: 0.8978:  77%|[36m███████▋  [0m| 20/26 [00:22<00:05,  1.02it/s]Epoch: 3/10. Loss: 0.8978:  81%|[36m████████  [0m| 21/26 [00:22<00:04,  1.01it/s]Epoch: 3/10. Loss: 0.8933:  81%|[36m████████  [0m| 21/26 [00:23<00:04,  1.01it/s]Epoch: 3/10. Loss: 0.8933:  85%|[36m████████▍ [0m| 22/26 [00:23<00:03,  1.03it/s]Epoch: 3/10. Loss: 0.9803:  85%|[36m████████▍ [0m| 22/26 [00:25<00:03,  1.03it/s]Epoch: 3/10. Loss: 0.9803:  88%|[36m████████▊ [0m| 23/26 [00:25<00:03,  1.27s/it]Epoch: 3/10. Loss: 0.9219:  88%|[36m████████▊ [0m| 23/26 [00:26<00:03,  1.27s/it]Epoch: 3/10. Loss: 0.9219:  92%|[36m█████████▏[0m| 24/26 [00:26<00:02,  1.20s/it]Epoch: 3/10. Loss: 0.9826:  92%|[36m█████████▏[0m| 24/26 [00:28<00:02,  1.20s/it]Epoch: 3/10. Loss: 0.9826:  96%|[36m█████████▌[0m| 25/26 [00:28<00:01,  1.27s/it]Epoch: 3/10. Loss: 0.8356:  96%|[36m█████████▌[0m| 25/26 [00:28<00:01,  1.27s/it]Epoch: 3/10. Loss: 0.8356: 100%|[36m██████████[0m| 26/26 [00:28<00:00,  1.06s/it]Epoch: 3/10. Loss: 0.8356: 100%|[36m██████████[0m| 26/26 [00:28<00:00,  1.11s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:03<00:21,  3.56s/it] 29%|[33m██▊       [0m| 2/7 [00:07<00:20,  4.06s/it] 43%|[33m████▎     [0m| 3/7 [00:08<00:09,  2.44s/it] 57%|[33m█████▋    [0m| 4/7 [00:10<00:06,  2.10s/it] 71%|[33m███████▏  [0m| 5/7 [00:12<00:04,  2.07s/it] 86%|[33m████████▌ [0m| 6/7 [00:15<00:02,  2.42s/it]100%|[33m██████████[0m| 7/7 [00:15<00:00,  1.75s/it]100%|[33m██████████[0m| 7/7 [00:15<00:00,  2.22s/it]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 4/10. Loss: 1.0459:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 4/10. Loss: 1.0459:   4%|[36m▍         [0m| 1/26 [00:00<00:23,  1.09it/s]Epoch: 4/10. Loss: 0.9012:   4%|[36m▍         [0m| 1/26 [00:01<00:23,  1.09it/s]Epoch: 4/10. Loss: 0.9012:   8%|[36m▊         [0m| 2/26 [00:01<00:22,  1.07it/s]Epoch: 4/10. Loss: 1.0390:   8%|[36m▊         [0m| 2/26 [00:02<00:22,  1.07it/s]Epoch: 4/10. Loss: 1.0390:  12%|[36m█▏        [0m| 3/26 [00:02<00:21,  1.08it/s]Epoch: 4/10. Loss: 0.9113:  12%|[36m█▏        [0m| 3/26 [00:03<00:21,  1.08it/s]Epoch: 4/10. Loss: 0.9113:  15%|[36m█▌        [0m| 4/26 [00:03<00:19,  1.13it/s]Epoch: 4/10. Loss: 0.7724:  15%|[36m█▌        [0m| 4/26 [00:04<00:19,  1.13it/s]Epoch: 4/10. Loss: 0.7724:  19%|[36m█▉        [0m| 5/26 [00:04<00:21,  1.03s/it]Epoch: 4/10. Loss: 0.9301:  19%|[36m█▉        [0m| 5/26 [00:06<00:21,  1.03s/it]Epoch: 4/10. Loss: 0.9301:  23%|[36m██▎       [0m| 6/26 [00:06<00:24,  1.24s/it]Epoch: 4/10. Loss: 0.8895:  23%|[36m██▎       [0m| 6/26 [00:07<00:24,  1.24s/it]Epoch: 4/10. Loss: 0.8895:  27%|[36m██▋       [0m| 7/26 [00:07<00:21,  1.12s/it]Epoch: 4/10. Loss: 0.9079:  27%|[36m██▋       [0m| 7/26 [00:08<00:21,  1.12s/it]Epoch: 4/10. Loss: 0.9079:  31%|[36m███       [0m| 8/26 [00:08<00:18,  1.03s/it]Epoch: 4/10. Loss: 0.9762:  31%|[36m███       [0m| 8/26 [00:10<00:18,  1.03s/it]Epoch: 4/10. Loss: 0.9762:  35%|[36m███▍      [0m| 9/26 [00:10<00:23,  1.38s/it]Epoch: 4/10. Loss: 1.0530:  35%|[36m███▍      [0m| 9/26 [00:13<00:23,  1.38s/it]Epoch: 4/10. Loss: 1.0530:  38%|[36m███▊      [0m| 10/26 [00:13<00:30,  1.92s/it]Epoch: 4/10. Loss: 0.9912:  38%|[36m███▊      [0m| 10/26 [00:14<00:30,  1.92s/it]Epoch: 4/10. Loss: 0.9912:  42%|[36m████▏     [0m| 11/26 [00:14<00:24,  1.64s/it]Epoch: 4/10. Loss: 1.0147:  42%|[36m████▏     [0m| 11/26 [00:15<00:24,  1.64s/it]Epoch: 4/10. Loss: 1.0147:  46%|[36m████▌     [0m| 12/26 [00:15<00:20,  1.43s/it]Epoch: 4/10. Loss: 0.9593:  46%|[36m████▌     [0m| 12/26 [00:16<00:20,  1.43s/it]Epoch: 4/10. Loss: 0.9593:  50%|[36m█████     [0m| 13/26 [00:16<00:16,  1.26s/it]Epoch: 4/10. Loss: 1.0065:  50%|[36m█████     [0m| 13/26 [00:17<00:16,  1.26s/it]Epoch: 4/10. Loss: 1.0065:  54%|[36m█████▍    [0m| 14/26 [00:17<00:16,  1.36s/it]Epoch: 4/10. Loss: 0.8814:  54%|[36m█████▍    [0m| 14/26 [00:18<00:16,  1.36s/it]Epoch: 4/10. Loss: 0.8814:  58%|[36m█████▊    [0m| 15/26 [00:18<00:13,  1.21s/it]Epoch: 4/10. Loss: 0.9464:  58%|[36m█████▊    [0m| 15/26 [00:19<00:13,  1.21s/it]Epoch: 4/10. Loss: 0.9464:  62%|[36m██████▏   [0m| 16/26 [00:19<00:11,  1.12s/it]Epoch: 4/10. Loss: 0.9168:  62%|[36m██████▏   [0m| 16/26 [00:22<00:11,  1.12s/it]Epoch: 4/10. Loss: 0.9168:  65%|[36m██████▌   [0m| 17/26 [00:22<00:14,  1.63s/it]Epoch: 4/10. Loss: 0.9671:  65%|[36m██████▌   [0m| 17/26 [00:23<00:14,  1.63s/it]Epoch: 4/10. Loss: 0.9671:  69%|[36m██████▉   [0m| 18/26 [00:23<00:11,  1.42s/it]Epoch: 4/10. Loss: 0.9385:  69%|[36m██████▉   [0m| 18/26 [00:24<00:11,  1.42s/it]Epoch: 4/10. Loss: 0.9385:  73%|[36m███████▎  [0m| 19/26 [00:24<00:08,  1.26s/it]Epoch: 4/10. Loss: 0.9386:  73%|[36m███████▎  [0m| 19/26 [00:25<00:08,  1.26s/it]Epoch: 4/10. Loss: 0.9386:  77%|[36m███████▋  [0m| 20/26 [00:25<00:07,  1.18s/it]Epoch: 4/10. Loss: 0.8250:  77%|[36m███████▋  [0m| 20/26 [00:26<00:07,  1.18s/it]Epoch: 4/10. Loss: 0.8250:  81%|[36m████████  [0m| 21/26 [00:26<00:05,  1.11s/it]Epoch: 4/10. Loss: 0.8479:  81%|[36m████████  [0m| 21/26 [00:27<00:05,  1.11s/it]Epoch: 4/10. Loss: 0.8479:  85%|[36m████████▍ [0m| 22/26 [00:27<00:04,  1.05s/it]Epoch: 4/10. Loss: 0.9447:  85%|[36m████████▍ [0m| 22/26 [00:28<00:04,  1.05s/it]Epoch: 4/10. Loss: 0.9447:  88%|[36m████████▊ [0m| 23/26 [00:28<00:03,  1.01s/it]Epoch: 4/10. Loss: 1.0244:  88%|[36m████████▊ [0m| 23/26 [00:29<00:03,  1.01s/it]Epoch: 4/10. Loss: 1.0244:  92%|[36m█████████▏[0m| 24/26 [00:29<00:01,  1.01it/s]Epoch: 4/10. Loss: 1.0255:  92%|[36m█████████▏[0m| 24/26 [00:30<00:01,  1.01it/s]Epoch: 4/10. Loss: 1.0255:  96%|[36m█████████▌[0m| 25/26 [00:30<00:01,  1.08s/it]Epoch: 4/10. Loss: 1.0821:  96%|[36m█████████▌[0m| 25/26 [00:31<00:01,  1.08s/it]Epoch: 4/10. Loss: 1.0821: 100%|[36m██████████[0m| 26/26 [00:31<00:00,  1.03it/s]Epoch: 4/10. Loss: 1.0821: 100%|[36m██████████[0m| 26/26 [00:31<00:00,  1.19s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:05,  1.18it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:05,  1.18s/it] 43%|[33m████▎     [0m| 3/7 [00:03<00:05,  1.37s/it] 57%|[33m█████▋    [0m| 4/7 [00:05<00:04,  1.37s/it] 71%|[33m███████▏  [0m| 5/7 [00:05<00:02,  1.02s/it] 86%|[33m████████▌ [0m| 6/7 [00:06<00:00,  1.02it/s]100%|[33m██████████[0m| 7/7 [00:06<00:00,  1.27it/s]100%|[33m██████████[0m| 7/7 [00:06<00:00,  1.01it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 5/10. Loss: 0.9136:   0%|[36m          [0m| 0/26 [00:01<?, ?it/s]Epoch: 5/10. Loss: 0.9136:   4%|[36m▍         [0m| 1/26 [00:02<00:50,  2.00s/it]Epoch: 5/10. Loss: 0.9300:   4%|[36m▍         [0m| 1/26 [00:02<00:50,  2.00s/it]Epoch: 5/10. Loss: 0.9300:   8%|[36m▊         [0m| 2/26 [00:02<00:29,  1.23s/it]Epoch: 5/10. Loss: 0.8915:   8%|[36m▊         [0m| 2/26 [00:04<00:29,  1.23s/it]Epoch: 5/10. Loss: 0.8915:  12%|[36m█▏        [0m| 3/26 [00:04<00:31,  1.39s/it]Epoch: 5/10. Loss: 0.8153:  12%|[36m█▏        [0m| 3/26 [00:05<00:31,  1.39s/it]Epoch: 5/10. Loss: 0.8153:  15%|[36m█▌        [0m| 4/26 [00:05<00:27,  1.25s/it]Epoch: 5/10. Loss: 0.8408:  15%|[36m█▌        [0m| 4/26 [00:08<00:27,  1.25s/it]Epoch: 5/10. Loss: 0.8408:  19%|[36m█▉        [0m| 5/26 [00:08<00:38,  1.84s/it]Epoch: 5/10. Loss: 1.0247:  19%|[36m█▉        [0m| 5/26 [00:09<00:38,  1.84s/it]Epoch: 5/10. Loss: 1.0247:  23%|[36m██▎       [0m| 6/26 [00:09<00:32,  1.63s/it]Epoch: 5/10. Loss: 0.8655:  23%|[36m██▎       [0m| 6/26 [00:10<00:32,  1.63s/it]Epoch: 5/10. Loss: 0.8655:  27%|[36m██▋       [0m| 7/26 [00:10<00:26,  1.41s/it]Epoch: 5/10. Loss: 0.8720:  27%|[36m██▋       [0m| 7/26 [00:11<00:26,  1.41s/it]Epoch: 5/10. Loss: 0.8720:  31%|[36m███       [0m| 8/26 [00:11<00:22,  1.27s/it]Epoch: 5/10. Loss: 0.9581:  31%|[36m███       [0m| 8/26 [00:12<00:22,  1.27s/it]Epoch: 5/10. Loss: 0.9581:  35%|[36m███▍      [0m| 9/26 [00:12<00:19,  1.17s/it]Epoch: 5/10. Loss: 0.8890:  35%|[36m███▍      [0m| 9/26 [00:13<00:19,  1.17s/it]Epoch: 5/10. Loss: 0.8890:  38%|[36m███▊      [0m| 10/26 [00:13<00:18,  1.14s/it]Epoch: 5/10. Loss: 0.9000:  38%|[36m███▊      [0m| 10/26 [00:14<00:18,  1.14s/it]Epoch: 5/10. Loss: 0.9000:  42%|[36m████▏     [0m| 11/26 [00:14<00:15,  1.05s/it]Epoch: 5/10. Loss: 0.9492:  42%|[36m████▏     [0m| 11/26 [00:15<00:15,  1.05s/it]Epoch: 5/10. Loss: 0.9492:  46%|[36m████▌     [0m| 12/26 [00:15<00:14,  1.03s/it]Epoch: 5/10. Loss: 0.8125:  46%|[36m████▌     [0m| 12/26 [00:16<00:14,  1.03s/it]Epoch: 5/10. Loss: 0.8125:  50%|[36m█████     [0m| 13/26 [00:16<00:13,  1.00s/it]Epoch: 5/10. Loss: 0.8932:  50%|[36m█████     [0m| 13/26 [00:17<00:13,  1.00s/it]Epoch: 5/10. Loss: 0.8932:  54%|[36m█████▍    [0m| 14/26 [00:17<00:13,  1.09s/it]Epoch: 5/10. Loss: 0.7964:  54%|[36m█████▍    [0m| 14/26 [00:18<00:13,  1.09s/it]Epoch: 5/10. Loss: 0.7964:  58%|[36m█████▊    [0m| 15/26 [00:18<00:11,  1.02s/it]Epoch: 5/10. Loss: 0.8659:  58%|[36m█████▊    [0m| 15/26 [00:19<00:11,  1.02s/it]Epoch: 5/10. Loss: 0.8659:  62%|[36m██████▏   [0m| 16/26 [00:19<00:10,  1.00s/it]Epoch: 5/10. Loss: 0.8437:  62%|[36m██████▏   [0m| 16/26 [00:20<00:10,  1.00s/it]Epoch: 5/10. Loss: 0.8437:  65%|[36m██████▌   [0m| 17/26 [00:20<00:08,  1.01it/s]Epoch: 5/10. Loss: 0.9245:  65%|[36m██████▌   [0m| 17/26 [00:21<00:08,  1.01it/s]Epoch: 5/10. Loss: 0.9245:  69%|[36m██████▉   [0m| 18/26 [00:21<00:08,  1.03s/it]Epoch: 5/10. Loss: 0.9246:  69%|[36m██████▉   [0m| 18/26 [00:22<00:08,  1.03s/it]Epoch: 5/10. Loss: 0.9246:  73%|[36m███████▎  [0m| 19/26 [00:22<00:07,  1.00s/it]Epoch: 5/10. Loss: 0.8807:  73%|[36m███████▎  [0m| 19/26 [00:23<00:07,  1.00s/it]Epoch: 5/10. Loss: 0.8807:  77%|[36m███████▋  [0m| 20/26 [00:23<00:05,  1.02it/s]Epoch: 5/10. Loss: 0.8605:  77%|[36m███████▋  [0m| 20/26 [00:24<00:05,  1.02it/s]Epoch: 5/10. Loss: 0.8605:  81%|[36m████████  [0m| 21/26 [00:24<00:04,  1.03it/s]Epoch: 5/10. Loss: 0.9894:  81%|[36m████████  [0m| 21/26 [00:24<00:04,  1.03it/s]Epoch: 5/10. Loss: 0.9894:  85%|[36m████████▍ [0m| 22/26 [00:25<00:03,  1.07it/s]Epoch: 5/10. Loss: 0.9224:  85%|[36m████████▍ [0m| 22/26 [00:25<00:03,  1.07it/s]Epoch: 5/10. Loss: 0.9224:  88%|[36m████████▊ [0m| 23/26 [00:25<00:02,  1.05it/s]Epoch: 5/10. Loss: 0.8948:  88%|[36m████████▊ [0m| 23/26 [00:27<00:02,  1.05it/s]Epoch: 5/10. Loss: 0.8948:  92%|[36m█████████▏[0m| 24/26 [00:27<00:02,  1.00s/it]Epoch: 5/10. Loss: 0.9473:  92%|[36m█████████▏[0m| 24/26 [00:28<00:02,  1.00s/it]Epoch: 5/10. Loss: 0.9473:  96%|[36m█████████▌[0m| 25/26 [00:28<00:00,  1.03it/s]Epoch: 5/10. Loss: 0.8348:  96%|[36m█████████▌[0m| 25/26 [00:28<00:00,  1.03it/s]Epoch: 5/10. Loss: 0.8348: 100%|[36m██████████[0m| 26/26 [00:28<00:00,  1.20it/s]Epoch: 5/10. Loss: 0.8348: 100%|[36m██████████[0m| 26/26 [00:28<00:00,  1.10s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:05,  1.03it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:06,  1.22s/it] 43%|[33m████▎     [0m| 3/7 [00:02<00:03,  1.09it/s] 57%|[33m█████▋    [0m| 4/7 [00:04<00:03,  1.11s/it] 71%|[33m███████▏  [0m| 5/7 [00:04<00:01,  1.16it/s] 86%|[33m████████▌ [0m| 6/7 [00:05<00:00,  1.14it/s]100%|[33m██████████[0m| 7/7 [00:06<00:00,  1.02it/s]100%|[33m██████████[0m| 7/7 [00:06<00:00,  1.02it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 6/10. Loss: 0.8624:   0%|[36m          [0m| 0/26 [00:01<?, ?it/s]Epoch: 6/10. Loss: 0.8624:   4%|[36m▍         [0m| 1/26 [00:01<00:31,  1.26s/it]Epoch: 6/10. Loss: 0.9371:   4%|[36m▍         [0m| 1/26 [00:02<00:31,  1.26s/it]Epoch: 6/10. Loss: 0.9371:   8%|[36m▊         [0m| 2/26 [00:02<00:25,  1.07s/it]Epoch: 6/10. Loss: 1.0073:   8%|[36m▊         [0m| 2/26 [00:03<00:25,  1.07s/it]Epoch: 6/10. Loss: 1.0073:  12%|[36m█▏        [0m| 3/26 [00:03<00:23,  1.01s/it]Epoch: 6/10. Loss: 0.7693:  12%|[36m█▏        [0m| 3/26 [00:03<00:23,  1.01s/it]Epoch: 6/10. Loss: 0.7693:  15%|[36m█▌        [0m| 4/26 [00:03<00:20,  1.06it/s]Epoch: 6/10. Loss: 0.8571:  15%|[36m█▌        [0m| 4/26 [00:05<00:20,  1.06it/s]Epoch: 6/10. Loss: 0.8571:  19%|[36m█▉        [0m| 5/26 [00:05<00:26,  1.26s/it]Epoch: 6/10. Loss: 0.9500:  19%|[36m█▉        [0m| 5/26 [00:07<00:26,  1.26s/it]Epoch: 6/10. Loss: 0.9500:  23%|[36m██▎       [0m| 6/26 [00:07<00:28,  1.44s/it]Epoch: 6/10. Loss: 0.9431:  23%|[36m██▎       [0m| 6/26 [00:08<00:28,  1.44s/it]Epoch: 6/10. Loss: 0.9431:  27%|[36m██▋       [0m| 7/26 [00:08<00:24,  1.31s/it]Epoch: 6/10. Loss: 0.8919:  27%|[36m██▋       [0m| 7/26 [00:09<00:24,  1.31s/it]Epoch: 6/10. Loss: 0.8919:  31%|[36m███       [0m| 8/26 [00:09<00:21,  1.18s/it]Epoch: 6/10. Loss: 0.8993:  31%|[36m███       [0m| 8/26 [00:10<00:21,  1.18s/it]Epoch: 6/10. Loss: 0.8993:  35%|[36m███▍      [0m| 9/26 [00:10<00:19,  1.15s/it]Epoch: 6/10. Loss: 0.9094:  35%|[36m███▍      [0m| 9/26 [00:11<00:19,  1.15s/it]Epoch: 6/10. Loss: 0.9094:  38%|[36m███▊      [0m| 10/26 [00:11<00:17,  1.07s/it]Epoch: 6/10. Loss: 0.8475:  38%|[36m███▊      [0m| 10/26 [00:12<00:17,  1.07s/it]Epoch: 6/10. Loss: 0.8475:  42%|[36m████▏     [0m| 11/26 [00:12<00:17,  1.17s/it]Epoch: 6/10. Loss: 0.7860:  42%|[36m████▏     [0m| 11/26 [00:13<00:17,  1.17s/it]Epoch: 6/10. Loss: 0.7860:  46%|[36m████▌     [0m| 12/26 [00:13<00:15,  1.08s/it]Epoch: 6/10. Loss: 0.9367:  46%|[36m████▌     [0m| 12/26 [00:14<00:15,  1.08s/it]Epoch: 6/10. Loss: 0.9367:  50%|[36m█████     [0m| 13/26 [00:14<00:12,  1.01it/s]Epoch: 6/10. Loss: 0.8146:  50%|[36m█████     [0m| 13/26 [00:15<00:12,  1.01it/s]Epoch: 6/10. Loss: 0.8146:  54%|[36m█████▍    [0m| 14/26 [00:15<00:11,  1.06it/s]Epoch: 6/10. Loss: 0.8917:  54%|[36m█████▍    [0m| 14/26 [00:16<00:11,  1.06it/s]Epoch: 6/10. Loss: 0.8917:  58%|[36m█████▊    [0m| 15/26 [00:16<00:09,  1.10it/s]Epoch: 6/10. Loss: 0.9158:  58%|[36m█████▊    [0m| 15/26 [00:17<00:09,  1.10it/s]Epoch: 6/10. Loss: 0.9158:  62%|[36m██████▏   [0m| 16/26 [00:17<00:09,  1.06it/s]Epoch: 6/10. Loss: 0.8088:  62%|[36m██████▏   [0m| 16/26 [00:18<00:09,  1.06it/s]Epoch: 6/10. Loss: 0.8088:  65%|[36m██████▌   [0m| 17/26 [00:18<00:08,  1.07it/s]Epoch: 6/10. Loss: 0.8788:  65%|[36m██████▌   [0m| 17/26 [00:19<00:08,  1.07it/s]Epoch: 6/10. Loss: 0.8788:  69%|[36m██████▉   [0m| 18/26 [00:19<00:08,  1.02s/it]Epoch: 6/10. Loss: 0.7471:  69%|[36m██████▉   [0m| 18/26 [00:20<00:08,  1.02s/it]Epoch: 6/10. Loss: 0.7471:  73%|[36m███████▎  [0m| 19/26 [00:20<00:07,  1.01s/it]Epoch: 6/10. Loss: 0.9232:  73%|[36m███████▎  [0m| 19/26 [00:21<00:07,  1.01s/it]Epoch: 6/10. Loss: 0.9232:  77%|[36m███████▋  [0m| 20/26 [00:21<00:06,  1.03s/it]Epoch: 6/10. Loss: 0.9423:  77%|[36m███████▋  [0m| 20/26 [00:22<00:06,  1.03s/it]Epoch: 6/10. Loss: 0.9423:  81%|[36m████████  [0m| 21/26 [00:22<00:04,  1.02it/s]Epoch: 6/10. Loss: 0.8260:  81%|[36m████████  [0m| 21/26 [00:23<00:04,  1.02it/s]Epoch: 6/10. Loss: 0.8260:  85%|[36m████████▍ [0m| 22/26 [00:23<00:04,  1.13s/it]Epoch: 6/10. Loss: 0.7872:  85%|[36m████████▍ [0m| 22/26 [00:24<00:04,  1.13s/it]Epoch: 6/10. Loss: 0.7872:  88%|[36m████████▊ [0m| 23/26 [00:24<00:03,  1.06s/it]Epoch: 6/10. Loss: 0.7540:  88%|[36m████████▊ [0m| 23/26 [00:25<00:03,  1.06s/it]Epoch: 6/10. Loss: 0.7540:  92%|[36m█████████▏[0m| 24/26 [00:25<00:02,  1.01s/it]Epoch: 6/10. Loss: 0.9135:  92%|[36m█████████▏[0m| 24/26 [00:26<00:02,  1.01s/it]Epoch: 6/10. Loss: 0.9135:  96%|[36m█████████▌[0m| 25/26 [00:26<00:00,  1.01it/s]Epoch: 6/10. Loss: 0.8836:  96%|[36m█████████▌[0m| 25/26 [00:27<00:00,  1.01it/s]Epoch: 6/10. Loss: 0.8836: 100%|[36m██████████[0m| 26/26 [00:27<00:00,  1.10it/s]Epoch: 6/10. Loss: 0.8836: 100%|[36m██████████[0m| 26/26 [00:27<00:00,  1.05s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:05,  1.18it/s] 29%|[33m██▊       [0m| 2/7 [00:03<00:10,  2.18s/it] 43%|[33m████▎     [0m| 3/7 [00:04<00:05,  1.42s/it] 57%|[33m█████▋    [0m| 4/7 [00:05<00:04,  1.41s/it] 71%|[33m███████▏  [0m| 5/7 [00:06<00:02,  1.06s/it] 86%|[33m████████▌ [0m| 6/7 [00:09<00:01,  1.62s/it]100%|[33m██████████[0m| 7/7 [00:09<00:00,  1.19s/it]100%|[33m██████████[0m| 7/7 [00:09<00:00,  1.33s/it]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 7/10. Loss: 0.8850:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 7/10. Loss: 0.8850:   4%|[36m▍         [0m| 1/26 [00:00<00:23,  1.08it/s]Epoch: 7/10. Loss: 0.9628:   4%|[36m▍         [0m| 1/26 [00:01<00:23,  1.08it/s]Epoch: 7/10. Loss: 0.9628:   8%|[36m▊         [0m| 2/26 [00:01<00:22,  1.05it/s]Epoch: 7/10. Loss: 0.8376:   8%|[36m▊         [0m| 2/26 [00:02<00:22,  1.05it/s]Epoch: 7/10. Loss: 0.8376:  12%|[36m█▏        [0m| 3/26 [00:02<00:22,  1.01it/s]Epoch: 7/10. Loss: 0.8941:  12%|[36m█▏        [0m| 3/26 [00:03<00:22,  1.01it/s]Epoch: 7/10. Loss: 0.8941:  15%|[36m█▌        [0m| 4/26 [00:03<00:20,  1.10it/s]Epoch: 7/10. Loss: 0.7811:  15%|[36m█▌        [0m| 4/26 [00:05<00:20,  1.10it/s]Epoch: 7/10. Loss: 0.7811:  19%|[36m█▉        [0m| 5/26 [00:05<00:22,  1.07s/it]Epoch: 7/10. Loss: 0.8235:  19%|[36m█▉        [0m| 5/26 [00:05<00:22,  1.07s/it]Epoch: 7/10. Loss: 0.8235:  23%|[36m██▎       [0m| 6/26 [00:05<00:19,  1.03it/s]Epoch: 7/10. Loss: 0.8545:  23%|[36m██▎       [0m| 6/26 [00:07<00:19,  1.03it/s]Epoch: 7/10. Loss: 0.8545:  27%|[36m██▋       [0m| 7/26 [00:07<00:20,  1.09s/it]Epoch: 7/10. Loss: 0.9208:  27%|[36m██▋       [0m| 7/26 [00:08<00:20,  1.09s/it]Epoch: 7/10. Loss: 0.9208:  31%|[36m███       [0m| 8/26 [00:08<00:19,  1.08s/it]Epoch: 7/10. Loss: 0.7611:  31%|[36m███       [0m| 8/26 [00:10<00:19,  1.08s/it]Epoch: 7/10. Loss: 0.7611:  35%|[36m███▍      [0m| 9/26 [00:10<00:24,  1.45s/it]Epoch: 7/10. Loss: 0.8217:  35%|[36m███▍      [0m| 9/26 [00:11<00:24,  1.45s/it]Epoch: 7/10. Loss: 0.8217:  38%|[36m███▊      [0m| 10/26 [00:11<00:20,  1.28s/it]Epoch: 7/10. Loss: 0.8477:  38%|[36m███▊      [0m| 10/26 [00:12<00:20,  1.28s/it]Epoch: 7/10. Loss: 0.8477:  42%|[36m████▏     [0m| 11/26 [00:12<00:17,  1.15s/it]Epoch: 7/10. Loss: 0.7213:  42%|[36m████▏     [0m| 11/26 [00:13<00:17,  1.15s/it]Epoch: 7/10. Loss: 0.7213:  46%|[36m████▌     [0m| 12/26 [00:13<00:15,  1.11s/it]Epoch: 7/10. Loss: 0.8364:  46%|[36m████▌     [0m| 12/26 [00:14<00:15,  1.11s/it]Epoch: 7/10. Loss: 0.8364:  50%|[36m█████     [0m| 13/26 [00:14<00:13,  1.02s/it]Epoch: 7/10. Loss: 0.8150:  50%|[36m█████     [0m| 13/26 [00:15<00:13,  1.02s/it]Epoch: 7/10. Loss: 0.8150:  54%|[36m█████▍    [0m| 14/26 [00:15<00:12,  1.08s/it]Epoch: 7/10. Loss: 0.8600:  54%|[36m█████▍    [0m| 14/26 [00:16<00:12,  1.08s/it]Epoch: 7/10. Loss: 0.8600:  58%|[36m█████▊    [0m| 15/26 [00:16<00:11,  1.07s/it]Epoch: 7/10. Loss: 0.7805:  58%|[36m█████▊    [0m| 15/26 [00:17<00:11,  1.07s/it]Epoch: 7/10. Loss: 0.7805:  62%|[36m██████▏   [0m| 16/26 [00:17<00:09,  1.01it/s]Epoch: 7/10. Loss: 0.8212:  62%|[36m██████▏   [0m| 16/26 [00:17<00:09,  1.01it/s]Epoch: 7/10. Loss: 0.8212:  65%|[36m██████▌   [0m| 17/26 [00:17<00:08,  1.07it/s]Epoch: 7/10. Loss: 0.8999:  65%|[36m██████▌   [0m| 17/26 [00:18<00:08,  1.07it/s]Epoch: 7/10. Loss: 0.8999:  69%|[36m██████▉   [0m| 18/26 [00:18<00:07,  1.07it/s]Epoch: 7/10. Loss: 0.8126:  69%|[36m██████▉   [0m| 18/26 [00:19<00:07,  1.07it/s]Epoch: 7/10. Loss: 0.8126:  73%|[36m███████▎  [0m| 19/26 [00:19<00:06,  1.12it/s]Epoch: 7/10. Loss: 0.8460:  73%|[36m███████▎  [0m| 19/26 [00:20<00:06,  1.12it/s]Epoch: 7/10. Loss: 0.8460:  77%|[36m███████▋  [0m| 20/26 [00:20<00:05,  1.15it/s]Epoch: 7/10. Loss: 0.7867:  77%|[36m███████▋  [0m| 20/26 [00:21<00:05,  1.15it/s]Epoch: 7/10. Loss: 0.7867:  81%|[36m████████  [0m| 21/26 [00:21<00:04,  1.21it/s]Epoch: 7/10. Loss: 0.8349:  81%|[36m████████  [0m| 21/26 [00:22<00:04,  1.21it/s]Epoch: 7/10. Loss: 0.8349:  85%|[36m████████▍ [0m| 22/26 [00:22<00:03,  1.16it/s]Epoch: 7/10. Loss: 0.8496:  85%|[36m████████▍ [0m| 22/26 [00:23<00:03,  1.16it/s]Epoch: 7/10. Loss: 0.8496:  88%|[36m████████▊ [0m| 23/26 [00:23<00:02,  1.16it/s]Epoch: 7/10. Loss: 0.8455:  88%|[36m████████▊ [0m| 23/26 [00:23<00:02,  1.16it/s]Epoch: 7/10. Loss: 0.8455:  92%|[36m█████████▏[0m| 24/26 [00:24<00:01,  1.13it/s]Epoch: 7/10. Loss: 0.8195:  92%|[36m█████████▏[0m| 24/26 [00:25<00:01,  1.13it/s]Epoch: 7/10. Loss: 0.8195:  96%|[36m█████████▌[0m| 25/26 [00:25<00:01,  1.10s/it]Epoch: 7/10. Loss: 0.7933:  96%|[36m█████████▌[0m| 25/26 [00:26<00:01,  1.10s/it]Epoch: 7/10. Loss: 0.7933: 100%|[36m██████████[0m| 26/26 [00:26<00:00,  1.04it/s]Epoch: 7/10. Loss: 0.7933: 100%|[36m██████████[0m| 26/26 [00:26<00:00,  1.01s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:01<00:09,  1.62s/it] 29%|[33m██▊       [0m| 2/7 [00:03<00:10,  2.03s/it] 43%|[33m████▎     [0m| 3/7 [00:04<00:05,  1.35s/it] 57%|[33m█████▋    [0m| 4/7 [00:06<00:05,  1.67s/it] 71%|[33m███████▏  [0m| 5/7 [00:06<00:02,  1.19s/it] 86%|[33m████████▌ [0m| 6/7 [00:07<00:01,  1.07s/it]100%|[33m██████████[0m| 7/7 [00:08<00:00,  1.24it/s]100%|[33m██████████[0m| 7/7 [00:08<00:00,  1.15s/it]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 8/10. Loss: 0.7862:   0%|[36m          [0m| 0/26 [00:01<?, ?it/s]Epoch: 8/10. Loss: 0.7862:   4%|[36m▍         [0m| 1/26 [00:01<00:28,  1.14s/it]Epoch: 8/10. Loss: 0.7251:   4%|[36m▍         [0m| 1/26 [00:02<00:28,  1.14s/it]Epoch: 8/10. Loss: 0.7251:   8%|[36m▊         [0m| 2/26 [00:02<00:31,  1.32s/it]Epoch: 8/10. Loss: 0.7421:   8%|[36m▊         [0m| 2/26 [00:03<00:31,  1.32s/it]Epoch: 8/10. Loss: 0.7421:  12%|[36m█▏        [0m| 3/26 [00:03<00:28,  1.23s/it]Epoch: 8/10. Loss: 0.8805:  12%|[36m█▏        [0m| 3/26 [00:04<00:28,  1.23s/it]Epoch: 8/10. Loss: 0.8805:  15%|[36m█▌        [0m| 4/26 [00:04<00:23,  1.09s/it]Epoch: 8/10. Loss: 0.8322:  15%|[36m█▌        [0m| 4/26 [00:05<00:23,  1.09s/it]Epoch: 8/10. Loss: 0.8322:  19%|[36m█▉        [0m| 5/26 [00:05<00:20,  1.01it/s]Epoch: 8/10. Loss: 0.9439:  19%|[36m█▉        [0m| 5/26 [00:06<00:20,  1.01it/s]Epoch: 8/10. Loss: 0.9439:  23%|[36m██▎       [0m| 6/26 [00:06<00:19,  1.04it/s]Epoch: 8/10. Loss: 0.8029:  23%|[36m██▎       [0m| 6/26 [00:08<00:19,  1.04it/s]Epoch: 8/10. Loss: 0.8029:  27%|[36m██▋       [0m| 7/26 [00:08<00:26,  1.39s/it]Epoch: 8/10. Loss: 0.7977:  27%|[36m██▋       [0m| 7/26 [00:09<00:26,  1.39s/it]Epoch: 8/10. Loss: 0.7977:  31%|[36m███       [0m| 8/26 [00:09<00:22,  1.24s/it]Epoch: 8/10. Loss: 0.7871:  31%|[36m███       [0m| 8/26 [00:10<00:22,  1.24s/it]Epoch: 8/10. Loss: 0.7871:  35%|[36m███▍      [0m| 9/26 [00:10<00:20,  1.21s/it]Epoch: 8/10. Loss: 0.7853:  35%|[36m███▍      [0m| 9/26 [00:12<00:20,  1.21s/it]Epoch: 8/10. Loss: 0.7853:  38%|[36m███▊      [0m| 10/26 [00:12<00:21,  1.36s/it]Epoch: 8/10. Loss: 0.7476:  38%|[36m███▊      [0m| 10/26 [00:13<00:21,  1.36s/it]Epoch: 8/10. Loss: 0.7476:  42%|[36m████▏     [0m| 11/26 [00:13<00:18,  1.21s/it]Epoch: 8/10. Loss: 0.7964:  42%|[36m████▏     [0m| 11/26 [00:14<00:18,  1.21s/it]Epoch: 8/10. Loss: 0.7964:  46%|[36m████▌     [0m| 12/26 [00:14<00:16,  1.19s/it]Epoch: 8/10. Loss: 0.7670:  46%|[36m████▌     [0m| 12/26 [00:16<00:16,  1.19s/it]Epoch: 8/10. Loss: 0.7670:  50%|[36m█████     [0m| 13/26 [00:17<00:21,  1.63s/it]Epoch: 8/10. Loss: 0.8118:  50%|[36m█████     [0m| 13/26 [00:18<00:21,  1.63s/it]Epoch: 8/10. Loss: 0.8118:  54%|[36m█████▍    [0m| 14/26 [00:18<00:19,  1.59s/it]Epoch: 8/10. Loss: 0.8932:  54%|[36m█████▍    [0m| 14/26 [00:19<00:19,  1.59s/it]Epoch: 8/10. Loss: 0.8932:  58%|[36m█████▊    [0m| 15/26 [00:19<00:15,  1.39s/it]Epoch: 8/10. Loss: 0.7867:  58%|[36m█████▊    [0m| 15/26 [00:20<00:15,  1.39s/it]Epoch: 8/10. Loss: 0.7867:  62%|[36m██████▏   [0m| 16/26 [00:20<00:13,  1.33s/it]Epoch: 8/10. Loss: 0.8256:  62%|[36m██████▏   [0m| 16/26 [00:21<00:13,  1.33s/it]Epoch: 8/10. Loss: 0.8256:  65%|[36m██████▌   [0m| 17/26 [00:21<00:11,  1.23s/it]Epoch: 8/10. Loss: 0.7783:  65%|[36m██████▌   [0m| 17/26 [00:22<00:11,  1.23s/it]Epoch: 8/10. Loss: 0.7783:  69%|[36m██████▉   [0m| 18/26 [00:22<00:10,  1.25s/it]Epoch: 8/10. Loss: 0.7867:  69%|[36m██████▉   [0m| 18/26 [00:23<00:10,  1.25s/it]Epoch: 8/10. Loss: 0.7867:  73%|[36m███████▎  [0m| 19/26 [00:23<00:07,  1.08s/it]Epoch: 8/10. Loss: 0.7316:  73%|[36m███████▎  [0m| 19/26 [00:24<00:07,  1.08s/it]Epoch: 8/10. Loss: 0.7316:  77%|[36m███████▋  [0m| 20/26 [00:24<00:05,  1.03it/s]Epoch: 8/10. Loss: 0.6785:  77%|[36m███████▋  [0m| 20/26 [00:26<00:05,  1.03it/s]Epoch: 8/10. Loss: 0.6785:  81%|[36m████████  [0m| 21/26 [00:26<00:06,  1.23s/it]Epoch: 8/10. Loss: 0.8987:  81%|[36m████████  [0m| 21/26 [00:27<00:06,  1.23s/it]Epoch: 8/10. Loss: 0.8987:  85%|[36m████████▍ [0m| 22/26 [00:27<00:04,  1.21s/it]Epoch: 8/10. Loss: 0.7804:  85%|[36m████████▍ [0m| 22/26 [00:28<00:04,  1.21s/it]Epoch: 8/10. Loss: 0.7804:  88%|[36m████████▊ [0m| 23/26 [00:28<00:03,  1.10s/it]Epoch: 8/10. Loss: 0.8538:  88%|[36m████████▊ [0m| 23/26 [00:28<00:03,  1.10s/it]Epoch: 8/10. Loss: 0.8538:  92%|[36m█████████▏[0m| 24/26 [00:28<00:02,  1.03s/it]Epoch: 8/10. Loss: 0.8220:  92%|[36m█████████▏[0m| 24/26 [00:30<00:02,  1.03s/it]Epoch: 8/10. Loss: 0.8220:  96%|[36m█████████▌[0m| 25/26 [00:30<00:01,  1.08s/it]Epoch: 8/10. Loss: 0.8010:  96%|[36m█████████▌[0m| 25/26 [00:31<00:01,  1.08s/it]Epoch: 8/10. Loss: 0.8010: 100%|[36m██████████[0m| 26/26 [00:31<00:00,  1.15s/it]Epoch: 8/10. Loss: 0.8010: 100%|[36m██████████[0m| 26/26 [00:31<00:00,  1.21s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:05,  1.17it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:05,  1.17s/it] 43%|[33m████▎     [0m| 3/7 [00:02<00:03,  1.12it/s] 57%|[33m█████▋    [0m| 4/7 [00:04<00:03,  1.08s/it] 71%|[33m███████▏  [0m| 5/7 [00:04<00:01,  1.21it/s] 86%|[33m████████▌ [0m| 6/7 [00:05<00:00,  1.21it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.55it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.24it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 9/10. Loss: 0.7695:   0%|[36m          [0m| 0/26 [00:01<?, ?it/s]Epoch: 9/10. Loss: 0.7695:   4%|[36m▍         [0m| 1/26 [00:01<00:30,  1.22s/it]Epoch: 9/10. Loss: 0.8596:   4%|[36m▍         [0m| 1/26 [00:02<00:30,  1.22s/it]Epoch: 9/10. Loss: 0.8596:   8%|[36m▊         [0m| 2/26 [00:02<00:26,  1.11s/it]Epoch: 9/10. Loss: 0.8559:   8%|[36m▊         [0m| 2/26 [00:03<00:26,  1.11s/it]Epoch: 9/10. Loss: 0.8559:  12%|[36m█▏        [0m| 3/26 [00:03<00:23,  1.01s/it]Epoch: 9/10. Loss: 0.6911:  12%|[36m█▏        [0m| 3/26 [00:03<00:23,  1.01s/it]Epoch: 9/10. Loss: 0.6911:  15%|[36m█▌        [0m| 4/26 [00:03<00:20,  1.10it/s]Epoch: 9/10. Loss: 0.7015:  15%|[36m█▌        [0m| 4/26 [00:04<00:20,  1.10it/s]Epoch: 9/10. Loss: 0.7015:  19%|[36m█▉        [0m| 5/26 [00:04<00:19,  1.07it/s]Epoch: 9/10. Loss: 0.7301:  19%|[36m█▉        [0m| 5/26 [00:05<00:19,  1.07it/s]Epoch: 9/10. Loss: 0.7301:  23%|[36m██▎       [0m| 6/26 [00:05<00:17,  1.13it/s]Epoch: 9/10. Loss: 0.8033:  23%|[36m██▎       [0m| 6/26 [00:06<00:17,  1.13it/s]Epoch: 9/10. Loss: 0.8033:  27%|[36m██▋       [0m| 7/26 [00:06<00:17,  1.08it/s]Epoch: 9/10. Loss: 0.7106:  27%|[36m██▋       [0m| 7/26 [00:07<00:17,  1.08it/s]Epoch: 9/10. Loss: 0.7106:  31%|[36m███       [0m| 8/26 [00:07<00:16,  1.12it/s]Epoch: 9/10. Loss: 0.8376:  31%|[36m███       [0m| 8/26 [00:08<00:16,  1.12it/s]Epoch: 9/10. Loss: 0.8376:  35%|[36m███▍      [0m| 9/26 [00:08<00:14,  1.15it/s]Epoch: 9/10. Loss: 0.7192:  35%|[36m███▍      [0m| 9/26 [00:09<00:14,  1.15it/s]Epoch: 9/10. Loss: 0.7192:  38%|[36m███▊      [0m| 10/26 [00:09<00:14,  1.11it/s]Epoch: 9/10. Loss: 0.8357:  38%|[36m███▊      [0m| 10/26 [00:10<00:14,  1.11it/s]Epoch: 9/10. Loss: 0.8357:  42%|[36m████▏     [0m| 11/26 [00:10<00:14,  1.05it/s]Epoch: 9/10. Loss: 0.7519:  42%|[36m████▏     [0m| 11/26 [00:11<00:14,  1.05it/s]Epoch: 9/10. Loss: 0.7519:  46%|[36m████▌     [0m| 12/26 [00:11<00:13,  1.05it/s]Epoch: 9/10. Loss: 0.6797:  46%|[36m████▌     [0m| 12/26 [00:12<00:13,  1.05it/s]Epoch: 9/10. Loss: 0.6797:  50%|[36m█████     [0m| 13/26 [00:12<00:11,  1.11it/s]Epoch: 9/10. Loss: 0.7074:  50%|[36m█████     [0m| 13/26 [00:13<00:11,  1.11it/s]Epoch: 9/10. Loss: 0.7074:  54%|[36m█████▍    [0m| 14/26 [00:13<00:11,  1.09it/s]Epoch: 9/10. Loss: 0.6976:  54%|[36m█████▍    [0m| 14/26 [00:16<00:11,  1.09it/s]Epoch: 9/10. Loss: 0.6976:  58%|[36m█████▊    [0m| 15/26 [00:16<00:18,  1.65s/it]Epoch: 9/10. Loss: 0.9939:  58%|[36m█████▊    [0m| 15/26 [00:17<00:18,  1.65s/it]Epoch: 9/10. Loss: 0.9939:  62%|[36m██████▏   [0m| 16/26 [00:17<00:13,  1.39s/it]Epoch: 9/10. Loss: 0.8276:  62%|[36m██████▏   [0m| 16/26 [00:18<00:13,  1.39s/it]Epoch: 9/10. Loss: 0.8276:  65%|[36m██████▌   [0m| 17/26 [00:18<00:11,  1.24s/it]Epoch: 9/10. Loss: 0.7235:  65%|[36m██████▌   [0m| 17/26 [00:18<00:11,  1.24s/it]Epoch: 9/10. Loss: 0.7235:  69%|[36m██████▉   [0m| 18/26 [00:18<00:09,  1.14s/it]Epoch: 9/10. Loss: 0.8047:  69%|[36m██████▉   [0m| 18/26 [00:20<00:09,  1.14s/it]Epoch: 9/10. Loss: 0.8047:  73%|[36m███████▎  [0m| 19/26 [00:20<00:08,  1.17s/it]Epoch: 9/10. Loss: 0.9046:  73%|[36m███████▎  [0m| 19/26 [00:21<00:08,  1.17s/it]Epoch: 9/10. Loss: 0.9046:  77%|[36m███████▋  [0m| 20/26 [00:21<00:07,  1.21s/it]Epoch: 9/10. Loss: 0.7627:  77%|[36m███████▋  [0m| 20/26 [00:22<00:07,  1.21s/it]Epoch: 9/10. Loss: 0.7627:  81%|[36m████████  [0m| 21/26 [00:22<00:05,  1.11s/it]Epoch: 9/10. Loss: 0.8407:  81%|[36m████████  [0m| 21/26 [00:23<00:05,  1.11s/it]Epoch: 9/10. Loss: 0.8407:  85%|[36m████████▍ [0m| 22/26 [00:23<00:04,  1.03s/it]Epoch: 9/10. Loss: 0.8071:  85%|[36m████████▍ [0m| 22/26 [00:24<00:04,  1.03s/it]Epoch: 9/10. Loss: 0.8071:  88%|[36m████████▊ [0m| 23/26 [00:24<00:02,  1.04it/s]Epoch: 9/10. Loss: 0.9610:  88%|[36m████████▊ [0m| 23/26 [00:24<00:02,  1.04it/s]Epoch: 9/10. Loss: 0.9610:  92%|[36m█████████▏[0m| 24/26 [00:24<00:01,  1.07it/s]Epoch: 9/10. Loss: 0.8073:  92%|[36m█████████▏[0m| 24/26 [00:26<00:01,  1.07it/s]Epoch: 9/10. Loss: 0.8073:  96%|[36m█████████▌[0m| 25/26 [00:26<00:01,  1.18s/it]Epoch: 9/10. Loss: 0.8850:  96%|[36m█████████▌[0m| 25/26 [00:28<00:01,  1.18s/it]Epoch: 9/10. Loss: 0.8850: 100%|[36m██████████[0m| 26/26 [00:28<00:00,  1.25s/it]Epoch: 9/10. Loss: 0.8850: 100%|[36m██████████[0m| 26/26 [00:28<00:00,  1.08s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:05,  1.16it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:06,  1.22s/it] 43%|[33m████▎     [0m| 3/7 [00:02<00:03,  1.09it/s] 57%|[33m█████▋    [0m| 4/7 [00:04<00:03,  1.18s/it] 71%|[33m███████▏  [0m| 5/7 [00:04<00:01,  1.12it/s] 86%|[33m████████▌ [0m| 6/7 [00:05<00:00,  1.14it/s]100%|[33m██████████[0m| 7/7 [00:07<00:00,  1.32s/it]100%|[33m██████████[0m| 7/7 [00:07<00:00,  1.13s/it]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 0/10. Loss: 1.1077:   0%|[36m          [0m| 0/26 [00:01<?, ?it/s]Epoch: 0/10. Loss: 1.1077:   4%|[36m▍         [0m| 1/26 [00:01<00:35,  1.44s/it]Epoch: 0/10. Loss: 1.7790:   4%|[36m▍         [0m| 1/26 [00:02<00:35,  1.44s/it]Epoch: 0/10. Loss: 1.7790:   8%|[36m▊         [0m| 2/26 [00:02<00:27,  1.15s/it]Epoch: 0/10. Loss: 2.5179:   8%|[36m▊         [0m| 2/26 [00:03<00:27,  1.15s/it]Epoch: 0/10. Loss: 2.5179:  12%|[36m█▏        [0m| 3/26 [00:03<00:24,  1.07s/it]Epoch: 0/10. Loss: 1.6092:  12%|[36m█▏        [0m| 3/26 [00:04<00:24,  1.07s/it]Epoch: 0/10. Loss: 1.6092:  15%|[36m█▌        [0m| 4/26 [00:04<00:22,  1.00s/it]Epoch: 0/10. Loss: 1.1592:  15%|[36m█▌        [0m| 4/26 [00:06<00:22,  1.00s/it]Epoch: 0/10. Loss: 1.1592:  19%|[36m█▉        [0m| 5/26 [00:06<00:33,  1.59s/it]Epoch: 0/10. Loss: 1.1071:  19%|[36m█▉        [0m| 5/26 [00:08<00:33,  1.59s/it]Epoch: 0/10. Loss: 1.1071:  23%|[36m██▎       [0m| 6/26 [00:08<00:30,  1.52s/it]Epoch: 0/10. Loss: 1.2956:  23%|[36m██▎       [0m| 6/26 [00:09<00:30,  1.52s/it]Epoch: 0/10. Loss: 1.2956:  27%|[36m██▋       [0m| 7/26 [00:09<00:26,  1.38s/it]Epoch: 0/10. Loss: 1.1099:  27%|[36m██▋       [0m| 7/26 [00:10<00:26,  1.38s/it]Epoch: 0/10. Loss: 1.1099:  31%|[36m███       [0m| 8/26 [00:10<00:22,  1.23s/it]Epoch: 0/10. Loss: 1.2418:  31%|[36m███       [0m| 8/26 [00:11<00:22,  1.23s/it]Epoch: 0/10. Loss: 1.2418:  35%|[36m███▍      [0m| 9/26 [00:11<00:19,  1.16s/it]Epoch: 0/10. Loss: 1.1998:  35%|[36m███▍      [0m| 9/26 [00:12<00:19,  1.16s/it]Epoch: 0/10. Loss: 1.1998:  38%|[36m███▊      [0m| 10/26 [00:12<00:18,  1.13s/it]Epoch: 0/10. Loss: 1.0820:  38%|[36m███▊      [0m| 10/26 [00:13<00:18,  1.13s/it]Epoch: 0/10. Loss: 1.0820:  42%|[36m████▏     [0m| 11/26 [00:13<00:17,  1.15s/it]Epoch: 0/10. Loss: 1.0477:  42%|[36m████▏     [0m| 11/26 [00:14<00:17,  1.15s/it]Epoch: 0/10. Loss: 1.0477:  46%|[36m████▌     [0m| 12/26 [00:14<00:16,  1.17s/it]Epoch: 0/10. Loss: 1.0720:  46%|[36m████▌     [0m| 12/26 [00:18<00:16,  1.17s/it]Epoch: 0/10. Loss: 1.0720:  50%|[36m█████     [0m| 13/26 [00:18<00:25,  1.93s/it]Epoch: 0/10. Loss: 1.0920:  50%|[36m█████     [0m| 13/26 [00:20<00:25,  1.93s/it]Epoch: 0/10. Loss: 1.0920:  54%|[36m█████▍    [0m| 14/26 [00:20<00:23,  1.92s/it]Epoch: 0/10. Loss: 0.9976:  54%|[36m█████▍    [0m| 14/26 [00:22<00:23,  1.92s/it]Epoch: 0/10. Loss: 0.9976:  58%|[36m█████▊    [0m| 15/26 [00:22<00:23,  2.09s/it]Epoch: 0/10. Loss: 1.1119:  58%|[36m█████▊    [0m| 15/26 [00:23<00:23,  2.09s/it]Epoch: 0/10. Loss: 1.1119:  62%|[36m██████▏   [0m| 16/26 [00:23<00:18,  1.80s/it]Epoch: 0/10. Loss: 1.2301:  62%|[36m██████▏   [0m| 16/26 [00:24<00:18,  1.80s/it]Epoch: 0/10. Loss: 1.2301:  65%|[36m██████▌   [0m| 17/26 [00:24<00:13,  1.55s/it]Epoch: 0/10. Loss: 1.3995:  65%|[36m██████▌   [0m| 17/26 [00:26<00:13,  1.55s/it]Epoch: 0/10. Loss: 1.3995:  69%|[36m██████▉   [0m| 18/26 [00:26<00:11,  1.48s/it]Epoch: 0/10. Loss: 1.0864:  69%|[36m██████▉   [0m| 18/26 [00:27<00:11,  1.48s/it]Epoch: 0/10. Loss: 1.0864:  73%|[36m███████▎  [0m| 19/26 [00:27<00:09,  1.32s/it]Epoch: 0/10. Loss: 0.9360:  73%|[36m███████▎  [0m| 19/26 [00:28<00:09,  1.32s/it]Epoch: 0/10. Loss: 0.9360:  77%|[36m███████▋  [0m| 20/26 [00:28<00:07,  1.22s/it]Epoch: 0/10. Loss: 1.3743:  77%|[36m███████▋  [0m| 20/26 [00:29<00:07,  1.22s/it]Epoch: 0/10. Loss: 1.3743:  81%|[36m████████  [0m| 21/26 [00:29<00:06,  1.21s/it]Epoch: 0/10. Loss: 1.0434:  81%|[36m████████  [0m| 21/26 [00:30<00:06,  1.21s/it]Epoch: 0/10. Loss: 1.0434:  85%|[36m████████▍ [0m| 22/26 [00:30<00:04,  1.18s/it]Epoch: 0/10. Loss: 1.3435:  85%|[36m████████▍ [0m| 22/26 [00:31<00:04,  1.18s/it]Epoch: 0/10. Loss: 1.3435:  88%|[36m████████▊ [0m| 23/26 [00:31<00:03,  1.11s/it]Epoch: 0/10. Loss: 1.0894:  88%|[36m████████▊ [0m| 23/26 [00:32<00:03,  1.11s/it]Epoch: 0/10. Loss: 1.0894:  92%|[36m█████████▏[0m| 24/26 [00:32<00:02,  1.07s/it]Epoch: 0/10. Loss: 1.0966:  92%|[36m█████████▏[0m| 24/26 [00:34<00:02,  1.07s/it]Epoch: 0/10. Loss: 1.0966:  96%|[36m█████████▌[0m| 25/26 [00:34<00:01,  1.52s/it]Epoch: 0/10. Loss: 1.0551:  96%|[36m█████████▌[0m| 25/26 [00:35<00:01,  1.52s/it]Epoch: 0/10. Loss: 1.0551: 100%|[36m██████████[0m| 26/26 [00:35<00:00,  1.31s/it]Epoch: 0/10. Loss: 1.0551: 100%|[36m██████████[0m| 26/26 [00:35<00:00,  1.38s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:05,  1.10it/s] 29%|[33m██▊       [0m| 2/7 [00:03<00:09,  1.90s/it] 43%|[33m████▎     [0m| 3/7 [00:04<00:05,  1.30s/it] 57%|[33m█████▋    [0m| 4/7 [00:05<00:04,  1.34s/it] 71%|[33m███████▏  [0m| 5/7 [00:06<00:02,  1.09s/it] 86%|[33m████████▌ [0m| 6/7 [00:07<00:01,  1.03s/it]100%|[33m██████████[0m| 7/7 [00:07<00:00,  1.22it/s]100%|[33m██████████[0m| 7/7 [00:07<00:00,  1.06s/it]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 1/10. Loss: 1.0357:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 1/10. Loss: 1.0357:   4%|[36m▍         [0m| 1/26 [00:01<00:25,  1.02s/it]Epoch: 1/10. Loss: 1.0451:   4%|[36m▍         [0m| 1/26 [00:02<00:25,  1.02s/it]Epoch: 1/10. Loss: 1.0451:   8%|[36m▊         [0m| 2/26 [00:02<00:25,  1.05s/it]Epoch: 1/10. Loss: 0.9317:   8%|[36m▊         [0m| 2/26 [00:02<00:25,  1.05s/it]Epoch: 1/10. Loss: 0.9317:  12%|[36m█▏        [0m| 3/26 [00:02<00:22,  1.02it/s]Epoch: 1/10. Loss: 1.1318:  12%|[36m█▏        [0m| 3/26 [00:03<00:22,  1.02it/s]Epoch: 1/10. Loss: 1.1318:  15%|[36m█▌        [0m| 4/26 [00:03<00:21,  1.01it/s]Epoch: 1/10. Loss: 1.0716:  15%|[36m█▌        [0m| 4/26 [00:05<00:21,  1.01it/s]Epoch: 1/10. Loss: 1.0716:  19%|[36m█▉        [0m| 5/26 [00:05<00:22,  1.07s/it]Epoch: 1/10. Loss: 1.1763:  19%|[36m█▉        [0m| 5/26 [00:06<00:22,  1.07s/it]Epoch: 1/10. Loss: 1.1763:  23%|[36m██▎       [0m| 6/26 [00:06<00:20,  1.02s/it]Epoch: 1/10. Loss: 1.1467:  23%|[36m██▎       [0m| 6/26 [00:07<00:20,  1.02s/it]Epoch: 1/10. Loss: 1.1467:  27%|[36m██▋       [0m| 7/26 [00:07<00:20,  1.07s/it]Epoch: 1/10. Loss: 1.0600:  27%|[36m██▋       [0m| 7/26 [00:08<00:20,  1.07s/it]Epoch: 1/10. Loss: 1.0600:  31%|[36m███       [0m| 8/26 [00:08<00:18,  1.01s/it]Epoch: 1/10. Loss: 1.1546:  31%|[36m███       [0m| 8/26 [00:09<00:18,  1.01s/it]Epoch: 1/10. Loss: 1.1546:  35%|[36m███▍      [0m| 9/26 [00:09<00:17,  1.02s/it]Epoch: 1/10. Loss: 1.0354:  35%|[36m███▍      [0m| 9/26 [00:10<00:17,  1.02s/it]Epoch: 1/10. Loss: 1.0354:  38%|[36m███▊      [0m| 10/26 [00:10<00:17,  1.11s/it]Epoch: 1/10. Loss: 0.9802:  38%|[36m███▊      [0m| 10/26 [00:12<00:17,  1.11s/it]Epoch: 1/10. Loss: 0.9802:  42%|[36m████▏     [0m| 11/26 [00:12<00:18,  1.26s/it]Epoch: 1/10. Loss: 1.0832:  42%|[36m████▏     [0m| 11/26 [00:13<00:18,  1.26s/it]Epoch: 1/10. Loss: 1.0832:  46%|[36m████▌     [0m| 12/26 [00:13<00:17,  1.23s/it]Epoch: 1/10. Loss: 0.9979:  46%|[36m████▌     [0m| 12/26 [00:14<00:17,  1.23s/it]Epoch: 1/10. Loss: 0.9979:  50%|[36m█████     [0m| 13/26 [00:14<00:14,  1.13s/it]Epoch: 1/10. Loss: 1.1076:  50%|[36m█████     [0m| 13/26 [00:15<00:14,  1.13s/it]Epoch: 1/10. Loss: 1.1076:  54%|[36m█████▍    [0m| 14/26 [00:15<00:12,  1.08s/it]Epoch: 1/10. Loss: 1.0296:  54%|[36m█████▍    [0m| 14/26 [00:16<00:12,  1.08s/it]Epoch: 1/10. Loss: 1.0296:  58%|[36m█████▊    [0m| 15/26 [00:16<00:11,  1.07s/it]Epoch: 1/10. Loss: 1.0314:  58%|[36m█████▊    [0m| 15/26 [00:17<00:11,  1.07s/it]Epoch: 1/10. Loss: 1.0314:  62%|[36m██████▏   [0m| 16/26 [00:17<00:10,  1.04s/it]Epoch: 1/10. Loss: 1.1205:  62%|[36m██████▏   [0m| 16/26 [00:18<00:10,  1.04s/it]Epoch: 1/10. Loss: 1.1205:  65%|[36m██████▌   [0m| 17/26 [00:18<00:10,  1.14s/it]Epoch: 1/10. Loss: 1.1038:  65%|[36m██████▌   [0m| 17/26 [00:19<00:10,  1.14s/it]Epoch: 1/10. Loss: 1.1038:  69%|[36m██████▉   [0m| 18/26 [00:19<00:08,  1.06s/it]Epoch: 1/10. Loss: 1.0162:  69%|[36m██████▉   [0m| 18/26 [00:20<00:08,  1.06s/it]Epoch: 1/10. Loss: 1.0162:  73%|[36m███████▎  [0m| 19/26 [00:20<00:07,  1.05s/it]Epoch: 1/10. Loss: 1.1310:  73%|[36m███████▎  [0m| 19/26 [00:22<00:07,  1.05s/it]Epoch: 1/10. Loss: 1.1310:  77%|[36m███████▋  [0m| 20/26 [00:22<00:07,  1.28s/it]Epoch: 1/10. Loss: 1.0353:  77%|[36m███████▋  [0m| 20/26 [00:23<00:07,  1.28s/it]Epoch: 1/10. Loss: 1.0353:  81%|[36m████████  [0m| 21/26 [00:23<00:05,  1.18s/it]Epoch: 1/10. Loss: 1.0874:  81%|[36m████████  [0m| 21/26 [00:24<00:05,  1.18s/it]Epoch: 1/10. Loss: 1.0874:  85%|[36m████████▍ [0m| 22/26 [00:24<00:04,  1.08s/it]Epoch: 1/10. Loss: 0.9877:  85%|[36m████████▍ [0m| 22/26 [00:25<00:04,  1.08s/it]Epoch: 1/10. Loss: 0.9877:  88%|[36m████████▊ [0m| 23/26 [00:25<00:03,  1.27s/it]Epoch: 1/10. Loss: 1.1051:  88%|[36m████████▊ [0m| 23/26 [00:27<00:03,  1.27s/it]Epoch: 1/10. Loss: 1.1051:  92%|[36m█████████▏[0m| 24/26 [00:27<00:02,  1.33s/it]Epoch: 1/10. Loss: 1.0072:  92%|[36m█████████▏[0m| 24/26 [00:28<00:02,  1.33s/it]Epoch: 1/10. Loss: 1.0072:  96%|[36m█████████▌[0m| 25/26 [00:28<00:01,  1.21s/it]Epoch: 1/10. Loss: 1.1059:  96%|[36m█████████▌[0m| 25/26 [00:29<00:01,  1.21s/it]Epoch: 1/10. Loss: 1.1059: 100%|[36m██████████[0m| 26/26 [00:29<00:00,  1.13s/it]Epoch: 1/10. Loss: 1.1059: 100%|[36m██████████[0m| 26/26 [00:29<00:00,  1.12s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:05,  1.08it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:06,  1.28s/it] 43%|[33m████▎     [0m| 3/7 [00:03<00:03,  1.02it/s] 57%|[33m█████▋    [0m| 4/7 [00:04<00:03,  1.17s/it] 71%|[33m███████▏  [0m| 5/7 [00:04<00:01,  1.09it/s] 86%|[33m████████▌ [0m| 6/7 [00:05<00:00,  1.09it/s]100%|[33m██████████[0m| 7/7 [00:06<00:00,  1.37it/s]100%|[33m██████████[0m| 7/7 [00:06<00:00,  1.12it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 2/10. Loss: 1.0205:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 2/10. Loss: 1.0205:   4%|[36m▍         [0m| 1/26 [00:00<00:23,  1.07it/s]Epoch: 2/10. Loss: 0.9993:   4%|[36m▍         [0m| 1/26 [00:01<00:23,  1.07it/s]Epoch: 2/10. Loss: 0.9993:   8%|[36m▊         [0m| 2/26 [00:01<00:21,  1.11it/s]Epoch: 2/10. Loss: 1.0787:   8%|[36m▊         [0m| 2/26 [00:02<00:21,  1.11it/s]Epoch: 2/10. Loss: 1.0787:  12%|[36m█▏        [0m| 3/26 [00:02<00:21,  1.08it/s]Epoch: 2/10. Loss: 1.2499:  12%|[36m█▏        [0m| 3/26 [00:03<00:21,  1.08it/s]Epoch: 2/10. Loss: 1.2499:  15%|[36m█▌        [0m| 4/26 [00:04<00:23,  1.05s/it]Epoch: 2/10. Loss: 1.1101:  15%|[36m█▌        [0m| 4/26 [00:04<00:23,  1.05s/it]Epoch: 2/10. Loss: 1.1101:  19%|[36m█▉        [0m| 5/26 [00:04<00:20,  1.04it/s]Epoch: 2/10. Loss: 1.1300:  19%|[36m█▉        [0m| 5/26 [00:05<00:20,  1.04it/s]Epoch: 2/10. Loss: 1.1300:  23%|[36m██▎       [0m| 6/26 [00:05<00:19,  1.00it/s]Epoch: 2/10. Loss: 1.0200:  23%|[36m██▎       [0m| 6/26 [00:06<00:19,  1.00it/s]Epoch: 2/10. Loss: 1.0200:  27%|[36m██▋       [0m| 7/26 [00:07<00:19,  1.04s/it]Epoch: 2/10. Loss: 1.0662:  27%|[36m██▋       [0m| 7/26 [00:07<00:19,  1.04s/it]Epoch: 2/10. Loss: 1.0662:  31%|[36m███       [0m| 8/26 [00:08<00:18,  1.03s/it]Epoch: 2/10. Loss: 1.0964:  31%|[36m███       [0m| 8/26 [00:09<00:18,  1.03s/it]Epoch: 2/10. Loss: 1.0964:  35%|[36m███▍      [0m| 9/26 [00:09<00:17,  1.05s/it]Epoch: 2/10. Loss: 1.0083:  35%|[36m███▍      [0m| 9/26 [00:09<00:17,  1.05s/it]Epoch: 2/10. Loss: 1.0083:  38%|[36m███▊      [0m| 10/26 [00:09<00:15,  1.03it/s]Epoch: 2/10. Loss: 0.9383:  38%|[36m███▊      [0m| 10/26 [00:10<00:15,  1.03it/s]Epoch: 2/10. Loss: 0.9383:  42%|[36m████▏     [0m| 11/26 [00:10<00:14,  1.03it/s]Epoch: 2/10. Loss: 1.0573:  42%|[36m████▏     [0m| 11/26 [00:11<00:14,  1.03it/s]Epoch: 2/10. Loss: 1.0573:  46%|[36m████▌     [0m| 12/26 [00:11<00:13,  1.01it/s]Epoch: 2/10. Loss: 1.0222:  46%|[36m████▌     [0m| 12/26 [00:12<00:13,  1.01it/s]Epoch: 2/10. Loss: 1.0222:  50%|[36m█████     [0m| 13/26 [00:12<00:12,  1.02it/s]Epoch: 2/10. Loss: 1.0305:  50%|[36m█████     [0m| 13/26 [00:13<00:12,  1.02it/s]Epoch: 2/10. Loss: 1.0305:  54%|[36m█████▍    [0m| 14/26 [00:13<00:11,  1.00it/s]Epoch: 2/10. Loss: 1.0164:  54%|[36m█████▍    [0m| 14/26 [00:14<00:11,  1.00it/s]Epoch: 2/10. Loss: 1.0164:  58%|[36m█████▊    [0m| 15/26 [00:14<00:11,  1.02s/it]Epoch: 2/10. Loss: 1.0559:  58%|[36m█████▊    [0m| 15/26 [00:16<00:11,  1.02s/it]Epoch: 2/10. Loss: 1.0559:  62%|[36m██████▏   [0m| 16/26 [00:16<00:10,  1.08s/it]Epoch: 2/10. Loss: 0.9757:  62%|[36m██████▏   [0m| 16/26 [00:17<00:10,  1.08s/it]Epoch: 2/10. Loss: 0.9757:  65%|[36m██████▌   [0m| 17/26 [00:17<00:09,  1.05s/it]Epoch: 2/10. Loss: 1.1028:  65%|[36m██████▌   [0m| 17/26 [00:18<00:09,  1.05s/it]Epoch: 2/10. Loss: 1.1028:  69%|[36m██████▉   [0m| 18/26 [00:18<00:08,  1.07s/it]Epoch: 2/10. Loss: 1.1590:  69%|[36m██████▉   [0m| 18/26 [00:19<00:08,  1.07s/it]Epoch: 2/10. Loss: 1.1590:  73%|[36m███████▎  [0m| 19/26 [00:19<00:07,  1.03s/it]Epoch: 2/10. Loss: 1.0304:  73%|[36m███████▎  [0m| 19/26 [00:20<00:07,  1.03s/it]Epoch: 2/10. Loss: 1.0304:  77%|[36m███████▋  [0m| 20/26 [00:20<00:05,  1.04it/s]Epoch: 2/10. Loss: 1.1827:  77%|[36m███████▋  [0m| 20/26 [00:21<00:05,  1.04it/s]Epoch: 2/10. Loss: 1.1827:  81%|[36m████████  [0m| 21/26 [00:21<00:05,  1.15s/it]Epoch: 2/10. Loss: 1.1088:  81%|[36m████████  [0m| 21/26 [00:22<00:05,  1.15s/it]Epoch: 2/10. Loss: 1.1088:  85%|[36m████████▍ [0m| 22/26 [00:22<00:04,  1.20s/it]Epoch: 2/10. Loss: 0.9955:  85%|[36m████████▍ [0m| 22/26 [00:23<00:04,  1.20s/it]Epoch: 2/10. Loss: 0.9955:  88%|[36m████████▊ [0m| 23/26 [00:23<00:03,  1.15s/it]Epoch: 2/10. Loss: 1.0394:  88%|[36m████████▊ [0m| 23/26 [00:24<00:03,  1.15s/it]Epoch: 2/10. Loss: 1.0394:  92%|[36m█████████▏[0m| 24/26 [00:24<00:02,  1.08s/it]Epoch: 2/10. Loss: 1.0033:  92%|[36m█████████▏[0m| 24/26 [00:25<00:02,  1.08s/it]Epoch: 2/10. Loss: 1.0033:  96%|[36m█████████▌[0m| 25/26 [00:25<00:01,  1.05s/it]Epoch: 2/10. Loss: 1.0916:  96%|[36m█████████▌[0m| 25/26 [00:26<00:01,  1.05s/it]Epoch: 2/10. Loss: 1.0916: 100%|[36m██████████[0m| 26/26 [00:26<00:00,  1.07it/s]Epoch: 2/10. Loss: 1.0916: 100%|[36m██████████[0m| 26/26 [00:26<00:00,  1.02s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:05,  1.10it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:06,  1.25s/it] 43%|[33m████▎     [0m| 3/7 [00:02<00:03,  1.05it/s] 57%|[33m█████▋    [0m| 4/7 [00:04<00:03,  1.16s/it] 71%|[33m███████▏  [0m| 5/7 [00:04<00:01,  1.11it/s] 86%|[33m████████▌ [0m| 6/7 [00:05<00:00,  1.10it/s]100%|[33m██████████[0m| 7/7 [00:06<00:00,  1.40it/s]100%|[33m██████████[0m| 7/7 [00:06<00:00,  1.14it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 3/10. Loss: 0.9704:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 3/10. Loss: 0.9704:   4%|[36m▍         [0m| 1/26 [00:00<00:22,  1.11it/s]Epoch: 3/10. Loss: 1.1041:   4%|[36m▍         [0m| 1/26 [00:01<00:22,  1.11it/s]Epoch: 3/10. Loss: 1.1041:   8%|[36m▊         [0m| 2/26 [00:01<00:23,  1.02it/s]Epoch: 3/10. Loss: 1.0941:   8%|[36m▊         [0m| 2/26 [00:02<00:23,  1.02it/s]Epoch: 3/10. Loss: 1.0941:  12%|[36m█▏        [0m| 3/26 [00:02<00:21,  1.06it/s]Epoch: 3/10. Loss: 1.0161:  12%|[36m█▏        [0m| 3/26 [00:03<00:21,  1.06it/s]Epoch: 3/10. Loss: 1.0161:  15%|[36m█▌        [0m| 4/26 [00:03<00:21,  1.02it/s]Epoch: 3/10. Loss: 1.0468:  15%|[36m█▌        [0m| 4/26 [00:04<00:21,  1.02it/s]Epoch: 3/10. Loss: 1.0468:  19%|[36m█▉        [0m| 5/26 [00:04<00:19,  1.06it/s]Epoch: 3/10. Loss: 1.0116:  19%|[36m█▉        [0m| 5/26 [00:05<00:19,  1.06it/s]Epoch: 3/10. Loss: 1.0116:  23%|[36m██▎       [0m| 6/26 [00:05<00:19,  1.04it/s]Epoch: 3/10. Loss: 1.0591:  23%|[36m██▎       [0m| 6/26 [00:06<00:19,  1.04it/s]Epoch: 3/10. Loss: 1.0591:  27%|[36m██▋       [0m| 7/26 [00:06<00:18,  1.05it/s]Epoch: 3/10. Loss: 0.9927:  27%|[36m██▋       [0m| 7/26 [00:07<00:18,  1.05it/s]Epoch: 3/10. Loss: 0.9927:  31%|[36m███       [0m| 8/26 [00:07<00:17,  1.03it/s]Epoch: 3/10. Loss: 1.0328:  31%|[36m███       [0m| 8/26 [00:08<00:17,  1.03it/s]Epoch: 3/10. Loss: 1.0328:  35%|[36m███▍      [0m| 9/26 [00:08<00:17,  1.02s/it]Epoch: 3/10. Loss: 1.0537:  35%|[36m███▍      [0m| 9/26 [00:09<00:17,  1.02s/it]Epoch: 3/10. Loss: 1.0537:  38%|[36m███▊      [0m| 10/26 [00:09<00:16,  1.01s/it]Epoch: 3/10. Loss: 1.0624:  38%|[36m███▊      [0m| 10/26 [00:10<00:16,  1.01s/it]Epoch: 3/10. Loss: 1.0624:  42%|[36m████▏     [0m| 11/26 [00:10<00:14,  1.03it/s]Epoch: 3/10. Loss: 1.1131:  42%|[36m████▏     [0m| 11/26 [00:11<00:14,  1.03it/s]Epoch: 3/10. Loss: 1.1131:  46%|[36m████▌     [0m| 12/26 [00:11<00:14,  1.04s/it]Epoch: 3/10. Loss: 0.9904:  46%|[36m████▌     [0m| 12/26 [00:12<00:14,  1.04s/it]Epoch: 3/10. Loss: 0.9904:  50%|[36m█████     [0m| 13/26 [00:12<00:13,  1.01s/it]Epoch: 3/10. Loss: 0.9611:  50%|[36m█████     [0m| 13/26 [00:13<00:13,  1.01s/it]Epoch: 3/10. Loss: 0.9611:  54%|[36m█████▍    [0m| 14/26 [00:13<00:12,  1.03s/it]Epoch: 3/10. Loss: 0.9860:  54%|[36m█████▍    [0m| 14/26 [00:14<00:12,  1.03s/it]Epoch: 3/10. Loss: 0.9860:  58%|[36m█████▊    [0m| 15/26 [00:14<00:11,  1.03s/it]Epoch: 3/10. Loss: 1.0501:  58%|[36m█████▊    [0m| 15/26 [00:15<00:11,  1.03s/it]Epoch: 3/10. Loss: 1.0501:  62%|[36m██████▏   [0m| 16/26 [00:15<00:10,  1.00s/it]Epoch: 3/10. Loss: 1.2572:  62%|[36m██████▏   [0m| 16/26 [00:17<00:10,  1.00s/it]Epoch: 3/10. Loss: 1.2572:  65%|[36m██████▌   [0m| 17/26 [00:17<00:09,  1.07s/it]Epoch: 3/10. Loss: 1.0069:  65%|[36m██████▌   [0m| 17/26 [00:18<00:09,  1.07s/it]Epoch: 3/10. Loss: 1.0069:  69%|[36m██████▉   [0m| 18/26 [00:18<00:08,  1.04s/it]Epoch: 3/10. Loss: 0.9826:  69%|[36m██████▉   [0m| 18/26 [00:19<00:08,  1.04s/it]Epoch: 3/10. Loss: 0.9826:  73%|[36m███████▎  [0m| 19/26 [00:19<00:07,  1.04s/it]Epoch: 3/10. Loss: 1.1262:  73%|[36m███████▎  [0m| 19/26 [00:20<00:07,  1.04s/it]Epoch: 3/10. Loss: 1.1262:  77%|[36m███████▋  [0m| 20/26 [00:20<00:06,  1.02s/it]Epoch: 3/10. Loss: 1.0424:  77%|[36m███████▋  [0m| 20/26 [00:21<00:06,  1.02s/it]Epoch: 3/10. Loss: 1.0424:  81%|[36m████████  [0m| 21/26 [00:21<00:05,  1.03s/it]Epoch: 3/10. Loss: 1.0049:  81%|[36m████████  [0m| 21/26 [00:22<00:05,  1.03s/it]Epoch: 3/10. Loss: 1.0049:  85%|[36m████████▍ [0m| 22/26 [00:22<00:04,  1.03s/it]Epoch: 3/10. Loss: 0.9959:  85%|[36m████████▍ [0m| 22/26 [00:23<00:04,  1.03s/it]Epoch: 3/10. Loss: 0.9959:  88%|[36m████████▊ [0m| 23/26 [00:23<00:03,  1.13s/it]Epoch: 3/10. Loss: 1.0091:  88%|[36m████████▊ [0m| 23/26 [00:24<00:03,  1.13s/it]Epoch: 3/10. Loss: 1.0091:  92%|[36m█████████▏[0m| 24/26 [00:24<00:02,  1.07s/it]Epoch: 3/10. Loss: 1.0646:  92%|[36m█████████▏[0m| 24/26 [00:27<00:02,  1.07s/it]Epoch: 3/10. Loss: 1.0646:  96%|[36m█████████▌[0m| 25/26 [00:27<00:01,  1.55s/it]Epoch: 3/10. Loss: 0.9572:  96%|[36m█████████▌[0m| 25/26 [00:28<00:01,  1.55s/it]Epoch: 3/10. Loss: 0.9572: 100%|[36m██████████[0m| 26/26 [00:28<00:00,  1.48s/it]Epoch: 3/10. Loss: 0.9572: 100%|[36m██████████[0m| 26/26 [00:28<00:00,  1.09s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:05,  1.05it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:06,  1.29s/it] 43%|[33m████▎     [0m| 3/7 [00:03<00:03,  1.02it/s] 57%|[33m█████▋    [0m| 4/7 [00:04<00:03,  1.20s/it] 71%|[33m███████▏  [0m| 5/7 [00:05<00:01,  1.07it/s] 86%|[33m████████▌ [0m| 6/7 [00:06<00:01,  1.07s/it]100%|[33m██████████[0m| 7/7 [00:06<00:00,  1.21it/s]100%|[33m██████████[0m| 7/7 [00:06<00:00,  1.04it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 4/10. Loss: 1.0064:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 4/10. Loss: 1.0064:   4%|[36m▍         [0m| 1/26 [00:00<00:24,  1.03it/s]Epoch: 4/10. Loss: 1.0425:   4%|[36m▍         [0m| 1/26 [00:01<00:24,  1.03it/s]Epoch: 4/10. Loss: 1.0425:   8%|[36m▊         [0m| 2/26 [00:01<00:22,  1.07it/s]Epoch: 4/10. Loss: 1.0095:   8%|[36m▊         [0m| 2/26 [00:02<00:22,  1.07it/s]Epoch: 4/10. Loss: 1.0095:  12%|[36m█▏        [0m| 3/26 [00:02<00:22,  1.04it/s]Epoch: 4/10. Loss: 0.9270:  12%|[36m█▏        [0m| 3/26 [00:04<00:22,  1.04it/s]Epoch: 4/10. Loss: 0.9270:  15%|[36m█▌        [0m| 4/26 [00:04<00:29,  1.34s/it]Epoch: 4/10. Loss: 1.0431:  15%|[36m█▌        [0m| 4/26 [00:05<00:29,  1.34s/it]Epoch: 4/10. Loss: 1.0431:  19%|[36m█▉        [0m| 5/26 [00:05<00:25,  1.22s/it]Epoch: 4/10. Loss: 1.0401:  19%|[36m█▉        [0m| 5/26 [00:07<00:25,  1.22s/it]Epoch: 4/10. Loss: 1.0401:  23%|[36m██▎       [0m| 6/26 [00:07<00:29,  1.49s/it]Epoch: 4/10. Loss: 1.0108:  23%|[36m██▎       [0m| 6/26 [00:09<00:29,  1.49s/it]Epoch: 4/10. Loss: 1.0108:  27%|[36m██▋       [0m| 7/26 [00:09<00:27,  1.44s/it]Epoch: 4/10. Loss: 1.0284:  27%|[36m██▋       [0m| 7/26 [00:10<00:27,  1.44s/it]Epoch: 4/10. Loss: 1.0284:  31%|[36m███       [0m| 8/26 [00:10<00:24,  1.38s/it]Epoch: 4/10. Loss: 1.0294:  31%|[36m███       [0m| 8/26 [00:11<00:24,  1.38s/it]Epoch: 4/10. Loss: 1.0294:  35%|[36m███▍      [0m| 9/26 [00:11<00:21,  1.24s/it]Epoch: 4/10. Loss: 1.0417:  35%|[36m███▍      [0m| 9/26 [00:12<00:21,  1.24s/it]Epoch: 4/10. Loss: 1.0417:  38%|[36m███▊      [0m| 10/26 [00:12<00:17,  1.11s/it]Epoch: 4/10. Loss: 0.9679:  38%|[36m███▊      [0m| 10/26 [00:12<00:17,  1.11s/it]Epoch: 4/10. Loss: 0.9679:  42%|[36m████▏     [0m| 11/26 [00:13<00:15,  1.03s/it]Epoch: 4/10. Loss: 1.0690:  42%|[36m████▏     [0m| 11/26 [00:13<00:15,  1.03s/it]Epoch: 4/10. Loss: 1.0690:  46%|[36m████▌     [0m| 12/26 [00:14<00:14,  1.03s/it]Epoch: 4/10. Loss: 1.0226:  46%|[36m████▌     [0m| 12/26 [00:14<00:14,  1.03s/it]Epoch: 4/10. Loss: 1.0226:  50%|[36m█████     [0m| 13/26 [00:14<00:12,  1.01it/s]Epoch: 4/10. Loss: 1.0457:  50%|[36m█████     [0m| 13/26 [00:15<00:12,  1.01it/s]Epoch: 4/10. Loss: 1.0457:  54%|[36m█████▍    [0m| 14/26 [00:15<00:11,  1.04it/s]Epoch: 4/10. Loss: 1.1254:  54%|[36m█████▍    [0m| 14/26 [00:16<00:11,  1.04it/s]Epoch: 4/10. Loss: 1.1254:  58%|[36m█████▊    [0m| 15/26 [00:17<00:11,  1.03s/it]Epoch: 4/10. Loss: 1.2749:  58%|[36m█████▊    [0m| 15/26 [00:17<00:11,  1.03s/it]Epoch: 4/10. Loss: 1.2749:  62%|[36m██████▏   [0m| 16/26 [00:17<00:09,  1.02it/s]Epoch: 4/10. Loss: 1.0862:  62%|[36m██████▏   [0m| 16/26 [00:18<00:09,  1.02it/s]Epoch: 4/10. Loss: 1.0862:  65%|[36m██████▌   [0m| 17/26 [00:18<00:08,  1.02it/s]Epoch: 4/10. Loss: 0.9695:  65%|[36m██████▌   [0m| 17/26 [00:19<00:08,  1.02it/s]Epoch: 4/10. Loss: 0.9695:  69%|[36m██████▉   [0m| 18/26 [00:19<00:07,  1.05it/s]Epoch: 4/10. Loss: 1.0925:  69%|[36m██████▉   [0m| 18/26 [00:20<00:07,  1.05it/s]Epoch: 4/10. Loss: 1.0925:  73%|[36m███████▎  [0m| 19/26 [00:20<00:06,  1.11it/s]Epoch: 4/10. Loss: 1.0127:  73%|[36m███████▎  [0m| 19/26 [00:21<00:06,  1.11it/s]Epoch: 4/10. Loss: 1.0127:  77%|[36m███████▋  [0m| 20/26 [00:21<00:05,  1.07it/s]Epoch: 4/10. Loss: 1.0155:  77%|[36m███████▋  [0m| 20/26 [00:22<00:05,  1.07it/s]Epoch: 4/10. Loss: 1.0155:  81%|[36m████████  [0m| 21/26 [00:22<00:05,  1.06s/it]Epoch: 4/10. Loss: 1.0277:  81%|[36m████████  [0m| 21/26 [00:23<00:05,  1.06s/it]Epoch: 4/10. Loss: 1.0277:  85%|[36m████████▍ [0m| 22/26 [00:23<00:04,  1.05s/it]Epoch: 4/10. Loss: 1.0251:  85%|[36m████████▍ [0m| 22/26 [00:24<00:04,  1.05s/it]Epoch: 4/10. Loss: 1.0251:  88%|[36m████████▊ [0m| 23/26 [00:24<00:03,  1.02s/it]Epoch: 4/10. Loss: 1.0271:  88%|[36m████████▊ [0m| 23/26 [00:25<00:03,  1.02s/it]Epoch: 4/10. Loss: 1.0271:  92%|[36m█████████▏[0m| 24/26 [00:25<00:01,  1.00it/s]Epoch: 4/10. Loss: 0.9867:  92%|[36m█████████▏[0m| 24/26 [00:26<00:01,  1.00it/s]Epoch: 4/10. Loss: 0.9867:  96%|[36m█████████▌[0m| 25/26 [00:26<00:00,  1.00it/s]Epoch: 4/10. Loss: 1.0251:  96%|[36m█████████▌[0m| 25/26 [00:27<00:00,  1.00it/s]Epoch: 4/10. Loss: 1.0251: 100%|[36m██████████[0m| 26/26 [00:27<00:00,  1.10it/s]Epoch: 4/10. Loss: 1.0251: 100%|[36m██████████[0m| 26/26 [00:27<00:00,  1.06s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:05,  1.08it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:06,  1.28s/it] 43%|[33m████▎     [0m| 3/7 [00:03<00:03,  1.04it/s] 57%|[33m█████▋    [0m| 4/7 [00:04<00:03,  1.16s/it] 71%|[33m███████▏  [0m| 5/7 [00:04<00:01,  1.10it/s] 86%|[33m████████▌ [0m| 6/7 [00:05<00:00,  1.09it/s]100%|[33m██████████[0m| 7/7 [00:06<00:00,  1.38it/s]100%|[33m██████████[0m| 7/7 [00:06<00:00,  1.12it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 5/10. Loss: 1.0570:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 5/10. Loss: 1.0570:   4%|[36m▍         [0m| 1/26 [00:00<00:23,  1.07it/s]Epoch: 5/10. Loss: 1.0199:   4%|[36m▍         [0m| 1/26 [00:01<00:23,  1.07it/s]Epoch: 5/10. Loss: 1.0199:   8%|[36m▊         [0m| 2/26 [00:02<00:24,  1.02s/it]Epoch: 5/10. Loss: 1.1312:   8%|[36m▊         [0m| 2/26 [00:02<00:24,  1.02s/it]Epoch: 5/10. Loss: 1.1312:  12%|[36m█▏        [0m| 3/26 [00:02<00:22,  1.01it/s]Epoch: 5/10. Loss: 1.0034:  12%|[36m█▏        [0m| 3/26 [00:03<00:22,  1.01it/s]Epoch: 5/10. Loss: 1.0034:  15%|[36m█▌        [0m| 4/26 [00:03<00:21,  1.00it/s]Epoch: 5/10. Loss: 1.0839:  15%|[36m█▌        [0m| 4/26 [00:06<00:21,  1.00it/s]Epoch: 5/10. Loss: 1.0839:  19%|[36m█▉        [0m| 5/26 [00:06<00:34,  1.66s/it]Epoch: 5/10. Loss: 1.0939:  19%|[36m█▉        [0m| 5/26 [00:07<00:34,  1.66s/it]Epoch: 5/10. Loss: 1.0939:  23%|[36m██▎       [0m| 6/26 [00:07<00:28,  1.41s/it]Epoch: 5/10. Loss: 1.0172:  23%|[36m██▎       [0m| 6/26 [00:08<00:28,  1.41s/it]Epoch: 5/10. Loss: 1.0172:  27%|[36m██▋       [0m| 7/26 [00:08<00:23,  1.25s/it]Epoch: 5/10. Loss: 1.1171:  27%|[36m██▋       [0m| 7/26 [00:09<00:23,  1.25s/it]Epoch: 5/10. Loss: 1.1171:  31%|[36m███       [0m| 8/26 [00:09<00:20,  1.13s/it]Epoch: 5/10. Loss: 1.1025:  31%|[36m███       [0m| 8/26 [00:10<00:20,  1.13s/it]Epoch: 5/10. Loss: 1.1025:  35%|[36m███▍      [0m| 9/26 [00:10<00:18,  1.08s/it]Epoch: 5/10. Loss: 1.1818:  35%|[36m███▍      [0m| 9/26 [00:11<00:18,  1.08s/it]Epoch: 5/10. Loss: 1.1818:  38%|[36m███▊      [0m| 10/26 [00:11<00:17,  1.07s/it]Epoch: 5/10. Loss: 1.0746:  38%|[36m███▊      [0m| 10/26 [00:12<00:17,  1.07s/it]Epoch: 5/10. Loss: 1.0746:  42%|[36m████▏     [0m| 11/26 [00:12<00:15,  1.03s/it]Epoch: 5/10. Loss: 1.0066:  42%|[36m████▏     [0m| 11/26 [00:13<00:15,  1.03s/it]Epoch: 5/10. Loss: 1.0066:  46%|[36m████▌     [0m| 12/26 [00:13<00:13,  1.03it/s]Epoch: 5/10. Loss: 1.0398:  46%|[36m████▌     [0m| 12/26 [00:14<00:13,  1.03it/s]Epoch: 5/10. Loss: 1.0398:  50%|[36m█████     [0m| 13/26 [00:14<00:12,  1.03it/s]Epoch: 5/10. Loss: 1.0174:  50%|[36m█████     [0m| 13/26 [00:15<00:12,  1.03it/s]Epoch: 5/10. Loss: 1.0174:  54%|[36m█████▍    [0m| 14/26 [00:15<00:11,  1.01it/s]Epoch: 5/10. Loss: 1.0473:  54%|[36m█████▍    [0m| 14/26 [00:16<00:11,  1.01it/s]Epoch: 5/10. Loss: 1.0473:  58%|[36m█████▊    [0m| 15/26 [00:16<00:10,  1.04it/s]Epoch: 5/10. Loss: 1.0432:  58%|[36m█████▊    [0m| 15/26 [00:17<00:10,  1.04it/s]Epoch: 5/10. Loss: 1.0432:  62%|[36m██████▏   [0m| 16/26 [00:17<00:09,  1.04it/s]Epoch: 5/10. Loss: 1.0210:  62%|[36m██████▏   [0m| 16/26 [00:18<00:09,  1.04it/s]Epoch: 5/10. Loss: 1.0210:  65%|[36m██████▌   [0m| 17/26 [00:18<00:08,  1.02it/s]Epoch: 5/10. Loss: 0.9861:  65%|[36m██████▌   [0m| 17/26 [00:19<00:08,  1.02it/s]Epoch: 5/10. Loss: 0.9861:  69%|[36m██████▉   [0m| 18/26 [00:19<00:07,  1.03it/s]Epoch: 5/10. Loss: 1.1096:  69%|[36m██████▉   [0m| 18/26 [00:20<00:07,  1.03it/s]Epoch: 5/10. Loss: 1.1096:  73%|[36m███████▎  [0m| 19/26 [00:20<00:06,  1.04it/s]Epoch: 5/10. Loss: 1.0221:  73%|[36m███████▎  [0m| 19/26 [00:21<00:06,  1.04it/s]Epoch: 5/10. Loss: 1.0221:  77%|[36m███████▋  [0m| 20/26 [00:21<00:05,  1.02it/s]Epoch: 5/10. Loss: 1.0318:  77%|[36m███████▋  [0m| 20/26 [00:22<00:05,  1.02it/s]Epoch: 5/10. Loss: 1.0318:  81%|[36m████████  [0m| 21/26 [00:22<00:04,  1.02it/s]Epoch: 5/10. Loss: 0.9848:  81%|[36m████████  [0m| 21/26 [00:23<00:04,  1.02it/s]Epoch: 5/10. Loss: 0.9848:  85%|[36m████████▍ [0m| 22/26 [00:23<00:04,  1.02s/it]Epoch: 5/10. Loss: 1.0660:  85%|[36m████████▍ [0m| 22/26 [00:24<00:04,  1.02s/it]Epoch: 5/10. Loss: 1.0660:  88%|[36m████████▊ [0m| 23/26 [00:24<00:03,  1.03s/it]Epoch: 5/10. Loss: 0.9920:  88%|[36m████████▊ [0m| 23/26 [00:25<00:03,  1.03s/it]Epoch: 5/10. Loss: 0.9920:  92%|[36m█████████▏[0m| 24/26 [00:25<00:02,  1.04s/it]Epoch: 5/10. Loss: 0.9786:  92%|[36m█████████▏[0m| 24/26 [00:26<00:02,  1.04s/it]Epoch: 5/10. Loss: 0.9786:  96%|[36m█████████▌[0m| 25/26 [00:26<00:01,  1.07s/it]Epoch: 5/10. Loss: 0.9837:  96%|[36m█████████▌[0m| 25/26 [00:27<00:01,  1.07s/it]Epoch: 5/10. Loss: 0.9837: 100%|[36m██████████[0m| 26/26 [00:27<00:00,  1.00s/it]Epoch: 5/10. Loss: 0.9837: 100%|[36m██████████[0m| 26/26 [00:27<00:00,  1.05s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:05,  1.10it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:06,  1.26s/it] 43%|[33m████▎     [0m| 3/7 [00:02<00:03,  1.05it/s] 57%|[33m█████▋    [0m| 4/7 [00:04<00:03,  1.15s/it] 71%|[33m███████▏  [0m| 5/7 [00:04<00:01,  1.11it/s] 86%|[33m████████▌ [0m| 6/7 [00:05<00:00,  1.10it/s]100%|[33m██████████[0m| 7/7 [00:06<00:00,  1.39it/s]100%|[33m██████████[0m| 7/7 [00:06<00:00,  1.14it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 6/10. Loss: 1.0209:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 6/10. Loss: 1.0209:   4%|[36m▍         [0m| 1/26 [00:00<00:21,  1.17it/s]Epoch: 6/10. Loss: 0.9777:   4%|[36m▍         [0m| 1/26 [00:02<00:21,  1.17it/s]Epoch: 6/10. Loss: 0.9777:   8%|[36m▊         [0m| 2/26 [00:02<00:25,  1.05s/it]Epoch: 6/10. Loss: 1.0078:   8%|[36m▊         [0m| 2/26 [00:03<00:25,  1.05s/it]Epoch: 6/10. Loss: 1.0078:  12%|[36m█▏        [0m| 3/26 [00:03<00:25,  1.12s/it]Epoch: 6/10. Loss: 1.0894:  12%|[36m█▏        [0m| 3/26 [00:04<00:25,  1.12s/it]Epoch: 6/10. Loss: 1.0894:  15%|[36m█▌        [0m| 4/26 [00:04<00:23,  1.06s/it]Epoch: 6/10. Loss: 0.9716:  15%|[36m█▌        [0m| 4/26 [00:05<00:23,  1.06s/it]Epoch: 6/10. Loss: 0.9716:  19%|[36m█▉        [0m| 5/26 [00:05<00:22,  1.06s/it]Epoch: 6/10. Loss: 1.0840:  19%|[36m█▉        [0m| 5/26 [00:06<00:22,  1.06s/it]Epoch: 6/10. Loss: 1.0840:  23%|[36m██▎       [0m| 6/26 [00:06<00:21,  1.07s/it]Epoch: 6/10. Loss: 0.9895:  23%|[36m██▎       [0m| 6/26 [00:07<00:21,  1.07s/it]Epoch: 6/10. Loss: 0.9895:  27%|[36m██▋       [0m| 7/26 [00:07<00:19,  1.03s/it]Epoch: 6/10. Loss: 1.0268:  27%|[36m██▋       [0m| 7/26 [00:08<00:19,  1.03s/it]Epoch: 6/10. Loss: 1.0268:  31%|[36m███       [0m| 8/26 [00:08<00:18,  1.03s/it]Epoch: 6/10. Loss: 0.9467:  31%|[36m███       [0m| 8/26 [00:09<00:18,  1.03s/it]Epoch: 6/10. Loss: 0.9467:  35%|[36m███▍      [0m| 9/26 [00:09<00:16,  1.05it/s]Epoch: 6/10. Loss: 0.9536:  35%|[36m███▍      [0m| 9/26 [00:10<00:16,  1.05it/s]Epoch: 6/10. Loss: 0.9536:  38%|[36m███▊      [0m| 10/26 [00:10<00:15,  1.01it/s]Epoch: 6/10. Loss: 1.0589:  38%|[36m███▊      [0m| 10/26 [00:10<00:15,  1.01it/s]Epoch: 6/10. Loss: 1.0589:  42%|[36m████▏     [0m| 11/26 [00:10<00:13,  1.09it/s]Epoch: 6/10. Loss: 1.0021:  42%|[36m████▏     [0m| 11/26 [00:11<00:13,  1.09it/s]Epoch: 6/10. Loss: 1.0021:  46%|[36m████▌     [0m| 12/26 [00:11<00:13,  1.06it/s]Epoch: 6/10. Loss: 0.9782:  46%|[36m████▌     [0m| 12/26 [00:12<00:13,  1.06it/s]Epoch: 6/10. Loss: 0.9782:  50%|[36m█████     [0m| 13/26 [00:12<00:12,  1.05it/s]Epoch: 6/10. Loss: 0.9796:  50%|[36m█████     [0m| 13/26 [00:13<00:12,  1.05it/s]Epoch: 6/10. Loss: 0.9796:  54%|[36m█████▍    [0m| 14/26 [00:13<00:11,  1.09it/s]Epoch: 6/10. Loss: 0.9936:  54%|[36m█████▍    [0m| 14/26 [00:14<00:11,  1.09it/s]Epoch: 6/10. Loss: 0.9936:  58%|[36m█████▊    [0m| 15/26 [00:14<00:10,  1.05it/s]Epoch: 6/10. Loss: 1.0451:  58%|[36m█████▊    [0m| 15/26 [00:15<00:10,  1.05it/s]Epoch: 6/10. Loss: 1.0451:  62%|[36m██████▏   [0m| 16/26 [00:15<00:09,  1.04it/s]Epoch: 6/10. Loss: 1.0083:  62%|[36m██████▏   [0m| 16/26 [00:16<00:09,  1.04it/s]Epoch: 6/10. Loss: 1.0083:  65%|[36m██████▌   [0m| 17/26 [00:16<00:08,  1.04it/s]Epoch: 6/10. Loss: 1.0007:  65%|[36m██████▌   [0m| 17/26 [00:17<00:08,  1.04it/s]Epoch: 6/10. Loss: 1.0007:  69%|[36m██████▉   [0m| 18/26 [00:17<00:08,  1.02s/it]Epoch: 6/10. Loss: 1.1173:  69%|[36m██████▉   [0m| 18/26 [00:18<00:08,  1.02s/it]Epoch: 6/10. Loss: 1.1173:  73%|[36m███████▎  [0m| 19/26 [00:18<00:06,  1.01it/s]Epoch: 6/10. Loss: 0.9810:  73%|[36m███████▎  [0m| 19/26 [00:19<00:06,  1.01it/s]Epoch: 6/10. Loss: 0.9810:  77%|[36m███████▋  [0m| 20/26 [00:20<00:06,  1.06s/it]Epoch: 6/10. Loss: 1.0234:  77%|[36m███████▋  [0m| 20/26 [00:21<00:06,  1.06s/it]Epoch: 6/10. Loss: 1.0234:  81%|[36m████████  [0m| 21/26 [00:21<00:05,  1.05s/it]Epoch: 6/10. Loss: 0.9328:  81%|[36m████████  [0m| 21/26 [00:21<00:05,  1.05s/it]Epoch: 6/10. Loss: 0.9328:  85%|[36m████████▍ [0m| 22/26 [00:22<00:04,  1.02s/it]Epoch: 6/10. Loss: 0.9933:  85%|[36m████████▍ [0m| 22/26 [00:22<00:04,  1.02s/it]Epoch: 6/10. Loss: 0.9933:  88%|[36m████████▊ [0m| 23/26 [00:22<00:02,  1.03it/s]Epoch: 6/10. Loss: 0.9039:  88%|[36m████████▊ [0m| 23/26 [00:23<00:02,  1.03it/s]Epoch: 6/10. Loss: 0.9039:  92%|[36m█████████▏[0m| 24/26 [00:23<00:01,  1.06it/s]Epoch: 6/10. Loss: 0.9895:  92%|[36m█████████▏[0m| 24/26 [00:24<00:01,  1.06it/s]Epoch: 6/10. Loss: 0.9895:  96%|[36m█████████▌[0m| 25/26 [00:24<00:00,  1.05it/s]Epoch: 6/10. Loss: 1.0464:  96%|[36m█████████▌[0m| 25/26 [00:25<00:00,  1.05it/s]Epoch: 6/10. Loss: 1.0464: 100%|[36m██████████[0m| 26/26 [00:25<00:00,  1.07it/s]Epoch: 6/10. Loss: 1.0464: 100%|[36m██████████[0m| 26/26 [00:25<00:00,  1.02it/s]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:01<00:09,  1.60s/it] 29%|[33m██▊       [0m| 2/7 [00:03<00:07,  1.54s/it] 43%|[33m████▎     [0m| 3/7 [00:03<00:04,  1.09s/it] 57%|[33m█████▋    [0m| 4/7 [00:05<00:03,  1.23s/it] 71%|[33m███████▏  [0m| 5/7 [00:05<00:01,  1.04it/s] 86%|[33m████████▌ [0m| 6/7 [00:06<00:01,  1.03s/it]100%|[33m██████████[0m| 7/7 [00:07<00:00,  1.25it/s]100%|[33m██████████[0m| 7/7 [00:07<00:00,  1.01s/it]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 7/10. Loss: 0.9726:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 7/10. Loss: 0.9726:   4%|[36m▍         [0m| 1/26 [00:00<00:22,  1.13it/s]Epoch: 7/10. Loss: 0.9942:   4%|[36m▍         [0m| 1/26 [00:01<00:22,  1.13it/s]Epoch: 7/10. Loss: 0.9942:   8%|[36m▊         [0m| 2/26 [00:01<00:22,  1.05it/s]Epoch: 7/10. Loss: 1.0237:   8%|[36m▊         [0m| 2/26 [00:03<00:22,  1.05it/s]Epoch: 7/10. Loss: 1.0237:  12%|[36m█▏        [0m| 3/26 [00:03<00:27,  1.20s/it]Epoch: 7/10. Loss: 1.0354:  12%|[36m█▏        [0m| 3/26 [00:04<00:27,  1.20s/it]Epoch: 7/10. Loss: 1.0354:  15%|[36m█▌        [0m| 4/26 [00:04<00:26,  1.20s/it]Epoch: 7/10. Loss: 1.0199:  15%|[36m█▌        [0m| 4/26 [00:06<00:26,  1.20s/it]Epoch: 7/10. Loss: 1.0199:  19%|[36m█▉        [0m| 5/26 [00:06<00:34,  1.62s/it]Epoch: 7/10. Loss: 0.9341:  19%|[36m█▉        [0m| 5/26 [00:07<00:34,  1.62s/it]Epoch: 7/10. Loss: 0.9341:  23%|[36m██▎       [0m| 6/26 [00:07<00:27,  1.38s/it]Epoch: 7/10. Loss: 0.9380:  23%|[36m██▎       [0m| 6/26 [00:08<00:27,  1.38s/it]Epoch: 7/10. Loss: 0.9380:  27%|[36m██▋       [0m| 7/26 [00:08<00:23,  1.23s/it]Epoch: 7/10. Loss: 1.0610:  27%|[36m██▋       [0m| 7/26 [00:09<00:23,  1.23s/it]Epoch: 7/10. Loss: 1.0610:  31%|[36m███       [0m| 8/26 [00:09<00:20,  1.16s/it]Epoch: 7/10. Loss: 1.0211:  31%|[36m███       [0m| 8/26 [00:10<00:20,  1.16s/it]Epoch: 7/10. Loss: 1.0211:  35%|[36m███▍      [0m| 9/26 [00:10<00:19,  1.12s/it]Epoch: 7/10. Loss: 0.9858:  35%|[36m███▍      [0m| 9/26 [00:11<00:19,  1.12s/it]Epoch: 7/10. Loss: 0.9858:  38%|[36m███▊      [0m| 10/26 [00:11<00:17,  1.11s/it]Epoch: 7/10. Loss: 1.0174:  38%|[36m███▊      [0m| 10/26 [00:12<00:17,  1.11s/it]Epoch: 7/10. Loss: 1.0174:  42%|[36m████▏     [0m| 11/26 [00:12<00:16,  1.08s/it]Epoch: 7/10. Loss: 1.0339:  42%|[36m████▏     [0m| 11/26 [00:13<00:16,  1.08s/it]Epoch: 7/10. Loss: 1.0339:  46%|[36m████▌     [0m| 12/26 [00:13<00:14,  1.05s/it]Epoch: 7/10. Loss: 0.9303:  46%|[36m████▌     [0m| 12/26 [00:15<00:14,  1.05s/it]Epoch: 7/10. Loss: 0.9303:  50%|[36m█████     [0m| 13/26 [00:15<00:16,  1.30s/it]Epoch: 7/10. Loss: 0.9673:  50%|[36m█████     [0m| 13/26 [00:16<00:16,  1.30s/it]Epoch: 7/10. Loss: 0.9673:  54%|[36m█████▍    [0m| 14/26 [00:16<00:14,  1.20s/it]Epoch: 7/10. Loss: 0.9728:  54%|[36m█████▍    [0m| 14/26 [00:17<00:14,  1.20s/it]Epoch: 7/10. Loss: 0.9728:  58%|[36m█████▊    [0m| 15/26 [00:17<00:11,  1.09s/it]Epoch: 7/10. Loss: 0.9987:  58%|[36m█████▊    [0m| 15/26 [00:18<00:11,  1.09s/it]Epoch: 7/10. Loss: 0.9987:  62%|[36m██████▏   [0m| 16/26 [00:18<00:10,  1.08s/it]Epoch: 7/10. Loss: 0.9122:  62%|[36m██████▏   [0m| 16/26 [00:19<00:10,  1.08s/it]Epoch: 7/10. Loss: 0.9122:  65%|[36m██████▌   [0m| 17/26 [00:19<00:09,  1.03s/it]Epoch: 7/10. Loss: 0.9433:  65%|[36m██████▌   [0m| 17/26 [00:20<00:09,  1.03s/it]Epoch: 7/10. Loss: 0.9433:  69%|[36m██████▉   [0m| 18/26 [00:20<00:08,  1.02s/it]Epoch: 7/10. Loss: 0.9933:  69%|[36m██████▉   [0m| 18/26 [00:21<00:08,  1.02s/it]Epoch: 7/10. Loss: 0.9933:  73%|[36m███████▎  [0m| 19/26 [00:21<00:07,  1.02s/it]Epoch: 7/10. Loss: 1.0124:  73%|[36m███████▎  [0m| 19/26 [00:22<00:07,  1.02s/it]Epoch: 7/10. Loss: 1.0124:  77%|[36m███████▋  [0m| 20/26 [00:22<00:06,  1.09s/it]Epoch: 7/10. Loss: 1.0708:  77%|[36m███████▋  [0m| 20/26 [00:23<00:06,  1.09s/it]Epoch: 7/10. Loss: 1.0708:  81%|[36m████████  [0m| 21/26 [00:23<00:05,  1.07s/it]Epoch: 7/10. Loss: 0.9513:  81%|[36m████████  [0m| 21/26 [00:24<00:05,  1.07s/it]Epoch: 7/10. Loss: 0.9513:  85%|[36m████████▍ [0m| 22/26 [00:24<00:03,  1.00it/s]Epoch: 7/10. Loss: 1.0137:  85%|[36m████████▍ [0m| 22/26 [00:25<00:03,  1.00it/s]Epoch: 7/10. Loss: 1.0137:  88%|[36m████████▊ [0m| 23/26 [00:25<00:02,  1.05it/s]Epoch: 7/10. Loss: 0.9323:  88%|[36m████████▊ [0m| 23/26 [00:26<00:02,  1.05it/s]Epoch: 7/10. Loss: 0.9323:  92%|[36m█████████▏[0m| 24/26 [00:26<00:01,  1.02it/s]Epoch: 7/10. Loss: 1.0479:  92%|[36m█████████▏[0m| 24/26 [00:27<00:01,  1.02it/s]Epoch: 7/10. Loss: 1.0479:  96%|[36m█████████▌[0m| 25/26 [00:27<00:00,  1.03it/s]Epoch: 7/10. Loss: 1.0631:  96%|[36m█████████▌[0m| 25/26 [00:28<00:00,  1.03it/s]Epoch: 7/10. Loss: 1.0631: 100%|[36m██████████[0m| 26/26 [00:28<00:00,  1.18it/s]Epoch: 7/10. Loss: 1.0631: 100%|[36m██████████[0m| 26/26 [00:28<00:00,  1.08s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:05,  1.09it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:06,  1.28s/it] 43%|[33m████▎     [0m| 3/7 [00:03<00:03,  1.04it/s] 57%|[33m█████▋    [0m| 4/7 [00:04<00:03,  1.14s/it] 71%|[33m███████▏  [0m| 5/7 [00:04<00:01,  1.15it/s] 86%|[33m████████▌ [0m| 6/7 [00:05<00:00,  1.15it/s]100%|[33m██████████[0m| 7/7 [00:06<00:00,  1.47it/s]100%|[33m██████████[0m| 7/7 [00:06<00:00,  1.17it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 8/10. Loss: 0.9360:   0%|[36m          [0m| 0/26 [00:01<?, ?it/s]Epoch: 8/10. Loss: 0.9360:   4%|[36m▍         [0m| 1/26 [00:01<00:26,  1.06s/it]Epoch: 8/10. Loss: 1.0218:   4%|[36m▍         [0m| 1/26 [00:01<00:26,  1.06s/it]Epoch: 8/10. Loss: 1.0218:   8%|[36m▊         [0m| 2/26 [00:01<00:20,  1.16it/s]Epoch: 8/10. Loss: 0.9748:   8%|[36m▊         [0m| 2/26 [00:03<00:20,  1.16it/s]Epoch: 8/10. Loss: 0.9748:  12%|[36m█▏        [0m| 3/26 [00:03<00:27,  1.19s/it]Epoch: 8/10. Loss: 0.9786:  12%|[36m█▏        [0m| 3/26 [00:04<00:27,  1.19s/it]Epoch: 8/10. Loss: 0.9786:  15%|[36m█▌        [0m| 4/26 [00:04<00:23,  1.06s/it]Epoch: 8/10. Loss: 1.0154:  15%|[36m█▌        [0m| 4/26 [00:06<00:23,  1.06s/it]Epoch: 8/10. Loss: 1.0154:  19%|[36m█▉        [0m| 5/26 [00:06<00:27,  1.33s/it]Epoch: 8/10. Loss: 0.9726:  19%|[36m█▉        [0m| 5/26 [00:07<00:27,  1.33s/it]Epoch: 8/10. Loss: 0.9726:  23%|[36m██▎       [0m| 6/26 [00:07<00:27,  1.36s/it]Epoch: 8/10. Loss: 1.0185:  23%|[36m██▎       [0m| 6/26 [00:08<00:27,  1.36s/it]Epoch: 8/10. Loss: 1.0185:  27%|[36m██▋       [0m| 7/26 [00:08<00:22,  1.20s/it]Epoch: 8/10. Loss: 1.0582:  27%|[36m██▋       [0m| 7/26 [00:09<00:22,  1.20s/it]Epoch: 8/10. Loss: 1.0582:  31%|[36m███       [0m| 8/26 [00:09<00:20,  1.12s/it]Epoch: 8/10. Loss: 1.0130:  31%|[36m███       [0m| 8/26 [00:10<00:20,  1.12s/it]Epoch: 8/10. Loss: 1.0130:  35%|[36m███▍      [0m| 9/26 [00:10<00:18,  1.11s/it]Epoch: 8/10. Loss: 1.0382:  35%|[36m███▍      [0m| 9/26 [00:11<00:18,  1.11s/it]Epoch: 8/10. Loss: 1.0382:  38%|[36m███▊      [0m| 10/26 [00:11<00:17,  1.10s/it]Epoch: 8/10. Loss: 0.9895:  38%|[36m███▊      [0m| 10/26 [00:12<00:17,  1.10s/it]Epoch: 8/10. Loss: 0.9895:  42%|[36m████▏     [0m| 11/26 [00:12<00:18,  1.23s/it]Epoch: 8/10. Loss: 1.0199:  42%|[36m████▏     [0m| 11/26 [00:14<00:18,  1.23s/it]Epoch: 8/10. Loss: 1.0199:  46%|[36m████▌     [0m| 12/26 [00:14<00:16,  1.19s/it]Epoch: 8/10. Loss: 0.9329:  46%|[36m████▌     [0m| 12/26 [00:14<00:16,  1.19s/it]Epoch: 8/10. Loss: 0.9329:  50%|[36m█████     [0m| 13/26 [00:14<00:14,  1.09s/it]Epoch: 8/10. Loss: 0.9469:  50%|[36m█████     [0m| 13/26 [00:16<00:14,  1.09s/it]Epoch: 8/10. Loss: 0.9469:  54%|[36m█████▍    [0m| 14/26 [00:16<00:13,  1.09s/it]Epoch: 8/10. Loss: 1.0020:  54%|[36m█████▍    [0m| 14/26 [00:17<00:13,  1.09s/it]Epoch: 8/10. Loss: 1.0020:  58%|[36m█████▊    [0m| 15/26 [00:17<00:11,  1.08s/it]Epoch: 8/10. Loss: 1.0130:  58%|[36m█████▊    [0m| 15/26 [00:17<00:11,  1.08s/it]Epoch: 8/10. Loss: 1.0130:  62%|[36m██████▏   [0m| 16/26 [00:17<00:09,  1.01it/s]Epoch: 8/10. Loss: 1.0471:  62%|[36m██████▏   [0m| 16/26 [00:18<00:09,  1.01it/s]Epoch: 8/10. Loss: 1.0471:  65%|[36m██████▌   [0m| 17/26 [00:18<00:08,  1.03it/s]Epoch: 8/10. Loss: 0.9425:  65%|[36m██████▌   [0m| 17/26 [00:19<00:08,  1.03it/s]Epoch: 8/10. Loss: 0.9425:  69%|[36m██████▉   [0m| 18/26 [00:19<00:07,  1.00it/s]Epoch: 8/10. Loss: 0.9508:  69%|[36m██████▉   [0m| 18/26 [00:20<00:07,  1.00it/s]Epoch: 8/10. Loss: 0.9508:  73%|[36m███████▎  [0m| 19/26 [00:21<00:07,  1.05s/it]Epoch: 8/10. Loss: 0.9756:  73%|[36m███████▎  [0m| 19/26 [00:22<00:07,  1.05s/it]Epoch: 8/10. Loss: 0.9756:  77%|[36m███████▋  [0m| 20/26 [00:23<00:07,  1.33s/it]Epoch: 8/10. Loss: 0.9956:  77%|[36m███████▋  [0m| 20/26 [00:24<00:07,  1.33s/it]Epoch: 8/10. Loss: 0.9956:  81%|[36m████████  [0m| 21/26 [00:24<00:06,  1.28s/it]Epoch: 8/10. Loss: 0.9396:  81%|[36m████████  [0m| 21/26 [00:25<00:06,  1.28s/it]Epoch: 8/10. Loss: 0.9396:  85%|[36m████████▍ [0m| 22/26 [00:25<00:04,  1.22s/it]Epoch: 8/10. Loss: 1.0436:  85%|[36m████████▍ [0m| 22/26 [00:26<00:04,  1.22s/it]Epoch: 8/10. Loss: 1.0436:  88%|[36m████████▊ [0m| 23/26 [00:26<00:03,  1.14s/it]Epoch: 8/10. Loss: 1.0016:  88%|[36m████████▊ [0m| 23/26 [00:27<00:03,  1.14s/it]Epoch: 8/10. Loss: 1.0016:  92%|[36m█████████▏[0m| 24/26 [00:27<00:02,  1.13s/it]Epoch: 8/10. Loss: 0.9600:  92%|[36m█████████▏[0m| 24/26 [00:28<00:02,  1.13s/it]Epoch: 8/10. Loss: 0.9600:  96%|[36m█████████▌[0m| 25/26 [00:28<00:01,  1.11s/it]Epoch: 8/10. Loss: 0.9664:  96%|[36m█████████▌[0m| 25/26 [00:29<00:01,  1.11s/it]Epoch: 8/10. Loss: 0.9664: 100%|[36m██████████[0m| 26/26 [00:29<00:00,  1.21s/it]Epoch: 8/10. Loss: 0.9664: 100%|[36m██████████[0m| 26/26 [00:29<00:00,  1.15s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:01<00:07,  1.24s/it] 29%|[33m██▊       [0m| 2/7 [00:02<00:06,  1.39s/it] 43%|[33m████▎     [0m| 3/7 [00:07<00:10,  2.75s/it] 57%|[33m█████▋    [0m| 4/7 [00:09<00:07,  2.66s/it] 71%|[33m███████▏  [0m| 5/7 [00:10<00:03,  1.85s/it] 86%|[33m████████▌ [0m| 6/7 [00:12<00:02,  2.06s/it]100%|[33m██████████[0m| 7/7 [00:12<00:00,  1.49s/it]100%|[33m██████████[0m| 7/7 [00:12<00:00,  1.83s/it]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 9/10. Loss: 0.9564:   0%|[36m          [0m| 0/26 [00:01<?, ?it/s]Epoch: 9/10. Loss: 0.9564:   4%|[36m▍         [0m| 1/26 [00:01<00:35,  1.43s/it]Epoch: 9/10. Loss: 0.9288:   4%|[36m▍         [0m| 1/26 [00:03<00:35,  1.43s/it]Epoch: 9/10. Loss: 0.9288:   8%|[36m▊         [0m| 2/26 [00:03<00:40,  1.70s/it]Epoch: 9/10. Loss: 1.0479:   8%|[36m▊         [0m| 2/26 [00:04<00:40,  1.70s/it]Epoch: 9/10. Loss: 1.0479:  12%|[36m█▏        [0m| 3/26 [00:04<00:34,  1.52s/it]Epoch: 9/10. Loss: 1.0493:  12%|[36m█▏        [0m| 3/26 [00:05<00:34,  1.52s/it]Epoch: 9/10. Loss: 1.0493:  15%|[36m█▌        [0m| 4/26 [00:05<00:30,  1.38s/it]Epoch: 9/10. Loss: 1.0033:  15%|[36m█▌        [0m| 4/26 [00:06<00:30,  1.38s/it]Epoch: 9/10. Loss: 1.0033:  19%|[36m█▉        [0m| 5/26 [00:06<00:25,  1.20s/it]Epoch: 9/10. Loss: 0.9115:  19%|[36m█▉        [0m| 5/26 [00:07<00:25,  1.20s/it]Epoch: 9/10. Loss: 0.9115:  23%|[36m██▎       [0m| 6/26 [00:07<00:22,  1.12s/it]Epoch: 9/10. Loss: 0.9611:  23%|[36m██▎       [0m| 6/26 [00:08<00:22,  1.12s/it]Epoch: 9/10. Loss: 0.9611:  27%|[36m██▋       [0m| 7/26 [00:08<00:22,  1.18s/it]Epoch: 9/10. Loss: 1.0634:  27%|[36m██▋       [0m| 7/26 [00:09<00:22,  1.18s/it]Epoch: 9/10. Loss: 1.0634:  31%|[36m███       [0m| 8/26 [00:09<00:20,  1.14s/it]Epoch: 9/10. Loss: 0.9783:  31%|[36m███       [0m| 8/26 [00:11<00:20,  1.14s/it]Epoch: 9/10. Loss: 0.9783:  35%|[36m███▍      [0m| 9/26 [00:11<00:19,  1.16s/it]Epoch: 9/10. Loss: 1.0147:  35%|[36m███▍      [0m| 9/26 [00:12<00:19,  1.16s/it]Epoch: 9/10. Loss: 1.0147:  38%|[36m███▊      [0m| 10/26 [00:12<00:17,  1.09s/it]Epoch: 9/10. Loss: 1.0209:  38%|[36m███▊      [0m| 10/26 [00:13<00:17,  1.09s/it]Epoch: 9/10. Loss: 1.0209:  42%|[36m████▏     [0m| 11/26 [00:13<00:15,  1.05s/it]Epoch: 9/10. Loss: 0.9257:  42%|[36m████▏     [0m| 11/26 [00:14<00:15,  1.05s/it]Epoch: 9/10. Loss: 0.9257:  46%|[36m████▌     [0m| 12/26 [00:14<00:14,  1.05s/it]Epoch: 9/10. Loss: 1.0249:  46%|[36m████▌     [0m| 12/26 [00:15<00:14,  1.05s/it]Epoch: 9/10. Loss: 1.0249:  50%|[36m█████     [0m| 13/26 [00:15<00:13,  1.01s/it]Epoch: 9/10. Loss: 1.0217:  50%|[36m█████     [0m| 13/26 [00:17<00:13,  1.01s/it]Epoch: 9/10. Loss: 1.0217:  54%|[36m█████▍    [0m| 14/26 [00:17<00:18,  1.54s/it]Epoch: 9/10. Loss: 0.9922:  54%|[36m█████▍    [0m| 14/26 [00:19<00:18,  1.54s/it]Epoch: 9/10. Loss: 0.9922:  58%|[36m█████▊    [0m| 15/26 [00:19<00:16,  1.54s/it]Epoch: 9/10. Loss: 0.9646:  58%|[36m█████▊    [0m| 15/26 [00:20<00:16,  1.54s/it]Epoch: 9/10. Loss: 0.9646:  62%|[36m██████▏   [0m| 16/26 [00:20<00:13,  1.35s/it]Epoch: 9/10. Loss: 1.0377:  62%|[36m██████▏   [0m| 16/26 [00:22<00:13,  1.35s/it]Epoch: 9/10. Loss: 1.0377:  65%|[36m██████▌   [0m| 17/26 [00:22<00:15,  1.70s/it]Epoch: 9/10. Loss: 0.9895:  65%|[36m██████▌   [0m| 17/26 [00:24<00:15,  1.70s/it]Epoch: 9/10. Loss: 0.9895:  69%|[36m██████▉   [0m| 18/26 [00:24<00:14,  1.76s/it]Epoch: 9/10. Loss: 0.9680:  69%|[36m██████▉   [0m| 18/26 [00:25<00:14,  1.76s/it]Epoch: 9/10. Loss: 0.9680:  73%|[36m███████▎  [0m| 19/26 [00:25<00:10,  1.46s/it]Epoch: 9/10. Loss: 1.0208:  73%|[36m███████▎  [0m| 19/26 [00:28<00:10,  1.46s/it]Epoch: 9/10. Loss: 1.0208:  77%|[36m███████▋  [0m| 20/26 [00:28<00:11,  1.96s/it]Epoch: 9/10. Loss: 0.9516:  77%|[36m███████▋  [0m| 20/26 [00:30<00:11,  1.96s/it]Epoch: 9/10. Loss: 0.9516:  81%|[36m████████  [0m| 21/26 [00:30<00:09,  1.90s/it]Epoch: 9/10. Loss: 0.9666:  81%|[36m████████  [0m| 21/26 [00:31<00:09,  1.90s/it]Epoch: 9/10. Loss: 0.9666:  85%|[36m████████▍ [0m| 22/26 [00:31<00:06,  1.65s/it]Epoch: 9/10. Loss: 1.0148:  85%|[36m████████▍ [0m| 22/26 [00:32<00:06,  1.65s/it]Epoch: 9/10. Loss: 1.0148:  88%|[36m████████▊ [0m| 23/26 [00:32<00:04,  1.62s/it]Epoch: 9/10. Loss: 0.9479:  88%|[36m████████▊ [0m| 23/26 [00:33<00:04,  1.62s/it]Epoch: 9/10. Loss: 0.9479:  92%|[36m█████████▏[0m| 24/26 [00:33<00:02,  1.42s/it]Epoch: 9/10. Loss: 0.9469:  92%|[36m█████████▏[0m| 24/26 [00:34<00:02,  1.42s/it]Epoch: 9/10. Loss: 0.9469:  96%|[36m█████████▌[0m| 25/26 [00:34<00:01,  1.29s/it]Epoch: 9/10. Loss: 0.9522:  96%|[36m█████████▌[0m| 25/26 [00:35<00:01,  1.29s/it]Epoch: 9/10. Loss: 0.9522: 100%|[36m██████████[0m| 26/26 [00:35<00:00,  1.20s/it]Epoch: 9/10. Loss: 0.9522: 100%|[36m██████████[0m| 26/26 [00:35<00:00,  1.38s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:01<00:09,  1.56s/it] 29%|[33m██▊       [0m| 2/7 [00:03<00:08,  1.64s/it] 43%|[33m████▎     [0m| 3/7 [00:03<00:04,  1.17s/it] 57%|[33m█████▋    [0m| 4/7 [00:05<00:03,  1.29s/it] 71%|[33m███████▏  [0m| 5/7 [00:05<00:01,  1.01it/s] 86%|[33m████████▌ [0m| 6/7 [00:07<00:01,  1.08s/it]100%|[33m██████████[0m| 7/7 [00:07<00:00,  1.21it/s]100%|[33m██████████[0m| 7/7 [00:07<00:00,  1.05s/it]
/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/models/inception.py:43: FutureWarning: The default weight initialization of inception_v3 will be changed in future releases of torchvision. If you wish to keep the old behavior (which leads to long initialization times due to scipy/scipy#11299), please set init_weights=True.
  warnings.warn(
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 0/10. Loss: 1.1597:   0%|[36m          [0m| 0/26 [00:01<?, ?it/s]Epoch: 0/10. Loss: 1.1597:   4%|[36m▍         [0m| 1/26 [00:02<00:58,  2.33s/it]Epoch: 0/10. Loss: 5.5934:   4%|[36m▍         [0m| 1/26 [00:05<00:58,  2.33s/it]Epoch: 0/10. Loss: 5.5934:   8%|[36m▊         [0m| 2/26 [00:05<01:09,  2.90s/it]Epoch: 0/10. Loss: 1.5904:   8%|[36m▊         [0m| 2/26 [00:06<01:09,  2.90s/it]Epoch: 0/10. Loss: 1.5904:  12%|[36m█▏        [0m| 3/26 [00:06<00:49,  2.14s/it]Epoch: 0/10. Loss: 2.9027:  12%|[36m█▏        [0m| 3/26 [00:09<00:49,  2.14s/it]Epoch: 0/10. Loss: 2.9027:  15%|[36m█▌        [0m| 4/26 [00:09<00:49,  2.24s/it]Epoch: 0/10. Loss: 1.0871:  15%|[36m█▌        [0m| 4/26 [00:10<00:49,  2.24s/it]Epoch: 0/10. Loss: 1.0871:  19%|[36m█▉        [0m| 5/26 [00:10<00:36,  1.73s/it]Epoch: 0/10. Loss: 1.7336:  19%|[36m█▉        [0m| 5/26 [00:11<00:36,  1.73s/it]Epoch: 0/10. Loss: 1.7336:  23%|[36m██▎       [0m| 6/26 [00:11<00:31,  1.58s/it]Epoch: 0/10. Loss: 1.7829:  23%|[36m██▎       [0m| 6/26 [00:12<00:31,  1.58s/it]Epoch: 0/10. Loss: 1.7829:  27%|[36m██▋       [0m| 7/26 [00:12<00:28,  1.50s/it]Epoch: 0/10. Loss: 1.5072:  27%|[36m██▋       [0m| 7/26 [00:15<00:28,  1.50s/it]Epoch: 0/10. Loss: 1.5072:  31%|[36m███       [0m| 8/26 [00:15<00:32,  1.81s/it]Epoch: 0/10. Loss: 1.0565:  31%|[36m███       [0m| 8/26 [00:17<00:32,  1.81s/it]Epoch: 0/10. Loss: 1.0565:  35%|[36m███▍      [0m| 9/26 [00:17<00:30,  1.82s/it]Epoch: 0/10. Loss: 1.1256:  35%|[36m███▍      [0m| 9/26 [00:18<00:30,  1.82s/it]Epoch: 0/10. Loss: 1.1256:  38%|[36m███▊      [0m| 10/26 [00:18<00:27,  1.74s/it]Epoch: 0/10. Loss: 1.5565:  38%|[36m███▊      [0m| 10/26 [00:19<00:27,  1.74s/it]Epoch: 0/10. Loss: 1.5565:  42%|[36m████▏     [0m| 11/26 [00:19<00:23,  1.54s/it]Epoch: 0/10. Loss: 1.2392:  42%|[36m████▏     [0m| 11/26 [00:21<00:23,  1.54s/it]Epoch: 0/10. Loss: 1.2392:  46%|[36m████▌     [0m| 12/26 [00:21<00:22,  1.59s/it]Epoch: 0/10. Loss: 1.2025:  46%|[36m████▌     [0m| 12/26 [00:22<00:22,  1.59s/it]Epoch: 0/10. Loss: 1.2025:  50%|[36m█████     [0m| 13/26 [00:22<00:17,  1.37s/it]Epoch: 0/10. Loss: 1.4337:  50%|[36m█████     [0m| 13/26 [00:24<00:17,  1.37s/it]Epoch: 0/10. Loss: 1.4337:  54%|[36m█████▍    [0m| 14/26 [00:24<00:18,  1.53s/it]Epoch: 0/10. Loss: 1.0860:  54%|[36m█████▍    [0m| 14/26 [00:24<00:18,  1.53s/it]Epoch: 0/10. Loss: 1.0860:  58%|[36m█████▊    [0m| 15/26 [00:24<00:14,  1.30s/it]Epoch: 0/10. Loss: 1.2353:  58%|[36m█████▊    [0m| 15/26 [00:25<00:14,  1.30s/it]Epoch: 0/10. Loss: 1.2353:  62%|[36m██████▏   [0m| 16/26 [00:25<00:12,  1.21s/it]Epoch: 0/10. Loss: 1.2195:  62%|[36m██████▏   [0m| 16/26 [00:26<00:12,  1.21s/it]Epoch: 0/10. Loss: 1.2195:  65%|[36m██████▌   [0m| 17/26 [00:26<00:10,  1.12s/it]Epoch: 0/10. Loss: 1.1304:  65%|[36m██████▌   [0m| 17/26 [00:27<00:10,  1.12s/it]Epoch: 0/10. Loss: 1.1304:  69%|[36m██████▉   [0m| 18/26 [00:27<00:08,  1.04s/it]Epoch: 0/10. Loss: 0.9997:  69%|[36m██████▉   [0m| 18/26 [00:29<00:08,  1.04s/it]Epoch: 0/10. Loss: 0.9997:  73%|[36m███████▎  [0m| 19/26 [00:29<00:07,  1.14s/it]Epoch: 0/10. Loss: 1.0481:  73%|[36m███████▎  [0m| 19/26 [00:30<00:07,  1.14s/it]Epoch: 0/10. Loss: 1.0481:  77%|[36m███████▋  [0m| 20/26 [00:30<00:06,  1.11s/it]Epoch: 0/10. Loss: 1.4471:  77%|[36m███████▋  [0m| 20/26 [00:31<00:06,  1.11s/it]Epoch: 0/10. Loss: 1.4471:  81%|[36m████████  [0m| 21/26 [00:31<00:05,  1.08s/it]Epoch: 0/10. Loss: 1.0113:  81%|[36m████████  [0m| 21/26 [00:32<00:05,  1.08s/it]Epoch: 0/10. Loss: 1.0113:  85%|[36m████████▍ [0m| 22/26 [00:32<00:04,  1.08s/it]Epoch: 0/10. Loss: 0.8931:  85%|[36m████████▍ [0m| 22/26 [00:33<00:04,  1.08s/it]Epoch: 0/10. Loss: 0.8931:  88%|[36m████████▊ [0m| 23/26 [00:33<00:03,  1.03s/it]Epoch: 0/10. Loss: 1.4469:  88%|[36m████████▊ [0m| 23/26 [00:33<00:03,  1.03s/it]Epoch: 0/10. Loss: 1.4469:  92%|[36m█████████▏[0m| 24/26 [00:33<00:01,  1.02it/s]Epoch: 0/10. Loss: 1.3054:  92%|[36m█████████▏[0m| 24/26 [00:34<00:01,  1.02it/s]Epoch: 0/10. Loss: 1.3054:  96%|[36m█████████▌[0m| 25/26 [00:34<00:00,  1.04it/s]Epoch: 0/10. Loss: 1.2072:  96%|[36m█████████▌[0m| 25/26 [00:35<00:00,  1.04it/s]Epoch: 0/10. Loss: 1.2072: 100%|[36m██████████[0m| 26/26 [00:35<00:00,  1.02it/s]Epoch: 0/10. Loss: 1.2072: 100%|[36m██████████[0m| 26/26 [00:35<00:00,  1.38s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:01<00:06,  1.11s/it] 29%|[33m██▊       [0m| 2/7 [00:02<00:06,  1.31s/it] 43%|[33m████▎     [0m| 3/7 [00:03<00:03,  1.04it/s] 57%|[33m█████▋    [0m| 4/7 [00:04<00:03,  1.09s/it] 71%|[33m███████▏  [0m| 5/7 [00:04<00:01,  1.21it/s] 86%|[33m████████▌ [0m| 6/7 [00:05<00:00,  1.21it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.48it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.18it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 1/10. Loss: 1.1930:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 1/10. Loss: 1.1930:   4%|[36m▍         [0m| 1/26 [00:00<00:22,  1.12it/s]Epoch: 1/10. Loss: 1.0037:   4%|[36m▍         [0m| 1/26 [00:01<00:22,  1.12it/s]Epoch: 1/10. Loss: 1.0037:   8%|[36m▊         [0m| 2/26 [00:02<00:24,  1.03s/it]Epoch: 1/10. Loss: 1.3196:   8%|[36m▊         [0m| 2/26 [00:03<00:24,  1.03s/it]Epoch: 1/10. Loss: 1.3196:  12%|[36m█▏        [0m| 3/26 [00:03<00:23,  1.02s/it]Epoch: 1/10. Loss: 1.6461:  12%|[36m█▏        [0m| 3/26 [00:03<00:23,  1.02s/it]Epoch: 1/10. Loss: 1.6461:  15%|[36m█▌        [0m| 4/26 [00:03<00:21,  1.02it/s]Epoch: 1/10. Loss: 1.3211:  15%|[36m█▌        [0m| 4/26 [00:04<00:21,  1.02it/s]Epoch: 1/10. Loss: 1.3211:  19%|[36m█▉        [0m| 5/26 [00:04<00:19,  1.07it/s]Epoch: 1/10. Loss: 1.2546:  19%|[36m█▉        [0m| 5/26 [00:06<00:19,  1.07it/s]Epoch: 1/10. Loss: 1.2546:  23%|[36m██▎       [0m| 6/26 [00:06<00:21,  1.07s/it]Epoch: 1/10. Loss: 1.5032:  23%|[36m██▎       [0m| 6/26 [00:07<00:21,  1.07s/it]Epoch: 1/10. Loss: 1.5032:  27%|[36m██▋       [0m| 7/26 [00:07<00:21,  1.13s/it]Epoch: 1/10. Loss: 1.1407:  27%|[36m██▋       [0m| 7/26 [00:08<00:21,  1.13s/it]Epoch: 1/10. Loss: 1.1407:  31%|[36m███       [0m| 8/26 [00:08<00:20,  1.12s/it]Epoch: 1/10. Loss: 1.0130:  31%|[36m███       [0m| 8/26 [00:09<00:20,  1.12s/it]Epoch: 1/10. Loss: 1.0130:  35%|[36m███▍      [0m| 9/26 [00:09<00:16,  1.01it/s]Epoch: 1/10. Loss: 1.1942:  35%|[36m███▍      [0m| 9/26 [00:10<00:16,  1.01it/s]Epoch: 1/10. Loss: 1.1942:  38%|[36m███▊      [0m| 10/26 [00:10<00:15,  1.06it/s]Epoch: 1/10. Loss: 1.1715:  38%|[36m███▊      [0m| 10/26 [00:11<00:15,  1.06it/s]Epoch: 1/10. Loss: 1.1715:  42%|[36m████▏     [0m| 11/26 [00:11<00:14,  1.02it/s]Epoch: 1/10. Loss: 1.0319:  42%|[36m████▏     [0m| 11/26 [00:12<00:14,  1.02it/s]Epoch: 1/10. Loss: 1.0319:  46%|[36m████▌     [0m| 12/26 [00:12<00:13,  1.03it/s]Epoch: 1/10. Loss: 1.1126:  46%|[36m████▌     [0m| 12/26 [00:13<00:13,  1.03it/s]Epoch: 1/10. Loss: 1.1126:  50%|[36m█████     [0m| 13/26 [00:13<00:12,  1.02it/s]Epoch: 1/10. Loss: 1.3844:  50%|[36m█████     [0m| 13/26 [00:13<00:12,  1.02it/s]Epoch: 1/10. Loss: 1.3844:  54%|[36m█████▍    [0m| 14/26 [00:13<00:11,  1.06it/s]Epoch: 1/10. Loss: 1.3102:  54%|[36m█████▍    [0m| 14/26 [00:15<00:11,  1.06it/s]Epoch: 1/10. Loss: 1.3102:  58%|[36m█████▊    [0m| 15/26 [00:15<00:13,  1.22s/it]Epoch: 1/10. Loss: 1.1129:  58%|[36m█████▊    [0m| 15/26 [00:16<00:13,  1.22s/it]Epoch: 1/10. Loss: 1.1129:  62%|[36m██████▏   [0m| 16/26 [00:16<00:11,  1.15s/it]Epoch: 1/10. Loss: 1.5546:  62%|[36m██████▏   [0m| 16/26 [00:17<00:11,  1.15s/it]Epoch: 1/10. Loss: 1.5546:  65%|[36m██████▌   [0m| 17/26 [00:17<00:09,  1.10s/it]Epoch: 1/10. Loss: 1.0946:  65%|[36m██████▌   [0m| 17/26 [00:18<00:09,  1.10s/it]Epoch: 1/10. Loss: 1.0946:  69%|[36m██████▉   [0m| 18/26 [00:18<00:08,  1.04s/it]Epoch: 1/10. Loss: 1.0300:  69%|[36m██████▉   [0m| 18/26 [00:19<00:08,  1.04s/it]Epoch: 1/10. Loss: 1.0300:  73%|[36m███████▎  [0m| 19/26 [00:19<00:07,  1.02s/it]Epoch: 1/10. Loss: 0.9832:  73%|[36m███████▎  [0m| 19/26 [00:20<00:07,  1.02s/it]Epoch: 1/10. Loss: 0.9832:  77%|[36m███████▋  [0m| 20/26 [00:20<00:05,  1.02it/s]Epoch: 1/10. Loss: 1.0705:  77%|[36m███████▋  [0m| 20/26 [00:21<00:05,  1.02it/s]Epoch: 1/10. Loss: 1.0705:  81%|[36m████████  [0m| 21/26 [00:21<00:04,  1.01it/s]Epoch: 1/10. Loss: 1.1200:  81%|[36m████████  [0m| 21/26 [00:22<00:04,  1.01it/s]Epoch: 1/10. Loss: 1.1200:  85%|[36m████████▍ [0m| 22/26 [00:22<00:03,  1.04it/s]Epoch: 1/10. Loss: 1.1284:  85%|[36m████████▍ [0m| 22/26 [00:23<00:03,  1.04it/s]Epoch: 1/10. Loss: 1.1284:  88%|[36m████████▊ [0m| 23/26 [00:23<00:02,  1.05it/s]Epoch: 1/10. Loss: 1.1779:  88%|[36m████████▊ [0m| 23/26 [00:24<00:02,  1.05it/s]Epoch: 1/10. Loss: 1.1779:  92%|[36m█████████▏[0m| 24/26 [00:24<00:01,  1.06it/s]Epoch: 1/10. Loss: 0.9961:  92%|[36m█████████▏[0m| 24/26 [00:25<00:01,  1.06it/s]Epoch: 1/10. Loss: 0.9961:  96%|[36m█████████▌[0m| 25/26 [00:25<00:00,  1.01it/s]Epoch: 1/10. Loss: 1.2052:  96%|[36m█████████▌[0m| 25/26 [00:26<00:00,  1.01it/s]Epoch: 1/10. Loss: 1.2052: 100%|[36m██████████[0m| 26/26 [00:26<00:00,  1.09it/s]Epoch: 1/10. Loss: 1.2052: 100%|[36m██████████[0m| 26/26 [00:26<00:00,  1.00s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:01<00:07,  1.19s/it] 29%|[33m██▊       [0m| 2/7 [00:03<00:08,  1.63s/it] 43%|[33m████▎     [0m| 3/7 [00:03<00:04,  1.15s/it] 57%|[33m█████▋    [0m| 4/7 [00:05<00:03,  1.22s/it] 71%|[33m███████▏  [0m| 5/7 [00:05<00:01,  1.09it/s] 86%|[33m████████▌ [0m| 6/7 [00:06<00:00,  1.09it/s]100%|[33m██████████[0m| 7/7 [00:06<00:00,  1.39it/s]100%|[33m██████████[0m| 7/7 [00:06<00:00,  1.05it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 2/10. Loss: 1.0606:   0%|[36m          [0m| 0/26 [00:01<?, ?it/s]Epoch: 2/10. Loss: 1.0606:   4%|[36m▍         [0m| 1/26 [00:01<00:25,  1.03s/it]Epoch: 2/10. Loss: 0.9994:   4%|[36m▍         [0m| 1/26 [00:01<00:25,  1.03s/it]Epoch: 2/10. Loss: 0.9994:   8%|[36m▊         [0m| 2/26 [00:01<00:21,  1.13it/s]Epoch: 2/10. Loss: 1.1009:   8%|[36m▊         [0m| 2/26 [00:02<00:21,  1.13it/s]Epoch: 2/10. Loss: 1.1009:  12%|[36m█▏        [0m| 3/26 [00:02<00:22,  1.03it/s]Epoch: 2/10. Loss: 1.0068:  12%|[36m█▏        [0m| 3/26 [00:03<00:22,  1.03it/s]Epoch: 2/10. Loss: 1.0068:  15%|[36m█▌        [0m| 4/26 [00:03<00:21,  1.04it/s]Epoch: 2/10. Loss: 1.1745:  15%|[36m█▌        [0m| 4/26 [00:04<00:21,  1.04it/s]Epoch: 2/10. Loss: 1.1745:  19%|[36m█▉        [0m| 5/26 [00:04<00:20,  1.04it/s]Epoch: 2/10. Loss: 1.0948:  19%|[36m█▉        [0m| 5/26 [00:05<00:20,  1.04it/s]Epoch: 2/10. Loss: 1.0948:  23%|[36m██▎       [0m| 6/26 [00:05<00:18,  1.09it/s]Epoch: 2/10. Loss: 1.0684:  23%|[36m██▎       [0m| 6/26 [00:06<00:18,  1.09it/s]Epoch: 2/10. Loss: 1.0684:  27%|[36m██▋       [0m| 7/26 [00:06<00:19,  1.02s/it]Epoch: 2/10. Loss: 1.1360:  27%|[36m██▋       [0m| 7/26 [00:07<00:19,  1.02s/it]Epoch: 2/10. Loss: 1.1360:  31%|[36m███       [0m| 8/26 [00:07<00:17,  1.02it/s]Epoch: 2/10. Loss: 0.9589:  31%|[36m███       [0m| 8/26 [00:08<00:17,  1.02it/s]Epoch: 2/10. Loss: 0.9589:  35%|[36m███▍      [0m| 9/26 [00:08<00:15,  1.08it/s]Epoch: 2/10. Loss: 1.0084:  35%|[36m███▍      [0m| 9/26 [00:09<00:15,  1.08it/s]Epoch: 2/10. Loss: 1.0084:  38%|[36m███▊      [0m| 10/26 [00:09<00:15,  1.06it/s]Epoch: 2/10. Loss: 0.9840:  38%|[36m███▊      [0m| 10/26 [00:10<00:15,  1.06it/s]Epoch: 2/10. Loss: 0.9840:  42%|[36m████▏     [0m| 11/26 [00:10<00:14,  1.07it/s]Epoch: 2/10. Loss: 0.9640:  42%|[36m████▏     [0m| 11/26 [00:11<00:14,  1.07it/s]Epoch: 2/10. Loss: 0.9640:  46%|[36m████▌     [0m| 12/26 [00:11<00:13,  1.07it/s]Epoch: 2/10. Loss: 1.1114:  46%|[36m████▌     [0m| 12/26 [00:12<00:13,  1.07it/s]Epoch: 2/10. Loss: 1.1114:  50%|[36m█████     [0m| 13/26 [00:12<00:12,  1.07it/s]Epoch: 2/10. Loss: 1.0533:  50%|[36m█████     [0m| 13/26 [00:13<00:12,  1.07it/s]Epoch: 2/10. Loss: 1.0533:  54%|[36m█████▍    [0m| 14/26 [00:13<00:11,  1.08it/s]Epoch: 2/10. Loss: 1.1929:  54%|[36m█████▍    [0m| 14/26 [00:13<00:11,  1.08it/s]Epoch: 2/10. Loss: 1.1929:  58%|[36m█████▊    [0m| 15/26 [00:13<00:09,  1.15it/s]Epoch: 2/10. Loss: 1.0480:  58%|[36m█████▊    [0m| 15/26 [00:14<00:09,  1.15it/s]Epoch: 2/10. Loss: 1.0480:  62%|[36m██████▏   [0m| 16/26 [00:14<00:08,  1.11it/s]Epoch: 2/10. Loss: 0.9935:  62%|[36m██████▏   [0m| 16/26 [00:15<00:08,  1.11it/s]Epoch: 2/10. Loss: 0.9935:  65%|[36m██████▌   [0m| 17/26 [00:15<00:08,  1.09it/s]Epoch: 2/10. Loss: 1.0255:  65%|[36m██████▌   [0m| 17/26 [00:16<00:08,  1.09it/s]Epoch: 2/10. Loss: 1.0255:  69%|[36m██████▉   [0m| 18/26 [00:16<00:07,  1.11it/s]Epoch: 2/10. Loss: 1.0403:  69%|[36m██████▉   [0m| 18/26 [00:17<00:07,  1.11it/s]Epoch: 2/10. Loss: 1.0403:  73%|[36m███████▎  [0m| 19/26 [00:17<00:06,  1.06it/s]Epoch: 2/10. Loss: 1.0912:  73%|[36m███████▎  [0m| 19/26 [00:18<00:06,  1.06it/s]Epoch: 2/10. Loss: 1.0912:  77%|[36m███████▋  [0m| 20/26 [00:18<00:05,  1.09it/s]Epoch: 2/10. Loss: 1.1137:  77%|[36m███████▋  [0m| 20/26 [00:19<00:05,  1.09it/s]Epoch: 2/10. Loss: 1.1137:  81%|[36m████████  [0m| 21/26 [00:19<00:04,  1.03it/s]Epoch: 2/10. Loss: 1.2106:  81%|[36m████████  [0m| 21/26 [00:20<00:04,  1.03it/s]Epoch: 2/10. Loss: 1.2106:  85%|[36m████████▍ [0m| 22/26 [00:20<00:03,  1.01it/s]Epoch: 2/10. Loss: 1.0831:  85%|[36m████████▍ [0m| 22/26 [00:22<00:03,  1.01it/s]Epoch: 2/10. Loss: 1.0831:  88%|[36m████████▊ [0m| 23/26 [00:22<00:03,  1.14s/it]Epoch: 2/10. Loss: 1.1494:  88%|[36m████████▊ [0m| 23/26 [00:23<00:03,  1.14s/it]Epoch: 2/10. Loss: 1.1494:  92%|[36m█████████▏[0m| 24/26 [00:23<00:02,  1.19s/it]Epoch: 2/10. Loss: 1.2055:  92%|[36m█████████▏[0m| 24/26 [00:24<00:02,  1.19s/it]Epoch: 2/10. Loss: 1.2055:  96%|[36m█████████▌[0m| 25/26 [00:24<00:01,  1.12s/it]Epoch: 2/10. Loss: 1.0317:  96%|[36m█████████▌[0m| 25/26 [00:25<00:01,  1.12s/it]Epoch: 2/10. Loss: 1.0317: 100%|[36m██████████[0m| 26/26 [00:25<00:00,  1.02it/s]Epoch: 2/10. Loss: 1.0317: 100%|[36m██████████[0m| 26/26 [00:25<00:00,  1.03it/s]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:05,  1.16it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:06,  1.29s/it] 43%|[33m████▎     [0m| 3/7 [00:03<00:03,  1.05it/s] 57%|[33m█████▋    [0m| 4/7 [00:04<00:03,  1.20s/it] 71%|[33m███████▏  [0m| 5/7 [00:04<00:01,  1.10it/s] 86%|[33m████████▌ [0m| 6/7 [00:06<00:01,  1.20s/it]100%|[33m██████████[0m| 7/7 [00:07<00:00,  1.11it/s]100%|[33m██████████[0m| 7/7 [00:07<00:00,  1.00s/it]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 3/10. Loss: 1.0807:   0%|[36m          [0m| 0/26 [00:03<?, ?it/s]Epoch: 3/10. Loss: 1.0807:   4%|[36m▍         [0m| 1/26 [00:03<01:22,  3.31s/it]Epoch: 3/10. Loss: 1.0510:   4%|[36m▍         [0m| 1/26 [00:04<01:22,  3.31s/it]Epoch: 3/10. Loss: 1.0510:   8%|[36m▊         [0m| 2/26 [00:04<00:44,  1.86s/it]Epoch: 3/10. Loss: 1.1253:   8%|[36m▊         [0m| 2/26 [00:05<00:44,  1.86s/it]Epoch: 3/10. Loss: 1.1253:  12%|[36m█▏        [0m| 3/26 [00:05<00:36,  1.57s/it]Epoch: 3/10. Loss: 1.0152:  12%|[36m█▏        [0m| 3/26 [00:06<00:36,  1.57s/it]Epoch: 3/10. Loss: 1.0152:  15%|[36m█▌        [0m| 4/26 [00:06<00:28,  1.31s/it]Epoch: 3/10. Loss: 0.9485:  15%|[36m█▌        [0m| 4/26 [00:07<00:28,  1.31s/it]Epoch: 3/10. Loss: 0.9485:  19%|[36m█▉        [0m| 5/26 [00:07<00:25,  1.20s/it]Epoch: 3/10. Loss: 1.0437:  19%|[36m█▉        [0m| 5/26 [00:08<00:25,  1.20s/it]Epoch: 3/10. Loss: 1.0437:  23%|[36m██▎       [0m| 6/26 [00:08<00:22,  1.14s/it]Epoch: 3/10. Loss: 1.0916:  23%|[36m██▎       [0m| 6/26 [00:09<00:22,  1.14s/it]Epoch: 3/10. Loss: 1.0916:  27%|[36m██▋       [0m| 7/26 [00:09<00:21,  1.14s/it]Epoch: 3/10. Loss: 1.0746:  27%|[36m██▋       [0m| 7/26 [00:10<00:21,  1.14s/it]Epoch: 3/10. Loss: 1.0746:  31%|[36m███       [0m| 8/26 [00:10<00:19,  1.07s/it]Epoch: 3/10. Loss: 0.9885:  31%|[36m███       [0m| 8/26 [00:11<00:19,  1.07s/it]Epoch: 3/10. Loss: 0.9885:  35%|[36m███▍      [0m| 9/26 [00:11<00:17,  1.05s/it]Epoch: 3/10. Loss: 1.0349:  35%|[36m███▍      [0m| 9/26 [00:12<00:17,  1.05s/it]Epoch: 3/10. Loss: 1.0349:  38%|[36m███▊      [0m| 10/26 [00:12<00:17,  1.07s/it]Epoch: 3/10. Loss: 1.0985:  38%|[36m███▊      [0m| 10/26 [00:13<00:17,  1.07s/it]Epoch: 3/10. Loss: 1.0985:  42%|[36m████▏     [0m| 11/26 [00:13<00:15,  1.05s/it]Epoch: 3/10. Loss: 1.1017:  42%|[36m████▏     [0m| 11/26 [00:14<00:15,  1.05s/it]Epoch: 3/10. Loss: 1.1017:  46%|[36m████▌     [0m| 12/26 [00:14<00:15,  1.11s/it]Epoch: 3/10. Loss: 1.1174:  46%|[36m████▌     [0m| 12/26 [00:15<00:15,  1.11s/it]Epoch: 3/10. Loss: 1.1174:  50%|[36m█████     [0m| 13/26 [00:15<00:13,  1.05s/it]Epoch: 3/10. Loss: 1.0619:  50%|[36m█████     [0m| 13/26 [00:16<00:13,  1.05s/it]Epoch: 3/10. Loss: 1.0619:  54%|[36m█████▍    [0m| 14/26 [00:16<00:12,  1.02s/it]Epoch: 3/10. Loss: 0.9785:  54%|[36m█████▍    [0m| 14/26 [00:17<00:12,  1.02s/it]Epoch: 3/10. Loss: 0.9785:  58%|[36m█████▊    [0m| 15/26 [00:17<00:10,  1.00it/s]Epoch: 3/10. Loss: 1.2870:  58%|[36m█████▊    [0m| 15/26 [00:18<00:10,  1.00it/s]Epoch: 3/10. Loss: 1.2870:  62%|[36m██████▏   [0m| 16/26 [00:18<00:10,  1.06s/it]Epoch: 3/10. Loss: 1.0876:  62%|[36m██████▏   [0m| 16/26 [00:19<00:10,  1.06s/it]Epoch: 3/10. Loss: 1.0876:  65%|[36m██████▌   [0m| 17/26 [00:19<00:09,  1.01s/it]Epoch: 3/10. Loss: 1.1461:  65%|[36m██████▌   [0m| 17/26 [00:20<00:09,  1.01s/it]Epoch: 3/10. Loss: 1.1461:  69%|[36m██████▉   [0m| 18/26 [00:20<00:08,  1.03s/it]Epoch: 3/10. Loss: 1.2084:  69%|[36m██████▉   [0m| 18/26 [00:21<00:08,  1.03s/it]Epoch: 3/10. Loss: 1.2084:  73%|[36m███████▎  [0m| 19/26 [00:21<00:07,  1.03s/it]Epoch: 3/10. Loss: 1.0113:  73%|[36m███████▎  [0m| 19/26 [00:22<00:07,  1.03s/it]Epoch: 3/10. Loss: 1.0113:  77%|[36m███████▋  [0m| 20/26 [00:22<00:06,  1.05s/it]Epoch: 3/10. Loss: 1.0129:  77%|[36m███████▋  [0m| 20/26 [00:23<00:06,  1.05s/it]Epoch: 3/10. Loss: 1.0129:  81%|[36m████████  [0m| 21/26 [00:23<00:04,  1.01it/s]Epoch: 3/10. Loss: 0.9980:  81%|[36m████████  [0m| 21/26 [00:24<00:04,  1.01it/s]Epoch: 3/10. Loss: 0.9980:  85%|[36m████████▍ [0m| 22/26 [00:24<00:04,  1.05s/it]Epoch: 3/10. Loss: 1.0270:  85%|[36m████████▍ [0m| 22/26 [00:25<00:04,  1.05s/it]Epoch: 3/10. Loss: 1.0270:  88%|[36m████████▊ [0m| 23/26 [00:25<00:03,  1.04s/it]Epoch: 3/10. Loss: 0.9967:  88%|[36m████████▊ [0m| 23/26 [00:26<00:03,  1.04s/it]Epoch: 3/10. Loss: 0.9967:  92%|[36m█████████▏[0m| 24/26 [00:26<00:01,  1.03it/s]Epoch: 3/10. Loss: 0.9993:  92%|[36m█████████▏[0m| 24/26 [00:27<00:01,  1.03it/s]Epoch: 3/10. Loss: 0.9993:  96%|[36m█████████▌[0m| 25/26 [00:27<00:00,  1.06it/s]Epoch: 3/10. Loss: 1.1547:  96%|[36m█████████▌[0m| 25/26 [00:28<00:00,  1.06it/s]Epoch: 3/10. Loss: 1.1547: 100%|[36m██████████[0m| 26/26 [00:28<00:00,  1.18it/s]Epoch: 3/10. Loss: 1.1547: 100%|[36m██████████[0m| 26/26 [00:28<00:00,  1.09s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:05,  1.10it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:06,  1.26s/it] 43%|[33m████▎     [0m| 3/7 [00:02<00:03,  1.06it/s] 57%|[33m█████▋    [0m| 4/7 [00:04<00:03,  1.13s/it] 71%|[33m███████▏  [0m| 5/7 [00:04<00:01,  1.14it/s] 86%|[33m████████▌ [0m| 6/7 [00:06<00:01,  1.02s/it]100%|[33m██████████[0m| 7/7 [00:06<00:00,  1.27it/s]100%|[33m██████████[0m| 7/7 [00:06<00:00,  1.09it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 4/10. Loss: 0.9885:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 4/10. Loss: 0.9885:   4%|[36m▍         [0m| 1/26 [00:00<00:24,  1.00it/s]Epoch: 4/10. Loss: 0.9914:   4%|[36m▍         [0m| 1/26 [00:02<00:24,  1.00it/s]Epoch: 4/10. Loss: 0.9914:   8%|[36m▊         [0m| 2/26 [00:02<00:28,  1.17s/it]Epoch: 4/10. Loss: 1.1491:   8%|[36m▊         [0m| 2/26 [00:04<00:28,  1.17s/it]Epoch: 4/10. Loss: 1.1491:  12%|[36m█▏        [0m| 3/26 [00:04<00:40,  1.75s/it]Epoch: 4/10. Loss: 0.9597:  12%|[36m█▏        [0m| 3/26 [00:07<00:40,  1.75s/it]Epoch: 4/10. Loss: 0.9597:  15%|[36m█▌        [0m| 4/26 [00:07<00:43,  1.99s/it]Epoch: 4/10. Loss: 1.0037:  15%|[36m█▌        [0m| 4/26 [00:08<00:43,  1.99s/it]Epoch: 4/10. Loss: 1.0037:  19%|[36m█▉        [0m| 5/26 [00:08<00:34,  1.65s/it]Epoch: 4/10. Loss: 0.9662:  19%|[36m█▉        [0m| 5/26 [00:09<00:34,  1.65s/it]Epoch: 4/10. Loss: 0.9662:  23%|[36m██▎       [0m| 6/26 [00:09<00:27,  1.39s/it]Epoch: 4/10. Loss: 1.0456:  23%|[36m██▎       [0m| 6/26 [00:09<00:27,  1.39s/it]Epoch: 4/10. Loss: 1.0456:  27%|[36m██▋       [0m| 7/26 [00:09<00:23,  1.23s/it]Epoch: 4/10. Loss: 0.9228:  27%|[36m██▋       [0m| 7/26 [00:11<00:23,  1.23s/it]Epoch: 4/10. Loss: 0.9228:  31%|[36m███       [0m| 8/26 [00:11<00:21,  1.19s/it]Epoch: 4/10. Loss: 0.9681:  31%|[36m███       [0m| 8/26 [00:12<00:21,  1.19s/it]Epoch: 4/10. Loss: 0.9681:  35%|[36m███▍      [0m| 9/26 [00:12<00:19,  1.14s/it]Epoch: 4/10. Loss: 1.1300:  35%|[36m███▍      [0m| 9/26 [00:12<00:19,  1.14s/it]Epoch: 4/10. Loss: 1.1300:  38%|[36m███▊      [0m| 10/26 [00:12<00:16,  1.05s/it]Epoch: 4/10. Loss: 0.9892:  38%|[36m███▊      [0m| 10/26 [00:13<00:16,  1.05s/it]Epoch: 4/10. Loss: 0.9892:  42%|[36m████▏     [0m| 11/26 [00:13<00:14,  1.00it/s]Epoch: 4/10. Loss: 0.9669:  42%|[36m████▏     [0m| 11/26 [00:14<00:14,  1.00it/s]Epoch: 4/10. Loss: 0.9669:  46%|[36m████▌     [0m| 12/26 [00:14<00:13,  1.02it/s]Epoch: 4/10. Loss: 1.0124:  46%|[36m████▌     [0m| 12/26 [00:15<00:13,  1.02it/s]Epoch: 4/10. Loss: 1.0124:  50%|[36m█████     [0m| 13/26 [00:15<00:12,  1.05it/s]Epoch: 4/10. Loss: 1.0436:  50%|[36m█████     [0m| 13/26 [00:16<00:12,  1.05it/s]Epoch: 4/10. Loss: 1.0436:  54%|[36m█████▍    [0m| 14/26 [00:16<00:10,  1.11it/s]Epoch: 4/10. Loss: 0.9802:  54%|[36m█████▍    [0m| 14/26 [00:17<00:10,  1.11it/s]Epoch: 4/10. Loss: 0.9802:  58%|[36m█████▊    [0m| 15/26 [00:17<00:11,  1.01s/it]Epoch: 4/10. Loss: 0.9302:  58%|[36m█████▊    [0m| 15/26 [00:18<00:11,  1.01s/it]Epoch: 4/10. Loss: 0.9302:  62%|[36m██████▏   [0m| 16/26 [00:18<00:09,  1.01it/s]Epoch: 4/10. Loss: 1.0519:  62%|[36m██████▏   [0m| 16/26 [00:19<00:09,  1.01it/s]Epoch: 4/10. Loss: 1.0519:  65%|[36m██████▌   [0m| 17/26 [00:19<00:08,  1.03it/s]Epoch: 4/10. Loss: 0.9478:  65%|[36m██████▌   [0m| 17/26 [00:20<00:08,  1.03it/s]Epoch: 4/10. Loss: 0.9478:  69%|[36m██████▉   [0m| 18/26 [00:20<00:07,  1.09it/s]Epoch: 4/10. Loss: 0.9604:  69%|[36m██████▉   [0m| 18/26 [00:21<00:07,  1.09it/s]Epoch: 4/10. Loss: 0.9604:  73%|[36m███████▎  [0m| 19/26 [00:21<00:06,  1.15it/s]Epoch: 4/10. Loss: 1.0263:  73%|[36m███████▎  [0m| 19/26 [00:22<00:06,  1.15it/s]Epoch: 4/10. Loss: 1.0263:  77%|[36m███████▋  [0m| 20/26 [00:22<00:05,  1.08it/s]Epoch: 4/10. Loss: 1.0656:  77%|[36m███████▋  [0m| 20/26 [00:22<00:05,  1.08it/s]Epoch: 4/10. Loss: 1.0656:  81%|[36m████████  [0m| 21/26 [00:22<00:04,  1.10it/s]Epoch: 4/10. Loss: 1.0285:  81%|[36m████████  [0m| 21/26 [00:23<00:04,  1.10it/s]Epoch: 4/10. Loss: 1.0285:  85%|[36m████████▍ [0m| 22/26 [00:23<00:03,  1.12it/s]Epoch: 4/10. Loss: 1.0032:  85%|[36m████████▍ [0m| 22/26 [00:25<00:03,  1.12it/s]Epoch: 4/10. Loss: 1.0032:  88%|[36m████████▊ [0m| 23/26 [00:25<00:03,  1.00s/it]Epoch: 4/10. Loss: 1.1054:  88%|[36m████████▊ [0m| 23/26 [00:26<00:03,  1.00s/it]Epoch: 4/10. Loss: 1.1054:  92%|[36m█████████▏[0m| 24/26 [00:26<00:02,  1.02s/it]Epoch: 4/10. Loss: 0.9487:  92%|[36m█████████▏[0m| 24/26 [00:27<00:02,  1.02s/it]Epoch: 4/10. Loss: 0.9487:  96%|[36m█████████▌[0m| 25/26 [00:27<00:00,  1.02it/s]Epoch: 4/10. Loss: 0.9195:  96%|[36m█████████▌[0m| 25/26 [00:27<00:00,  1.02it/s]Epoch: 4/10. Loss: 0.9195: 100%|[36m██████████[0m| 26/26 [00:27<00:00,  1.14it/s]Epoch: 4/10. Loss: 0.9195: 100%|[36m██████████[0m| 26/26 [00:27<00:00,  1.07s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:05,  1.17it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:06,  1.23s/it] 43%|[33m████▎     [0m| 3/7 [00:02<00:03,  1.08it/s] 57%|[33m█████▋    [0m| 4/7 [00:04<00:03,  1.12s/it] 71%|[33m███████▏  [0m| 5/7 [00:04<00:01,  1.16it/s] 86%|[33m████████▌ [0m| 6/7 [00:05<00:00,  1.13it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.44it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.17it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 5/10. Loss: 0.9175:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 5/10. Loss: 0.9175:   4%|[36m▍         [0m| 1/26 [00:00<00:23,  1.06it/s]Epoch: 5/10. Loss: 1.0225:   4%|[36m▍         [0m| 1/26 [00:01<00:23,  1.06it/s]Epoch: 5/10. Loss: 1.0225:   8%|[36m▊         [0m| 2/26 [00:01<00:22,  1.08it/s]Epoch: 5/10. Loss: 0.9357:   8%|[36m▊         [0m| 2/26 [00:02<00:22,  1.08it/s]Epoch: 5/10. Loss: 0.9357:  12%|[36m█▏        [0m| 3/26 [00:02<00:20,  1.10it/s]Epoch: 5/10. Loss: 1.1287:  12%|[36m█▏        [0m| 3/26 [00:03<00:20,  1.10it/s]Epoch: 5/10. Loss: 1.1287:  15%|[36m█▌        [0m| 4/26 [00:03<00:20,  1.07it/s]Epoch: 5/10. Loss: 1.0691:  15%|[36m█▌        [0m| 4/26 [00:04<00:20,  1.07it/s]Epoch: 5/10. Loss: 1.0691:  19%|[36m█▉        [0m| 5/26 [00:04<00:20,  1.02it/s]Epoch: 5/10. Loss: 0.9128:  19%|[36m█▉        [0m| 5/26 [00:05<00:20,  1.02it/s]Epoch: 5/10. Loss: 0.9128:  23%|[36m██▎       [0m| 6/26 [00:05<00:18,  1.09it/s]Epoch: 5/10. Loss: 1.0275:  23%|[36m██▎       [0m| 6/26 [00:06<00:18,  1.09it/s]Epoch: 5/10. Loss: 1.0275:  27%|[36m██▋       [0m| 7/26 [00:06<00:18,  1.04it/s]Epoch: 5/10. Loss: 0.9717:  27%|[36m██▋       [0m| 7/26 [00:08<00:18,  1.04it/s]Epoch: 5/10. Loss: 0.9717:  31%|[36m███       [0m| 8/26 [00:08<00:20,  1.15s/it]Epoch: 5/10. Loss: 1.0219:  31%|[36m███       [0m| 8/26 [00:10<00:20,  1.15s/it]Epoch: 5/10. Loss: 1.0219:  35%|[36m███▍      [0m| 9/26 [00:10<00:23,  1.40s/it]Epoch: 5/10. Loss: 0.9543:  35%|[36m███▍      [0m| 9/26 [00:12<00:23,  1.40s/it]Epoch: 5/10. Loss: 0.9543:  38%|[36m███▊      [0m| 10/26 [00:12<00:25,  1.59s/it]Epoch: 5/10. Loss: 0.9544:  38%|[36m███▊      [0m| 10/26 [00:15<00:25,  1.59s/it]Epoch: 5/10. Loss: 0.9544:  42%|[36m████▏     [0m| 11/26 [00:15<00:32,  2.17s/it]Epoch: 5/10. Loss: 0.9910:  42%|[36m████▏     [0m| 11/26 [00:16<00:32,  2.17s/it]Epoch: 5/10. Loss: 0.9910:  46%|[36m████▌     [0m| 12/26 [00:16<00:26,  1.86s/it]Epoch: 5/10. Loss: 1.1668:  46%|[36m████▌     [0m| 12/26 [00:17<00:26,  1.86s/it]Epoch: 5/10. Loss: 1.1668:  50%|[36m█████     [0m| 13/26 [00:17<00:20,  1.55s/it]Epoch: 5/10. Loss: 0.9142:  50%|[36m█████     [0m| 13/26 [00:18<00:20,  1.55s/it]Epoch: 5/10. Loss: 0.9142:  54%|[36m█████▍    [0m| 14/26 [00:18<00:16,  1.33s/it]Epoch: 5/10. Loss: 1.0499:  54%|[36m█████▍    [0m| 14/26 [00:20<00:16,  1.33s/it]Epoch: 5/10. Loss: 1.0499:  58%|[36m█████▊    [0m| 15/26 [00:20<00:17,  1.57s/it]Epoch: 5/10. Loss: 1.1563:  58%|[36m█████▊    [0m| 15/26 [00:21<00:17,  1.57s/it]Epoch: 5/10. Loss: 1.1563:  62%|[36m██████▏   [0m| 16/26 [00:21<00:13,  1.36s/it]Epoch: 5/10. Loss: 1.0218:  62%|[36m██████▏   [0m| 16/26 [00:23<00:13,  1.36s/it]Epoch: 5/10. Loss: 1.0218:  65%|[36m██████▌   [0m| 17/26 [00:23<00:13,  1.53s/it]Epoch: 5/10. Loss: 1.0464:  65%|[36m██████▌   [0m| 17/26 [00:24<00:13,  1.53s/it]Epoch: 5/10. Loss: 1.0464:  69%|[36m██████▉   [0m| 18/26 [00:24<00:11,  1.38s/it]Epoch: 5/10. Loss: 1.1389:  69%|[36m██████▉   [0m| 18/26 [00:25<00:11,  1.38s/it]Epoch: 5/10. Loss: 1.1389:  73%|[36m███████▎  [0m| 19/26 [00:25<00:08,  1.25s/it]Epoch: 5/10. Loss: 1.0953:  73%|[36m███████▎  [0m| 19/26 [00:26<00:08,  1.25s/it]Epoch: 5/10. Loss: 1.0953:  77%|[36m███████▋  [0m| 20/26 [00:26<00:06,  1.17s/it]Epoch: 5/10. Loss: 0.9910:  77%|[36m███████▋  [0m| 20/26 [00:27<00:06,  1.17s/it]Epoch: 5/10. Loss: 0.9910:  81%|[36m████████  [0m| 21/26 [00:27<00:05,  1.12s/it]Epoch: 5/10. Loss: 0.9868:  81%|[36m████████  [0m| 21/26 [00:29<00:05,  1.12s/it]Epoch: 5/10. Loss: 0.9868:  85%|[36m████████▍ [0m| 22/26 [00:29<00:05,  1.34s/it]Epoch: 5/10. Loss: 0.9917:  85%|[36m████████▍ [0m| 22/26 [00:30<00:05,  1.34s/it]Epoch: 5/10. Loss: 0.9917:  88%|[36m████████▊ [0m| 23/26 [00:30<00:03,  1.31s/it]Epoch: 5/10. Loss: 1.1749:  88%|[36m████████▊ [0m| 23/26 [00:31<00:03,  1.31s/it]Epoch: 5/10. Loss: 1.1749:  92%|[36m█████████▏[0m| 24/26 [00:31<00:02,  1.22s/it]Epoch: 5/10. Loss: 1.1994:  92%|[36m█████████▏[0m| 24/26 [00:32<00:02,  1.22s/it]Epoch: 5/10. Loss: 1.1994:  96%|[36m█████████▌[0m| 25/26 [00:32<00:01,  1.11s/it]Epoch: 5/10. Loss: 1.3859:  96%|[36m█████████▌[0m| 25/26 [00:33<00:01,  1.11s/it]Epoch: 5/10. Loss: 1.3859: 100%|[36m██████████[0m| 26/26 [00:33<00:00,  1.10s/it]Epoch: 5/10. Loss: 1.3859: 100%|[36m██████████[0m| 26/26 [00:33<00:00,  1.28s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:01<00:06,  1.12s/it] 29%|[33m██▊       [0m| 2/7 [00:02<00:07,  1.44s/it] 43%|[33m████▎     [0m| 3/7 [00:03<00:04,  1.03s/it] 57%|[33m█████▋    [0m| 4/7 [00:04<00:03,  1.16s/it] 71%|[33m███████▏  [0m| 5/7 [00:05<00:01,  1.15it/s] 86%|[33m████████▌ [0m| 6/7 [00:05<00:00,  1.17it/s]100%|[33m██████████[0m| 7/7 [00:06<00:00,  1.51it/s]100%|[33m██████████[0m| 7/7 [00:06<00:00,  1.14it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 6/10. Loss: 0.9765:   0%|[36m          [0m| 0/26 [00:01<?, ?it/s]Epoch: 6/10. Loss: 0.9765:   4%|[36m▍         [0m| 1/26 [00:01<00:44,  1.78s/it]Epoch: 6/10. Loss: 1.0574:   4%|[36m▍         [0m| 1/26 [00:02<00:44,  1.78s/it]Epoch: 6/10. Loss: 1.0574:   8%|[36m▊         [0m| 2/26 [00:02<00:28,  1.18s/it]Epoch: 6/10. Loss: 0.9691:   8%|[36m▊         [0m| 2/26 [00:03<00:28,  1.18s/it]Epoch: 6/10. Loss: 0.9691:  12%|[36m█▏        [0m| 3/26 [00:03<00:26,  1.14s/it]Epoch: 6/10. Loss: 1.0044:  12%|[36m█▏        [0m| 3/26 [00:04<00:26,  1.14s/it]Epoch: 6/10. Loss: 1.0044:  15%|[36m█▌        [0m| 4/26 [00:04<00:26,  1.21s/it]Epoch: 6/10. Loss: 0.9532:  15%|[36m█▌        [0m| 4/26 [00:05<00:26,  1.21s/it]Epoch: 6/10. Loss: 0.9532:  19%|[36m█▉        [0m| 5/26 [00:05<00:23,  1.10s/it]Epoch: 6/10. Loss: 0.9270:  19%|[36m█▉        [0m| 5/26 [00:06<00:23,  1.10s/it]Epoch: 6/10. Loss: 0.9270:  23%|[36m██▎       [0m| 6/26 [00:06<00:21,  1.06s/it]Epoch: 6/10. Loss: 1.1931:  23%|[36m██▎       [0m| 6/26 [00:07<00:21,  1.06s/it]Epoch: 6/10. Loss: 1.1931:  27%|[36m██▋       [0m| 7/26 [00:07<00:20,  1.06s/it]Epoch: 6/10. Loss: 1.2792:  27%|[36m██▋       [0m| 7/26 [00:09<00:20,  1.06s/it]Epoch: 6/10. Loss: 1.2792:  31%|[36m███       [0m| 8/26 [00:09<00:22,  1.26s/it]Epoch: 6/10. Loss: 1.2111:  31%|[36m███       [0m| 8/26 [00:10<00:22,  1.26s/it]Epoch: 6/10. Loss: 1.2111:  35%|[36m███▍      [0m| 9/26 [00:10<00:20,  1.22s/it]Epoch: 6/10. Loss: 1.0089:  35%|[36m███▍      [0m| 9/26 [00:11<00:20,  1.22s/it]Epoch: 6/10. Loss: 1.0089:  38%|[36m███▊      [0m| 10/26 [00:11<00:18,  1.16s/it]Epoch: 6/10. Loss: 1.2137:  38%|[36m███▊      [0m| 10/26 [00:12<00:18,  1.16s/it]Epoch: 6/10. Loss: 1.2137:  42%|[36m████▏     [0m| 11/26 [00:12<00:16,  1.10s/it]Epoch: 6/10. Loss: 1.0160:  42%|[36m████▏     [0m| 11/26 [00:13<00:16,  1.10s/it]Epoch: 6/10. Loss: 1.0160:  46%|[36m████▌     [0m| 12/26 [00:13<00:14,  1.06s/it]Epoch: 6/10. Loss: 1.0107:  46%|[36m████▌     [0m| 12/26 [00:14<00:14,  1.06s/it]Epoch: 6/10. Loss: 1.0107:  50%|[36m█████     [0m| 13/26 [00:14<00:13,  1.07s/it]Epoch: 6/10. Loss: 1.0446:  50%|[36m█████     [0m| 13/26 [00:15<00:13,  1.07s/it]Epoch: 6/10. Loss: 1.0446:  54%|[36m█████▍    [0m| 14/26 [00:15<00:12,  1.04s/it]Epoch: 6/10. Loss: 1.0098:  54%|[36m█████▍    [0m| 14/26 [00:16<00:12,  1.04s/it]Epoch: 6/10. Loss: 1.0098:  58%|[36m█████▊    [0m| 15/26 [00:16<00:11,  1.04s/it]Epoch: 6/10. Loss: 1.0193:  58%|[36m█████▊    [0m| 15/26 [00:17<00:11,  1.04s/it]Epoch: 6/10. Loss: 1.0193:  62%|[36m██████▏   [0m| 16/26 [00:17<00:10,  1.02s/it]Epoch: 6/10. Loss: 1.0453:  62%|[36m██████▏   [0m| 16/26 [00:18<00:10,  1.02s/it]Epoch: 6/10. Loss: 1.0453:  65%|[36m██████▌   [0m| 17/26 [00:18<00:09,  1.05s/it]Epoch: 6/10. Loss: 1.5512:  65%|[36m██████▌   [0m| 17/26 [00:19<00:09,  1.05s/it]Epoch: 6/10. Loss: 1.5512:  69%|[36m██████▉   [0m| 18/26 [00:19<00:08,  1.04s/it]Epoch: 6/10. Loss: 1.0977:  69%|[36m██████▉   [0m| 18/26 [00:20<00:08,  1.04s/it]Epoch: 6/10. Loss: 1.0977:  73%|[36m███████▎  [0m| 19/26 [00:20<00:06,  1.01it/s]Epoch: 6/10. Loss: 1.1143:  73%|[36m███████▎  [0m| 19/26 [00:21<00:06,  1.01it/s]Epoch: 6/10. Loss: 1.1143:  77%|[36m███████▋  [0m| 20/26 [00:21<00:05,  1.01it/s]Epoch: 6/10. Loss: 1.0620:  77%|[36m███████▋  [0m| 20/26 [00:22<00:05,  1.01it/s]Epoch: 6/10. Loss: 1.0620:  81%|[36m████████  [0m| 21/26 [00:22<00:04,  1.03it/s]Epoch: 6/10. Loss: 1.0941:  81%|[36m████████  [0m| 21/26 [00:23<00:04,  1.03it/s]Epoch: 6/10. Loss: 1.0941:  85%|[36m████████▍ [0m| 22/26 [00:23<00:03,  1.03it/s]Epoch: 6/10. Loss: 1.3397:  85%|[36m████████▍ [0m| 22/26 [00:24<00:03,  1.03it/s]Epoch: 6/10. Loss: 1.3397:  88%|[36m████████▊ [0m| 23/26 [00:24<00:02,  1.03it/s]Epoch: 6/10. Loss: 1.3349:  88%|[36m████████▊ [0m| 23/26 [00:25<00:02,  1.03it/s]Epoch: 6/10. Loss: 1.3349:  92%|[36m█████████▏[0m| 24/26 [00:25<00:02,  1.01s/it]Epoch: 6/10. Loss: 1.5422:  92%|[36m█████████▏[0m| 24/26 [00:26<00:02,  1.01s/it]Epoch: 6/10. Loss: 1.5422:  96%|[36m█████████▌[0m| 25/26 [00:26<00:00,  1.02it/s]Epoch: 6/10. Loss: 1.0011:  96%|[36m█████████▌[0m| 25/26 [00:27<00:00,  1.02it/s]Epoch: 6/10. Loss: 1.0011: 100%|[36m██████████[0m| 26/26 [00:27<00:00,  1.12it/s]Epoch: 6/10. Loss: 1.0011: 100%|[36m██████████[0m| 26/26 [00:27<00:00,  1.05s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:05,  1.13it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:06,  1.22s/it] 43%|[33m████▎     [0m| 3/7 [00:02<00:03,  1.09it/s] 57%|[33m█████▋    [0m| 4/7 [00:04<00:03,  1.09s/it] 71%|[33m███████▏  [0m| 5/7 [00:04<00:01,  1.19it/s] 86%|[33m████████▌ [0m| 6/7 [00:05<00:00,  1.18it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.51it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.21it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 7/10. Loss: 1.0212:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 7/10. Loss: 1.0212:   4%|[36m▍         [0m| 1/26 [00:00<00:21,  1.14it/s]Epoch: 7/10. Loss: 1.1484:   4%|[36m▍         [0m| 1/26 [00:01<00:21,  1.14it/s]Epoch: 7/10. Loss: 1.1484:   8%|[36m▊         [0m| 2/26 [00:01<00:22,  1.05it/s]Epoch: 7/10. Loss: 1.0441:   8%|[36m▊         [0m| 2/26 [00:02<00:22,  1.05it/s]Epoch: 7/10. Loss: 1.0441:  12%|[36m█▏        [0m| 3/26 [00:02<00:19,  1.16it/s]Epoch: 7/10. Loss: 1.2255:  12%|[36m█▏        [0m| 3/26 [00:03<00:19,  1.16it/s]Epoch: 7/10. Loss: 1.2255:  15%|[36m█▌        [0m| 4/26 [00:03<00:20,  1.05it/s]Epoch: 7/10. Loss: 1.1831:  15%|[36m█▌        [0m| 4/26 [00:04<00:20,  1.05it/s]Epoch: 7/10. Loss: 1.1831:  19%|[36m█▉        [0m| 5/26 [00:04<00:18,  1.11it/s]Epoch: 7/10. Loss: 0.9918:  19%|[36m█▉        [0m| 5/26 [00:05<00:18,  1.11it/s]Epoch: 7/10. Loss: 0.9918:  23%|[36m██▎       [0m| 6/26 [00:05<00:18,  1.06it/s]Epoch: 7/10. Loss: 1.1738:  23%|[36m██▎       [0m| 6/26 [00:06<00:18,  1.06it/s]Epoch: 7/10. Loss: 1.1738:  27%|[36m██▋       [0m| 7/26 [00:06<00:18,  1.03it/s]Epoch: 7/10. Loss: 1.0952:  27%|[36m██▋       [0m| 7/26 [00:07<00:18,  1.03it/s]Epoch: 7/10. Loss: 1.0952:  31%|[36m███       [0m| 8/26 [00:07<00:17,  1.01it/s]Epoch: 7/10. Loss: 0.9827:  31%|[36m███       [0m| 8/26 [00:08<00:17,  1.01it/s]Epoch: 7/10. Loss: 0.9827:  35%|[36m███▍      [0m| 9/26 [00:08<00:16,  1.05it/s]Epoch: 7/10. Loss: 1.0703:  35%|[36m███▍      [0m| 9/26 [00:09<00:16,  1.05it/s]Epoch: 7/10. Loss: 1.0703:  38%|[36m███▊      [0m| 10/26 [00:09<00:15,  1.04it/s]Epoch: 7/10. Loss: 1.0707:  38%|[36m███▊      [0m| 10/26 [00:10<00:15,  1.04it/s]Epoch: 7/10. Loss: 1.0707:  42%|[36m████▏     [0m| 11/26 [00:10<00:13,  1.09it/s]Epoch: 7/10. Loss: 0.9875:  42%|[36m████▏     [0m| 11/26 [00:11<00:13,  1.09it/s]Epoch: 7/10. Loss: 0.9875:  46%|[36m████▌     [0m| 12/26 [00:11<00:12,  1.12it/s]Epoch: 7/10. Loss: 1.2719:  46%|[36m████▌     [0m| 12/26 [00:12<00:12,  1.12it/s]Epoch: 7/10. Loss: 1.2719:  50%|[36m█████     [0m| 13/26 [00:12<00:12,  1.08it/s]Epoch: 7/10. Loss: 1.5067:  50%|[36m█████     [0m| 13/26 [00:13<00:12,  1.08it/s]Epoch: 7/10. Loss: 1.5067:  54%|[36m█████▍    [0m| 14/26 [00:13<00:11,  1.01it/s]Epoch: 7/10. Loss: 1.1686:  54%|[36m█████▍    [0m| 14/26 [00:14<00:11,  1.01it/s]Epoch: 7/10. Loss: 1.1686:  58%|[36m█████▊    [0m| 15/26 [00:14<00:10,  1.03it/s]Epoch: 7/10. Loss: 1.0062:  58%|[36m█████▊    [0m| 15/26 [00:15<00:10,  1.03it/s]Epoch: 7/10. Loss: 1.0062:  62%|[36m██████▏   [0m| 16/26 [00:15<00:09,  1.05it/s]Epoch: 7/10. Loss: 1.1646:  62%|[36m██████▏   [0m| 16/26 [00:16<00:09,  1.05it/s]Epoch: 7/10. Loss: 1.1646:  65%|[36m██████▌   [0m| 17/26 [00:16<00:09,  1.08s/it]Epoch: 7/10. Loss: 0.9711:  65%|[36m██████▌   [0m| 17/26 [00:17<00:09,  1.08s/it]Epoch: 7/10. Loss: 0.9711:  69%|[36m██████▉   [0m| 18/26 [00:17<00:08,  1.04s/it]Epoch: 7/10. Loss: 1.0381:  69%|[36m██████▉   [0m| 18/26 [00:20<00:08,  1.04s/it]Epoch: 7/10. Loss: 1.0381:  73%|[36m███████▎  [0m| 19/26 [00:20<00:11,  1.65s/it]Epoch: 7/10. Loss: 1.0515:  73%|[36m███████▎  [0m| 19/26 [00:21<00:11,  1.65s/it]Epoch: 7/10. Loss: 1.0515:  77%|[36m███████▋  [0m| 20/26 [00:21<00:09,  1.51s/it]Epoch: 7/10. Loss: 1.0049:  77%|[36m███████▋  [0m| 20/26 [00:23<00:09,  1.51s/it]Epoch: 7/10. Loss: 1.0049:  81%|[36m████████  [0m| 21/26 [00:23<00:07,  1.52s/it]Epoch: 7/10. Loss: 0.9994:  81%|[36m████████  [0m| 21/26 [00:24<00:07,  1.52s/it]Epoch: 7/10. Loss: 0.9994:  85%|[36m████████▍ [0m| 22/26 [00:24<00:05,  1.38s/it]Epoch: 7/10. Loss: 1.0164:  85%|[36m████████▍ [0m| 22/26 [00:25<00:05,  1.38s/it]Epoch: 7/10. Loss: 1.0164:  88%|[36m████████▊ [0m| 23/26 [00:25<00:03,  1.28s/it]Epoch: 7/10. Loss: 0.9692:  88%|[36m████████▊ [0m| 23/26 [00:25<00:03,  1.28s/it]Epoch: 7/10. Loss: 0.9692:  92%|[36m█████████▏[0m| 24/26 [00:26<00:02,  1.10s/it]Epoch: 7/10. Loss: 0.9331:  92%|[36m█████████▏[0m| 24/26 [00:27<00:02,  1.10s/it]Epoch: 7/10. Loss: 0.9331:  96%|[36m█████████▌[0m| 25/26 [00:27<00:01,  1.11s/it]Epoch: 7/10. Loss: 1.2582:  96%|[36m█████████▌[0m| 25/26 [00:27<00:01,  1.11s/it]Epoch: 7/10. Loss: 1.2582: 100%|[36m██████████[0m| 26/26 [00:27<00:00,  1.06it/s]Epoch: 7/10. Loss: 1.2582: 100%|[36m██████████[0m| 26/26 [00:27<00:00,  1.07s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:05,  1.12it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:06,  1.28s/it] 43%|[33m████▎     [0m| 3/7 [00:03<00:03,  1.01it/s] 57%|[33m█████▋    [0m| 4/7 [00:04<00:03,  1.15s/it] 71%|[33m███████▏  [0m| 5/7 [00:04<00:01,  1.14it/s] 86%|[33m████████▌ [0m| 6/7 [00:05<00:00,  1.14it/s]100%|[33m██████████[0m| 7/7 [00:06<00:00,  1.46it/s]100%|[33m██████████[0m| 7/7 [00:06<00:00,  1.16it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 8/10. Loss: 1.0641:   0%|[36m          [0m| 0/26 [00:02<?, ?it/s]Epoch: 8/10. Loss: 1.0641:   4%|[36m▍         [0m| 1/26 [00:02<00:53,  2.15s/it]Epoch: 8/10. Loss: 1.0639:   4%|[36m▍         [0m| 1/26 [00:03<00:53,  2.15s/it]Epoch: 8/10. Loss: 1.0639:   8%|[36m▊         [0m| 2/26 [00:03<00:33,  1.41s/it]Epoch: 8/10. Loss: 1.0475:   8%|[36m▊         [0m| 2/26 [00:04<00:33,  1.41s/it]Epoch: 8/10. Loss: 1.0475:  12%|[36m█▏        [0m| 3/26 [00:04<00:29,  1.30s/it]Epoch: 8/10. Loss: 1.0761:  12%|[36m█▏        [0m| 3/26 [00:05<00:29,  1.30s/it]Epoch: 8/10. Loss: 1.0761:  15%|[36m█▌        [0m| 4/26 [00:05<00:27,  1.26s/it]Epoch: 8/10. Loss: 1.0080:  15%|[36m█▌        [0m| 4/26 [00:06<00:27,  1.26s/it]Epoch: 8/10. Loss: 1.0080:  19%|[36m█▉        [0m| 5/26 [00:06<00:22,  1.09s/it]Epoch: 8/10. Loss: 0.9905:  19%|[36m█▉        [0m| 5/26 [00:07<00:22,  1.09s/it]Epoch: 8/10. Loss: 0.9905:  23%|[36m██▎       [0m| 6/26 [00:07<00:20,  1.04s/it]Epoch: 8/10. Loss: 0.9953:  23%|[36m██▎       [0m| 6/26 [00:08<00:20,  1.04s/it]Epoch: 8/10. Loss: 0.9953:  27%|[36m██▋       [0m| 7/26 [00:08<00:20,  1.08s/it]Epoch: 8/10. Loss: 1.0766:  27%|[36m██▋       [0m| 7/26 [00:09<00:20,  1.08s/it]Epoch: 8/10. Loss: 1.0766:  31%|[36m███       [0m| 8/26 [00:09<00:22,  1.22s/it]Epoch: 8/10. Loss: 1.0289:  31%|[36m███       [0m| 8/26 [00:10<00:22,  1.22s/it]Epoch: 8/10. Loss: 1.0289:  35%|[36m███▍      [0m| 9/26 [00:10<00:19,  1.14s/it]Epoch: 8/10. Loss: 1.1632:  35%|[36m███▍      [0m| 9/26 [00:11<00:19,  1.14s/it]Epoch: 8/10. Loss: 1.1632:  38%|[36m███▊      [0m| 10/26 [00:11<00:18,  1.15s/it]Epoch: 8/10. Loss: 1.0615:  38%|[36m███▊      [0m| 10/26 [00:12<00:18,  1.15s/it]Epoch: 8/10. Loss: 1.0615:  42%|[36m████▏     [0m| 11/26 [00:13<00:16,  1.12s/it]Epoch: 8/10. Loss: 1.1738:  42%|[36m████▏     [0m| 11/26 [00:13<00:16,  1.12s/it]Epoch: 8/10. Loss: 1.1738:  46%|[36m████▌     [0m| 12/26 [00:13<00:14,  1.06s/it]Epoch: 8/10. Loss: 1.1863:  46%|[36m████▌     [0m| 12/26 [00:14<00:14,  1.06s/it]Epoch: 8/10. Loss: 1.1863:  50%|[36m█████     [0m| 13/26 [00:14<00:13,  1.02s/it]Epoch: 8/10. Loss: 1.1093:  50%|[36m█████     [0m| 13/26 [00:15<00:13,  1.02s/it]Epoch: 8/10. Loss: 1.1093:  54%|[36m█████▍    [0m| 14/26 [00:15<00:12,  1.01s/it]Epoch: 8/10. Loss: 1.0717:  54%|[36m█████▍    [0m| 14/26 [00:16<00:12,  1.01s/it]Epoch: 8/10. Loss: 1.0717:  58%|[36m█████▊    [0m| 15/26 [00:16<00:10,  1.05it/s]Epoch: 8/10. Loss: 0.9475:  58%|[36m█████▊    [0m| 15/26 [00:17<00:10,  1.05it/s]Epoch: 8/10. Loss: 0.9475:  62%|[36m██████▏   [0m| 16/26 [00:17<00:09,  1.03it/s]Epoch: 8/10. Loss: 1.1239:  62%|[36m██████▏   [0m| 16/26 [00:18<00:09,  1.03it/s]Epoch: 8/10. Loss: 1.1239:  65%|[36m██████▌   [0m| 17/26 [00:18<00:08,  1.05it/s]Epoch: 8/10. Loss: 1.0711:  65%|[36m██████▌   [0m| 17/26 [00:19<00:08,  1.05it/s]Epoch: 8/10. Loss: 1.0711:  69%|[36m██████▉   [0m| 18/26 [00:19<00:07,  1.04it/s]Epoch: 8/10. Loss: 0.9625:  69%|[36m██████▉   [0m| 18/26 [00:20<00:07,  1.04it/s]Epoch: 8/10. Loss: 0.9625:  73%|[36m███████▎  [0m| 19/26 [00:20<00:07,  1.02s/it]Epoch: 8/10. Loss: 0.9883:  73%|[36m███████▎  [0m| 19/26 [00:21<00:07,  1.02s/it]Epoch: 8/10. Loss: 0.9883:  77%|[36m███████▋  [0m| 20/26 [00:21<00:05,  1.01it/s]Epoch: 8/10. Loss: 1.0434:  77%|[36m███████▋  [0m| 20/26 [00:22<00:05,  1.01it/s]Epoch: 8/10. Loss: 1.0434:  81%|[36m████████  [0m| 21/26 [00:22<00:04,  1.05it/s]Epoch: 8/10. Loss: 1.0094:  81%|[36m████████  [0m| 21/26 [00:23<00:04,  1.05it/s]Epoch: 8/10. Loss: 1.0094:  85%|[36m████████▍ [0m| 22/26 [00:23<00:03,  1.07it/s]Epoch: 8/10. Loss: 1.1011:  85%|[36m████████▍ [0m| 22/26 [00:24<00:03,  1.07it/s]Epoch: 8/10. Loss: 1.1011:  88%|[36m████████▊ [0m| 23/26 [00:24<00:02,  1.04it/s]Epoch: 8/10. Loss: 1.0462:  88%|[36m████████▊ [0m| 23/26 [00:25<00:02,  1.04it/s]Epoch: 8/10. Loss: 1.0462:  92%|[36m█████████▏[0m| 24/26 [00:25<00:02,  1.02s/it]Epoch: 8/10. Loss: 0.9986:  92%|[36m█████████▏[0m| 24/26 [00:26<00:02,  1.02s/it]Epoch: 8/10. Loss: 0.9986:  96%|[36m█████████▌[0m| 25/26 [00:26<00:01,  1.05s/it]Epoch: 8/10. Loss: 1.0197:  96%|[36m█████████▌[0m| 25/26 [00:27<00:01,  1.05s/it]Epoch: 8/10. Loss: 1.0197: 100%|[36m██████████[0m| 26/26 [00:27<00:00,  1.14it/s]Epoch: 8/10. Loss: 1.0197: 100%|[36m██████████[0m| 26/26 [00:27<00:00,  1.05s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:05,  1.14it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:07,  1.41s/it] 43%|[33m████▎     [0m| 3/7 [00:03<00:04,  1.03s/it] 57%|[33m█████▋    [0m| 4/7 [00:04<00:03,  1.17s/it] 71%|[33m███████▏  [0m| 5/7 [00:05<00:01,  1.11it/s] 86%|[33m████████▌ [0m| 6/7 [00:05<00:00,  1.12it/s]100%|[33m██████████[0m| 7/7 [00:06<00:00,  1.43it/s]100%|[33m██████████[0m| 7/7 [00:06<00:00,  1.12it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 9/10. Loss: 1.0307:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 9/10. Loss: 1.0307:   4%|[36m▍         [0m| 1/26 [00:00<00:24,  1.01it/s]Epoch: 9/10. Loss: 1.0028:   4%|[36m▍         [0m| 1/26 [00:01<00:24,  1.01it/s]Epoch: 9/10. Loss: 1.0028:   8%|[36m▊         [0m| 2/26 [00:01<00:22,  1.08it/s]Epoch: 9/10. Loss: 0.9917:   8%|[36m▊         [0m| 2/26 [00:02<00:22,  1.08it/s]Epoch: 9/10. Loss: 0.9917:  12%|[36m█▏        [0m| 3/26 [00:02<00:21,  1.06it/s]Epoch: 9/10. Loss: 0.9785:  12%|[36m█▏        [0m| 3/26 [00:03<00:21,  1.06it/s]Epoch: 9/10. Loss: 0.9785:  15%|[36m█▌        [0m| 4/26 [00:03<00:19,  1.15it/s]Epoch: 9/10. Loss: 1.0920:  15%|[36m█▌        [0m| 4/26 [00:04<00:19,  1.15it/s]Epoch: 9/10. Loss: 1.0920:  19%|[36m█▉        [0m| 5/26 [00:04<00:21,  1.04s/it]Epoch: 9/10. Loss: 0.9027:  19%|[36m█▉        [0m| 5/26 [00:06<00:21,  1.04s/it]Epoch: 9/10. Loss: 0.9027:  23%|[36m██▎       [0m| 6/26 [00:06<00:21,  1.06s/it]Epoch: 9/10. Loss: 1.0680:  23%|[36m██▎       [0m| 6/26 [00:06<00:21,  1.06s/it]Epoch: 9/10. Loss: 1.0680:  27%|[36m██▋       [0m| 7/26 [00:06<00:19,  1.02s/it]Epoch: 9/10. Loss: 1.0687:  27%|[36m██▋       [0m| 7/26 [00:07<00:19,  1.02s/it]Epoch: 9/10. Loss: 1.0687:  31%|[36m███       [0m| 8/26 [00:07<00:17,  1.02it/s]Epoch: 9/10. Loss: 0.9751:  31%|[36m███       [0m| 8/26 [00:08<00:17,  1.02it/s]Epoch: 9/10. Loss: 0.9751:  35%|[36m███▍      [0m| 9/26 [00:08<00:16,  1.02it/s]Epoch: 9/10. Loss: 0.9723:  35%|[36m███▍      [0m| 9/26 [00:09<00:16,  1.02it/s]Epoch: 9/10. Loss: 0.9723:  38%|[36m███▊      [0m| 10/26 [00:09<00:16,  1.02s/it]Epoch: 9/10. Loss: 1.0919:  38%|[36m███▊      [0m| 10/26 [00:11<00:16,  1.02s/it]Epoch: 9/10. Loss: 1.0919:  42%|[36m████▏     [0m| 11/26 [00:11<00:17,  1.18s/it]Epoch: 9/10. Loss: 1.1104:  42%|[36m████▏     [0m| 11/26 [00:12<00:17,  1.18s/it]Epoch: 9/10. Loss: 1.1104:  46%|[36m████▌     [0m| 12/26 [00:12<00:15,  1.12s/it]Epoch: 9/10. Loss: 0.9973:  46%|[36m████▌     [0m| 12/26 [00:13<00:15,  1.12s/it]Epoch: 9/10. Loss: 0.9973:  50%|[36m█████     [0m| 13/26 [00:13<00:14,  1.15s/it]Epoch: 9/10. Loss: 0.9521:  50%|[36m█████     [0m| 13/26 [00:14<00:14,  1.15s/it]Epoch: 9/10. Loss: 0.9521:  54%|[36m█████▍    [0m| 14/26 [00:14<00:13,  1.11s/it]Epoch: 9/10. Loss: 1.0054:  54%|[36m█████▍    [0m| 14/26 [00:15<00:13,  1.11s/it]Epoch: 9/10. Loss: 1.0054:  58%|[36m█████▊    [0m| 15/26 [00:15<00:12,  1.09s/it]Epoch: 9/10. Loss: 1.0486:  58%|[36m█████▊    [0m| 15/26 [00:16<00:12,  1.09s/it]Epoch: 9/10. Loss: 1.0486:  62%|[36m██████▏   [0m| 16/26 [00:16<00:11,  1.13s/it]Epoch: 9/10. Loss: 0.9533:  62%|[36m██████▏   [0m| 16/26 [00:17<00:11,  1.13s/it]Epoch: 9/10. Loss: 0.9533:  65%|[36m██████▌   [0m| 17/26 [00:17<00:09,  1.04s/it]Epoch: 9/10. Loss: 0.9685:  65%|[36m██████▌   [0m| 17/26 [00:18<00:09,  1.04s/it]Epoch: 9/10. Loss: 0.9685:  69%|[36m██████▉   [0m| 18/26 [00:18<00:08,  1.00s/it]Epoch: 9/10. Loss: 1.0286:  69%|[36m██████▉   [0m| 18/26 [00:19<00:08,  1.00s/it]Epoch: 9/10. Loss: 1.0286:  73%|[36m███████▎  [0m| 19/26 [00:19<00:06,  1.03it/s]Epoch: 9/10. Loss: 1.0191:  73%|[36m███████▎  [0m| 19/26 [00:20<00:06,  1.03it/s]Epoch: 9/10. Loss: 1.0191:  77%|[36m███████▋  [0m| 20/26 [00:20<00:05,  1.06it/s]Epoch: 9/10. Loss: 0.9818:  77%|[36m███████▋  [0m| 20/26 [00:21<00:05,  1.06it/s]Epoch: 9/10. Loss: 0.9818:  81%|[36m████████  [0m| 21/26 [00:21<00:04,  1.14it/s]Epoch: 9/10. Loss: 0.9758:  81%|[36m████████  [0m| 21/26 [00:22<00:04,  1.14it/s]Epoch: 9/10. Loss: 0.9758:  85%|[36m████████▍ [0m| 22/26 [00:22<00:03,  1.08it/s]Epoch: 9/10. Loss: 1.1539:  85%|[36m████████▍ [0m| 22/26 [00:23<00:03,  1.08it/s]Epoch: 9/10. Loss: 1.1539:  88%|[36m████████▊ [0m| 23/26 [00:23<00:03,  1.07s/it]Epoch: 9/10. Loss: 0.9187:  88%|[36m████████▊ [0m| 23/26 [00:24<00:03,  1.07s/it]Epoch: 9/10. Loss: 0.9187:  92%|[36m█████████▏[0m| 24/26 [00:24<00:02,  1.03s/it]Epoch: 9/10. Loss: 1.0805:  92%|[36m█████████▏[0m| 24/26 [00:25<00:02,  1.03s/it]Epoch: 9/10. Loss: 1.0805:  96%|[36m█████████▌[0m| 25/26 [00:25<00:00,  1.04it/s]Epoch: 9/10. Loss: 1.0526:  96%|[36m█████████▌[0m| 25/26 [00:26<00:00,  1.04it/s]Epoch: 9/10. Loss: 1.0526: 100%|[36m██████████[0m| 26/26 [00:26<00:00,  1.11it/s]Epoch: 9/10. Loss: 1.0526: 100%|[36m██████████[0m| 26/26 [00:26<00:00,  1.01s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:05,  1.16it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:05,  1.20s/it] 43%|[33m████▎     [0m| 3/7 [00:02<00:03,  1.10it/s] 57%|[33m█████▋    [0m| 4/7 [00:05<00:04,  1.61s/it] 71%|[33m███████▏  [0m| 5/7 [00:05<00:02,  1.18s/it] 86%|[33m████████▌ [0m| 6/7 [00:06<00:01,  1.08s/it]100%|[33m██████████[0m| 7/7 [00:07<00:00,  1.21it/s]100%|[33m██████████[0m| 7/7 [00:07<00:00,  1.02s/it]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 0/10. Loss: 1.1115:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 0/10. Loss: 1.1115:   4%|[36m▍         [0m| 1/26 [00:00<00:20,  1.19it/s]Epoch: 0/10. Loss: 2.3534:   4%|[36m▍         [0m| 1/26 [00:01<00:20,  1.19it/s]Epoch: 0/10. Loss: 2.3534:   8%|[36m▊         [0m| 2/26 [00:01<00:21,  1.09it/s]Epoch: 0/10. Loss: 3.8870:   8%|[36m▊         [0m| 2/26 [00:02<00:21,  1.09it/s]Epoch: 0/10. Loss: 3.8870:  12%|[36m█▏        [0m| 3/26 [00:02<00:22,  1.01it/s]Epoch: 0/10. Loss: 2.0119:  12%|[36m█▏        [0m| 3/26 [00:03<00:22,  1.01it/s]Epoch: 0/10. Loss: 2.0119:  15%|[36m█▌        [0m| 4/26 [00:03<00:21,  1.04it/s]Epoch: 0/10. Loss: 2.2845:  15%|[36m█▌        [0m| 4/26 [00:04<00:21,  1.04it/s]Epoch: 0/10. Loss: 2.2845:  19%|[36m█▉        [0m| 5/26 [00:04<00:21,  1.00s/it]Epoch: 0/10. Loss: 1.8953:  19%|[36m█▉        [0m| 5/26 [00:05<00:21,  1.00s/it]Epoch: 0/10. Loss: 1.8953:  23%|[36m██▎       [0m| 6/26 [00:05<00:20,  1.04s/it]Epoch: 0/10. Loss: 1.6947:  23%|[36m██▎       [0m| 6/26 [00:08<00:20,  1.04s/it]Epoch: 0/10. Loss: 1.6947:  27%|[36m██▋       [0m| 7/26 [00:08<00:28,  1.52s/it]Epoch: 0/10. Loss: 1.7909:  27%|[36m██▋       [0m| 7/26 [00:09<00:28,  1.52s/it]Epoch: 0/10. Loss: 1.7909:  31%|[36m███       [0m| 8/26 [00:09<00:24,  1.38s/it]Epoch: 0/10. Loss: 1.4373:  31%|[36m███       [0m| 8/26 [00:10<00:24,  1.38s/it]Epoch: 0/10. Loss: 1.4373:  35%|[36m███▍      [0m| 9/26 [00:10<00:21,  1.25s/it]Epoch: 0/10. Loss: 1.3543:  35%|[36m███▍      [0m| 9/26 [00:11<00:21,  1.25s/it]Epoch: 0/10. Loss: 1.3543:  38%|[36m███▊      [0m| 10/26 [00:11<00:17,  1.12s/it]Epoch: 0/10. Loss: 1.0930:  38%|[36m███▊      [0m| 10/26 [00:12<00:17,  1.12s/it]Epoch: 0/10. Loss: 1.0930:  42%|[36m████▏     [0m| 11/26 [00:12<00:15,  1.06s/it]Epoch: 0/10. Loss: 1.2285:  42%|[36m████▏     [0m| 11/26 [00:13<00:15,  1.06s/it]Epoch: 0/10. Loss: 1.2285:  46%|[36m████▌     [0m| 12/26 [00:13<00:14,  1.04s/it]Epoch: 0/10. Loss: 1.2848:  46%|[36m████▌     [0m| 12/26 [00:14<00:14,  1.04s/it]Epoch: 0/10. Loss: 1.2848:  50%|[36m█████     [0m| 13/26 [00:14<00:13,  1.03s/it]Epoch: 0/10. Loss: 1.3524:  50%|[36m█████     [0m| 13/26 [00:15<00:13,  1.03s/it]Epoch: 0/10. Loss: 1.3524:  54%|[36m█████▍    [0m| 14/26 [00:15<00:11,  1.01it/s]Epoch: 0/10. Loss: 1.2446:  54%|[36m█████▍    [0m| 14/26 [00:16<00:11,  1.01it/s]Epoch: 0/10. Loss: 1.2446:  58%|[36m█████▊    [0m| 15/26 [00:16<00:11,  1.06s/it]Epoch: 0/10. Loss: 0.9800:  58%|[36m█████▊    [0m| 15/26 [00:17<00:11,  1.06s/it]Epoch: 0/10. Loss: 0.9800:  62%|[36m██████▏   [0m| 16/26 [00:17<00:11,  1.16s/it]Epoch: 0/10. Loss: 1.1699:  62%|[36m██████▏   [0m| 16/26 [00:18<00:11,  1.16s/it]Epoch: 0/10. Loss: 1.1699:  65%|[36m██████▌   [0m| 17/26 [00:18<00:09,  1.09s/it]Epoch: 0/10. Loss: 1.0480:  65%|[36m██████▌   [0m| 17/26 [00:19<00:09,  1.09s/it]Epoch: 0/10. Loss: 1.0480:  69%|[36m██████▉   [0m| 18/26 [00:19<00:08,  1.00s/it]Epoch: 0/10. Loss: 1.0171:  69%|[36m██████▉   [0m| 18/26 [00:20<00:08,  1.00s/it]Epoch: 0/10. Loss: 1.0171:  73%|[36m███████▎  [0m| 19/26 [00:20<00:06,  1.03it/s]Epoch: 0/10. Loss: 1.1506:  73%|[36m███████▎  [0m| 19/26 [00:21<00:06,  1.03it/s]Epoch: 0/10. Loss: 1.1506:  77%|[36m███████▋  [0m| 20/26 [00:21<00:05,  1.05it/s]Epoch: 0/10. Loss: 1.0629:  77%|[36m███████▋  [0m| 20/26 [00:22<00:05,  1.05it/s]Epoch: 0/10. Loss: 1.0629:  81%|[36m████████  [0m| 21/26 [00:22<00:04,  1.03it/s]Epoch: 0/10. Loss: 1.0249:  81%|[36m████████  [0m| 21/26 [00:23<00:04,  1.03it/s]Epoch: 0/10. Loss: 1.0249:  85%|[36m████████▍ [0m| 22/26 [00:23<00:03,  1.08it/s]Epoch: 0/10. Loss: 0.9756:  85%|[36m████████▍ [0m| 22/26 [00:24<00:03,  1.08it/s]Epoch: 0/10. Loss: 0.9756:  88%|[36m████████▊ [0m| 23/26 [00:24<00:02,  1.10it/s]Epoch: 0/10. Loss: 0.9382:  88%|[36m████████▊ [0m| 23/26 [00:25<00:02,  1.10it/s]Epoch: 0/10. Loss: 0.9382:  92%|[36m█████████▏[0m| 24/26 [00:25<00:01,  1.06it/s]Epoch: 0/10. Loss: 1.2174:  92%|[36m█████████▏[0m| 24/26 [00:25<00:01,  1.06it/s]Epoch: 0/10. Loss: 1.2174:  96%|[36m█████████▌[0m| 25/26 [00:26<00:00,  1.06it/s]Epoch: 0/10. Loss: 0.9947:  96%|[36m█████████▌[0m| 25/26 [00:26<00:00,  1.06it/s]Epoch: 0/10. Loss: 0.9947: 100%|[36m██████████[0m| 26/26 [00:26<00:00,  1.11it/s]Epoch: 0/10. Loss: 0.9947: 100%|[36m██████████[0m| 26/26 [00:26<00:00,  1.03s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:05,  1.13it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:06,  1.27s/it] 43%|[33m████▎     [0m| 3/7 [00:03<00:03,  1.01it/s] 57%|[33m█████▋    [0m| 4/7 [00:04<00:03,  1.28s/it] 71%|[33m███████▏  [0m| 5/7 [00:05<00:01,  1.02it/s] 86%|[33m████████▌ [0m| 6/7 [00:06<00:00,  1.02it/s]100%|[33m██████████[0m| 7/7 [00:06<00:00,  1.29it/s]100%|[33m██████████[0m| 7/7 [00:06<00:00,  1.06it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 1/10. Loss: 1.0505:   0%|[36m          [0m| 0/26 [00:01<?, ?it/s]Epoch: 1/10. Loss: 1.0505:   4%|[36m▍         [0m| 1/26 [00:01<00:34,  1.36s/it]Epoch: 1/10. Loss: 0.9378:   4%|[36m▍         [0m| 1/26 [00:02<00:34,  1.36s/it]Epoch: 1/10. Loss: 0.9378:   8%|[36m▊         [0m| 2/26 [00:02<00:27,  1.15s/it]Epoch: 1/10. Loss: 0.9641:   8%|[36m▊         [0m| 2/26 [00:03<00:27,  1.15s/it]Epoch: 1/10. Loss: 0.9641:  12%|[36m█▏        [0m| 3/26 [00:03<00:24,  1.07s/it]Epoch: 1/10. Loss: 0.9771:  12%|[36m█▏        [0m| 3/26 [00:04<00:24,  1.07s/it]Epoch: 1/10. Loss: 0.9771:  15%|[36m█▌        [0m| 4/26 [00:04<00:22,  1.03s/it]Epoch: 1/10. Loss: 0.9810:  15%|[36m█▌        [0m| 4/26 [00:05<00:22,  1.03s/it]Epoch: 1/10. Loss: 0.9810:  19%|[36m█▉        [0m| 5/26 [00:05<00:21,  1.02s/it]Epoch: 1/10. Loss: 0.9409:  19%|[36m█▉        [0m| 5/26 [00:06<00:21,  1.02s/it]Epoch: 1/10. Loss: 0.9409:  23%|[36m██▎       [0m| 6/26 [00:06<00:18,  1.06it/s]Epoch: 1/10. Loss: 0.9810:  23%|[36m██▎       [0m| 6/26 [00:07<00:18,  1.06it/s]Epoch: 1/10. Loss: 0.9810:  27%|[36m██▋       [0m| 7/26 [00:07<00:17,  1.07it/s]Epoch: 1/10. Loss: 0.9507:  27%|[36m██▋       [0m| 7/26 [00:07<00:17,  1.07it/s]Epoch: 1/10. Loss: 0.9507:  31%|[36m███       [0m| 8/26 [00:07<00:16,  1.07it/s]Epoch: 1/10. Loss: 0.9025:  31%|[36m███       [0m| 8/26 [00:08<00:16,  1.07it/s]Epoch: 1/10. Loss: 0.9025:  35%|[36m███▍      [0m| 9/26 [00:08<00:16,  1.06it/s]Epoch: 1/10. Loss: 1.1183:  35%|[36m███▍      [0m| 9/26 [00:09<00:16,  1.06it/s]Epoch: 1/10. Loss: 1.1183:  38%|[36m███▊      [0m| 10/26 [00:09<00:14,  1.07it/s]Epoch: 1/10. Loss: 1.0006:  38%|[36m███▊      [0m| 10/26 [00:10<00:14,  1.07it/s]Epoch: 1/10. Loss: 1.0006:  42%|[36m████▏     [0m| 11/26 [00:10<00:13,  1.12it/s]Epoch: 1/10. Loss: 0.9826:  42%|[36m████▏     [0m| 11/26 [00:11<00:13,  1.12it/s]Epoch: 1/10. Loss: 0.9826:  46%|[36m████▌     [0m| 12/26 [00:11<00:12,  1.10it/s]Epoch: 1/10. Loss: 0.9355:  46%|[36m████▌     [0m| 12/26 [00:12<00:12,  1.10it/s]Epoch: 1/10. Loss: 0.9355:  50%|[36m█████     [0m| 13/26 [00:12<00:12,  1.05it/s]Epoch: 1/10. Loss: 0.9925:  50%|[36m█████     [0m| 13/26 [00:13<00:12,  1.05it/s]Epoch: 1/10. Loss: 0.9925:  54%|[36m█████▍    [0m| 14/26 [00:13<00:11,  1.03it/s]Epoch: 1/10. Loss: 0.8987:  54%|[36m█████▍    [0m| 14/26 [00:14<00:11,  1.03it/s]Epoch: 1/10. Loss: 0.8987:  58%|[36m█████▊    [0m| 15/26 [00:14<00:10,  1.07it/s]Epoch: 1/10. Loss: 1.0085:  58%|[36m█████▊    [0m| 15/26 [00:15<00:10,  1.07it/s]Epoch: 1/10. Loss: 1.0085:  62%|[36m██████▏   [0m| 16/26 [00:15<00:09,  1.07it/s]Epoch: 1/10. Loss: 0.9673:  62%|[36m██████▏   [0m| 16/26 [00:16<00:09,  1.07it/s]Epoch: 1/10. Loss: 0.9673:  65%|[36m██████▌   [0m| 17/26 [00:16<00:08,  1.12it/s]Epoch: 1/10. Loss: 0.9513:  65%|[36m██████▌   [0m| 17/26 [00:17<00:08,  1.12it/s]Epoch: 1/10. Loss: 0.9513:  69%|[36m██████▉   [0m| 18/26 [00:17<00:07,  1.13it/s]Epoch: 1/10. Loss: 0.8793:  69%|[36m██████▉   [0m| 18/26 [00:18<00:07,  1.13it/s]Epoch: 1/10. Loss: 0.8793:  73%|[36m███████▎  [0m| 19/26 [00:18<00:06,  1.10it/s]Epoch: 1/10. Loss: 1.0841:  73%|[36m███████▎  [0m| 19/26 [00:18<00:06,  1.10it/s]Epoch: 1/10. Loss: 1.0841:  77%|[36m███████▋  [0m| 20/26 [00:18<00:05,  1.11it/s]Epoch: 1/10. Loss: 1.1008:  77%|[36m███████▋  [0m| 20/26 [00:19<00:05,  1.11it/s]Epoch: 1/10. Loss: 1.1008:  81%|[36m████████  [0m| 21/26 [00:19<00:04,  1.08it/s]Epoch: 1/10. Loss: 0.9159:  81%|[36m████████  [0m| 21/26 [00:20<00:04,  1.08it/s]Epoch: 1/10. Loss: 0.9159:  85%|[36m████████▍ [0m| 22/26 [00:20<00:03,  1.07it/s]Epoch: 1/10. Loss: 0.8683:  85%|[36m████████▍ [0m| 22/26 [00:21<00:03,  1.07it/s]Epoch: 1/10. Loss: 0.8683:  88%|[36m████████▊ [0m| 23/26 [00:21<00:02,  1.12it/s]Epoch: 1/10. Loss: 0.9468:  88%|[36m████████▊ [0m| 23/26 [00:22<00:02,  1.12it/s]Epoch: 1/10. Loss: 0.9468:  92%|[36m█████████▏[0m| 24/26 [00:22<00:01,  1.08it/s]Epoch: 1/10. Loss: 0.9236:  92%|[36m█████████▏[0m| 24/26 [00:23<00:01,  1.08it/s]Epoch: 1/10. Loss: 0.9236:  96%|[36m█████████▌[0m| 25/26 [00:23<00:00,  1.07it/s]Epoch: 1/10. Loss: 0.9628:  96%|[36m█████████▌[0m| 25/26 [00:24<00:00,  1.07it/s]Epoch: 1/10. Loss: 0.9628: 100%|[36m██████████[0m| 26/26 [00:24<00:00,  1.18it/s]Epoch: 1/10. Loss: 0.9628: 100%|[36m██████████[0m| 26/26 [00:24<00:00,  1.07it/s]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:05,  1.15it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:06,  1.23s/it] 43%|[33m████▎     [0m| 3/7 [00:02<00:03,  1.09it/s] 57%|[33m█████▋    [0m| 4/7 [00:05<00:04,  1.41s/it] 71%|[33m███████▏  [0m| 5/7 [00:05<00:02,  1.06s/it] 86%|[33m████████▌ [0m| 6/7 [00:06<00:01,  1.12s/it]100%|[33m██████████[0m| 7/7 [00:07<00:00,  1.10it/s]100%|[33m██████████[0m| 7/7 [00:07<00:00,  1.03s/it]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 2/10. Loss: 0.9158:   0%|[36m          [0m| 0/26 [00:01<?, ?it/s]Epoch: 2/10. Loss: 0.9158:   4%|[36m▍         [0m| 1/26 [00:01<00:46,  1.87s/it]Epoch: 2/10. Loss: 0.9263:   4%|[36m▍         [0m| 1/26 [00:02<00:46,  1.87s/it]Epoch: 2/10. Loss: 0.9263:   8%|[36m▊         [0m| 2/26 [00:02<00:33,  1.40s/it]Epoch: 2/10. Loss: 0.9983:   8%|[36m▊         [0m| 2/26 [00:03<00:33,  1.40s/it]Epoch: 2/10. Loss: 0.9983:  12%|[36m█▏        [0m| 3/26 [00:03<00:27,  1.18s/it]Epoch: 2/10. Loss: 1.0046:  12%|[36m█▏        [0m| 3/26 [00:06<00:27,  1.18s/it]Epoch: 2/10. Loss: 1.0046:  15%|[36m█▌        [0m| 4/26 [00:06<00:34,  1.58s/it]Epoch: 2/10. Loss: 0.9553:  15%|[36m█▌        [0m| 4/26 [00:07<00:34,  1.58s/it]Epoch: 2/10. Loss: 0.9553:  19%|[36m█▉        [0m| 5/26 [00:07<00:29,  1.38s/it]Epoch: 2/10. Loss: 0.9547:  19%|[36m█▉        [0m| 5/26 [00:08<00:29,  1.38s/it]Epoch: 2/10. Loss: 0.9547:  23%|[36m██▎       [0m| 6/26 [00:08<00:29,  1.48s/it]Epoch: 2/10. Loss: 0.9306:  23%|[36m██▎       [0m| 6/26 [00:09<00:29,  1.48s/it]Epoch: 2/10. Loss: 0.9306:  27%|[36m██▋       [0m| 7/26 [00:09<00:25,  1.35s/it]Epoch: 2/10. Loss: 0.9294:  27%|[36m██▋       [0m| 7/26 [00:10<00:25,  1.35s/it]Epoch: 2/10. Loss: 0.9294:  31%|[36m███       [0m| 8/26 [00:10<00:20,  1.16s/it]Epoch: 2/10. Loss: 0.8969:  31%|[36m███       [0m| 8/26 [00:11<00:20,  1.16s/it]Epoch: 2/10. Loss: 0.8969:  35%|[36m███▍      [0m| 9/26 [00:11<00:18,  1.06s/it]Epoch: 2/10. Loss: 0.9745:  35%|[36m███▍      [0m| 9/26 [00:12<00:18,  1.06s/it]Epoch: 2/10. Loss: 0.9745:  38%|[36m███▊      [0m| 10/26 [00:12<00:16,  1.06s/it]Epoch: 2/10. Loss: 0.9244:  38%|[36m███▊      [0m| 10/26 [00:13<00:16,  1.06s/it]Epoch: 2/10. Loss: 0.9244:  42%|[36m████▏     [0m| 11/26 [00:13<00:15,  1.06s/it]Epoch: 2/10. Loss: 0.9309:  42%|[36m████▏     [0m| 11/26 [00:14<00:15,  1.06s/it]Epoch: 2/10. Loss: 0.9309:  46%|[36m████▌     [0m| 12/26 [00:14<00:14,  1.01s/it]Epoch: 2/10. Loss: 0.9082:  46%|[36m████▌     [0m| 12/26 [00:15<00:14,  1.01s/it]Epoch: 2/10. Loss: 0.9082:  50%|[36m█████     [0m| 13/26 [00:15<00:12,  1.01it/s]Epoch: 2/10. Loss: 0.9562:  50%|[36m█████     [0m| 13/26 [00:16<00:12,  1.01it/s]Epoch: 2/10. Loss: 0.9562:  54%|[36m█████▍    [0m| 14/26 [00:16<00:11,  1.01it/s]Epoch: 2/10. Loss: 0.9446:  54%|[36m█████▍    [0m| 14/26 [00:17<00:11,  1.01it/s]Epoch: 2/10. Loss: 0.9446:  58%|[36m█████▊    [0m| 15/26 [00:17<00:10,  1.04it/s]Epoch: 2/10. Loss: 0.8275:  58%|[36m█████▊    [0m| 15/26 [00:18<00:10,  1.04it/s]Epoch: 2/10. Loss: 0.8275:  62%|[36m██████▏   [0m| 16/26 [00:18<00:10,  1.05s/it]Epoch: 2/10. Loss: 1.0518:  62%|[36m██████▏   [0m| 16/26 [00:19<00:10,  1.05s/it]Epoch: 2/10. Loss: 1.0518:  65%|[36m██████▌   [0m| 17/26 [00:19<00:09,  1.05s/it]Epoch: 2/10. Loss: 0.9142:  65%|[36m██████▌   [0m| 17/26 [00:22<00:09,  1.05s/it]Epoch: 2/10. Loss: 0.9142:  69%|[36m██████▉   [0m| 18/26 [00:22<00:13,  1.71s/it]Epoch: 2/10. Loss: 0.9283:  69%|[36m██████▉   [0m| 18/26 [00:24<00:13,  1.71s/it]Epoch: 2/10. Loss: 0.9283:  73%|[36m███████▎  [0m| 19/26 [00:24<00:11,  1.61s/it]Epoch: 2/10. Loss: 0.9160:  73%|[36m███████▎  [0m| 19/26 [00:26<00:11,  1.61s/it]Epoch: 2/10. Loss: 0.9160:  77%|[36m███████▋  [0m| 20/26 [00:26<00:10,  1.68s/it]Epoch: 2/10. Loss: 0.9423:  77%|[36m███████▋  [0m| 20/26 [00:27<00:10,  1.68s/it]Epoch: 2/10. Loss: 0.9423:  81%|[36m████████  [0m| 21/26 [00:27<00:07,  1.48s/it]Epoch: 2/10. Loss: 0.8008:  81%|[36m████████  [0m| 21/26 [00:28<00:07,  1.48s/it]Epoch: 2/10. Loss: 0.8008:  85%|[36m████████▍ [0m| 22/26 [00:28<00:05,  1.33s/it]Epoch: 2/10. Loss: 0.8526:  85%|[36m████████▍ [0m| 22/26 [00:28<00:05,  1.33s/it]Epoch: 2/10. Loss: 0.8526:  88%|[36m████████▊ [0m| 23/26 [00:29<00:03,  1.22s/it]Epoch: 2/10. Loss: 0.9165:  88%|[36m████████▊ [0m| 23/26 [00:33<00:03,  1.22s/it]Epoch: 2/10. Loss: 0.9165:  92%|[36m█████████▏[0m| 24/26 [00:33<00:04,  2.15s/it]Epoch: 2/10. Loss: 0.8102:  92%|[36m█████████▏[0m| 24/26 [00:35<00:04,  2.15s/it]Epoch: 2/10. Loss: 0.8102:  96%|[36m█████████▌[0m| 25/26 [00:35<00:02,  2.07s/it]Epoch: 2/10. Loss: 0.8548:  96%|[36m█████████▌[0m| 25/26 [00:35<00:02,  2.07s/it]Epoch: 2/10. Loss: 0.8548: 100%|[36m██████████[0m| 26/26 [00:35<00:00,  1.63s/it]Epoch: 2/10. Loss: 0.8548: 100%|[36m██████████[0m| 26/26 [00:35<00:00,  1.38s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:05,  1.05it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:06,  1.32s/it] 43%|[33m████▎     [0m| 3/7 [00:03<00:04,  1.04s/it] 57%|[33m█████▋    [0m| 4/7 [00:05<00:04,  1.38s/it] 71%|[33m███████▏  [0m| 5/7 [00:06<00:02,  1.36s/it] 86%|[33m████████▌ [0m| 6/7 [00:08<00:01,  1.70s/it]100%|[33m██████████[0m| 7/7 [00:09<00:00,  1.23s/it]100%|[33m██████████[0m| 7/7 [00:09<00:00,  1.30s/it]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 3/10. Loss: 0.8272:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 3/10. Loss: 0.8272:   4%|[36m▍         [0m| 1/26 [00:00<00:21,  1.16it/s]Epoch: 3/10. Loss: 0.8110:   4%|[36m▍         [0m| 1/26 [00:02<00:21,  1.16it/s]Epoch: 3/10. Loss: 0.8110:   8%|[36m▊         [0m| 2/26 [00:02<00:29,  1.24s/it]Epoch: 3/10. Loss: 0.8491:   8%|[36m▊         [0m| 2/26 [00:03<00:29,  1.24s/it]Epoch: 3/10. Loss: 0.8491:  12%|[36m█▏        [0m| 3/26 [00:03<00:26,  1.16s/it]Epoch: 3/10. Loss: 0.8079:  12%|[36m█▏        [0m| 3/26 [00:04<00:26,  1.16s/it]Epoch: 3/10. Loss: 0.8079:  15%|[36m█▌        [0m| 4/26 [00:04<00:23,  1.09s/it]Epoch: 3/10. Loss: 0.8795:  15%|[36m█▌        [0m| 4/26 [00:05<00:23,  1.09s/it]Epoch: 3/10. Loss: 0.8795:  19%|[36m█▉        [0m| 5/26 [00:05<00:22,  1.06s/it]Epoch: 3/10. Loss: 0.7730:  19%|[36m█▉        [0m| 5/26 [00:06<00:22,  1.06s/it]Epoch: 3/10. Loss: 0.7730:  23%|[36m██▎       [0m| 6/26 [00:06<00:22,  1.12s/it]Epoch: 3/10. Loss: 0.9654:  23%|[36m██▎       [0m| 6/26 [00:07<00:22,  1.12s/it]Epoch: 3/10. Loss: 0.9654:  27%|[36m██▋       [0m| 7/26 [00:07<00:21,  1.12s/it]Epoch: 3/10. Loss: 0.9673:  27%|[36m██▋       [0m| 7/26 [00:08<00:21,  1.12s/it]Epoch: 3/10. Loss: 0.9673:  31%|[36m███       [0m| 8/26 [00:08<00:19,  1.08s/it]Epoch: 3/10. Loss: 0.9630:  31%|[36m███       [0m| 8/26 [00:09<00:19,  1.08s/it]Epoch: 3/10. Loss: 0.9630:  35%|[36m███▍      [0m| 9/26 [00:09<00:18,  1.08s/it]Epoch: 3/10. Loss: 0.9532:  35%|[36m███▍      [0m| 9/26 [00:10<00:18,  1.08s/it]Epoch: 3/10. Loss: 0.9532:  38%|[36m███▊      [0m| 10/26 [00:10<00:17,  1.06s/it]Epoch: 3/10. Loss: 0.8170:  38%|[36m███▊      [0m| 10/26 [00:11<00:17,  1.06s/it]Epoch: 3/10. Loss: 0.8170:  42%|[36m████▏     [0m| 11/26 [00:11<00:14,  1.02it/s]Epoch: 3/10. Loss: 0.8016:  42%|[36m████▏     [0m| 11/26 [00:12<00:14,  1.02it/s]Epoch: 3/10. Loss: 0.8016:  46%|[36m████▌     [0m| 12/26 [00:12<00:13,  1.06it/s]Epoch: 3/10. Loss: 0.8519:  46%|[36m████▌     [0m| 12/26 [00:13<00:13,  1.06it/s]Epoch: 3/10. Loss: 0.8519:  50%|[36m█████     [0m| 13/26 [00:13<00:12,  1.08it/s]Epoch: 3/10. Loss: 0.8242:  50%|[36m█████     [0m| 13/26 [00:14<00:12,  1.08it/s]Epoch: 3/10. Loss: 0.8242:  54%|[36m█████▍    [0m| 14/26 [00:14<00:12,  1.04s/it]Epoch: 3/10. Loss: 0.7785:  54%|[36m█████▍    [0m| 14/26 [00:15<00:12,  1.04s/it]Epoch: 3/10. Loss: 0.7785:  58%|[36m█████▊    [0m| 15/26 [00:15<00:10,  1.00it/s]Epoch: 3/10. Loss: 0.8970:  58%|[36m█████▊    [0m| 15/26 [00:16<00:10,  1.00it/s]Epoch: 3/10. Loss: 0.8970:  62%|[36m██████▏   [0m| 16/26 [00:16<00:10,  1.06s/it]Epoch: 3/10. Loss: 0.7889:  62%|[36m██████▏   [0m| 16/26 [00:17<00:10,  1.06s/it]Epoch: 3/10. Loss: 0.7889:  65%|[36m██████▌   [0m| 17/26 [00:17<00:09,  1.08s/it]Epoch: 3/10. Loss: 0.8195:  65%|[36m██████▌   [0m| 17/26 [00:18<00:09,  1.08s/it]Epoch: 3/10. Loss: 0.8195:  69%|[36m██████▉   [0m| 18/26 [00:18<00:08,  1.07s/it]Epoch: 3/10. Loss: 0.9286:  69%|[36m██████▉   [0m| 18/26 [00:20<00:08,  1.07s/it]Epoch: 3/10. Loss: 0.9286:  73%|[36m███████▎  [0m| 19/26 [00:20<00:07,  1.08s/it]Epoch: 3/10. Loss: 0.8274:  73%|[36m███████▎  [0m| 19/26 [00:20<00:07,  1.08s/it]Epoch: 3/10. Loss: 0.8274:  77%|[36m███████▋  [0m| 20/26 [00:20<00:06,  1.01s/it]Epoch: 3/10. Loss: 0.9827:  77%|[36m███████▋  [0m| 20/26 [00:21<00:06,  1.01s/it]Epoch: 3/10. Loss: 0.9827:  81%|[36m████████  [0m| 21/26 [00:21<00:04,  1.03it/s]Epoch: 3/10. Loss: 0.8803:  81%|[36m████████  [0m| 21/26 [00:22<00:04,  1.03it/s]Epoch: 3/10. Loss: 0.8803:  85%|[36m████████▍ [0m| 22/26 [00:22<00:03,  1.04it/s]Epoch: 3/10. Loss: 0.9056:  85%|[36m████████▍ [0m| 22/26 [00:23<00:03,  1.04it/s]Epoch: 3/10. Loss: 0.9056:  88%|[36m████████▊ [0m| 23/26 [00:23<00:02,  1.12it/s]Epoch: 3/10. Loss: 0.8472:  88%|[36m████████▊ [0m| 23/26 [00:24<00:02,  1.12it/s]Epoch: 3/10. Loss: 0.8472:  92%|[36m█████████▏[0m| 24/26 [00:24<00:01,  1.06it/s]Epoch: 3/10. Loss: 0.8620:  92%|[36m█████████▏[0m| 24/26 [00:25<00:01,  1.06it/s]Epoch: 3/10. Loss: 0.8620:  96%|[36m█████████▌[0m| 25/26 [00:25<00:00,  1.10it/s]Epoch: 3/10. Loss: 0.9522:  96%|[36m█████████▌[0m| 25/26 [00:26<00:00,  1.10it/s]Epoch: 3/10. Loss: 0.9522: 100%|[36m██████████[0m| 26/26 [00:26<00:00,  1.20it/s]Epoch: 3/10. Loss: 0.9522: 100%|[36m██████████[0m| 26/26 [00:26<00:00,  1.00s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:05,  1.16it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:06,  1.26s/it] 43%|[33m████▎     [0m| 3/7 [00:02<00:03,  1.08it/s] 57%|[33m█████▋    [0m| 4/7 [00:04<00:03,  1.18s/it] 71%|[33m███████▏  [0m| 5/7 [00:04<00:01,  1.13it/s] 86%|[33m████████▌ [0m| 6/7 [00:05<00:00,  1.14it/s]100%|[33m██████████[0m| 7/7 [00:06<00:00,  1.46it/s]100%|[33m██████████[0m| 7/7 [00:06<00:00,  1.16it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 4/10. Loss: 0.8777:   0%|[36m          [0m| 0/26 [00:01<?, ?it/s]Epoch: 4/10. Loss: 0.8777:   4%|[36m▍         [0m| 1/26 [00:01<00:29,  1.18s/it]Epoch: 4/10. Loss: 0.8714:   4%|[36m▍         [0m| 1/26 [00:02<00:29,  1.18s/it]Epoch: 4/10. Loss: 0.8714:   8%|[36m▊         [0m| 2/26 [00:02<00:36,  1.52s/it]Epoch: 4/10. Loss: 0.8918:   8%|[36m▊         [0m| 2/26 [00:04<00:36,  1.52s/it]Epoch: 4/10. Loss: 0.8918:  12%|[36m█▏        [0m| 3/26 [00:04<00:32,  1.41s/it]Epoch: 4/10. Loss: 0.8302:  12%|[36m█▏        [0m| 3/26 [00:05<00:32,  1.41s/it]Epoch: 4/10. Loss: 0.8302:  15%|[36m█▌        [0m| 4/26 [00:05<00:27,  1.24s/it]Epoch: 4/10. Loss: 0.7706:  15%|[36m█▌        [0m| 4/26 [00:06<00:27,  1.24s/it]Epoch: 4/10. Loss: 0.7706:  19%|[36m█▉        [0m| 5/26 [00:06<00:23,  1.11s/it]Epoch: 4/10. Loss: 0.8442:  19%|[36m█▉        [0m| 5/26 [00:07<00:23,  1.11s/it]Epoch: 4/10. Loss: 0.8442:  23%|[36m██▎       [0m| 6/26 [00:07<00:21,  1.09s/it]Epoch: 4/10. Loss: 0.7639:  23%|[36m██▎       [0m| 6/26 [00:08<00:21,  1.09s/it]Epoch: 4/10. Loss: 0.7639:  27%|[36m██▋       [0m| 7/26 [00:08<00:24,  1.30s/it]Epoch: 4/10. Loss: 0.8329:  27%|[36m██▋       [0m| 7/26 [00:09<00:24,  1.30s/it]Epoch: 4/10. Loss: 0.8329:  31%|[36m███       [0m| 8/26 [00:09<00:21,  1.18s/it]Epoch: 4/10. Loss: 0.8460:  31%|[36m███       [0m| 8/26 [00:10<00:21,  1.18s/it]Epoch: 4/10. Loss: 0.8460:  35%|[36m███▍      [0m| 9/26 [00:10<00:18,  1.06s/it]Epoch: 4/10. Loss: 0.8066:  35%|[36m███▍      [0m| 9/26 [00:11<00:18,  1.06s/it]Epoch: 4/10. Loss: 0.8066:  38%|[36m███▊      [0m| 10/26 [00:11<00:15,  1.00it/s]Epoch: 4/10. Loss: 0.9040:  38%|[36m███▊      [0m| 10/26 [00:13<00:15,  1.00it/s]Epoch: 4/10. Loss: 0.9040:  42%|[36m████▏     [0m| 11/26 [00:13<00:19,  1.32s/it]Epoch: 4/10. Loss: 0.7899:  42%|[36m████▏     [0m| 11/26 [00:14<00:19,  1.32s/it]Epoch: 4/10. Loss: 0.7899:  46%|[36m████▌     [0m| 12/26 [00:14<00:16,  1.15s/it]Epoch: 4/10. Loss: 0.9037:  46%|[36m████▌     [0m| 12/26 [00:15<00:16,  1.15s/it]Epoch: 4/10. Loss: 0.9037:  50%|[36m█████     [0m| 13/26 [00:15<00:14,  1.12s/it]Epoch: 4/10. Loss: 0.9420:  50%|[36m█████     [0m| 13/26 [00:16<00:14,  1.12s/it]Epoch: 4/10. Loss: 0.9420:  54%|[36m█████▍    [0m| 14/26 [00:16<00:13,  1.12s/it]Epoch: 4/10. Loss: 0.7749:  54%|[36m█████▍    [0m| 14/26 [00:19<00:13,  1.12s/it]Epoch: 4/10. Loss: 0.7749:  58%|[36m█████▊    [0m| 15/26 [00:19<00:19,  1.81s/it]Epoch: 4/10. Loss: 0.7290:  58%|[36m█████▊    [0m| 15/26 [00:20<00:19,  1.81s/it]Epoch: 4/10. Loss: 0.7290:  62%|[36m██████▏   [0m| 16/26 [00:20<00:15,  1.56s/it]Epoch: 4/10. Loss: 0.8733:  62%|[36m██████▏   [0m| 16/26 [00:21<00:15,  1.56s/it]Epoch: 4/10. Loss: 0.8733:  65%|[36m██████▌   [0m| 17/26 [00:21<00:12,  1.36s/it]Epoch: 4/10. Loss: 0.8196:  65%|[36m██████▌   [0m| 17/26 [00:22<00:12,  1.36s/it]Epoch: 4/10. Loss: 0.8196:  69%|[36m██████▉   [0m| 18/26 [00:22<00:10,  1.30s/it]Epoch: 4/10. Loss: 0.9182:  69%|[36m██████▉   [0m| 18/26 [00:24<00:10,  1.30s/it]Epoch: 4/10. Loss: 0.9182:  73%|[36m███████▎  [0m| 19/26 [00:24<00:08,  1.27s/it]Epoch: 4/10. Loss: 0.7871:  73%|[36m███████▎  [0m| 19/26 [00:25<00:08,  1.27s/it]Epoch: 4/10. Loss: 0.7871:  77%|[36m███████▋  [0m| 20/26 [00:25<00:07,  1.18s/it]Epoch: 4/10. Loss: 0.8773:  77%|[36m███████▋  [0m| 20/26 [00:26<00:07,  1.18s/it]Epoch: 4/10. Loss: 0.8773:  81%|[36m████████  [0m| 21/26 [00:26<00:05,  1.15s/it]Epoch: 4/10. Loss: 0.9152:  81%|[36m████████  [0m| 21/26 [00:26<00:05,  1.15s/it]Epoch: 4/10. Loss: 0.9152:  85%|[36m████████▍ [0m| 22/26 [00:26<00:04,  1.04s/it]Epoch: 4/10. Loss: 0.9015:  85%|[36m████████▍ [0m| 22/26 [00:28<00:04,  1.04s/it]Epoch: 4/10. Loss: 0.9015:  88%|[36m████████▊ [0m| 23/26 [00:28<00:03,  1.30s/it]Epoch: 4/10. Loss: 0.8839:  88%|[36m████████▊ [0m| 23/26 [00:29<00:03,  1.30s/it]Epoch: 4/10. Loss: 0.8839:  92%|[36m█████████▏[0m| 24/26 [00:29<00:02,  1.19s/it]Epoch: 4/10. Loss: 0.8251:  92%|[36m█████████▏[0m| 24/26 [00:32<00:02,  1.19s/it]Epoch: 4/10. Loss: 0.8251:  96%|[36m█████████▌[0m| 25/26 [00:32<00:01,  1.72s/it]Epoch: 4/10. Loss: 0.8379:  96%|[36m█████████▌[0m| 25/26 [00:33<00:01,  1.72s/it]Epoch: 4/10. Loss: 0.8379: 100%|[36m██████████[0m| 26/26 [00:33<00:00,  1.40s/it]Epoch: 4/10. Loss: 0.8379: 100%|[36m██████████[0m| 26/26 [00:33<00:00,  1.28s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:05,  1.15it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:07,  1.51s/it] 43%|[33m████▎     [0m| 3/7 [00:03<00:04,  1.12s/it] 57%|[33m█████▋    [0m| 4/7 [00:04<00:03,  1.24s/it] 71%|[33m███████▏  [0m| 5/7 [00:05<00:01,  1.07it/s] 86%|[33m████████▌ [0m| 6/7 [00:06<00:00,  1.09it/s]100%|[33m██████████[0m| 7/7 [00:06<00:00,  1.29it/s]100%|[33m██████████[0m| 7/7 [00:06<00:00,  1.05it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 5/10. Loss: 0.7901:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 5/10. Loss: 0.7901:   4%|[36m▍         [0m| 1/26 [00:00<00:20,  1.24it/s]Epoch: 5/10. Loss: 0.7560:   4%|[36m▍         [0m| 1/26 [00:01<00:20,  1.24it/s]Epoch: 5/10. Loss: 0.7560:   8%|[36m▊         [0m| 2/26 [00:01<00:19,  1.24it/s]Epoch: 5/10. Loss: 0.7793:   8%|[36m▊         [0m| 2/26 [00:02<00:19,  1.24it/s]Epoch: 5/10. Loss: 0.7793:  12%|[36m█▏        [0m| 3/26 [00:02<00:20,  1.13it/s]Epoch: 5/10. Loss: 0.7971:  12%|[36m█▏        [0m| 3/26 [00:03<00:20,  1.13it/s]Epoch: 5/10. Loss: 0.7971:  15%|[36m█▌        [0m| 4/26 [00:03<00:21,  1.04it/s]Epoch: 5/10. Loss: 0.7657:  15%|[36m█▌        [0m| 4/26 [00:05<00:21,  1.04it/s]Epoch: 5/10. Loss: 0.7657:  19%|[36m█▉        [0m| 5/26 [00:05<00:26,  1.25s/it]Epoch: 5/10. Loss: 0.7804:  19%|[36m█▉        [0m| 5/26 [00:06<00:26,  1.25s/it]Epoch: 5/10. Loss: 0.7804:  23%|[36m██▎       [0m| 6/26 [00:06<00:23,  1.15s/it]Epoch: 5/10. Loss: 0.7784:  23%|[36m██▎       [0m| 6/26 [00:08<00:23,  1.15s/it]Epoch: 5/10. Loss: 0.7784:  27%|[36m██▋       [0m| 7/26 [00:08<00:29,  1.57s/it]Epoch: 5/10. Loss: 0.7702:  27%|[36m██▋       [0m| 7/26 [00:09<00:29,  1.57s/it]Epoch: 5/10. Loss: 0.7702:  31%|[36m███       [0m| 8/26 [00:09<00:24,  1.38s/it]Epoch: 5/10. Loss: 0.7963:  31%|[36m███       [0m| 8/26 [00:10<00:24,  1.38s/it]Epoch: 5/10. Loss: 0.7963:  35%|[36m███▍      [0m| 9/26 [00:10<00:20,  1.22s/it]Epoch: 5/10. Loss: 0.7464:  35%|[36m███▍      [0m| 9/26 [00:11<00:20,  1.22s/it]Epoch: 5/10. Loss: 0.7464:  38%|[36m███▊      [0m| 10/26 [00:11<00:18,  1.13s/it]Epoch: 5/10. Loss: 0.8261:  38%|[36m███▊      [0m| 10/26 [00:12<00:18,  1.13s/it]Epoch: 5/10. Loss: 0.8261:  42%|[36m████▏     [0m| 11/26 [00:12<00:16,  1.08s/it]Epoch: 5/10. Loss: 0.8047:  42%|[36m████▏     [0m| 11/26 [00:13<00:16,  1.08s/it]Epoch: 5/10. Loss: 0.8047:  46%|[36m████▌     [0m| 12/26 [00:13<00:15,  1.13s/it]Epoch: 5/10. Loss: 0.7568:  46%|[36m████▌     [0m| 12/26 [00:14<00:15,  1.13s/it]Epoch: 5/10. Loss: 0.7568:  50%|[36m█████     [0m| 13/26 [00:14<00:14,  1.09s/it]Epoch: 5/10. Loss: 0.7315:  50%|[36m█████     [0m| 13/26 [00:15<00:14,  1.09s/it]Epoch: 5/10. Loss: 0.7315:  54%|[36m█████▍    [0m| 14/26 [00:15<00:12,  1.02s/it]Epoch: 5/10. Loss: 0.9013:  54%|[36m█████▍    [0m| 14/26 [00:16<00:12,  1.02s/it]Epoch: 5/10. Loss: 0.9013:  58%|[36m█████▊    [0m| 15/26 [00:16<00:10,  1.02it/s]Epoch: 5/10. Loss: 0.7506:  58%|[36m█████▊    [0m| 15/26 [00:17<00:10,  1.02it/s]Epoch: 5/10. Loss: 0.7506:  62%|[36m██████▏   [0m| 16/26 [00:17<00:09,  1.07it/s]Epoch: 5/10. Loss: 0.6739:  62%|[36m██████▏   [0m| 16/26 [00:18<00:09,  1.07it/s]Epoch: 5/10. Loss: 0.6739:  65%|[36m██████▌   [0m| 17/26 [00:18<00:08,  1.10it/s]Epoch: 5/10. Loss: 0.7053:  65%|[36m██████▌   [0m| 17/26 [00:19<00:08,  1.10it/s]Epoch: 5/10. Loss: 0.7053:  69%|[36m██████▉   [0m| 18/26 [00:19<00:06,  1.14it/s]Epoch: 5/10. Loss: 0.7554:  69%|[36m██████▉   [0m| 18/26 [00:20<00:06,  1.14it/s]Epoch: 5/10. Loss: 0.7554:  73%|[36m███████▎  [0m| 19/26 [00:20<00:06,  1.08it/s]Epoch: 5/10. Loss: 0.7443:  73%|[36m███████▎  [0m| 19/26 [00:21<00:06,  1.08it/s]Epoch: 5/10. Loss: 0.7443:  77%|[36m███████▋  [0m| 20/26 [00:21<00:05,  1.04it/s]Epoch: 5/10. Loss: 0.7347:  77%|[36m███████▋  [0m| 20/26 [00:23<00:05,  1.04it/s]Epoch: 5/10. Loss: 0.7347:  81%|[36m████████  [0m| 21/26 [00:23<00:06,  1.27s/it]Epoch: 5/10. Loss: 0.7863:  81%|[36m████████  [0m| 21/26 [00:24<00:06,  1.27s/it]Epoch: 5/10. Loss: 0.7863:  85%|[36m████████▍ [0m| 22/26 [00:24<00:04,  1.18s/it]Epoch: 5/10. Loss: 0.7678:  85%|[36m████████▍ [0m| 22/26 [00:25<00:04,  1.18s/it]Epoch: 5/10. Loss: 0.7678:  88%|[36m████████▊ [0m| 23/26 [00:25<00:03,  1.14s/it]Epoch: 5/10. Loss: 0.7684:  88%|[36m████████▊ [0m| 23/26 [00:26<00:03,  1.14s/it]Epoch: 5/10. Loss: 0.7684:  92%|[36m█████████▏[0m| 24/26 [00:26<00:02,  1.09s/it]Epoch: 5/10. Loss: 0.7871:  92%|[36m█████████▏[0m| 24/26 [00:27<00:02,  1.09s/it]Epoch: 5/10. Loss: 0.7871:  96%|[36m█████████▌[0m| 25/26 [00:27<00:01,  1.06s/it]Epoch: 5/10. Loss: 0.8887:  96%|[36m█████████▌[0m| 25/26 [00:27<00:01,  1.06s/it]Epoch: 5/10. Loss: 0.8887: 100%|[36m██████████[0m| 26/26 [00:27<00:00,  1.11it/s]Epoch: 5/10. Loss: 0.8887: 100%|[36m██████████[0m| 26/26 [00:27<00:00,  1.06s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:05,  1.15it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:06,  1.21s/it] 43%|[33m████▎     [0m| 3/7 [00:02<00:03,  1.09it/s] 57%|[33m█████▋    [0m| 4/7 [00:04<00:03,  1.10s/it] 71%|[33m███████▏  [0m| 5/7 [00:04<00:01,  1.17it/s] 86%|[33m████████▌ [0m| 6/7 [00:05<00:00,  1.14it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.41it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.17it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 6/10. Loss: 0.7010:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 6/10. Loss: 0.7010:   4%|[36m▍         [0m| 1/26 [00:01<00:25,  1.01s/it]Epoch: 6/10. Loss: 0.7861:   4%|[36m▍         [0m| 1/26 [00:02<00:25,  1.01s/it]Epoch: 6/10. Loss: 0.7861:   8%|[36m▊         [0m| 2/26 [00:02<00:24,  1.01s/it]Epoch: 6/10. Loss: 0.7267:   8%|[36m▊         [0m| 2/26 [00:04<00:24,  1.01s/it]Epoch: 6/10. Loss: 0.7267:  12%|[36m█▏        [0m| 3/26 [00:04<00:36,  1.59s/it]Epoch: 6/10. Loss: 0.7209:  12%|[36m█▏        [0m| 3/26 [00:05<00:36,  1.59s/it]Epoch: 6/10. Loss: 0.7209:  15%|[36m█▌        [0m| 4/26 [00:05<00:31,  1.44s/it]Epoch: 6/10. Loss: 0.7592:  15%|[36m█▌        [0m| 4/26 [00:06<00:31,  1.44s/it]Epoch: 6/10. Loss: 0.7592:  19%|[36m█▉        [0m| 5/26 [00:06<00:26,  1.26s/it]Epoch: 6/10. Loss: 0.7482:  19%|[36m█▉        [0m| 5/26 [00:08<00:26,  1.26s/it]Epoch: 6/10. Loss: 0.7482:  23%|[36m██▎       [0m| 6/26 [00:08<00:29,  1.48s/it]Epoch: 6/10. Loss: 0.6934:  23%|[36m██▎       [0m| 6/26 [00:09<00:29,  1.48s/it]Epoch: 6/10. Loss: 0.6934:  27%|[36m██▋       [0m| 7/26 [00:09<00:23,  1.25s/it]Epoch: 6/10. Loss: 0.8440:  27%|[36m██▋       [0m| 7/26 [00:10<00:23,  1.25s/it]Epoch: 6/10. Loss: 0.8440:  31%|[36m███       [0m| 8/26 [00:10<00:23,  1.30s/it]Epoch: 6/10. Loss: 0.6356:  31%|[36m███       [0m| 8/26 [00:13<00:23,  1.30s/it]Epoch: 6/10. Loss: 0.6356:  35%|[36m███▍      [0m| 9/26 [00:13<00:28,  1.69s/it]Epoch: 6/10. Loss: 0.7359:  35%|[36m███▍      [0m| 9/26 [00:14<00:28,  1.69s/it]Epoch: 6/10. Loss: 0.7359:  38%|[36m███▊      [0m| 10/26 [00:14<00:23,  1.49s/it]Epoch: 6/10. Loss: 0.8611:  38%|[36m███▊      [0m| 10/26 [00:14<00:23,  1.49s/it]Epoch: 6/10. Loss: 0.8611:  42%|[36m████▏     [0m| 11/26 [00:15<00:19,  1.30s/it]Epoch: 6/10. Loss: 0.8519:  42%|[36m████▏     [0m| 11/26 [00:15<00:19,  1.30s/it]Epoch: 6/10. Loss: 0.8519:  46%|[36m████▌     [0m| 12/26 [00:15<00:16,  1.19s/it]Epoch: 6/10. Loss: 0.8143:  46%|[36m████▌     [0m| 12/26 [00:16<00:16,  1.19s/it]Epoch: 6/10. Loss: 0.8143:  50%|[36m█████     [0m| 13/26 [00:16<00:14,  1.09s/it]Epoch: 6/10. Loss: 0.7862:  50%|[36m█████     [0m| 13/26 [00:17<00:14,  1.09s/it]Epoch: 6/10. Loss: 0.7862:  54%|[36m█████▍    [0m| 14/26 [00:17<00:12,  1.05s/it]Epoch: 6/10. Loss: 0.7627:  54%|[36m█████▍    [0m| 14/26 [00:19<00:12,  1.05s/it]Epoch: 6/10. Loss: 0.7627:  58%|[36m█████▊    [0m| 15/26 [00:19<00:12,  1.13s/it]Epoch: 6/10. Loss: 0.7472:  58%|[36m█████▊    [0m| 15/26 [00:20<00:12,  1.13s/it]Epoch: 6/10. Loss: 0.7472:  62%|[36m██████▏   [0m| 16/26 [00:20<00:10,  1.09s/it]Epoch: 6/10. Loss: 0.7523:  62%|[36m██████▏   [0m| 16/26 [00:20<00:10,  1.09s/it]Epoch: 6/10. Loss: 0.7523:  65%|[36m██████▌   [0m| 17/26 [00:20<00:09,  1.04s/it]Epoch: 6/10. Loss: 0.8313:  65%|[36m██████▌   [0m| 17/26 [00:21<00:09,  1.04s/it]Epoch: 6/10. Loss: 0.8313:  69%|[36m██████▉   [0m| 18/26 [00:21<00:07,  1.03it/s]Epoch: 6/10. Loss: 0.7993:  69%|[36m██████▉   [0m| 18/26 [00:22<00:07,  1.03it/s]Epoch: 6/10. Loss: 0.7993:  73%|[36m███████▎  [0m| 19/26 [00:22<00:06,  1.06it/s]Epoch: 6/10. Loss: 0.7532:  73%|[36m███████▎  [0m| 19/26 [00:23<00:06,  1.06it/s]Epoch: 6/10. Loss: 0.7532:  77%|[36m███████▋  [0m| 20/26 [00:23<00:05,  1.08it/s]Epoch: 6/10. Loss: 0.7095:  77%|[36m███████▋  [0m| 20/26 [00:24<00:05,  1.08it/s]Epoch: 6/10. Loss: 0.7095:  81%|[36m████████  [0m| 21/26 [00:24<00:04,  1.09it/s]Epoch: 6/10. Loss: 0.7511:  81%|[36m████████  [0m| 21/26 [00:25<00:04,  1.09it/s]Epoch: 6/10. Loss: 0.7511:  85%|[36m████████▍ [0m| 22/26 [00:25<00:03,  1.08it/s]Epoch: 6/10. Loss: 0.6980:  85%|[36m████████▍ [0m| 22/26 [00:26<00:03,  1.08it/s]Epoch: 6/10. Loss: 0.6980:  88%|[36m████████▊ [0m| 23/26 [00:26<00:02,  1.08it/s]Epoch: 6/10. Loss: 0.8043:  88%|[36m████████▊ [0m| 23/26 [00:27<00:02,  1.08it/s]Epoch: 6/10. Loss: 0.8043:  92%|[36m█████████▏[0m| 24/26 [00:27<00:01,  1.06it/s]Epoch: 6/10. Loss: 0.8483:  92%|[36m█████████▏[0m| 24/26 [00:28<00:01,  1.06it/s]Epoch: 6/10. Loss: 0.8483:  96%|[36m█████████▌[0m| 25/26 [00:28<00:00,  1.06it/s]Epoch: 6/10. Loss: 0.8578:  96%|[36m█████████▌[0m| 25/26 [00:28<00:00,  1.06it/s]Epoch: 6/10. Loss: 0.8578: 100%|[36m██████████[0m| 26/26 [00:28<00:00,  1.21it/s]Epoch: 6/10. Loss: 0.8578: 100%|[36m██████████[0m| 26/26 [00:28<00:00,  1.11s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:05,  1.13it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:06,  1.21s/it] 43%|[33m████▎     [0m| 3/7 [00:02<00:03,  1.08it/s] 57%|[33m█████▋    [0m| 4/7 [00:04<00:03,  1.13s/it] 71%|[33m███████▏  [0m| 5/7 [00:04<00:01,  1.12it/s] 86%|[33m████████▌ [0m| 6/7 [00:05<00:00,  1.11it/s]100%|[33m██████████[0m| 7/7 [00:06<00:00,  1.42it/s]100%|[33m██████████[0m| 7/7 [00:06<00:00,  1.16it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 7/10. Loss: 0.7475:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 7/10. Loss: 0.7475:   4%|[36m▍         [0m| 1/26 [00:00<00:20,  1.20it/s]Epoch: 7/10. Loss: 0.7444:   4%|[36m▍         [0m| 1/26 [00:01<00:20,  1.20it/s]Epoch: 7/10. Loss: 0.7444:   8%|[36m▊         [0m| 2/26 [00:01<00:21,  1.12it/s]Epoch: 7/10. Loss: 0.7262:   8%|[36m▊         [0m| 2/26 [00:02<00:21,  1.12it/s]Epoch: 7/10. Loss: 0.7262:  12%|[36m█▏        [0m| 3/26 [00:02<00:19,  1.15it/s]Epoch: 7/10. Loss: 0.7226:  12%|[36m█▏        [0m| 3/26 [00:03<00:19,  1.15it/s]Epoch: 7/10. Loss: 0.7226:  15%|[36m█▌        [0m| 4/26 [00:03<00:18,  1.16it/s]Epoch: 7/10. Loss: 0.7262:  15%|[36m█▌        [0m| 4/26 [00:04<00:18,  1.16it/s]Epoch: 7/10. Loss: 0.7262:  19%|[36m█▉        [0m| 5/26 [00:04<00:18,  1.14it/s]Epoch: 7/10. Loss: 0.7280:  19%|[36m█▉        [0m| 5/26 [00:05<00:18,  1.14it/s]Epoch: 7/10. Loss: 0.7280:  23%|[36m██▎       [0m| 6/26 [00:05<00:17,  1.12it/s]Epoch: 7/10. Loss: 0.8325:  23%|[36m██▎       [0m| 6/26 [00:06<00:17,  1.12it/s]Epoch: 7/10. Loss: 0.8325:  27%|[36m██▋       [0m| 7/26 [00:06<00:16,  1.15it/s]Epoch: 7/10. Loss: 0.7849:  27%|[36m██▋       [0m| 7/26 [00:07<00:16,  1.15it/s]Epoch: 7/10. Loss: 0.7849:  31%|[36m███       [0m| 8/26 [00:07<00:18,  1.01s/it]Epoch: 7/10. Loss: 0.7219:  31%|[36m███       [0m| 8/26 [00:08<00:18,  1.01s/it]Epoch: 7/10. Loss: 0.7219:  35%|[36m███▍      [0m| 9/26 [00:08<00:16,  1.01it/s]Epoch: 7/10. Loss: 0.7405:  35%|[36m███▍      [0m| 9/26 [00:09<00:16,  1.01it/s]Epoch: 7/10. Loss: 0.7405:  38%|[36m███▊      [0m| 10/26 [00:09<00:16,  1.00s/it]Epoch: 7/10. Loss: 0.8054:  38%|[36m███▊      [0m| 10/26 [00:10<00:16,  1.00s/it]Epoch: 7/10. Loss: 0.8054:  42%|[36m████▏     [0m| 11/26 [00:10<00:15,  1.00s/it]Epoch: 7/10. Loss: 0.7072:  42%|[36m████▏     [0m| 11/26 [00:11<00:15,  1.00s/it]Epoch: 7/10. Loss: 0.7072:  46%|[36m████▌     [0m| 12/26 [00:11<00:13,  1.01it/s]Epoch: 7/10. Loss: 0.7980:  46%|[36m████▌     [0m| 12/26 [00:12<00:13,  1.01it/s]Epoch: 7/10. Loss: 0.7980:  50%|[36m█████     [0m| 13/26 [00:12<00:12,  1.04it/s]Epoch: 7/10. Loss: 0.7267:  50%|[36m█████     [0m| 13/26 [00:13<00:12,  1.04it/s]Epoch: 7/10. Loss: 0.7267:  54%|[36m█████▍    [0m| 14/26 [00:13<00:11,  1.07it/s]Epoch: 7/10. Loss: 0.7866:  54%|[36m█████▍    [0m| 14/26 [00:13<00:11,  1.07it/s]Epoch: 7/10. Loss: 0.7866:  58%|[36m█████▊    [0m| 15/26 [00:13<00:09,  1.11it/s]Epoch: 7/10. Loss: 0.7837:  58%|[36m█████▊    [0m| 15/26 [00:14<00:09,  1.11it/s]Epoch: 7/10. Loss: 0.7837:  62%|[36m██████▏   [0m| 16/26 [00:15<00:09,  1.06it/s]Epoch: 7/10. Loss: 0.8392:  62%|[36m██████▏   [0m| 16/26 [00:15<00:09,  1.06it/s]Epoch: 7/10. Loss: 0.8392:  65%|[36m██████▌   [0m| 17/26 [00:15<00:08,  1.06it/s]Epoch: 7/10. Loss: 0.7007:  65%|[36m██████▌   [0m| 17/26 [00:16<00:08,  1.06it/s]Epoch: 7/10. Loss: 0.7007:  69%|[36m██████▉   [0m| 18/26 [00:16<00:07,  1.10it/s]Epoch: 7/10. Loss: 0.6684:  69%|[36m██████▉   [0m| 18/26 [00:17<00:07,  1.10it/s]Epoch: 7/10. Loss: 0.6684:  73%|[36m███████▎  [0m| 19/26 [00:17<00:06,  1.12it/s]Epoch: 7/10. Loss: 0.7262:  73%|[36m███████▎  [0m| 19/26 [00:18<00:06,  1.12it/s]Epoch: 7/10. Loss: 0.7262:  77%|[36m███████▋  [0m| 20/26 [00:18<00:05,  1.07it/s]Epoch: 7/10. Loss: 0.7280:  77%|[36m███████▋  [0m| 20/26 [00:19<00:05,  1.07it/s]Epoch: 7/10. Loss: 0.7280:  81%|[36m████████  [0m| 21/26 [00:19<00:04,  1.07it/s]Epoch: 7/10. Loss: 0.7186:  81%|[36m████████  [0m| 21/26 [00:20<00:04,  1.07it/s]Epoch: 7/10. Loss: 0.7186:  85%|[36m████████▍ [0m| 22/26 [00:20<00:03,  1.03it/s]Epoch: 7/10. Loss: 0.7729:  85%|[36m████████▍ [0m| 22/26 [00:22<00:03,  1.03it/s]Epoch: 7/10. Loss: 0.7729:  88%|[36m████████▊ [0m| 23/26 [00:22<00:03,  1.20s/it]Epoch: 7/10. Loss: 0.7835:  88%|[36m████████▊ [0m| 23/26 [00:23<00:03,  1.20s/it]Epoch: 7/10. Loss: 0.7835:  92%|[36m█████████▏[0m| 24/26 [00:23<00:02,  1.09s/it]Epoch: 7/10. Loss: 0.7676:  92%|[36m█████████▏[0m| 24/26 [00:24<00:02,  1.09s/it]Epoch: 7/10. Loss: 0.7676:  96%|[36m█████████▌[0m| 25/26 [00:24<00:01,  1.10s/it]Epoch: 7/10. Loss: 0.7017:  96%|[36m█████████▌[0m| 25/26 [00:24<00:01,  1.10s/it]Epoch: 7/10. Loss: 0.7017: 100%|[36m██████████[0m| 26/26 [00:24<00:00,  1.05it/s]Epoch: 7/10. Loss: 0.7017: 100%|[36m██████████[0m| 26/26 [00:24<00:00,  1.04it/s]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:01<00:07,  1.31s/it] 29%|[33m██▊       [0m| 2/7 [00:03<00:07,  1.58s/it] 43%|[33m████▎     [0m| 3/7 [00:03<00:04,  1.08s/it] 57%|[33m█████▋    [0m| 4/7 [00:04<00:03,  1.16s/it] 71%|[33m███████▏  [0m| 5/7 [00:05<00:01,  1.13it/s] 86%|[33m████████▌ [0m| 6/7 [00:09<00:02,  2.05s/it]100%|[33m██████████[0m| 7/7 [00:09<00:00,  1.48s/it]100%|[33m██████████[0m| 7/7 [00:09<00:00,  1.41s/it]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 8/10. Loss: 0.6505:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 8/10. Loss: 0.6505:   4%|[36m▍         [0m| 1/26 [00:00<00:24,  1.03it/s]Epoch: 8/10. Loss: 0.7887:   4%|[36m▍         [0m| 1/26 [00:01<00:24,  1.03it/s]Epoch: 8/10. Loss: 0.7887:   8%|[36m▊         [0m| 2/26 [00:01<00:21,  1.10it/s]Epoch: 8/10. Loss: 0.8450:   8%|[36m▊         [0m| 2/26 [00:02<00:21,  1.10it/s]Epoch: 8/10. Loss: 0.8450:  12%|[36m█▏        [0m| 3/26 [00:02<00:22,  1.00it/s]Epoch: 8/10. Loss: 0.7377:  12%|[36m█▏        [0m| 3/26 [00:03<00:22,  1.00it/s]Epoch: 8/10. Loss: 0.7377:  15%|[36m█▌        [0m| 4/26 [00:03<00:20,  1.08it/s]Epoch: 8/10. Loss: 0.6531:  15%|[36m█▌        [0m| 4/26 [00:04<00:20,  1.08it/s]Epoch: 8/10. Loss: 0.6531:  19%|[36m█▉        [0m| 5/26 [00:04<00:20,  1.00it/s]Epoch: 8/10. Loss: 0.6839:  19%|[36m█▉        [0m| 5/26 [00:05<00:20,  1.00it/s]Epoch: 8/10. Loss: 0.6839:  23%|[36m██▎       [0m| 6/26 [00:05<00:18,  1.05it/s]Epoch: 8/10. Loss: 0.6451:  23%|[36m██▎       [0m| 6/26 [00:06<00:18,  1.05it/s]Epoch: 8/10. Loss: 0.6451:  27%|[36m██▋       [0m| 7/26 [00:06<00:19,  1.01s/it]Epoch: 8/10. Loss: 0.7533:  27%|[36m██▋       [0m| 7/26 [00:07<00:19,  1.01s/it]Epoch: 8/10. Loss: 0.7533:  31%|[36m███       [0m| 8/26 [00:07<00:17,  1.01it/s]Epoch: 8/10. Loss: 0.7359:  31%|[36m███       [0m| 8/26 [00:08<00:17,  1.01it/s]Epoch: 8/10. Loss: 0.7359:  35%|[36m███▍      [0m| 9/26 [00:08<00:16,  1.02it/s]Epoch: 8/10. Loss: 0.7920:  35%|[36m███▍      [0m| 9/26 [00:09<00:16,  1.02it/s]Epoch: 8/10. Loss: 0.7920:  38%|[36m███▊      [0m| 10/26 [00:09<00:15,  1.04it/s]Epoch: 8/10. Loss: 0.7973:  38%|[36m███▊      [0m| 10/26 [00:10<00:15,  1.04it/s]Epoch: 8/10. Loss: 0.7973:  42%|[36m████▏     [0m| 11/26 [00:10<00:14,  1.02it/s]Epoch: 8/10. Loss: 0.6734:  42%|[36m████▏     [0m| 11/26 [00:11<00:14,  1.02it/s]Epoch: 8/10. Loss: 0.6734:  46%|[36m████▌     [0m| 12/26 [00:11<00:13,  1.03it/s]Epoch: 8/10. Loss: 0.6994:  46%|[36m████▌     [0m| 12/26 [00:13<00:13,  1.03it/s]Epoch: 8/10. Loss: 0.6994:  50%|[36m█████     [0m| 13/26 [00:13<00:17,  1.32s/it]Epoch: 8/10. Loss: 0.6440:  50%|[36m█████     [0m| 13/26 [00:14<00:17,  1.32s/it]Epoch: 8/10. Loss: 0.6440:  54%|[36m█████▍    [0m| 14/26 [00:14<00:14,  1.20s/it]Epoch: 8/10. Loss: 0.5453:  54%|[36m█████▍    [0m| 14/26 [00:15<00:14,  1.20s/it]Epoch: 8/10. Loss: 0.5453:  58%|[36m█████▊    [0m| 15/26 [00:15<00:11,  1.07s/it]Epoch: 8/10. Loss: 0.6579:  58%|[36m█████▊    [0m| 15/26 [00:16<00:11,  1.07s/it]Epoch: 8/10. Loss: 0.6579:  62%|[36m██████▏   [0m| 16/26 [00:16<00:10,  1.02s/it]Epoch: 8/10. Loss: 0.5825:  62%|[36m██████▏   [0m| 16/26 [00:17<00:10,  1.02s/it]Epoch: 8/10. Loss: 0.5825:  65%|[36m██████▌   [0m| 17/26 [00:17<00:08,  1.03it/s]Epoch: 8/10. Loss: 0.6330:  65%|[36m██████▌   [0m| 17/26 [00:17<00:08,  1.03it/s]Epoch: 8/10. Loss: 0.6330:  69%|[36m██████▉   [0m| 18/26 [00:17<00:07,  1.13it/s]Epoch: 8/10. Loss: 0.7565:  69%|[36m██████▉   [0m| 18/26 [00:19<00:07,  1.13it/s]Epoch: 8/10. Loss: 0.7565:  73%|[36m███████▎  [0m| 19/26 [00:19<00:06,  1.04it/s]Epoch: 8/10. Loss: 0.6126:  73%|[36m███████▎  [0m| 19/26 [00:19<00:06,  1.04it/s]Epoch: 8/10. Loss: 0.6126:  77%|[36m███████▋  [0m| 20/26 [00:20<00:05,  1.05it/s]Epoch: 8/10. Loss: 0.7039:  77%|[36m███████▋  [0m| 20/26 [00:20<00:05,  1.05it/s]Epoch: 8/10. Loss: 0.7039:  81%|[36m████████  [0m| 21/26 [00:21<00:04,  1.03it/s]Epoch: 8/10. Loss: 0.5958:  81%|[36m████████  [0m| 21/26 [00:25<00:04,  1.03it/s]Epoch: 8/10. Loss: 0.5958:  85%|[36m████████▍ [0m| 22/26 [00:25<00:07,  1.91s/it]Epoch: 8/10. Loss: 0.6570:  85%|[36m████████▍ [0m| 22/26 [00:26<00:07,  1.91s/it]Epoch: 8/10. Loss: 0.6570:  88%|[36m████████▊ [0m| 23/26 [00:26<00:04,  1.62s/it]Epoch: 8/10. Loss: 0.5965:  88%|[36m████████▊ [0m| 23/26 [00:27<00:04,  1.62s/it]Epoch: 8/10. Loss: 0.5965:  92%|[36m█████████▏[0m| 24/26 [00:27<00:03,  1.52s/it]Epoch: 8/10. Loss: 0.8212:  92%|[36m█████████▏[0m| 24/26 [00:29<00:03,  1.52s/it]Epoch: 8/10. Loss: 0.8212:  96%|[36m█████████▌[0m| 25/26 [00:29<00:01,  1.85s/it]Epoch: 8/10. Loss: 0.6733:  96%|[36m█████████▌[0m| 25/26 [00:30<00:01,  1.85s/it]Epoch: 8/10. Loss: 0.6733: 100%|[36m██████████[0m| 26/26 [00:30<00:00,  1.57s/it]Epoch: 8/10. Loss: 0.6733: 100%|[36m██████████[0m| 26/26 [00:30<00:00,  1.19s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:05,  1.15it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:07,  1.46s/it] 43%|[33m████▎     [0m| 3/7 [00:03<00:04,  1.04s/it] 57%|[33m█████▋    [0m| 4/7 [00:04<00:03,  1.17s/it] 71%|[33m███████▏  [0m| 5/7 [00:05<00:01,  1.12it/s] 86%|[33m████████▌ [0m| 6/7 [00:06<00:00,  1.07it/s]100%|[33m██████████[0m| 7/7 [00:06<00:00,  1.37it/s]100%|[33m██████████[0m| 7/7 [00:06<00:00,  1.10it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 9/10. Loss: 0.6564:   0%|[36m          [0m| 0/26 [00:01<?, ?it/s]Epoch: 9/10. Loss: 0.6564:   4%|[36m▍         [0m| 1/26 [00:01<00:45,  1.84s/it]Epoch: 9/10. Loss: 0.6633:   4%|[36m▍         [0m| 1/26 [00:02<00:45,  1.84s/it]Epoch: 9/10. Loss: 0.6633:   8%|[36m▊         [0m| 2/26 [00:02<00:30,  1.25s/it]Epoch: 9/10. Loss: 0.6774:   8%|[36m▊         [0m| 2/26 [00:04<00:30,  1.25s/it]Epoch: 9/10. Loss: 0.6774:  12%|[36m█▏        [0m| 3/26 [00:04<00:29,  1.30s/it]Epoch: 9/10. Loss: 0.7493:  12%|[36m█▏        [0m| 3/26 [00:04<00:29,  1.30s/it]Epoch: 9/10. Loss: 0.7493:  15%|[36m█▌        [0m| 4/26 [00:04<00:24,  1.11s/it]Epoch: 9/10. Loss: 0.7358:  15%|[36m█▌        [0m| 4/26 [00:06<00:24,  1.11s/it]Epoch: 9/10. Loss: 0.7358:  19%|[36m█▉        [0m| 5/26 [00:06<00:23,  1.13s/it]Epoch: 9/10. Loss: 0.6245:  19%|[36m█▉        [0m| 5/26 [00:06<00:23,  1.13s/it]Epoch: 9/10. Loss: 0.6245:  23%|[36m██▎       [0m| 6/26 [00:06<00:21,  1.06s/it]Epoch: 9/10. Loss: 0.7193:  23%|[36m██▎       [0m| 6/26 [00:07<00:21,  1.06s/it]Epoch: 9/10. Loss: 0.7193:  27%|[36m██▋       [0m| 7/26 [00:07<00:19,  1.02s/it]Epoch: 9/10. Loss: 0.7316:  27%|[36m██▋       [0m| 7/26 [00:08<00:19,  1.02s/it]Epoch: 9/10. Loss: 0.7316:  31%|[36m███       [0m| 8/26 [00:08<00:17,  1.01it/s]Epoch: 9/10. Loss: 0.6227:  31%|[36m███       [0m| 8/26 [00:09<00:17,  1.01it/s]Epoch: 9/10. Loss: 0.6227:  35%|[36m███▍      [0m| 9/26 [00:09<00:16,  1.02it/s]Epoch: 9/10. Loss: 0.6731:  35%|[36m███▍      [0m| 9/26 [00:10<00:16,  1.02it/s]Epoch: 9/10. Loss: 0.6731:  38%|[36m███▊      [0m| 10/26 [00:10<00:15,  1.04it/s]Epoch: 9/10. Loss: 0.6435:  38%|[36m███▊      [0m| 10/26 [00:11<00:15,  1.04it/s]Epoch: 9/10. Loss: 0.6435:  42%|[36m████▏     [0m| 11/26 [00:11<00:14,  1.04it/s]Epoch: 9/10. Loss: 0.6903:  42%|[36m████▏     [0m| 11/26 [00:12<00:14,  1.04it/s]Epoch: 9/10. Loss: 0.6903:  46%|[36m████▌     [0m| 12/26 [00:12<00:14,  1.03s/it]Epoch: 9/10. Loss: 0.6584:  46%|[36m████▌     [0m| 12/26 [00:13<00:14,  1.03s/it]Epoch: 9/10. Loss: 0.6584:  50%|[36m█████     [0m| 13/26 [00:13<00:12,  1.04it/s]Epoch: 9/10. Loss: 0.6656:  50%|[36m█████     [0m| 13/26 [00:14<00:12,  1.04it/s]Epoch: 9/10. Loss: 0.6656:  54%|[36m█████▍    [0m| 14/26 [00:14<00:11,  1.06it/s]Epoch: 9/10. Loss: 0.7602:  54%|[36m█████▍    [0m| 14/26 [00:15<00:11,  1.06it/s]Epoch: 9/10. Loss: 0.7602:  58%|[36m█████▊    [0m| 15/26 [00:15<00:11,  1.03s/it]Epoch: 9/10. Loss: 0.6158:  58%|[36m█████▊    [0m| 15/26 [00:16<00:11,  1.03s/it]Epoch: 9/10. Loss: 0.6158:  62%|[36m██████▏   [0m| 16/26 [00:16<00:09,  1.02it/s]Epoch: 9/10. Loss: 0.6718:  62%|[36m██████▏   [0m| 16/26 [00:17<00:09,  1.02it/s]Epoch: 9/10. Loss: 0.6718:  65%|[36m██████▌   [0m| 17/26 [00:17<00:08,  1.05it/s]Epoch: 9/10. Loss: 0.6654:  65%|[36m██████▌   [0m| 17/26 [00:18<00:08,  1.05it/s]Epoch: 9/10. Loss: 0.6654:  69%|[36m██████▉   [0m| 18/26 [00:18<00:07,  1.07it/s]Epoch: 9/10. Loss: 0.7228:  69%|[36m██████▉   [0m| 18/26 [00:19<00:07,  1.07it/s]Epoch: 9/10. Loss: 0.7228:  73%|[36m███████▎  [0m| 19/26 [00:19<00:06,  1.07it/s]Epoch: 9/10. Loss: 0.7257:  73%|[36m███████▎  [0m| 19/26 [00:20<00:06,  1.07it/s]Epoch: 9/10. Loss: 0.7257:  77%|[36m███████▋  [0m| 20/26 [00:20<00:05,  1.05it/s]Epoch: 9/10. Loss: 0.6802:  77%|[36m███████▋  [0m| 20/26 [00:21<00:05,  1.05it/s]Epoch: 9/10. Loss: 0.6802:  81%|[36m████████  [0m| 21/26 [00:21<00:04,  1.10it/s]Epoch: 9/10. Loss: 0.6994:  81%|[36m████████  [0m| 21/26 [00:22<00:04,  1.10it/s]Epoch: 9/10. Loss: 0.6994:  85%|[36m████████▍ [0m| 22/26 [00:22<00:03,  1.09it/s]Epoch: 9/10. Loss: 0.7736:  85%|[36m████████▍ [0m| 22/26 [00:23<00:03,  1.09it/s]Epoch: 9/10. Loss: 0.7736:  88%|[36m████████▊ [0m| 23/26 [00:23<00:02,  1.00it/s]Epoch: 9/10. Loss: 0.8294:  88%|[36m████████▊ [0m| 23/26 [00:23<00:02,  1.00it/s]Epoch: 9/10. Loss: 0.8294:  92%|[36m█████████▏[0m| 24/26 [00:23<00:01,  1.09it/s]Epoch: 9/10. Loss: 0.7807:  92%|[36m█████████▏[0m| 24/26 [00:25<00:01,  1.09it/s]Epoch: 9/10. Loss: 0.7807:  96%|[36m█████████▌[0m| 25/26 [00:25<00:01,  1.03s/it]Epoch: 9/10. Loss: 0.6146:  96%|[36m█████████▌[0m| 25/26 [00:25<00:01,  1.03s/it]Epoch: 9/10. Loss: 0.6146: 100%|[36m██████████[0m| 26/26 [00:25<00:00,  1.13it/s]Epoch: 9/10. Loss: 0.6146: 100%|[36m██████████[0m| 26/26 [00:25<00:00,  1.01it/s]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:05,  1.15it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:06,  1.20s/it] 43%|[33m████▎     [0m| 3/7 [00:02<00:03,  1.04it/s] 57%|[33m█████▋    [0m| 4/7 [00:04<00:03,  1.11s/it] 71%|[33m███████▏  [0m| 5/7 [00:04<00:01,  1.17it/s] 86%|[33m████████▌ [0m| 6/7 [00:05<00:00,  1.12it/s]100%|[33m██████████[0m| 7/7 [00:06<00:00,  1.42it/s]100%|[33m██████████[0m| 7/7 [00:06<00:00,  1.17it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 0/10. Loss: 1.1005:   0%|[36m          [0m| 0/26 [00:02<?, ?it/s]Epoch: 0/10. Loss: 1.1005:   4%|[36m▍         [0m| 1/26 [00:02<00:57,  2.32s/it]Epoch: 0/10. Loss: 2861878.0000:   4%|[36m▍         [0m| 1/26 [00:03<00:57,  2.32s/it]Epoch: 0/10. Loss: 2861878.0000:   8%|[36m▊         [0m| 2/26 [00:03<00:36,  1.54s/it]Epoch: 0/10. Loss: 136.9476:   8%|[36m▊         [0m| 2/26 [00:04<00:36,  1.54s/it]    Epoch: 0/10. Loss: 136.9476:  12%|[36m█▏        [0m| 3/26 [00:04<00:28,  1.23s/it]Epoch: 0/10. Loss: 782.5550:  12%|[36m█▏        [0m| 3/26 [00:05<00:28,  1.23s/it]Epoch: 0/10. Loss: 782.5550:  15%|[36m█▌        [0m| 4/26 [00:05<00:24,  1.10s/it]Epoch: 0/10. Loss: 15399.3711:  15%|[36m█▌        [0m| 4/26 [00:06<00:24,  1.10s/it]Epoch: 0/10. Loss: 15399.3711:  19%|[36m█▉        [0m| 5/26 [00:06<00:22,  1.05s/it]Epoch: 0/10. Loss: 489.1326:  19%|[36m█▉        [0m| 5/26 [00:07<00:22,  1.05s/it]  Epoch: 0/10. Loss: 489.1326:  23%|[36m██▎       [0m| 6/26 [00:07<00:21,  1.05s/it]Epoch: 0/10. Loss: 4997.4902:  23%|[36m██▎       [0m| 6/26 [00:08<00:21,  1.05s/it]Epoch: 0/10. Loss: 4997.4902:  27%|[36m██▋       [0m| 7/26 [00:08<00:19,  1.04s/it]Epoch: 0/10. Loss: 1078.3385:  27%|[36m██▋       [0m| 7/26 [00:08<00:19,  1.04s/it]Epoch: 0/10. Loss: 1078.3385:  31%|[36m███       [0m| 8/26 [00:08<00:17,  1.01it/s]Epoch: 0/10. Loss: 317.2889:  31%|[36m███       [0m| 8/26 [00:09<00:17,  1.01it/s] Epoch: 0/10. Loss: 317.2889:  35%|[36m███▍      [0m| 9/26 [00:09<00:16,  1.01it/s]Epoch: 0/10. Loss: 73.7560:  35%|[36m███▍      [0m| 9/26 [00:10<00:16,  1.01it/s] Epoch: 0/10. Loss: 73.7560:  38%|[36m███▊      [0m| 10/26 [00:10<00:14,  1.09it/s]Epoch: 0/10. Loss: 818.2350:  38%|[36m███▊      [0m| 10/26 [00:11<00:14,  1.09it/s]Epoch: 0/10. Loss: 818.2350:  42%|[36m████▏     [0m| 11/26 [00:11<00:13,  1.12it/s]Epoch: 0/10. Loss: 57.7251:  42%|[36m████▏     [0m| 11/26 [00:12<00:13,  1.12it/s] Epoch: 0/10. Loss: 57.7251:  46%|[36m████▌     [0m| 12/26 [00:12<00:13,  1.07it/s]Epoch: 0/10. Loss: 16.3685:  46%|[36m████▌     [0m| 12/26 [00:13<00:13,  1.07it/s]Epoch: 0/10. Loss: 16.3685:  50%|[36m█████     [0m| 13/26 [00:13<00:12,  1.03it/s]Epoch: 0/10. Loss: 24.4228:  50%|[36m█████     [0m| 13/26 [00:14<00:12,  1.03it/s]Epoch: 0/10. Loss: 24.4228:  54%|[36m█████▍    [0m| 14/26 [00:14<00:10,  1.13it/s]Epoch: 0/10. Loss: 24.7845:  54%|[36m█████▍    [0m| 14/26 [00:15<00:10,  1.13it/s]Epoch: 0/10. Loss: 24.7845:  58%|[36m█████▊    [0m| 15/26 [00:15<00:09,  1.17it/s]Epoch: 0/10. Loss: 119.7652:  58%|[36m█████▊    [0m| 15/26 [00:15<00:09,  1.17it/s]Epoch: 0/10. Loss: 119.7652:  62%|[36m██████▏   [0m| 16/26 [00:15<00:08,  1.19it/s]Epoch: 0/10. Loss: 30.8859:  62%|[36m██████▏   [0m| 16/26 [00:16<00:08,  1.19it/s] Epoch: 0/10. Loss: 30.8859:  65%|[36m██████▌   [0m| 17/26 [00:16<00:07,  1.19it/s]Epoch: 0/10. Loss: 7.2714:  65%|[36m██████▌   [0m| 17/26 [00:17<00:07,  1.19it/s] Epoch: 0/10. Loss: 7.2714:  69%|[36m██████▉   [0m| 18/26 [00:17<00:06,  1.20it/s]Epoch: 0/10. Loss: 114.7689:  69%|[36m██████▉   [0m| 18/26 [00:18<00:06,  1.20it/s]Epoch: 0/10. Loss: 114.7689:  73%|[36m███████▎  [0m| 19/26 [00:18<00:05,  1.22it/s]Epoch: 0/10. Loss: 19.8088:  73%|[36m███████▎  [0m| 19/26 [00:19<00:05,  1.22it/s] Epoch: 0/10. Loss: 19.8088:  77%|[36m███████▋  [0m| 20/26 [00:19<00:05,  1.20it/s]Epoch: 0/10. Loss: 17.0745:  77%|[36m███████▋  [0m| 20/26 [00:20<00:05,  1.20it/s]Epoch: 0/10. Loss: 17.0745:  81%|[36m████████  [0m| 21/26 [00:20<00:04,  1.19it/s]Epoch: 0/10. Loss: 7.3916:  81%|[36m████████  [0m| 21/26 [00:21<00:04,  1.19it/s] Epoch: 0/10. Loss: 7.3916:  85%|[36m████████▍ [0m| 22/26 [00:21<00:04,  1.08s/it]Epoch: 0/10. Loss: 2.9952:  85%|[36m████████▍ [0m| 22/26 [00:22<00:04,  1.08s/it]Epoch: 0/10. Loss: 2.9952:  88%|[36m████████▊ [0m| 23/26 [00:22<00:03,  1.09s/it]Epoch: 0/10. Loss: 5.5519:  88%|[36m████████▊ [0m| 23/26 [00:24<00:03,  1.09s/it]Epoch: 0/10. Loss: 5.5519:  92%|[36m█████████▏[0m| 24/26 [00:24<00:02,  1.24s/it]Epoch: 0/10. Loss: 4.8664:  92%|[36m█████████▏[0m| 24/26 [00:25<00:02,  1.24s/it]Epoch: 0/10. Loss: 4.8664:  96%|[36m█████████▌[0m| 25/26 [00:25<00:01,  1.16s/it]Epoch: 0/10. Loss: 2.0497:  96%|[36m█████████▌[0m| 25/26 [00:26<00:01,  1.16s/it]Epoch: 0/10. Loss: 2.0497: 100%|[36m██████████[0m| 26/26 [00:26<00:00,  1.01s/it]Epoch: 0/10. Loss: 2.0497: 100%|[36m██████████[0m| 26/26 [00:26<00:00,  1.00s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:05,  1.19it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:05,  1.17s/it] 43%|[33m████▎     [0m| 3/7 [00:02<00:03,  1.15it/s] 57%|[33m█████▋    [0m| 4/7 [00:04<00:03,  1.06s/it] 71%|[33m███████▏  [0m| 5/7 [00:04<00:01,  1.22it/s] 86%|[33m████████▌ [0m| 6/7 [00:05<00:00,  1.18it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.49it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.23it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 1/10. Loss: 1.2840:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 1/10. Loss: 1.2840:   4%|[36m▍         [0m| 1/26 [00:00<00:15,  1.57it/s]Epoch: 1/10. Loss: 0.9658:   4%|[36m▍         [0m| 1/26 [00:01<00:15,  1.57it/s]Epoch: 1/10. Loss: 0.9658:   8%|[36m▊         [0m| 2/26 [00:01<00:22,  1.09it/s]Epoch: 1/10. Loss: 2.0355:   8%|[36m▊         [0m| 2/26 [00:03<00:22,  1.09it/s]Epoch: 1/10. Loss: 2.0355:  12%|[36m█▏        [0m| 3/26 [00:03<00:27,  1.21s/it]Epoch: 1/10. Loss: 1.1469:  12%|[36m█▏        [0m| 3/26 [00:04<00:27,  1.21s/it]Epoch: 1/10. Loss: 1.1469:  15%|[36m█▌        [0m| 4/26 [00:04<00:25,  1.14s/it]Epoch: 1/10. Loss: 1.0562:  15%|[36m█▌        [0m| 4/26 [00:05<00:25,  1.14s/it]Epoch: 1/10. Loss: 1.0562:  19%|[36m█▉        [0m| 5/26 [00:05<00:21,  1.05s/it]Epoch: 1/10. Loss: 1.1301:  19%|[36m█▉        [0m| 5/26 [00:06<00:21,  1.05s/it]Epoch: 1/10. Loss: 1.1301:  23%|[36m██▎       [0m| 6/26 [00:06<00:21,  1.05s/it]Epoch: 1/10. Loss: 1.1603:  23%|[36m██▎       [0m| 6/26 [00:07<00:21,  1.05s/it]Epoch: 1/10. Loss: 1.1603:  27%|[36m██▋       [0m| 7/26 [00:07<00:18,  1.02it/s]Epoch: 1/10. Loss: 1.1499:  27%|[36m██▋       [0m| 7/26 [00:08<00:18,  1.02it/s]Epoch: 1/10. Loss: 1.1499:  31%|[36m███       [0m| 8/26 [00:08<00:17,  1.03it/s]Epoch: 1/10. Loss: 0.9095:  31%|[36m███       [0m| 8/26 [00:09<00:17,  1.03it/s]Epoch: 1/10. Loss: 0.9095:  35%|[36m███▍      [0m| 9/26 [00:09<00:16,  1.02it/s]Epoch: 1/10. Loss: 1.1662:  35%|[36m███▍      [0m| 9/26 [00:09<00:16,  1.02it/s]Epoch: 1/10. Loss: 1.1662:  38%|[36m███▊      [0m| 10/26 [00:09<00:14,  1.09it/s]Epoch: 1/10. Loss: 0.9316:  38%|[36m███▊      [0m| 10/26 [00:10<00:14,  1.09it/s]Epoch: 1/10. Loss: 0.9316:  42%|[36m████▏     [0m| 11/26 [00:10<00:13,  1.08it/s]Epoch: 1/10. Loss: 1.0999:  42%|[36m████▏     [0m| 11/26 [00:11<00:13,  1.08it/s]Epoch: 1/10. Loss: 1.0999:  46%|[36m████▌     [0m| 12/26 [00:11<00:13,  1.01it/s]Epoch: 1/10. Loss: 1.0847:  46%|[36m████▌     [0m| 12/26 [00:12<00:13,  1.01it/s]Epoch: 1/10. Loss: 1.0847:  50%|[36m█████     [0m| 13/26 [00:12<00:12,  1.01it/s]Epoch: 1/10. Loss: 1.0424:  50%|[36m█████     [0m| 13/26 [00:13<00:12,  1.01it/s]Epoch: 1/10. Loss: 1.0424:  54%|[36m█████▍    [0m| 14/26 [00:13<00:11,  1.05it/s]Epoch: 1/10. Loss: 0.9710:  54%|[36m█████▍    [0m| 14/26 [00:14<00:11,  1.05it/s]Epoch: 1/10. Loss: 0.9710:  58%|[36m█████▊    [0m| 15/26 [00:14<00:10,  1.05it/s]Epoch: 1/10. Loss: 0.9757:  58%|[36m█████▊    [0m| 15/26 [00:15<00:10,  1.05it/s]Epoch: 1/10. Loss: 0.9757:  62%|[36m██████▏   [0m| 16/26 [00:15<00:08,  1.14it/s]Epoch: 1/10. Loss: 1.0682:  62%|[36m██████▏   [0m| 16/26 [00:16<00:08,  1.14it/s]Epoch: 1/10. Loss: 1.0682:  65%|[36m██████▌   [0m| 17/26 [00:16<00:08,  1.10it/s]Epoch: 1/10. Loss: 1.0594:  65%|[36m██████▌   [0m| 17/26 [00:17<00:08,  1.10it/s]Epoch: 1/10. Loss: 1.0594:  69%|[36m██████▉   [0m| 18/26 [00:17<00:07,  1.12it/s]Epoch: 1/10. Loss: 0.9632:  69%|[36m██████▉   [0m| 18/26 [00:18<00:07,  1.12it/s]Epoch: 1/10. Loss: 0.9632:  73%|[36m███████▎  [0m| 19/26 [00:18<00:06,  1.07it/s]Epoch: 1/10. Loss: 1.0498:  73%|[36m███████▎  [0m| 19/26 [00:19<00:06,  1.07it/s]Epoch: 1/10. Loss: 1.0498:  77%|[36m███████▋  [0m| 20/26 [00:19<00:05,  1.08it/s]Epoch: 1/10. Loss: 1.0320:  77%|[36m███████▋  [0m| 20/26 [00:20<00:05,  1.08it/s]Epoch: 1/10. Loss: 1.0320:  81%|[36m████████  [0m| 21/26 [00:20<00:04,  1.06it/s]Epoch: 1/10. Loss: 1.0208:  81%|[36m████████  [0m| 21/26 [00:21<00:04,  1.06it/s]Epoch: 1/10. Loss: 1.0208:  85%|[36m████████▍ [0m| 22/26 [00:21<00:03,  1.05it/s]Epoch: 1/10. Loss: 1.0601:  85%|[36m████████▍ [0m| 22/26 [00:22<00:03,  1.05it/s]Epoch: 1/10. Loss: 1.0601:  88%|[36m████████▊ [0m| 23/26 [00:22<00:02,  1.03it/s]Epoch: 1/10. Loss: 1.0181:  88%|[36m████████▊ [0m| 23/26 [00:22<00:02,  1.03it/s]Epoch: 1/10. Loss: 1.0181:  92%|[36m█████████▏[0m| 24/26 [00:22<00:01,  1.09it/s]Epoch: 1/10. Loss: 1.0304:  92%|[36m█████████▏[0m| 24/26 [00:23<00:01,  1.09it/s]Epoch: 1/10. Loss: 1.0304:  96%|[36m█████████▌[0m| 25/26 [00:23<00:00,  1.16it/s]Epoch: 1/10. Loss: 1.0723:  96%|[36m█████████▌[0m| 25/26 [00:24<00:00,  1.16it/s]Epoch: 1/10. Loss: 1.0723: 100%|[36m██████████[0m| 26/26 [00:24<00:00,  1.25it/s]Epoch: 1/10. Loss: 1.0723: 100%|[36m██████████[0m| 26/26 [00:24<00:00,  1.07it/s]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:04,  1.27it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:05,  1.11s/it] 43%|[33m████▎     [0m| 3/7 [00:02<00:03,  1.21it/s] 57%|[33m█████▋    [0m| 4/7 [00:03<00:03,  1.02s/it] 71%|[33m███████▏  [0m| 5/7 [00:04<00:01,  1.26it/s] 86%|[33m████████▌ [0m| 6/7 [00:05<00:00,  1.07it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.37it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.20it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 2/10. Loss: 0.9989:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 2/10. Loss: 0.9989:   4%|[36m▍         [0m| 1/26 [00:01<00:25,  1.00s/it]Epoch: 2/10. Loss: 0.9943:   4%|[36m▍         [0m| 1/26 [00:01<00:25,  1.00s/it]Epoch: 2/10. Loss: 0.9943:   8%|[36m▊         [0m| 2/26 [00:01<00:23,  1.04it/s]Epoch: 2/10. Loss: 0.9907:   8%|[36m▊         [0m| 2/26 [00:02<00:23,  1.04it/s]Epoch: 2/10. Loss: 0.9907:  12%|[36m█▏        [0m| 3/26 [00:02<00:23,  1.00s/it]Epoch: 2/10. Loss: 0.9620:  12%|[36m█▏        [0m| 3/26 [00:04<00:23,  1.00s/it]Epoch: 2/10. Loss: 0.9620:  15%|[36m█▌        [0m| 4/26 [00:04<00:22,  1.01s/it]Epoch: 2/10. Loss: 0.9925:  15%|[36m█▌        [0m| 4/26 [00:04<00:22,  1.01s/it]Epoch: 2/10. Loss: 0.9925:  19%|[36m█▉        [0m| 5/26 [00:04<00:20,  1.05it/s]Epoch: 2/10. Loss: 0.9970:  19%|[36m█▉        [0m| 5/26 [00:05<00:20,  1.05it/s]Epoch: 2/10. Loss: 0.9970:  23%|[36m██▎       [0m| 6/26 [00:05<00:18,  1.09it/s]Epoch: 2/10. Loss: 0.9904:  23%|[36m██▎       [0m| 6/26 [00:06<00:18,  1.09it/s]Epoch: 2/10. Loss: 0.9904:  27%|[36m██▋       [0m| 7/26 [00:06<00:16,  1.15it/s]Epoch: 2/10. Loss: 1.0004:  27%|[36m██▋       [0m| 7/26 [00:07<00:16,  1.15it/s]Epoch: 2/10. Loss: 1.0004:  31%|[36m███       [0m| 8/26 [00:07<00:15,  1.15it/s]Epoch: 2/10. Loss: 1.0242:  31%|[36m███       [0m| 8/26 [00:08<00:15,  1.15it/s]Epoch: 2/10. Loss: 1.0242:  35%|[36m███▍      [0m| 9/26 [00:08<00:16,  1.05it/s]Epoch: 2/10. Loss: 1.0378:  35%|[36m███▍      [0m| 9/26 [00:09<00:16,  1.05it/s]Epoch: 2/10. Loss: 1.0378:  38%|[36m███▊      [0m| 10/26 [00:09<00:14,  1.09it/s]Epoch: 2/10. Loss: 0.9468:  38%|[36m███▊      [0m| 10/26 [00:10<00:14,  1.09it/s]Epoch: 2/10. Loss: 0.9468:  42%|[36m████▏     [0m| 11/26 [00:10<00:13,  1.08it/s]Epoch: 2/10. Loss: 0.9922:  42%|[36m████▏     [0m| 11/26 [00:11<00:13,  1.08it/s]Epoch: 2/10. Loss: 0.9922:  46%|[36m████▌     [0m| 12/26 [00:11<00:16,  1.16s/it]Epoch: 2/10. Loss: 0.9644:  46%|[36m████▌     [0m| 12/26 [00:12<00:16,  1.16s/it]Epoch: 2/10. Loss: 0.9644:  50%|[36m█████     [0m| 13/26 [00:12<00:13,  1.04s/it]Epoch: 2/10. Loss: 0.9841:  50%|[36m█████     [0m| 13/26 [00:13<00:13,  1.04s/it]Epoch: 2/10. Loss: 0.9841:  54%|[36m█████▍    [0m| 14/26 [00:13<00:12,  1.02s/it]Epoch: 2/10. Loss: 1.0433:  54%|[36m█████▍    [0m| 14/26 [00:14<00:12,  1.02s/it]Epoch: 2/10. Loss: 1.0433:  58%|[36m█████▊    [0m| 15/26 [00:14<00:10,  1.01it/s]Epoch: 2/10. Loss: 1.0856:  58%|[36m█████▊    [0m| 15/26 [00:15<00:10,  1.01it/s]Epoch: 2/10. Loss: 1.0856:  62%|[36m██████▏   [0m| 16/26 [00:15<00:10,  1.00s/it]Epoch: 2/10. Loss: 1.0657:  62%|[36m██████▏   [0m| 16/26 [00:17<00:10,  1.00s/it]Epoch: 2/10. Loss: 1.0657:  65%|[36m██████▌   [0m| 17/26 [00:17<00:10,  1.20s/it]Epoch: 2/10. Loss: 0.9916:  65%|[36m██████▌   [0m| 17/26 [00:18<00:10,  1.20s/it]Epoch: 2/10. Loss: 0.9916:  69%|[36m██████▉   [0m| 18/26 [00:18<00:08,  1.09s/it]Epoch: 2/10. Loss: 1.0624:  69%|[36m██████▉   [0m| 18/26 [00:19<00:08,  1.09s/it]Epoch: 2/10. Loss: 1.0624:  73%|[36m███████▎  [0m| 19/26 [00:19<00:07,  1.07s/it]Epoch: 2/10. Loss: 1.0123:  73%|[36m███████▎  [0m| 19/26 [00:20<00:07,  1.07s/it]Epoch: 2/10. Loss: 1.0123:  77%|[36m███████▋  [0m| 20/26 [00:20<00:06,  1.06s/it]Epoch: 2/10. Loss: 1.0162:  77%|[36m███████▋  [0m| 20/26 [00:21<00:06,  1.06s/it]Epoch: 2/10. Loss: 1.0162:  81%|[36m████████  [0m| 21/26 [00:21<00:05,  1.01s/it]Epoch: 2/10. Loss: 1.0406:  81%|[36m████████  [0m| 21/26 [00:22<00:05,  1.01s/it]Epoch: 2/10. Loss: 1.0406:  85%|[36m████████▍ [0m| 22/26 [00:22<00:05,  1.25s/it]Epoch: 2/10. Loss: 1.0469:  85%|[36m████████▍ [0m| 22/26 [00:24<00:05,  1.25s/it]Epoch: 2/10. Loss: 1.0469:  88%|[36m████████▊ [0m| 23/26 [00:24<00:03,  1.22s/it]Epoch: 2/10. Loss: 1.0396:  88%|[36m████████▊ [0m| 23/26 [00:25<00:03,  1.22s/it]Epoch: 2/10. Loss: 1.0396:  92%|[36m█████████▏[0m| 24/26 [00:25<00:02,  1.25s/it]Epoch: 2/10. Loss: 1.0472:  92%|[36m█████████▏[0m| 24/26 [00:26<00:02,  1.25s/it]Epoch: 2/10. Loss: 1.0472:  96%|[36m█████████▌[0m| 25/26 [00:26<00:01,  1.16s/it]Epoch: 2/10. Loss: 1.0736:  96%|[36m█████████▌[0m| 25/26 [00:26<00:01,  1.16s/it]Epoch: 2/10. Loss: 1.0736: 100%|[36m██████████[0m| 26/26 [00:26<00:00,  1.02it/s]Epoch: 2/10. Loss: 1.0736: 100%|[36m██████████[0m| 26/26 [00:26<00:00,  1.03s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:04,  1.23it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:06,  1.21s/it] 43%|[33m████▎     [0m| 3/7 [00:02<00:03,  1.11it/s] 57%|[33m█████▋    [0m| 4/7 [00:05<00:04,  1.63s/it] 71%|[33m███████▏  [0m| 5/7 [00:08<00:04,  2.06s/it] 86%|[33m████████▌ [0m| 6/7 [00:09<00:01,  1.66s/it]100%|[33m██████████[0m| 7/7 [00:10<00:00,  1.65s/it]100%|[33m██████████[0m| 7/7 [00:10<00:00,  1.56s/it]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 3/10. Loss: 1.0248:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 3/10. Loss: 1.0248:   4%|[36m▍         [0m| 1/26 [00:00<00:24,  1.02it/s]Epoch: 3/10. Loss: 1.0100:   4%|[36m▍         [0m| 1/26 [00:01<00:24,  1.02it/s]Epoch: 3/10. Loss: 1.0100:   8%|[36m▊         [0m| 2/26 [00:01<00:22,  1.08it/s]Epoch: 3/10. Loss: 1.0371:   8%|[36m▊         [0m| 2/26 [00:02<00:22,  1.08it/s]Epoch: 3/10. Loss: 1.0371:  12%|[36m█▏        [0m| 3/26 [00:02<00:21,  1.08it/s]Epoch: 3/10. Loss: 1.0090:  12%|[36m█▏        [0m| 3/26 [00:03<00:21,  1.08it/s]Epoch: 3/10. Loss: 1.0090:  15%|[36m█▌        [0m| 4/26 [00:03<00:19,  1.12it/s]Epoch: 3/10. Loss: 1.0215:  15%|[36m█▌        [0m| 4/26 [00:04<00:19,  1.12it/s]Epoch: 3/10. Loss: 1.0215:  19%|[36m█▉        [0m| 5/26 [00:04<00:19,  1.09it/s]Epoch: 3/10. Loss: 1.0278:  19%|[36m█▉        [0m| 5/26 [00:05<00:19,  1.09it/s]Epoch: 3/10. Loss: 1.0278:  23%|[36m██▎       [0m| 6/26 [00:05<00:17,  1.16it/s]Epoch: 3/10. Loss: 1.0628:  23%|[36m██▎       [0m| 6/26 [00:06<00:17,  1.16it/s]Epoch: 3/10. Loss: 1.0628:  27%|[36m██▋       [0m| 7/26 [00:06<00:16,  1.17it/s]Epoch: 3/10. Loss: 0.9859:  27%|[36m██▋       [0m| 7/26 [00:07<00:16,  1.17it/s]Epoch: 3/10. Loss: 0.9859:  31%|[36m███       [0m| 8/26 [00:07<00:15,  1.16it/s]Epoch: 3/10. Loss: 1.0085:  31%|[36m███       [0m| 8/26 [00:08<00:15,  1.16it/s]Epoch: 3/10. Loss: 1.0085:  35%|[36m███▍      [0m| 9/26 [00:08<00:15,  1.13it/s]Epoch: 3/10. Loss: 1.0400:  35%|[36m███▍      [0m| 9/26 [00:10<00:15,  1.13it/s]Epoch: 3/10. Loss: 1.0400:  38%|[36m███▊      [0m| 10/26 [00:10<00:19,  1.25s/it]Epoch: 3/10. Loss: 1.0551:  38%|[36m███▊      [0m| 10/26 [00:10<00:19,  1.25s/it]Epoch: 3/10. Loss: 1.0551:  42%|[36m████▏     [0m| 11/26 [00:10<00:17,  1.15s/it]Epoch: 3/10. Loss: 0.9768:  42%|[36m████▏     [0m| 11/26 [00:11<00:17,  1.15s/it]Epoch: 3/10. Loss: 0.9768:  46%|[36m████▌     [0m| 12/26 [00:11<00:15,  1.07s/it]Epoch: 3/10. Loss: 0.9832:  46%|[36m████▌     [0m| 12/26 [00:14<00:15,  1.07s/it]Epoch: 3/10. Loss: 0.9832:  50%|[36m█████     [0m| 13/26 [00:14<00:18,  1.39s/it]Epoch: 3/10. Loss: 1.0402:  50%|[36m█████     [0m| 13/26 [00:14<00:18,  1.39s/it]Epoch: 3/10. Loss: 1.0402:  54%|[36m█████▍    [0m| 14/26 [00:14<00:14,  1.23s/it]Epoch: 3/10. Loss: 0.9641:  54%|[36m█████▍    [0m| 14/26 [00:16<00:14,  1.23s/it]Epoch: 3/10. Loss: 0.9641:  58%|[36m█████▊    [0m| 15/26 [00:16<00:14,  1.32s/it]Epoch: 3/10. Loss: 0.9980:  58%|[36m█████▊    [0m| 15/26 [00:17<00:14,  1.32s/it]Epoch: 3/10. Loss: 0.9980:  62%|[36m██████▏   [0m| 16/26 [00:17<00:11,  1.18s/it]Epoch: 3/10. Loss: 0.9983:  62%|[36m██████▏   [0m| 16/26 [00:18<00:11,  1.18s/it]Epoch: 3/10. Loss: 0.9983:  65%|[36m██████▌   [0m| 17/26 [00:18<00:09,  1.07s/it]Epoch: 3/10. Loss: 1.1042:  65%|[36m██████▌   [0m| 17/26 [00:19<00:09,  1.07s/it]Epoch: 3/10. Loss: 1.1042:  69%|[36m██████▉   [0m| 18/26 [00:19<00:08,  1.06s/it]Epoch: 3/10. Loss: 1.0522:  69%|[36m██████▉   [0m| 18/26 [00:19<00:08,  1.06s/it]Epoch: 3/10. Loss: 1.0522:  73%|[36m███████▎  [0m| 19/26 [00:19<00:06,  1.00it/s]Epoch: 3/10. Loss: 1.0127:  73%|[36m███████▎  [0m| 19/26 [00:20<00:06,  1.00it/s]Epoch: 3/10. Loss: 1.0127:  77%|[36m███████▋  [0m| 20/26 [00:20<00:05,  1.09it/s]Epoch: 3/10. Loss: 1.0127:  77%|[36m███████▋  [0m| 20/26 [00:21<00:05,  1.09it/s]Epoch: 3/10. Loss: 1.0127:  81%|[36m████████  [0m| 21/26 [00:21<00:04,  1.09it/s]Epoch: 3/10. Loss: 1.0600:  81%|[36m████████  [0m| 21/26 [00:22<00:04,  1.09it/s]Epoch: 3/10. Loss: 1.0600:  85%|[36m████████▍ [0m| 22/26 [00:22<00:03,  1.08it/s]Epoch: 3/10. Loss: 0.9796:  85%|[36m████████▍ [0m| 22/26 [00:23<00:03,  1.08it/s]Epoch: 3/10. Loss: 0.9796:  88%|[36m████████▊ [0m| 23/26 [00:23<00:03,  1.00s/it]Epoch: 3/10. Loss: 1.0319:  88%|[36m████████▊ [0m| 23/26 [00:24<00:03,  1.00s/it]Epoch: 3/10. Loss: 1.0319:  92%|[36m█████████▏[0m| 24/26 [00:24<00:02,  1.04s/it]Epoch: 3/10. Loss: 1.0464:  92%|[36m█████████▏[0m| 24/26 [00:26<00:02,  1.04s/it]Epoch: 3/10. Loss: 1.0464:  96%|[36m█████████▌[0m| 25/26 [00:26<00:01,  1.30s/it]Epoch: 3/10. Loss: 0.9378:  96%|[36m█████████▌[0m| 25/26 [00:30<00:01,  1.30s/it]Epoch: 3/10. Loss: 0.9378: 100%|[36m██████████[0m| 26/26 [00:30<00:00,  1.90s/it]Epoch: 3/10. Loss: 0.9378: 100%|[36m██████████[0m| 26/26 [00:30<00:00,  1.16s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:01<00:06,  1.12s/it] 29%|[33m██▊       [0m| 2/7 [00:03<00:08,  1.78s/it] 43%|[33m████▎     [0m| 3/7 [00:03<00:04,  1.22s/it] 57%|[33m█████▋    [0m| 4/7 [00:06<00:05,  1.71s/it] 71%|[33m███████▏  [0m| 5/7 [00:06<00:02,  1.24s/it] 86%|[33m████████▌ [0m| 6/7 [00:08<00:01,  1.35s/it]100%|[33m██████████[0m| 7/7 [00:08<00:00,  1.01s/it]100%|[33m██████████[0m| 7/7 [00:08<00:00,  1.24s/it]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 4/10. Loss: 1.0033:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 4/10. Loss: 1.0033:   4%|[36m▍         [0m| 1/26 [00:00<00:19,  1.27it/s]Epoch: 4/10. Loss: 1.0243:   4%|[36m▍         [0m| 1/26 [00:01<00:19,  1.27it/s]Epoch: 4/10. Loss: 1.0243:   8%|[36m▊         [0m| 2/26 [00:01<00:24,  1.02s/it]Epoch: 4/10. Loss: 0.9978:   8%|[36m▊         [0m| 2/26 [00:04<00:24,  1.02s/it]Epoch: 4/10. Loss: 0.9978:  12%|[36m█▏        [0m| 3/26 [00:04<00:43,  1.88s/it]Epoch: 4/10. Loss: 1.0328:  12%|[36m█▏        [0m| 3/26 [00:05<00:43,  1.88s/it]Epoch: 4/10. Loss: 1.0328:  15%|[36m█▌        [0m| 4/26 [00:05<00:33,  1.52s/it]Epoch: 4/10. Loss: 1.0066:  15%|[36m█▌        [0m| 4/26 [00:06<00:33,  1.52s/it]Epoch: 4/10. Loss: 1.0066:  19%|[36m█▉        [0m| 5/26 [00:06<00:26,  1.25s/it]Epoch: 4/10. Loss: 1.0270:  19%|[36m█▉        [0m| 5/26 [00:08<00:26,  1.25s/it]Epoch: 4/10. Loss: 1.0270:  23%|[36m██▎       [0m| 6/26 [00:08<00:28,  1.44s/it]Epoch: 4/10. Loss: 0.9809:  23%|[36m██▎       [0m| 6/26 [00:09<00:28,  1.44s/it]Epoch: 4/10. Loss: 0.9809:  27%|[36m██▋       [0m| 7/26 [00:09<00:23,  1.25s/it]Epoch: 4/10. Loss: 1.0855:  27%|[36m██▋       [0m| 7/26 [00:10<00:23,  1.25s/it]Epoch: 4/10. Loss: 1.0855:  31%|[36m███       [0m| 8/26 [00:10<00:20,  1.11s/it]Epoch: 4/10. Loss: 1.0665:  31%|[36m███       [0m| 8/26 [00:10<00:20,  1.11s/it]Epoch: 4/10. Loss: 1.0665:  35%|[36m███▍      [0m| 9/26 [00:10<00:17,  1.04s/it]Epoch: 4/10. Loss: 1.0149:  35%|[36m███▍      [0m| 9/26 [00:11<00:17,  1.04s/it]Epoch: 4/10. Loss: 1.0149:  38%|[36m███▊      [0m| 10/26 [00:11<00:15,  1.01it/s]Epoch: 4/10. Loss: 0.9993:  38%|[36m███▊      [0m| 10/26 [00:12<00:15,  1.01it/s]Epoch: 4/10. Loss: 0.9993:  42%|[36m████▏     [0m| 11/26 [00:12<00:14,  1.03it/s]Epoch: 4/10. Loss: 0.9584:  42%|[36m████▏     [0m| 11/26 [00:13<00:14,  1.03it/s]Epoch: 4/10. Loss: 0.9584:  46%|[36m████▌     [0m| 12/26 [00:13<00:12,  1.12it/s]Epoch: 4/10. Loss: 1.0668:  46%|[36m████▌     [0m| 12/26 [00:16<00:12,  1.12it/s]Epoch: 4/10. Loss: 1.0668:  50%|[36m█████     [0m| 13/26 [00:16<00:18,  1.43s/it]Epoch: 4/10. Loss: 1.0252:  50%|[36m█████     [0m| 13/26 [00:17<00:18,  1.43s/it]Epoch: 4/10. Loss: 1.0252:  54%|[36m█████▍    [0m| 14/26 [00:17<00:15,  1.32s/it]Epoch: 4/10. Loss: 1.0172:  54%|[36m█████▍    [0m| 14/26 [00:18<00:15,  1.32s/it]Epoch: 4/10. Loss: 1.0172:  58%|[36m█████▊    [0m| 15/26 [00:18<00:13,  1.25s/it]Epoch: 4/10. Loss: 0.9973:  58%|[36m█████▊    [0m| 15/26 [00:19<00:13,  1.25s/it]Epoch: 4/10. Loss: 0.9973:  62%|[36m██████▏   [0m| 16/26 [00:19<00:11,  1.19s/it]Epoch: 4/10. Loss: 0.9689:  62%|[36m██████▏   [0m| 16/26 [00:20<00:11,  1.19s/it]Epoch: 4/10. Loss: 0.9689:  65%|[36m██████▌   [0m| 17/26 [00:20<00:10,  1.12s/it]Epoch: 4/10. Loss: 1.0003:  65%|[36m██████▌   [0m| 17/26 [00:21<00:10,  1.12s/it]Epoch: 4/10. Loss: 1.0003:  69%|[36m██████▉   [0m| 18/26 [00:21<00:08,  1.09s/it]Epoch: 4/10. Loss: 1.0437:  69%|[36m██████▉   [0m| 18/26 [00:22<00:08,  1.09s/it]Epoch: 4/10. Loss: 1.0437:  73%|[36m███████▎  [0m| 19/26 [00:22<00:07,  1.02s/it]Epoch: 4/10. Loss: 0.9821:  73%|[36m███████▎  [0m| 19/26 [00:22<00:07,  1.02s/it]Epoch: 4/10. Loss: 0.9821:  77%|[36m███████▋  [0m| 20/26 [00:23<00:05,  1.05it/s]Epoch: 4/10. Loss: 1.0074:  77%|[36m███████▋  [0m| 20/26 [00:24<00:05,  1.05it/s]Epoch: 4/10. Loss: 1.0074:  81%|[36m████████  [0m| 21/26 [00:24<00:05,  1.02s/it]Epoch: 4/10. Loss: 1.0201:  81%|[36m████████  [0m| 21/26 [00:25<00:05,  1.02s/it]Epoch: 4/10. Loss: 1.0201:  85%|[36m████████▍ [0m| 22/26 [00:25<00:04,  1.04s/it]Epoch: 4/10. Loss: 0.9931:  85%|[36m████████▍ [0m| 22/26 [00:26<00:04,  1.04s/it]Epoch: 4/10. Loss: 0.9931:  88%|[36m████████▊ [0m| 23/26 [00:26<00:03,  1.24s/it]Epoch: 4/10. Loss: 1.0316:  88%|[36m████████▊ [0m| 23/26 [00:28<00:03,  1.24s/it]Epoch: 4/10. Loss: 1.0316:  92%|[36m█████████▏[0m| 24/26 [00:28<00:02,  1.34s/it]Epoch: 4/10. Loss: 1.0152:  92%|[36m█████████▏[0m| 24/26 [00:29<00:02,  1.34s/it]Epoch: 4/10. Loss: 1.0152:  96%|[36m█████████▌[0m| 25/26 [00:29<00:01,  1.18s/it]Epoch: 4/10. Loss: 0.9662:  96%|[36m█████████▌[0m| 25/26 [00:29<00:01,  1.18s/it]Epoch: 4/10. Loss: 0.9662: 100%|[36m██████████[0m| 26/26 [00:29<00:00,  1.02it/s]Epoch: 4/10. Loss: 0.9662: 100%|[36m██████████[0m| 26/26 [00:29<00:00,  1.15s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:01<00:07,  1.30s/it] 29%|[33m██▊       [0m| 2/7 [00:02<00:06,  1.35s/it] 43%|[33m████▎     [0m| 3/7 [00:03<00:03,  1.03it/s] 57%|[33m█████▋    [0m| 4/7 [00:04<00:03,  1.20s/it] 71%|[33m███████▏  [0m| 5/7 [00:05<00:01,  1.09it/s] 86%|[33m████████▌ [0m| 6/7 [00:06<00:00,  1.11it/s]100%|[33m██████████[0m| 7/7 [00:06<00:00,  1.36it/s]100%|[33m██████████[0m| 7/7 [00:06<00:00,  1.09it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 5/10. Loss: 1.0723:   0%|[36m          [0m| 0/26 [00:01<?, ?it/s]Epoch: 5/10. Loss: 1.0723:   4%|[36m▍         [0m| 1/26 [00:01<00:49,  1.99s/it]Epoch: 5/10. Loss: 0.9886:   4%|[36m▍         [0m| 1/26 [00:03<00:49,  1.99s/it]Epoch: 5/10. Loss: 0.9886:   8%|[36m▊         [0m| 2/26 [00:03<00:34,  1.44s/it]Epoch: 5/10. Loss: 1.0253:   8%|[36m▊         [0m| 2/26 [00:03<00:34,  1.44s/it]Epoch: 5/10. Loss: 1.0253:  12%|[36m█▏        [0m| 3/26 [00:03<00:27,  1.19s/it]Epoch: 5/10. Loss: 0.9826:  12%|[36m█▏        [0m| 3/26 [00:05<00:27,  1.19s/it]Epoch: 5/10. Loss: 0.9826:  15%|[36m█▌        [0m| 4/26 [00:05<00:26,  1.18s/it]Epoch: 5/10. Loss: 1.0370:  15%|[36m█▌        [0m| 4/26 [00:06<00:26,  1.18s/it]Epoch: 5/10. Loss: 1.0370:  19%|[36m█▉        [0m| 5/26 [00:06<00:23,  1.10s/it]Epoch: 5/10. Loss: 1.0151:  19%|[36m█▉        [0m| 5/26 [00:06<00:23,  1.10s/it]Epoch: 5/10. Loss: 1.0151:  23%|[36m██▎       [0m| 6/26 [00:06<00:20,  1.02s/it]Epoch: 5/10. Loss: 0.9758:  23%|[36m██▎       [0m| 6/26 [00:08<00:20,  1.02s/it]Epoch: 5/10. Loss: 0.9758:  27%|[36m██▋       [0m| 7/26 [00:08<00:20,  1.10s/it]Epoch: 5/10. Loss: 1.0314:  27%|[36m██▋       [0m| 7/26 [00:09<00:20,  1.10s/it]Epoch: 5/10. Loss: 1.0314:  31%|[36m███       [0m| 8/26 [00:09<00:18,  1.04s/it]Epoch: 5/10. Loss: 0.9751:  31%|[36m███       [0m| 8/26 [00:10<00:18,  1.04s/it]Epoch: 5/10. Loss: 0.9751:  35%|[36m███▍      [0m| 9/26 [00:10<00:17,  1.02s/it]Epoch: 5/10. Loss: 1.0404:  35%|[36m███▍      [0m| 9/26 [00:11<00:17,  1.02s/it]Epoch: 5/10. Loss: 1.0404:  38%|[36m███▊      [0m| 10/26 [00:11<00:16,  1.05s/it]Epoch: 5/10. Loss: 1.0131:  38%|[36m███▊      [0m| 10/26 [00:12<00:16,  1.05s/it]Epoch: 5/10. Loss: 1.0131:  42%|[36m████▏     [0m| 11/26 [00:12<00:15,  1.01s/it]Epoch: 5/10. Loss: 1.0129:  42%|[36m████▏     [0m| 11/26 [00:13<00:15,  1.01s/it]Epoch: 5/10. Loss: 1.0129:  46%|[36m████▌     [0m| 12/26 [00:13<00:14,  1.05s/it]Epoch: 5/10. Loss: 0.9819:  46%|[36m████▌     [0m| 12/26 [00:14<00:14,  1.05s/it]Epoch: 5/10. Loss: 0.9819:  50%|[36m█████     [0m| 13/26 [00:14<00:13,  1.03s/it]Epoch: 5/10. Loss: 1.0015:  50%|[36m█████     [0m| 13/26 [00:15<00:13,  1.03s/it]Epoch: 5/10. Loss: 1.0015:  54%|[36m█████▍    [0m| 14/26 [00:15<00:11,  1.06it/s]Epoch: 5/10. Loss: 1.0725:  54%|[36m█████▍    [0m| 14/26 [00:15<00:11,  1.06it/s]Epoch: 5/10. Loss: 1.0725:  58%|[36m█████▊    [0m| 15/26 [00:15<00:10,  1.10it/s]Epoch: 5/10. Loss: 1.0387:  58%|[36m█████▊    [0m| 15/26 [00:16<00:10,  1.10it/s]Epoch: 5/10. Loss: 1.0387:  62%|[36m██████▏   [0m| 16/26 [00:16<00:08,  1.14it/s]Epoch: 5/10. Loss: 1.0287:  62%|[36m██████▏   [0m| 16/26 [00:17<00:08,  1.14it/s]Epoch: 5/10. Loss: 1.0287:  65%|[36m██████▌   [0m| 17/26 [00:17<00:07,  1.14it/s]Epoch: 5/10. Loss: 1.0126:  65%|[36m██████▌   [0m| 17/26 [00:18<00:07,  1.14it/s]Epoch: 5/10. Loss: 1.0126:  69%|[36m██████▉   [0m| 18/26 [00:18<00:06,  1.16it/s]Epoch: 5/10. Loss: 0.9409:  69%|[36m██████▉   [0m| 18/26 [00:19<00:06,  1.16it/s]Epoch: 5/10. Loss: 0.9409:  73%|[36m███████▎  [0m| 19/26 [00:19<00:06,  1.16it/s]Epoch: 5/10. Loss: 1.0347:  73%|[36m███████▎  [0m| 19/26 [00:20<00:06,  1.16it/s]Epoch: 5/10. Loss: 1.0347:  77%|[36m███████▋  [0m| 20/26 [00:20<00:05,  1.13it/s]Epoch: 5/10. Loss: 1.0165:  77%|[36m███████▋  [0m| 20/26 [00:21<00:05,  1.13it/s]Epoch: 5/10. Loss: 1.0165:  81%|[36m████████  [0m| 21/26 [00:21<00:04,  1.10it/s]Epoch: 5/10. Loss: 1.0322:  81%|[36m████████  [0m| 21/26 [00:21<00:04,  1.10it/s]Epoch: 5/10. Loss: 1.0322:  85%|[36m████████▍ [0m| 22/26 [00:21<00:03,  1.12it/s]Epoch: 5/10. Loss: 1.0003:  85%|[36m████████▍ [0m| 22/26 [00:23<00:03,  1.12it/s]Epoch: 5/10. Loss: 1.0003:  88%|[36m████████▊ [0m| 23/26 [00:23<00:02,  1.05it/s]Epoch: 5/10. Loss: 1.0440:  88%|[36m████████▊ [0m| 23/26 [00:23<00:02,  1.05it/s]Epoch: 5/10. Loss: 1.0440:  92%|[36m█████████▏[0m| 24/26 [00:23<00:01,  1.09it/s]Epoch: 5/10. Loss: 0.9952:  92%|[36m█████████▏[0m| 24/26 [00:28<00:01,  1.09it/s]Epoch: 5/10. Loss: 0.9952:  96%|[36m█████████▌[0m| 25/26 [00:28<00:01,  1.93s/it]Epoch: 5/10. Loss: 0.9744:  96%|[36m█████████▌[0m| 25/26 [00:28<00:01,  1.93s/it]Epoch: 5/10. Loss: 0.9744: 100%|[36m██████████[0m| 26/26 [00:28<00:00,  1.59s/it]Epoch: 5/10. Loss: 0.9744: 100%|[36m██████████[0m| 26/26 [00:28<00:00,  1.11s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:05,  1.18it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:06,  1.26s/it] 43%|[33m████▎     [0m| 3/7 [00:02<00:03,  1.08it/s] 57%|[33m█████▋    [0m| 4/7 [00:04<00:03,  1.10s/it] 71%|[33m███████▏  [0m| 5/7 [00:04<00:01,  1.17it/s] 86%|[33m████████▌ [0m| 6/7 [00:05<00:00,  1.15it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.46it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.19it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 6/10. Loss: 1.0114:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 6/10. Loss: 1.0114:   4%|[36m▍         [0m| 1/26 [00:00<00:23,  1.04it/s]Epoch: 6/10. Loss: 0.9817:   4%|[36m▍         [0m| 1/26 [00:02<00:23,  1.04it/s]Epoch: 6/10. Loss: 0.9817:   8%|[36m▊         [0m| 2/26 [00:02<00:26,  1.11s/it]Epoch: 6/10. Loss: 0.9830:   8%|[36m▊         [0m| 2/26 [00:03<00:26,  1.11s/it]Epoch: 6/10. Loss: 0.9830:  12%|[36m█▏        [0m| 3/26 [00:03<00:23,  1.02s/it]Epoch: 6/10. Loss: 0.9986:  12%|[36m█▏        [0m| 3/26 [00:04<00:23,  1.02s/it]Epoch: 6/10. Loss: 0.9986:  15%|[36m█▌        [0m| 4/26 [00:04<00:22,  1.01s/it]Epoch: 6/10. Loss: 0.9629:  15%|[36m█▌        [0m| 4/26 [00:04<00:22,  1.01s/it]Epoch: 6/10. Loss: 0.9629:  19%|[36m█▉        [0m| 5/26 [00:04<00:19,  1.06it/s]Epoch: 6/10. Loss: 1.0495:  19%|[36m█▉        [0m| 5/26 [00:06<00:19,  1.06it/s]Epoch: 6/10. Loss: 1.0495:  23%|[36m██▎       [0m| 6/26 [00:06<00:20,  1.01s/it]Epoch: 6/10. Loss: 0.9981:  23%|[36m██▎       [0m| 6/26 [00:07<00:20,  1.01s/it]Epoch: 6/10. Loss: 0.9981:  27%|[36m██▋       [0m| 7/26 [00:07<00:18,  1.00it/s]Epoch: 6/10. Loss: 1.0492:  27%|[36m██▋       [0m| 7/26 [00:07<00:18,  1.00it/s]Epoch: 6/10. Loss: 1.0492:  31%|[36m███       [0m| 8/26 [00:07<00:16,  1.12it/s]Epoch: 6/10. Loss: 1.0482:  31%|[36m███       [0m| 8/26 [00:08<00:16,  1.12it/s]Epoch: 6/10. Loss: 1.0482:  35%|[36m███▍      [0m| 9/26 [00:08<00:15,  1.12it/s]Epoch: 6/10. Loss: 1.0071:  35%|[36m███▍      [0m| 9/26 [00:09<00:15,  1.12it/s]Epoch: 6/10. Loss: 1.0071:  38%|[36m███▊      [0m| 10/26 [00:09<00:14,  1.09it/s]Epoch: 6/10. Loss: 0.9639:  38%|[36m███▊      [0m| 10/26 [00:10<00:14,  1.09it/s]Epoch: 6/10. Loss: 0.9639:  42%|[36m████▏     [0m| 11/26 [00:10<00:13,  1.13it/s]Epoch: 6/10. Loss: 1.0522:  42%|[36m████▏     [0m| 11/26 [00:11<00:13,  1.13it/s]Epoch: 6/10. Loss: 1.0522:  46%|[36m████▌     [0m| 12/26 [00:11<00:12,  1.11it/s]Epoch: 6/10. Loss: 1.0001:  46%|[36m████▌     [0m| 12/26 [00:12<00:12,  1.11it/s]Epoch: 6/10. Loss: 1.0001:  50%|[36m█████     [0m| 13/26 [00:12<00:11,  1.15it/s]Epoch: 6/10. Loss: 1.0798:  50%|[36m█████     [0m| 13/26 [00:12<00:11,  1.15it/s]Epoch: 6/10. Loss: 1.0798:  54%|[36m█████▍    [0m| 14/26 [00:12<00:10,  1.19it/s]Epoch: 6/10. Loss: 1.0485:  54%|[36m█████▍    [0m| 14/26 [00:13<00:10,  1.19it/s]Epoch: 6/10. Loss: 1.0485:  58%|[36m█████▊    [0m| 15/26 [00:13<00:08,  1.23it/s]Epoch: 6/10. Loss: 1.0471:  58%|[36m█████▊    [0m| 15/26 [00:15<00:08,  1.23it/s]Epoch: 6/10. Loss: 1.0471:  62%|[36m██████▏   [0m| 16/26 [00:15<00:09,  1.01it/s]Epoch: 6/10. Loss: 0.9854:  62%|[36m██████▏   [0m| 16/26 [00:15<00:09,  1.01it/s]Epoch: 6/10. Loss: 0.9854:  65%|[36m██████▌   [0m| 17/26 [00:15<00:08,  1.06it/s]Epoch: 6/10. Loss: 1.0735:  65%|[36m██████▌   [0m| 17/26 [00:16<00:08,  1.06it/s]Epoch: 6/10. Loss: 1.0735:  69%|[36m██████▉   [0m| 18/26 [00:16<00:07,  1.05it/s]Epoch: 6/10. Loss: 0.9651:  69%|[36m██████▉   [0m| 18/26 [00:17<00:07,  1.05it/s]Epoch: 6/10. Loss: 0.9651:  73%|[36m███████▎  [0m| 19/26 [00:17<00:06,  1.07it/s]Epoch: 6/10. Loss: 1.0499:  73%|[36m███████▎  [0m| 19/26 [00:18<00:06,  1.07it/s]Epoch: 6/10. Loss: 1.0499:  77%|[36m███████▋  [0m| 20/26 [00:18<00:05,  1.05it/s]Epoch: 6/10. Loss: 1.0211:  77%|[36m███████▋  [0m| 20/26 [00:19<00:05,  1.05it/s]Epoch: 6/10. Loss: 1.0211:  81%|[36m████████  [0m| 21/26 [00:19<00:04,  1.05it/s]Epoch: 6/10. Loss: 1.0470:  81%|[36m████████  [0m| 21/26 [00:20<00:04,  1.05it/s]Epoch: 6/10. Loss: 1.0470:  85%|[36m████████▍ [0m| 22/26 [00:20<00:03,  1.06it/s]Epoch: 6/10. Loss: 1.0339:  85%|[36m████████▍ [0m| 22/26 [00:21<00:03,  1.06it/s]Epoch: 6/10. Loss: 1.0339:  88%|[36m████████▊ [0m| 23/26 [00:21<00:02,  1.14it/s]Epoch: 6/10. Loss: 0.9868:  88%|[36m████████▊ [0m| 23/26 [00:22<00:02,  1.14it/s]Epoch: 6/10. Loss: 0.9868:  92%|[36m█████████▏[0m| 24/26 [00:22<00:01,  1.11it/s]Epoch: 6/10. Loss: 0.9945:  92%|[36m█████████▏[0m| 24/26 [00:23<00:01,  1.11it/s]Epoch: 6/10. Loss: 0.9945:  96%|[36m█████████▌[0m| 25/26 [00:23<00:00,  1.10it/s]Epoch: 6/10. Loss: 0.9533:  96%|[36m█████████▌[0m| 25/26 [00:23<00:00,  1.10it/s]Epoch: 6/10. Loss: 0.9533: 100%|[36m██████████[0m| 26/26 [00:23<00:00,  1.29it/s]Epoch: 6/10. Loss: 0.9533: 100%|[36m██████████[0m| 26/26 [00:23<00:00,  1.10it/s]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:04,  1.21it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:05,  1.17s/it] 43%|[33m████▎     [0m| 3/7 [00:02<00:03,  1.14it/s] 57%|[33m█████▋    [0m| 4/7 [00:04<00:03,  1.06s/it] 71%|[33m███████▏  [0m| 5/7 [00:04<00:01,  1.21it/s] 86%|[33m████████▌ [0m| 6/7 [00:05<00:00,  1.18it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.36it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.18it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 7/10. Loss: 0.9991:   0%|[36m          [0m| 0/26 [00:01<?, ?it/s]Epoch: 7/10. Loss: 0.9991:   4%|[36m▍         [0m| 1/26 [00:01<00:30,  1.24s/it]Epoch: 7/10. Loss: 0.9799:   4%|[36m▍         [0m| 1/26 [00:02<00:30,  1.24s/it]Epoch: 7/10. Loss: 0.9799:   8%|[36m▊         [0m| 2/26 [00:02<00:27,  1.16s/it]Epoch: 7/10. Loss: 1.0484:   8%|[36m▊         [0m| 2/26 [00:03<00:27,  1.16s/it]Epoch: 7/10. Loss: 1.0484:  12%|[36m█▏        [0m| 3/26 [00:03<00:24,  1.07s/it]Epoch: 7/10. Loss: 0.9441:  12%|[36m█▏        [0m| 3/26 [00:04<00:24,  1.07s/it]Epoch: 7/10. Loss: 0.9441:  15%|[36m█▌        [0m| 4/26 [00:04<00:21,  1.05it/s]Epoch: 7/10. Loss: 1.0100:  15%|[36m█▌        [0m| 4/26 [00:04<00:21,  1.05it/s]Epoch: 7/10. Loss: 1.0100:  19%|[36m█▉        [0m| 5/26 [00:04<00:19,  1.10it/s]Epoch: 7/10. Loss: 0.9858:  19%|[36m█▉        [0m| 5/26 [00:05<00:19,  1.10it/s]Epoch: 7/10. Loss: 0.9858:  23%|[36m██▎       [0m| 6/26 [00:05<00:18,  1.07it/s]Epoch: 7/10. Loss: 0.9876:  23%|[36m██▎       [0m| 6/26 [00:06<00:18,  1.07it/s]Epoch: 7/10. Loss: 0.9876:  27%|[36m██▋       [0m| 7/26 [00:06<00:16,  1.12it/s]Epoch: 7/10. Loss: 0.9799:  27%|[36m██▋       [0m| 7/26 [00:07<00:16,  1.12it/s]Epoch: 7/10. Loss: 0.9799:  31%|[36m███       [0m| 8/26 [00:07<00:16,  1.11it/s]Epoch: 7/10. Loss: 1.0722:  31%|[36m███       [0m| 8/26 [00:08<00:16,  1.11it/s]Epoch: 7/10. Loss: 1.0722:  35%|[36m███▍      [0m| 9/26 [00:08<00:15,  1.11it/s]Epoch: 7/10. Loss: 1.0046:  35%|[36m███▍      [0m| 9/26 [00:09<00:15,  1.11it/s]Epoch: 7/10. Loss: 1.0046:  38%|[36m███▊      [0m| 10/26 [00:09<00:14,  1.11it/s]Epoch: 7/10. Loss: 1.0629:  38%|[36m███▊      [0m| 10/26 [00:10<00:14,  1.11it/s]Epoch: 7/10. Loss: 1.0629:  42%|[36m████▏     [0m| 11/26 [00:10<00:13,  1.13it/s]Epoch: 7/10. Loss: 1.0342:  42%|[36m████▏     [0m| 11/26 [00:11<00:13,  1.13it/s]Epoch: 7/10. Loss: 1.0342:  46%|[36m████▌     [0m| 12/26 [00:11<00:12,  1.09it/s]Epoch: 7/10. Loss: 0.9707:  46%|[36m████▌     [0m| 12/26 [00:12<00:12,  1.09it/s]Epoch: 7/10. Loss: 0.9707:  50%|[36m█████     [0m| 13/26 [00:12<00:11,  1.13it/s]Epoch: 7/10. Loss: 1.1121:  50%|[36m█████     [0m| 13/26 [00:12<00:11,  1.13it/s]Epoch: 7/10. Loss: 1.1121:  54%|[36m█████▍    [0m| 14/26 [00:12<00:10,  1.13it/s]Epoch: 7/10. Loss: 1.0202:  54%|[36m█████▍    [0m| 14/26 [00:13<00:10,  1.13it/s]Epoch: 7/10. Loss: 1.0202:  58%|[36m█████▊    [0m| 15/26 [00:13<00:09,  1.14it/s]Epoch: 7/10. Loss: 1.0176:  58%|[36m█████▊    [0m| 15/26 [00:14<00:09,  1.14it/s]Epoch: 7/10. Loss: 1.0176:  62%|[36m██████▏   [0m| 16/26 [00:14<00:09,  1.07it/s]Epoch: 7/10. Loss: 0.9946:  62%|[36m██████▏   [0m| 16/26 [00:16<00:09,  1.07it/s]Epoch: 7/10. Loss: 0.9946:  65%|[36m██████▌   [0m| 17/26 [00:16<00:10,  1.12s/it]Epoch: 7/10. Loss: 1.0230:  65%|[36m██████▌   [0m| 17/26 [00:17<00:10,  1.12s/it]Epoch: 7/10. Loss: 1.0230:  69%|[36m██████▉   [0m| 18/26 [00:17<00:09,  1.20s/it]Epoch: 7/10. Loss: 1.0492:  69%|[36m██████▉   [0m| 18/26 [00:18<00:09,  1.20s/it]Epoch: 7/10. Loss: 1.0492:  73%|[36m███████▎  [0m| 19/26 [00:18<00:07,  1.12s/it]Epoch: 7/10. Loss: 1.0585:  73%|[36m███████▎  [0m| 19/26 [00:19<00:07,  1.12s/it]Epoch: 7/10. Loss: 1.0585:  77%|[36m███████▋  [0m| 20/26 [00:19<00:06,  1.01s/it]Epoch: 7/10. Loss: 1.0081:  77%|[36m███████▋  [0m| 20/26 [00:20<00:06,  1.01s/it]Epoch: 7/10. Loss: 1.0081:  81%|[36m████████  [0m| 21/26 [00:20<00:04,  1.04it/s]Epoch: 7/10. Loss: 1.0168:  81%|[36m████████  [0m| 21/26 [00:21<00:04,  1.04it/s]Epoch: 7/10. Loss: 1.0168:  85%|[36m████████▍ [0m| 22/26 [00:21<00:03,  1.07it/s]Epoch: 7/10. Loss: 0.9980:  85%|[36m████████▍ [0m| 22/26 [00:22<00:03,  1.07it/s]Epoch: 7/10. Loss: 0.9980:  88%|[36m████████▊ [0m| 23/26 [00:22<00:02,  1.12it/s]Epoch: 7/10. Loss: 1.0224:  88%|[36m████████▊ [0m| 23/26 [00:22<00:02,  1.12it/s]Epoch: 7/10. Loss: 1.0224:  92%|[36m█████████▏[0m| 24/26 [00:22<00:01,  1.17it/s]Epoch: 7/10. Loss: 0.9932:  92%|[36m█████████▏[0m| 24/26 [00:24<00:01,  1.17it/s]Epoch: 7/10. Loss: 0.9932:  96%|[36m█████████▌[0m| 25/26 [00:24<00:01,  1.22s/it]Epoch: 7/10. Loss: 1.0313:  96%|[36m█████████▌[0m| 25/26 [00:25<00:01,  1.22s/it]Epoch: 7/10. Loss: 1.0313: 100%|[36m██████████[0m| 26/26 [00:25<00:00,  1.02s/it]Epoch: 7/10. Loss: 1.0313: 100%|[36m██████████[0m| 26/26 [00:25<00:00,  1.02it/s]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:01<00:07,  1.21s/it] 29%|[33m██▊       [0m| 2/7 [00:02<00:06,  1.34s/it] 43%|[33m████▎     [0m| 3/7 [00:03<00:03,  1.04it/s] 57%|[33m█████▋    [0m| 4/7 [00:04<00:03,  1.13s/it] 71%|[33m███████▏  [0m| 5/7 [00:04<00:01,  1.15it/s] 86%|[33m████████▌ [0m| 6/7 [00:05<00:00,  1.17it/s]100%|[33m██████████[0m| 7/7 [00:06<00:00,  1.51it/s]100%|[33m██████████[0m| 7/7 [00:06<00:00,  1.16it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 8/10. Loss: 1.0473:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 8/10. Loss: 1.0473:   4%|[36m▍         [0m| 1/26 [00:00<00:23,  1.08it/s]Epoch: 8/10. Loss: 1.0199:   4%|[36m▍         [0m| 1/26 [00:01<00:23,  1.08it/s]Epoch: 8/10. Loss: 1.0199:   8%|[36m▊         [0m| 2/26 [00:01<00:21,  1.13it/s]Epoch: 8/10. Loss: 1.0106:   8%|[36m▊         [0m| 2/26 [00:02<00:21,  1.13it/s]Epoch: 8/10. Loss: 1.0106:  12%|[36m█▏        [0m| 3/26 [00:02<00:20,  1.13it/s]Epoch: 8/10. Loss: 1.0535:  12%|[36m█▏        [0m| 3/26 [00:03<00:20,  1.13it/s]Epoch: 8/10. Loss: 1.0535:  15%|[36m█▌        [0m| 4/26 [00:03<00:18,  1.17it/s]Epoch: 8/10. Loss: 0.9869:  15%|[36m█▌        [0m| 4/26 [00:04<00:18,  1.17it/s]Epoch: 8/10. Loss: 0.9869:  19%|[36m█▉        [0m| 5/26 [00:04<00:18,  1.12it/s]Epoch: 8/10. Loss: 1.0149:  19%|[36m█▉        [0m| 5/26 [00:06<00:18,  1.12it/s]Epoch: 8/10. Loss: 1.0149:  23%|[36m██▎       [0m| 6/26 [00:06<00:24,  1.21s/it]Epoch: 8/10. Loss: 1.0653:  23%|[36m██▎       [0m| 6/26 [00:07<00:24,  1.21s/it]Epoch: 8/10. Loss: 1.0653:  27%|[36m██▋       [0m| 7/26 [00:07<00:21,  1.12s/it]Epoch: 8/10. Loss: 1.0538:  27%|[36m██▋       [0m| 7/26 [00:08<00:21,  1.12s/it]Epoch: 8/10. Loss: 1.0538:  31%|[36m███       [0m| 8/26 [00:08<00:19,  1.09s/it]Epoch: 8/10. Loss: 1.0114:  31%|[36m███       [0m| 8/26 [00:09<00:19,  1.09s/it]Epoch: 8/10. Loss: 1.0114:  35%|[36m███▍      [0m| 9/26 [00:09<00:17,  1.04s/it]Epoch: 8/10. Loss: 1.0273:  35%|[36m███▍      [0m| 9/26 [00:10<00:17,  1.04s/it]Epoch: 8/10. Loss: 1.0273:  38%|[36m███▊      [0m| 10/26 [00:10<00:15,  1.01it/s]Epoch: 8/10. Loss: 1.0324:  38%|[36m███▊      [0m| 10/26 [00:10<00:15,  1.01it/s]Epoch: 8/10. Loss: 1.0324:  42%|[36m████▏     [0m| 11/26 [00:10<00:14,  1.05it/s]Epoch: 8/10. Loss: 1.0129:  42%|[36m████▏     [0m| 11/26 [00:11<00:14,  1.05it/s]Epoch: 8/10. Loss: 1.0129:  46%|[36m████▌     [0m| 12/26 [00:11<00:12,  1.11it/s]Epoch: 8/10. Loss: 0.9794:  46%|[36m████▌     [0m| 12/26 [00:12<00:12,  1.11it/s]Epoch: 8/10. Loss: 0.9794:  50%|[36m█████     [0m| 13/26 [00:12<00:11,  1.11it/s]Epoch: 8/10. Loss: 1.0148:  50%|[36m█████     [0m| 13/26 [00:13<00:11,  1.11it/s]Epoch: 8/10. Loss: 1.0148:  54%|[36m█████▍    [0m| 14/26 [00:13<00:10,  1.19it/s]Epoch: 8/10. Loss: 1.0209:  54%|[36m█████▍    [0m| 14/26 [00:14<00:10,  1.19it/s]Epoch: 8/10. Loss: 1.0209:  58%|[36m█████▊    [0m| 15/26 [00:14<00:09,  1.20it/s]Epoch: 8/10. Loss: 1.0057:  58%|[36m█████▊    [0m| 15/26 [00:15<00:09,  1.20it/s]Epoch: 8/10. Loss: 1.0057:  62%|[36m██████▏   [0m| 16/26 [00:15<00:08,  1.13it/s]Epoch: 8/10. Loss: 1.0308:  62%|[36m██████▏   [0m| 16/26 [00:15<00:08,  1.13it/s]Epoch: 8/10. Loss: 1.0308:  65%|[36m██████▌   [0m| 17/26 [00:15<00:07,  1.16it/s]Epoch: 8/10. Loss: 1.0416:  65%|[36m██████▌   [0m| 17/26 [00:16<00:07,  1.16it/s]Epoch: 8/10. Loss: 1.0416:  69%|[36m██████▉   [0m| 18/26 [00:16<00:06,  1.16it/s]Epoch: 8/10. Loss: 0.9945:  69%|[36m██████▉   [0m| 18/26 [00:18<00:06,  1.16it/s]Epoch: 8/10. Loss: 0.9945:  73%|[36m███████▎  [0m| 19/26 [00:18<00:07,  1.14s/it]Epoch: 8/10. Loss: 0.9701:  73%|[36m███████▎  [0m| 19/26 [00:19<00:07,  1.14s/it]Epoch: 8/10. Loss: 0.9701:  77%|[36m███████▋  [0m| 20/26 [00:19<00:06,  1.06s/it]Epoch: 8/10. Loss: 0.9622:  77%|[36m███████▋  [0m| 20/26 [00:20<00:06,  1.06s/it]Epoch: 8/10. Loss: 0.9622:  81%|[36m████████  [0m| 21/26 [00:20<00:04,  1.03it/s]Epoch: 8/10. Loss: 1.0403:  81%|[36m████████  [0m| 21/26 [00:20<00:04,  1.03it/s]Epoch: 8/10. Loss: 1.0403:  85%|[36m████████▍ [0m| 22/26 [00:20<00:03,  1.12it/s]Epoch: 8/10. Loss: 1.0166:  85%|[36m████████▍ [0m| 22/26 [00:23<00:03,  1.12it/s]Epoch: 8/10. Loss: 1.0166:  88%|[36m████████▊ [0m| 23/26 [00:23<00:04,  1.52s/it]Epoch: 8/10. Loss: 0.9766:  88%|[36m████████▊ [0m| 23/26 [00:25<00:04,  1.52s/it]Epoch: 8/10. Loss: 0.9766:  92%|[36m█████████▏[0m| 24/26 [00:25<00:03,  1.55s/it]Epoch: 8/10. Loss: 1.0113:  92%|[36m█████████▏[0m| 24/26 [00:26<00:03,  1.55s/it]Epoch: 8/10. Loss: 1.0113:  96%|[36m█████████▌[0m| 25/26 [00:26<00:01,  1.36s/it]Epoch: 8/10. Loss: 0.9159:  96%|[36m█████████▌[0m| 25/26 [00:27<00:01,  1.36s/it]Epoch: 8/10. Loss: 0.9159: 100%|[36m██████████[0m| 26/26 [00:27<00:00,  1.14s/it]Epoch: 8/10. Loss: 0.9159: 100%|[36m██████████[0m| 26/26 [00:27<00:00,  1.04s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:05,  1.11it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:06,  1.24s/it] 43%|[33m████▎     [0m| 3/7 [00:02<00:03,  1.10it/s] 57%|[33m█████▋    [0m| 4/7 [00:04<00:03,  1.09s/it] 71%|[33m███████▏  [0m| 5/7 [00:04<00:01,  1.18it/s] 86%|[33m████████▌ [0m| 6/7 [00:05<00:00,  1.17it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.51it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.20it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 9/10. Loss: 0.9948:   0%|[36m          [0m| 0/26 [00:02<?, ?it/s]Epoch: 9/10. Loss: 0.9948:   4%|[36m▍         [0m| 1/26 [00:02<00:57,  2.31s/it]Epoch: 9/10. Loss: 1.0010:   4%|[36m▍         [0m| 1/26 [00:03<00:57,  2.31s/it]Epoch: 9/10. Loss: 1.0010:   8%|[36m▊         [0m| 2/26 [00:03<00:33,  1.38s/it]Epoch: 9/10. Loss: 0.9893:   8%|[36m▊         [0m| 2/26 [00:03<00:33,  1.38s/it]Epoch: 9/10. Loss: 0.9893:  12%|[36m█▏        [0m| 3/26 [00:03<00:26,  1.17s/it]Epoch: 9/10. Loss: 1.0448:  12%|[36m█▏        [0m| 3/26 [00:04<00:26,  1.17s/it]Epoch: 9/10. Loss: 1.0448:  15%|[36m█▌        [0m| 4/26 [00:04<00:24,  1.10s/it]Epoch: 9/10. Loss: 0.9333:  15%|[36m█▌        [0m| 4/26 [00:05<00:24,  1.10s/it]Epoch: 9/10. Loss: 0.9333:  19%|[36m█▉        [0m| 5/26 [00:05<00:22,  1.08s/it]Epoch: 9/10. Loss: 1.0472:  19%|[36m█▉        [0m| 5/26 [00:06<00:22,  1.08s/it]Epoch: 9/10. Loss: 1.0472:  23%|[36m██▎       [0m| 6/26 [00:06<00:20,  1.03s/it]Epoch: 9/10. Loss: 0.9997:  23%|[36m██▎       [0m| 6/26 [00:07<00:20,  1.03s/it]Epoch: 9/10. Loss: 0.9997:  27%|[36m██▋       [0m| 7/26 [00:07<00:18,  1.02it/s]Epoch: 9/10. Loss: 1.0254:  27%|[36m██▋       [0m| 7/26 [00:08<00:18,  1.02it/s]Epoch: 9/10. Loss: 1.0254:  31%|[36m███       [0m| 8/26 [00:08<00:15,  1.13it/s]Epoch: 9/10. Loss: 0.9981:  31%|[36m███       [0m| 8/26 [00:09<00:15,  1.13it/s]Epoch: 9/10. Loss: 0.9981:  35%|[36m███▍      [0m| 9/26 [00:09<00:16,  1.06it/s]Epoch: 9/10. Loss: 0.9740:  35%|[36m███▍      [0m| 9/26 [00:10<00:16,  1.06it/s]Epoch: 9/10. Loss: 0.9740:  38%|[36m███▊      [0m| 10/26 [00:10<00:14,  1.14it/s]Epoch: 9/10. Loss: 0.9761:  38%|[36m███▊      [0m| 10/26 [00:11<00:14,  1.14it/s]Epoch: 9/10. Loss: 0.9761:  42%|[36m████▏     [0m| 11/26 [00:11<00:12,  1.20it/s]Epoch: 9/10. Loss: 0.9800:  42%|[36m████▏     [0m| 11/26 [00:11<00:12,  1.20it/s]Epoch: 9/10. Loss: 0.9800:  46%|[36m████▌     [0m| 12/26 [00:11<00:11,  1.21it/s]Epoch: 9/10. Loss: 0.9867:  46%|[36m████▌     [0m| 12/26 [00:12<00:11,  1.21it/s]Epoch: 9/10. Loss: 0.9867:  50%|[36m█████     [0m| 13/26 [00:12<00:10,  1.20it/s]Epoch: 9/10. Loss: 1.0563:  50%|[36m█████     [0m| 13/26 [00:13<00:10,  1.20it/s]Epoch: 9/10. Loss: 1.0563:  54%|[36m█████▍    [0m| 14/26 [00:13<00:09,  1.24it/s]Epoch: 9/10. Loss: 1.0318:  54%|[36m█████▍    [0m| 14/26 [00:14<00:09,  1.24it/s]Epoch: 9/10. Loss: 1.0318:  58%|[36m█████▊    [0m| 15/26 [00:14<00:08,  1.26it/s]Epoch: 9/10. Loss: 1.0374:  58%|[36m█████▊    [0m| 15/26 [00:15<00:08,  1.26it/s]Epoch: 9/10. Loss: 1.0374:  62%|[36m██████▏   [0m| 16/26 [00:15<00:10,  1.07s/it]Epoch: 9/10. Loss: 1.0624:  62%|[36m██████▏   [0m| 16/26 [00:16<00:10,  1.07s/it]Epoch: 9/10. Loss: 1.0624:  65%|[36m██████▌   [0m| 17/26 [00:16<00:08,  1.03it/s]Epoch: 9/10. Loss: 1.1118:  65%|[36m██████▌   [0m| 17/26 [00:17<00:08,  1.03it/s]Epoch: 9/10. Loss: 1.1118:  69%|[36m██████▉   [0m| 18/26 [00:17<00:07,  1.05it/s]Epoch: 9/10. Loss: 1.0528:  69%|[36m██████▉   [0m| 18/26 [00:18<00:07,  1.05it/s]Epoch: 9/10. Loss: 1.0528:  73%|[36m███████▎  [0m| 19/26 [00:18<00:06,  1.02it/s]Epoch: 9/10. Loss: 0.9929:  73%|[36m███████▎  [0m| 19/26 [00:19<00:06,  1.02it/s]Epoch: 9/10. Loss: 0.9929:  77%|[36m███████▋  [0m| 20/26 [00:19<00:05,  1.03it/s]Epoch: 9/10. Loss: 1.0147:  77%|[36m███████▋  [0m| 20/26 [00:20<00:05,  1.03it/s]Epoch: 9/10. Loss: 1.0147:  81%|[36m████████  [0m| 21/26 [00:20<00:04,  1.06it/s]Epoch: 9/10. Loss: 1.0325:  81%|[36m████████  [0m| 21/26 [00:21<00:04,  1.06it/s]Epoch: 9/10. Loss: 1.0325:  85%|[36m████████▍ [0m| 22/26 [00:21<00:03,  1.08it/s]Epoch: 9/10. Loss: 1.0403:  85%|[36m████████▍ [0m| 22/26 [00:22<00:03,  1.08it/s]Epoch: 9/10. Loss: 1.0403:  88%|[36m████████▊ [0m| 23/26 [00:22<00:02,  1.13it/s]Epoch: 9/10. Loss: 0.9706:  88%|[36m████████▊ [0m| 23/26 [00:22<00:02,  1.13it/s]Epoch: 9/10. Loss: 0.9706:  92%|[36m█████████▏[0m| 24/26 [00:22<00:01,  1.18it/s]Epoch: 9/10. Loss: 1.0188:  92%|[36m█████████▏[0m| 24/26 [00:23<00:01,  1.18it/s]Epoch: 9/10. Loss: 1.0188:  96%|[36m█████████▌[0m| 25/26 [00:23<00:00,  1.09it/s]Epoch: 9/10. Loss: 1.0054:  96%|[36m█████████▌[0m| 25/26 [00:24<00:00,  1.09it/s]Epoch: 9/10. Loss: 1.0054: 100%|[36m██████████[0m| 26/26 [00:24<00:00,  1.13it/s]Epoch: 9/10. Loss: 1.0054: 100%|[36m██████████[0m| 26/26 [00:24<00:00,  1.05it/s]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:04,  1.36it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:05,  1.11s/it] 43%|[33m████▎     [0m| 3/7 [00:02<00:03,  1.18it/s] 57%|[33m█████▋    [0m| 4/7 [00:04<00:03,  1.06s/it] 71%|[33m███████▏  [0m| 5/7 [00:04<00:01,  1.22it/s] 86%|[33m████████▌ [0m| 6/7 [00:05<00:00,  1.20it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.53it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.26it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 0/10. Loss: 6.7983:   0%|[36m          [0m| 0/26 [00:01<?, ?it/s]Epoch: 0/10. Loss: 6.7983:   4%|[36m▍         [0m| 1/26 [00:01<00:31,  1.28s/it]Epoch: 0/10. Loss: 2.7306:   4%|[36m▍         [0m| 1/26 [00:02<00:31,  1.28s/it]Epoch: 0/10. Loss: 2.7306:   8%|[36m▊         [0m| 2/26 [00:02<00:25,  1.08s/it]Epoch: 0/10. Loss: 1.6985:   8%|[36m▊         [0m| 2/26 [00:02<00:25,  1.08s/it]Epoch: 0/10. Loss: 1.6985:  12%|[36m█▏        [0m| 3/26 [00:02<00:21,  1.07it/s]Epoch: 0/10. Loss: 1.2076:  12%|[36m█▏        [0m| 3/26 [00:03<00:21,  1.07it/s]Epoch: 0/10. Loss: 1.2076:  15%|[36m█▌        [0m| 4/26 [00:03<00:21,  1.04it/s]Epoch: 0/10. Loss: 1.2457:  15%|[36m█▌        [0m| 4/26 [00:05<00:21,  1.04it/s]Epoch: 0/10. Loss: 1.2457:  19%|[36m█▉        [0m| 5/26 [00:05<00:21,  1.04s/it]Epoch: 0/10. Loss: 1.0984:  19%|[36m█▉        [0m| 5/26 [00:06<00:21,  1.04s/it]Epoch: 0/10. Loss: 1.0984:  23%|[36m██▎       [0m| 6/26 [00:06<00:19,  1.01it/s]Epoch: 0/10. Loss: 1.0404:  23%|[36m██▎       [0m| 6/26 [00:06<00:19,  1.01it/s]Epoch: 0/10. Loss: 1.0404:  27%|[36m██▋       [0m| 7/26 [00:06<00:17,  1.08it/s]Epoch: 0/10. Loss: 1.1736:  27%|[36m██▋       [0m| 7/26 [00:07<00:17,  1.08it/s]Epoch: 0/10. Loss: 1.1736:  31%|[36m███       [0m| 8/26 [00:07<00:16,  1.10it/s]Epoch: 0/10. Loss: 1.0669:  31%|[36m███       [0m| 8/26 [00:08<00:16,  1.10it/s]Epoch: 0/10. Loss: 1.0669:  35%|[36m███▍      [0m| 9/26 [00:08<00:16,  1.05it/s]Epoch: 0/10. Loss: 1.0488:  35%|[36m███▍      [0m| 9/26 [00:09<00:16,  1.05it/s]Epoch: 0/10. Loss: 1.0488:  38%|[36m███▊      [0m| 10/26 [00:09<00:15,  1.06it/s]Epoch: 0/10. Loss: 1.0558:  38%|[36m███▊      [0m| 10/26 [00:10<00:15,  1.06it/s]Epoch: 0/10. Loss: 1.0558:  42%|[36m████▏     [0m| 11/26 [00:10<00:14,  1.02it/s]Epoch: 0/10. Loss: 0.9597:  42%|[36m████▏     [0m| 11/26 [00:12<00:14,  1.02it/s]Epoch: 0/10. Loss: 0.9597:  46%|[36m████▌     [0m| 12/26 [00:12<00:15,  1.08s/it]Epoch: 0/10. Loss: 1.1367:  46%|[36m████▌     [0m| 12/26 [00:13<00:15,  1.08s/it]Epoch: 0/10. Loss: 1.1367:  50%|[36m█████     [0m| 13/26 [00:13<00:14,  1.08s/it]Epoch: 0/10. Loss: 1.1722:  50%|[36m█████     [0m| 13/26 [00:15<00:14,  1.08s/it]Epoch: 0/10. Loss: 1.1722:  54%|[36m█████▍    [0m| 14/26 [00:15<00:15,  1.32s/it]Epoch: 0/10. Loss: 0.9806:  54%|[36m█████▍    [0m| 14/26 [00:16<00:15,  1.32s/it]Epoch: 0/10. Loss: 0.9806:  58%|[36m█████▊    [0m| 15/26 [00:16<00:13,  1.26s/it]Epoch: 0/10. Loss: 0.9714:  58%|[36m█████▊    [0m| 15/26 [00:17<00:13,  1.26s/it]Epoch: 0/10. Loss: 0.9714:  62%|[36m██████▏   [0m| 16/26 [00:17<00:11,  1.15s/it]Epoch: 0/10. Loss: 0.9781:  62%|[36m██████▏   [0m| 16/26 [00:17<00:11,  1.15s/it]Epoch: 0/10. Loss: 0.9781:  65%|[36m██████▌   [0m| 17/26 [00:17<00:09,  1.05s/it]Epoch: 0/10. Loss: 0.9243:  65%|[36m██████▌   [0m| 17/26 [00:18<00:09,  1.05s/it]Epoch: 0/10. Loss: 0.9243:  69%|[36m██████▉   [0m| 18/26 [00:18<00:07,  1.00it/s]Epoch: 0/10. Loss: 0.9781:  69%|[36m██████▉   [0m| 18/26 [00:19<00:07,  1.00it/s]Epoch: 0/10. Loss: 0.9781:  73%|[36m███████▎  [0m| 19/26 [00:19<00:06,  1.03it/s]Epoch: 0/10. Loss: 1.2258:  73%|[36m███████▎  [0m| 19/26 [00:20<00:06,  1.03it/s]Epoch: 0/10. Loss: 1.2258:  77%|[36m███████▋  [0m| 20/26 [00:20<00:05,  1.06it/s]Epoch: 0/10. Loss: 1.1110:  77%|[36m███████▋  [0m| 20/26 [00:21<00:05,  1.06it/s]Epoch: 0/10. Loss: 1.1110:  81%|[36m████████  [0m| 21/26 [00:21<00:04,  1.03it/s]Epoch: 0/10. Loss: 1.0886:  81%|[36m████████  [0m| 21/26 [00:22<00:04,  1.03it/s]Epoch: 0/10. Loss: 1.0886:  85%|[36m████████▍ [0m| 22/26 [00:22<00:03,  1.02it/s]Epoch: 0/10. Loss: 1.0905:  85%|[36m████████▍ [0m| 22/26 [00:23<00:03,  1.02it/s]Epoch: 0/10. Loss: 1.0905:  88%|[36m████████▊ [0m| 23/26 [00:23<00:02,  1.05it/s]Epoch: 0/10. Loss: 1.0513:  88%|[36m████████▊ [0m| 23/26 [00:24<00:02,  1.05it/s]Epoch: 0/10. Loss: 1.0513:  92%|[36m█████████▏[0m| 24/26 [00:24<00:01,  1.06it/s]Epoch: 0/10. Loss: 0.9678:  92%|[36m█████████▏[0m| 24/26 [00:25<00:01,  1.06it/s]Epoch: 0/10. Loss: 0.9678:  96%|[36m█████████▌[0m| 25/26 [00:25<00:00,  1.03it/s]Epoch: 0/10. Loss: 1.0754:  96%|[36m█████████▌[0m| 25/26 [00:26<00:00,  1.03it/s]Epoch: 0/10. Loss: 1.0754: 100%|[36m██████████[0m| 26/26 [00:26<00:00,  1.07it/s]Epoch: 0/10. Loss: 1.0754: 100%|[36m██████████[0m| 26/26 [00:26<00:00,  1.01s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:04,  1.25it/s] 29%|[33m██▊       [0m| 2/7 [00:03<00:09,  1.90s/it] 43%|[33m████▎     [0m| 3/7 [00:04<00:05,  1.32s/it] 57%|[33m█████▋    [0m| 4/7 [00:05<00:04,  1.36s/it] 71%|[33m███████▏  [0m| 5/7 [00:05<00:02,  1.04s/it] 86%|[33m████████▌ [0m| 6/7 [00:06<00:00,  1.00it/s]100%|[33m██████████[0m| 7/7 [00:07<00:00,  1.22it/s]100%|[33m██████████[0m| 7/7 [00:07<00:00,  1.05s/it]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 1/10. Loss: 1.1413:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 1/10. Loss: 1.1413:   4%|[36m▍         [0m| 1/26 [00:00<00:21,  1.19it/s]Epoch: 1/10. Loss: 1.0001:   4%|[36m▍         [0m| 1/26 [00:01<00:21,  1.19it/s]Epoch: 1/10. Loss: 1.0001:   8%|[36m▊         [0m| 2/26 [00:01<00:20,  1.17it/s]Epoch: 1/10. Loss: 1.0950:   8%|[36m▊         [0m| 2/26 [00:02<00:20,  1.17it/s]Epoch: 1/10. Loss: 1.0950:  12%|[36m█▏        [0m| 3/26 [00:02<00:23,  1.01s/it]Epoch: 1/10. Loss: 1.2247:  12%|[36m█▏        [0m| 3/26 [00:04<00:23,  1.01s/it]Epoch: 1/10. Loss: 1.2247:  15%|[36m█▌        [0m| 4/26 [00:04<00:25,  1.16s/it]Epoch: 1/10. Loss: 1.0375:  15%|[36m█▌        [0m| 4/26 [00:05<00:25,  1.16s/it]Epoch: 1/10. Loss: 1.0375:  19%|[36m█▉        [0m| 5/26 [00:05<00:22,  1.08s/it]Epoch: 1/10. Loss: 1.1865:  19%|[36m█▉        [0m| 5/26 [00:06<00:22,  1.08s/it]Epoch: 1/10. Loss: 1.1865:  23%|[36m██▎       [0m| 6/26 [00:06<00:21,  1.09s/it]Epoch: 1/10. Loss: 1.0963:  23%|[36m██▎       [0m| 6/26 [00:07<00:21,  1.09s/it]Epoch: 1/10. Loss: 1.0963:  27%|[36m██▋       [0m| 7/26 [00:07<00:19,  1.04s/it]Epoch: 1/10. Loss: 1.0862:  27%|[36m██▋       [0m| 7/26 [00:08<00:19,  1.04s/it]Epoch: 1/10. Loss: 1.0862:  31%|[36m███       [0m| 8/26 [00:08<00:18,  1.02s/it]Epoch: 1/10. Loss: 1.1373:  31%|[36m███       [0m| 8/26 [00:09<00:18,  1.02s/it]Epoch: 1/10. Loss: 1.1373:  35%|[36m███▍      [0m| 9/26 [00:09<00:17,  1.01s/it]Epoch: 1/10. Loss: 1.1316:  35%|[36m███▍      [0m| 9/26 [00:10<00:17,  1.01s/it]Epoch: 1/10. Loss: 1.1316:  38%|[36m███▊      [0m| 10/26 [00:10<00:16,  1.01s/it]Epoch: 1/10. Loss: 1.1922:  38%|[36m███▊      [0m| 10/26 [00:11<00:16,  1.01s/it]Epoch: 1/10. Loss: 1.1922:  42%|[36m████▏     [0m| 11/26 [00:11<00:14,  1.04it/s]Epoch: 1/10. Loss: 0.9166:  42%|[36m████▏     [0m| 11/26 [00:11<00:14,  1.04it/s]Epoch: 1/10. Loss: 0.9166:  46%|[36m████▌     [0m| 12/26 [00:11<00:13,  1.07it/s]Epoch: 1/10. Loss: 1.0781:  46%|[36m████▌     [0m| 12/26 [00:12<00:13,  1.07it/s]Epoch: 1/10. Loss: 1.0781:  50%|[36m█████     [0m| 13/26 [00:12<00:11,  1.13it/s]Epoch: 1/10. Loss: 1.3502:  50%|[36m█████     [0m| 13/26 [00:13<00:11,  1.13it/s]Epoch: 1/10. Loss: 1.3502:  54%|[36m█████▍    [0m| 14/26 [00:13<00:10,  1.17it/s]Epoch: 1/10. Loss: 1.0497:  54%|[36m█████▍    [0m| 14/26 [00:14<00:10,  1.17it/s]Epoch: 1/10. Loss: 1.0497:  58%|[36m█████▊    [0m| 15/26 [00:14<00:10,  1.07it/s]Epoch: 1/10. Loss: 1.0828:  58%|[36m█████▊    [0m| 15/26 [00:16<00:10,  1.07it/s]Epoch: 1/10. Loss: 1.0828:  62%|[36m██████▏   [0m| 16/26 [00:16<00:12,  1.29s/it]Epoch: 1/10. Loss: 1.2727:  62%|[36m██████▏   [0m| 16/26 [00:17<00:12,  1.29s/it]Epoch: 1/10. Loss: 1.2727:  65%|[36m██████▌   [0m| 17/26 [00:17<00:10,  1.17s/it]Epoch: 1/10. Loss: 0.9293:  65%|[36m██████▌   [0m| 17/26 [00:18<00:10,  1.17s/it]Epoch: 1/10. Loss: 0.9293:  69%|[36m██████▉   [0m| 18/26 [00:19<00:09,  1.22s/it]Epoch: 1/10. Loss: 1.0452:  69%|[36m██████▉   [0m| 18/26 [00:19<00:09,  1.22s/it]Epoch: 1/10. Loss: 1.0452:  73%|[36m███████▎  [0m| 19/26 [00:19<00:07,  1.14s/it]Epoch: 1/10. Loss: 0.9971:  73%|[36m███████▎  [0m| 19/26 [00:20<00:07,  1.14s/it]Epoch: 1/10. Loss: 0.9971:  77%|[36m███████▋  [0m| 20/26 [00:20<00:06,  1.06s/it]Epoch: 1/10. Loss: 1.0036:  77%|[36m███████▋  [0m| 20/26 [00:21<00:06,  1.06s/it]Epoch: 1/10. Loss: 1.0036:  81%|[36m████████  [0m| 21/26 [00:21<00:05,  1.06s/it]Epoch: 1/10. Loss: 1.0297:  81%|[36m████████  [0m| 21/26 [00:22<00:05,  1.06s/it]Epoch: 1/10. Loss: 1.0297:  85%|[36m████████▍ [0m| 22/26 [00:23<00:04,  1.07s/it]Epoch: 1/10. Loss: 1.1018:  85%|[36m████████▍ [0m| 22/26 [00:23<00:04,  1.07s/it]Epoch: 1/10. Loss: 1.1018:  88%|[36m████████▊ [0m| 23/26 [00:23<00:03,  1.03s/it]Epoch: 1/10. Loss: 1.0459:  88%|[36m████████▊ [0m| 23/26 [00:24<00:03,  1.03s/it]Epoch: 1/10. Loss: 1.0459:  92%|[36m█████████▏[0m| 24/26 [00:24<00:01,  1.02it/s]Epoch: 1/10. Loss: 1.1771:  92%|[36m█████████▏[0m| 24/26 [00:27<00:01,  1.02it/s]Epoch: 1/10. Loss: 1.1771:  96%|[36m█████████▌[0m| 25/26 [00:27<00:01,  1.53s/it]Epoch: 1/10. Loss: 0.9686:  96%|[36m█████████▌[0m| 25/26 [00:28<00:01,  1.53s/it]Epoch: 1/10. Loss: 0.9686: 100%|[36m██████████[0m| 26/26 [00:28<00:00,  1.30s/it]Epoch: 1/10. Loss: 0.9686: 100%|[36m██████████[0m| 26/26 [00:28<00:00,  1.09s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:05,  1.17it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:06,  1.22s/it] 43%|[33m████▎     [0m| 3/7 [00:02<00:03,  1.07it/s] 57%|[33m█████▋    [0m| 4/7 [00:05<00:04,  1.42s/it] 71%|[33m███████▏  [0m| 5/7 [00:05<00:02,  1.08s/it] 86%|[33m████████▌ [0m| 6/7 [00:06<00:01,  1.03s/it]100%|[33m██████████[0m| 7/7 [00:06<00:00,  1.26it/s]100%|[33m██████████[0m| 7/7 [00:06<00:00,  1.03it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 2/10. Loss: 0.9853:   0%|[36m          [0m| 0/26 [00:01<?, ?it/s]Epoch: 2/10. Loss: 0.9853:   4%|[36m▍         [0m| 1/26 [00:01<00:26,  1.06s/it]Epoch: 2/10. Loss: 0.9553:   4%|[36m▍         [0m| 1/26 [00:02<00:26,  1.06s/it]Epoch: 2/10. Loss: 0.9553:   8%|[36m▊         [0m| 2/26 [00:02<00:25,  1.06s/it]Epoch: 2/10. Loss: 1.0345:   8%|[36m▊         [0m| 2/26 [00:02<00:25,  1.06s/it]Epoch: 2/10. Loss: 1.0345:  12%|[36m█▏        [0m| 3/26 [00:02<00:21,  1.06it/s]Epoch: 2/10. Loss: 0.9446:  12%|[36m█▏        [0m| 3/26 [00:04<00:21,  1.06it/s]Epoch: 2/10. Loss: 0.9446:  15%|[36m█▌        [0m| 4/26 [00:04<00:22,  1.04s/it]Epoch: 2/10. Loss: 1.0615:  15%|[36m█▌        [0m| 4/26 [00:05<00:22,  1.04s/it]Epoch: 2/10. Loss: 1.0615:  19%|[36m█▉        [0m| 5/26 [00:05<00:21,  1.03s/it]Epoch: 2/10. Loss: 0.9100:  19%|[36m█▉        [0m| 5/26 [00:06<00:21,  1.03s/it]Epoch: 2/10. Loss: 0.9100:  23%|[36m██▎       [0m| 6/26 [00:06<00:20,  1.04s/it]Epoch: 2/10. Loss: 0.9558:  23%|[36m██▎       [0m| 6/26 [00:06<00:20,  1.04s/it]Epoch: 2/10. Loss: 0.9558:  27%|[36m██▋       [0m| 7/26 [00:07<00:18,  1.03it/s]Epoch: 2/10. Loss: 0.9706:  27%|[36m██▋       [0m| 7/26 [00:08<00:18,  1.03it/s]Epoch: 2/10. Loss: 0.9706:  31%|[36m███       [0m| 8/26 [00:08<00:18,  1.02s/it]Epoch: 2/10. Loss: 1.0561:  31%|[36m███       [0m| 8/26 [00:09<00:18,  1.02s/it]Epoch: 2/10. Loss: 1.0561:  35%|[36m███▍      [0m| 9/26 [00:09<00:17,  1.03s/it]Epoch: 2/10. Loss: 1.0179:  35%|[36m███▍      [0m| 9/26 [00:10<00:17,  1.03s/it]Epoch: 2/10. Loss: 1.0179:  38%|[36m███▊      [0m| 10/26 [00:10<00:15,  1.02it/s]Epoch: 2/10. Loss: 0.8770:  38%|[36m███▊      [0m| 10/26 [00:11<00:15,  1.02it/s]Epoch: 2/10. Loss: 0.8770:  42%|[36m████▏     [0m| 11/26 [00:11<00:15,  1.02s/it]Epoch: 2/10. Loss: 0.9462:  42%|[36m████▏     [0m| 11/26 [00:12<00:15,  1.02s/it]Epoch: 2/10. Loss: 0.9462:  46%|[36m████▌     [0m| 12/26 [00:12<00:14,  1.01s/it]Epoch: 2/10. Loss: 1.0071:  46%|[36m████▌     [0m| 12/26 [00:13<00:14,  1.01s/it]Epoch: 2/10. Loss: 1.0071:  50%|[36m█████     [0m| 13/26 [00:13<00:12,  1.01it/s]Epoch: 2/10. Loss: 0.9867:  50%|[36m█████     [0m| 13/26 [00:14<00:12,  1.01it/s]Epoch: 2/10. Loss: 0.9867:  54%|[36m█████▍    [0m| 14/26 [00:14<00:12,  1.01s/it]Epoch: 2/10. Loss: 0.9642:  54%|[36m█████▍    [0m| 14/26 [00:15<00:12,  1.01s/it]Epoch: 2/10. Loss: 0.9642:  58%|[36m█████▊    [0m| 15/26 [00:15<00:10,  1.01it/s]Epoch: 2/10. Loss: 0.9921:  58%|[36m█████▊    [0m| 15/26 [00:16<00:10,  1.01it/s]Epoch: 2/10. Loss: 0.9921:  62%|[36m██████▏   [0m| 16/26 [00:16<00:09,  1.02it/s]Epoch: 2/10. Loss: 0.8887:  62%|[36m██████▏   [0m| 16/26 [00:16<00:09,  1.02it/s]Epoch: 2/10. Loss: 0.8887:  65%|[36m██████▌   [0m| 17/26 [00:17<00:08,  1.03it/s]Epoch: 2/10. Loss: 0.9668:  65%|[36m██████▌   [0m| 17/26 [00:17<00:08,  1.03it/s]Epoch: 2/10. Loss: 0.9668:  69%|[36m██████▉   [0m| 18/26 [00:17<00:07,  1.05it/s]Epoch: 2/10. Loss: 0.9226:  69%|[36m██████▉   [0m| 18/26 [00:18<00:07,  1.05it/s]Epoch: 2/10. Loss: 0.9226:  73%|[36m███████▎  [0m| 19/26 [00:18<00:06,  1.04it/s]Epoch: 2/10. Loss: 0.9639:  73%|[36m███████▎  [0m| 19/26 [00:19<00:06,  1.04it/s]Epoch: 2/10. Loss: 0.9639:  77%|[36m███████▋  [0m| 20/26 [00:19<00:05,  1.04it/s]Epoch: 2/10. Loss: 0.9173:  77%|[36m███████▋  [0m| 20/26 [00:20<00:05,  1.04it/s]Epoch: 2/10. Loss: 0.9173:  81%|[36m████████  [0m| 21/26 [00:20<00:04,  1.06it/s]Epoch: 2/10. Loss: 0.9522:  81%|[36m████████  [0m| 21/26 [00:21<00:04,  1.06it/s]Epoch: 2/10. Loss: 0.9522:  85%|[36m████████▍ [0m| 22/26 [00:21<00:03,  1.09it/s]Epoch: 2/10. Loss: 0.9253:  85%|[36m████████▍ [0m| 22/26 [00:22<00:03,  1.09it/s]Epoch: 2/10. Loss: 0.9253:  88%|[36m████████▊ [0m| 23/26 [00:22<00:02,  1.10it/s]Epoch: 2/10. Loss: 0.9295:  88%|[36m████████▊ [0m| 23/26 [00:23<00:02,  1.10it/s]Epoch: 2/10. Loss: 0.9295:  92%|[36m█████████▏[0m| 24/26 [00:23<00:01,  1.00it/s]Epoch: 2/10. Loss: 0.9701:  92%|[36m█████████▏[0m| 24/26 [00:24<00:01,  1.00it/s]Epoch: 2/10. Loss: 0.9701:  96%|[36m█████████▌[0m| 25/26 [00:24<00:00,  1.02it/s]Epoch: 2/10. Loss: 1.0155:  96%|[36m█████████▌[0m| 25/26 [00:25<00:00,  1.02it/s]Epoch: 2/10. Loss: 1.0155: 100%|[36m██████████[0m| 26/26 [00:25<00:00,  1.12it/s]Epoch: 2/10. Loss: 1.0155: 100%|[36m██████████[0m| 26/26 [00:25<00:00,  1.03it/s]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:05,  1.19it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:07,  1.44s/it] 43%|[33m████▎     [0m| 3/7 [00:03<00:04,  1.09s/it] 57%|[33m█████▋    [0m| 4/7 [00:04<00:03,  1.21s/it] 71%|[33m███████▏  [0m| 5/7 [00:05<00:01,  1.06it/s] 86%|[33m████████▌ [0m| 6/7 [00:06<00:00,  1.07it/s]100%|[33m██████████[0m| 7/7 [00:06<00:00,  1.36it/s]100%|[33m██████████[0m| 7/7 [00:06<00:00,  1.08it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 3/10. Loss: 0.9869:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 3/10. Loss: 0.9869:   4%|[36m▍         [0m| 1/26 [00:00<00:24,  1.02it/s]Epoch: 3/10. Loss: 0.9090:   4%|[36m▍         [0m| 1/26 [00:01<00:24,  1.02it/s]Epoch: 3/10. Loss: 0.9090:   8%|[36m▊         [0m| 2/26 [00:01<00:21,  1.12it/s]Epoch: 3/10. Loss: 1.0783:   8%|[36m▊         [0m| 2/26 [00:02<00:21,  1.12it/s]Epoch: 3/10. Loss: 1.0783:  12%|[36m█▏        [0m| 3/26 [00:02<00:19,  1.18it/s]Epoch: 3/10. Loss: 0.9345:  12%|[36m█▏        [0m| 3/26 [00:03<00:19,  1.18it/s]Epoch: 3/10. Loss: 0.9345:  15%|[36m█▌        [0m| 4/26 [00:03<00:19,  1.16it/s]Epoch: 3/10. Loss: 1.0002:  15%|[36m█▌        [0m| 4/26 [00:04<00:19,  1.16it/s]Epoch: 3/10. Loss: 1.0002:  19%|[36m█▉        [0m| 5/26 [00:04<00:22,  1.06s/it]Epoch: 3/10. Loss: 1.0068:  19%|[36m█▉        [0m| 5/26 [00:05<00:22,  1.06s/it]Epoch: 3/10. Loss: 1.0068:  23%|[36m██▎       [0m| 6/26 [00:05<00:21,  1.05s/it]Epoch: 3/10. Loss: 1.0493:  23%|[36m██▎       [0m| 6/26 [00:06<00:21,  1.05s/it]Epoch: 3/10. Loss: 1.0493:  27%|[36m██▋       [0m| 7/26 [00:06<00:19,  1.03s/it]Epoch: 3/10. Loss: 0.9455:  27%|[36m██▋       [0m| 7/26 [00:07<00:19,  1.03s/it]Epoch: 3/10. Loss: 0.9455:  31%|[36m███       [0m| 8/26 [00:07<00:17,  1.04it/s]Epoch: 3/10. Loss: 0.9309:  31%|[36m███       [0m| 8/26 [00:08<00:17,  1.04it/s]Epoch: 3/10. Loss: 0.9309:  35%|[36m███▍      [0m| 9/26 [00:08<00:16,  1.05it/s]Epoch: 3/10. Loss: 0.9872:  35%|[36m███▍      [0m| 9/26 [00:09<00:16,  1.05it/s]Epoch: 3/10. Loss: 0.9872:  38%|[36m███▊      [0m| 10/26 [00:09<00:14,  1.11it/s]Epoch: 3/10. Loss: 0.9538:  38%|[36m███▊      [0m| 10/26 [00:12<00:14,  1.11it/s]Epoch: 3/10. Loss: 0.9538:  42%|[36m████▏     [0m| 11/26 [00:12<00:21,  1.43s/it]Epoch: 3/10. Loss: 0.9571:  42%|[36m████▏     [0m| 11/26 [00:13<00:21,  1.43s/it]Epoch: 3/10. Loss: 0.9571:  46%|[36m████▌     [0m| 12/26 [00:13<00:18,  1.29s/it]Epoch: 3/10. Loss: 0.8734:  46%|[36m████▌     [0m| 12/26 [00:14<00:18,  1.29s/it]Epoch: 3/10. Loss: 0.8734:  50%|[36m█████     [0m| 13/26 [00:14<00:15,  1.20s/it]Epoch: 3/10. Loss: 0.8078:  50%|[36m█████     [0m| 13/26 [00:15<00:15,  1.20s/it]Epoch: 3/10. Loss: 0.8078:  54%|[36m█████▍    [0m| 14/26 [00:15<00:14,  1.23s/it]Epoch: 3/10. Loss: 0.9680:  54%|[36m█████▍    [0m| 14/26 [00:16<00:14,  1.23s/it]Epoch: 3/10. Loss: 0.9680:  58%|[36m█████▊    [0m| 15/26 [00:16<00:12,  1.15s/it]Epoch: 3/10. Loss: 0.8602:  58%|[36m█████▊    [0m| 15/26 [00:17<00:12,  1.15s/it]Epoch: 3/10. Loss: 0.8602:  62%|[36m██████▏   [0m| 16/26 [00:17<00:10,  1.07s/it]Epoch: 3/10. Loss: 0.9334:  62%|[36m██████▏   [0m| 16/26 [00:18<00:10,  1.07s/it]Epoch: 3/10. Loss: 0.9334:  65%|[36m██████▌   [0m| 17/26 [00:18<00:09,  1.06s/it]Epoch: 3/10. Loss: 0.8819:  65%|[36m██████▌   [0m| 17/26 [00:19<00:09,  1.06s/it]Epoch: 3/10. Loss: 0.8819:  69%|[36m██████▉   [0m| 18/26 [00:19<00:08,  1.02s/it]Epoch: 3/10. Loss: 0.9883:  69%|[36m██████▉   [0m| 18/26 [00:19<00:08,  1.02s/it]Epoch: 3/10. Loss: 0.9883:  73%|[36m███████▎  [0m| 19/26 [00:19<00:06,  1.05it/s]Epoch: 3/10. Loss: 0.8628:  73%|[36m███████▎  [0m| 19/26 [00:21<00:06,  1.05it/s]Epoch: 3/10. Loss: 0.8628:  77%|[36m███████▋  [0m| 20/26 [00:21<00:07,  1.27s/it]Epoch: 3/10. Loss: 0.9542:  77%|[36m███████▋  [0m| 20/26 [00:22<00:07,  1.27s/it]Epoch: 3/10. Loss: 0.9542:  81%|[36m████████  [0m| 21/26 [00:22<00:05,  1.16s/it]Epoch: 3/10. Loss: 0.8826:  81%|[36m████████  [0m| 21/26 [00:23<00:05,  1.16s/it]Epoch: 3/10. Loss: 0.8826:  85%|[36m████████▍ [0m| 22/26 [00:23<00:04,  1.12s/it]Epoch: 3/10. Loss: 0.8440:  85%|[36m████████▍ [0m| 22/26 [00:24<00:04,  1.12s/it]Epoch: 3/10. Loss: 0.8440:  88%|[36m████████▊ [0m| 23/26 [00:24<00:03,  1.03s/it]Epoch: 3/10. Loss: 0.9157:  88%|[36m████████▊ [0m| 23/26 [00:25<00:03,  1.03s/it]Epoch: 3/10. Loss: 0.9157:  92%|[36m█████████▏[0m| 24/26 [00:25<00:02,  1.04s/it]Epoch: 3/10. Loss: 1.0104:  92%|[36m█████████▏[0m| 24/26 [00:26<00:02,  1.04s/it]Epoch: 3/10. Loss: 1.0104:  96%|[36m█████████▌[0m| 25/26 [00:26<00:00,  1.05it/s]Epoch: 3/10. Loss: 0.9520:  96%|[36m█████████▌[0m| 25/26 [00:27<00:00,  1.05it/s]Epoch: 3/10. Loss: 0.9520: 100%|[36m██████████[0m| 26/26 [00:27<00:00,  1.13it/s]Epoch: 3/10. Loss: 0.9520: 100%|[36m██████████[0m| 26/26 [00:27<00:00,  1.05s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:05,  1.17it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:05,  1.20s/it] 43%|[33m████▎     [0m| 3/7 [00:02<00:03,  1.11it/s] 57%|[33m█████▋    [0m| 4/7 [00:04<00:03,  1.10s/it] 71%|[33m███████▏  [0m| 5/7 [00:04<00:01,  1.16it/s] 86%|[33m████████▌ [0m| 6/7 [00:05<00:00,  1.13it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.43it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.18it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 4/10. Loss: 0.7891:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 4/10. Loss: 0.7891:   4%|[36m▍         [0m| 1/26 [00:00<00:21,  1.14it/s]Epoch: 4/10. Loss: 0.8624:   4%|[36m▍         [0m| 1/26 [00:01<00:21,  1.14it/s]Epoch: 4/10. Loss: 0.8624:   8%|[36m▊         [0m| 2/26 [00:01<00:21,  1.11it/s]Epoch: 4/10. Loss: 0.8928:   8%|[36m▊         [0m| 2/26 [00:06<00:21,  1.11it/s]Epoch: 4/10. Loss: 0.8928:  12%|[36m█▏        [0m| 3/26 [00:06<00:57,  2.51s/it]Epoch: 4/10. Loss: 1.0354:  12%|[36m█▏        [0m| 3/26 [00:07<00:57,  2.51s/it]Epoch: 4/10. Loss: 1.0354:  15%|[36m█▌        [0m| 4/26 [00:07<00:46,  2.11s/it]Epoch: 4/10. Loss: 0.9150:  15%|[36m█▌        [0m| 4/26 [00:08<00:46,  2.11s/it]Epoch: 4/10. Loss: 0.9150:  19%|[36m█▉        [0m| 5/26 [00:08<00:36,  1.72s/it]Epoch: 4/10. Loss: 0.8993:  19%|[36m█▉        [0m| 5/26 [00:09<00:36,  1.72s/it]Epoch: 4/10. Loss: 0.8993:  23%|[36m██▎       [0m| 6/26 [00:09<00:29,  1.48s/it]Epoch: 4/10. Loss: 0.8552:  23%|[36m██▎       [0m| 6/26 [00:10<00:29,  1.48s/it]Epoch: 4/10. Loss: 0.8552:  27%|[36m██▋       [0m| 7/26 [00:10<00:25,  1.33s/it]Epoch: 4/10. Loss: 0.9050:  27%|[36m██▋       [0m| 7/26 [00:11<00:25,  1.33s/it]Epoch: 4/10. Loss: 0.9050:  31%|[36m███       [0m| 8/26 [00:11<00:22,  1.23s/it]Epoch: 4/10. Loss: 0.8994:  31%|[36m███       [0m| 8/26 [00:12<00:22,  1.23s/it]Epoch: 4/10. Loss: 0.8994:  35%|[36m███▍      [0m| 9/26 [00:12<00:19,  1.14s/it]Epoch: 4/10. Loss: 1.0551:  35%|[36m███▍      [0m| 9/26 [00:13<00:19,  1.14s/it]Epoch: 4/10. Loss: 1.0551:  38%|[36m███▊      [0m| 10/26 [00:13<00:18,  1.15s/it]Epoch: 4/10. Loss: 0.9775:  38%|[36m███▊      [0m| 10/26 [00:15<00:18,  1.15s/it]Epoch: 4/10. Loss: 0.9775:  42%|[36m████▏     [0m| 11/26 [00:15<00:17,  1.15s/it]Epoch: 4/10. Loss: 0.9712:  42%|[36m████▏     [0m| 11/26 [00:15<00:17,  1.15s/it]Epoch: 4/10. Loss: 0.9712:  46%|[36m████▌     [0m| 12/26 [00:15<00:14,  1.06s/it]Epoch: 4/10. Loss: 0.8459:  46%|[36m████▌     [0m| 12/26 [00:16<00:14,  1.06s/it]Epoch: 4/10. Loss: 0.8459:  50%|[36m█████     [0m| 13/26 [00:16<00:12,  1.01it/s]Epoch: 4/10. Loss: 0.8720:  50%|[36m█████     [0m| 13/26 [00:17<00:12,  1.01it/s]Epoch: 4/10. Loss: 0.8720:  54%|[36m█████▍    [0m| 14/26 [00:17<00:11,  1.03it/s]Epoch: 4/10. Loss: 0.9912:  54%|[36m█████▍    [0m| 14/26 [00:18<00:11,  1.03it/s]Epoch: 4/10. Loss: 0.9912:  58%|[36m█████▊    [0m| 15/26 [00:18<00:10,  1.01it/s]Epoch: 4/10. Loss: 0.8120:  58%|[36m█████▊    [0m| 15/26 [00:19<00:10,  1.01it/s]Epoch: 4/10. Loss: 0.8120:  62%|[36m██████▏   [0m| 16/26 [00:19<00:09,  1.02it/s]Epoch: 4/10. Loss: 0.8891:  62%|[36m██████▏   [0m| 16/26 [00:20<00:09,  1.02it/s]Epoch: 4/10. Loss: 0.8891:  65%|[36m██████▌   [0m| 17/26 [00:20<00:09,  1.04s/it]Epoch: 4/10. Loss: 0.9266:  65%|[36m██████▌   [0m| 17/26 [00:21<00:09,  1.04s/it]Epoch: 4/10. Loss: 0.9266:  69%|[36m██████▉   [0m| 18/26 [00:21<00:07,  1.02it/s]Epoch: 4/10. Loss: 1.1551:  69%|[36m██████▉   [0m| 18/26 [00:22<00:07,  1.02it/s]Epoch: 4/10. Loss: 1.1551:  73%|[36m███████▎  [0m| 19/26 [00:22<00:06,  1.00it/s]Epoch: 4/10. Loss: 0.9394:  73%|[36m███████▎  [0m| 19/26 [00:23<00:06,  1.00it/s]Epoch: 4/10. Loss: 0.9394:  77%|[36m███████▋  [0m| 20/26 [00:23<00:06,  1.00s/it]Epoch: 4/10. Loss: 0.8215:  77%|[36m███████▋  [0m| 20/26 [00:24<00:06,  1.00s/it]Epoch: 4/10. Loss: 0.8215:  81%|[36m████████  [0m| 21/26 [00:24<00:05,  1.06s/it]Epoch: 4/10. Loss: 1.0095:  81%|[36m████████  [0m| 21/26 [00:25<00:05,  1.06s/it]Epoch: 4/10. Loss: 1.0095:  85%|[36m████████▍ [0m| 22/26 [00:25<00:04,  1.05s/it]Epoch: 4/10. Loss: 0.9258:  85%|[36m████████▍ [0m| 22/26 [00:26<00:04,  1.05s/it]Epoch: 4/10. Loss: 0.9258:  88%|[36m████████▊ [0m| 23/26 [00:26<00:03,  1.02s/it]Epoch: 4/10. Loss: 1.0764:  88%|[36m████████▊ [0m| 23/26 [00:27<00:03,  1.02s/it]Epoch: 4/10. Loss: 1.0764:  92%|[36m█████████▏[0m| 24/26 [00:27<00:02,  1.00s/it]Epoch: 4/10. Loss: 0.7869:  92%|[36m█████████▏[0m| 24/26 [00:28<00:02,  1.00s/it]Epoch: 4/10. Loss: 0.7869:  96%|[36m█████████▌[0m| 25/26 [00:28<00:00,  1.06it/s]Epoch: 4/10. Loss: 0.8848:  96%|[36m█████████▌[0m| 25/26 [00:29<00:00,  1.06it/s]Epoch: 4/10. Loss: 0.8848: 100%|[36m██████████[0m| 26/26 [00:29<00:00,  1.22it/s]Epoch: 4/10. Loss: 0.8848: 100%|[36m██████████[0m| 26/26 [00:29<00:00,  1.12s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:05,  1.08it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:06,  1.25s/it] 43%|[33m████▎     [0m| 3/7 [00:02<00:03,  1.06it/s] 57%|[33m█████▋    [0m| 4/7 [00:04<00:03,  1.14s/it] 71%|[33m███████▏  [0m| 5/7 [00:04<00:01,  1.12it/s] 86%|[33m████████▌ [0m| 6/7 [00:05<00:00,  1.09it/s]100%|[33m██████████[0m| 7/7 [00:06<00:00,  1.39it/s]100%|[33m██████████[0m| 7/7 [00:06<00:00,  1.14it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 5/10. Loss: 0.8937:   0%|[36m          [0m| 0/26 [00:01<?, ?it/s]Epoch: 5/10. Loss: 0.8937:   4%|[36m▍         [0m| 1/26 [00:01<00:27,  1.12s/it]Epoch: 5/10. Loss: 0.8581:   4%|[36m▍         [0m| 1/26 [00:01<00:27,  1.12s/it]Epoch: 5/10. Loss: 0.8581:   8%|[36m▊         [0m| 2/26 [00:02<00:23,  1.01it/s]Epoch: 5/10. Loss: 0.8130:   8%|[36m▊         [0m| 2/26 [00:03<00:23,  1.01it/s]Epoch: 5/10. Loss: 0.8130:  12%|[36m█▏        [0m| 3/26 [00:03<00:24,  1.05s/it]Epoch: 5/10. Loss: 0.8712:  12%|[36m█▏        [0m| 3/26 [00:04<00:24,  1.05s/it]Epoch: 5/10. Loss: 0.8712:  15%|[36m█▌        [0m| 4/26 [00:04<00:24,  1.10s/it]Epoch: 5/10. Loss: 0.8783:  15%|[36m█▌        [0m| 4/26 [00:05<00:24,  1.10s/it]Epoch: 5/10. Loss: 0.8783:  19%|[36m█▉        [0m| 5/26 [00:05<00:21,  1.05s/it]Epoch: 5/10. Loss: 0.9637:  19%|[36m█▉        [0m| 5/26 [00:06<00:21,  1.05s/it]Epoch: 5/10. Loss: 0.9637:  23%|[36m██▎       [0m| 6/26 [00:06<00:19,  1.01it/s]Epoch: 5/10. Loss: 0.9164:  23%|[36m██▎       [0m| 6/26 [00:07<00:19,  1.01it/s]Epoch: 5/10. Loss: 0.9164:  27%|[36m██▋       [0m| 7/26 [00:07<00:18,  1.04it/s]Epoch: 5/10. Loss: 0.9733:  27%|[36m██▋       [0m| 7/26 [00:07<00:18,  1.04it/s]Epoch: 5/10. Loss: 0.9733:  31%|[36m███       [0m| 8/26 [00:08<00:17,  1.04it/s]Epoch: 5/10. Loss: 0.8971:  31%|[36m███       [0m| 8/26 [00:08<00:17,  1.04it/s]Epoch: 5/10. Loss: 0.8971:  35%|[36m███▍      [0m| 9/26 [00:09<00:16,  1.03it/s]Epoch: 5/10. Loss: 0.9668:  35%|[36m███▍      [0m| 9/26 [00:09<00:16,  1.03it/s]Epoch: 5/10. Loss: 0.9668:  38%|[36m███▊      [0m| 10/26 [00:10<00:15,  1.01it/s]Epoch: 5/10. Loss: 0.8764:  38%|[36m███▊      [0m| 10/26 [00:10<00:15,  1.01it/s]Epoch: 5/10. Loss: 0.8764:  42%|[36m████▏     [0m| 11/26 [00:10<00:13,  1.08it/s]Epoch: 5/10. Loss: 0.9225:  42%|[36m████▏     [0m| 11/26 [00:11<00:13,  1.08it/s]Epoch: 5/10. Loss: 0.9225:  46%|[36m████▌     [0m| 12/26 [00:11<00:12,  1.08it/s]Epoch: 5/10. Loss: 0.8779:  46%|[36m████▌     [0m| 12/26 [00:12<00:12,  1.08it/s]Epoch: 5/10. Loss: 0.8779:  50%|[36m█████     [0m| 13/26 [00:12<00:11,  1.10it/s]Epoch: 5/10. Loss: 0.8392:  50%|[36m█████     [0m| 13/26 [00:13<00:11,  1.10it/s]Epoch: 5/10. Loss: 0.8392:  54%|[36m█████▍    [0m| 14/26 [00:13<00:11,  1.09it/s]Epoch: 5/10. Loss: 0.8480:  54%|[36m█████▍    [0m| 14/26 [00:14<00:11,  1.09it/s]Epoch: 5/10. Loss: 0.8480:  58%|[36m█████▊    [0m| 15/26 [00:14<00:10,  1.09it/s]Epoch: 5/10. Loss: 0.9401:  58%|[36m█████▊    [0m| 15/26 [00:15<00:10,  1.09it/s]Epoch: 5/10. Loss: 0.9401:  62%|[36m██████▏   [0m| 16/26 [00:15<00:09,  1.11it/s]Epoch: 5/10. Loss: 0.8113:  62%|[36m██████▏   [0m| 16/26 [00:16<00:09,  1.11it/s]Epoch: 5/10. Loss: 0.8113:  65%|[36m██████▌   [0m| 17/26 [00:16<00:08,  1.10it/s]Epoch: 5/10. Loss: 0.8694:  65%|[36m██████▌   [0m| 17/26 [00:17<00:08,  1.10it/s]Epoch: 5/10. Loss: 0.8694:  69%|[36m██████▉   [0m| 18/26 [00:17<00:07,  1.12it/s]Epoch: 5/10. Loss: 0.9858:  69%|[36m██████▉   [0m| 18/26 [00:18<00:07,  1.12it/s]Epoch: 5/10. Loss: 0.9858:  73%|[36m███████▎  [0m| 19/26 [00:18<00:06,  1.05it/s]Epoch: 5/10. Loss: 0.8598:  73%|[36m███████▎  [0m| 19/26 [00:19<00:06,  1.05it/s]Epoch: 5/10. Loss: 0.8598:  77%|[36m███████▋  [0m| 20/26 [00:19<00:05,  1.05it/s]Epoch: 5/10. Loss: 0.8703:  77%|[36m███████▋  [0m| 20/26 [00:20<00:05,  1.05it/s]Epoch: 5/10. Loss: 0.8703:  81%|[36m████████  [0m| 21/26 [00:20<00:04,  1.01it/s]Epoch: 5/10. Loss: 0.9482:  81%|[36m████████  [0m| 21/26 [00:21<00:04,  1.01it/s]Epoch: 5/10. Loss: 0.9482:  85%|[36m████████▍ [0m| 22/26 [00:21<00:03,  1.03it/s]Epoch: 5/10. Loss: 0.9221:  85%|[36m████████▍ [0m| 22/26 [00:22<00:03,  1.03it/s]Epoch: 5/10. Loss: 0.9221:  88%|[36m████████▊ [0m| 23/26 [00:22<00:02,  1.02it/s]Epoch: 5/10. Loss: 0.8719:  88%|[36m████████▊ [0m| 23/26 [00:23<00:02,  1.02it/s]Epoch: 5/10. Loss: 0.8719:  92%|[36m█████████▏[0m| 24/26 [00:23<00:01,  1.00it/s]Epoch: 5/10. Loss: 0.8368:  92%|[36m█████████▏[0m| 24/26 [00:24<00:01,  1.00it/s]Epoch: 5/10. Loss: 0.8368:  96%|[36m█████████▌[0m| 25/26 [00:24<00:00,  1.02it/s]Epoch: 5/10. Loss: 0.8821:  96%|[36m█████████▌[0m| 25/26 [00:24<00:00,  1.02it/s]Epoch: 5/10. Loss: 0.8821: 100%|[36m██████████[0m| 26/26 [00:24<00:00,  1.13it/s]Epoch: 5/10. Loss: 0.8821: 100%|[36m██████████[0m| 26/26 [00:24<00:00,  1.05it/s]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:05,  1.18it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:05,  1.20s/it] 43%|[33m████▎     [0m| 3/7 [00:02<00:03,  1.09it/s] 57%|[33m█████▋    [0m| 4/7 [00:04<00:03,  1.11s/it] 71%|[33m███████▏  [0m| 5/7 [00:04<00:01,  1.15it/s] 86%|[33m████████▌ [0m| 6/7 [00:06<00:01,  1.16s/it]100%|[33m██████████[0m| 7/7 [00:06<00:00,  1.13it/s]100%|[33m██████████[0m| 7/7 [00:06<00:00,  1.04it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 6/10. Loss: 0.8607:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 6/10. Loss: 0.8607:   4%|[36m▍         [0m| 1/26 [00:00<00:23,  1.06it/s]Epoch: 6/10. Loss: 0.8837:   4%|[36m▍         [0m| 1/26 [00:02<00:23,  1.06it/s]Epoch: 6/10. Loss: 0.8837:   8%|[36m▊         [0m| 2/26 [00:02<00:26,  1.09s/it]Epoch: 6/10. Loss: 0.8821:   8%|[36m▊         [0m| 2/26 [00:03<00:26,  1.09s/it]Epoch: 6/10. Loss: 0.8821:  12%|[36m█▏        [0m| 3/26 [00:03<00:23,  1.04s/it]Epoch: 6/10. Loss: 0.8417:  12%|[36m█▏        [0m| 3/26 [00:04<00:23,  1.04s/it]Epoch: 6/10. Loss: 0.8417:  15%|[36m█▌        [0m| 4/26 [00:04<00:24,  1.09s/it]Epoch: 6/10. Loss: 0.7912:  15%|[36m█▌        [0m| 4/26 [00:05<00:24,  1.09s/it]Epoch: 6/10. Loss: 0.7912:  19%|[36m█▉        [0m| 5/26 [00:05<00:21,  1.02s/it]Epoch: 6/10. Loss: 0.8459:  19%|[36m█▉        [0m| 5/26 [00:06<00:21,  1.02s/it]Epoch: 6/10. Loss: 0.8459:  23%|[36m██▎       [0m| 6/26 [00:06<00:20,  1.01s/it]Epoch: 6/10. Loss: 0.8502:  23%|[36m██▎       [0m| 6/26 [00:07<00:20,  1.01s/it]Epoch: 6/10. Loss: 0.8502:  27%|[36m██▋       [0m| 7/26 [00:07<00:23,  1.22s/it]Epoch: 6/10. Loss: 0.7422:  27%|[36m██▋       [0m| 7/26 [00:08<00:23,  1.22s/it]Epoch: 6/10. Loss: 0.7422:  31%|[36m███       [0m| 8/26 [00:08<00:21,  1.18s/it]Epoch: 6/10. Loss: 0.8604:  31%|[36m███       [0m| 8/26 [00:10<00:21,  1.18s/it]Epoch: 6/10. Loss: 0.8604:  35%|[36m███▍      [0m| 9/26 [00:10<00:24,  1.42s/it]Epoch: 6/10. Loss: 1.0108:  35%|[36m███▍      [0m| 9/26 [00:13<00:24,  1.42s/it]Epoch: 6/10. Loss: 1.0108:  38%|[36m███▊      [0m| 10/26 [00:13<00:27,  1.71s/it]Epoch: 6/10. Loss: 0.8457:  38%|[36m███▊      [0m| 10/26 [00:14<00:27,  1.71s/it]Epoch: 6/10. Loss: 0.8457:  42%|[36m████▏     [0m| 11/26 [00:14<00:21,  1.46s/it]Epoch: 6/10. Loss: 0.8184:  42%|[36m████▏     [0m| 11/26 [00:15<00:21,  1.46s/it]Epoch: 6/10. Loss: 0.8184:  46%|[36m████▌     [0m| 12/26 [00:15<00:21,  1.57s/it]Epoch: 6/10. Loss: 0.9450:  46%|[36m████▌     [0m| 12/26 [00:16<00:21,  1.57s/it]Epoch: 6/10. Loss: 0.9450:  50%|[36m█████     [0m| 13/26 [00:16<00:17,  1.36s/it]Epoch: 6/10. Loss: 0.9671:  50%|[36m█████     [0m| 13/26 [00:17<00:17,  1.36s/it]Epoch: 6/10. Loss: 0.9671:  54%|[36m█████▍    [0m| 14/26 [00:17<00:14,  1.24s/it]Epoch: 6/10. Loss: 0.9188:  54%|[36m█████▍    [0m| 14/26 [00:18<00:14,  1.24s/it]Epoch: 6/10. Loss: 0.9188:  58%|[36m█████▊    [0m| 15/26 [00:18<00:12,  1.17s/it]Epoch: 6/10. Loss: 0.8339:  58%|[36m█████▊    [0m| 15/26 [00:20<00:12,  1.17s/it]Epoch: 6/10. Loss: 0.8339:  62%|[36m██████▏   [0m| 16/26 [00:21<00:14,  1.49s/it]Epoch: 6/10. Loss: 0.7998:  62%|[36m██████▏   [0m| 16/26 [00:22<00:14,  1.49s/it]Epoch: 6/10. Loss: 0.7998:  65%|[36m██████▌   [0m| 17/26 [00:22<00:12,  1.40s/it]Epoch: 6/10. Loss: 0.8580:  65%|[36m██████▌   [0m| 17/26 [00:23<00:12,  1.40s/it]Epoch: 6/10. Loss: 0.8580:  69%|[36m██████▉   [0m| 18/26 [00:23<00:10,  1.30s/it]Epoch: 6/10. Loss: 0.8509:  69%|[36m██████▉   [0m| 18/26 [00:25<00:10,  1.30s/it]Epoch: 6/10. Loss: 0.8509:  73%|[36m███████▎  [0m| 19/26 [00:25<00:10,  1.45s/it]Epoch: 6/10. Loss: 0.8604:  73%|[36m███████▎  [0m| 19/26 [00:26<00:10,  1.45s/it]Epoch: 6/10. Loss: 0.8604:  77%|[36m███████▋  [0m| 20/26 [00:26<00:08,  1.35s/it]Epoch: 6/10. Loss: 0.9997:  77%|[36m███████▋  [0m| 20/26 [00:26<00:08,  1.35s/it]Epoch: 6/10. Loss: 0.9997:  81%|[36m████████  [0m| 21/26 [00:27<00:05,  1.19s/it]Epoch: 6/10. Loss: 0.8016:  81%|[36m████████  [0m| 21/26 [00:28<00:05,  1.19s/it]Epoch: 6/10. Loss: 0.8016:  85%|[36m████████▍ [0m| 22/26 [00:28<00:04,  1.21s/it]Epoch: 6/10. Loss: 0.8574:  85%|[36m████████▍ [0m| 22/26 [00:29<00:04,  1.21s/it]Epoch: 6/10. Loss: 0.8574:  88%|[36m████████▊ [0m| 23/26 [00:29<00:03,  1.12s/it]Epoch: 6/10. Loss: 0.8995:  88%|[36m████████▊ [0m| 23/26 [00:30<00:03,  1.12s/it]Epoch: 6/10. Loss: 0.8995:  92%|[36m█████████▏[0m| 24/26 [00:30<00:02,  1.05s/it]Epoch: 6/10. Loss: 0.8539:  92%|[36m█████████▏[0m| 24/26 [00:31<00:02,  1.05s/it]Epoch: 6/10. Loss: 0.8539:  96%|[36m█████████▌[0m| 25/26 [00:31<00:01,  1.04s/it]Epoch: 6/10. Loss: 1.1383:  96%|[36m█████████▌[0m| 25/26 [00:31<00:01,  1.04s/it]Epoch: 6/10. Loss: 1.1383: 100%|[36m██████████[0m| 26/26 [00:31<00:00,  1.02it/s]Epoch: 6/10. Loss: 1.1383: 100%|[36m██████████[0m| 26/26 [00:31<00:00,  1.23s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:05,  1.14it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:06,  1.24s/it] 43%|[33m████▎     [0m| 3/7 [00:02<00:03,  1.07it/s] 57%|[33m█████▋    [0m| 4/7 [00:04<00:03,  1.08s/it] 71%|[33m███████▏  [0m| 5/7 [00:04<00:01,  1.21it/s] 86%|[33m████████▌ [0m| 6/7 [00:05<00:00,  1.20it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.46it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.20it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 7/10. Loss: 0.8710:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 7/10. Loss: 0.8710:   4%|[36m▍         [0m| 1/26 [00:00<00:23,  1.05it/s]Epoch: 7/10. Loss: 0.8624:   4%|[36m▍         [0m| 1/26 [00:01<00:23,  1.05it/s]Epoch: 7/10. Loss: 0.8624:   8%|[36m▊         [0m| 2/26 [00:02<00:24,  1.02s/it]Epoch: 7/10. Loss: 0.8949:   8%|[36m▊         [0m| 2/26 [00:03<00:24,  1.02s/it]Epoch: 7/10. Loss: 0.8949:  12%|[36m█▏        [0m| 3/26 [00:03<00:23,  1.02s/it]Epoch: 7/10. Loss: 0.9095:  12%|[36m█▏        [0m| 3/26 [00:04<00:23,  1.02s/it]Epoch: 7/10. Loss: 0.9095:  15%|[36m█▌        [0m| 4/26 [00:04<00:24,  1.13s/it]Epoch: 7/10. Loss: 1.0144:  15%|[36m█▌        [0m| 4/26 [00:05<00:24,  1.13s/it]Epoch: 7/10. Loss: 1.0144:  19%|[36m█▉        [0m| 5/26 [00:05<00:23,  1.13s/it]Epoch: 7/10. Loss: 0.8846:  19%|[36m█▉        [0m| 5/26 [00:06<00:23,  1.13s/it]Epoch: 7/10. Loss: 0.8846:  23%|[36m██▎       [0m| 6/26 [00:06<00:22,  1.11s/it]Epoch: 7/10. Loss: 0.9414:  23%|[36m██▎       [0m| 6/26 [00:07<00:22,  1.11s/it]Epoch: 7/10. Loss: 0.9414:  27%|[36m██▋       [0m| 7/26 [00:07<00:20,  1.07s/it]Epoch: 7/10. Loss: 0.9167:  27%|[36m██▋       [0m| 7/26 [00:08<00:20,  1.07s/it]Epoch: 7/10. Loss: 0.9167:  31%|[36m███       [0m| 8/26 [00:08<00:18,  1.01s/it]Epoch: 7/10. Loss: 0.8103:  31%|[36m███       [0m| 8/26 [00:09<00:18,  1.01s/it]Epoch: 7/10. Loss: 0.8103:  35%|[36m███▍      [0m| 9/26 [00:09<00:17,  1.04s/it]Epoch: 7/10. Loss: 0.8004:  35%|[36m███▍      [0m| 9/26 [00:10<00:17,  1.04s/it]Epoch: 7/10. Loss: 0.8004:  38%|[36m███▊      [0m| 10/26 [00:10<00:15,  1.04it/s]Epoch: 7/10. Loss: 0.8111:  38%|[36m███▊      [0m| 10/26 [00:12<00:15,  1.04it/s]Epoch: 7/10. Loss: 0.8111:  42%|[36m████▏     [0m| 11/26 [00:12<00:20,  1.34s/it]Epoch: 7/10. Loss: 0.9050:  42%|[36m████▏     [0m| 11/26 [00:13<00:20,  1.34s/it]Epoch: 7/10. Loss: 0.9050:  46%|[36m████▌     [0m| 12/26 [00:13<00:17,  1.24s/it]Epoch: 7/10. Loss: 0.7409:  46%|[36m████▌     [0m| 12/26 [00:14<00:17,  1.24s/it]Epoch: 7/10. Loss: 0.7409:  50%|[36m█████     [0m| 13/26 [00:14<00:14,  1.10s/it]Epoch: 7/10. Loss: 0.8322:  50%|[36m█████     [0m| 13/26 [00:15<00:14,  1.10s/it]Epoch: 7/10. Loss: 0.8322:  54%|[36m█████▍    [0m| 14/26 [00:15<00:12,  1.02s/it]Epoch: 7/10. Loss: 0.8278:  54%|[36m█████▍    [0m| 14/26 [00:16<00:12,  1.02s/it]Epoch: 7/10. Loss: 0.8278:  58%|[36m█████▊    [0m| 15/26 [00:16<00:10,  1.01it/s]Epoch: 7/10. Loss: 0.8264:  58%|[36m█████▊    [0m| 15/26 [00:18<00:10,  1.01it/s]Epoch: 7/10. Loss: 0.8264:  62%|[36m██████▏   [0m| 16/26 [00:18<00:14,  1.42s/it]Epoch: 7/10. Loss: 0.8726:  62%|[36m██████▏   [0m| 16/26 [00:19<00:14,  1.42s/it]Epoch: 7/10. Loss: 0.8726:  65%|[36m██████▌   [0m| 17/26 [00:19<00:12,  1.33s/it]Epoch: 7/10. Loss: 0.8827:  65%|[36m██████▌   [0m| 17/26 [00:20<00:12,  1.33s/it]Epoch: 7/10. Loss: 0.8827:  69%|[36m██████▉   [0m| 18/26 [00:20<00:09,  1.25s/it]Epoch: 7/10. Loss: 0.8106:  69%|[36m██████▉   [0m| 18/26 [00:21<00:09,  1.25s/it]Epoch: 7/10. Loss: 0.8106:  73%|[36m███████▎  [0m| 19/26 [00:21<00:08,  1.21s/it]Epoch: 7/10. Loss: 0.8277:  73%|[36m███████▎  [0m| 19/26 [00:22<00:08,  1.21s/it]Epoch: 7/10. Loss: 0.8277:  77%|[36m███████▋  [0m| 20/26 [00:22<00:07,  1.19s/it]Epoch: 7/10. Loss: 0.8859:  77%|[36m███████▋  [0m| 20/26 [00:23<00:07,  1.19s/it]Epoch: 7/10. Loss: 0.8859:  81%|[36m████████  [0m| 21/26 [00:23<00:05,  1.09s/it]Epoch: 7/10. Loss: 0.8431:  81%|[36m████████  [0m| 21/26 [00:24<00:05,  1.09s/it]Epoch: 7/10. Loss: 0.8431:  85%|[36m████████▍ [0m| 22/26 [00:24<00:04,  1.04s/it]Epoch: 7/10. Loss: 0.8950:  85%|[36m████████▍ [0m| 22/26 [00:26<00:04,  1.04s/it]Epoch: 7/10. Loss: 0.8950:  88%|[36m████████▊ [0m| 23/26 [00:26<00:03,  1.15s/it]Epoch: 7/10. Loss: 0.9359:  88%|[36m████████▊ [0m| 23/26 [00:27<00:03,  1.15s/it]Epoch: 7/10. Loss: 0.9359:  92%|[36m█████████▏[0m| 24/26 [00:27<00:02,  1.25s/it]Epoch: 7/10. Loss: 0.8600:  92%|[36m█████████▏[0m| 24/26 [00:29<00:02,  1.25s/it]Epoch: 7/10. Loss: 0.8600:  96%|[36m█████████▌[0m| 25/26 [00:29<00:01,  1.34s/it]Epoch: 7/10. Loss: 0.7550:  96%|[36m█████████▌[0m| 25/26 [00:29<00:01,  1.34s/it]Epoch: 7/10. Loss: 0.7550: 100%|[36m██████████[0m| 26/26 [00:29<00:00,  1.15s/it]Epoch: 7/10. Loss: 0.7550: 100%|[36m██████████[0m| 26/26 [00:29<00:00,  1.15s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:05,  1.13it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:06,  1.25s/it] 43%|[33m████▎     [0m| 3/7 [00:02<00:03,  1.06it/s] 57%|[33m█████▋    [0m| 4/7 [00:04<00:03,  1.11s/it] 71%|[33m███████▏  [0m| 5/7 [00:04<00:01,  1.16it/s] 86%|[33m████████▌ [0m| 6/7 [00:06<00:01,  1.04s/it]100%|[33m██████████[0m| 7/7 [00:06<00:00,  1.24it/s]100%|[33m██████████[0m| 7/7 [00:06<00:00,  1.08it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 8/10. Loss: 0.9272:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 8/10. Loss: 0.9272:   4%|[36m▍         [0m| 1/26 [00:00<00:23,  1.06it/s]Epoch: 8/10. Loss: 0.8782:   4%|[36m▍         [0m| 1/26 [00:01<00:23,  1.06it/s]Epoch: 8/10. Loss: 0.8782:   8%|[36m▊         [0m| 2/26 [00:01<00:22,  1.04it/s]Epoch: 8/10. Loss: 0.8426:   8%|[36m▊         [0m| 2/26 [00:02<00:22,  1.04it/s]Epoch: 8/10. Loss: 0.8426:  12%|[36m█▏        [0m| 3/26 [00:02<00:22,  1.01it/s]Epoch: 8/10. Loss: 0.9242:  12%|[36m█▏        [0m| 3/26 [00:03<00:22,  1.01it/s]Epoch: 8/10. Loss: 0.9242:  15%|[36m█▌        [0m| 4/26 [00:03<00:20,  1.05it/s]Epoch: 8/10. Loss: 0.8326:  15%|[36m█▌        [0m| 4/26 [00:04<00:20,  1.05it/s]Epoch: 8/10. Loss: 0.8326:  19%|[36m█▉        [0m| 5/26 [00:04<00:21,  1.02s/it]Epoch: 8/10. Loss: 0.8876:  19%|[36m█▉        [0m| 5/26 [00:05<00:21,  1.02s/it]Epoch: 8/10. Loss: 0.8876:  23%|[36m██▎       [0m| 6/26 [00:05<00:19,  1.02it/s]Epoch: 8/10. Loss: 0.8871:  23%|[36m██▎       [0m| 6/26 [00:06<00:19,  1.02it/s]Epoch: 8/10. Loss: 0.8871:  27%|[36m██▋       [0m| 7/26 [00:06<00:19,  1.01s/it]Epoch: 8/10. Loss: 0.9068:  27%|[36m██▋       [0m| 7/26 [00:07<00:19,  1.01s/it]Epoch: 8/10. Loss: 0.9068:  31%|[36m███       [0m| 8/26 [00:07<00:17,  1.01it/s]Epoch: 8/10. Loss: 0.9147:  31%|[36m███       [0m| 8/26 [00:09<00:17,  1.01it/s]Epoch: 8/10. Loss: 0.9147:  35%|[36m███▍      [0m| 9/26 [00:09<00:20,  1.18s/it]Epoch: 8/10. Loss: 0.7947:  35%|[36m███▍      [0m| 9/26 [00:10<00:20,  1.18s/it]Epoch: 8/10. Loss: 0.7947:  38%|[36m███▊      [0m| 10/26 [00:10<00:17,  1.10s/it]Epoch: 8/10. Loss: 0.8847:  38%|[36m███▊      [0m| 10/26 [00:11<00:17,  1.10s/it]Epoch: 8/10. Loss: 0.8847:  42%|[36m████▏     [0m| 11/26 [00:11<00:16,  1.08s/it]Epoch: 8/10. Loss: 0.8360:  42%|[36m████▏     [0m| 11/26 [00:12<00:16,  1.08s/it]Epoch: 8/10. Loss: 0.8360:  46%|[36m████▌     [0m| 12/26 [00:12<00:14,  1.05s/it]Epoch: 8/10. Loss: 0.7760:  46%|[36m████▌     [0m| 12/26 [00:13<00:14,  1.05s/it]Epoch: 8/10. Loss: 0.7760:  50%|[36m█████     [0m| 13/26 [00:13<00:13,  1.04s/it]Epoch: 8/10. Loss: 0.9425:  50%|[36m█████     [0m| 13/26 [00:14<00:13,  1.04s/it]Epoch: 8/10. Loss: 0.9425:  54%|[36m█████▍    [0m| 14/26 [00:14<00:12,  1.01s/it]Epoch: 8/10. Loss: 0.8466:  54%|[36m█████▍    [0m| 14/26 [00:15<00:12,  1.01s/it]Epoch: 8/10. Loss: 0.8466:  58%|[36m█████▊    [0m| 15/26 [00:15<00:10,  1.04it/s]Epoch: 8/10. Loss: 0.8111:  58%|[36m█████▊    [0m| 15/26 [00:16<00:10,  1.04it/s]Epoch: 8/10. Loss: 0.8111:  62%|[36m██████▏   [0m| 16/26 [00:16<00:09,  1.02it/s]Epoch: 8/10. Loss: 0.8229:  62%|[36m██████▏   [0m| 16/26 [00:17<00:09,  1.02it/s]Epoch: 8/10. Loss: 0.8229:  65%|[36m██████▌   [0m| 17/26 [00:17<00:08,  1.04it/s]Epoch: 8/10. Loss: 0.8462:  65%|[36m██████▌   [0m| 17/26 [00:18<00:08,  1.04it/s]Epoch: 8/10. Loss: 0.8462:  69%|[36m██████▉   [0m| 18/26 [00:18<00:07,  1.05it/s]Epoch: 8/10. Loss: 0.8423:  69%|[36m██████▉   [0m| 18/26 [00:19<00:07,  1.05it/s]Epoch: 8/10. Loss: 0.8423:  73%|[36m███████▎  [0m| 19/26 [00:19<00:07,  1.07s/it]Epoch: 8/10. Loss: 0.8043:  73%|[36m███████▎  [0m| 19/26 [00:20<00:07,  1.07s/it]Epoch: 8/10. Loss: 0.8043:  77%|[36m███████▋  [0m| 20/26 [00:20<00:06,  1.01s/it]Epoch: 8/10. Loss: 0.7936:  77%|[36m███████▋  [0m| 20/26 [00:21<00:06,  1.01s/it]Epoch: 8/10. Loss: 0.7936:  81%|[36m████████  [0m| 21/26 [00:21<00:04,  1.03it/s]Epoch: 8/10. Loss: 0.8837:  81%|[36m████████  [0m| 21/26 [00:22<00:04,  1.03it/s]Epoch: 8/10. Loss: 0.8837:  85%|[36m████████▍ [0m| 22/26 [00:22<00:03,  1.03it/s]Epoch: 8/10. Loss: 0.8872:  85%|[36m████████▍ [0m| 22/26 [00:23<00:03,  1.03it/s]Epoch: 8/10. Loss: 0.8872:  88%|[36m████████▊ [0m| 23/26 [00:23<00:02,  1.03it/s]Epoch: 8/10. Loss: 0.8082:  88%|[36m████████▊ [0m| 23/26 [00:24<00:02,  1.03it/s]Epoch: 8/10. Loss: 0.8082:  92%|[36m█████████▏[0m| 24/26 [00:24<00:02,  1.04s/it]Epoch: 8/10. Loss: 0.8143:  92%|[36m█████████▏[0m| 24/26 [00:25<00:02,  1.04s/it]Epoch: 8/10. Loss: 0.8143:  96%|[36m█████████▌[0m| 25/26 [00:25<00:01,  1.01s/it]Epoch: 8/10. Loss: 0.9252:  96%|[36m█████████▌[0m| 25/26 [00:25<00:01,  1.01s/it]Epoch: 8/10. Loss: 0.9252: 100%|[36m██████████[0m| 26/26 [00:25<00:00,  1.10it/s]Epoch: 8/10. Loss: 0.9252: 100%|[36m██████████[0m| 26/26 [00:25<00:00,  1.00it/s]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:05,  1.11it/s] 29%|[33m██▊       [0m| 2/7 [00:03<00:09,  1.85s/it] 43%|[33m████▎     [0m| 3/7 [00:03<00:05,  1.26s/it] 57%|[33m█████▋    [0m| 4/7 [00:05<00:04,  1.34s/it] 71%|[33m███████▏  [0m| 5/7 [00:05<00:02,  1.01s/it] 86%|[33m████████▌ [0m| 6/7 [00:06<00:00,  1.02it/s]100%|[33m██████████[0m| 7/7 [00:07<00:00,  1.31it/s]100%|[33m██████████[0m| 7/7 [00:07<00:00,  1.01s/it]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 9/10. Loss: 0.7939:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 9/10. Loss: 0.7939:   4%|[36m▍         [0m| 1/26 [00:00<00:23,  1.05it/s]Epoch: 9/10. Loss: 0.7162:   4%|[36m▍         [0m| 1/26 [00:01<00:23,  1.05it/s]Epoch: 9/10. Loss: 0.7162:   8%|[36m▊         [0m| 2/26 [00:01<00:21,  1.11it/s]Epoch: 9/10. Loss: 0.7304:   8%|[36m▊         [0m| 2/26 [00:02<00:21,  1.11it/s]Epoch: 9/10. Loss: 0.7304:  12%|[36m█▏        [0m| 3/26 [00:02<00:21,  1.09it/s]Epoch: 9/10. Loss: 0.8778:  12%|[36m█▏        [0m| 3/26 [00:03<00:21,  1.09it/s]Epoch: 9/10. Loss: 0.8778:  15%|[36m█▌        [0m| 4/26 [00:03<00:20,  1.05it/s]Epoch: 9/10. Loss: 0.7773:  15%|[36m█▌        [0m| 4/26 [00:04<00:20,  1.05it/s]Epoch: 9/10. Loss: 0.7773:  19%|[36m█▉        [0m| 5/26 [00:04<00:20,  1.03it/s]Epoch: 9/10. Loss: 0.7459:  19%|[36m█▉        [0m| 5/26 [00:05<00:20,  1.03it/s]Epoch: 9/10. Loss: 0.7459:  23%|[36m██▎       [0m| 6/26 [00:05<00:19,  1.04it/s]Epoch: 9/10. Loss: 0.7743:  23%|[36m██▎       [0m| 6/26 [00:06<00:19,  1.04it/s]Epoch: 9/10. Loss: 0.7743:  27%|[36m██▋       [0m| 7/26 [00:06<00:18,  1.02it/s]Epoch: 9/10. Loss: 0.7929:  27%|[36m██▋       [0m| 7/26 [00:07<00:18,  1.02it/s]Epoch: 9/10. Loss: 0.7929:  31%|[36m███       [0m| 8/26 [00:07<00:16,  1.12it/s]Epoch: 9/10. Loss: 0.7822:  31%|[36m███       [0m| 8/26 [00:08<00:16,  1.12it/s]Epoch: 9/10. Loss: 0.7822:  35%|[36m███▍      [0m| 9/26 [00:08<00:17,  1.04s/it]Epoch: 9/10. Loss: 0.8456:  35%|[36m███▍      [0m| 9/26 [00:10<00:17,  1.04s/it]Epoch: 9/10. Loss: 0.8456:  38%|[36m███▊      [0m| 10/26 [00:10<00:18,  1.17s/it]Epoch: 9/10. Loss: 0.8775:  38%|[36m███▊      [0m| 10/26 [00:11<00:18,  1.17s/it]Epoch: 9/10. Loss: 0.8775:  42%|[36m████▏     [0m| 11/26 [00:11<00:18,  1.24s/it]Epoch: 9/10. Loss: 0.8260:  42%|[36m████▏     [0m| 11/26 [00:13<00:18,  1.24s/it]Epoch: 9/10. Loss: 0.8260:  46%|[36m████▌     [0m| 12/26 [00:13<00:19,  1.37s/it]Epoch: 9/10. Loss: 0.8134:  46%|[36m████▌     [0m| 12/26 [00:14<00:19,  1.37s/it]Epoch: 9/10. Loss: 0.8134:  50%|[36m█████     [0m| 13/26 [00:14<00:17,  1.34s/it]Epoch: 9/10. Loss: 0.8892:  50%|[36m█████     [0m| 13/26 [00:15<00:17,  1.34s/it]Epoch: 9/10. Loss: 0.8892:  54%|[36m█████▍    [0m| 14/26 [00:15<00:14,  1.23s/it]Epoch: 9/10. Loss: 0.7946:  54%|[36m█████▍    [0m| 14/26 [00:16<00:14,  1.23s/it]Epoch: 9/10. Loss: 0.7946:  58%|[36m█████▊    [0m| 15/26 [00:16<00:12,  1.18s/it]Epoch: 9/10. Loss: 0.8576:  58%|[36m█████▊    [0m| 15/26 [00:18<00:12,  1.18s/it]Epoch: 9/10. Loss: 0.8576:  62%|[36m██████▏   [0m| 16/26 [00:18<00:15,  1.53s/it]Epoch: 9/10. Loss: 0.8175:  62%|[36m██████▏   [0m| 16/26 [00:19<00:15,  1.53s/it]Epoch: 9/10. Loss: 0.8175:  65%|[36m██████▌   [0m| 17/26 [00:19<00:12,  1.36s/it]Epoch: 9/10. Loss: 0.9445:  65%|[36m██████▌   [0m| 17/26 [00:21<00:12,  1.36s/it]Epoch: 9/10. Loss: 0.9445:  69%|[36m██████▉   [0m| 18/26 [00:21<00:11,  1.45s/it]Epoch: 9/10. Loss: 0.8428:  69%|[36m██████▉   [0m| 18/26 [00:22<00:11,  1.45s/it]Epoch: 9/10. Loss: 0.8428:  73%|[36m███████▎  [0m| 19/26 [00:22<00:08,  1.24s/it]Epoch: 9/10. Loss: 0.8054:  73%|[36m███████▎  [0m| 19/26 [00:23<00:08,  1.24s/it]Epoch: 9/10. Loss: 0.8054:  77%|[36m███████▋  [0m| 20/26 [00:23<00:07,  1.17s/it]Epoch: 9/10. Loss: 0.8623:  77%|[36m███████▋  [0m| 20/26 [00:24<00:07,  1.17s/it]Epoch: 9/10. Loss: 0.8623:  81%|[36m████████  [0m| 21/26 [00:24<00:05,  1.18s/it]Epoch: 9/10. Loss: 0.8693:  81%|[36m████████  [0m| 21/26 [00:26<00:05,  1.18s/it]Epoch: 9/10. Loss: 0.8693:  85%|[36m████████▍ [0m| 22/26 [00:26<00:05,  1.34s/it]Epoch: 9/10. Loss: 0.8740:  85%|[36m████████▍ [0m| 22/26 [00:27<00:05,  1.34s/it]Epoch: 9/10. Loss: 0.8740:  88%|[36m████████▊ [0m| 23/26 [00:27<00:03,  1.32s/it]Epoch: 9/10. Loss: 0.8314:  88%|[36m████████▊ [0m| 23/26 [00:29<00:03,  1.32s/it]Epoch: 9/10. Loss: 0.8314:  92%|[36m█████████▏[0m| 24/26 [00:29<00:02,  1.44s/it]Epoch: 9/10. Loss: 0.8731:  92%|[36m█████████▏[0m| 24/26 [00:30<00:02,  1.44s/it]Epoch: 9/10. Loss: 0.8731:  96%|[36m█████████▌[0m| 25/26 [00:30<00:01,  1.29s/it]Epoch: 9/10. Loss: 0.9104:  96%|[36m█████████▌[0m| 25/26 [00:30<00:01,  1.29s/it]Epoch: 9/10. Loss: 0.9104: 100%|[36m██████████[0m| 26/26 [00:30<00:00,  1.12s/it]Epoch: 9/10. Loss: 0.9104: 100%|[36m██████████[0m| 26/26 [00:30<00:00,  1.19s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:05,  1.15it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:07,  1.45s/it] 43%|[33m████▎     [0m| 3/7 [00:03<00:04,  1.05s/it] 57%|[33m█████▋    [0m| 4/7 [00:04<00:03,  1.19s/it] 71%|[33m███████▏  [0m| 5/7 [00:05<00:01,  1.09it/s] 86%|[33m████████▌ [0m| 6/7 [00:06<00:00,  1.08it/s]100%|[33m██████████[0m| 7/7 [00:06<00:00,  1.37it/s]100%|[33m██████████[0m| 7/7 [00:06<00:00,  1.09it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 0/10. Loss: 1.0984:   0%|[36m          [0m| 0/26 [00:01<?, ?it/s]Epoch: 0/10. Loss: 1.0984:   4%|[36m▍         [0m| 1/26 [00:01<00:29,  1.16s/it]Epoch: 0/10. Loss: 5.8863:   4%|[36m▍         [0m| 1/26 [00:02<00:29,  1.16s/it]Epoch: 0/10. Loss: 5.8863:   8%|[36m▊         [0m| 2/26 [00:02<00:26,  1.08s/it]Epoch: 0/10. Loss: 4.6995:   8%|[36m▊         [0m| 2/26 [00:03<00:26,  1.08s/it]Epoch: 0/10. Loss: 4.6995:  12%|[36m█▏        [0m| 3/26 [00:03<00:22,  1.01it/s]Epoch: 0/10. Loss: 1.5905:  12%|[36m█▏        [0m| 3/26 [00:04<00:22,  1.01it/s]Epoch: 0/10. Loss: 1.5905:  15%|[36m█▌        [0m| 4/26 [00:04<00:26,  1.20s/it]Epoch: 0/10. Loss: 1.8065:  15%|[36m█▌        [0m| 4/26 [00:05<00:26,  1.20s/it]Epoch: 0/10. Loss: 1.8065:  19%|[36m█▉        [0m| 5/26 [00:05<00:23,  1.11s/it]Epoch: 0/10. Loss: 2.4105:  19%|[36m█▉        [0m| 5/26 [00:07<00:23,  1.11s/it]Epoch: 0/10. Loss: 2.4105:  23%|[36m██▎       [0m| 6/26 [00:07<00:27,  1.38s/it]Epoch: 0/10. Loss: 1.2329:  23%|[36m██▎       [0m| 6/26 [00:08<00:27,  1.38s/it]Epoch: 0/10. Loss: 1.2329:  27%|[36m██▋       [0m| 7/26 [00:08<00:23,  1.25s/it]Epoch: 0/10. Loss: 1.4340:  27%|[36m██▋       [0m| 7/26 [00:09<00:23,  1.25s/it]Epoch: 0/10. Loss: 1.4340:  31%|[36m███       [0m| 8/26 [00:09<00:20,  1.16s/it]Epoch: 0/10. Loss: 1.4412:  31%|[36m███       [0m| 8/26 [00:10<00:20,  1.16s/it]Epoch: 0/10. Loss: 1.4412:  35%|[36m███▍      [0m| 9/26 [00:10<00:20,  1.20s/it]Epoch: 0/10. Loss: 1.5601:  35%|[36m███▍      [0m| 9/26 [00:11<00:20,  1.20s/it]Epoch: 0/10. Loss: 1.5601:  38%|[36m███▊      [0m| 10/26 [00:11<00:18,  1.13s/it]Epoch: 0/10. Loss: 1.3087:  38%|[36m███▊      [0m| 10/26 [00:12<00:18,  1.13s/it]Epoch: 0/10. Loss: 1.3087:  42%|[36m████▏     [0m| 11/26 [00:12<00:15,  1.05s/it]Epoch: 0/10. Loss: 2.7937:  42%|[36m████▏     [0m| 11/26 [00:13<00:15,  1.05s/it]Epoch: 0/10. Loss: 2.7937:  46%|[36m████▌     [0m| 12/26 [00:13<00:14,  1.01s/it]Epoch: 0/10. Loss: 1.1564:  46%|[36m████▌     [0m| 12/26 [00:14<00:14,  1.01s/it]Epoch: 0/10. Loss: 1.1564:  50%|[36m█████     [0m| 13/26 [00:14<00:13,  1.02s/it]Epoch: 0/10. Loss: 1.2081:  50%|[36m█████     [0m| 13/26 [00:15<00:13,  1.02s/it]Epoch: 0/10. Loss: 1.2081:  54%|[36m█████▍    [0m| 14/26 [00:15<00:11,  1.06it/s]Epoch: 0/10. Loss: 1.4011:  54%|[36m█████▍    [0m| 14/26 [00:16<00:11,  1.06it/s]Epoch: 0/10. Loss: 1.4011:  58%|[36m█████▊    [0m| 15/26 [00:16<00:10,  1.07it/s]Epoch: 0/10. Loss: 1.1430:  58%|[36m█████▊    [0m| 15/26 [00:17<00:10,  1.07it/s]Epoch: 0/10. Loss: 1.1430:  62%|[36m██████▏   [0m| 16/26 [00:17<00:09,  1.10it/s]Epoch: 0/10. Loss: 1.3686:  62%|[36m██████▏   [0m| 16/26 [00:19<00:09,  1.10it/s]Epoch: 0/10. Loss: 1.3686:  65%|[36m██████▌   [0m| 17/26 [00:19<00:13,  1.50s/it]Epoch: 0/10. Loss: 1.1855:  65%|[36m██████▌   [0m| 17/26 [00:21<00:13,  1.50s/it]Epoch: 0/10. Loss: 1.1855:  69%|[36m██████▉   [0m| 18/26 [00:21<00:12,  1.57s/it]Epoch: 0/10. Loss: 1.1579:  69%|[36m██████▉   [0m| 18/26 [00:22<00:12,  1.57s/it]Epoch: 0/10. Loss: 1.1579:  73%|[36m███████▎  [0m| 19/26 [00:22<00:10,  1.47s/it]Epoch: 0/10. Loss: 1.2108:  73%|[36m███████▎  [0m| 19/26 [00:23<00:10,  1.47s/it]Epoch: 0/10. Loss: 1.2108:  77%|[36m███████▋  [0m| 20/26 [00:23<00:07,  1.33s/it]Epoch: 0/10. Loss: 1.0680:  77%|[36m███████▋  [0m| 20/26 [00:24<00:07,  1.33s/it]Epoch: 0/10. Loss: 1.0680:  81%|[36m████████  [0m| 21/26 [00:24<00:06,  1.20s/it]Epoch: 0/10. Loss: 1.1659:  81%|[36m████████  [0m| 21/26 [00:25<00:06,  1.20s/it]Epoch: 0/10. Loss: 1.1659:  85%|[36m████████▍ [0m| 22/26 [00:25<00:04,  1.10s/it]Epoch: 0/10. Loss: 1.0635:  85%|[36m████████▍ [0m| 22/26 [00:26<00:04,  1.10s/it]Epoch: 0/10. Loss: 1.0635:  88%|[36m████████▊ [0m| 23/26 [00:26<00:03,  1.10s/it]Epoch: 0/10. Loss: 1.0455:  88%|[36m████████▊ [0m| 23/26 [00:27<00:03,  1.10s/it]Epoch: 0/10. Loss: 1.0455:  92%|[36m█████████▏[0m| 24/26 [00:27<00:02,  1.05s/it]Epoch: 0/10. Loss: 1.0353:  92%|[36m█████████▏[0m| 24/26 [00:28<00:02,  1.05s/it]Epoch: 0/10. Loss: 1.0353:  96%|[36m█████████▌[0m| 25/26 [00:28<00:01,  1.01s/it]Epoch: 0/10. Loss: 1.2012:  96%|[36m█████████▌[0m| 25/26 [00:29<00:01,  1.01s/it]Epoch: 0/10. Loss: 1.2012: 100%|[36m██████████[0m| 26/26 [00:29<00:00,  1.09it/s]Epoch: 0/10. Loss: 1.2012: 100%|[36m██████████[0m| 26/26 [00:29<00:00,  1.13s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:05,  1.01it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:06,  1.24s/it] 43%|[33m████▎     [0m| 3/7 [00:02<00:03,  1.09it/s] 57%|[33m█████▋    [0m| 4/7 [00:04<00:03,  1.22s/it] 71%|[33m███████▏  [0m| 5/7 [00:05<00:01,  1.08it/s] 86%|[33m████████▌ [0m| 6/7 [00:05<00:00,  1.11it/s]100%|[33m██████████[0m| 7/7 [00:06<00:00,  1.37it/s]100%|[33m██████████[0m| 7/7 [00:06<00:00,  1.12it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 1/10. Loss: 0.9538:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 1/10. Loss: 0.9538:   4%|[36m▍         [0m| 1/26 [00:00<00:24,  1.01it/s]Epoch: 1/10. Loss: 1.1407:   4%|[36m▍         [0m| 1/26 [00:01<00:24,  1.01it/s]Epoch: 1/10. Loss: 1.1407:   8%|[36m▊         [0m| 2/26 [00:01<00:22,  1.06it/s]Epoch: 1/10. Loss: 1.0934:   8%|[36m▊         [0m| 2/26 [00:02<00:22,  1.06it/s]Epoch: 1/10. Loss: 1.0934:  12%|[36m█▏        [0m| 3/26 [00:02<00:22,  1.03it/s]Epoch: 1/10. Loss: 1.0308:  12%|[36m█▏        [0m| 3/26 [00:03<00:22,  1.03it/s]Epoch: 1/10. Loss: 1.0308:  15%|[36m█▌        [0m| 4/26 [00:03<00:22,  1.01s/it]Epoch: 1/10. Loss: 1.0823:  15%|[36m█▌        [0m| 4/26 [00:04<00:22,  1.01s/it]Epoch: 1/10. Loss: 1.0823:  19%|[36m█▉        [0m| 5/26 [00:04<00:20,  1.05it/s]Epoch: 1/10. Loss: 1.0174:  19%|[36m█▉        [0m| 5/26 [00:06<00:20,  1.05it/s]Epoch: 1/10. Loss: 1.0174:  23%|[36m██▎       [0m| 6/26 [00:06<00:21,  1.06s/it]Epoch: 1/10. Loss: 1.0395:  23%|[36m██▎       [0m| 6/26 [00:06<00:21,  1.06s/it]Epoch: 1/10. Loss: 1.0395:  27%|[36m██▋       [0m| 7/26 [00:06<00:19,  1.00s/it]Epoch: 1/10. Loss: 1.0450:  27%|[36m██▋       [0m| 7/26 [00:07<00:19,  1.00s/it]Epoch: 1/10. Loss: 1.0450:  31%|[36m███       [0m| 8/26 [00:07<00:18,  1.00s/it]Epoch: 1/10. Loss: 1.1134:  31%|[36m███       [0m| 8/26 [00:08<00:18,  1.00s/it]Epoch: 1/10. Loss: 1.1134:  35%|[36m███▍      [0m| 9/26 [00:08<00:15,  1.09it/s]Epoch: 1/10. Loss: 1.0720:  35%|[36m███▍      [0m| 9/26 [00:09<00:15,  1.09it/s]Epoch: 1/10. Loss: 1.0720:  38%|[36m███▊      [0m| 10/26 [00:09<00:15,  1.02it/s]Epoch: 1/10. Loss: 1.1390:  38%|[36m███▊      [0m| 10/26 [00:10<00:15,  1.02it/s]Epoch: 1/10. Loss: 1.1390:  42%|[36m████▏     [0m| 11/26 [00:10<00:14,  1.04it/s]Epoch: 1/10. Loss: 1.1121:  42%|[36m████▏     [0m| 11/26 [00:11<00:14,  1.04it/s]Epoch: 1/10. Loss: 1.1121:  46%|[36m████▌     [0m| 12/26 [00:11<00:13,  1.05it/s]Epoch: 1/10. Loss: 1.0557:  46%|[36m████▌     [0m| 12/26 [00:12<00:13,  1.05it/s]Epoch: 1/10. Loss: 1.0557:  50%|[36m█████     [0m| 13/26 [00:12<00:11,  1.11it/s]Epoch: 1/10. Loss: 1.0398:  50%|[36m█████     [0m| 13/26 [00:13<00:11,  1.11it/s]Epoch: 1/10. Loss: 1.0398:  54%|[36m█████▍    [0m| 14/26 [00:13<00:11,  1.01it/s]Epoch: 1/10. Loss: 1.0786:  54%|[36m█████▍    [0m| 14/26 [00:14<00:11,  1.01it/s]Epoch: 1/10. Loss: 1.0786:  58%|[36m█████▊    [0m| 15/26 [00:14<00:11,  1.01s/it]Epoch: 1/10. Loss: 0.9919:  58%|[36m█████▊    [0m| 15/26 [00:15<00:11,  1.01s/it]Epoch: 1/10. Loss: 0.9919:  62%|[36m██████▏   [0m| 16/26 [00:15<00:09,  1.01it/s]Epoch: 1/10. Loss: 0.9447:  62%|[36m██████▏   [0m| 16/26 [00:16<00:09,  1.01it/s]Epoch: 1/10. Loss: 0.9447:  65%|[36m██████▌   [0m| 17/26 [00:16<00:09,  1.02s/it]Epoch: 1/10. Loss: 1.0500:  65%|[36m██████▌   [0m| 17/26 [00:17<00:09,  1.02s/it]Epoch: 1/10. Loss: 1.0500:  69%|[36m██████▉   [0m| 18/26 [00:17<00:07,  1.05it/s]Epoch: 1/10. Loss: 1.1201:  69%|[36m██████▉   [0m| 18/26 [00:18<00:07,  1.05it/s]Epoch: 1/10. Loss: 1.1201:  73%|[36m███████▎  [0m| 19/26 [00:18<00:06,  1.09it/s]Epoch: 1/10. Loss: 0.9398:  73%|[36m███████▎  [0m| 19/26 [00:19<00:06,  1.09it/s]Epoch: 1/10. Loss: 0.9398:  77%|[36m███████▋  [0m| 20/26 [00:19<00:05,  1.06it/s]Epoch: 1/10. Loss: 0.9684:  77%|[36m███████▋  [0m| 20/26 [00:21<00:05,  1.06it/s]Epoch: 1/10. Loss: 0.9684:  81%|[36m████████  [0m| 21/26 [00:21<00:05,  1.19s/it]Epoch: 1/10. Loss: 1.0269:  81%|[36m████████  [0m| 21/26 [00:21<00:05,  1.19s/it]Epoch: 1/10. Loss: 1.0269:  85%|[36m████████▍ [0m| 22/26 [00:21<00:04,  1.09s/it]Epoch: 1/10. Loss: 1.0499:  85%|[36m████████▍ [0m| 22/26 [00:22<00:04,  1.09s/it]Epoch: 1/10. Loss: 1.0499:  88%|[36m████████▊ [0m| 23/26 [00:22<00:03,  1.04s/it]Epoch: 1/10. Loss: 0.9938:  88%|[36m████████▊ [0m| 23/26 [00:23<00:03,  1.04s/it]Epoch: 1/10. Loss: 0.9938:  92%|[36m█████████▏[0m| 24/26 [00:23<00:01,  1.01it/s]Epoch: 1/10. Loss: 1.0414:  92%|[36m█████████▏[0m| 24/26 [00:24<00:01,  1.01it/s]Epoch: 1/10. Loss: 1.0414:  96%|[36m█████████▌[0m| 25/26 [00:24<00:00,  1.13it/s]Epoch: 1/10. Loss: 0.9966:  96%|[36m█████████▌[0m| 25/26 [00:25<00:00,  1.13it/s]Epoch: 1/10. Loss: 0.9966: 100%|[36m██████████[0m| 26/26 [00:25<00:00,  1.09it/s]Epoch: 1/10. Loss: 0.9966: 100%|[36m██████████[0m| 26/26 [00:25<00:00,  1.02it/s]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:05,  1.16it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:05,  1.15s/it] 43%|[33m████▎     [0m| 3/7 [00:02<00:03,  1.20it/s] 57%|[33m█████▋    [0m| 4/7 [00:03<00:03,  1.00s/it] 71%|[33m███████▏  [0m| 5/7 [00:04<00:01,  1.30it/s] 86%|[33m████████▌ [0m| 6/7 [00:05<00:00,  1.29it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.64it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.31it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 2/10. Loss: 0.9800:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 2/10. Loss: 0.9800:   4%|[36m▍         [0m| 1/26 [00:00<00:18,  1.33it/s]Epoch: 2/10. Loss: 0.9874:   4%|[36m▍         [0m| 1/26 [00:01<00:18,  1.33it/s]Epoch: 2/10. Loss: 0.9874:   8%|[36m▊         [0m| 2/26 [00:01<00:22,  1.05it/s]Epoch: 2/10. Loss: 1.0474:   8%|[36m▊         [0m| 2/26 [00:02<00:22,  1.05it/s]Epoch: 2/10. Loss: 1.0474:  12%|[36m█▏        [0m| 3/26 [00:02<00:21,  1.09it/s]Epoch: 2/10. Loss: 1.0394:  12%|[36m█▏        [0m| 3/26 [00:04<00:21,  1.09it/s]Epoch: 2/10. Loss: 1.0394:  15%|[36m█▌        [0m| 4/26 [00:04<00:24,  1.13s/it]Epoch: 2/10. Loss: 1.0412:  15%|[36m█▌        [0m| 4/26 [00:05<00:24,  1.13s/it]Epoch: 2/10. Loss: 1.0412:  19%|[36m█▉        [0m| 5/26 [00:05<00:23,  1.12s/it]Epoch: 2/10. Loss: 0.9688:  19%|[36m█▉        [0m| 5/26 [00:06<00:23,  1.12s/it]Epoch: 2/10. Loss: 0.9688:  23%|[36m██▎       [0m| 6/26 [00:06<00:21,  1.08s/it]Epoch: 2/10. Loss: 1.0148:  23%|[36m██▎       [0m| 6/26 [00:07<00:21,  1.08s/it]Epoch: 2/10. Loss: 1.0148:  27%|[36m██▋       [0m| 7/26 [00:07<00:19,  1.00s/it]Epoch: 2/10. Loss: 1.0616:  27%|[36m██▋       [0m| 7/26 [00:08<00:19,  1.00s/it]Epoch: 2/10. Loss: 1.0616:  31%|[36m███       [0m| 8/26 [00:08<00:18,  1.02s/it]Epoch: 2/10. Loss: 1.0261:  31%|[36m███       [0m| 8/26 [00:09<00:18,  1.02s/it]Epoch: 2/10. Loss: 1.0261:  35%|[36m███▍      [0m| 9/26 [00:09<00:16,  1.04it/s]Epoch: 2/10. Loss: 1.0241:  35%|[36m███▍      [0m| 9/26 [00:09<00:16,  1.04it/s]Epoch: 2/10. Loss: 1.0241:  38%|[36m███▊      [0m| 10/26 [00:09<00:15,  1.06it/s]Epoch: 2/10. Loss: 0.9402:  38%|[36m███▊      [0m| 10/26 [00:10<00:15,  1.06it/s]Epoch: 2/10. Loss: 0.9402:  42%|[36m████▏     [0m| 11/26 [00:10<00:13,  1.13it/s]Epoch: 2/10. Loss: 1.0000:  42%|[36m████▏     [0m| 11/26 [00:11<00:13,  1.13it/s]Epoch: 2/10. Loss: 1.0000:  46%|[36m████▌     [0m| 12/26 [00:11<00:12,  1.12it/s]Epoch: 2/10. Loss: 1.0633:  46%|[36m████▌     [0m| 12/26 [00:12<00:12,  1.12it/s]Epoch: 2/10. Loss: 1.0633:  50%|[36m█████     [0m| 13/26 [00:12<00:11,  1.11it/s]Epoch: 2/10. Loss: 0.9223:  50%|[36m█████     [0m| 13/26 [00:13<00:11,  1.11it/s]Epoch: 2/10. Loss: 0.9223:  54%|[36m█████▍    [0m| 14/26 [00:13<00:10,  1.12it/s]Epoch: 2/10. Loss: 0.9578:  54%|[36m█████▍    [0m| 14/26 [00:14<00:10,  1.12it/s]Epoch: 2/10. Loss: 0.9578:  58%|[36m█████▊    [0m| 15/26 [00:14<00:10,  1.05it/s]Epoch: 2/10. Loss: 0.9889:  58%|[36m█████▊    [0m| 15/26 [00:16<00:10,  1.05it/s]Epoch: 2/10. Loss: 0.9889:  62%|[36m██████▏   [0m| 16/26 [00:16<00:12,  1.26s/it]Epoch: 2/10. Loss: 1.1557:  62%|[36m██████▏   [0m| 16/26 [00:17<00:12,  1.26s/it]Epoch: 2/10. Loss: 1.1557:  65%|[36m██████▌   [0m| 17/26 [00:17<00:10,  1.16s/it]Epoch: 2/10. Loss: 0.8730:  65%|[36m██████▌   [0m| 17/26 [00:18<00:10,  1.16s/it]Epoch: 2/10. Loss: 0.8730:  69%|[36m██████▉   [0m| 18/26 [00:18<00:08,  1.09s/it]Epoch: 2/10. Loss: 0.9852:  69%|[36m██████▉   [0m| 18/26 [00:19<00:08,  1.09s/it]Epoch: 2/10. Loss: 0.9852:  73%|[36m███████▎  [0m| 19/26 [00:19<00:07,  1.09s/it]Epoch: 2/10. Loss: 0.9387:  73%|[36m███████▎  [0m| 19/26 [00:20<00:07,  1.09s/it]Epoch: 2/10. Loss: 0.9387:  77%|[36m███████▋  [0m| 20/26 [00:20<00:06,  1.04s/it]Epoch: 2/10. Loss: 1.0449:  77%|[36m███████▋  [0m| 20/26 [00:22<00:06,  1.04s/it]Epoch: 2/10. Loss: 1.0449:  81%|[36m████████  [0m| 21/26 [00:22<00:06,  1.37s/it]Epoch: 2/10. Loss: 0.9619:  81%|[36m████████  [0m| 21/26 [00:23<00:06,  1.37s/it]Epoch: 2/10. Loss: 0.9619:  85%|[36m████████▍ [0m| 22/26 [00:23<00:04,  1.20s/it]Epoch: 2/10. Loss: 0.9122:  85%|[36m████████▍ [0m| 22/26 [00:24<00:04,  1.20s/it]Epoch: 2/10. Loss: 0.9122:  88%|[36m████████▊ [0m| 23/26 [00:24<00:03,  1.10s/it]Epoch: 2/10. Loss: 0.9192:  88%|[36m████████▊ [0m| 23/26 [00:25<00:03,  1.10s/it]Epoch: 2/10. Loss: 0.9192:  92%|[36m█████████▏[0m| 24/26 [00:25<00:02,  1.17s/it]Epoch: 2/10. Loss: 0.9765:  92%|[36m█████████▏[0m| 24/26 [00:26<00:02,  1.17s/it]Epoch: 2/10. Loss: 0.9765:  96%|[36m█████████▌[0m| 25/26 [00:26<00:01,  1.25s/it]Epoch: 2/10. Loss: 0.9628:  96%|[36m█████████▌[0m| 25/26 [00:27<00:01,  1.25s/it]Epoch: 2/10. Loss: 0.9628: 100%|[36m██████████[0m| 26/26 [00:27<00:00,  1.03s/it]Epoch: 2/10. Loss: 0.9628: 100%|[36m██████████[0m| 26/26 [00:27<00:00,  1.05s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:05,  1.13it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:06,  1.21s/it] 43%|[33m████▎     [0m| 3/7 [00:02<00:03,  1.13it/s] 57%|[33m█████▋    [0m| 4/7 [00:04<00:03,  1.07s/it] 71%|[33m███████▏  [0m| 5/7 [00:04<00:01,  1.23it/s] 86%|[33m████████▌ [0m| 6/7 [00:05<00:00,  1.22it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.56it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.24it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 3/10. Loss: 1.0433:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 3/10. Loss: 1.0433:   4%|[36m▍         [0m| 1/26 [00:00<00:22,  1.14it/s]Epoch: 3/10. Loss: 1.0062:   4%|[36m▍         [0m| 1/26 [00:01<00:22,  1.14it/s]Epoch: 3/10. Loss: 1.0062:   8%|[36m▊         [0m| 2/26 [00:01<00:22,  1.05it/s]Epoch: 3/10. Loss: 0.9648:   8%|[36m▊         [0m| 2/26 [00:02<00:22,  1.05it/s]Epoch: 3/10. Loss: 0.9648:  12%|[36m█▏        [0m| 3/26 [00:02<00:22,  1.00it/s]Epoch: 3/10. Loss: 0.9500:  12%|[36m█▏        [0m| 3/26 [00:03<00:22,  1.00it/s]Epoch: 3/10. Loss: 0.9500:  15%|[36m█▌        [0m| 4/26 [00:03<00:20,  1.06it/s]Epoch: 3/10. Loss: 1.0263:  15%|[36m█▌        [0m| 4/26 [00:04<00:20,  1.06it/s]Epoch: 3/10. Loss: 1.0263:  19%|[36m█▉        [0m| 5/26 [00:04<00:18,  1.12it/s]Epoch: 3/10. Loss: 0.8737:  19%|[36m█▉        [0m| 5/26 [00:05<00:18,  1.12it/s]Epoch: 3/10. Loss: 0.8737:  23%|[36m██▎       [0m| 6/26 [00:05<00:17,  1.14it/s]Epoch: 3/10. Loss: 0.9697:  23%|[36m██▎       [0m| 6/26 [00:06<00:17,  1.14it/s]Epoch: 3/10. Loss: 0.9697:  27%|[36m██▋       [0m| 7/26 [00:06<00:16,  1.13it/s]Epoch: 3/10. Loss: 0.9340:  27%|[36m██▋       [0m| 7/26 [00:07<00:16,  1.13it/s]Epoch: 3/10. Loss: 0.9340:  31%|[36m███       [0m| 8/26 [00:07<00:16,  1.11it/s]Epoch: 3/10. Loss: 0.9452:  31%|[36m███       [0m| 8/26 [00:08<00:16,  1.11it/s]Epoch: 3/10. Loss: 0.9452:  35%|[36m███▍      [0m| 9/26 [00:08<00:15,  1.07it/s]Epoch: 3/10. Loss: 0.9555:  35%|[36m███▍      [0m| 9/26 [00:09<00:15,  1.07it/s]Epoch: 3/10. Loss: 0.9555:  38%|[36m███▊      [0m| 10/26 [00:09<00:15,  1.04it/s]Epoch: 3/10. Loss: 0.9124:  38%|[36m███▊      [0m| 10/26 [00:10<00:15,  1.04it/s]Epoch: 3/10. Loss: 0.9124:  42%|[36m████▏     [0m| 11/26 [00:10<00:14,  1.01it/s]Epoch: 3/10. Loss: 0.9587:  42%|[36m████▏     [0m| 11/26 [00:11<00:14,  1.01it/s]Epoch: 3/10. Loss: 0.9587:  46%|[36m████▌     [0m| 12/26 [00:11<00:13,  1.04it/s]Epoch: 3/10. Loss: 1.0563:  46%|[36m████▌     [0m| 12/26 [00:12<00:13,  1.04it/s]Epoch: 3/10. Loss: 1.0563:  50%|[36m█████     [0m| 13/26 [00:12<00:12,  1.04it/s]Epoch: 3/10. Loss: 0.9075:  50%|[36m█████     [0m| 13/26 [00:13<00:12,  1.04it/s]Epoch: 3/10. Loss: 0.9075:  54%|[36m█████▍    [0m| 14/26 [00:13<00:11,  1.02it/s]Epoch: 3/10. Loss: 0.8806:  54%|[36m█████▍    [0m| 14/26 [00:14<00:11,  1.02it/s]Epoch: 3/10. Loss: 0.8806:  58%|[36m█████▊    [0m| 15/26 [00:14<00:10,  1.06it/s]Epoch: 3/10. Loss: 0.8855:  58%|[36m█████▊    [0m| 15/26 [00:15<00:10,  1.06it/s]Epoch: 3/10. Loss: 0.8855:  62%|[36m██████▏   [0m| 16/26 [00:15<00:09,  1.01it/s]Epoch: 3/10. Loss: 0.8692:  62%|[36m██████▏   [0m| 16/26 [00:16<00:09,  1.01it/s]Epoch: 3/10. Loss: 0.8692:  65%|[36m██████▌   [0m| 17/26 [00:16<00:08,  1.01it/s]Epoch: 3/10. Loss: 0.9964:  65%|[36m██████▌   [0m| 17/26 [00:17<00:08,  1.01it/s]Epoch: 3/10. Loss: 0.9964:  69%|[36m██████▉   [0m| 18/26 [00:17<00:07,  1.03it/s]Epoch: 3/10. Loss: 1.0326:  69%|[36m██████▉   [0m| 18/26 [00:18<00:07,  1.03it/s]Epoch: 3/10. Loss: 1.0326:  73%|[36m███████▎  [0m| 19/26 [00:18<00:07,  1.05s/it]Epoch: 3/10. Loss: 0.8260:  73%|[36m███████▎  [0m| 19/26 [00:19<00:07,  1.05s/it]Epoch: 3/10. Loss: 0.8260:  77%|[36m███████▋  [0m| 20/26 [00:19<00:06,  1.01s/it]Epoch: 3/10. Loss: 0.8067:  77%|[36m███████▋  [0m| 20/26 [00:20<00:06,  1.01s/it]Epoch: 3/10. Loss: 0.8067:  81%|[36m████████  [0m| 21/26 [00:20<00:04,  1.06it/s]Epoch: 3/10. Loss: 1.0035:  81%|[36m████████  [0m| 21/26 [00:20<00:04,  1.06it/s]Epoch: 3/10. Loss: 1.0035:  85%|[36m████████▍ [0m| 22/26 [00:20<00:03,  1.08it/s]Epoch: 3/10. Loss: 0.9129:  85%|[36m████████▍ [0m| 22/26 [00:21<00:03,  1.08it/s]Epoch: 3/10. Loss: 0.9129:  88%|[36m████████▊ [0m| 23/26 [00:21<00:02,  1.08it/s]Epoch: 3/10. Loss: 0.9587:  88%|[36m████████▊ [0m| 23/26 [00:22<00:02,  1.08it/s]Epoch: 3/10. Loss: 0.9587:  92%|[36m█████████▏[0m| 24/26 [00:22<00:01,  1.07it/s]Epoch: 3/10. Loss: 0.9664:  92%|[36m█████████▏[0m| 24/26 [00:23<00:01,  1.07it/s]Epoch: 3/10. Loss: 0.9664:  96%|[36m█████████▌[0m| 25/26 [00:23<00:00,  1.12it/s]Epoch: 3/10. Loss: 0.9564:  96%|[36m█████████▌[0m| 25/26 [00:24<00:00,  1.12it/s]Epoch: 3/10. Loss: 0.9564: 100%|[36m██████████[0m| 26/26 [00:24<00:00,  1.22it/s]Epoch: 3/10. Loss: 0.9564: 100%|[36m██████████[0m| 26/26 [00:24<00:00,  1.07it/s]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:04,  1.30it/s] 29%|[33m██▊       [0m| 2/7 [00:03<00:09,  1.83s/it] 43%|[33m████▎     [0m| 3/7 [00:03<00:04,  1.23s/it] 57%|[33m█████▋    [0m| 4/7 [00:05<00:03,  1.27s/it] 71%|[33m███████▏  [0m| 5/7 [00:05<00:01,  1.05it/s] 86%|[33m████████▌ [0m| 6/7 [00:06<00:00,  1.06it/s]100%|[33m██████████[0m| 7/7 [00:06<00:00,  1.37it/s]100%|[33m██████████[0m| 7/7 [00:06<00:00,  1.03it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 4/10. Loss: 0.9490:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 4/10. Loss: 0.9490:   4%|[36m▍         [0m| 1/26 [00:00<00:21,  1.15it/s]Epoch: 4/10. Loss: 0.9809:   4%|[36m▍         [0m| 1/26 [00:01<00:21,  1.15it/s]Epoch: 4/10. Loss: 0.9809:   8%|[36m▊         [0m| 2/26 [00:01<00:22,  1.09it/s]Epoch: 4/10. Loss: 0.8623:   8%|[36m▊         [0m| 2/26 [00:02<00:22,  1.09it/s]Epoch: 4/10. Loss: 0.8623:  12%|[36m█▏        [0m| 3/26 [00:02<00:20,  1.15it/s]Epoch: 4/10. Loss: 0.8327:  12%|[36m█▏        [0m| 3/26 [00:03<00:20,  1.15it/s]Epoch: 4/10. Loss: 0.8327:  15%|[36m█▌        [0m| 4/26 [00:03<00:20,  1.08it/s]Epoch: 4/10. Loss: 0.8893:  15%|[36m█▌        [0m| 4/26 [00:04<00:20,  1.08it/s]Epoch: 4/10. Loss: 0.8893:  19%|[36m█▉        [0m| 5/26 [00:04<00:19,  1.07it/s]Epoch: 4/10. Loss: 0.9133:  19%|[36m█▉        [0m| 5/26 [00:05<00:19,  1.07it/s]Epoch: 4/10. Loss: 0.9133:  23%|[36m██▎       [0m| 6/26 [00:05<00:19,  1.00it/s]Epoch: 4/10. Loss: 0.9825:  23%|[36m██▎       [0m| 6/26 [00:06<00:19,  1.00it/s]Epoch: 4/10. Loss: 0.9825:  27%|[36m██▋       [0m| 7/26 [00:06<00:18,  1.03it/s]Epoch: 4/10. Loss: 0.9318:  27%|[36m██▋       [0m| 7/26 [00:07<00:18,  1.03it/s]Epoch: 4/10. Loss: 0.9318:  31%|[36m███       [0m| 8/26 [00:07<00:17,  1.03it/s]Epoch: 4/10. Loss: 0.9083:  31%|[36m███       [0m| 8/26 [00:08<00:17,  1.03it/s]Epoch: 4/10. Loss: 0.9083:  35%|[36m███▍      [0m| 9/26 [00:08<00:17,  1.03s/it]Epoch: 4/10. Loss: 0.8342:  35%|[36m███▍      [0m| 9/26 [00:09<00:17,  1.03s/it]Epoch: 4/10. Loss: 0.8342:  38%|[36m███▊      [0m| 10/26 [00:09<00:16,  1.02s/it]Epoch: 4/10. Loss: 0.8330:  38%|[36m███▊      [0m| 10/26 [00:10<00:16,  1.02s/it]Epoch: 4/10. Loss: 0.8330:  42%|[36m████▏     [0m| 11/26 [00:10<00:14,  1.04it/s]Epoch: 4/10. Loss: 1.0643:  42%|[36m████▏     [0m| 11/26 [00:12<00:14,  1.04it/s]Epoch: 4/10. Loss: 1.0643:  46%|[36m████▌     [0m| 12/26 [00:12<00:15,  1.12s/it]Epoch: 4/10. Loss: 0.8832:  46%|[36m████▌     [0m| 12/26 [00:12<00:15,  1.12s/it]Epoch: 4/10. Loss: 0.8832:  50%|[36m█████     [0m| 13/26 [00:12<00:13,  1.06s/it]Epoch: 4/10. Loss: 1.0280:  50%|[36m█████     [0m| 13/26 [00:13<00:13,  1.06s/it]Epoch: 4/10. Loss: 1.0280:  54%|[36m█████▍    [0m| 14/26 [00:13<00:12,  1.04s/it]Epoch: 4/10. Loss: 0.9132:  54%|[36m█████▍    [0m| 14/26 [00:14<00:12,  1.04s/it]Epoch: 4/10. Loss: 0.9132:  58%|[36m█████▊    [0m| 15/26 [00:14<00:10,  1.05it/s]Epoch: 4/10. Loss: 0.8540:  58%|[36m█████▊    [0m| 15/26 [00:15<00:10,  1.05it/s]Epoch: 4/10. Loss: 0.8540:  62%|[36m██████▏   [0m| 16/26 [00:15<00:09,  1.09it/s]Epoch: 4/10. Loss: 0.9839:  62%|[36m██████▏   [0m| 16/26 [00:16<00:09,  1.09it/s]Epoch: 4/10. Loss: 0.9839:  65%|[36m██████▌   [0m| 17/26 [00:16<00:08,  1.08it/s]Epoch: 4/10. Loss: 0.9102:  65%|[36m██████▌   [0m| 17/26 [00:18<00:08,  1.08it/s]Epoch: 4/10. Loss: 0.9102:  69%|[36m██████▉   [0m| 18/26 [00:18<00:09,  1.19s/it]Epoch: 4/10. Loss: 0.9330:  69%|[36m██████▉   [0m| 18/26 [00:19<00:09,  1.19s/it]Epoch: 4/10. Loss: 0.9330:  73%|[36m███████▎  [0m| 19/26 [00:19<00:07,  1.13s/it]Epoch: 4/10. Loss: 0.8746:  73%|[36m███████▎  [0m| 19/26 [00:20<00:07,  1.13s/it]Epoch: 4/10. Loss: 0.8746:  77%|[36m███████▋  [0m| 20/26 [00:20<00:06,  1.09s/it]Epoch: 4/10. Loss: 0.8929:  77%|[36m███████▋  [0m| 20/26 [00:21<00:06,  1.09s/it]Epoch: 4/10. Loss: 0.8929:  81%|[36m████████  [0m| 21/26 [00:21<00:05,  1.04s/it]Epoch: 4/10. Loss: 0.8244:  81%|[36m████████  [0m| 21/26 [00:22<00:05,  1.04s/it]Epoch: 4/10. Loss: 0.8244:  85%|[36m████████▍ [0m| 22/26 [00:22<00:04,  1.03s/it]Epoch: 4/10. Loss: 0.8994:  85%|[36m████████▍ [0m| 22/26 [00:23<00:04,  1.03s/it]Epoch: 4/10. Loss: 0.8994:  88%|[36m████████▊ [0m| 23/26 [00:23<00:02,  1.02it/s]Epoch: 4/10. Loss: 1.0508:  88%|[36m████████▊ [0m| 23/26 [00:23<00:02,  1.02it/s]Epoch: 4/10. Loss: 1.0508:  92%|[36m█████████▏[0m| 24/26 [00:23<00:01,  1.06it/s]Epoch: 4/10. Loss: 0.9311:  92%|[36m█████████▏[0m| 24/26 [00:24<00:01,  1.06it/s]Epoch: 4/10. Loss: 0.9311:  96%|[36m█████████▌[0m| 25/26 [00:24<00:00,  1.05it/s]Epoch: 4/10. Loss: 0.7976:  96%|[36m█████████▌[0m| 25/26 [00:25<00:00,  1.05it/s]Epoch: 4/10. Loss: 0.7976: 100%|[36m██████████[0m| 26/26 [00:25<00:00,  1.21it/s]Epoch: 4/10. Loss: 0.7976: 100%|[36m██████████[0m| 26/26 [00:25<00:00,  1.02it/s]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:04,  1.24it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:05,  1.17s/it] 43%|[33m████▎     [0m| 3/7 [00:02<00:03,  1.15it/s] 57%|[33m█████▋    [0m| 4/7 [00:04<00:03,  1.08s/it] 71%|[33m███████▏  [0m| 5/7 [00:04<00:01,  1.21it/s] 86%|[33m████████▌ [0m| 6/7 [00:05<00:00,  1.18it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.51it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.23it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 5/10. Loss: 0.8811:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 5/10. Loss: 0.8811:   4%|[36m▍         [0m| 1/26 [00:00<00:21,  1.16it/s]Epoch: 5/10. Loss: 0.8637:   4%|[36m▍         [0m| 1/26 [00:01<00:21,  1.16it/s]Epoch: 5/10. Loss: 0.8637:   8%|[36m▊         [0m| 2/26 [00:01<00:19,  1.21it/s]Epoch: 5/10. Loss: 0.8235:   8%|[36m▊         [0m| 2/26 [00:03<00:19,  1.21it/s]Epoch: 5/10. Loss: 0.8235:  12%|[36m█▏        [0m| 3/26 [00:03<00:25,  1.09s/it]Epoch: 5/10. Loss: 0.8780:  12%|[36m█▏        [0m| 3/26 [00:03<00:25,  1.09s/it]Epoch: 5/10. Loss: 0.8780:  15%|[36m█▌        [0m| 4/26 [00:03<00:21,  1.04it/s]Epoch: 5/10. Loss: 0.9387:  15%|[36m█▌        [0m| 4/26 [00:04<00:21,  1.04it/s]Epoch: 5/10. Loss: 0.9387:  19%|[36m█▉        [0m| 5/26 [00:04<00:20,  1.04it/s]Epoch: 5/10. Loss: 0.9110:  19%|[36m█▉        [0m| 5/26 [00:05<00:20,  1.04it/s]Epoch: 5/10. Loss: 0.9110:  23%|[36m██▎       [0m| 6/26 [00:05<00:18,  1.09it/s]Epoch: 5/10. Loss: 0.9739:  23%|[36m██▎       [0m| 6/26 [00:06<00:18,  1.09it/s]Epoch: 5/10. Loss: 0.9739:  27%|[36m██▋       [0m| 7/26 [00:06<00:17,  1.10it/s]Epoch: 5/10. Loss: 0.8614:  27%|[36m██▋       [0m| 7/26 [00:07<00:17,  1.10it/s]Epoch: 5/10. Loss: 0.8614:  31%|[36m███       [0m| 8/26 [00:07<00:17,  1.02it/s]Epoch: 5/10. Loss: 0.8384:  31%|[36m███       [0m| 8/26 [00:08<00:17,  1.02it/s]Epoch: 5/10. Loss: 0.8384:  35%|[36m███▍      [0m| 9/26 [00:08<00:16,  1.05it/s]Epoch: 5/10. Loss: 0.8274:  35%|[36m███▍      [0m| 9/26 [00:09<00:16,  1.05it/s]Epoch: 5/10. Loss: 0.8274:  38%|[36m███▊      [0m| 10/26 [00:09<00:14,  1.08it/s]Epoch: 5/10. Loss: 0.8853:  38%|[36m███▊      [0m| 10/26 [00:10<00:14,  1.08it/s]Epoch: 5/10. Loss: 0.8853:  42%|[36m████▏     [0m| 11/26 [00:10<00:14,  1.04it/s]Epoch: 5/10. Loss: 0.8389:  42%|[36m████▏     [0m| 11/26 [00:11<00:14,  1.04it/s]Epoch: 5/10. Loss: 0.8389:  46%|[36m████▌     [0m| 12/26 [00:11<00:13,  1.08it/s]Epoch: 5/10. Loss: 0.9520:  46%|[36m████▌     [0m| 12/26 [00:12<00:13,  1.08it/s]Epoch: 5/10. Loss: 0.9520:  50%|[36m█████     [0m| 13/26 [00:12<00:12,  1.06it/s]Epoch: 5/10. Loss: 0.8105:  50%|[36m█████     [0m| 13/26 [00:13<00:12,  1.06it/s]Epoch: 5/10. Loss: 0.8105:  54%|[36m█████▍    [0m| 14/26 [00:13<00:11,  1.07it/s]Epoch: 5/10. Loss: 0.8151:  54%|[36m█████▍    [0m| 14/26 [00:14<00:11,  1.07it/s]Epoch: 5/10. Loss: 0.8151:  58%|[36m█████▊    [0m| 15/26 [00:14<00:10,  1.02it/s]Epoch: 5/10. Loss: 0.9211:  58%|[36m█████▊    [0m| 15/26 [00:15<00:10,  1.02it/s]Epoch: 5/10. Loss: 0.9211:  62%|[36m██████▏   [0m| 16/26 [00:15<00:09,  1.11it/s]Epoch: 5/10. Loss: 0.8872:  62%|[36m██████▏   [0m| 16/26 [00:15<00:09,  1.11it/s]Epoch: 5/10. Loss: 0.8872:  65%|[36m██████▌   [0m| 17/26 [00:15<00:08,  1.11it/s]Epoch: 5/10. Loss: 0.8826:  65%|[36m██████▌   [0m| 17/26 [00:16<00:08,  1.11it/s]Epoch: 5/10. Loss: 0.8826:  69%|[36m██████▉   [0m| 18/26 [00:16<00:07,  1.11it/s]Epoch: 5/10. Loss: 0.8553:  69%|[36m██████▉   [0m| 18/26 [00:17<00:07,  1.11it/s]Epoch: 5/10. Loss: 0.8553:  73%|[36m███████▎  [0m| 19/26 [00:17<00:06,  1.12it/s]Epoch: 5/10. Loss: 0.8419:  73%|[36m███████▎  [0m| 19/26 [00:18<00:06,  1.12it/s]Epoch: 5/10. Loss: 0.8419:  77%|[36m███████▋  [0m| 20/26 [00:18<00:05,  1.17it/s]Epoch: 5/10. Loss: 0.9216:  77%|[36m███████▋  [0m| 20/26 [00:19<00:05,  1.17it/s]Epoch: 5/10. Loss: 0.9216:  81%|[36m████████  [0m| 21/26 [00:19<00:04,  1.10it/s]Epoch: 5/10. Loss: 0.8667:  81%|[36m████████  [0m| 21/26 [00:20<00:04,  1.10it/s]Epoch: 5/10. Loss: 0.8667:  85%|[36m████████▍ [0m| 22/26 [00:20<00:03,  1.05it/s]Epoch: 5/10. Loss: 0.8475:  85%|[36m████████▍ [0m| 22/26 [00:21<00:03,  1.05it/s]Epoch: 5/10. Loss: 0.8475:  88%|[36m████████▊ [0m| 23/26 [00:21<00:02,  1.06it/s]Epoch: 5/10. Loss: 0.8107:  88%|[36m████████▊ [0m| 23/26 [00:22<00:02,  1.06it/s]Epoch: 5/10. Loss: 0.8107:  92%|[36m█████████▏[0m| 24/26 [00:22<00:01,  1.02it/s]Epoch: 5/10. Loss: 0.8944:  92%|[36m█████████▏[0m| 24/26 [00:23<00:01,  1.02it/s]Epoch: 5/10. Loss: 0.8944:  96%|[36m█████████▌[0m| 25/26 [00:23<00:00,  1.12it/s]Epoch: 5/10. Loss: 0.9067:  96%|[36m█████████▌[0m| 25/26 [00:23<00:00,  1.12it/s]Epoch: 5/10. Loss: 0.9067: 100%|[36m██████████[0m| 26/26 [00:23<00:00,  1.21it/s]Epoch: 5/10. Loss: 0.9067: 100%|[36m██████████[0m| 26/26 [00:23<00:00,  1.09it/s]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:04,  1.28it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:05,  1.17s/it] 43%|[33m████▎     [0m| 3/7 [00:02<00:03,  1.13it/s] 57%|[33m█████▋    [0m| 4/7 [00:04<00:03,  1.08s/it] 71%|[33m███████▏  [0m| 5/7 [00:04<00:01,  1.19it/s] 86%|[33m████████▌ [0m| 6/7 [00:05<00:00,  1.17it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.49it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.22it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 6/10. Loss: 0.9876:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 6/10. Loss: 0.9876:   4%|[36m▍         [0m| 1/26 [00:00<00:22,  1.13it/s]Epoch: 6/10. Loss: 0.8365:   4%|[36m▍         [0m| 1/26 [00:01<00:22,  1.13it/s]Epoch: 6/10. Loss: 0.8365:   8%|[36m▊         [0m| 2/26 [00:01<00:22,  1.07it/s]Epoch: 6/10. Loss: 0.8311:   8%|[36m▊         [0m| 2/26 [00:02<00:22,  1.07it/s]Epoch: 6/10. Loss: 0.8311:  12%|[36m█▏        [0m| 3/26 [00:02<00:20,  1.12it/s]Epoch: 6/10. Loss: 0.9322:  12%|[36m█▏        [0m| 3/26 [00:03<00:20,  1.12it/s]Epoch: 6/10. Loss: 0.9322:  15%|[36m█▌        [0m| 4/26 [00:03<00:20,  1.09it/s]Epoch: 6/10. Loss: 0.8318:  15%|[36m█▌        [0m| 4/26 [00:04<00:20,  1.09it/s]Epoch: 6/10. Loss: 0.8318:  19%|[36m█▉        [0m| 5/26 [00:04<00:19,  1.06it/s]Epoch: 6/10. Loss: 0.8621:  19%|[36m█▉        [0m| 5/26 [00:05<00:19,  1.06it/s]Epoch: 6/10. Loss: 0.8621:  23%|[36m██▎       [0m| 6/26 [00:05<00:18,  1.06it/s]Epoch: 6/10. Loss: 0.8984:  23%|[36m██▎       [0m| 6/26 [00:06<00:18,  1.06it/s]Epoch: 6/10. Loss: 0.8984:  27%|[36m██▋       [0m| 7/26 [00:06<00:17,  1.12it/s]Epoch: 6/10. Loss: 0.8241:  27%|[36m██▋       [0m| 7/26 [00:07<00:17,  1.12it/s]Epoch: 6/10. Loss: 0.8241:  31%|[36m███       [0m| 8/26 [00:07<00:16,  1.11it/s]Epoch: 6/10. Loss: 0.9713:  31%|[36m███       [0m| 8/26 [00:08<00:16,  1.11it/s]Epoch: 6/10. Loss: 0.9713:  35%|[36m███▍      [0m| 9/26 [00:08<00:16,  1.06it/s]Epoch: 6/10. Loss: 0.8384:  35%|[36m███▍      [0m| 9/26 [00:09<00:16,  1.06it/s]Epoch: 6/10. Loss: 0.8384:  38%|[36m███▊      [0m| 10/26 [00:09<00:14,  1.09it/s]Epoch: 6/10. Loss: 0.8614:  38%|[36m███▊      [0m| 10/26 [00:10<00:14,  1.09it/s]Epoch: 6/10. Loss: 0.8614:  42%|[36m████▏     [0m| 11/26 [00:10<00:13,  1.13it/s]Epoch: 6/10. Loss: 0.8125:  42%|[36m████▏     [0m| 11/26 [00:10<00:13,  1.13it/s]Epoch: 6/10. Loss: 0.8125:  46%|[36m████▌     [0m| 12/26 [00:10<00:12,  1.12it/s]Epoch: 6/10. Loss: 0.9554:  46%|[36m████▌     [0m| 12/26 [00:11<00:12,  1.12it/s]Epoch: 6/10. Loss: 0.9554:  50%|[36m█████     [0m| 13/26 [00:11<00:11,  1.11it/s]Epoch: 6/10. Loss: 0.8439:  50%|[36m█████     [0m| 13/26 [00:13<00:11,  1.11it/s]Epoch: 6/10. Loss: 0.8439:  54%|[36m█████▍    [0m| 14/26 [00:13<00:13,  1.10s/it]Epoch: 6/10. Loss: 0.8543:  54%|[36m█████▍    [0m| 14/26 [00:14<00:13,  1.10s/it]Epoch: 6/10. Loss: 0.8543:  58%|[36m█████▊    [0m| 15/26 [00:14<00:11,  1.02s/it]Epoch: 6/10. Loss: 0.8625:  58%|[36m█████▊    [0m| 15/26 [00:15<00:11,  1.02s/it]Epoch: 6/10. Loss: 0.8625:  62%|[36m██████▏   [0m| 16/26 [00:15<00:09,  1.04it/s]Epoch: 6/10. Loss: 0.8579:  62%|[36m██████▏   [0m| 16/26 [00:16<00:09,  1.04it/s]Epoch: 6/10. Loss: 0.8579:  65%|[36m██████▌   [0m| 17/26 [00:16<00:08,  1.03it/s]Epoch: 6/10. Loss: 0.9381:  65%|[36m██████▌   [0m| 17/26 [00:16<00:08,  1.03it/s]Epoch: 6/10. Loss: 0.9381:  69%|[36m██████▉   [0m| 18/26 [00:16<00:07,  1.05it/s]Epoch: 6/10. Loss: 0.7788:  69%|[36m██████▉   [0m| 18/26 [00:17<00:07,  1.05it/s]Epoch: 6/10. Loss: 0.7788:  73%|[36m███████▎  [0m| 19/26 [00:17<00:06,  1.10it/s]Epoch: 6/10. Loss: 0.8459:  73%|[36m███████▎  [0m| 19/26 [00:18<00:06,  1.10it/s]Epoch: 6/10. Loss: 0.8459:  77%|[36m███████▋  [0m| 20/26 [00:18<00:05,  1.07it/s]Epoch: 6/10. Loss: 0.8066:  77%|[36m███████▋  [0m| 20/26 [00:19<00:05,  1.07it/s]Epoch: 6/10. Loss: 0.8066:  81%|[36m████████  [0m| 21/26 [00:19<00:04,  1.09it/s]Epoch: 6/10. Loss: 0.8164:  81%|[36m████████  [0m| 21/26 [00:22<00:04,  1.09it/s]Epoch: 6/10. Loss: 0.8164:  85%|[36m████████▍ [0m| 22/26 [00:22<00:05,  1.42s/it]Epoch: 6/10. Loss: 0.8276:  85%|[36m████████▍ [0m| 22/26 [00:24<00:05,  1.42s/it]Epoch: 6/10. Loss: 0.8276:  88%|[36m████████▊ [0m| 23/26 [00:24<00:05,  1.71s/it]Epoch: 6/10. Loss: 0.8981:  88%|[36m████████▊ [0m| 23/26 [00:25<00:05,  1.71s/it]Epoch: 6/10. Loss: 0.8981:  92%|[36m█████████▏[0m| 24/26 [00:25<00:03,  1.53s/it]Epoch: 6/10. Loss: 0.7402:  92%|[36m█████████▏[0m| 24/26 [00:26<00:03,  1.53s/it]Epoch: 6/10. Loss: 0.7402:  96%|[36m█████████▌[0m| 25/26 [00:26<00:01,  1.35s/it]Epoch: 6/10. Loss: 0.7641:  96%|[36m█████████▌[0m| 25/26 [00:27<00:01,  1.35s/it]Epoch: 6/10. Loss: 0.7641: 100%|[36m██████████[0m| 26/26 [00:27<00:00,  1.16s/it]Epoch: 6/10. Loss: 0.7641: 100%|[36m██████████[0m| 26/26 [00:27<00:00,  1.05s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:04,  1.23it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:05,  1.18s/it] 43%|[33m████▎     [0m| 3/7 [00:02<00:03,  1.14it/s] 57%|[33m█████▋    [0m| 4/7 [00:04<00:03,  1.05s/it] 71%|[33m███████▏  [0m| 5/7 [00:04<00:01,  1.22it/s] 86%|[33m████████▌ [0m| 6/7 [00:05<00:00,  1.18it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.50it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.23it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 7/10. Loss: 0.8418:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 7/10. Loss: 0.8418:   4%|[36m▍         [0m| 1/26 [00:00<00:21,  1.15it/s]Epoch: 7/10. Loss: 0.8499:   4%|[36m▍         [0m| 1/26 [00:01<00:21,  1.15it/s]Epoch: 7/10. Loss: 0.8499:   8%|[36m▊         [0m| 2/26 [00:01<00:22,  1.09it/s]Epoch: 7/10. Loss: 0.8463:   8%|[36m▊         [0m| 2/26 [00:02<00:22,  1.09it/s]Epoch: 7/10. Loss: 0.8463:  12%|[36m█▏        [0m| 3/26 [00:03<00:23,  1.04s/it]Epoch: 7/10. Loss: 0.8565:  12%|[36m█▏        [0m| 3/26 [00:03<00:23,  1.04s/it]Epoch: 7/10. Loss: 0.8565:  15%|[36m█▌        [0m| 4/26 [00:03<00:20,  1.06it/s]Epoch: 7/10. Loss: 0.8875:  15%|[36m█▌        [0m| 4/26 [00:04<00:20,  1.06it/s]Epoch: 7/10. Loss: 0.8875:  19%|[36m█▉        [0m| 5/26 [00:04<00:21,  1.03s/it]Epoch: 7/10. Loss: 0.8545:  19%|[36m█▉        [0m| 5/26 [00:05<00:21,  1.03s/it]Epoch: 7/10. Loss: 0.8545:  23%|[36m██▎       [0m| 6/26 [00:05<00:20,  1.01s/it]Epoch: 7/10. Loss: 0.9010:  23%|[36m██▎       [0m| 6/26 [00:06<00:20,  1.01s/it]Epoch: 7/10. Loss: 0.9010:  27%|[36m██▋       [0m| 7/26 [00:07<00:19,  1.02s/it]Epoch: 7/10. Loss: 0.8034:  27%|[36m██▋       [0m| 7/26 [00:08<00:19,  1.02s/it]Epoch: 7/10. Loss: 0.8034:  31%|[36m███       [0m| 8/26 [00:08<00:21,  1.21s/it]Epoch: 7/10. Loss: 0.8680:  31%|[36m███       [0m| 8/26 [00:09<00:21,  1.21s/it]Epoch: 7/10. Loss: 0.8680:  35%|[36m███▍      [0m| 9/26 [00:09<00:19,  1.15s/it]Epoch: 7/10. Loss: 0.8452:  35%|[36m███▍      [0m| 9/26 [00:10<00:19,  1.15s/it]Epoch: 7/10. Loss: 0.8452:  38%|[36m███▊      [0m| 10/26 [00:10<00:17,  1.09s/it]Epoch: 7/10. Loss: 0.9660:  38%|[36m███▊      [0m| 10/26 [00:11<00:17,  1.09s/it]Epoch: 7/10. Loss: 0.9660:  42%|[36m████▏     [0m| 11/26 [00:11<00:15,  1.01s/it]Epoch: 7/10. Loss: 0.9007:  42%|[36m████▏     [0m| 11/26 [00:12<00:15,  1.01s/it]Epoch: 7/10. Loss: 0.9007:  46%|[36m████▌     [0m| 12/26 [00:12<00:13,  1.08it/s]Epoch: 7/10. Loss: 0.8152:  46%|[36m████▌     [0m| 12/26 [00:13<00:13,  1.08it/s]Epoch: 7/10. Loss: 0.8152:  50%|[36m█████     [0m| 13/26 [00:13<00:11,  1.10it/s]Epoch: 7/10. Loss: 0.7752:  50%|[36m█████     [0m| 13/26 [00:13<00:11,  1.10it/s]Epoch: 7/10. Loss: 0.7752:  54%|[36m█████▍    [0m| 14/26 [00:13<00:11,  1.08it/s]Epoch: 7/10. Loss: 0.8562:  54%|[36m█████▍    [0m| 14/26 [00:15<00:11,  1.08it/s]Epoch: 7/10. Loss: 0.8562:  58%|[36m█████▊    [0m| 15/26 [00:15<00:10,  1.04it/s]Epoch: 7/10. Loss: 0.6855:  58%|[36m█████▊    [0m| 15/26 [00:15<00:10,  1.04it/s]Epoch: 7/10. Loss: 0.6855:  62%|[36m██████▏   [0m| 16/26 [00:15<00:09,  1.08it/s]Epoch: 7/10. Loss: 0.9434:  62%|[36m██████▏   [0m| 16/26 [00:16<00:09,  1.08it/s]Epoch: 7/10. Loss: 0.9434:  65%|[36m██████▌   [0m| 17/26 [00:16<00:08,  1.05it/s]Epoch: 7/10. Loss: 0.8400:  65%|[36m██████▌   [0m| 17/26 [00:17<00:08,  1.05it/s]Epoch: 7/10. Loss: 0.8400:  69%|[36m██████▉   [0m| 18/26 [00:17<00:07,  1.06it/s]Epoch: 7/10. Loss: 1.0625:  69%|[36m██████▉   [0m| 18/26 [00:18<00:07,  1.06it/s]Epoch: 7/10. Loss: 1.0625:  73%|[36m███████▎  [0m| 19/26 [00:18<00:06,  1.05it/s]Epoch: 7/10. Loss: 0.7947:  73%|[36m███████▎  [0m| 19/26 [00:19<00:06,  1.05it/s]Epoch: 7/10. Loss: 0.7947:  77%|[36m███████▋  [0m| 20/26 [00:19<00:05,  1.08it/s]Epoch: 7/10. Loss: 0.8211:  77%|[36m███████▋  [0m| 20/26 [00:20<00:05,  1.08it/s]Epoch: 7/10. Loss: 0.8211:  81%|[36m████████  [0m| 21/26 [00:20<00:04,  1.08it/s]Epoch: 7/10. Loss: 0.8934:  81%|[36m████████  [0m| 21/26 [00:21<00:04,  1.08it/s]Epoch: 7/10. Loss: 0.8934:  85%|[36m████████▍ [0m| 22/26 [00:21<00:03,  1.12it/s]Epoch: 7/10. Loss: 0.8857:  85%|[36m████████▍ [0m| 22/26 [00:22<00:03,  1.12it/s]Epoch: 7/10. Loss: 0.8857:  88%|[36m████████▊ [0m| 23/26 [00:22<00:02,  1.14it/s]Epoch: 7/10. Loss: 0.8998:  88%|[36m████████▊ [0m| 23/26 [00:23<00:02,  1.14it/s]Epoch: 7/10. Loss: 0.8998:  92%|[36m█████████▏[0m| 24/26 [00:23<00:02,  1.01s/it]Epoch: 7/10. Loss: 0.8239:  92%|[36m█████████▏[0m| 24/26 [00:24<00:02,  1.01s/it]Epoch: 7/10. Loss: 0.8239:  96%|[36m█████████▌[0m| 25/26 [00:24<00:01,  1.03s/it]Epoch: 7/10. Loss: 0.7841:  96%|[36m█████████▌[0m| 25/26 [00:26<00:01,  1.03s/it]Epoch: 7/10. Loss: 0.7841: 100%|[36m██████████[0m| 26/26 [00:26<00:00,  1.30s/it]Epoch: 7/10. Loss: 0.7841: 100%|[36m██████████[0m| 26/26 [00:26<00:00,  1.02s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:01<00:07,  1.27s/it] 29%|[33m██▊       [0m| 2/7 [00:02<00:06,  1.37s/it] 43%|[33m████▎     [0m| 3/7 [00:03<00:03,  1.01it/s] 57%|[33m█████▋    [0m| 4/7 [00:04<00:03,  1.15s/it] 71%|[33m███████▏  [0m| 5/7 [00:07<00:03,  1.74s/it] 86%|[33m████████▌ [0m| 6/7 [00:08<00:01,  1.44s/it]100%|[33m██████████[0m| 7/7 [00:08<00:00,  1.07s/it]100%|[33m██████████[0m| 7/7 [00:08<00:00,  1.23s/it]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 8/10. Loss: 0.9050:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 8/10. Loss: 0.9050:   4%|[36m▍         [0m| 1/26 [00:00<00:23,  1.07it/s]Epoch: 8/10. Loss: 0.8193:   4%|[36m▍         [0m| 1/26 [00:01<00:23,  1.07it/s]Epoch: 8/10. Loss: 0.8193:   8%|[36m▊         [0m| 2/26 [00:01<00:24,  1.00s/it]Epoch: 8/10. Loss: 0.8398:   8%|[36m▊         [0m| 2/26 [00:02<00:24,  1.00s/it]Epoch: 8/10. Loss: 0.8398:  12%|[36m█▏        [0m| 3/26 [00:02<00:21,  1.08it/s]Epoch: 8/10. Loss: 0.8222:  12%|[36m█▏        [0m| 3/26 [00:03<00:21,  1.08it/s]Epoch: 8/10. Loss: 0.8222:  15%|[36m█▌        [0m| 4/26 [00:03<00:20,  1.08it/s]Epoch: 8/10. Loss: 0.8112:  15%|[36m█▌        [0m| 4/26 [00:04<00:20,  1.08it/s]Epoch: 8/10. Loss: 0.8112:  19%|[36m█▉        [0m| 5/26 [00:04<00:19,  1.09it/s]Epoch: 8/10. Loss: 0.8162:  19%|[36m█▉        [0m| 5/26 [00:05<00:19,  1.09it/s]Epoch: 8/10. Loss: 0.8162:  23%|[36m██▎       [0m| 6/26 [00:05<00:18,  1.10it/s]Epoch: 8/10. Loss: 0.7594:  23%|[36m██▎       [0m| 6/26 [00:06<00:18,  1.10it/s]Epoch: 8/10. Loss: 0.7594:  27%|[36m██▋       [0m| 7/26 [00:06<00:16,  1.18it/s]Epoch: 8/10. Loss: 0.8097:  27%|[36m██▋       [0m| 7/26 [00:07<00:16,  1.18it/s]Epoch: 8/10. Loss: 0.8097:  31%|[36m███       [0m| 8/26 [00:07<00:18,  1.05s/it]Epoch: 8/10. Loss: 0.8044:  31%|[36m███       [0m| 8/26 [00:08<00:18,  1.05s/it]Epoch: 8/10. Loss: 0.8044:  35%|[36m███▍      [0m| 9/26 [00:08<00:18,  1.07s/it]Epoch: 8/10. Loss: 0.7799:  35%|[36m███▍      [0m| 9/26 [00:09<00:18,  1.07s/it]Epoch: 8/10. Loss: 0.7799:  38%|[36m███▊      [0m| 10/26 [00:09<00:16,  1.03s/it]Epoch: 8/10. Loss: 0.9743:  38%|[36m███▊      [0m| 10/26 [00:10<00:16,  1.03s/it]Epoch: 8/10. Loss: 0.9743:  42%|[36m████▏     [0m| 11/26 [00:10<00:14,  1.01it/s]Epoch: 8/10. Loss: 0.8351:  42%|[36m████▏     [0m| 11/26 [00:11<00:14,  1.01it/s]Epoch: 8/10. Loss: 0.8351:  46%|[36m████▌     [0m| 12/26 [00:11<00:13,  1.01it/s]Epoch: 8/10. Loss: 0.8510:  46%|[36m████▌     [0m| 12/26 [00:12<00:13,  1.01it/s]Epoch: 8/10. Loss: 0.8510:  50%|[36m█████     [0m| 13/26 [00:12<00:13,  1.01s/it]Epoch: 8/10. Loss: 0.7894:  50%|[36m█████     [0m| 13/26 [00:13<00:13,  1.01s/it]Epoch: 8/10. Loss: 0.7894:  54%|[36m█████▍    [0m| 14/26 [00:13<00:11,  1.09it/s]Epoch: 8/10. Loss: 0.7697:  54%|[36m█████▍    [0m| 14/26 [00:14<00:11,  1.09it/s]Epoch: 8/10. Loss: 0.7697:  58%|[36m█████▊    [0m| 15/26 [00:14<00:10,  1.03it/s]Epoch: 8/10. Loss: 0.8299:  58%|[36m█████▊    [0m| 15/26 [00:15<00:10,  1.03it/s]Epoch: 8/10. Loss: 0.8299:  62%|[36m██████▏   [0m| 16/26 [00:15<00:09,  1.06it/s]Epoch: 8/10. Loss: 0.8000:  62%|[36m██████▏   [0m| 16/26 [00:16<00:09,  1.06it/s]Epoch: 8/10. Loss: 0.8000:  65%|[36m██████▌   [0m| 17/26 [00:16<00:08,  1.05it/s]Epoch: 8/10. Loss: 0.8231:  65%|[36m██████▌   [0m| 17/26 [00:17<00:08,  1.05it/s]Epoch: 8/10. Loss: 0.8231:  69%|[36m██████▉   [0m| 18/26 [00:17<00:07,  1.02it/s]Epoch: 8/10. Loss: 0.8817:  69%|[36m██████▉   [0m| 18/26 [00:20<00:07,  1.02it/s]Epoch: 8/10. Loss: 0.8817:  73%|[36m███████▎  [0m| 19/26 [00:20<00:11,  1.58s/it]Epoch: 8/10. Loss: 0.9586:  73%|[36m███████▎  [0m| 19/26 [00:21<00:11,  1.58s/it]Epoch: 8/10. Loss: 0.9586:  77%|[36m███████▋  [0m| 20/26 [00:21<00:08,  1.39s/it]Epoch: 8/10. Loss: 0.8808:  77%|[36m███████▋  [0m| 20/26 [00:22<00:08,  1.39s/it]Epoch: 8/10. Loss: 0.8808:  81%|[36m████████  [0m| 21/26 [00:22<00:06,  1.25s/it]Epoch: 8/10. Loss: 0.7801:  81%|[36m████████  [0m| 21/26 [00:23<00:06,  1.25s/it]Epoch: 8/10. Loss: 0.7801:  85%|[36m████████▍ [0m| 22/26 [00:23<00:04,  1.11s/it]Epoch: 8/10. Loss: 0.8179:  85%|[36m████████▍ [0m| 22/26 [00:23<00:04,  1.11s/it]Epoch: 8/10. Loss: 0.8179:  88%|[36m████████▊ [0m| 23/26 [00:23<00:03,  1.04s/it]Epoch: 8/10. Loss: 0.7836:  88%|[36m████████▊ [0m| 23/26 [00:24<00:03,  1.04s/it]Epoch: 8/10. Loss: 0.7836:  92%|[36m█████████▏[0m| 24/26 [00:24<00:01,  1.00it/s]Epoch: 8/10. Loss: 0.7414:  92%|[36m█████████▏[0m| 24/26 [00:25<00:01,  1.00it/s]Epoch: 8/10. Loss: 0.7414:  96%|[36m█████████▌[0m| 25/26 [00:25<00:00,  1.01it/s]Epoch: 8/10. Loss: 0.7815:  96%|[36m█████████▌[0m| 25/26 [00:26<00:00,  1.01it/s]Epoch: 8/10. Loss: 0.7815: 100%|[36m██████████[0m| 26/26 [00:26<00:00,  1.15it/s]Epoch: 8/10. Loss: 0.7815: 100%|[36m██████████[0m| 26/26 [00:26<00:00,  1.02s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:04,  1.21it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:05,  1.19s/it] 43%|[33m████▎     [0m| 3/7 [00:02<00:03,  1.12it/s] 57%|[33m█████▋    [0m| 4/7 [00:04<00:03,  1.16s/it] 71%|[33m███████▏  [0m| 5/7 [00:04<00:01,  1.12it/s] 86%|[33m████████▌ [0m| 6/7 [00:05<00:00,  1.05it/s]100%|[33m██████████[0m| 7/7 [00:06<00:00,  1.36it/s]100%|[33m██████████[0m| 7/7 [00:06<00:00,  1.14it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 9/10. Loss: 0.7591:   0%|[36m          [0m| 0/26 [00:03<?, ?it/s]Epoch: 9/10. Loss: 0.7591:   4%|[36m▍         [0m| 1/26 [00:03<01:20,  3.23s/it]Epoch: 9/10. Loss: 0.8834:   4%|[36m▍         [0m| 1/26 [00:04<01:20,  3.23s/it]Epoch: 9/10. Loss: 0.8834:   8%|[36m▊         [0m| 2/26 [00:04<00:44,  1.87s/it]Epoch: 9/10. Loss: 0.7616:   8%|[36m▊         [0m| 2/26 [00:05<00:44,  1.87s/it]Epoch: 9/10. Loss: 0.7616:  12%|[36m█▏        [0m| 3/26 [00:05<00:34,  1.49s/it]Epoch: 9/10. Loss: 0.8091:  12%|[36m█▏        [0m| 3/26 [00:06<00:34,  1.49s/it]Epoch: 9/10. Loss: 0.8091:  15%|[36m█▌        [0m| 4/26 [00:06<00:35,  1.60s/it]Epoch: 9/10. Loss: 0.7370:  15%|[36m█▌        [0m| 4/26 [00:07<00:35,  1.60s/it]Epoch: 9/10. Loss: 0.7370:  19%|[36m█▉        [0m| 5/26 [00:07<00:27,  1.31s/it]Epoch: 9/10. Loss: 0.7503:  19%|[36m█▉        [0m| 5/26 [00:09<00:27,  1.31s/it]Epoch: 9/10. Loss: 0.7503:  23%|[36m██▎       [0m| 6/26 [00:09<00:29,  1.49s/it]Epoch: 9/10. Loss: 0.9138:  23%|[36m██▎       [0m| 6/26 [00:10<00:29,  1.49s/it]Epoch: 9/10. Loss: 0.9138:  27%|[36m██▋       [0m| 7/26 [00:10<00:24,  1.28s/it]Epoch: 9/10. Loss: 0.9039:  27%|[36m██▋       [0m| 7/26 [00:11<00:24,  1.28s/it]Epoch: 9/10. Loss: 0.9039:  31%|[36m███       [0m| 8/26 [00:11<00:20,  1.13s/it]Epoch: 9/10. Loss: 0.8592:  31%|[36m███       [0m| 8/26 [00:12<00:20,  1.13s/it]Epoch: 9/10. Loss: 0.8592:  35%|[36m███▍      [0m| 9/26 [00:12<00:19,  1.14s/it]Epoch: 9/10. Loss: 0.8021:  35%|[36m███▍      [0m| 9/26 [00:13<00:19,  1.14s/it]Epoch: 9/10. Loss: 0.8021:  38%|[36m███▊      [0m| 10/26 [00:13<00:19,  1.23s/it]Epoch: 9/10. Loss: 0.8081:  38%|[36m███▊      [0m| 10/26 [00:14<00:19,  1.23s/it]Epoch: 9/10. Loss: 0.8081:  42%|[36m████▏     [0m| 11/26 [00:14<00:16,  1.09s/it]Epoch: 9/10. Loss: 0.8577:  42%|[36m████▏     [0m| 11/26 [00:15<00:16,  1.09s/it]Epoch: 9/10. Loss: 0.8577:  46%|[36m████▌     [0m| 12/26 [00:15<00:14,  1.02s/it]Epoch: 9/10. Loss: 0.9082:  46%|[36m████▌     [0m| 12/26 [00:16<00:14,  1.02s/it]Epoch: 9/10. Loss: 0.9082:  50%|[36m█████     [0m| 13/26 [00:16<00:13,  1.03s/it]Epoch: 9/10. Loss: 0.8288:  50%|[36m█████     [0m| 13/26 [00:17<00:13,  1.03s/it]Epoch: 9/10. Loss: 0.8288:  54%|[36m█████▍    [0m| 14/26 [00:17<00:11,  1.01it/s]Epoch: 9/10. Loss: 0.7972:  54%|[36m█████▍    [0m| 14/26 [00:19<00:11,  1.01it/s]Epoch: 9/10. Loss: 0.7972:  58%|[36m█████▊    [0m| 15/26 [00:19<00:12,  1.18s/it]Epoch: 9/10. Loss: 0.7451:  58%|[36m█████▊    [0m| 15/26 [00:19<00:12,  1.18s/it]Epoch: 9/10. Loss: 0.7451:  62%|[36m██████▏   [0m| 16/26 [00:19<00:10,  1.07s/it]Epoch: 9/10. Loss: 0.7898:  62%|[36m██████▏   [0m| 16/26 [00:20<00:10,  1.07s/it]Epoch: 9/10. Loss: 0.7898:  65%|[36m██████▌   [0m| 17/26 [00:20<00:09,  1.01s/it]Epoch: 9/10. Loss: 0.8449:  65%|[36m██████▌   [0m| 17/26 [00:21<00:09,  1.01s/it]Epoch: 9/10. Loss: 0.8449:  69%|[36m██████▉   [0m| 18/26 [00:21<00:07,  1.01it/s]Epoch: 9/10. Loss: 0.8951:  69%|[36m██████▉   [0m| 18/26 [00:22<00:07,  1.01it/s]Epoch: 9/10. Loss: 0.8951:  73%|[36m███████▎  [0m| 19/26 [00:22<00:06,  1.04it/s]Epoch: 9/10. Loss: 0.8093:  73%|[36m███████▎  [0m| 19/26 [00:23<00:06,  1.04it/s]Epoch: 9/10. Loss: 0.8093:  77%|[36m███████▋  [0m| 20/26 [00:23<00:05,  1.06it/s]Epoch: 9/10. Loss: 0.8058:  77%|[36m███████▋  [0m| 20/26 [00:24<00:05,  1.06it/s]Epoch: 9/10. Loss: 0.8058:  81%|[36m████████  [0m| 21/26 [00:24<00:04,  1.13it/s]Epoch: 9/10. Loss: 0.8440:  81%|[36m████████  [0m| 21/26 [00:24<00:04,  1.13it/s]Epoch: 9/10. Loss: 0.8440:  85%|[36m████████▍ [0m| 22/26 [00:24<00:03,  1.17it/s]Epoch: 9/10. Loss: 0.7506:  85%|[36m████████▍ [0m| 22/26 [00:25<00:03,  1.17it/s]Epoch: 9/10. Loss: 0.7506:  88%|[36m████████▊ [0m| 23/26 [00:25<00:02,  1.15it/s]Epoch: 9/10. Loss: 0.8411:  88%|[36m████████▊ [0m| 23/26 [00:26<00:02,  1.15it/s]Epoch: 9/10. Loss: 0.8411:  92%|[36m█████████▏[0m| 24/26 [00:26<00:01,  1.15it/s]Epoch: 9/10. Loss: 0.7382:  92%|[36m█████████▏[0m| 24/26 [00:28<00:01,  1.15it/s]Epoch: 9/10. Loss: 0.7382:  96%|[36m█████████▌[0m| 25/26 [00:28<00:01,  1.22s/it]Epoch: 9/10. Loss: 0.7724:  96%|[36m█████████▌[0m| 25/26 [00:30<00:01,  1.22s/it]Epoch: 9/10. Loss: 0.7724: 100%|[36m██████████[0m| 26/26 [00:30<00:00,  1.36s/it]Epoch: 9/10. Loss: 0.7724: 100%|[36m██████████[0m| 26/26 [00:30<00:00,  1.17s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:01<00:09,  1.59s/it] 29%|[33m██▊       [0m| 2/7 [00:03<00:08,  1.65s/it] 43%|[33m████▎     [0m| 3/7 [00:03<00:04,  1.18s/it] 57%|[33m█████▋    [0m| 4/7 [00:06<00:05,  1.87s/it] 71%|[33m███████▏  [0m| 5/7 [00:07<00:02,  1.43s/it] 86%|[33m████████▌ [0m| 6/7 [00:08<00:01,  1.24s/it]100%|[33m██████████[0m| 7/7 [00:08<00:00,  1.07it/s]100%|[33m██████████[0m| 7/7 [00:08<00:00,  1.24s/it]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 0/10. Loss: 1.3072:   0%|[36m          [0m| 0/26 [00:01<?, ?it/s]Epoch: 0/10. Loss: 1.3072:   4%|[36m▍         [0m| 1/26 [00:01<00:33,  1.34s/it]Epoch: 0/10. Loss: 10.6160:   4%|[36m▍         [0m| 1/26 [00:02<00:33,  1.34s/it]Epoch: 0/10. Loss: 10.6160:   8%|[36m▊         [0m| 2/26 [00:02<00:26,  1.10s/it]Epoch: 0/10. Loss: 2.4008:   8%|[36m▊         [0m| 2/26 [00:03<00:26,  1.10s/it] Epoch: 0/10. Loss: 2.4008:  12%|[36m█▏        [0m| 3/26 [00:03<00:23,  1.02s/it]Epoch: 0/10. Loss: 5.5437:  12%|[36m█▏        [0m| 3/26 [00:04<00:23,  1.02s/it]Epoch: 0/10. Loss: 5.5437:  15%|[36m█▌        [0m| 4/26 [00:04<00:20,  1.06it/s]Epoch: 0/10. Loss: 1.0725:  15%|[36m█▌        [0m| 4/26 [00:04<00:20,  1.06it/s]Epoch: 0/10. Loss: 1.0725:  19%|[36m█▉        [0m| 5/26 [00:04<00:19,  1.06it/s]Epoch: 0/10. Loss: 1.5123:  19%|[36m█▉        [0m| 5/26 [00:07<00:19,  1.06it/s]Epoch: 0/10. Loss: 1.5123:  23%|[36m██▎       [0m| 6/26 [00:07<00:28,  1.44s/it]Epoch: 0/10. Loss: 2.5042:  23%|[36m██▎       [0m| 6/26 [00:08<00:28,  1.44s/it]Epoch: 0/10. Loss: 2.5042:  27%|[36m██▋       [0m| 7/26 [00:09<00:28,  1.50s/it]Epoch: 0/10. Loss: 1.1294:  27%|[36m██▋       [0m| 7/26 [00:10<00:28,  1.50s/it]Epoch: 0/10. Loss: 1.1294:  31%|[36m███       [0m| 8/26 [00:10<00:24,  1.36s/it]Epoch: 0/10. Loss: 1.8725:  31%|[36m███       [0m| 8/26 [00:10<00:24,  1.36s/it]Epoch: 0/10. Loss: 1.8725:  35%|[36m███▍      [0m| 9/26 [00:10<00:20,  1.21s/it]Epoch: 0/10. Loss: 1.2476:  35%|[36m███▍      [0m| 9/26 [00:11<00:20,  1.21s/it]Epoch: 0/10. Loss: 1.2476:  38%|[36m███▊      [0m| 10/26 [00:11<00:17,  1.09s/it]Epoch: 0/10. Loss: 1.1955:  38%|[36m███▊      [0m| 10/26 [00:12<00:17,  1.09s/it]Epoch: 0/10. Loss: 1.1955:  42%|[36m████▏     [0m| 11/26 [00:12<00:15,  1.05s/it]Epoch: 0/10. Loss: 1.0635:  42%|[36m████▏     [0m| 11/26 [00:14<00:15,  1.05s/it]Epoch: 0/10. Loss: 1.0635:  46%|[36m████▌     [0m| 12/26 [00:14<00:18,  1.31s/it]Epoch: 0/10. Loss: 2.2126:  46%|[36m████▌     [0m| 12/26 [00:15<00:18,  1.31s/it]Epoch: 0/10. Loss: 2.2126:  50%|[36m█████     [0m| 13/26 [00:15<00:16,  1.24s/it]Epoch: 0/10. Loss: 1.2188:  50%|[36m█████     [0m| 13/26 [00:16<00:16,  1.24s/it]Epoch: 0/10. Loss: 1.2188:  54%|[36m█████▍    [0m| 14/26 [00:16<00:13,  1.16s/it]Epoch: 0/10. Loss: 1.6409:  54%|[36m█████▍    [0m| 14/26 [00:17<00:13,  1.16s/it]Epoch: 0/10. Loss: 1.6409:  58%|[36m█████▊    [0m| 15/26 [00:17<00:11,  1.07s/it]Epoch: 0/10. Loss: 3.3388:  58%|[36m█████▊    [0m| 15/26 [00:18<00:11,  1.07s/it]Epoch: 0/10. Loss: 3.3388:  62%|[36m██████▏   [0m| 16/26 [00:18<00:10,  1.05s/it]Epoch: 0/10. Loss: 1.2244:  62%|[36m██████▏   [0m| 16/26 [00:19<00:10,  1.05s/it]Epoch: 0/10. Loss: 1.2244:  65%|[36m██████▌   [0m| 17/26 [00:19<00:09,  1.03s/it]Epoch: 0/10. Loss: 1.8037:  65%|[36m██████▌   [0m| 17/26 [00:20<00:09,  1.03s/it]Epoch: 0/10. Loss: 1.8037:  69%|[36m██████▉   [0m| 18/26 [00:20<00:07,  1.01it/s]Epoch: 0/10. Loss: 1.2290:  69%|[36m██████▉   [0m| 18/26 [00:21<00:07,  1.01it/s]Epoch: 0/10. Loss: 1.2290:  73%|[36m███████▎  [0m| 19/26 [00:21<00:06,  1.00it/s]Epoch: 0/10. Loss: 1.8035:  73%|[36m███████▎  [0m| 19/26 [00:22<00:06,  1.00it/s]Epoch: 0/10. Loss: 1.8035:  77%|[36m███████▋  [0m| 20/26 [00:22<00:05,  1.02it/s]Epoch: 0/10. Loss: 1.8773:  77%|[36m███████▋  [0m| 20/26 [00:25<00:05,  1.02it/s]Epoch: 0/10. Loss: 1.8773:  81%|[36m████████  [0m| 21/26 [00:25<00:07,  1.60s/it]Epoch: 0/10. Loss: 1.6736:  81%|[36m████████  [0m| 21/26 [00:26<00:07,  1.60s/it]Epoch: 0/10. Loss: 1.6736:  85%|[36m████████▍ [0m| 22/26 [00:26<00:05,  1.36s/it]Epoch: 0/10. Loss: 1.5691:  85%|[36m████████▍ [0m| 22/26 [00:27<00:05,  1.36s/it]Epoch: 0/10. Loss: 1.5691:  88%|[36m████████▊ [0m| 23/26 [00:27<00:04,  1.34s/it]Epoch: 0/10. Loss: 1.2987:  88%|[36m████████▊ [0m| 23/26 [00:30<00:04,  1.34s/it]Epoch: 0/10. Loss: 1.2987:  92%|[36m█████████▏[0m| 24/26 [00:30<00:03,  1.81s/it]Epoch: 0/10. Loss: 1.2378:  92%|[36m█████████▏[0m| 24/26 [00:33<00:03,  1.81s/it]Epoch: 0/10. Loss: 1.2378:  96%|[36m█████████▌[0m| 25/26 [00:33<00:02,  2.16s/it]Epoch: 0/10. Loss: 0.8994:  96%|[36m█████████▌[0m| 25/26 [00:34<00:02,  2.16s/it]Epoch: 0/10. Loss: 0.8994: 100%|[36m██████████[0m| 26/26 [00:34<00:00,  1.72s/it]Epoch: 0/10. Loss: 0.8994: 100%|[36m██████████[0m| 26/26 [00:34<00:00,  1.31s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:02<00:15,  2.57s/it] 29%|[33m██▊       [0m| 2/7 [00:04<00:11,  2.33s/it] 43%|[33m████▎     [0m| 3/7 [00:06<00:08,  2.19s/it] 57%|[33m█████▋    [0m| 4/7 [00:08<00:06,  2.18s/it] 71%|[33m███████▏  [0m| 5/7 [00:09<00:03,  1.56s/it] 86%|[33m████████▌ [0m| 6/7 [00:10<00:01,  1.38s/it]100%|[33m██████████[0m| 7/7 [00:10<00:00,  1.04s/it]100%|[33m██████████[0m| 7/7 [00:10<00:00,  1.54s/it]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 1/10. Loss: 1.3863:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 1/10. Loss: 1.3863:   4%|[36m▍         [0m| 1/26 [00:00<00:24,  1.01it/s]Epoch: 1/10. Loss: 1.1301:   4%|[36m▍         [0m| 1/26 [00:01<00:24,  1.01it/s]Epoch: 1/10. Loss: 1.1301:   8%|[36m▊         [0m| 2/26 [00:01<00:24,  1.00s/it]Epoch: 1/10. Loss: 1.0630:   8%|[36m▊         [0m| 2/26 [00:03<00:24,  1.00s/it]Epoch: 1/10. Loss: 1.0630:  12%|[36m█▏        [0m| 3/26 [00:03<00:28,  1.24s/it]Epoch: 1/10. Loss: 1.0813:  12%|[36m█▏        [0m| 3/26 [00:04<00:28,  1.24s/it]Epoch: 1/10. Loss: 1.0813:  15%|[36m█▌        [0m| 4/26 [00:04<00:23,  1.08s/it]Epoch: 1/10. Loss: 1.5817:  15%|[36m█▌        [0m| 4/26 [00:05<00:23,  1.08s/it]Epoch: 1/10. Loss: 1.5817:  19%|[36m█▉        [0m| 5/26 [00:05<00:21,  1.02s/it]Epoch: 1/10. Loss: 2.3542:  19%|[36m█▉        [0m| 5/26 [00:06<00:21,  1.02s/it]Epoch: 1/10. Loss: 2.3542:  23%|[36m██▎       [0m| 6/26 [00:06<00:19,  1.02it/s]Epoch: 1/10. Loss: 2.8532:  23%|[36m██▎       [0m| 6/26 [00:07<00:19,  1.02it/s]Epoch: 1/10. Loss: 2.8532:  27%|[36m██▋       [0m| 7/26 [00:07<00:18,  1.03it/s]Epoch: 1/10. Loss: 1.0256:  27%|[36m██▋       [0m| 7/26 [00:08<00:18,  1.03it/s]Epoch: 1/10. Loss: 1.0256:  31%|[36m███       [0m| 8/26 [00:08<00:17,  1.04it/s]Epoch: 1/10. Loss: 1.4320:  31%|[36m███       [0m| 8/26 [00:08<00:17,  1.04it/s]Epoch: 1/10. Loss: 1.4320:  35%|[36m███▍      [0m| 9/26 [00:08<00:16,  1.06it/s]Epoch: 1/10. Loss: 2.1412:  35%|[36m███▍      [0m| 9/26 [00:10<00:16,  1.06it/s]Epoch: 1/10. Loss: 2.1412:  38%|[36m███▊      [0m| 10/26 [00:10<00:16,  1.01s/it]Epoch: 1/10. Loss: 0.9838:  38%|[36m███▊      [0m| 10/26 [00:11<00:16,  1.01s/it]Epoch: 1/10. Loss: 0.9838:  42%|[36m████▏     [0m| 11/26 [00:11<00:14,  1.00it/s]Epoch: 1/10. Loss: 1.9398:  42%|[36m████▏     [0m| 11/26 [00:11<00:14,  1.00it/s]Epoch: 1/10. Loss: 1.9398:  46%|[36m████▌     [0m| 12/26 [00:11<00:13,  1.04it/s]Epoch: 1/10. Loss: 1.5721:  46%|[36m████▌     [0m| 12/26 [00:12<00:13,  1.04it/s]Epoch: 1/10. Loss: 1.5721:  50%|[36m█████     [0m| 13/26 [00:12<00:12,  1.04it/s]Epoch: 1/10. Loss: 1.0103:  50%|[36m█████     [0m| 13/26 [00:13<00:12,  1.04it/s]Epoch: 1/10. Loss: 1.0103:  54%|[36m█████▍    [0m| 14/26 [00:13<00:11,  1.02it/s]Epoch: 1/10. Loss: 1.7538:  54%|[36m█████▍    [0m| 14/26 [00:14<00:11,  1.02it/s]Epoch: 1/10. Loss: 1.7538:  58%|[36m█████▊    [0m| 15/26 [00:14<00:10,  1.01it/s]Epoch: 1/10. Loss: 1.2378:  58%|[36m█████▊    [0m| 15/26 [00:15<00:10,  1.01it/s]Epoch: 1/10. Loss: 1.2378:  62%|[36m██████▏   [0m| 16/26 [00:15<00:09,  1.03it/s]Epoch: 1/10. Loss: 1.1612:  62%|[36m██████▏   [0m| 16/26 [00:16<00:09,  1.03it/s]Epoch: 1/10. Loss: 1.1612:  65%|[36m██████▌   [0m| 17/26 [00:16<00:08,  1.09it/s]Epoch: 1/10. Loss: 1.1594:  65%|[36m██████▌   [0m| 17/26 [00:17<00:08,  1.09it/s]Epoch: 1/10. Loss: 1.1594:  69%|[36m██████▉   [0m| 18/26 [00:17<00:07,  1.04it/s]Epoch: 1/10. Loss: 1.0186:  69%|[36m██████▉   [0m| 18/26 [00:18<00:07,  1.04it/s]Epoch: 1/10. Loss: 1.0186:  73%|[36m███████▎  [0m| 19/26 [00:18<00:06,  1.03it/s]Epoch: 1/10. Loss: 1.1228:  73%|[36m███████▎  [0m| 19/26 [00:19<00:06,  1.03it/s]Epoch: 1/10. Loss: 1.1228:  77%|[36m███████▋  [0m| 20/26 [00:19<00:05,  1.04it/s]Epoch: 1/10. Loss: 1.2096:  77%|[36m███████▋  [0m| 20/26 [00:21<00:05,  1.04it/s]Epoch: 1/10. Loss: 1.2096:  81%|[36m████████  [0m| 21/26 [00:21<00:05,  1.07s/it]Epoch: 1/10. Loss: 1.3149:  81%|[36m████████  [0m| 21/26 [00:21<00:05,  1.07s/it]Epoch: 1/10. Loss: 1.3149:  85%|[36m████████▍ [0m| 22/26 [00:21<00:03,  1.02it/s]Epoch: 1/10. Loss: 0.9803:  85%|[36m████████▍ [0m| 22/26 [00:22<00:03,  1.02it/s]Epoch: 1/10. Loss: 0.9803:  88%|[36m████████▊ [0m| 23/26 [00:22<00:02,  1.04it/s]Epoch: 1/10. Loss: 1.2169:  88%|[36m████████▊ [0m| 23/26 [00:24<00:02,  1.04it/s]Epoch: 1/10. Loss: 1.2169:  92%|[36m█████████▏[0m| 24/26 [00:24<00:02,  1.20s/it]Epoch: 1/10. Loss: 1.0211:  92%|[36m█████████▏[0m| 24/26 [00:25<00:02,  1.20s/it]Epoch: 1/10. Loss: 1.0211:  96%|[36m█████████▌[0m| 25/26 [00:25<00:01,  1.09s/it]Epoch: 1/10. Loss: 1.1258:  96%|[36m█████████▌[0m| 25/26 [00:26<00:01,  1.09s/it]Epoch: 1/10. Loss: 1.1258: 100%|[36m██████████[0m| 26/26 [00:26<00:00,  1.15s/it]Epoch: 1/10. Loss: 1.1258: 100%|[36m██████████[0m| 26/26 [00:26<00:00,  1.02s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:05,  1.11it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:07,  1.46s/it] 43%|[33m████▎     [0m| 3/7 [00:03<00:04,  1.05s/it] 57%|[33m█████▋    [0m| 4/7 [00:04<00:03,  1.20s/it] 71%|[33m███████▏  [0m| 5/7 [00:05<00:01,  1.08it/s] 86%|[33m████████▌ [0m| 6/7 [00:06<00:00,  1.08it/s]100%|[33m██████████[0m| 7/7 [00:06<00:00,  1.37it/s]100%|[33m██████████[0m| 7/7 [00:06<00:00,  1.08it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 2/10. Loss: 1.1215:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 2/10. Loss: 1.1215:   4%|[36m▍         [0m| 1/26 [00:00<00:24,  1.02it/s]Epoch: 2/10. Loss: 1.0483:   4%|[36m▍         [0m| 1/26 [00:02<00:24,  1.02it/s]Epoch: 2/10. Loss: 1.0483:   8%|[36m▊         [0m| 2/26 [00:02<00:25,  1.06s/it]Epoch: 2/10. Loss: 0.9748:   8%|[36m▊         [0m| 2/26 [00:03<00:25,  1.06s/it]Epoch: 2/10. Loss: 0.9748:  12%|[36m█▏        [0m| 3/26 [00:03<00:23,  1.04s/it]Epoch: 2/10. Loss: 1.1197:  12%|[36m█▏        [0m| 3/26 [00:04<00:23,  1.04s/it]Epoch: 2/10. Loss: 1.1197:  15%|[36m█▌        [0m| 4/26 [00:04<00:22,  1.04s/it]Epoch: 2/10. Loss: 1.0730:  15%|[36m█▌        [0m| 4/26 [00:05<00:22,  1.04s/it]Epoch: 2/10. Loss: 1.0730:  19%|[36m█▉        [0m| 5/26 [00:05<00:21,  1.04s/it]Epoch: 2/10. Loss: 1.0303:  19%|[36m█▉        [0m| 5/26 [00:06<00:21,  1.04s/it]Epoch: 2/10. Loss: 1.0303:  23%|[36m██▎       [0m| 6/26 [00:06<00:20,  1.02s/it]Epoch: 2/10. Loss: 0.9953:  23%|[36m██▎       [0m| 6/26 [00:07<00:20,  1.02s/it]Epoch: 2/10. Loss: 0.9953:  27%|[36m██▋       [0m| 7/26 [00:07<00:19,  1.01s/it]Epoch: 2/10. Loss: 1.2553:  27%|[36m██▋       [0m| 7/26 [00:08<00:19,  1.01s/it]Epoch: 2/10. Loss: 1.2553:  31%|[36m███       [0m| 8/26 [00:08<00:18,  1.01s/it]Epoch: 2/10. Loss: 1.2045:  31%|[36m███       [0m| 8/26 [00:09<00:18,  1.01s/it]Epoch: 2/10. Loss: 1.2045:  35%|[36m███▍      [0m| 9/26 [00:09<00:16,  1.02it/s]Epoch: 2/10. Loss: 1.1043:  35%|[36m███▍      [0m| 9/26 [00:10<00:16,  1.02it/s]Epoch: 2/10. Loss: 1.1043:  38%|[36m███▊      [0m| 10/26 [00:10<00:15,  1.01it/s]Epoch: 2/10. Loss: 0.9401:  38%|[36m███▊      [0m| 10/26 [00:11<00:15,  1.01it/s]Epoch: 2/10. Loss: 0.9401:  42%|[36m████▏     [0m| 11/26 [00:11<00:18,  1.26s/it]Epoch: 2/10. Loss: 1.1131:  42%|[36m████▏     [0m| 11/26 [00:12<00:18,  1.26s/it]Epoch: 2/10. Loss: 1.1131:  46%|[36m████▌     [0m| 12/26 [00:12<00:16,  1.18s/it]Epoch: 2/10. Loss: 1.0353:  46%|[36m████▌     [0m| 12/26 [00:14<00:16,  1.18s/it]Epoch: 2/10. Loss: 1.0353:  50%|[36m█████     [0m| 13/26 [00:14<00:17,  1.32s/it]Epoch: 2/10. Loss: 1.0688:  50%|[36m█████     [0m| 13/26 [00:15<00:17,  1.32s/it]Epoch: 2/10. Loss: 1.0688:  54%|[36m█████▍    [0m| 14/26 [00:15<00:13,  1.16s/it]Epoch: 2/10. Loss: 0.9628:  54%|[36m█████▍    [0m| 14/26 [00:16<00:13,  1.16s/it]Epoch: 2/10. Loss: 0.9628:  58%|[36m█████▊    [0m| 15/26 [00:16<00:11,  1.05s/it]Epoch: 2/10. Loss: 1.1253:  58%|[36m█████▊    [0m| 15/26 [00:18<00:11,  1.05s/it]Epoch: 2/10. Loss: 1.1253:  62%|[36m██████▏   [0m| 16/26 [00:18<00:13,  1.34s/it]Epoch: 2/10. Loss: 1.0474:  62%|[36m██████▏   [0m| 16/26 [00:19<00:13,  1.34s/it]Epoch: 2/10. Loss: 1.0474:  65%|[36m██████▌   [0m| 17/26 [00:19<00:12,  1.35s/it]Epoch: 2/10. Loss: 1.0284:  65%|[36m██████▌   [0m| 17/26 [00:20<00:12,  1.35s/it]Epoch: 2/10. Loss: 1.0284:  69%|[36m██████▉   [0m| 18/26 [00:20<00:09,  1.18s/it]Epoch: 2/10. Loss: 1.0790:  69%|[36m██████▉   [0m| 18/26 [00:21<00:09,  1.18s/it]Epoch: 2/10. Loss: 1.0790:  73%|[36m███████▎  [0m| 19/26 [00:21<00:07,  1.05s/it]Epoch: 2/10. Loss: 1.0056:  73%|[36m███████▎  [0m| 19/26 [00:22<00:07,  1.05s/it]Epoch: 2/10. Loss: 1.0056:  77%|[36m███████▋  [0m| 20/26 [00:22<00:06,  1.13s/it]Epoch: 2/10. Loss: 1.1001:  77%|[36m███████▋  [0m| 20/26 [00:23<00:06,  1.13s/it]Epoch: 2/10. Loss: 1.1001:  81%|[36m████████  [0m| 21/26 [00:23<00:05,  1.06s/it]Epoch: 2/10. Loss: 1.0363:  81%|[36m████████  [0m| 21/26 [00:24<00:05,  1.06s/it]Epoch: 2/10. Loss: 1.0363:  85%|[36m████████▍ [0m| 22/26 [00:24<00:04,  1.09s/it]Epoch: 2/10. Loss: 1.1064:  85%|[36m████████▍ [0m| 22/26 [00:26<00:04,  1.09s/it]Epoch: 2/10. Loss: 1.1064:  88%|[36m████████▊ [0m| 23/26 [00:26<00:04,  1.37s/it]Epoch: 2/10. Loss: 1.0073:  88%|[36m████████▊ [0m| 23/26 [00:28<00:04,  1.37s/it]Epoch: 2/10. Loss: 1.0073:  92%|[36m█████████▏[0m| 24/26 [00:28<00:02,  1.48s/it]Epoch: 2/10. Loss: 1.0807:  92%|[36m█████████▏[0m| 24/26 [00:29<00:02,  1.48s/it]Epoch: 2/10. Loss: 1.0807:  96%|[36m█████████▌[0m| 25/26 [00:29<00:01,  1.42s/it]Epoch: 2/10. Loss: 0.9666:  96%|[36m█████████▌[0m| 25/26 [00:30<00:01,  1.42s/it]Epoch: 2/10. Loss: 0.9666: 100%|[36m██████████[0m| 26/26 [00:30<00:00,  1.27s/it]Epoch: 2/10. Loss: 0.9666: 100%|[36m██████████[0m| 26/26 [00:30<00:00,  1.17s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:01<00:08,  1.41s/it] 29%|[33m██▊       [0m| 2/7 [00:02<00:07,  1.48s/it] 43%|[33m████▎     [0m| 3/7 [00:03<00:04,  1.06s/it] 57%|[33m█████▋    [0m| 4/7 [00:04<00:03,  1.20s/it] 71%|[33m███████▏  [0m| 5/7 [00:05<00:01,  1.09it/s] 86%|[33m████████▌ [0m| 6/7 [00:06<00:00,  1.08it/s]100%|[33m██████████[0m| 7/7 [00:08<00:00,  1.37s/it]100%|[33m██████████[0m| 7/7 [00:08<00:00,  1.22s/it]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 3/10. Loss: 1.0202:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 3/10. Loss: 1.0202:   4%|[36m▍         [0m| 1/26 [00:00<00:19,  1.26it/s]Epoch: 3/10. Loss: 1.0615:   4%|[36m▍         [0m| 1/26 [00:02<00:19,  1.26it/s]Epoch: 3/10. Loss: 1.0615:   8%|[36m▊         [0m| 2/26 [00:02<00:26,  1.11s/it]Epoch: 3/10. Loss: 1.1275:   8%|[36m▊         [0m| 2/26 [00:04<00:26,  1.11s/it]Epoch: 3/10. Loss: 1.1275:  12%|[36m█▏        [0m| 3/26 [00:04<00:43,  1.87s/it]Epoch: 3/10. Loss: 0.9456:  12%|[36m█▏        [0m| 3/26 [00:05<00:43,  1.87s/it]Epoch: 3/10. Loss: 0.9456:  15%|[36m█▌        [0m| 4/26 [00:05<00:33,  1.53s/it]Epoch: 3/10. Loss: 1.0008:  15%|[36m█▌        [0m| 4/26 [00:06<00:33,  1.53s/it]Epoch: 3/10. Loss: 1.0008:  19%|[36m█▉        [0m| 5/26 [00:06<00:28,  1.35s/it]Epoch: 3/10. Loss: 1.0344:  19%|[36m█▉        [0m| 5/26 [00:07<00:28,  1.35s/it]Epoch: 3/10. Loss: 1.0344:  23%|[36m██▎       [0m| 6/26 [00:07<00:24,  1.22s/it]Epoch: 3/10. Loss: 1.0632:  23%|[36m██▎       [0m| 6/26 [00:08<00:24,  1.22s/it]Epoch: 3/10. Loss: 1.0632:  27%|[36m██▋       [0m| 7/26 [00:08<00:21,  1.14s/it]Epoch: 3/10. Loss: 0.9931:  27%|[36m██▋       [0m| 7/26 [00:09<00:21,  1.14s/it]Epoch: 3/10. Loss: 0.9931:  31%|[36m███       [0m| 8/26 [00:09<00:18,  1.03s/it]Epoch: 3/10. Loss: 1.0045:  31%|[36m███       [0m| 8/26 [00:11<00:18,  1.03s/it]Epoch: 3/10. Loss: 1.0045:  35%|[36m███▍      [0m| 9/26 [00:11<00:22,  1.33s/it]Epoch: 3/10. Loss: 0.9751:  35%|[36m███▍      [0m| 9/26 [00:12<00:22,  1.33s/it]Epoch: 3/10. Loss: 0.9751:  38%|[36m███▊      [0m| 10/26 [00:12<00:19,  1.23s/it]Epoch: 3/10. Loss: 0.9556:  38%|[36m███▊      [0m| 10/26 [00:13<00:19,  1.23s/it]Epoch: 3/10. Loss: 0.9556:  42%|[36m████▏     [0m| 11/26 [00:13<00:17,  1.14s/it]Epoch: 3/10. Loss: 0.9971:  42%|[36m████▏     [0m| 11/26 [00:15<00:17,  1.14s/it]Epoch: 3/10. Loss: 0.9971:  46%|[36m████▌     [0m| 12/26 [00:15<00:20,  1.47s/it]Epoch: 3/10. Loss: 0.9609:  46%|[36m████▌     [0m| 12/26 [00:16<00:20,  1.47s/it]Epoch: 3/10. Loss: 0.9609:  50%|[36m█████     [0m| 13/26 [00:16<00:16,  1.25s/it]Epoch: 3/10. Loss: 1.0024:  50%|[36m█████     [0m| 13/26 [00:17<00:16,  1.25s/it]Epoch: 3/10. Loss: 1.0024:  54%|[36m█████▍    [0m| 14/26 [00:17<00:13,  1.16s/it]Epoch: 3/10. Loss: 1.0697:  54%|[36m█████▍    [0m| 14/26 [00:20<00:13,  1.16s/it]Epoch: 3/10. Loss: 1.0697:  58%|[36m█████▊    [0m| 15/26 [00:20<00:17,  1.58s/it]Epoch: 3/10. Loss: 0.9230:  58%|[36m█████▊    [0m| 15/26 [00:21<00:17,  1.58s/it]Epoch: 3/10. Loss: 0.9230:  62%|[36m██████▏   [0m| 16/26 [00:21<00:16,  1.60s/it]Epoch: 3/10. Loss: 0.9593:  62%|[36m██████▏   [0m| 16/26 [00:23<00:16,  1.60s/it]Epoch: 3/10. Loss: 0.9593:  65%|[36m██████▌   [0m| 17/26 [00:23<00:13,  1.52s/it]Epoch: 3/10. Loss: 1.0092:  65%|[36m██████▌   [0m| 17/26 [00:24<00:13,  1.52s/it]Epoch: 3/10. Loss: 1.0092:  69%|[36m██████▉   [0m| 18/26 [00:24<00:11,  1.42s/it]Epoch: 3/10. Loss: 0.9713:  69%|[36m██████▉   [0m| 18/26 [00:25<00:11,  1.42s/it]Epoch: 3/10. Loss: 0.9713:  73%|[36m███████▎  [0m| 19/26 [00:25<00:08,  1.28s/it]Epoch: 3/10. Loss: 0.8674:  73%|[36m███████▎  [0m| 19/26 [00:26<00:08,  1.28s/it]Epoch: 3/10. Loss: 0.8674:  77%|[36m███████▋  [0m| 20/26 [00:26<00:07,  1.20s/it]Epoch: 3/10. Loss: 0.9575:  77%|[36m███████▋  [0m| 20/26 [00:27<00:07,  1.20s/it]Epoch: 3/10. Loss: 0.9575:  81%|[36m████████  [0m| 21/26 [00:27<00:05,  1.12s/it]Epoch: 3/10. Loss: 0.9756:  81%|[36m████████  [0m| 21/26 [00:28<00:05,  1.12s/it]Epoch: 3/10. Loss: 0.9756:  85%|[36m████████▍ [0m| 22/26 [00:28<00:04,  1.15s/it]Epoch: 3/10. Loss: 1.0972:  85%|[36m████████▍ [0m| 22/26 [00:29<00:04,  1.15s/it]Epoch: 3/10. Loss: 1.0972:  88%|[36m████████▊ [0m| 23/26 [00:29<00:03,  1.13s/it]Epoch: 3/10. Loss: 0.9817:  88%|[36m████████▊ [0m| 23/26 [00:30<00:03,  1.13s/it]Epoch: 3/10. Loss: 0.9817:  92%|[36m█████████▏[0m| 24/26 [00:30<00:02,  1.09s/it]Epoch: 3/10. Loss: 1.0223:  92%|[36m█████████▏[0m| 24/26 [00:31<00:02,  1.09s/it]Epoch: 3/10. Loss: 1.0223:  96%|[36m█████████▌[0m| 25/26 [00:31<00:01,  1.03s/it]Epoch: 3/10. Loss: 0.9822:  96%|[36m█████████▌[0m| 25/26 [00:31<00:01,  1.03s/it]Epoch: 3/10. Loss: 0.9822: 100%|[36m██████████[0m| 26/26 [00:31<00:00,  1.15it/s]Epoch: 3/10. Loss: 0.9822: 100%|[36m██████████[0m| 26/26 [00:31<00:00,  1.22s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:05,  1.15it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:06,  1.21s/it] 43%|[33m████▎     [0m| 3/7 [00:02<00:03,  1.08it/s] 57%|[33m█████▋    [0m| 4/7 [00:04<00:03,  1.15s/it] 71%|[33m███████▏  [0m| 5/7 [00:04<00:01,  1.11it/s] 86%|[33m████████▌ [0m| 6/7 [00:05<00:00,  1.04it/s]100%|[33m██████████[0m| 7/7 [00:06<00:00,  1.33it/s]100%|[33m██████████[0m| 7/7 [00:06<00:00,  1.12it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 4/10. Loss: 0.9644:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 4/10. Loss: 0.9644:   4%|[36m▍         [0m| 1/26 [00:00<00:24,  1.02it/s]Epoch: 4/10. Loss: 1.0100:   4%|[36m▍         [0m| 1/26 [00:02<00:24,  1.02it/s]Epoch: 4/10. Loss: 1.0100:   8%|[36m▊         [0m| 2/26 [00:02<00:27,  1.13s/it]Epoch: 4/10. Loss: 0.9777:   8%|[36m▊         [0m| 2/26 [00:03<00:27,  1.13s/it]Epoch: 4/10. Loss: 0.9777:  12%|[36m█▏        [0m| 3/26 [00:03<00:27,  1.21s/it]Epoch: 4/10. Loss: 1.0124:  12%|[36m█▏        [0m| 3/26 [00:04<00:27,  1.21s/it]Epoch: 4/10. Loss: 1.0124:  15%|[36m█▌        [0m| 4/26 [00:04<00:24,  1.13s/it]Epoch: 4/10. Loss: 1.0024:  15%|[36m█▌        [0m| 4/26 [00:05<00:24,  1.13s/it]Epoch: 4/10. Loss: 1.0024:  19%|[36m█▉        [0m| 5/26 [00:05<00:22,  1.09s/it]Epoch: 4/10. Loss: 0.9899:  19%|[36m█▉        [0m| 5/26 [00:06<00:22,  1.09s/it]Epoch: 4/10. Loss: 0.9899:  23%|[36m██▎       [0m| 6/26 [00:06<00:20,  1.00s/it]Epoch: 4/10. Loss: 1.0451:  23%|[36m██▎       [0m| 6/26 [00:07<00:20,  1.00s/it]Epoch: 4/10. Loss: 1.0451:  27%|[36m██▋       [0m| 7/26 [00:07<00:19,  1.03s/it]Epoch: 4/10. Loss: 0.9306:  27%|[36m██▋       [0m| 7/26 [00:08<00:19,  1.03s/it]Epoch: 4/10. Loss: 0.9306:  31%|[36m███       [0m| 8/26 [00:08<00:19,  1.06s/it]Epoch: 4/10. Loss: 0.9510:  31%|[36m███       [0m| 8/26 [00:09<00:19,  1.06s/it]Epoch: 4/10. Loss: 0.9510:  35%|[36m███▍      [0m| 9/26 [00:09<00:18,  1.10s/it]Epoch: 4/10. Loss: 1.0996:  35%|[36m███▍      [0m| 9/26 [00:10<00:18,  1.10s/it]Epoch: 4/10. Loss: 1.0996:  38%|[36m███▊      [0m| 10/26 [00:10<00:16,  1.03s/it]Epoch: 4/10. Loss: 1.0661:  38%|[36m███▊      [0m| 10/26 [00:11<00:16,  1.03s/it]Epoch: 4/10. Loss: 1.0661:  42%|[36m████▏     [0m| 11/26 [00:11<00:15,  1.03s/it]Epoch: 4/10. Loss: 0.9931:  42%|[36m████▏     [0m| 11/26 [00:12<00:15,  1.03s/it]Epoch: 4/10. Loss: 0.9931:  46%|[36m████▌     [0m| 12/26 [00:12<00:14,  1.01s/it]Epoch: 4/10. Loss: 0.9372:  46%|[36m████▌     [0m| 12/26 [00:13<00:14,  1.01s/it]Epoch: 4/10. Loss: 0.9372:  50%|[36m█████     [0m| 13/26 [00:13<00:12,  1.05it/s]Epoch: 4/10. Loss: 0.9005:  50%|[36m█████     [0m| 13/26 [00:14<00:12,  1.05it/s]Epoch: 4/10. Loss: 0.9005:  54%|[36m█████▍    [0m| 14/26 [00:14<00:12,  1.05s/it]Epoch: 4/10. Loss: 0.9367:  54%|[36m█████▍    [0m| 14/26 [00:16<00:12,  1.05s/it]Epoch: 4/10. Loss: 0.9367:  58%|[36m█████▊    [0m| 15/26 [00:16<00:13,  1.24s/it]Epoch: 4/10. Loss: 0.9516:  58%|[36m█████▊    [0m| 15/26 [00:17<00:13,  1.24s/it]Epoch: 4/10. Loss: 0.9516:  62%|[36m██████▏   [0m| 16/26 [00:17<00:11,  1.12s/it]Epoch: 4/10. Loss: 0.8470:  62%|[36m██████▏   [0m| 16/26 [00:18<00:11,  1.12s/it]Epoch: 4/10. Loss: 0.8470:  65%|[36m██████▌   [0m| 17/26 [00:18<00:09,  1.08s/it]Epoch: 4/10. Loss: 0.8997:  65%|[36m██████▌   [0m| 17/26 [00:19<00:09,  1.08s/it]Epoch: 4/10. Loss: 0.8997:  69%|[36m██████▉   [0m| 18/26 [00:19<00:08,  1.05s/it]Epoch: 4/10. Loss: 0.9799:  69%|[36m██████▉   [0m| 18/26 [00:20<00:08,  1.05s/it]Epoch: 4/10. Loss: 0.9799:  73%|[36m███████▎  [0m| 19/26 [00:20<00:07,  1.09s/it]Epoch: 4/10. Loss: 0.9653:  73%|[36m███████▎  [0m| 19/26 [00:23<00:07,  1.09s/it]Epoch: 4/10. Loss: 0.9653:  77%|[36m███████▋  [0m| 20/26 [00:23<00:09,  1.57s/it]Epoch: 4/10. Loss: 0.9639:  77%|[36m███████▋  [0m| 20/26 [00:24<00:09,  1.57s/it]Epoch: 4/10. Loss: 0.9639:  81%|[36m████████  [0m| 21/26 [00:24<00:07,  1.44s/it]Epoch: 4/10. Loss: 0.9202:  81%|[36m████████  [0m| 21/26 [00:26<00:07,  1.44s/it]Epoch: 4/10. Loss: 0.9202:  85%|[36m████████▍ [0m| 22/26 [00:26<00:07,  1.79s/it]Epoch: 4/10. Loss: 1.0011:  85%|[36m████████▍ [0m| 22/26 [00:27<00:07,  1.79s/it]Epoch: 4/10. Loss: 1.0011:  88%|[36m████████▊ [0m| 23/26 [00:27<00:04,  1.59s/it]Epoch: 4/10. Loss: 0.8698:  88%|[36m████████▊ [0m| 23/26 [00:29<00:04,  1.59s/it]Epoch: 4/10. Loss: 0.8698:  92%|[36m█████████▏[0m| 24/26 [00:29<00:02,  1.48s/it]Epoch: 4/10. Loss: 0.9436:  92%|[36m█████████▏[0m| 24/26 [00:30<00:02,  1.48s/it]Epoch: 4/10. Loss: 0.9436:  96%|[36m█████████▌[0m| 25/26 [00:30<00:01,  1.36s/it]Epoch: 4/10. Loss: 0.9597:  96%|[36m█████████▌[0m| 25/26 [00:30<00:01,  1.36s/it]Epoch: 4/10. Loss: 0.9597: 100%|[36m██████████[0m| 26/26 [00:30<00:00,  1.17s/it]Epoch: 4/10. Loss: 0.9597: 100%|[36m██████████[0m| 26/26 [00:30<00:00,  1.19s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:05,  1.13it/s] 29%|[33m██▊       [0m| 2/7 [00:03<00:08,  1.64s/it] 43%|[33m████▎     [0m| 3/7 [00:03<00:05,  1.27s/it] 57%|[33m█████▋    [0m| 4/7 [00:06<00:04,  1.64s/it] 71%|[33m███████▏  [0m| 5/7 [00:06<00:02,  1.22s/it] 86%|[33m████████▌ [0m| 6/7 [00:07<00:01,  1.12s/it]100%|[33m██████████[0m| 7/7 [00:07<00:00,  1.17it/s]100%|[33m██████████[0m| 7/7 [00:07<00:00,  1.12s/it]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 5/10. Loss: 0.9819:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 5/10. Loss: 0.9819:   4%|[36m▍         [0m| 1/26 [00:00<00:22,  1.13it/s]Epoch: 5/10. Loss: 0.9206:   4%|[36m▍         [0m| 1/26 [00:01<00:22,  1.13it/s]Epoch: 5/10. Loss: 0.9206:   8%|[36m▊         [0m| 2/26 [00:01<00:22,  1.07it/s]Epoch: 5/10. Loss: 1.0080:   8%|[36m▊         [0m| 2/26 [00:02<00:22,  1.07it/s]Epoch: 5/10. Loss: 1.0080:  12%|[36m█▏        [0m| 3/26 [00:02<00:20,  1.12it/s]Epoch: 5/10. Loss: 0.8554:  12%|[36m█▏        [0m| 3/26 [00:03<00:20,  1.12it/s]Epoch: 5/10. Loss: 0.8554:  15%|[36m█▌        [0m| 4/26 [00:03<00:19,  1.11it/s]Epoch: 5/10. Loss: 0.8932:  15%|[36m█▌        [0m| 4/26 [00:04<00:19,  1.11it/s]Epoch: 5/10. Loss: 0.8932:  19%|[36m█▉        [0m| 5/26 [00:04<00:18,  1.11it/s]Epoch: 5/10. Loss: 0.8895:  19%|[36m█▉        [0m| 5/26 [00:05<00:18,  1.11it/s]Epoch: 5/10. Loss: 0.8895:  23%|[36m██▎       [0m| 6/26 [00:05<00:19,  1.00it/s]Epoch: 5/10. Loss: 0.9771:  23%|[36m██▎       [0m| 6/26 [00:06<00:19,  1.00it/s]Epoch: 5/10. Loss: 0.9771:  27%|[36m██▋       [0m| 7/26 [00:06<00:18,  1.04it/s]Epoch: 5/10. Loss: 0.8253:  27%|[36m██▋       [0m| 7/26 [00:07<00:18,  1.04it/s]Epoch: 5/10. Loss: 0.8253:  31%|[36m███       [0m| 8/26 [00:07<00:17,  1.04it/s]Epoch: 5/10. Loss: 0.9579:  31%|[36m███       [0m| 8/26 [00:08<00:17,  1.04it/s]Epoch: 5/10. Loss: 0.9579:  35%|[36m███▍      [0m| 9/26 [00:08<00:18,  1.07s/it]Epoch: 5/10. Loss: 0.8796:  35%|[36m███▍      [0m| 9/26 [00:09<00:18,  1.07s/it]Epoch: 5/10. Loss: 0.8796:  38%|[36m███▊      [0m| 10/26 [00:09<00:17,  1.08s/it]Epoch: 5/10. Loss: 1.0008:  38%|[36m███▊      [0m| 10/26 [00:10<00:17,  1.08s/it]Epoch: 5/10. Loss: 1.0008:  42%|[36m████▏     [0m| 11/26 [00:10<00:15,  1.07s/it]Epoch: 5/10. Loss: 0.9126:  42%|[36m████▏     [0m| 11/26 [00:12<00:15,  1.07s/it]Epoch: 5/10. Loss: 0.9126:  46%|[36m████▌     [0m| 12/26 [00:12<00:15,  1.07s/it]Epoch: 5/10. Loss: 0.9004:  46%|[36m████▌     [0m| 12/26 [00:13<00:15,  1.07s/it]Epoch: 5/10. Loss: 0.9004:  50%|[36m█████     [0m| 13/26 [00:13<00:13,  1.04s/it]Epoch: 5/10. Loss: 0.9383:  50%|[36m█████     [0m| 13/26 [00:13<00:13,  1.04s/it]Epoch: 5/10. Loss: 0.9383:  54%|[36m█████▍    [0m| 14/26 [00:13<00:11,  1.02it/s]Epoch: 5/10. Loss: 1.0081:  54%|[36m█████▍    [0m| 14/26 [00:14<00:11,  1.02it/s]Epoch: 5/10. Loss: 1.0081:  58%|[36m█████▊    [0m| 15/26 [00:14<00:10,  1.05it/s]Epoch: 5/10. Loss: 0.8616:  58%|[36m█████▊    [0m| 15/26 [00:15<00:10,  1.05it/s]Epoch: 5/10. Loss: 0.8616:  62%|[36m██████▏   [0m| 16/26 [00:15<00:09,  1.05it/s]Epoch: 5/10. Loss: 0.9045:  62%|[36m██████▏   [0m| 16/26 [00:16<00:09,  1.05it/s]Epoch: 5/10. Loss: 0.9045:  65%|[36m██████▌   [0m| 17/26 [00:16<00:08,  1.10it/s]Epoch: 5/10. Loss: 0.9569:  65%|[36m██████▌   [0m| 17/26 [00:17<00:08,  1.10it/s]Epoch: 5/10. Loss: 0.9569:  69%|[36m██████▉   [0m| 18/26 [00:17<00:08,  1.04s/it]Epoch: 5/10. Loss: 0.8407:  69%|[36m██████▉   [0m| 18/26 [00:18<00:08,  1.04s/it]Epoch: 5/10. Loss: 0.8407:  73%|[36m███████▎  [0m| 19/26 [00:18<00:07,  1.03s/it]Epoch: 5/10. Loss: 0.8864:  73%|[36m███████▎  [0m| 19/26 [00:19<00:07,  1.03s/it]Epoch: 5/10. Loss: 0.8864:  77%|[36m███████▋  [0m| 20/26 [00:19<00:06,  1.03s/it]Epoch: 5/10. Loss: 0.8308:  77%|[36m███████▋  [0m| 20/26 [00:20<00:06,  1.03s/it]Epoch: 5/10. Loss: 0.8308:  81%|[36m████████  [0m| 21/26 [00:20<00:05,  1.03s/it]Epoch: 5/10. Loss: 0.9877:  81%|[36m████████  [0m| 21/26 [00:22<00:05,  1.03s/it]Epoch: 5/10. Loss: 0.9877:  85%|[36m████████▍ [0m| 22/26 [00:22<00:04,  1.04s/it]Epoch: 5/10. Loss: 0.8751:  85%|[36m████████▍ [0m| 22/26 [00:22<00:04,  1.04s/it]Epoch: 5/10. Loss: 0.8751:  88%|[36m████████▊ [0m| 23/26 [00:22<00:03,  1.00s/it]Epoch: 5/10. Loss: 0.9439:  88%|[36m████████▊ [0m| 23/26 [00:23<00:03,  1.00s/it]Epoch: 5/10. Loss: 0.9439:  92%|[36m█████████▏[0m| 24/26 [00:23<00:01,  1.05it/s]Epoch: 5/10. Loss: 0.8147:  92%|[36m█████████▏[0m| 24/26 [00:24<00:01,  1.05it/s]Epoch: 5/10. Loss: 0.8147:  96%|[36m█████████▌[0m| 25/26 [00:24<00:00,  1.04it/s]Epoch: 5/10. Loss: 0.9409:  96%|[36m█████████▌[0m| 25/26 [00:25<00:00,  1.04it/s]Epoch: 5/10. Loss: 0.9409: 100%|[36m██████████[0m| 26/26 [00:25<00:00,  1.16it/s]Epoch: 5/10. Loss: 0.9409: 100%|[36m██████████[0m| 26/26 [00:25<00:00,  1.02it/s]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:05,  1.06it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:06,  1.25s/it] 43%|[33m████▎     [0m| 3/7 [00:03<00:03,  1.05it/s] 57%|[33m█████▋    [0m| 4/7 [00:04<00:03,  1.14s/it] 71%|[33m███████▏  [0m| 5/7 [00:04<00:01,  1.12it/s] 86%|[33m████████▌ [0m| 6/7 [00:05<00:00,  1.09it/s]100%|[33m██████████[0m| 7/7 [00:06<00:00,  1.37it/s]100%|[33m██████████[0m| 7/7 [00:06<00:00,  1.13it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 6/10. Loss: 0.7855:   0%|[36m          [0m| 0/26 [00:01<?, ?it/s]Epoch: 6/10. Loss: 0.7855:   4%|[36m▍         [0m| 1/26 [00:01<00:38,  1.53s/it]Epoch: 6/10. Loss: 0.9191:   4%|[36m▍         [0m| 1/26 [00:03<00:38,  1.53s/it]Epoch: 6/10. Loss: 0.9191:   8%|[36m▊         [0m| 2/26 [00:03<00:40,  1.69s/it]Epoch: 6/10. Loss: 0.9338:   8%|[36m▊         [0m| 2/26 [00:04<00:40,  1.69s/it]Epoch: 6/10. Loss: 0.9338:  12%|[36m█▏        [0m| 3/26 [00:04<00:30,  1.32s/it]Epoch: 6/10. Loss: 0.9427:  12%|[36m█▏        [0m| 3/26 [00:05<00:30,  1.32s/it]Epoch: 6/10. Loss: 0.9427:  15%|[36m█▌        [0m| 4/26 [00:05<00:26,  1.23s/it]Epoch: 6/10. Loss: 0.9443:  15%|[36m█▌        [0m| 4/26 [00:06<00:26,  1.23s/it]Epoch: 6/10. Loss: 0.9443:  19%|[36m█▉        [0m| 5/26 [00:06<00:24,  1.17s/it]Epoch: 6/10. Loss: 0.8670:  19%|[36m█▉        [0m| 5/26 [00:07<00:24,  1.17s/it]Epoch: 6/10. Loss: 0.8670:  23%|[36m██▎       [0m| 6/26 [00:07<00:23,  1.18s/it]Epoch: 6/10. Loss: 0.8817:  23%|[36m██▎       [0m| 6/26 [00:09<00:23,  1.18s/it]Epoch: 6/10. Loss: 0.8817:  27%|[36m██▋       [0m| 7/26 [00:09<00:28,  1.48s/it]Epoch: 6/10. Loss: 0.9205:  27%|[36m██▋       [0m| 7/26 [00:10<00:28,  1.48s/it]Epoch: 6/10. Loss: 0.9205:  31%|[36m███       [0m| 8/26 [00:10<00:23,  1.29s/it]Epoch: 6/10. Loss: 0.9542:  31%|[36m███       [0m| 8/26 [00:11<00:23,  1.29s/it]Epoch: 6/10. Loss: 0.9542:  35%|[36m███▍      [0m| 9/26 [00:11<00:20,  1.18s/it]Epoch: 6/10. Loss: 0.9787:  35%|[36m███▍      [0m| 9/26 [00:12<00:20,  1.18s/it]Epoch: 6/10. Loss: 0.9787:  38%|[36m███▊      [0m| 10/26 [00:12<00:19,  1.24s/it]Epoch: 6/10. Loss: 0.9582:  38%|[36m███▊      [0m| 10/26 [00:13<00:19,  1.24s/it]Epoch: 6/10. Loss: 0.9582:  42%|[36m████▏     [0m| 11/26 [00:13<00:17,  1.19s/it]Epoch: 6/10. Loss: 0.9227:  42%|[36m████▏     [0m| 11/26 [00:15<00:17,  1.19s/it]Epoch: 6/10. Loss: 0.9227:  46%|[36m████▌     [0m| 12/26 [00:15<00:16,  1.18s/it]Epoch: 6/10. Loss: 1.0276:  46%|[36m████▌     [0m| 12/26 [00:16<00:16,  1.18s/it]Epoch: 6/10. Loss: 1.0276:  50%|[36m█████     [0m| 13/26 [00:16<00:14,  1.14s/it]Epoch: 6/10. Loss: 0.9681:  50%|[36m█████     [0m| 13/26 [00:18<00:14,  1.14s/it]Epoch: 6/10. Loss: 0.9681:  54%|[36m█████▍    [0m| 14/26 [00:18<00:17,  1.44s/it]Epoch: 6/10. Loss: 0.9430:  54%|[36m█████▍    [0m| 14/26 [00:19<00:17,  1.44s/it]Epoch: 6/10. Loss: 0.9430:  58%|[36m█████▊    [0m| 15/26 [00:19<00:14,  1.27s/it]Epoch: 6/10. Loss: 0.9549:  58%|[36m█████▊    [0m| 15/26 [00:21<00:14,  1.27s/it]Epoch: 6/10. Loss: 0.9549:  62%|[36m██████▏   [0m| 16/26 [00:21<00:14,  1.48s/it]Epoch: 6/10. Loss: 0.9452:  62%|[36m██████▏   [0m| 16/26 [00:21<00:14,  1.48s/it]Epoch: 6/10. Loss: 0.9452:  65%|[36m██████▌   [0m| 17/26 [00:21<00:11,  1.28s/it]Epoch: 6/10. Loss: 0.9316:  65%|[36m██████▌   [0m| 17/26 [00:22<00:11,  1.28s/it]Epoch: 6/10. Loss: 0.9316:  69%|[36m██████▉   [0m| 18/26 [00:22<00:09,  1.17s/it]Epoch: 6/10. Loss: 0.9306:  69%|[36m██████▉   [0m| 18/26 [00:23<00:09,  1.17s/it]Epoch: 6/10. Loss: 0.9306:  73%|[36m███████▎  [0m| 19/26 [00:23<00:07,  1.13s/it]Epoch: 6/10. Loss: 0.9548:  73%|[36m███████▎  [0m| 19/26 [00:26<00:07,  1.13s/it]Epoch: 6/10. Loss: 0.9548:  77%|[36m███████▋  [0m| 20/26 [00:26<00:09,  1.53s/it]Epoch: 6/10. Loss: 0.9101:  77%|[36m███████▋  [0m| 20/26 [00:27<00:09,  1.53s/it]Epoch: 6/10. Loss: 0.9101:  81%|[36m████████  [0m| 21/26 [00:27<00:06,  1.31s/it]Epoch: 6/10. Loss: 0.8633:  81%|[36m████████  [0m| 21/26 [00:28<00:06,  1.31s/it]Epoch: 6/10. Loss: 0.8633:  85%|[36m████████▍ [0m| 22/26 [00:28<00:04,  1.19s/it]Epoch: 6/10. Loss: 0.8001:  85%|[36m████████▍ [0m| 22/26 [00:28<00:04,  1.19s/it]Epoch: 6/10. Loss: 0.8001:  88%|[36m████████▊ [0m| 23/26 [00:28<00:03,  1.08s/it]Epoch: 6/10. Loss: 0.9270:  88%|[36m████████▊ [0m| 23/26 [00:29<00:03,  1.08s/it]Epoch: 6/10. Loss: 0.9270:  92%|[36m█████████▏[0m| 24/26 [00:29<00:02,  1.06s/it]Epoch: 6/10. Loss: 0.7969:  92%|[36m█████████▏[0m| 24/26 [00:30<00:02,  1.06s/it]Epoch: 6/10. Loss: 0.7969:  96%|[36m█████████▌[0m| 25/26 [00:30<00:01,  1.06s/it]Epoch: 6/10. Loss: 0.8990:  96%|[36m█████████▌[0m| 25/26 [00:31<00:01,  1.06s/it]Epoch: 6/10. Loss: 0.8990: 100%|[36m██████████[0m| 26/26 [00:31<00:00,  1.01it/s]Epoch: 6/10. Loss: 0.8990: 100%|[36m██████████[0m| 26/26 [00:31<00:00,  1.22s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:05,  1.11it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:06,  1.24s/it] 43%|[33m████▎     [0m| 3/7 [00:02<00:03,  1.08it/s] 57%|[33m█████▋    [0m| 4/7 [00:04<00:03,  1.11s/it] 71%|[33m███████▏  [0m| 5/7 [00:04<00:01,  1.14it/s] 86%|[33m████████▌ [0m| 6/7 [00:06<00:00,  1.00it/s]100%|[33m██████████[0m| 7/7 [00:06<00:00,  1.29it/s]100%|[33m██████████[0m| 7/7 [00:06<00:00,  1.10it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 7/10. Loss: 0.9441:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 7/10. Loss: 0.9441:   4%|[36m▍         [0m| 1/26 [00:00<00:22,  1.12it/s]Epoch: 7/10. Loss: 0.8597:   4%|[36m▍         [0m| 1/26 [00:02<00:22,  1.12it/s]Epoch: 7/10. Loss: 0.8597:   8%|[36m▊         [0m| 2/26 [00:02<00:31,  1.32s/it]Epoch: 7/10. Loss: 0.8512:   8%|[36m▊         [0m| 2/26 [00:03<00:31,  1.32s/it]Epoch: 7/10. Loss: 0.8512:  12%|[36m█▏        [0m| 3/26 [00:03<00:27,  1.21s/it]Epoch: 7/10. Loss: 0.8781:  12%|[36m█▏        [0m| 3/26 [00:04<00:27,  1.21s/it]Epoch: 7/10. Loss: 0.8781:  15%|[36m█▌        [0m| 4/26 [00:04<00:26,  1.21s/it]Epoch: 7/10. Loss: 0.7813:  15%|[36m█▌        [0m| 4/26 [00:06<00:26,  1.21s/it]Epoch: 7/10. Loss: 0.7813:  19%|[36m█▉        [0m| 5/26 [00:06<00:30,  1.44s/it]Epoch: 7/10. Loss: 0.9401:  19%|[36m█▉        [0m| 5/26 [00:08<00:30,  1.44s/it]Epoch: 7/10. Loss: 0.9401:  23%|[36m██▎       [0m| 6/26 [00:08<00:29,  1.46s/it]Epoch: 7/10. Loss: 0.9158:  23%|[36m██▎       [0m| 6/26 [00:09<00:29,  1.46s/it]Epoch: 7/10. Loss: 0.9158:  27%|[36m██▋       [0m| 7/26 [00:09<00:24,  1.31s/it]Epoch: 7/10. Loss: 0.9230:  27%|[36m██▋       [0m| 7/26 [00:09<00:24,  1.31s/it]Epoch: 7/10. Loss: 0.9230:  31%|[36m███       [0m| 8/26 [00:09<00:20,  1.16s/it]Epoch: 7/10. Loss: 0.9710:  31%|[36m███       [0m| 8/26 [00:10<00:20,  1.16s/it]Epoch: 7/10. Loss: 0.9710:  35%|[36m███▍      [0m| 9/26 [00:10<00:18,  1.09s/it]Epoch: 7/10. Loss: 0.8558:  35%|[36m███▍      [0m| 9/26 [00:11<00:18,  1.09s/it]Epoch: 7/10. Loss: 0.8558:  38%|[36m███▊      [0m| 10/26 [00:11<00:17,  1.08s/it]Epoch: 7/10. Loss: 0.8792:  38%|[36m███▊      [0m| 10/26 [00:12<00:17,  1.08s/it]Epoch: 7/10. Loss: 0.8792:  42%|[36m████▏     [0m| 11/26 [00:12<00:15,  1.02s/it]Epoch: 7/10. Loss: 0.8255:  42%|[36m████▏     [0m| 11/26 [00:13<00:15,  1.02s/it]Epoch: 7/10. Loss: 0.8255:  46%|[36m████▌     [0m| 12/26 [00:13<00:13,  1.02it/s]Epoch: 7/10. Loss: 0.8694:  46%|[36m████▌     [0m| 12/26 [00:14<00:13,  1.02it/s]Epoch: 7/10. Loss: 0.8694:  50%|[36m█████     [0m| 13/26 [00:14<00:12,  1.02it/s]Epoch: 7/10. Loss: 0.8655:  50%|[36m█████     [0m| 13/26 [00:15<00:12,  1.02it/s]Epoch: 7/10. Loss: 0.8655:  54%|[36m█████▍    [0m| 14/26 [00:15<00:11,  1.03it/s]Epoch: 7/10. Loss: 0.9152:  54%|[36m█████▍    [0m| 14/26 [00:16<00:11,  1.03it/s]Epoch: 7/10. Loss: 0.9152:  58%|[36m█████▊    [0m| 15/26 [00:16<00:10,  1.01it/s]Epoch: 7/10. Loss: 0.8610:  58%|[36m█████▊    [0m| 15/26 [00:17<00:10,  1.01it/s]Epoch: 7/10. Loss: 0.8610:  62%|[36m██████▏   [0m| 16/26 [00:17<00:10,  1.04s/it]Epoch: 7/10. Loss: 0.8801:  62%|[36m██████▏   [0m| 16/26 [00:18<00:10,  1.04s/it]Epoch: 7/10. Loss: 0.8801:  65%|[36m██████▌   [0m| 17/26 [00:18<00:08,  1.01it/s]Epoch: 7/10. Loss: 0.9674:  65%|[36m██████▌   [0m| 17/26 [00:19<00:08,  1.01it/s]Epoch: 7/10. Loss: 0.9674:  69%|[36m██████▉   [0m| 18/26 [00:19<00:08,  1.00s/it]Epoch: 7/10. Loss: 0.8247:  69%|[36m██████▉   [0m| 18/26 [00:20<00:08,  1.00s/it]Epoch: 7/10. Loss: 0.8247:  73%|[36m███████▎  [0m| 19/26 [00:20<00:07,  1.03s/it]Epoch: 7/10. Loss: 0.8519:  73%|[36m███████▎  [0m| 19/26 [00:21<00:07,  1.03s/it]Epoch: 7/10. Loss: 0.8519:  77%|[36m███████▋  [0m| 20/26 [00:21<00:05,  1.01it/s]Epoch: 7/10. Loss: 0.9205:  77%|[36m███████▋  [0m| 20/26 [00:22<00:05,  1.01it/s]Epoch: 7/10. Loss: 0.9205:  81%|[36m████████  [0m| 21/26 [00:22<00:04,  1.05it/s]Epoch: 7/10. Loss: 0.8851:  81%|[36m████████  [0m| 21/26 [00:23<00:04,  1.05it/s]Epoch: 7/10. Loss: 0.8851:  85%|[36m████████▍ [0m| 22/26 [00:23<00:03,  1.11it/s]Epoch: 7/10. Loss: 0.8827:  85%|[36m████████▍ [0m| 22/26 [00:24<00:03,  1.11it/s]Epoch: 7/10. Loss: 0.8827:  88%|[36m████████▊ [0m| 23/26 [00:24<00:02,  1.06it/s]Epoch: 7/10. Loss: 0.8305:  88%|[36m████████▊ [0m| 23/26 [00:25<00:02,  1.06it/s]Epoch: 7/10. Loss: 0.8305:  92%|[36m█████████▏[0m| 24/26 [00:25<00:01,  1.09it/s]Epoch: 7/10. Loss: 0.8615:  92%|[36m█████████▏[0m| 24/26 [00:26<00:01,  1.09it/s]Epoch: 7/10. Loss: 0.8615:  96%|[36m█████████▌[0m| 25/26 [00:26<00:01,  1.08s/it]Epoch: 7/10. Loss: 0.8857:  96%|[36m█████████▌[0m| 25/26 [00:27<00:01,  1.08s/it]Epoch: 7/10. Loss: 0.8857: 100%|[36m██████████[0m| 26/26 [00:27<00:00,  1.06it/s]Epoch: 7/10. Loss: 0.8857: 100%|[36m██████████[0m| 26/26 [00:27<00:00,  1.05s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:05,  1.05it/s] 29%|[33m██▊       [0m| 2/7 [00:03<00:09,  1.81s/it] 43%|[33m████▎     [0m| 3/7 [00:04<00:05,  1.28s/it] 57%|[33m█████▋    [0m| 4/7 [00:05<00:04,  1.36s/it] 71%|[33m███████▏  [0m| 5/7 [00:05<00:02,  1.04s/it] 86%|[33m████████▌ [0m| 6/7 [00:06<00:01,  1.00s/it]100%|[33m██████████[0m| 7/7 [00:07<00:00,  1.28it/s]100%|[33m██████████[0m| 7/7 [00:07<00:00,  1.03s/it]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 8/10. Loss: 0.8849:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 8/10. Loss: 0.8849:   4%|[36m▍         [0m| 1/26 [00:00<00:24,  1.03it/s]Epoch: 8/10. Loss: 0.9641:   4%|[36m▍         [0m| 1/26 [00:01<00:24,  1.03it/s]Epoch: 8/10. Loss: 0.9641:   8%|[36m▊         [0m| 2/26 [00:01<00:24,  1.00s/it]Epoch: 8/10. Loss: 0.8522:   8%|[36m▊         [0m| 2/26 [00:02<00:24,  1.00s/it]Epoch: 8/10. Loss: 0.8522:  12%|[36m█▏        [0m| 3/26 [00:02<00:22,  1.03it/s]Epoch: 8/10. Loss: 0.9829:  12%|[36m█▏        [0m| 3/26 [00:03<00:22,  1.03it/s]Epoch: 8/10. Loss: 0.9829:  15%|[36m█▌        [0m| 4/26 [00:03<00:20,  1.07it/s]Epoch: 8/10. Loss: 0.8156:  15%|[36m█▌        [0m| 4/26 [00:04<00:20,  1.07it/s]Epoch: 8/10. Loss: 0.8156:  19%|[36m█▉        [0m| 5/26 [00:04<00:18,  1.14it/s]Epoch: 8/10. Loss: 0.7869:  19%|[36m█▉        [0m| 5/26 [00:06<00:18,  1.14it/s]Epoch: 8/10. Loss: 0.7869:  23%|[36m██▎       [0m| 6/26 [00:06<00:22,  1.10s/it]Epoch: 8/10. Loss: 0.8968:  23%|[36m██▎       [0m| 6/26 [00:07<00:22,  1.10s/it]Epoch: 8/10. Loss: 0.8968:  27%|[36m██▋       [0m| 7/26 [00:07<00:23,  1.24s/it]Epoch: 8/10. Loss: 0.9871:  27%|[36m██▋       [0m| 7/26 [00:08<00:23,  1.24s/it]Epoch: 8/10. Loss: 0.9871:  31%|[36m███       [0m| 8/26 [00:08<00:20,  1.16s/it]Epoch: 8/10. Loss: 0.8833:  31%|[36m███       [0m| 8/26 [00:09<00:20,  1.16s/it]Epoch: 8/10. Loss: 0.8833:  35%|[36m███▍      [0m| 9/26 [00:09<00:19,  1.14s/it]Epoch: 8/10. Loss: 0.9009:  35%|[36m███▍      [0m| 9/26 [00:10<00:19,  1.14s/it]Epoch: 8/10. Loss: 0.9009:  38%|[36m███▊      [0m| 10/26 [00:10<00:17,  1.06s/it]Epoch: 8/10. Loss: 0.9013:  38%|[36m███▊      [0m| 10/26 [00:11<00:17,  1.06s/it]Epoch: 8/10. Loss: 0.9013:  42%|[36m████▏     [0m| 11/26 [00:11<00:15,  1.02s/it]Epoch: 8/10. Loss: 0.7904:  42%|[36m████▏     [0m| 11/26 [00:12<00:15,  1.02s/it]Epoch: 8/10. Loss: 0.7904:  46%|[36m████▌     [0m| 12/26 [00:12<00:13,  1.00it/s]Epoch: 8/10. Loss: 0.7830:  46%|[36m████▌     [0m| 12/26 [00:13<00:13,  1.00it/s]Epoch: 8/10. Loss: 0.7830:  50%|[36m█████     [0m| 13/26 [00:13<00:12,  1.01it/s]Epoch: 8/10. Loss: 0.8780:  50%|[36m█████     [0m| 13/26 [00:14<00:12,  1.01it/s]Epoch: 8/10. Loss: 0.8780:  54%|[36m█████▍    [0m| 14/26 [00:14<00:11,  1.05it/s]Epoch: 8/10. Loss: 0.9715:  54%|[36m█████▍    [0m| 14/26 [00:15<00:11,  1.05it/s]Epoch: 8/10. Loss: 0.9715:  58%|[36m█████▊    [0m| 15/26 [00:15<00:10,  1.05it/s]Epoch: 8/10. Loss: 0.9577:  58%|[36m█████▊    [0m| 15/26 [00:16<00:10,  1.05it/s]Epoch: 8/10. Loss: 0.9577:  62%|[36m██████▏   [0m| 16/26 [00:16<00:09,  1.07it/s]Epoch: 8/10. Loss: 0.8455:  62%|[36m██████▏   [0m| 16/26 [00:17<00:09,  1.07it/s]Epoch: 8/10. Loss: 0.8455:  65%|[36m██████▌   [0m| 17/26 [00:17<00:08,  1.02it/s]Epoch: 8/10. Loss: 0.9279:  65%|[36m██████▌   [0m| 17/26 [00:18<00:08,  1.02it/s]Epoch: 8/10. Loss: 0.9279:  69%|[36m██████▉   [0m| 18/26 [00:18<00:07,  1.03it/s]Epoch: 8/10. Loss: 0.9101:  69%|[36m██████▉   [0m| 18/26 [00:19<00:07,  1.03it/s]Epoch: 8/10. Loss: 0.9101:  73%|[36m███████▎  [0m| 19/26 [00:19<00:06,  1.05it/s]Epoch: 8/10. Loss: 0.7662:  73%|[36m███████▎  [0m| 19/26 [00:19<00:06,  1.05it/s]Epoch: 8/10. Loss: 0.7662:  77%|[36m███████▋  [0m| 20/26 [00:19<00:05,  1.09it/s]Epoch: 8/10. Loss: 0.7977:  77%|[36m███████▋  [0m| 20/26 [00:21<00:05,  1.09it/s]Epoch: 8/10. Loss: 0.7977:  81%|[36m████████  [0m| 21/26 [00:21<00:04,  1.01it/s]Epoch: 8/10. Loss: 0.8851:  81%|[36m████████  [0m| 21/26 [00:22<00:04,  1.01it/s]Epoch: 8/10. Loss: 0.8851:  85%|[36m████████▍ [0m| 22/26 [00:22<00:03,  1.02it/s]Epoch: 8/10. Loss: 0.8723:  85%|[36m████████▍ [0m| 22/26 [00:23<00:03,  1.02it/s]Epoch: 8/10. Loss: 0.8723:  88%|[36m████████▊ [0m| 23/26 [00:23<00:02,  1.01it/s]Epoch: 8/10. Loss: 0.8523:  88%|[36m████████▊ [0m| 23/26 [00:24<00:02,  1.01it/s]Epoch: 8/10. Loss: 0.8523:  92%|[36m█████████▏[0m| 24/26 [00:24<00:02,  1.12s/it]Epoch: 8/10. Loss: 0.8164:  92%|[36m█████████▏[0m| 24/26 [00:29<00:02,  1.12s/it]Epoch: 8/10. Loss: 0.8164:  96%|[36m█████████▌[0m| 25/26 [00:29<00:02,  2.28s/it]Epoch: 8/10. Loss: 0.8415:  96%|[36m█████████▌[0m| 25/26 [00:31<00:02,  2.28s/it]Epoch: 8/10. Loss: 0.8415: 100%|[36m██████████[0m| 26/26 [00:31<00:00,  2.16s/it]Epoch: 8/10. Loss: 0.8415: 100%|[36m██████████[0m| 26/26 [00:31<00:00,  1.21s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:02<00:12,  2.08s/it] 29%|[33m██▊       [0m| 2/7 [00:04<00:10,  2.14s/it] 43%|[33m████▎     [0m| 3/7 [00:04<00:05,  1.44s/it] 57%|[33m█████▋    [0m| 4/7 [00:06<00:04,  1.47s/it] 71%|[33m███████▏  [0m| 5/7 [00:06<00:02,  1.08s/it] 86%|[33m████████▌ [0m| 6/7 [00:07<00:01,  1.11s/it]100%|[33m██████████[0m| 7/7 [00:08<00:00,  1.19it/s]100%|[33m██████████[0m| 7/7 [00:08<00:00,  1.18s/it]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 9/10. Loss: 0.7821:   0%|[36m          [0m| 0/26 [00:01<?, ?it/s]Epoch: 9/10. Loss: 0.7821:   4%|[36m▍         [0m| 1/26 [00:01<00:25,  1.04s/it]Epoch: 9/10. Loss: 0.8967:   4%|[36m▍         [0m| 1/26 [00:03<00:25,  1.04s/it]Epoch: 9/10. Loss: 0.8967:   8%|[36m▊         [0m| 2/26 [00:03<00:39,  1.65s/it]Epoch: 9/10. Loss: 0.8821:   8%|[36m▊         [0m| 2/26 [00:04<00:39,  1.65s/it]Epoch: 9/10. Loss: 0.8821:  12%|[36m█▏        [0m| 3/26 [00:04<00:30,  1.33s/it]Epoch: 9/10. Loss: 0.7753:  12%|[36m█▏        [0m| 3/26 [00:04<00:30,  1.33s/it]Epoch: 9/10. Loss: 0.7753:  15%|[36m█▌        [0m| 4/26 [00:04<00:24,  1.13s/it]Epoch: 9/10. Loss: 0.8287:  15%|[36m█▌        [0m| 4/26 [00:05<00:24,  1.13s/it]Epoch: 9/10. Loss: 0.8287:  19%|[36m█▉        [0m| 5/26 [00:05<00:22,  1.09s/it]Epoch: 9/10. Loss: 0.9085:  19%|[36m█▉        [0m| 5/26 [00:06<00:22,  1.09s/it]Epoch: 9/10. Loss: 0.9085:  23%|[36m██▎       [0m| 6/26 [00:06<00:21,  1.07s/it]Epoch: 9/10. Loss: 0.8005:  23%|[36m██▎       [0m| 6/26 [00:07<00:21,  1.07s/it]Epoch: 9/10. Loss: 0.8005:  27%|[36m██▋       [0m| 7/26 [00:07<00:18,  1.03it/s]Epoch: 9/10. Loss: 0.8417:  27%|[36m██▋       [0m| 7/26 [00:08<00:18,  1.03it/s]Epoch: 9/10. Loss: 0.8417:  31%|[36m███       [0m| 8/26 [00:08<00:17,  1.04it/s]Epoch: 9/10. Loss: 0.7682:  31%|[36m███       [0m| 8/26 [00:09<00:17,  1.04it/s]Epoch: 9/10. Loss: 0.7682:  35%|[36m███▍      [0m| 9/26 [00:09<00:15,  1.12it/s]Epoch: 9/10. Loss: 1.0011:  35%|[36m███▍      [0m| 9/26 [00:10<00:15,  1.12it/s]Epoch: 9/10. Loss: 1.0011:  38%|[36m███▊      [0m| 10/26 [00:10<00:14,  1.08it/s]Epoch: 9/10. Loss: 0.8730:  38%|[36m███▊      [0m| 10/26 [00:11<00:14,  1.08it/s]Epoch: 9/10. Loss: 0.8730:  42%|[36m████▏     [0m| 11/26 [00:11<00:14,  1.05it/s]Epoch: 9/10. Loss: 0.8188:  42%|[36m████▏     [0m| 11/26 [00:12<00:14,  1.05it/s]Epoch: 9/10. Loss: 0.8188:  46%|[36m████▌     [0m| 12/26 [00:12<00:13,  1.06it/s]Epoch: 9/10. Loss: 0.9332:  46%|[36m████▌     [0m| 12/26 [00:13<00:13,  1.06it/s]Epoch: 9/10. Loss: 0.9332:  50%|[36m█████     [0m| 13/26 [00:13<00:11,  1.12it/s]Epoch: 9/10. Loss: 0.9332:  50%|[36m█████     [0m| 13/26 [00:14<00:11,  1.12it/s]Epoch: 9/10. Loss: 0.9332:  54%|[36m█████▍    [0m| 14/26 [00:14<00:11,  1.04it/s]Epoch: 9/10. Loss: 0.8832:  54%|[36m█████▍    [0m| 14/26 [00:15<00:11,  1.04it/s]Epoch: 9/10. Loss: 0.8832:  58%|[36m█████▊    [0m| 15/26 [00:15<00:10,  1.04it/s]Epoch: 9/10. Loss: 0.8398:  58%|[36m█████▊    [0m| 15/26 [00:16<00:10,  1.04it/s]Epoch: 9/10. Loss: 0.8398:  62%|[36m██████▏   [0m| 16/26 [00:16<00:09,  1.02it/s]Epoch: 9/10. Loss: 0.8030:  62%|[36m██████▏   [0m| 16/26 [00:17<00:09,  1.02it/s]Epoch: 9/10. Loss: 0.8030:  65%|[36m██████▌   [0m| 17/26 [00:17<00:08,  1.05it/s]Epoch: 9/10. Loss: 0.7805:  65%|[36m██████▌   [0m| 17/26 [00:18<00:08,  1.05it/s]Epoch: 9/10. Loss: 0.7805:  69%|[36m██████▉   [0m| 18/26 [00:18<00:07,  1.02it/s]Epoch: 9/10. Loss: 0.8197:  69%|[36m██████▉   [0m| 18/26 [00:19<00:07,  1.02it/s]Epoch: 9/10. Loss: 0.8197:  73%|[36m███████▎  [0m| 19/26 [00:19<00:06,  1.02it/s]Epoch: 9/10. Loss: 0.7764:  73%|[36m███████▎  [0m| 19/26 [00:20<00:06,  1.02it/s]Epoch: 9/10. Loss: 0.7764:  77%|[36m███████▋  [0m| 20/26 [00:20<00:05,  1.04it/s]Epoch: 9/10. Loss: 0.7746:  77%|[36m███████▋  [0m| 20/26 [00:21<00:05,  1.04it/s]Epoch: 9/10. Loss: 0.7746:  81%|[36m████████  [0m| 21/26 [00:21<00:05,  1.00s/it]Epoch: 9/10. Loss: 0.8964:  81%|[36m████████  [0m| 21/26 [00:22<00:05,  1.00s/it]Epoch: 9/10. Loss: 0.8964:  85%|[36m████████▍ [0m| 22/26 [00:22<00:03,  1.00it/s]Epoch: 9/10. Loss: 0.9129:  85%|[36m████████▍ [0m| 22/26 [00:23<00:03,  1.00it/s]Epoch: 9/10. Loss: 0.9129:  88%|[36m████████▊ [0m| 23/26 [00:23<00:02,  1.02it/s]Epoch: 9/10. Loss: 0.7793:  88%|[36m████████▊ [0m| 23/26 [00:23<00:02,  1.02it/s]Epoch: 9/10. Loss: 0.7793:  92%|[36m█████████▏[0m| 24/26 [00:23<00:01,  1.06it/s]Epoch: 9/10. Loss: 0.7857:  92%|[36m█████████▏[0m| 24/26 [00:24<00:01,  1.06it/s]Epoch: 9/10. Loss: 0.7857:  96%|[36m█████████▌[0m| 25/26 [00:24<00:00,  1.04it/s]Epoch: 9/10. Loss: 0.9330:  96%|[36m█████████▌[0m| 25/26 [00:25<00:00,  1.04it/s]Epoch: 9/10. Loss: 0.9330: 100%|[36m██████████[0m| 26/26 [00:25<00:00,  1.10it/s]Epoch: 9/10. Loss: 0.9330: 100%|[36m██████████[0m| 26/26 [00:25<00:00,  1.01it/s]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:05,  1.10it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:06,  1.26s/it] 43%|[33m████▎     [0m| 3/7 [00:02<00:03,  1.05it/s] 57%|[33m█████▋    [0m| 4/7 [00:04<00:03,  1.14s/it] 71%|[33m███████▏  [0m| 5/7 [00:04<00:01,  1.14it/s] 86%|[33m████████▌ [0m| 6/7 [00:05<00:00,  1.14it/s]100%|[33m██████████[0m| 7/7 [00:06<00:00,  1.46it/s]100%|[33m██████████[0m| 7/7 [00:06<00:00,  1.17it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 0/10. Loss: 1.2011:   0%|[36m          [0m| 0/26 [00:01<?, ?it/s]Epoch: 0/10. Loss: 1.2011:   4%|[36m▍         [0m| 1/26 [00:01<00:40,  1.61s/it]Epoch: 0/10. Loss: 6.3693:   4%|[36m▍         [0m| 1/26 [00:02<00:40,  1.61s/it]Epoch: 0/10. Loss: 6.3693:   8%|[36m▊         [0m| 2/26 [00:02<00:27,  1.14s/it]Epoch: 0/10. Loss: 1.9815:   8%|[36m▊         [0m| 2/26 [00:03<00:27,  1.14s/it]Epoch: 0/10. Loss: 1.9815:  12%|[36m█▏        [0m| 3/26 [00:03<00:23,  1.01s/it]Epoch: 0/10. Loss: 2.7923:  12%|[36m█▏        [0m| 3/26 [00:04<00:23,  1.01s/it]Epoch: 0/10. Loss: 2.7923:  15%|[36m█▌        [0m| 4/26 [00:04<00:22,  1.03s/it]Epoch: 0/10. Loss: 2.0879:  15%|[36m█▌        [0m| 4/26 [00:05<00:22,  1.03s/it]Epoch: 0/10. Loss: 2.0879:  19%|[36m█▉        [0m| 5/26 [00:05<00:23,  1.13s/it]Epoch: 0/10. Loss: 1.5010:  19%|[36m█▉        [0m| 5/26 [00:06<00:23,  1.13s/it]Epoch: 0/10. Loss: 1.5010:  23%|[36m██▎       [0m| 6/26 [00:06<00:20,  1.04s/it]Epoch: 0/10. Loss: 1.0653:  23%|[36m██▎       [0m| 6/26 [00:07<00:20,  1.04s/it]Epoch: 0/10. Loss: 1.0653:  27%|[36m██▋       [0m| 7/26 [00:07<00:18,  1.00it/s]Epoch: 0/10. Loss: 1.4418:  27%|[36m██▋       [0m| 7/26 [00:08<00:18,  1.00it/s]Epoch: 0/10. Loss: 1.4418:  31%|[36m███       [0m| 8/26 [00:08<00:17,  1.01it/s]Epoch: 0/10. Loss: 1.4380:  31%|[36m███       [0m| 8/26 [00:09<00:17,  1.01it/s]Epoch: 0/10. Loss: 1.4380:  35%|[36m███▍      [0m| 9/26 [00:09<00:16,  1.02it/s]Epoch: 0/10. Loss: 1.1763:  35%|[36m███▍      [0m| 9/26 [00:10<00:16,  1.02it/s]Epoch: 0/10. Loss: 1.1763:  38%|[36m███▊      [0m| 10/26 [00:10<00:14,  1.11it/s]Epoch: 0/10. Loss: 1.3769:  38%|[36m███▊      [0m| 10/26 [00:11<00:14,  1.11it/s]Epoch: 0/10. Loss: 1.3769:  42%|[36m████▏     [0m| 11/26 [00:11<00:13,  1.08it/s]Epoch: 0/10. Loss: 1.2960:  42%|[36m████▏     [0m| 11/26 [00:12<00:13,  1.08it/s]Epoch: 0/10. Loss: 1.2960:  46%|[36m████▌     [0m| 12/26 [00:12<00:13,  1.03it/s]Epoch: 0/10. Loss: 1.1196:  46%|[36m████▌     [0m| 12/26 [00:12<00:13,  1.03it/s]Epoch: 0/10. Loss: 1.1196:  50%|[36m█████     [0m| 13/26 [00:12<00:11,  1.09it/s]Epoch: 0/10. Loss: 0.9818:  50%|[36m█████     [0m| 13/26 [00:13<00:11,  1.09it/s]Epoch: 0/10. Loss: 0.9818:  54%|[36m█████▍    [0m| 14/26 [00:13<00:10,  1.13it/s]Epoch: 0/10. Loss: 1.0496:  54%|[36m█████▍    [0m| 14/26 [00:14<00:10,  1.13it/s]Epoch: 0/10. Loss: 1.0496:  58%|[36m█████▊    [0m| 15/26 [00:14<00:10,  1.06it/s]Epoch: 0/10. Loss: 1.4802:  58%|[36m█████▊    [0m| 15/26 [00:15<00:10,  1.06it/s]Epoch: 0/10. Loss: 1.4802:  62%|[36m██████▏   [0m| 16/26 [00:15<00:09,  1.10it/s]Epoch: 0/10. Loss: 1.1360:  62%|[36m██████▏   [0m| 16/26 [00:16<00:09,  1.10it/s]Epoch: 0/10. Loss: 1.1360:  65%|[36m██████▌   [0m| 17/26 [00:16<00:08,  1.06it/s]Epoch: 0/10. Loss: 1.1808:  65%|[36m██████▌   [0m| 17/26 [00:17<00:08,  1.06it/s]Epoch: 0/10. Loss: 1.1808:  69%|[36m██████▉   [0m| 18/26 [00:17<00:07,  1.03it/s]Epoch: 0/10. Loss: 1.1536:  69%|[36m██████▉   [0m| 18/26 [00:21<00:07,  1.03it/s]Epoch: 0/10. Loss: 1.1536:  73%|[36m███████▎  [0m| 19/26 [00:21<00:12,  1.84s/it]Epoch: 0/10. Loss: 1.0519:  73%|[36m███████▎  [0m| 19/26 [00:22<00:12,  1.84s/it]Epoch: 0/10. Loss: 1.0519:  77%|[36m███████▋  [0m| 20/26 [00:22<00:09,  1.57s/it]Epoch: 0/10. Loss: 1.1581:  77%|[36m███████▋  [0m| 20/26 [00:23<00:09,  1.57s/it]Epoch: 0/10. Loss: 1.1581:  81%|[36m████████  [0m| 21/26 [00:23<00:06,  1.40s/it]Epoch: 0/10. Loss: 1.2329:  81%|[36m████████  [0m| 21/26 [00:24<00:06,  1.40s/it]Epoch: 0/10. Loss: 1.2329:  85%|[36m████████▍ [0m| 22/26 [00:24<00:05,  1.28s/it]Epoch: 0/10. Loss: 1.1755:  85%|[36m████████▍ [0m| 22/26 [00:25<00:05,  1.28s/it]Epoch: 0/10. Loss: 1.1755:  88%|[36m████████▊ [0m| 23/26 [00:25<00:03,  1.11s/it]Epoch: 0/10. Loss: 1.0783:  88%|[36m████████▊ [0m| 23/26 [00:25<00:03,  1.11s/it]Epoch: 0/10. Loss: 1.0783:  92%|[36m█████████▏[0m| 24/26 [00:25<00:01,  1.01it/s]Epoch: 0/10. Loss: 0.9773:  92%|[36m█████████▏[0m| 24/26 [00:26<00:01,  1.01it/s]Epoch: 0/10. Loss: 0.9773:  96%|[36m█████████▌[0m| 25/26 [00:26<00:00,  1.05it/s]Epoch: 0/10. Loss: 1.0700:  96%|[36m█████████▌[0m| 25/26 [00:27<00:00,  1.05it/s]Epoch: 0/10. Loss: 1.0700: 100%|[36m██████████[0m| 26/26 [00:27<00:00,  1.00it/s]Epoch: 0/10. Loss: 1.0700: 100%|[36m██████████[0m| 26/26 [00:27<00:00,  1.07s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:05,  1.15it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:06,  1.23s/it] 43%|[33m████▎     [0m| 3/7 [00:02<00:03,  1.09it/s] 57%|[33m█████▋    [0m| 4/7 [00:04<00:03,  1.09s/it] 71%|[33m███████▏  [0m| 5/7 [00:06<00:03,  1.62s/it] 86%|[33m████████▌ [0m| 6/7 [00:08<00:01,  1.73s/it]100%|[33m██████████[0m| 7/7 [00:09<00:00,  1.28s/it]100%|[33m██████████[0m| 7/7 [00:09<00:00,  1.30s/it]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 1/10. Loss: 1.0192:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 1/10. Loss: 1.0192:   4%|[36m▍         [0m| 1/26 [00:00<00:23,  1.07it/s]Epoch: 1/10. Loss: 1.0055:   4%|[36m▍         [0m| 1/26 [00:03<00:23,  1.07it/s]Epoch: 1/10. Loss: 1.0055:   8%|[36m▊         [0m| 2/26 [00:03<00:47,  2.00s/it]Epoch: 1/10. Loss: 1.0518:   8%|[36m▊         [0m| 2/26 [00:05<00:47,  2.00s/it]Epoch: 1/10. Loss: 1.0518:  12%|[36m█▏        [0m| 3/26 [00:05<00:42,  1.84s/it]Epoch: 1/10. Loss: 0.9736:  12%|[36m█▏        [0m| 3/26 [00:06<00:42,  1.84s/it]Epoch: 1/10. Loss: 0.9736:  15%|[36m█▌        [0m| 4/26 [00:06<00:31,  1.44s/it]Epoch: 1/10. Loss: 0.9939:  15%|[36m█▌        [0m| 4/26 [00:06<00:31,  1.44s/it]Epoch: 1/10. Loss: 0.9939:  19%|[36m█▉        [0m| 5/26 [00:06<00:24,  1.17s/it]Epoch: 1/10. Loss: 1.0817:  19%|[36m█▉        [0m| 5/26 [00:07<00:24,  1.17s/it]Epoch: 1/10. Loss: 1.0817:  23%|[36m██▎       [0m| 6/26 [00:07<00:22,  1.14s/it]Epoch: 1/10. Loss: 0.9772:  23%|[36m██▎       [0m| 6/26 [00:08<00:22,  1.14s/it]Epoch: 1/10. Loss: 0.9772:  27%|[36m██▋       [0m| 7/26 [00:08<00:20,  1.07s/it]Epoch: 1/10. Loss: 1.0604:  27%|[36m██▋       [0m| 7/26 [00:09<00:20,  1.07s/it]Epoch: 1/10. Loss: 1.0604:  31%|[36m███       [0m| 8/26 [00:09<00:19,  1.06s/it]Epoch: 1/10. Loss: 0.9689:  31%|[36m███       [0m| 8/26 [00:10<00:19,  1.06s/it]Epoch: 1/10. Loss: 0.9689:  35%|[36m███▍      [0m| 9/26 [00:10<00:17,  1.02s/it]Epoch: 1/10. Loss: 0.9082:  35%|[36m███▍      [0m| 9/26 [00:11<00:17,  1.02s/it]Epoch: 1/10. Loss: 0.9082:  38%|[36m███▊      [0m| 10/26 [00:11<00:15,  1.05it/s]Epoch: 1/10. Loss: 1.2219:  38%|[36m███▊      [0m| 10/26 [00:13<00:15,  1.05it/s]Epoch: 1/10. Loss: 1.2219:  42%|[36m████▏     [0m| 11/26 [00:13<00:19,  1.31s/it]Epoch: 1/10. Loss: 1.0647:  42%|[36m████▏     [0m| 11/26 [00:14<00:19,  1.31s/it]Epoch: 1/10. Loss: 1.0647:  46%|[36m████▌     [0m| 12/26 [00:14<00:16,  1.20s/it]Epoch: 1/10. Loss: 1.2383:  46%|[36m████▌     [0m| 12/26 [00:15<00:16,  1.20s/it]Epoch: 1/10. Loss: 1.2383:  50%|[36m█████     [0m| 13/26 [00:15<00:14,  1.10s/it]Epoch: 1/10. Loss: 1.0234:  50%|[36m█████     [0m| 13/26 [00:16<00:14,  1.10s/it]Epoch: 1/10. Loss: 1.0234:  54%|[36m█████▍    [0m| 14/26 [00:16<00:13,  1.14s/it]Epoch: 1/10. Loss: 0.9046:  54%|[36m█████▍    [0m| 14/26 [00:19<00:13,  1.14s/it]Epoch: 1/10. Loss: 0.9046:  58%|[36m█████▊    [0m| 15/26 [00:19<00:18,  1.69s/it]Epoch: 1/10. Loss: 1.0358:  58%|[36m█████▊    [0m| 15/26 [00:20<00:18,  1.69s/it]Epoch: 1/10. Loss: 1.0358:  62%|[36m██████▏   [0m| 16/26 [00:20<00:15,  1.53s/it]Epoch: 1/10. Loss: 1.0431:  62%|[36m██████▏   [0m| 16/26 [00:21<00:15,  1.53s/it]Epoch: 1/10. Loss: 1.0431:  65%|[36m██████▌   [0m| 17/26 [00:21<00:11,  1.31s/it]Epoch: 1/10. Loss: 1.7821:  65%|[36m██████▌   [0m| 17/26 [00:22<00:11,  1.31s/it]Epoch: 1/10. Loss: 1.7821:  69%|[36m██████▉   [0m| 18/26 [00:22<00:09,  1.23s/it]Epoch: 1/10. Loss: 1.1708:  69%|[36m██████▉   [0m| 18/26 [00:24<00:09,  1.23s/it]Epoch: 1/10. Loss: 1.1708:  73%|[36m███████▎  [0m| 19/26 [00:24<00:08,  1.25s/it]Epoch: 1/10. Loss: 0.9958:  73%|[36m███████▎  [0m| 19/26 [00:25<00:08,  1.25s/it]Epoch: 1/10. Loss: 0.9958:  77%|[36m███████▋  [0m| 20/26 [00:25<00:07,  1.31s/it]Epoch: 1/10. Loss: 0.9935:  77%|[36m███████▋  [0m| 20/26 [00:27<00:07,  1.31s/it]Epoch: 1/10. Loss: 0.9935:  81%|[36m████████  [0m| 21/26 [00:27<00:07,  1.48s/it]Epoch: 1/10. Loss: 1.2769:  81%|[36m████████  [0m| 21/26 [00:28<00:07,  1.48s/it]Epoch: 1/10. Loss: 1.2769:  85%|[36m████████▍ [0m| 22/26 [00:28<00:05,  1.45s/it]Epoch: 1/10. Loss: 1.1334:  85%|[36m████████▍ [0m| 22/26 [00:29<00:05,  1.45s/it]Epoch: 1/10. Loss: 1.1334:  88%|[36m████████▊ [0m| 23/26 [00:29<00:03,  1.28s/it]Epoch: 1/10. Loss: 1.0380:  88%|[36m████████▊ [0m| 23/26 [00:30<00:03,  1.28s/it]Epoch: 1/10. Loss: 1.0380:  92%|[36m█████████▏[0m| 24/26 [00:30<00:02,  1.15s/it]Epoch: 1/10. Loss: 1.0591:  92%|[36m█████████▏[0m| 24/26 [00:32<00:02,  1.15s/it]Epoch: 1/10. Loss: 1.0591:  96%|[36m█████████▌[0m| 25/26 [00:32<00:01,  1.33s/it]Epoch: 1/10. Loss: 1.0117:  96%|[36m█████████▌[0m| 25/26 [00:33<00:01,  1.33s/it]Epoch: 1/10. Loss: 1.0117: 100%|[36m██████████[0m| 26/26 [00:33<00:00,  1.17s/it]Epoch: 1/10. Loss: 1.0117: 100%|[36m██████████[0m| 26/26 [00:33<00:00,  1.27s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:01<00:06,  1.16s/it] 29%|[33m██▊       [0m| 2/7 [00:02<00:06,  1.34s/it] 43%|[33m████▎     [0m| 3/7 [00:03<00:03,  1.02it/s] 57%|[33m█████▋    [0m| 4/7 [00:04<00:03,  1.15s/it] 71%|[33m███████▏  [0m| 5/7 [00:04<00:01,  1.15it/s] 86%|[33m████████▌ [0m| 6/7 [00:08<00:01,  1.65s/it]100%|[33m██████████[0m| 7/7 [00:08<00:00,  1.20s/it]100%|[33m██████████[0m| 7/7 [00:08<00:00,  1.20s/it]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 2/10. Loss: 1.1431:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 2/10. Loss: 1.1431:   4%|[36m▍         [0m| 1/26 [00:00<00:23,  1.07it/s]Epoch: 2/10. Loss: 1.0212:   4%|[36m▍         [0m| 1/26 [00:01<00:23,  1.07it/s]Epoch: 2/10. Loss: 1.0212:   8%|[36m▊         [0m| 2/26 [00:01<00:22,  1.08it/s]Epoch: 2/10. Loss: 0.9542:   8%|[36m▊         [0m| 2/26 [00:02<00:22,  1.08it/s]Epoch: 2/10. Loss: 0.9542:  12%|[36m█▏        [0m| 3/26 [00:02<00:23,  1.00s/it]Epoch: 2/10. Loss: 1.0377:  12%|[36m█▏        [0m| 3/26 [00:07<00:23,  1.00s/it]Epoch: 2/10. Loss: 1.0377:  15%|[36m█▌        [0m| 4/26 [00:07<00:49,  2.26s/it]Epoch: 2/10. Loss: 1.1222:  15%|[36m█▌        [0m| 4/26 [00:08<00:49,  2.26s/it]Epoch: 2/10. Loss: 1.1222:  19%|[36m█▉        [0m| 5/26 [00:08<00:37,  1.78s/it]Epoch: 2/10. Loss: 1.0185:  19%|[36m█▉        [0m| 5/26 [00:09<00:37,  1.78s/it]Epoch: 2/10. Loss: 1.0185:  23%|[36m██▎       [0m| 6/26 [00:09<00:30,  1.50s/it]Epoch: 2/10. Loss: 1.0353:  23%|[36m██▎       [0m| 6/26 [00:09<00:30,  1.50s/it]Epoch: 2/10. Loss: 1.0353:  27%|[36m██▋       [0m| 7/26 [00:09<00:25,  1.32s/it]Epoch: 2/10. Loss: 0.9830:  27%|[36m██▋       [0m| 7/26 [00:10<00:25,  1.32s/it]Epoch: 2/10. Loss: 0.9830:  31%|[36m███       [0m| 8/26 [00:10<00:20,  1.14s/it]Epoch: 2/10. Loss: 0.9598:  31%|[36m███       [0m| 8/26 [00:11<00:20,  1.14s/it]Epoch: 2/10. Loss: 0.9598:  35%|[36m███▍      [0m| 9/26 [00:11<00:18,  1.07s/it]Epoch: 2/10. Loss: 0.9008:  35%|[36m███▍      [0m| 9/26 [00:12<00:18,  1.07s/it]Epoch: 2/10. Loss: 0.9008:  38%|[36m███▊      [0m| 10/26 [00:12<00:15,  1.00it/s]Epoch: 2/10. Loss: 1.0370:  38%|[36m███▊      [0m| 10/26 [00:13<00:15,  1.00it/s]Epoch: 2/10. Loss: 1.0370:  42%|[36m████▏     [0m| 11/26 [00:13<00:14,  1.01it/s]Epoch: 2/10. Loss: 0.9970:  42%|[36m████▏     [0m| 11/26 [00:17<00:14,  1.01it/s]Epoch: 2/10. Loss: 0.9970:  46%|[36m████▌     [0m| 12/26 [00:17<00:28,  2.03s/it]Epoch: 2/10. Loss: 0.9947:  46%|[36m████▌     [0m| 12/26 [00:19<00:28,  2.03s/it]Epoch: 2/10. Loss: 0.9947:  50%|[36m█████     [0m| 13/26 [00:19<00:23,  1.80s/it]Epoch: 2/10. Loss: 1.0950:  50%|[36m█████     [0m| 13/26 [00:21<00:23,  1.80s/it]Epoch: 2/10. Loss: 1.0950:  54%|[36m█████▍    [0m| 14/26 [00:21<00:25,  2.09s/it]Epoch: 2/10. Loss: 0.8866:  54%|[36m█████▍    [0m| 14/26 [00:22<00:25,  2.09s/it]Epoch: 2/10. Loss: 0.8866:  58%|[36m█████▊    [0m| 15/26 [00:22<00:18,  1.72s/it]Epoch: 2/10. Loss: 1.0290:  58%|[36m█████▊    [0m| 15/26 [00:23<00:18,  1.72s/it]Epoch: 2/10. Loss: 1.0290:  62%|[36m██████▏   [0m| 16/26 [00:23<00:15,  1.51s/it]Epoch: 2/10. Loss: 1.0110:  62%|[36m██████▏   [0m| 16/26 [00:24<00:15,  1.51s/it]Epoch: 2/10. Loss: 1.0110:  65%|[36m██████▌   [0m| 17/26 [00:24<00:11,  1.31s/it]Epoch: 2/10. Loss: 0.9602:  65%|[36m██████▌   [0m| 17/26 [00:25<00:11,  1.31s/it]Epoch: 2/10. Loss: 0.9602:  69%|[36m██████▉   [0m| 18/26 [00:25<00:09,  1.21s/it]Epoch: 2/10. Loss: 1.0445:  69%|[36m██████▉   [0m| 18/26 [00:26<00:09,  1.21s/it]Epoch: 2/10. Loss: 1.0445:  73%|[36m███████▎  [0m| 19/26 [00:26<00:07,  1.10s/it]Epoch: 2/10. Loss: 1.0338:  73%|[36m███████▎  [0m| 19/26 [00:27<00:07,  1.10s/it]Epoch: 2/10. Loss: 1.0338:  77%|[36m███████▋  [0m| 20/26 [00:27<00:06,  1.08s/it]Epoch: 2/10. Loss: 0.9725:  77%|[36m███████▋  [0m| 20/26 [00:28<00:06,  1.08s/it]Epoch: 2/10. Loss: 0.9725:  81%|[36m████████  [0m| 21/26 [00:28<00:05,  1.04s/it]Epoch: 2/10. Loss: 1.0200:  81%|[36m████████  [0m| 21/26 [00:29<00:05,  1.04s/it]Epoch: 2/10. Loss: 1.0200:  85%|[36m████████▍ [0m| 22/26 [00:29<00:03,  1.01it/s]Epoch: 2/10. Loss: 0.9562:  85%|[36m████████▍ [0m| 22/26 [00:30<00:03,  1.01it/s]Epoch: 2/10. Loss: 0.9562:  88%|[36m████████▊ [0m| 23/26 [00:30<00:02,  1.01it/s]Epoch: 2/10. Loss: 1.0116:  88%|[36m████████▊ [0m| 23/26 [00:31<00:02,  1.01it/s]Epoch: 2/10. Loss: 1.0116:  92%|[36m█████████▏[0m| 24/26 [00:31<00:01,  1.03it/s]Epoch: 2/10. Loss: 1.0183:  92%|[36m█████████▏[0m| 24/26 [00:32<00:01,  1.03it/s]Epoch: 2/10. Loss: 1.0183:  96%|[36m█████████▌[0m| 25/26 [00:32<00:00,  1.07it/s]Epoch: 2/10. Loss: 1.0238:  96%|[36m█████████▌[0m| 25/26 [00:32<00:00,  1.07it/s]Epoch: 2/10. Loss: 1.0238: 100%|[36m██████████[0m| 26/26 [00:32<00:00,  1.17it/s]Epoch: 2/10. Loss: 1.0238: 100%|[36m██████████[0m| 26/26 [00:32<00:00,  1.26s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:05,  1.14it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:06,  1.23s/it] 43%|[33m████▎     [0m| 3/7 [00:02<00:03,  1.10it/s] 57%|[33m█████▋    [0m| 4/7 [00:04<00:03,  1.22s/it] 71%|[33m███████▏  [0m| 5/7 [00:04<00:01,  1.08it/s] 86%|[33m████████▌ [0m| 6/7 [00:05<00:00,  1.10it/s]100%|[33m██████████[0m| 7/7 [00:06<00:00,  1.41it/s]100%|[33m██████████[0m| 7/7 [00:06<00:00,  1.14it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 3/10. Loss: 1.0350:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 3/10. Loss: 1.0350:   4%|[36m▍         [0m| 1/26 [00:00<00:18,  1.33it/s]Epoch: 3/10. Loss: 1.0040:   4%|[36m▍         [0m| 1/26 [00:03<00:18,  1.33it/s]Epoch: 3/10. Loss: 1.0040:   8%|[36m▊         [0m| 2/26 [00:03<00:40,  1.71s/it]Epoch: 3/10. Loss: 0.9446:   8%|[36m▊         [0m| 2/26 [00:04<00:40,  1.71s/it]Epoch: 3/10. Loss: 0.9446:  12%|[36m█▏        [0m| 3/26 [00:04<00:34,  1.48s/it]Epoch: 3/10. Loss: 0.9831:  12%|[36m█▏        [0m| 3/26 [00:05<00:34,  1.48s/it]Epoch: 3/10. Loss: 0.9831:  15%|[36m█▌        [0m| 4/26 [00:05<00:27,  1.25s/it]Epoch: 3/10. Loss: 1.0444:  15%|[36m█▌        [0m| 4/26 [00:06<00:27,  1.25s/it]Epoch: 3/10. Loss: 1.0444:  19%|[36m█▉        [0m| 5/26 [00:06<00:22,  1.08s/it]Epoch: 3/10. Loss: 0.9739:  19%|[36m█▉        [0m| 5/26 [00:07<00:22,  1.08s/it]Epoch: 3/10. Loss: 0.9739:  23%|[36m██▎       [0m| 6/26 [00:07<00:22,  1.14s/it]Epoch: 3/10. Loss: 0.9641:  23%|[36m██▎       [0m| 6/26 [00:08<00:22,  1.14s/it]Epoch: 3/10. Loss: 0.9641:  27%|[36m██▋       [0m| 7/26 [00:08<00:22,  1.16s/it]Epoch: 3/10. Loss: 0.8938:  27%|[36m██▋       [0m| 7/26 [00:09<00:22,  1.16s/it]Epoch: 3/10. Loss: 0.8938:  31%|[36m███       [0m| 8/26 [00:09<00:20,  1.14s/it]Epoch: 3/10. Loss: 0.9420:  31%|[36m███       [0m| 8/26 [00:10<00:20,  1.14s/it]Epoch: 3/10. Loss: 0.9420:  35%|[36m███▍      [0m| 9/26 [00:10<00:18,  1.07s/it]Epoch: 3/10. Loss: 0.9561:  35%|[36m███▍      [0m| 9/26 [00:11<00:18,  1.07s/it]Epoch: 3/10. Loss: 0.9561:  38%|[36m███▊      [0m| 10/26 [00:11<00:16,  1.01s/it]Epoch: 3/10. Loss: 0.9799:  38%|[36m███▊      [0m| 10/26 [00:12<00:16,  1.01s/it]Epoch: 3/10. Loss: 0.9799:  42%|[36m████▏     [0m| 11/26 [00:12<00:14,  1.00it/s]Epoch: 3/10. Loss: 0.9769:  42%|[36m████▏     [0m| 11/26 [00:13<00:14,  1.00it/s]Epoch: 3/10. Loss: 0.9769:  46%|[36m████▌     [0m| 12/26 [00:13<00:13,  1.06it/s]Epoch: 3/10. Loss: 0.8810:  46%|[36m████▌     [0m| 12/26 [00:14<00:13,  1.06it/s]Epoch: 3/10. Loss: 0.8810:  50%|[36m█████     [0m| 13/26 [00:14<00:13,  1.01s/it]Epoch: 3/10. Loss: 0.9528:  50%|[36m█████     [0m| 13/26 [00:15<00:13,  1.01s/it]Epoch: 3/10. Loss: 0.9528:  54%|[36m█████▍    [0m| 14/26 [00:15<00:11,  1.08it/s]Epoch: 3/10. Loss: 0.8914:  54%|[36m█████▍    [0m| 14/26 [00:15<00:11,  1.08it/s]Epoch: 3/10. Loss: 0.8914:  58%|[36m█████▊    [0m| 15/26 [00:15<00:09,  1.12it/s]Epoch: 3/10. Loss: 0.9511:  58%|[36m█████▊    [0m| 15/26 [00:16<00:09,  1.12it/s]Epoch: 3/10. Loss: 0.9511:  62%|[36m██████▏   [0m| 16/26 [00:16<00:08,  1.15it/s]Epoch: 3/10. Loss: 1.0260:  62%|[36m██████▏   [0m| 16/26 [00:17<00:08,  1.15it/s]Epoch: 3/10. Loss: 1.0260:  65%|[36m██████▌   [0m| 17/26 [00:17<00:07,  1.15it/s]Epoch: 3/10. Loss: 0.9028:  65%|[36m██████▌   [0m| 17/26 [00:18<00:07,  1.15it/s]Epoch: 3/10. Loss: 0.9028:  69%|[36m██████▉   [0m| 18/26 [00:18<00:06,  1.18it/s]Epoch: 3/10. Loss: 0.9592:  69%|[36m██████▉   [0m| 18/26 [00:19<00:06,  1.18it/s]Epoch: 3/10. Loss: 0.9592:  73%|[36m███████▎  [0m| 19/26 [00:19<00:06,  1.15it/s]Epoch: 3/10. Loss: 0.9679:  73%|[36m███████▎  [0m| 19/26 [00:20<00:06,  1.15it/s]Epoch: 3/10. Loss: 0.9679:  77%|[36m███████▋  [0m| 20/26 [00:20<00:05,  1.14it/s]Epoch: 3/10. Loss: 0.9584:  77%|[36m███████▋  [0m| 20/26 [00:21<00:05,  1.14it/s]Epoch: 3/10. Loss: 0.9584:  81%|[36m████████  [0m| 21/26 [00:21<00:04,  1.10it/s]Epoch: 3/10. Loss: 0.9871:  81%|[36m████████  [0m| 21/26 [00:22<00:04,  1.10it/s]Epoch: 3/10. Loss: 0.9871:  85%|[36m████████▍ [0m| 22/26 [00:22<00:03,  1.06it/s]Epoch: 3/10. Loss: 0.9351:  85%|[36m████████▍ [0m| 22/26 [00:22<00:03,  1.06it/s]Epoch: 3/10. Loss: 0.9351:  88%|[36m████████▊ [0m| 23/26 [00:22<00:02,  1.12it/s]Epoch: 3/10. Loss: 0.9321:  88%|[36m████████▊ [0m| 23/26 [00:23<00:02,  1.12it/s]Epoch: 3/10. Loss: 0.9321:  92%|[36m█████████▏[0m| 24/26 [00:23<00:01,  1.08it/s]Epoch: 3/10. Loss: 0.9045:  92%|[36m█████████▏[0m| 24/26 [00:26<00:01,  1.08it/s]Epoch: 3/10. Loss: 0.9045:  96%|[36m█████████▌[0m| 25/26 [00:26<00:01,  1.42s/it]Epoch: 3/10. Loss: 0.9831:  96%|[36m█████████▌[0m| 25/26 [00:26<00:01,  1.42s/it]Epoch: 3/10. Loss: 0.9831: 100%|[36m██████████[0m| 26/26 [00:26<00:00,  1.14s/it]Epoch: 3/10. Loss: 0.9831: 100%|[36m██████████[0m| 26/26 [00:26<00:00,  1.04s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:04,  1.27it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:07,  1.44s/it] 43%|[33m████▎     [0m| 3/7 [00:03<00:04,  1.04s/it] 57%|[33m█████▋    [0m| 4/7 [00:05<00:04,  1.35s/it] 71%|[33m███████▏  [0m| 5/7 [00:05<00:02,  1.00s/it] 86%|[33m████████▌ [0m| 6/7 [00:06<00:01,  1.15s/it]100%|[33m██████████[0m| 7/7 [00:07<00:00,  1.14it/s]100%|[33m██████████[0m| 7/7 [00:07<00:00,  1.03s/it]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 4/10. Loss: 0.9321:   0%|[36m          [0m| 0/26 [00:02<?, ?it/s]Epoch: 4/10. Loss: 0.9321:   4%|[36m▍         [0m| 1/26 [00:02<01:07,  2.69s/it]Epoch: 4/10. Loss: 0.9202:   4%|[36m▍         [0m| 1/26 [00:03<01:07,  2.69s/it]Epoch: 4/10. Loss: 0.9202:   8%|[36m▊         [0m| 2/26 [00:03<00:37,  1.56s/it]Epoch: 4/10. Loss: 0.8871:   8%|[36m▊         [0m| 2/26 [00:04<00:37,  1.56s/it]Epoch: 4/10. Loss: 0.8871:  12%|[36m█▏        [0m| 3/26 [00:04<00:30,  1.31s/it]Epoch: 4/10. Loss: 0.9806:  12%|[36m█▏        [0m| 3/26 [00:05<00:30,  1.31s/it]Epoch: 4/10. Loss: 0.9806:  15%|[36m█▌        [0m| 4/26 [00:05<00:23,  1.08s/it]Epoch: 4/10. Loss: 0.9698:  15%|[36m█▌        [0m| 4/26 [00:06<00:23,  1.08s/it]Epoch: 4/10. Loss: 0.9698:  19%|[36m█▉        [0m| 5/26 [00:06<00:22,  1.05s/it]Epoch: 4/10. Loss: 0.9057:  19%|[36m█▉        [0m| 5/26 [00:06<00:22,  1.05s/it]Epoch: 4/10. Loss: 0.9057:  23%|[36m██▎       [0m| 6/26 [00:07<00:19,  1.03it/s]Epoch: 4/10. Loss: 0.8798:  23%|[36m██▎       [0m| 6/26 [00:07<00:19,  1.03it/s]Epoch: 4/10. Loss: 0.8798:  27%|[36m██▋       [0m| 7/26 [00:07<00:17,  1.11it/s]Epoch: 4/10. Loss: 0.9194:  27%|[36m██▋       [0m| 7/26 [00:08<00:17,  1.11it/s]Epoch: 4/10. Loss: 0.9194:  31%|[36m███       [0m| 8/26 [00:08<00:16,  1.12it/s]Epoch: 4/10. Loss: 0.9217:  31%|[36m███       [0m| 8/26 [00:10<00:16,  1.12it/s]Epoch: 4/10. Loss: 0.9217:  35%|[36m███▍      [0m| 9/26 [00:10<00:17,  1.05s/it]Epoch: 4/10. Loss: 0.9390:  35%|[36m███▍      [0m| 9/26 [00:11<00:17,  1.05s/it]Epoch: 4/10. Loss: 0.9390:  38%|[36m███▊      [0m| 10/26 [00:11<00:19,  1.19s/it]Epoch: 4/10. Loss: 0.9848:  38%|[36m███▊      [0m| 10/26 [00:12<00:19,  1.19s/it]Epoch: 4/10. Loss: 0.9848:  42%|[36m████▏     [0m| 11/26 [00:12<00:17,  1.19s/it]Epoch: 4/10. Loss: 0.8849:  42%|[36m████▏     [0m| 11/26 [00:13<00:17,  1.19s/it]Epoch: 4/10. Loss: 0.8849:  46%|[36m████▌     [0m| 12/26 [00:13<00:14,  1.04s/it]Epoch: 4/10. Loss: 0.9728:  46%|[36m████▌     [0m| 12/26 [00:14<00:14,  1.04s/it]Epoch: 4/10. Loss: 0.9728:  50%|[36m█████     [0m| 13/26 [00:14<00:14,  1.08s/it]Epoch: 4/10. Loss: 1.0795:  50%|[36m█████     [0m| 13/26 [00:15<00:14,  1.08s/it]Epoch: 4/10. Loss: 1.0795:  54%|[36m█████▍    [0m| 14/26 [00:15<00:12,  1.07s/it]Epoch: 4/10. Loss: 0.8508:  54%|[36m█████▍    [0m| 14/26 [00:16<00:12,  1.07s/it]Epoch: 4/10. Loss: 0.8508:  58%|[36m█████▊    [0m| 15/26 [00:16<00:12,  1.10s/it]Epoch: 4/10. Loss: 0.9602:  58%|[36m█████▊    [0m| 15/26 [00:17<00:12,  1.10s/it]Epoch: 4/10. Loss: 0.9602:  62%|[36m██████▏   [0m| 16/26 [00:17<00:11,  1.11s/it]Epoch: 4/10. Loss: 0.9968:  62%|[36m██████▏   [0m| 16/26 [00:18<00:11,  1.11s/it]Epoch: 4/10. Loss: 0.9968:  65%|[36m██████▌   [0m| 17/26 [00:18<00:09,  1.03s/it]Epoch: 4/10. Loss: 0.9575:  65%|[36m██████▌   [0m| 17/26 [00:19<00:09,  1.03s/it]Epoch: 4/10. Loss: 0.9575:  69%|[36m██████▉   [0m| 18/26 [00:19<00:08,  1.07s/it]Epoch: 4/10. Loss: 0.8930:  69%|[36m██████▉   [0m| 18/26 [00:22<00:08,  1.07s/it]Epoch: 4/10. Loss: 0.8930:  73%|[36m███████▎  [0m| 19/26 [00:22<00:11,  1.63s/it]Epoch: 4/10. Loss: 0.8789:  73%|[36m███████▎  [0m| 19/26 [00:24<00:11,  1.63s/it]Epoch: 4/10. Loss: 0.8789:  77%|[36m███████▋  [0m| 20/26 [00:24<00:09,  1.58s/it]Epoch: 4/10. Loss: 0.8877:  77%|[36m███████▋  [0m| 20/26 [00:25<00:09,  1.58s/it]Epoch: 4/10. Loss: 0.8877:  81%|[36m████████  [0m| 21/26 [00:25<00:07,  1.50s/it]Epoch: 4/10. Loss: 0.9494:  81%|[36m████████  [0m| 21/26 [00:26<00:07,  1.50s/it]Epoch: 4/10. Loss: 0.9494:  85%|[36m████████▍ [0m| 22/26 [00:26<00:05,  1.37s/it]Epoch: 4/10. Loss: 0.9644:  85%|[36m████████▍ [0m| 22/26 [00:28<00:05,  1.37s/it]Epoch: 4/10. Loss: 0.9644:  88%|[36m████████▊ [0m| 23/26 [00:28<00:04,  1.39s/it]Epoch: 4/10. Loss: 0.8998:  88%|[36m████████▊ [0m| 23/26 [00:29<00:04,  1.39s/it]Epoch: 4/10. Loss: 0.8998:  92%|[36m█████████▏[0m| 24/26 [00:29<00:02,  1.30s/it]Epoch: 4/10. Loss: 0.8195:  92%|[36m█████████▏[0m| 24/26 [00:31<00:02,  1.30s/it]Epoch: 4/10. Loss: 0.8195:  96%|[36m█████████▌[0m| 25/26 [00:31<00:01,  1.53s/it]Epoch: 4/10. Loss: 0.8635:  96%|[36m█████████▌[0m| 25/26 [00:31<00:01,  1.53s/it]Epoch: 4/10. Loss: 0.8635: 100%|[36m██████████[0m| 26/26 [00:31<00:00,  1.27s/it]Epoch: 4/10. Loss: 0.8635: 100%|[36m██████████[0m| 26/26 [00:31<00:00,  1.23s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:02<00:16,  2.72s/it] 29%|[33m██▊       [0m| 2/7 [00:07<00:19,  3.95s/it] 43%|[33m████▎     [0m| 3/7 [00:08<00:09,  2.39s/it] 57%|[33m█████▋    [0m| 4/7 [00:10<00:07,  2.58s/it] 71%|[33m███████▏  [0m| 5/7 [00:11<00:03,  1.80s/it] 86%|[33m████████▌ [0m| 6/7 [00:14<00:02,  2.11s/it]100%|[33m██████████[0m| 7/7 [00:14<00:00,  1.62s/it]100%|[33m██████████[0m| 7/7 [00:14<00:00,  2.10s/it]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 5/10. Loss: 0.8870:   0%|[36m          [0m| 0/26 [00:02<?, ?it/s]Epoch: 5/10. Loss: 0.8870:   4%|[36m▍         [0m| 1/26 [00:02<00:58,  2.34s/it]Epoch: 5/10. Loss: 1.0090:   4%|[36m▍         [0m| 1/26 [00:03<00:58,  2.34s/it]Epoch: 5/10. Loss: 1.0090:   8%|[36m▊         [0m| 2/26 [00:03<00:35,  1.48s/it]Epoch: 5/10. Loss: 0.9246:   8%|[36m▊         [0m| 2/26 [00:04<00:35,  1.48s/it]Epoch: 5/10. Loss: 0.9246:  12%|[36m█▏        [0m| 3/26 [00:04<00:29,  1.26s/it]Epoch: 5/10. Loss: 0.9955:  12%|[36m█▏        [0m| 3/26 [00:08<00:29,  1.26s/it]Epoch: 5/10. Loss: 0.9955:  15%|[36m█▌        [0m| 4/26 [00:08<00:51,  2.32s/it]Epoch: 5/10. Loss: 0.9179:  15%|[36m█▌        [0m| 4/26 [00:09<00:51,  2.32s/it]Epoch: 5/10. Loss: 0.9179:  19%|[36m█▉        [0m| 5/26 [00:09<00:39,  1.88s/it]Epoch: 5/10. Loss: 0.9058:  19%|[36m█▉        [0m| 5/26 [00:10<00:39,  1.88s/it]Epoch: 5/10. Loss: 0.9058:  23%|[36m██▎       [0m| 6/26 [00:10<00:30,  1.55s/it]Epoch: 5/10. Loss: 0.8764:  23%|[36m██▎       [0m| 6/26 [00:11<00:30,  1.55s/it]Epoch: 5/10. Loss: 0.8764:  27%|[36m██▋       [0m| 7/26 [00:11<00:30,  1.60s/it]Epoch: 5/10. Loss: 0.9580:  27%|[36m██▋       [0m| 7/26 [00:12<00:30,  1.60s/it]Epoch: 5/10. Loss: 0.9580:  31%|[36m███       [0m| 8/26 [00:12<00:24,  1.39s/it]Epoch: 5/10. Loss: 0.9255:  31%|[36m███       [0m| 8/26 [00:15<00:24,  1.39s/it]Epoch: 5/10. Loss: 0.9255:  35%|[36m███▍      [0m| 9/26 [00:15<00:31,  1.87s/it]Epoch: 5/10. Loss: 0.9176:  35%|[36m███▍      [0m| 9/26 [00:17<00:31,  1.87s/it]Epoch: 5/10. Loss: 0.9176:  38%|[36m███▊      [0m| 10/26 [00:17<00:30,  1.89s/it]Epoch: 5/10. Loss: 0.9883:  38%|[36m███▊      [0m| 10/26 [00:20<00:30,  1.89s/it]Epoch: 5/10. Loss: 0.9883:  42%|[36m████▏     [0m| 11/26 [00:20<00:31,  2.09s/it]Epoch: 5/10. Loss: 0.9494:  42%|[36m████▏     [0m| 11/26 [00:21<00:31,  2.09s/it]Epoch: 5/10. Loss: 0.9494:  46%|[36m████▌     [0m| 12/26 [00:21<00:24,  1.73s/it]Epoch: 5/10. Loss: 0.9695:  46%|[36m████▌     [0m| 12/26 [00:22<00:24,  1.73s/it]Epoch: 5/10. Loss: 0.9695:  50%|[36m█████     [0m| 13/26 [00:22<00:21,  1.65s/it]Epoch: 5/10. Loss: 0.8989:  50%|[36m█████     [0m| 13/26 [00:24<00:21,  1.65s/it]Epoch: 5/10. Loss: 0.8989:  54%|[36m█████▍    [0m| 14/26 [00:24<00:20,  1.69s/it]Epoch: 5/10. Loss: 0.8456:  54%|[36m█████▍    [0m| 14/26 [00:25<00:20,  1.69s/it]Epoch: 5/10. Loss: 0.8456:  58%|[36m█████▊    [0m| 15/26 [00:25<00:15,  1.41s/it]Epoch: 5/10. Loss: 1.0191:  58%|[36m█████▊    [0m| 15/26 [00:28<00:15,  1.41s/it]Epoch: 5/10. Loss: 1.0191:  62%|[36m██████▏   [0m| 16/26 [00:28<00:18,  1.90s/it]Epoch: 5/10. Loss: 0.9128:  62%|[36m██████▏   [0m| 16/26 [00:29<00:18,  1.90s/it]Epoch: 5/10. Loss: 0.9128:  65%|[36m██████▌   [0m| 17/26 [00:29<00:15,  1.71s/it]Epoch: 5/10. Loss: 0.8796:  65%|[36m██████▌   [0m| 17/26 [00:30<00:15,  1.71s/it]Epoch: 5/10. Loss: 0.8796:  69%|[36m██████▉   [0m| 18/26 [00:30<00:12,  1.50s/it]Epoch: 5/10. Loss: 0.9443:  69%|[36m██████▉   [0m| 18/26 [00:32<00:12,  1.50s/it]Epoch: 5/10. Loss: 0.9443:  73%|[36m███████▎  [0m| 19/26 [00:32<00:12,  1.73s/it]Epoch: 5/10. Loss: 0.9780:  73%|[36m███████▎  [0m| 19/26 [00:33<00:12,  1.73s/it]Epoch: 5/10. Loss: 0.9780:  77%|[36m███████▋  [0m| 20/26 [00:33<00:08,  1.50s/it]Epoch: 5/10. Loss: 0.8801:  77%|[36m███████▋  [0m| 20/26 [00:34<00:08,  1.50s/it]Epoch: 5/10. Loss: 0.8801:  81%|[36m████████  [0m| 21/26 [00:34<00:06,  1.35s/it]Epoch: 5/10. Loss: 0.9162:  81%|[36m████████  [0m| 21/26 [00:35<00:06,  1.35s/it]Epoch: 5/10. Loss: 0.9162:  85%|[36m████████▍ [0m| 22/26 [00:35<00:05,  1.30s/it]Epoch: 5/10. Loss: 0.8466:  85%|[36m████████▍ [0m| 22/26 [00:37<00:05,  1.30s/it]Epoch: 5/10. Loss: 0.8466:  88%|[36m████████▊ [0m| 23/26 [00:37<00:03,  1.31s/it]Epoch: 5/10. Loss: 0.8702:  88%|[36m████████▊ [0m| 23/26 [00:38<00:03,  1.31s/it]Epoch: 5/10. Loss: 0.8702:  92%|[36m█████████▏[0m| 24/26 [00:38<00:02,  1.27s/it]Epoch: 5/10. Loss: 0.8774:  92%|[36m█████████▏[0m| 24/26 [00:39<00:02,  1.27s/it]Epoch: 5/10. Loss: 0.8774:  96%|[36m█████████▌[0m| 25/26 [00:39<00:01,  1.15s/it]Epoch: 5/10. Loss: 0.8144:  96%|[36m█████████▌[0m| 25/26 [00:39<00:01,  1.15s/it]Epoch: 5/10. Loss: 0.8144: 100%|[36m██████████[0m| 26/26 [00:39<00:00,  1.02it/s]Epoch: 5/10. Loss: 0.8144: 100%|[36m██████████[0m| 26/26 [00:39<00:00,  1.53s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:01<00:07,  1.17s/it] 29%|[33m██▊       [0m| 2/7 [00:02<00:06,  1.35s/it] 43%|[33m████▎     [0m| 3/7 [00:03<00:04,  1.19s/it] 57%|[33m█████▋    [0m| 4/7 [00:05<00:04,  1.48s/it] 71%|[33m███████▏  [0m| 5/7 [00:05<00:02,  1.10s/it] 86%|[33m████████▌ [0m| 6/7 [00:07<00:01,  1.13s/it]100%|[33m██████████[0m| 7/7 [00:07<00:00,  1.16it/s]100%|[33m██████████[0m| 7/7 [00:07<00:00,  1.07s/it]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 6/10. Loss: 0.9209:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 6/10. Loss: 0.9209:   4%|[36m▍         [0m| 1/26 [00:00<00:24,  1.03it/s]Epoch: 6/10. Loss: 0.8105:   4%|[36m▍         [0m| 1/26 [00:01<00:24,  1.03it/s]Epoch: 6/10. Loss: 0.8105:   8%|[36m▊         [0m| 2/26 [00:01<00:24,  1.00s/it]Epoch: 6/10. Loss: 0.9034:   8%|[36m▊         [0m| 2/26 [00:04<00:24,  1.00s/it]Epoch: 6/10. Loss: 0.9034:  12%|[36m█▏        [0m| 3/26 [00:04<00:44,  1.92s/it]Epoch: 6/10. Loss: 0.9247:  12%|[36m█▏        [0m| 3/26 [00:05<00:44,  1.92s/it]Epoch: 6/10. Loss: 0.9247:  15%|[36m█▌        [0m| 4/26 [00:05<00:33,  1.54s/it]Epoch: 6/10. Loss: 0.7581:  15%|[36m█▌        [0m| 4/26 [00:06<00:33,  1.54s/it]Epoch: 6/10. Loss: 0.7581:  19%|[36m█▉        [0m| 5/26 [00:06<00:26,  1.25s/it]Epoch: 6/10. Loss: 0.8389:  19%|[36m█▉        [0m| 5/26 [00:07<00:26,  1.25s/it]Epoch: 6/10. Loss: 0.8389:  23%|[36m██▎       [0m| 6/26 [00:07<00:21,  1.08s/it]Epoch: 6/10. Loss: 0.8816:  23%|[36m██▎       [0m| 6/26 [00:08<00:21,  1.08s/it]Epoch: 6/10. Loss: 0.8816:  27%|[36m██▋       [0m| 7/26 [00:08<00:20,  1.08s/it]Epoch: 6/10. Loss: 0.8300:  27%|[36m██▋       [0m| 7/26 [00:09<00:20,  1.08s/it]Epoch: 6/10. Loss: 0.8300:  31%|[36m███       [0m| 8/26 [00:09<00:18,  1.01s/it]Epoch: 6/10. Loss: 0.8432:  31%|[36m███       [0m| 8/26 [00:10<00:18,  1.01s/it]Epoch: 6/10. Loss: 0.8432:  35%|[36m███▍      [0m| 9/26 [00:10<00:18,  1.06s/it]Epoch: 6/10. Loss: 0.8127:  35%|[36m███▍      [0m| 9/26 [00:12<00:18,  1.06s/it]Epoch: 6/10. Loss: 0.8127:  38%|[36m███▊      [0m| 10/26 [00:12<00:22,  1.43s/it]Epoch: 6/10. Loss: 0.9666:  38%|[36m███▊      [0m| 10/26 [00:15<00:22,  1.43s/it]Epoch: 6/10. Loss: 0.9666:  42%|[36m████▏     [0m| 11/26 [00:15<00:26,  1.78s/it]Epoch: 6/10. Loss: 0.9784:  42%|[36m████▏     [0m| 11/26 [00:16<00:26,  1.78s/it]Epoch: 6/10. Loss: 0.9784:  46%|[36m████▌     [0m| 12/26 [00:16<00:22,  1.63s/it]Epoch: 6/10. Loss: 0.8233:  46%|[36m████▌     [0m| 12/26 [00:17<00:22,  1.63s/it]Epoch: 6/10. Loss: 0.8233:  50%|[36m█████     [0m| 13/26 [00:17<00:18,  1.46s/it]Epoch: 6/10. Loss: 0.8525:  50%|[36m█████     [0m| 13/26 [00:19<00:18,  1.46s/it]Epoch: 6/10. Loss: 0.8525:  54%|[36m█████▍    [0m| 14/26 [00:19<00:18,  1.55s/it]Epoch: 6/10. Loss: 0.8807:  54%|[36m█████▍    [0m| 14/26 [00:20<00:18,  1.55s/it]Epoch: 6/10. Loss: 0.8807:  58%|[36m█████▊    [0m| 15/26 [00:20<00:15,  1.38s/it]Epoch: 6/10. Loss: 0.7893:  58%|[36m█████▊    [0m| 15/26 [00:22<00:15,  1.38s/it]Epoch: 6/10. Loss: 0.7893:  62%|[36m██████▏   [0m| 16/26 [00:23<00:17,  1.73s/it]Epoch: 6/10. Loss: 0.7763:  62%|[36m██████▏   [0m| 16/26 [00:23<00:17,  1.73s/it]Epoch: 6/10. Loss: 0.7763:  65%|[36m██████▌   [0m| 17/26 [00:23<00:13,  1.48s/it]Epoch: 6/10. Loss: 0.9333:  65%|[36m██████▌   [0m| 17/26 [00:26<00:13,  1.48s/it]Epoch: 6/10. Loss: 0.9333:  69%|[36m██████▉   [0m| 18/26 [00:26<00:14,  1.84s/it]Epoch: 6/10. Loss: 0.9123:  69%|[36m██████▉   [0m| 18/26 [00:28<00:14,  1.84s/it]Epoch: 6/10. Loss: 0.9123:  73%|[36m███████▎  [0m| 19/26 [00:28<00:12,  1.83s/it]Epoch: 6/10. Loss: 0.8791:  73%|[36m███████▎  [0m| 19/26 [00:29<00:12,  1.83s/it]Epoch: 6/10. Loss: 0.8791:  77%|[36m███████▋  [0m| 20/26 [00:29<00:09,  1.57s/it]Epoch: 6/10. Loss: 0.9763:  77%|[36m███████▋  [0m| 20/26 [00:30<00:09,  1.57s/it]Epoch: 6/10. Loss: 0.9763:  81%|[36m████████  [0m| 21/26 [00:30<00:07,  1.45s/it]Epoch: 6/10. Loss: 0.7637:  81%|[36m████████  [0m| 21/26 [00:31<00:07,  1.45s/it]Epoch: 6/10. Loss: 0.7637:  85%|[36m████████▍ [0m| 22/26 [00:31<00:05,  1.29s/it]Epoch: 6/10. Loss: 0.8122:  85%|[36m████████▍ [0m| 22/26 [00:32<00:05,  1.29s/it]Epoch: 6/10. Loss: 0.8122:  88%|[36m████████▊ [0m| 23/26 [00:32<00:04,  1.35s/it]Epoch: 6/10. Loss: 0.7853:  88%|[36m████████▊ [0m| 23/26 [00:33<00:04,  1.35s/it]Epoch: 6/10. Loss: 0.7853:  92%|[36m█████████▏[0m| 24/26 [00:33<00:02,  1.23s/it]Epoch: 6/10. Loss: 0.8847:  92%|[36m█████████▏[0m| 24/26 [00:36<00:02,  1.23s/it]Epoch: 6/10. Loss: 0.8847:  96%|[36m█████████▌[0m| 25/26 [00:36<00:01,  1.64s/it]Epoch: 6/10. Loss: 0.8710:  96%|[36m█████████▌[0m| 25/26 [00:37<00:01,  1.64s/it]Epoch: 6/10. Loss: 0.8710: 100%|[36m██████████[0m| 26/26 [00:37<00:00,  1.37s/it]Epoch: 6/10. Loss: 0.8710: 100%|[36m██████████[0m| 26/26 [00:37<00:00,  1.43s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:01<00:09,  1.63s/it] 29%|[33m██▊       [0m| 2/7 [00:03<00:08,  1.66s/it] 43%|[33m████▎     [0m| 3/7 [00:03<00:04,  1.15s/it] 57%|[33m█████▋    [0m| 4/7 [00:05<00:04,  1.38s/it] 71%|[33m███████▏  [0m| 5/7 [00:06<00:02,  1.03s/it] 86%|[33m████████▌ [0m| 6/7 [00:06<00:00,  1.01it/s]100%|[33m██████████[0m| 7/7 [00:07<00:00,  1.31it/s]100%|[33m██████████[0m| 7/7 [00:07<00:00,  1.03s/it]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 7/10. Loss: 0.7632:   0%|[36m          [0m| 0/26 [00:01<?, ?it/s]Epoch: 7/10. Loss: 0.7632:   4%|[36m▍         [0m| 1/26 [00:01<00:32,  1.31s/it]Epoch: 7/10. Loss: 0.7943:   4%|[36m▍         [0m| 1/26 [00:02<00:32,  1.31s/it]Epoch: 7/10. Loss: 0.7943:   8%|[36m▊         [0m| 2/26 [00:02<00:27,  1.13s/it]Epoch: 7/10. Loss: 0.9223:   8%|[36m▊         [0m| 2/26 [00:03<00:27,  1.13s/it]Epoch: 7/10. Loss: 0.9223:  12%|[36m█▏        [0m| 3/26 [00:03<00:29,  1.30s/it]Epoch: 7/10. Loss: 0.8053:  12%|[36m█▏        [0m| 3/26 [00:04<00:29,  1.30s/it]Epoch: 7/10. Loss: 0.8053:  15%|[36m█▌        [0m| 4/26 [00:04<00:26,  1.21s/it]Epoch: 7/10. Loss: 0.7826:  15%|[36m█▌        [0m| 4/26 [00:06<00:26,  1.21s/it]Epoch: 7/10. Loss: 0.7826:  19%|[36m█▉        [0m| 5/26 [00:06<00:26,  1.26s/it]Epoch: 7/10. Loss: 0.6734:  19%|[36m█▉        [0m| 5/26 [00:09<00:26,  1.26s/it]Epoch: 7/10. Loss: 0.6734:  23%|[36m██▎       [0m| 6/26 [00:09<00:36,  1.83s/it]Epoch: 7/10. Loss: 0.8195:  23%|[36m██▎       [0m| 6/26 [00:10<00:36,  1.83s/it]Epoch: 7/10. Loss: 0.8195:  27%|[36m██▋       [0m| 7/26 [00:11<00:34,  1.83s/it]Epoch: 7/10. Loss: 0.8511:  27%|[36m██▋       [0m| 7/26 [00:14<00:34,  1.83s/it]Epoch: 7/10. Loss: 0.8511:  31%|[36m███       [0m| 8/26 [00:14<00:39,  2.22s/it]Epoch: 7/10. Loss: 0.8456:  31%|[36m███       [0m| 8/26 [00:15<00:39,  2.22s/it]Epoch: 7/10. Loss: 0.8456:  35%|[36m███▍      [0m| 9/26 [00:15<00:31,  1.85s/it]Epoch: 7/10. Loss: 0.8527:  35%|[36m███▍      [0m| 9/26 [00:16<00:31,  1.85s/it]Epoch: 7/10. Loss: 0.8527:  38%|[36m███▊      [0m| 10/26 [00:16<00:29,  1.81s/it]Epoch: 7/10. Loss: 0.7794:  38%|[36m███▊      [0m| 10/26 [00:18<00:29,  1.81s/it]Epoch: 7/10. Loss: 0.7794:  42%|[36m████▏     [0m| 11/26 [00:18<00:26,  1.77s/it]Epoch: 7/10. Loss: 0.8901:  42%|[36m████▏     [0m| 11/26 [00:19<00:26,  1.77s/it]Epoch: 7/10. Loss: 0.8901:  46%|[36m████▌     [0m| 12/26 [00:19<00:21,  1.53s/it]Epoch: 7/10. Loss: 0.7860:  46%|[36m████▌     [0m| 12/26 [00:22<00:21,  1.53s/it]Epoch: 7/10. Loss: 0.7860:  50%|[36m█████     [0m| 13/26 [00:22<00:26,  2.03s/it]Epoch: 7/10. Loss: 0.7350:  50%|[36m█████     [0m| 13/26 [00:23<00:26,  2.03s/it]Epoch: 7/10. Loss: 0.7350:  54%|[36m█████▍    [0m| 14/26 [00:23<00:21,  1.78s/it]Epoch: 7/10. Loss: 0.7568:  54%|[36m█████▍    [0m| 14/26 [00:24<00:21,  1.78s/it]Epoch: 7/10. Loss: 0.7568:  58%|[36m█████▊    [0m| 15/26 [00:24<00:17,  1.58s/it]Epoch: 7/10. Loss: 0.7795:  58%|[36m█████▊    [0m| 15/26 [00:27<00:17,  1.58s/it]Epoch: 7/10. Loss: 0.7795:  62%|[36m██████▏   [0m| 16/26 [00:27<00:19,  1.95s/it]Epoch: 7/10. Loss: 0.8381:  62%|[36m██████▏   [0m| 16/26 [00:29<00:19,  1.95s/it]Epoch: 7/10. Loss: 0.8381:  65%|[36m██████▌   [0m| 17/26 [00:29<00:16,  1.86s/it]Epoch: 7/10. Loss: 0.7984:  65%|[36m██████▌   [0m| 17/26 [00:30<00:16,  1.86s/it]Epoch: 7/10. Loss: 0.7984:  69%|[36m██████▉   [0m| 18/26 [00:30<00:12,  1.57s/it]Epoch: 7/10. Loss: 0.9137:  69%|[36m██████▉   [0m| 18/26 [00:32<00:12,  1.57s/it]Epoch: 7/10. Loss: 0.9137:  73%|[36m███████▎  [0m| 19/26 [00:32<00:12,  1.83s/it]Epoch: 7/10. Loss: 0.7630:  73%|[36m███████▎  [0m| 19/26 [00:33<00:12,  1.83s/it]Epoch: 7/10. Loss: 0.7630:  77%|[36m███████▋  [0m| 20/26 [00:33<00:09,  1.63s/it]Epoch: 7/10. Loss: 0.8615:  77%|[36m███████▋  [0m| 20/26 [00:34<00:09,  1.63s/it]Epoch: 7/10. Loss: 0.8615:  81%|[36m████████  [0m| 21/26 [00:34<00:07,  1.45s/it]Epoch: 7/10. Loss: 0.7327:  81%|[36m████████  [0m| 21/26 [00:36<00:07,  1.45s/it]Epoch: 7/10. Loss: 0.7327:  85%|[36m████████▍ [0m| 22/26 [00:36<00:05,  1.45s/it]Epoch: 7/10. Loss: 0.8916:  85%|[36m████████▍ [0m| 22/26 [00:37<00:05,  1.45s/it]Epoch: 7/10. Loss: 0.8916:  88%|[36m████████▊ [0m| 23/26 [00:37<00:03,  1.29s/it]Epoch: 7/10. Loss: 0.7385:  88%|[36m████████▊ [0m| 23/26 [00:38<00:03,  1.29s/it]Epoch: 7/10. Loss: 0.7385:  92%|[36m█████████▏[0m| 24/26 [00:38<00:02,  1.13s/it]Epoch: 7/10. Loss: 0.8242:  92%|[36m█████████▏[0m| 24/26 [00:38<00:02,  1.13s/it]Epoch: 7/10. Loss: 0.8242:  96%|[36m█████████▌[0m| 25/26 [00:39<00:01,  1.07s/it]Epoch: 7/10. Loss: 0.7851:  96%|[36m█████████▌[0m| 25/26 [00:39<00:01,  1.07s/it]Epoch: 7/10. Loss: 0.7851: 100%|[36m██████████[0m| 26/26 [00:39<00:00,  1.10it/s]Epoch: 7/10. Loss: 0.7851: 100%|[36m██████████[0m| 26/26 [00:39<00:00,  1.52s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:01<00:09,  1.56s/it] 29%|[33m██▊       [0m| 2/7 [00:02<00:07,  1.48s/it] 43%|[33m████▎     [0m| 3/7 [00:03<00:04,  1.05s/it] 57%|[33m█████▋    [0m| 4/7 [00:04<00:03,  1.19s/it] 71%|[33m███████▏  [0m| 5/7 [00:05<00:01,  1.13it/s] 86%|[33m████████▌ [0m| 6/7 [00:06<00:00,  1.17it/s]100%|[33m██████████[0m| 7/7 [00:06<00:00,  1.51it/s]100%|[33m██████████[0m| 7/7 [00:06<00:00,  1.11it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 8/10. Loss: 0.6917:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 8/10. Loss: 0.6917:   4%|[36m▍         [0m| 1/26 [00:00<00:22,  1.12it/s]Epoch: 8/10. Loss: 0.8114:   4%|[36m▍         [0m| 1/26 [00:01<00:22,  1.12it/s]Epoch: 8/10. Loss: 0.8114:   8%|[36m▊         [0m| 2/26 [00:01<00:22,  1.06it/s]Epoch: 8/10. Loss: 0.8177:   8%|[36m▊         [0m| 2/26 [00:04<00:22,  1.06it/s]Epoch: 8/10. Loss: 0.8177:  12%|[36m█▏        [0m| 3/26 [00:04<00:38,  1.69s/it]Epoch: 8/10. Loss: 0.7998:  12%|[36m█▏        [0m| 3/26 [00:05<00:38,  1.69s/it]Epoch: 8/10. Loss: 0.7998:  15%|[36m█▌        [0m| 4/26 [00:05<00:29,  1.35s/it]Epoch: 8/10. Loss: 0.8043:  15%|[36m█▌        [0m| 4/26 [00:07<00:29,  1.35s/it]Epoch: 8/10. Loss: 0.8043:  19%|[36m█▉        [0m| 5/26 [00:07<00:36,  1.72s/it]Epoch: 8/10. Loss: 0.7886:  19%|[36m█▉        [0m| 5/26 [00:08<00:36,  1.72s/it]Epoch: 8/10. Loss: 0.7886:  23%|[36m██▎       [0m| 6/26 [00:08<00:30,  1.52s/it]Epoch: 8/10. Loss: 0.8040:  23%|[36m██▎       [0m| 6/26 [00:10<00:30,  1.52s/it]Epoch: 8/10. Loss: 0.8040:  27%|[36m██▋       [0m| 7/26 [00:10<00:27,  1.46s/it]Epoch: 8/10. Loss: 0.8206:  27%|[36m██▋       [0m| 7/26 [00:10<00:27,  1.46s/it]Epoch: 8/10. Loss: 0.8206:  31%|[36m███       [0m| 8/26 [00:10<00:22,  1.26s/it]Epoch: 8/10. Loss: 0.7309:  31%|[36m███       [0m| 8/26 [00:12<00:22,  1.26s/it]Epoch: 8/10. Loss: 0.7309:  35%|[36m███▍      [0m| 9/26 [00:12<00:23,  1.36s/it]Epoch: 8/10. Loss: 0.6815:  35%|[36m███▍      [0m| 9/26 [00:15<00:23,  1.36s/it]Epoch: 8/10. Loss: 0.6815:  38%|[36m███▊      [0m| 10/26 [00:15<00:30,  1.90s/it]Epoch: 8/10. Loss: 0.8155:  38%|[36m███▊      [0m| 10/26 [00:16<00:30,  1.90s/it]Epoch: 8/10. Loss: 0.8155:  42%|[36m████▏     [0m| 11/26 [00:17<00:26,  1.74s/it]Epoch: 8/10. Loss: 0.8795:  42%|[36m████▏     [0m| 11/26 [00:17<00:26,  1.74s/it]Epoch: 8/10. Loss: 0.8795:  46%|[36m████▌     [0m| 12/26 [00:17<00:20,  1.46s/it]Epoch: 8/10. Loss: 0.7284:  46%|[36m████▌     [0m| 12/26 [00:19<00:20,  1.46s/it]Epoch: 8/10. Loss: 0.7284:  50%|[36m█████     [0m| 13/26 [00:19<00:18,  1.39s/it]Epoch: 8/10. Loss: 0.6892:  50%|[36m█████     [0m| 13/26 [00:20<00:18,  1.39s/it]Epoch: 8/10. Loss: 0.6892:  54%|[36m█████▍    [0m| 14/26 [00:20<00:15,  1.29s/it]Epoch: 8/10. Loss: 0.7181:  54%|[36m█████▍    [0m| 14/26 [00:20<00:15,  1.29s/it]Epoch: 8/10. Loss: 0.7181:  58%|[36m█████▊    [0m| 15/26 [00:20<00:12,  1.10s/it]Epoch: 8/10. Loss: 0.6896:  58%|[36m█████▊    [0m| 15/26 [00:21<00:12,  1.10s/it]Epoch: 8/10. Loss: 0.6896:  62%|[36m██████▏   [0m| 16/26 [00:21<00:10,  1.00s/it]Epoch: 8/10. Loss: 0.7913:  62%|[36m██████▏   [0m| 16/26 [00:22<00:10,  1.00s/it]Epoch: 8/10. Loss: 0.7913:  65%|[36m██████▌   [0m| 17/26 [00:22<00:09,  1.03s/it]Epoch: 8/10. Loss: 0.7267:  65%|[36m██████▌   [0m| 17/26 [00:23<00:09,  1.03s/it]Epoch: 8/10. Loss: 0.7267:  69%|[36m██████▉   [0m| 18/26 [00:23<00:07,  1.01it/s]Epoch: 8/10. Loss: 0.7211:  69%|[36m██████▉   [0m| 18/26 [00:24<00:07,  1.01it/s]Epoch: 8/10. Loss: 0.7211:  73%|[36m███████▎  [0m| 19/26 [00:24<00:07,  1.08s/it]Epoch: 8/10. Loss: 0.7994:  73%|[36m███████▎  [0m| 19/26 [00:26<00:07,  1.08s/it]Epoch: 8/10. Loss: 0.7994:  77%|[36m███████▋  [0m| 20/26 [00:26<00:06,  1.11s/it]Epoch: 8/10. Loss: 0.8042:  77%|[36m███████▋  [0m| 20/26 [00:27<00:06,  1.11s/it]Epoch: 8/10. Loss: 0.8042:  81%|[36m████████  [0m| 21/26 [00:27<00:06,  1.34s/it]Epoch: 8/10. Loss: 0.8017:  81%|[36m████████  [0m| 21/26 [00:28<00:06,  1.34s/it]Epoch: 8/10. Loss: 0.8017:  85%|[36m████████▍ [0m| 22/26 [00:28<00:04,  1.18s/it]Epoch: 8/10. Loss: 0.8326:  85%|[36m████████▍ [0m| 22/26 [00:29<00:04,  1.18s/it]Epoch: 8/10. Loss: 0.8326:  88%|[36m████████▊ [0m| 23/26 [00:29<00:03,  1.09s/it]Epoch: 8/10. Loss: 0.7753:  88%|[36m████████▊ [0m| 23/26 [00:30<00:03,  1.09s/it]Epoch: 8/10. Loss: 0.7753:  92%|[36m█████████▏[0m| 24/26 [00:30<00:02,  1.08s/it]Epoch: 8/10. Loss: 0.7482:  92%|[36m█████████▏[0m| 24/26 [00:31<00:02,  1.08s/it]Epoch: 8/10. Loss: 0.7482:  96%|[36m█████████▌[0m| 25/26 [00:31<00:01,  1.13s/it]Epoch: 8/10. Loss: 0.8205:  96%|[36m█████████▌[0m| 25/26 [00:32<00:01,  1.13s/it]Epoch: 8/10. Loss: 0.8205: 100%|[36m██████████[0m| 26/26 [00:32<00:00,  1.01it/s]Epoch: 8/10. Loss: 0.8205: 100%|[36m██████████[0m| 26/26 [00:32<00:00,  1.25s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:05,  1.07it/s] 29%|[33m██▊       [0m| 2/7 [00:03<00:09,  1.87s/it] 43%|[33m████▎     [0m| 3/7 [00:04<00:05,  1.34s/it] 57%|[33m█████▋    [0m| 4/7 [00:07<00:05,  1.96s/it] 71%|[33m███████▏  [0m| 5/7 [00:07<00:02,  1.38s/it] 86%|[33m████████▌ [0m| 6/7 [00:08<00:01,  1.19s/it]100%|[33m██████████[0m| 7/7 [00:08<00:00,  1.12it/s]100%|[33m██████████[0m| 7/7 [00:08<00:00,  1.22s/it]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 9/10. Loss: 0.7964:   0%|[36m          [0m| 0/26 [00:01<?, ?it/s]Epoch: 9/10. Loss: 0.7964:   4%|[36m▍         [0m| 1/26 [00:01<00:26,  1.07s/it]Epoch: 9/10. Loss: 0.7313:   4%|[36m▍         [0m| 1/26 [00:01<00:26,  1.07s/it]Epoch: 9/10. Loss: 0.7313:   8%|[36m▊         [0m| 2/26 [00:02<00:23,  1.01it/s]Epoch: 9/10. Loss: 0.6622:   8%|[36m▊         [0m| 2/26 [00:03<00:23,  1.01it/s]Epoch: 9/10. Loss: 0.6622:  12%|[36m█▏        [0m| 3/26 [00:03<00:23,  1.02s/it]Epoch: 9/10. Loss: 0.7186:  12%|[36m█▏        [0m| 3/26 [00:03<00:23,  1.02s/it]Epoch: 9/10. Loss: 0.7186:  15%|[36m█▌        [0m| 4/26 [00:03<00:21,  1.05it/s]Epoch: 9/10. Loss: 0.7291:  15%|[36m█▌        [0m| 4/26 [00:04<00:21,  1.05it/s]Epoch: 9/10. Loss: 0.7291:  19%|[36m█▉        [0m| 5/26 [00:04<00:19,  1.10it/s]Epoch: 9/10. Loss: 0.6705:  19%|[36m█▉        [0m| 5/26 [00:06<00:19,  1.10it/s]Epoch: 9/10. Loss: 0.6705:  23%|[36m██▎       [0m| 6/26 [00:06<00:26,  1.35s/it]Epoch: 9/10. Loss: 0.7122:  23%|[36m██▎       [0m| 6/26 [00:07<00:26,  1.35s/it]Epoch: 9/10. Loss: 0.7122:  27%|[36m██▋       [0m| 7/26 [00:07<00:22,  1.20s/it]Epoch: 9/10. Loss: 0.7319:  27%|[36m██▋       [0m| 7/26 [00:08<00:22,  1.20s/it]Epoch: 9/10. Loss: 0.7319:  31%|[36m███       [0m| 8/26 [00:08<00:19,  1.09s/it]Epoch: 9/10. Loss: 0.7856:  31%|[36m███       [0m| 8/26 [00:09<00:19,  1.09s/it]Epoch: 9/10. Loss: 0.7856:  35%|[36m███▍      [0m| 9/26 [00:09<00:18,  1.06s/it]Epoch: 9/10. Loss: 0.6692:  35%|[36m███▍      [0m| 9/26 [00:10<00:18,  1.06s/it]Epoch: 9/10. Loss: 0.6692:  38%|[36m███▊      [0m| 10/26 [00:10<00:16,  1.02s/it]Epoch: 9/10. Loss: 0.6386:  38%|[36m███▊      [0m| 10/26 [00:11<00:16,  1.02s/it]Epoch: 9/10. Loss: 0.6386:  42%|[36m████▏     [0m| 11/26 [00:11<00:15,  1.01s/it]Epoch: 9/10. Loss: 0.7712:  42%|[36m████▏     [0m| 11/26 [00:12<00:15,  1.01s/it]Epoch: 9/10. Loss: 0.7712:  46%|[36m████▌     [0m| 12/26 [00:12<00:13,  1.04it/s]Epoch: 9/10. Loss: 0.7225:  46%|[36m████▌     [0m| 12/26 [00:13<00:13,  1.04it/s]Epoch: 9/10. Loss: 0.7225:  50%|[36m█████     [0m| 13/26 [00:13<00:12,  1.02it/s]Epoch: 9/10. Loss: 0.7269:  50%|[36m█████     [0m| 13/26 [00:14<00:12,  1.02it/s]Epoch: 9/10. Loss: 0.7269:  54%|[36m█████▍    [0m| 14/26 [00:14<00:11,  1.03it/s]Epoch: 9/10. Loss: 0.7735:  54%|[36m█████▍    [0m| 14/26 [00:15<00:11,  1.03it/s]Epoch: 9/10. Loss: 0.7735:  58%|[36m█████▊    [0m| 15/26 [00:15<00:10,  1.01it/s]Epoch: 9/10. Loss: 0.8511:  58%|[36m█████▊    [0m| 15/26 [00:16<00:10,  1.01it/s]Epoch: 9/10. Loss: 0.8511:  62%|[36m██████▏   [0m| 16/26 [00:16<00:08,  1.11it/s]Epoch: 9/10. Loss: 0.8191:  62%|[36m██████▏   [0m| 16/26 [00:17<00:08,  1.11it/s]Epoch: 9/10. Loss: 0.8191:  65%|[36m██████▌   [0m| 17/26 [00:17<00:08,  1.04it/s]Epoch: 9/10. Loss: 0.8581:  65%|[36m██████▌   [0m| 17/26 [00:18<00:08,  1.04it/s]Epoch: 9/10. Loss: 0.8581:  69%|[36m██████▉   [0m| 18/26 [00:18<00:07,  1.01it/s]Epoch: 9/10. Loss: 0.7260:  69%|[36m██████▉   [0m| 18/26 [00:19<00:07,  1.01it/s]Epoch: 9/10. Loss: 0.7260:  73%|[36m███████▎  [0m| 19/26 [00:19<00:07,  1.03s/it]Epoch: 9/10. Loss: 0.6749:  73%|[36m███████▎  [0m| 19/26 [00:20<00:07,  1.03s/it]Epoch: 9/10. Loss: 0.6749:  77%|[36m███████▋  [0m| 20/26 [00:20<00:05,  1.02it/s]Epoch: 9/10. Loss: 0.7155:  77%|[36m███████▋  [0m| 20/26 [00:21<00:05,  1.02it/s]Epoch: 9/10. Loss: 0.7155:  81%|[36m████████  [0m| 21/26 [00:21<00:04,  1.05it/s]Epoch: 9/10. Loss: 0.7529:  81%|[36m████████  [0m| 21/26 [00:22<00:04,  1.05it/s]Epoch: 9/10. Loss: 0.7529:  85%|[36m████████▍ [0m| 22/26 [00:22<00:03,  1.02it/s]Epoch: 9/10. Loss: 0.7161:  85%|[36m████████▍ [0m| 22/26 [00:23<00:03,  1.02it/s]Epoch: 9/10. Loss: 0.7161:  88%|[36m████████▊ [0m| 23/26 [00:23<00:02,  1.07it/s]Epoch: 9/10. Loss: 0.6466:  88%|[36m████████▊ [0m| 23/26 [00:23<00:02,  1.07it/s]Epoch: 9/10. Loss: 0.6466:  92%|[36m█████████▏[0m| 24/26 [00:24<00:01,  1.07it/s]Epoch: 9/10. Loss: 0.7793:  92%|[36m█████████▏[0m| 24/26 [00:25<00:01,  1.07it/s]Epoch: 9/10. Loss: 0.7793:  96%|[36m█████████▌[0m| 25/26 [00:25<00:01,  1.13s/it]Epoch: 9/10. Loss: 0.7269:  96%|[36m█████████▌[0m| 25/26 [00:26<00:01,  1.13s/it]Epoch: 9/10. Loss: 0.7269: 100%|[36m██████████[0m| 26/26 [00:26<00:00,  1.08s/it]Epoch: 9/10. Loss: 0.7269: 100%|[36m██████████[0m| 26/26 [00:26<00:00,  1.02s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:05,  1.19it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:06,  1.24s/it] 43%|[33m████▎     [0m| 3/7 [00:02<00:03,  1.09it/s] 57%|[33m█████▋    [0m| 4/7 [00:04<00:03,  1.09s/it] 71%|[33m███████▏  [0m| 5/7 [00:04<00:01,  1.20it/s] 86%|[33m████████▌ [0m| 6/7 [00:06<00:01,  1.20s/it]100%|[33m██████████[0m| 7/7 [00:06<00:00,  1.11it/s]100%|[33m██████████[0m| 7/7 [00:06<00:00,  1.03it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 0/10. Loss: 1.1689:   0%|[36m          [0m| 0/26 [00:01<?, ?it/s]Epoch: 0/10. Loss: 1.1689:   4%|[36m▍         [0m| 1/26 [00:01<00:45,  1.83s/it]Epoch: 0/10. Loss: 5.0728:   4%|[36m▍         [0m| 1/26 [00:02<00:45,  1.83s/it]Epoch: 0/10. Loss: 5.0728:   8%|[36m▊         [0m| 2/26 [00:02<00:29,  1.24s/it]Epoch: 0/10. Loss: 1.0240:   8%|[36m▊         [0m| 2/26 [00:03<00:29,  1.24s/it]Epoch: 0/10. Loss: 1.0240:  12%|[36m█▏        [0m| 3/26 [00:03<00:25,  1.11s/it]Epoch: 0/10. Loss: 2.3856:  12%|[36m█▏        [0m| 3/26 [00:04<00:25,  1.11s/it]Epoch: 0/10. Loss: 2.3856:  15%|[36m█▌        [0m| 4/26 [00:04<00:22,  1.03s/it]Epoch: 0/10. Loss: 1.0464:  15%|[36m█▌        [0m| 4/26 [00:05<00:22,  1.03s/it]Epoch: 0/10. Loss: 1.0464:  19%|[36m█▉        [0m| 5/26 [00:05<00:21,  1.04s/it]Epoch: 0/10. Loss: 1.0243:  19%|[36m█▉        [0m| 5/26 [00:06<00:21,  1.04s/it]Epoch: 0/10. Loss: 1.0243:  23%|[36m██▎       [0m| 6/26 [00:06<00:20,  1.02s/it]Epoch: 0/10. Loss: 1.0831:  23%|[36m██▎       [0m| 6/26 [00:07<00:20,  1.02s/it]Epoch: 0/10. Loss: 1.0831:  27%|[36m██▋       [0m| 7/26 [00:07<00:18,  1.02it/s]Epoch: 0/10. Loss: 0.9937:  27%|[36m██▋       [0m| 7/26 [00:08<00:18,  1.02it/s]Epoch: 0/10. Loss: 0.9937:  31%|[36m███       [0m| 8/26 [00:08<00:17,  1.05it/s]Epoch: 0/10. Loss: 1.1804:  31%|[36m███       [0m| 8/26 [00:09<00:17,  1.05it/s]Epoch: 0/10. Loss: 1.1804:  35%|[36m███▍      [0m| 9/26 [00:09<00:16,  1.00it/s]Epoch: 0/10. Loss: 1.0793:  35%|[36m███▍      [0m| 9/26 [00:10<00:16,  1.00it/s]Epoch: 0/10. Loss: 1.0793:  38%|[36m███▊      [0m| 10/26 [00:10<00:15,  1.05it/s]Epoch: 0/10. Loss: 1.0484:  38%|[36m███▊      [0m| 10/26 [00:11<00:15,  1.05it/s]Epoch: 0/10. Loss: 1.0484:  42%|[36m████▏     [0m| 11/26 [00:11<00:14,  1.07it/s]Epoch: 0/10. Loss: 0.9905:  42%|[36m████▏     [0m| 11/26 [00:12<00:14,  1.07it/s]Epoch: 0/10. Loss: 0.9905:  46%|[36m████▌     [0m| 12/26 [00:12<00:13,  1.00it/s]Epoch: 0/10. Loss: 1.0211:  46%|[36m████▌     [0m| 12/26 [00:13<00:13,  1.00it/s]Epoch: 0/10. Loss: 1.0211:  50%|[36m█████     [0m| 13/26 [00:13<00:14,  1.14s/it]Epoch: 0/10. Loss: 0.9956:  50%|[36m█████     [0m| 13/26 [00:15<00:14,  1.14s/it]Epoch: 0/10. Loss: 0.9956:  54%|[36m█████▍    [0m| 14/26 [00:15<00:14,  1.17s/it]Epoch: 0/10. Loss: 0.9335:  54%|[36m█████▍    [0m| 14/26 [00:16<00:14,  1.17s/it]Epoch: 0/10. Loss: 0.9335:  58%|[36m█████▊    [0m| 15/26 [00:16<00:12,  1.14s/it]Epoch: 0/10. Loss: 0.9965:  58%|[36m█████▊    [0m| 15/26 [00:16<00:12,  1.14s/it]Epoch: 0/10. Loss: 0.9965:  62%|[36m██████▏   [0m| 16/26 [00:17<00:10,  1.07s/it]Epoch: 0/10. Loss: 1.0703:  62%|[36m██████▏   [0m| 16/26 [00:17<00:10,  1.07s/it]Epoch: 0/10. Loss: 1.0703:  65%|[36m██████▌   [0m| 17/26 [00:17<00:09,  1.03s/it]Epoch: 0/10. Loss: 1.0184:  65%|[36m██████▌   [0m| 17/26 [00:20<00:09,  1.03s/it]Epoch: 0/10. Loss: 1.0184:  69%|[36m██████▉   [0m| 18/26 [00:20<00:10,  1.36s/it]Epoch: 0/10. Loss: 0.9343:  69%|[36m██████▉   [0m| 18/26 [00:21<00:10,  1.36s/it]Epoch: 0/10. Loss: 0.9343:  73%|[36m███████▎  [0m| 19/26 [00:21<00:08,  1.25s/it]Epoch: 0/10. Loss: 0.9480:  73%|[36m███████▎  [0m| 19/26 [00:22<00:08,  1.25s/it]Epoch: 0/10. Loss: 0.9480:  77%|[36m███████▋  [0m| 20/26 [00:22<00:07,  1.25s/it]Epoch: 0/10. Loss: 1.0441:  77%|[36m███████▋  [0m| 20/26 [00:23<00:07,  1.25s/it]Epoch: 0/10. Loss: 1.0441:  81%|[36m████████  [0m| 21/26 [00:23<00:06,  1.20s/it]Epoch: 0/10. Loss: 1.1986:  81%|[36m████████  [0m| 21/26 [00:24<00:06,  1.20s/it]Epoch: 0/10. Loss: 1.1986:  85%|[36m████████▍ [0m| 22/26 [00:24<00:04,  1.13s/it]Epoch: 0/10. Loss: 1.0093:  85%|[36m████████▍ [0m| 22/26 [00:25<00:04,  1.13s/it]Epoch: 0/10. Loss: 1.0093:  88%|[36m████████▊ [0m| 23/26 [00:25<00:03,  1.11s/it]Epoch: 0/10. Loss: 1.0728:  88%|[36m████████▊ [0m| 23/26 [00:26<00:03,  1.11s/it]Epoch: 0/10. Loss: 1.0728:  92%|[36m█████████▏[0m| 24/26 [00:26<00:02,  1.05s/it]Epoch: 0/10. Loss: 1.2582:  92%|[36m█████████▏[0m| 24/26 [00:27<00:02,  1.05s/it]Epoch: 0/10. Loss: 1.2582:  96%|[36m█████████▌[0m| 25/26 [00:27<00:01,  1.04s/it]Epoch: 0/10. Loss: 1.2412:  96%|[36m█████████▌[0m| 25/26 [00:28<00:01,  1.04s/it]Epoch: 0/10. Loss: 1.2412: 100%|[36m██████████[0m| 26/26 [00:28<00:00,  1.01it/s]Epoch: 0/10. Loss: 1.2412: 100%|[36m██████████[0m| 26/26 [00:28<00:00,  1.09s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:05,  1.13it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:06,  1.23s/it] 43%|[33m████▎     [0m| 3/7 [00:02<00:03,  1.07it/s] 57%|[33m█████▋    [0m| 4/7 [00:04<00:03,  1.13s/it] 71%|[33m███████▏  [0m| 5/7 [00:04<00:01,  1.14it/s] 86%|[33m████████▌ [0m| 6/7 [00:05<00:00,  1.15it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.44it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.17it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 1/10. Loss: 1.0240:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 1/10. Loss: 1.0240:   4%|[36m▍         [0m| 1/26 [00:00<00:24,  1.02it/s]Epoch: 1/10. Loss: 1.1162:   4%|[36m▍         [0m| 1/26 [00:04<00:24,  1.02it/s]Epoch: 1/10. Loss: 1.1162:   8%|[36m▊         [0m| 2/26 [00:04<00:59,  2.49s/it]Epoch: 1/10. Loss: 1.1999:   8%|[36m▊         [0m| 2/26 [00:06<00:59,  2.49s/it]Epoch: 1/10. Loss: 1.1999:  12%|[36m█▏        [0m| 3/26 [00:06<00:55,  2.40s/it]Epoch: 1/10. Loss: 0.9712:  12%|[36m█▏        [0m| 3/26 [00:07<00:55,  2.40s/it]Epoch: 1/10. Loss: 0.9712:  15%|[36m█▌        [0m| 4/26 [00:07<00:40,  1.85s/it]Epoch: 1/10. Loss: 0.9987:  15%|[36m█▌        [0m| 4/26 [00:08<00:40,  1.85s/it]Epoch: 1/10. Loss: 0.9987:  19%|[36m█▉        [0m| 5/26 [00:08<00:33,  1.61s/it]Epoch: 1/10. Loss: 1.0444:  19%|[36m█▉        [0m| 5/26 [00:10<00:33,  1.61s/it]Epoch: 1/10. Loss: 1.0444:  23%|[36m██▎       [0m| 6/26 [00:10<00:28,  1.43s/it]Epoch: 1/10. Loss: 1.0038:  23%|[36m██▎       [0m| 6/26 [00:10<00:28,  1.43s/it]Epoch: 1/10. Loss: 1.0038:  27%|[36m██▋       [0m| 7/26 [00:10<00:23,  1.23s/it]Epoch: 1/10. Loss: 1.0234:  27%|[36m██▋       [0m| 7/26 [00:12<00:23,  1.23s/it]Epoch: 1/10. Loss: 1.0234:  31%|[36m███       [0m| 8/26 [00:12<00:23,  1.30s/it]Epoch: 1/10. Loss: 1.0415:  31%|[36m███       [0m| 8/26 [00:13<00:23,  1.30s/it]Epoch: 1/10. Loss: 1.0415:  35%|[36m███▍      [0m| 9/26 [00:13<00:20,  1.22s/it]Epoch: 1/10. Loss: 1.1666:  35%|[36m███▍      [0m| 9/26 [00:14<00:20,  1.22s/it]Epoch: 1/10. Loss: 1.1666:  38%|[36m███▊      [0m| 10/26 [00:14<00:18,  1.13s/it]Epoch: 1/10. Loss: 0.9778:  38%|[36m███▊      [0m| 10/26 [00:17<00:18,  1.13s/it]Epoch: 1/10. Loss: 0.9778:  42%|[36m████▏     [0m| 11/26 [00:17<00:27,  1.85s/it]Epoch: 1/10. Loss: 1.0308:  42%|[36m████▏     [0m| 11/26 [00:19<00:27,  1.85s/it]Epoch: 1/10. Loss: 1.0308:  46%|[36m████▌     [0m| 12/26 [00:19<00:25,  1.85s/it]Epoch: 1/10. Loss: 0.9968:  46%|[36m████▌     [0m| 12/26 [00:20<00:25,  1.85s/it]Epoch: 1/10. Loss: 0.9968:  50%|[36m█████     [0m| 13/26 [00:20<00:20,  1.61s/it]Epoch: 1/10. Loss: 1.0048:  50%|[36m█████     [0m| 13/26 [00:21<00:20,  1.61s/it]Epoch: 1/10. Loss: 1.0048:  54%|[36m█████▍    [0m| 14/26 [00:21<00:17,  1.42s/it]Epoch: 1/10. Loss: 0.9857:  54%|[36m█████▍    [0m| 14/26 [00:22<00:17,  1.42s/it]Epoch: 1/10. Loss: 0.9857:  58%|[36m█████▊    [0m| 15/26 [00:22<00:13,  1.25s/it]Epoch: 1/10. Loss: 0.9981:  58%|[36m█████▊    [0m| 15/26 [00:23<00:13,  1.25s/it]Epoch: 1/10. Loss: 0.9981:  62%|[36m██████▏   [0m| 16/26 [00:23<00:11,  1.13s/it]Epoch: 1/10. Loss: 0.9429:  62%|[36m██████▏   [0m| 16/26 [00:24<00:11,  1.13s/it]Epoch: 1/10. Loss: 0.9429:  65%|[36m██████▌   [0m| 17/26 [00:24<00:09,  1.04s/it]Epoch: 1/10. Loss: 0.9660:  65%|[36m██████▌   [0m| 17/26 [00:25<00:09,  1.04s/it]Epoch: 1/10. Loss: 0.9660:  69%|[36m██████▉   [0m| 18/26 [00:25<00:08,  1.08s/it]Epoch: 1/10. Loss: 1.1811:  69%|[36m██████▉   [0m| 18/26 [00:26<00:08,  1.08s/it]Epoch: 1/10. Loss: 1.1811:  73%|[36m███████▎  [0m| 19/26 [00:26<00:07,  1.01s/it]Epoch: 1/10. Loss: 1.1987:  73%|[36m███████▎  [0m| 19/26 [00:27<00:07,  1.01s/it]Epoch: 1/10. Loss: 1.1987:  77%|[36m███████▋  [0m| 20/26 [00:27<00:06,  1.03s/it]Epoch: 1/10. Loss: 1.0044:  77%|[36m███████▋  [0m| 20/26 [00:28<00:06,  1.03s/it]Epoch: 1/10. Loss: 1.0044:  81%|[36m████████  [0m| 21/26 [00:28<00:04,  1.03it/s]Epoch: 1/10. Loss: 0.9828:  81%|[36m████████  [0m| 21/26 [00:29<00:04,  1.03it/s]Epoch: 1/10. Loss: 0.9828:  85%|[36m████████▍ [0m| 22/26 [00:29<00:03,  1.06it/s]Epoch: 1/10. Loss: 1.0287:  85%|[36m████████▍ [0m| 22/26 [00:30<00:03,  1.06it/s]Epoch: 1/10. Loss: 1.0287:  88%|[36m████████▊ [0m| 23/26 [00:30<00:03,  1.17s/it]Epoch: 1/10. Loss: 1.1133:  88%|[36m████████▊ [0m| 23/26 [00:31<00:03,  1.17s/it]Epoch: 1/10. Loss: 1.1133:  92%|[36m█████████▏[0m| 24/26 [00:31<00:02,  1.08s/it]Epoch: 1/10. Loss: 1.1088:  92%|[36m█████████▏[0m| 24/26 [00:33<00:02,  1.08s/it]Epoch: 1/10. Loss: 1.1088:  96%|[36m█████████▌[0m| 25/26 [00:33<00:01,  1.27s/it]Epoch: 1/10. Loss: 1.0237:  96%|[36m█████████▌[0m| 25/26 [00:35<00:01,  1.27s/it]Epoch: 1/10. Loss: 1.0237: 100%|[36m██████████[0m| 26/26 [00:35<00:00,  1.56s/it]Epoch: 1/10. Loss: 1.0237: 100%|[36m██████████[0m| 26/26 [00:35<00:00,  1.37s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:05,  1.01it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:07,  1.45s/it] 43%|[33m████▎     [0m| 3/7 [00:03<00:04,  1.05s/it] 57%|[33m█████▋    [0m| 4/7 [00:05<00:04,  1.34s/it] 71%|[33m███████▏  [0m| 5/7 [00:05<00:02,  1.01s/it] 86%|[33m████████▌ [0m| 6/7 [00:06<00:00,  1.02it/s]100%|[33m██████████[0m| 7/7 [00:06<00:00,  1.32it/s]100%|[33m██████████[0m| 7/7 [00:06<00:00,  1.03it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 2/10. Loss: 1.0220:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 2/10. Loss: 1.0220:   4%|[36m▍         [0m| 1/26 [00:00<00:24,  1.01it/s]Epoch: 2/10. Loss: 1.0672:   4%|[36m▍         [0m| 1/26 [00:02<00:24,  1.01it/s]Epoch: 2/10. Loss: 1.0672:   8%|[36m▊         [0m| 2/26 [00:02<00:26,  1.12s/it]Epoch: 2/10. Loss: 0.9995:   8%|[36m▊         [0m| 2/26 [00:03<00:26,  1.12s/it]Epoch: 2/10. Loss: 0.9995:  12%|[36m█▏        [0m| 3/26 [00:03<00:25,  1.09s/it]Epoch: 2/10. Loss: 0.9538:  12%|[36m█▏        [0m| 3/26 [00:04<00:25,  1.09s/it]Epoch: 2/10. Loss: 0.9538:  15%|[36m█▌        [0m| 4/26 [00:04<00:22,  1.02s/it]Epoch: 2/10. Loss: 1.0137:  15%|[36m█▌        [0m| 4/26 [00:05<00:22,  1.02s/it]Epoch: 2/10. Loss: 1.0137:  19%|[36m█▉        [0m| 5/26 [00:05<00:20,  1.02it/s]Epoch: 2/10. Loss: 0.9683:  19%|[36m█▉        [0m| 5/26 [00:05<00:20,  1.02it/s]Epoch: 2/10. Loss: 0.9683:  23%|[36m██▎       [0m| 6/26 [00:05<00:18,  1.09it/s]Epoch: 2/10. Loss: 1.0270:  23%|[36m██▎       [0m| 6/26 [00:06<00:18,  1.09it/s]Epoch: 2/10. Loss: 1.0270:  27%|[36m██▋       [0m| 7/26 [00:06<00:17,  1.12it/s]Epoch: 2/10. Loss: 1.0546:  27%|[36m██▋       [0m| 7/26 [00:07<00:17,  1.12it/s]Epoch: 2/10. Loss: 1.0546:  31%|[36m███       [0m| 8/26 [00:07<00:16,  1.06it/s]Epoch: 2/10. Loss: 0.9188:  31%|[36m███       [0m| 8/26 [00:08<00:16,  1.06it/s]Epoch: 2/10. Loss: 0.9188:  35%|[36m███▍      [0m| 9/26 [00:08<00:15,  1.07it/s]Epoch: 2/10. Loss: 1.0096:  35%|[36m███▍      [0m| 9/26 [00:09<00:15,  1.07it/s]Epoch: 2/10. Loss: 1.0096:  38%|[36m███▊      [0m| 10/26 [00:09<00:16,  1.05s/it]Epoch: 2/10. Loss: 1.0199:  38%|[36m███▊      [0m| 10/26 [00:10<00:16,  1.05s/it]Epoch: 2/10. Loss: 1.0199:  42%|[36m████▏     [0m| 11/26 [00:10<00:14,  1.04it/s]Epoch: 2/10. Loss: 0.9511:  42%|[36m████▏     [0m| 11/26 [00:11<00:14,  1.04it/s]Epoch: 2/10. Loss: 0.9511:  46%|[36m████▌     [0m| 12/26 [00:11<00:12,  1.11it/s]Epoch: 2/10. Loss: 0.9861:  46%|[36m████▌     [0m| 12/26 [00:12<00:12,  1.11it/s]Epoch: 2/10. Loss: 0.9861:  50%|[36m█████     [0m| 13/26 [00:12<00:12,  1.04it/s]Epoch: 2/10. Loss: 1.0342:  50%|[36m█████     [0m| 13/26 [00:14<00:12,  1.04it/s]Epoch: 2/10. Loss: 1.0342:  54%|[36m█████▍    [0m| 14/26 [00:14<00:13,  1.14s/it]Epoch: 2/10. Loss: 0.9595:  54%|[36m█████▍    [0m| 14/26 [00:15<00:13,  1.14s/it]Epoch: 2/10. Loss: 0.9595:  58%|[36m█████▊    [0m| 15/26 [00:15<00:12,  1.14s/it]Epoch: 2/10. Loss: 0.9856:  58%|[36m█████▊    [0m| 15/26 [00:16<00:12,  1.14s/it]Epoch: 2/10. Loss: 0.9856:  62%|[36m██████▏   [0m| 16/26 [00:16<00:10,  1.08s/it]Epoch: 2/10. Loss: 0.9507:  62%|[36m██████▏   [0m| 16/26 [00:17<00:10,  1.08s/it]Epoch: 2/10. Loss: 0.9507:  65%|[36m██████▌   [0m| 17/26 [00:17<00:09,  1.02s/it]Epoch: 2/10. Loss: 1.0419:  65%|[36m██████▌   [0m| 17/26 [00:18<00:09,  1.02s/it]Epoch: 2/10. Loss: 1.0419:  69%|[36m██████▉   [0m| 18/26 [00:18<00:07,  1.00it/s]Epoch: 2/10. Loss: 0.9173:  69%|[36m██████▉   [0m| 18/26 [00:19<00:07,  1.00it/s]Epoch: 2/10. Loss: 0.9173:  73%|[36m███████▎  [0m| 19/26 [00:19<00:07,  1.04s/it]Epoch: 2/10. Loss: 0.9710:  73%|[36m███████▎  [0m| 19/26 [00:20<00:07,  1.04s/it]Epoch: 2/10. Loss: 0.9710:  77%|[36m███████▋  [0m| 20/26 [00:20<00:05,  1.03it/s]Epoch: 2/10. Loss: 1.3292:  77%|[36m███████▋  [0m| 20/26 [00:21<00:05,  1.03it/s]Epoch: 2/10. Loss: 1.3292:  81%|[36m████████  [0m| 21/26 [00:21<00:04,  1.02it/s]Epoch: 2/10. Loss: 1.0172:  81%|[36m████████  [0m| 21/26 [00:22<00:04,  1.02it/s]Epoch: 2/10. Loss: 1.0172:  85%|[36m████████▍ [0m| 22/26 [00:22<00:04,  1.01s/it]Epoch: 2/10. Loss: 0.9535:  85%|[36m████████▍ [0m| 22/26 [00:23<00:04,  1.01s/it]Epoch: 2/10. Loss: 0.9535:  88%|[36m████████▊ [0m| 23/26 [00:23<00:03,  1.00s/it]Epoch: 2/10. Loss: 0.9547:  88%|[36m████████▊ [0m| 23/26 [00:23<00:03,  1.00s/it]Epoch: 2/10. Loss: 0.9547:  92%|[36m█████████▏[0m| 24/26 [00:23<00:01,  1.05it/s]Epoch: 2/10. Loss: 0.9727:  92%|[36m█████████▏[0m| 24/26 [00:24<00:01,  1.05it/s]Epoch: 2/10. Loss: 0.9727:  96%|[36m█████████▌[0m| 25/26 [00:24<00:00,  1.06it/s]Epoch: 2/10. Loss: 0.9017:  96%|[36m█████████▌[0m| 25/26 [00:25<00:00,  1.06it/s]Epoch: 2/10. Loss: 0.9017: 100%|[36m██████████[0m| 26/26 [00:25<00:00,  1.13it/s]Epoch: 2/10. Loss: 0.9017: 100%|[36m██████████[0m| 26/26 [00:25<00:00,  1.01it/s]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:01<00:11,  1.85s/it] 29%|[33m██▊       [0m| 2/7 [00:03<00:08,  1.62s/it] 43%|[33m████▎     [0m| 3/7 [00:03<00:04,  1.14s/it] 57%|[33m█████▋    [0m| 4/7 [00:05<00:03,  1.26s/it] 71%|[33m███████▏  [0m| 5/7 [00:05<00:01,  1.04it/s] 86%|[33m████████▌ [0m| 6/7 [00:06<00:00,  1.08it/s]100%|[33m██████████[0m| 7/7 [00:06<00:00,  1.38it/s]100%|[33m██████████[0m| 7/7 [00:06<00:00,  1.01it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 3/10. Loss: 1.0510:   0%|[36m          [0m| 0/26 [00:02<?, ?it/s]Epoch: 3/10. Loss: 1.0510:   4%|[36m▍         [0m| 1/26 [00:02<00:57,  2.30s/it]Epoch: 3/10. Loss: 0.9340:   4%|[36m▍         [0m| 1/26 [00:03<00:57,  2.30s/it]Epoch: 3/10. Loss: 0.9340:   8%|[36m▊         [0m| 2/26 [00:03<00:37,  1.57s/it]Epoch: 3/10. Loss: 0.8986:   8%|[36m▊         [0m| 2/26 [00:04<00:37,  1.57s/it]Epoch: 3/10. Loss: 0.8986:  12%|[36m█▏        [0m| 3/26 [00:04<00:32,  1.40s/it]Epoch: 3/10. Loss: 0.9271:  12%|[36m█▏        [0m| 3/26 [00:05<00:32,  1.40s/it]Epoch: 3/10. Loss: 0.9271:  15%|[36m█▌        [0m| 4/26 [00:05<00:26,  1.21s/it]Epoch: 3/10. Loss: 0.9366:  15%|[36m█▌        [0m| 4/26 [00:06<00:26,  1.21s/it]Epoch: 3/10. Loss: 0.9366:  19%|[36m█▉        [0m| 5/26 [00:06<00:23,  1.10s/it]Epoch: 3/10. Loss: 1.1072:  19%|[36m█▉        [0m| 5/26 [00:07<00:23,  1.10s/it]Epoch: 3/10. Loss: 1.1072:  23%|[36m██▎       [0m| 6/26 [00:07<00:21,  1.05s/it]Epoch: 3/10. Loss: 0.9142:  23%|[36m██▎       [0m| 6/26 [00:09<00:21,  1.05s/it]Epoch: 3/10. Loss: 0.9142:  27%|[36m██▋       [0m| 7/26 [00:09<00:25,  1.35s/it]Epoch: 3/10. Loss: 0.9749:  27%|[36m██▋       [0m| 7/26 [00:10<00:25,  1.35s/it]Epoch: 3/10. Loss: 0.9749:  31%|[36m███       [0m| 8/26 [00:10<00:22,  1.23s/it]Epoch: 3/10. Loss: 1.0794:  31%|[36m███       [0m| 8/26 [00:11<00:22,  1.23s/it]Epoch: 3/10. Loss: 1.0794:  35%|[36m███▍      [0m| 9/26 [00:11<00:22,  1.31s/it]Epoch: 3/10. Loss: 0.8948:  35%|[36m███▍      [0m| 9/26 [00:12<00:22,  1.31s/it]Epoch: 3/10. Loss: 0.8948:  38%|[36m███▊      [0m| 10/26 [00:12<00:18,  1.16s/it]Epoch: 3/10. Loss: 0.9268:  38%|[36m███▊      [0m| 10/26 [00:13<00:18,  1.16s/it]Epoch: 3/10. Loss: 0.9268:  42%|[36m████▏     [0m| 11/26 [00:13<00:15,  1.07s/it]Epoch: 3/10. Loss: 0.9783:  42%|[36m████▏     [0m| 11/26 [00:14<00:15,  1.07s/it]Epoch: 3/10. Loss: 0.9783:  46%|[36m████▌     [0m| 12/26 [00:14<00:15,  1.07s/it]Epoch: 3/10. Loss: 1.0033:  46%|[36m████▌     [0m| 12/26 [00:15<00:15,  1.07s/it]Epoch: 3/10. Loss: 1.0033:  50%|[36m█████     [0m| 13/26 [00:15<00:13,  1.01s/it]Epoch: 3/10. Loss: 0.9889:  50%|[36m█████     [0m| 13/26 [00:16<00:13,  1.01s/it]Epoch: 3/10. Loss: 0.9889:  54%|[36m█████▍    [0m| 14/26 [00:16<00:13,  1.08s/it]Epoch: 3/10. Loss: 0.9171:  54%|[36m█████▍    [0m| 14/26 [00:17<00:13,  1.08s/it]Epoch: 3/10. Loss: 0.9171:  58%|[36m█████▊    [0m| 15/26 [00:17<00:11,  1.01s/it]Epoch: 3/10. Loss: 0.9611:  58%|[36m█████▊    [0m| 15/26 [00:18<00:11,  1.01s/it]Epoch: 3/10. Loss: 0.9611:  62%|[36m██████▏   [0m| 16/26 [00:18<00:09,  1.04it/s]Epoch: 3/10. Loss: 0.9578:  62%|[36m██████▏   [0m| 16/26 [00:19<00:09,  1.04it/s]Epoch: 3/10. Loss: 0.9578:  65%|[36m██████▌   [0m| 17/26 [00:19<00:08,  1.10it/s]Epoch: 3/10. Loss: 0.9549:  65%|[36m██████▌   [0m| 17/26 [00:20<00:08,  1.10it/s]Epoch: 3/10. Loss: 0.9549:  69%|[36m██████▉   [0m| 18/26 [00:20<00:07,  1.04it/s]Epoch: 3/10. Loss: 1.0427:  69%|[36m██████▉   [0m| 18/26 [00:21<00:07,  1.04it/s]Epoch: 3/10. Loss: 1.0427:  73%|[36m███████▎  [0m| 19/26 [00:21<00:06,  1.07it/s]Epoch: 3/10. Loss: 0.9510:  73%|[36m███████▎  [0m| 19/26 [00:22<00:06,  1.07it/s]Epoch: 3/10. Loss: 0.9510:  77%|[36m███████▋  [0m| 20/26 [00:22<00:06,  1.01s/it]Epoch: 3/10. Loss: 0.8960:  77%|[36m███████▋  [0m| 20/26 [00:23<00:06,  1.01s/it]Epoch: 3/10. Loss: 0.8960:  81%|[36m████████  [0m| 21/26 [00:23<00:05,  1.01s/it]Epoch: 3/10. Loss: 0.9654:  81%|[36m████████  [0m| 21/26 [00:24<00:05,  1.01s/it]Epoch: 3/10. Loss: 0.9654:  85%|[36m████████▍ [0m| 22/26 [00:24<00:03,  1.03it/s]Epoch: 3/10. Loss: 1.0973:  85%|[36m████████▍ [0m| 22/26 [00:25<00:03,  1.03it/s]Epoch: 3/10. Loss: 1.0973:  88%|[36m████████▊ [0m| 23/26 [00:25<00:02,  1.02it/s]Epoch: 3/10. Loss: 0.9963:  88%|[36m████████▊ [0m| 23/26 [00:25<00:02,  1.02it/s]Epoch: 3/10. Loss: 0.9963:  92%|[36m█████████▏[0m| 24/26 [00:25<00:01,  1.08it/s]Epoch: 3/10. Loss: 0.9724:  92%|[36m█████████▏[0m| 24/26 [00:26<00:01,  1.08it/s]Epoch: 3/10. Loss: 0.9724:  96%|[36m█████████▌[0m| 25/26 [00:26<00:00,  1.09it/s]Epoch: 3/10. Loss: 1.0391:  96%|[36m█████████▌[0m| 25/26 [00:27<00:00,  1.09it/s]Epoch: 3/10. Loss: 1.0391: 100%|[36m██████████[0m| 26/26 [00:27<00:00,  1.17it/s]Epoch: 3/10. Loss: 1.0391: 100%|[36m██████████[0m| 26/26 [00:27<00:00,  1.06s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:05,  1.15it/s] 29%|[33m██▊       [0m| 2/7 [00:04<00:12,  2.51s/it] 43%|[33m████▎     [0m| 3/7 [00:05<00:07,  1.83s/it] 57%|[33m█████▋    [0m| 4/7 [00:07<00:05,  1.99s/it] 71%|[33m███████▏  [0m| 5/7 [00:08<00:02,  1.43s/it] 86%|[33m████████▌ [0m| 6/7 [00:09<00:01,  1.25s/it]100%|[33m██████████[0m| 7/7 [00:09<00:00,  1.06it/s]100%|[33m██████████[0m| 7/7 [00:09<00:00,  1.35s/it]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 4/10. Loss: 1.0074:   0%|[36m          [0m| 0/26 [00:02<?, ?it/s]Epoch: 4/10. Loss: 1.0074:   4%|[36m▍         [0m| 1/26 [00:02<01:01,  2.44s/it]Epoch: 4/10. Loss: 0.9790:   4%|[36m▍         [0m| 1/26 [00:03<01:01,  2.44s/it]Epoch: 4/10. Loss: 0.9790:   8%|[36m▊         [0m| 2/26 [00:03<00:40,  1.69s/it]Epoch: 4/10. Loss: 1.0515:   8%|[36m▊         [0m| 2/26 [00:04<00:40,  1.69s/it]Epoch: 4/10. Loss: 1.0515:  12%|[36m█▏        [0m| 3/26 [00:04<00:32,  1.42s/it]Epoch: 4/10. Loss: 0.9332:  12%|[36m█▏        [0m| 3/26 [00:05<00:32,  1.42s/it]Epoch: 4/10. Loss: 0.9332:  15%|[36m█▌        [0m| 4/26 [00:05<00:28,  1.28s/it]Epoch: 4/10. Loss: 0.9450:  15%|[36m█▌        [0m| 4/26 [00:06<00:28,  1.28s/it]Epoch: 4/10. Loss: 0.9450:  19%|[36m█▉        [0m| 5/26 [00:06<00:25,  1.23s/it]Epoch: 4/10. Loss: 1.0002:  19%|[36m█▉        [0m| 5/26 [00:08<00:25,  1.23s/it]Epoch: 4/10. Loss: 1.0002:  23%|[36m██▎       [0m| 6/26 [00:08<00:25,  1.26s/it]Epoch: 4/10. Loss: 0.9960:  23%|[36m██▎       [0m| 6/26 [00:09<00:25,  1.26s/it]Epoch: 4/10. Loss: 0.9960:  27%|[36m██▋       [0m| 7/26 [00:09<00:21,  1.13s/it]Epoch: 4/10. Loss: 0.8956:  27%|[36m██▋       [0m| 7/26 [00:09<00:21,  1.13s/it]Epoch: 4/10. Loss: 0.8956:  31%|[36m███       [0m| 8/26 [00:09<00:19,  1.06s/it]Epoch: 4/10. Loss: 1.0421:  31%|[36m███       [0m| 8/26 [00:10<00:19,  1.06s/it]Epoch: 4/10. Loss: 1.0421:  35%|[36m███▍      [0m| 9/26 [00:11<00:17,  1.05s/it]Epoch: 4/10. Loss: 0.9431:  35%|[36m███▍      [0m| 9/26 [00:12<00:17,  1.05s/it]Epoch: 4/10. Loss: 0.9431:  38%|[36m███▊      [0m| 10/26 [00:12<00:16,  1.05s/it]Epoch: 4/10. Loss: 0.8832:  38%|[36m███▊      [0m| 10/26 [00:12<00:16,  1.05s/it]Epoch: 4/10. Loss: 0.8832:  42%|[36m████▏     [0m| 11/26 [00:12<00:14,  1.00it/s]Epoch: 4/10. Loss: 1.0562:  42%|[36m████▏     [0m| 11/26 [00:13<00:14,  1.00it/s]Epoch: 4/10. Loss: 1.0562:  46%|[36m████▌     [0m| 12/26 [00:13<00:13,  1.03it/s]Epoch: 4/10. Loss: 1.1189:  46%|[36m████▌     [0m| 12/26 [00:14<00:13,  1.03it/s]Epoch: 4/10. Loss: 1.1189:  50%|[36m█████     [0m| 13/26 [00:14<00:12,  1.06it/s]Epoch: 4/10. Loss: 1.0440:  50%|[36m█████     [0m| 13/26 [00:15<00:12,  1.06it/s]Epoch: 4/10. Loss: 1.0440:  54%|[36m█████▍    [0m| 14/26 [00:15<00:11,  1.02it/s]Epoch: 4/10. Loss: 0.9863:  54%|[36m█████▍    [0m| 14/26 [00:16<00:11,  1.02it/s]Epoch: 4/10. Loss: 0.9863:  58%|[36m█████▊    [0m| 15/26 [00:17<00:11,  1.05s/it]Epoch: 4/10. Loss: 0.9965:  58%|[36m█████▊    [0m| 15/26 [00:17<00:11,  1.05s/it]Epoch: 4/10. Loss: 0.9965:  62%|[36m██████▏   [0m| 16/26 [00:17<00:09,  1.00it/s]Epoch: 4/10. Loss: 0.9813:  62%|[36m██████▏   [0m| 16/26 [00:18<00:09,  1.00it/s]Epoch: 4/10. Loss: 0.9813:  65%|[36m██████▌   [0m| 17/26 [00:18<00:08,  1.01it/s]Epoch: 4/10. Loss: 1.0353:  65%|[36m██████▌   [0m| 17/26 [00:19<00:08,  1.01it/s]Epoch: 4/10. Loss: 1.0353:  69%|[36m██████▉   [0m| 18/26 [00:19<00:07,  1.03it/s]Epoch: 4/10. Loss: 1.0979:  69%|[36m██████▉   [0m| 18/26 [00:20<00:07,  1.03it/s]Epoch: 4/10. Loss: 1.0979:  73%|[36m███████▎  [0m| 19/26 [00:20<00:06,  1.07it/s]Epoch: 4/10. Loss: 1.0870:  73%|[36m███████▎  [0m| 19/26 [00:21<00:06,  1.07it/s]Epoch: 4/10. Loss: 1.0870:  77%|[36m███████▋  [0m| 20/26 [00:21<00:05,  1.01it/s]Epoch: 4/10. Loss: 1.0941:  77%|[36m███████▋  [0m| 20/26 [00:22<00:05,  1.01it/s]Epoch: 4/10. Loss: 1.0941:  81%|[36m████████  [0m| 21/26 [00:22<00:05,  1.03s/it]Epoch: 4/10. Loss: 0.9855:  81%|[36m████████  [0m| 21/26 [00:23<00:05,  1.03s/it]Epoch: 4/10. Loss: 0.9855:  85%|[36m████████▍ [0m| 22/26 [00:24<00:04,  1.06s/it]Epoch: 4/10. Loss: 0.9051:  85%|[36m████████▍ [0m| 22/26 [00:24<00:04,  1.06s/it]Epoch: 4/10. Loss: 0.9051:  88%|[36m████████▊ [0m| 23/26 [00:24<00:03,  1.04s/it]Epoch: 4/10. Loss: 1.0971:  88%|[36m████████▊ [0m| 23/26 [00:25<00:03,  1.04s/it]Epoch: 4/10. Loss: 1.0971:  92%|[36m█████████▏[0m| 24/26 [00:25<00:02,  1.03s/it]Epoch: 4/10. Loss: 0.9146:  92%|[36m█████████▏[0m| 24/26 [00:26<00:02,  1.03s/it]Epoch: 4/10. Loss: 0.9146:  96%|[36m█████████▌[0m| 25/26 [00:26<00:01,  1.00s/it]Epoch: 4/10. Loss: 1.0500:  96%|[36m█████████▌[0m| 25/26 [00:27<00:01,  1.00s/it]Epoch: 4/10. Loss: 1.0500: 100%|[36m██████████[0m| 26/26 [00:27<00:00,  1.15it/s]Epoch: 4/10. Loss: 1.0500: 100%|[36m██████████[0m| 26/26 [00:27<00:00,  1.06s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:05,  1.14it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:06,  1.23s/it] 43%|[33m████▎     [0m| 3/7 [00:02<00:03,  1.09it/s] 57%|[33m█████▋    [0m| 4/7 [00:04<00:03,  1.09s/it] 71%|[33m███████▏  [0m| 5/7 [00:04<00:01,  1.17it/s] 86%|[33m████████▌ [0m| 6/7 [00:05<00:00,  1.17it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.49it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.20it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 5/10. Loss: 0.9871:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 5/10. Loss: 0.9871:   4%|[36m▍         [0m| 1/26 [00:00<00:19,  1.26it/s]Epoch: 5/10. Loss: 0.9455:   4%|[36m▍         [0m| 1/26 [00:01<00:19,  1.26it/s]Epoch: 5/10. Loss: 0.9455:   8%|[36m▊         [0m| 2/26 [00:01<00:19,  1.24it/s]Epoch: 5/10. Loss: 0.8988:   8%|[36m▊         [0m| 2/26 [00:02<00:19,  1.24it/s]Epoch: 5/10. Loss: 0.8988:  12%|[36m█▏        [0m| 3/26 [00:02<00:20,  1.10it/s]Epoch: 5/10. Loss: 0.9136:  12%|[36m█▏        [0m| 3/26 [00:03<00:20,  1.10it/s]Epoch: 5/10. Loss: 0.9136:  15%|[36m█▌        [0m| 4/26 [00:03<00:19,  1.10it/s]Epoch: 5/10. Loss: 0.8421:  15%|[36m█▌        [0m| 4/26 [00:04<00:19,  1.10it/s]Epoch: 5/10. Loss: 0.8421:  19%|[36m█▉        [0m| 5/26 [00:04<00:23,  1.10s/it]Epoch: 5/10. Loss: 0.9949:  19%|[36m█▉        [0m| 5/26 [00:06<00:23,  1.10s/it]Epoch: 5/10. Loss: 0.9949:  23%|[36m██▎       [0m| 6/26 [00:06<00:22,  1.14s/it]Epoch: 5/10. Loss: 0.8434:  23%|[36m██▎       [0m| 6/26 [00:06<00:22,  1.14s/it]Epoch: 5/10. Loss: 0.8434:  27%|[36m██▋       [0m| 7/26 [00:06<00:19,  1.02s/it]Epoch: 5/10. Loss: 0.9325:  27%|[36m██▋       [0m| 7/26 [00:08<00:19,  1.02s/it]Epoch: 5/10. Loss: 0.9325:  31%|[36m███       [0m| 8/26 [00:08<00:19,  1.07s/it]Epoch: 5/10. Loss: 0.9083:  31%|[36m███       [0m| 8/26 [00:09<00:19,  1.07s/it]Epoch: 5/10. Loss: 0.9083:  35%|[36m███▍      [0m| 9/26 [00:09<00:19,  1.15s/it]Epoch: 5/10. Loss: 0.8462:  35%|[36m███▍      [0m| 9/26 [00:10<00:19,  1.15s/it]Epoch: 5/10. Loss: 0.8462:  38%|[36m███▊      [0m| 10/26 [00:10<00:16,  1.06s/it]Epoch: 5/10. Loss: 0.9953:  38%|[36m███▊      [0m| 10/26 [00:11<00:16,  1.06s/it]Epoch: 5/10. Loss: 0.9953:  42%|[36m████▏     [0m| 11/26 [00:11<00:14,  1.01it/s]Epoch: 5/10. Loss: 0.9348:  42%|[36m████▏     [0m| 11/26 [00:11<00:14,  1.01it/s]Epoch: 5/10. Loss: 0.9348:  46%|[36m████▌     [0m| 12/26 [00:12<00:13,  1.06it/s]Epoch: 5/10. Loss: 0.9273:  46%|[36m████▌     [0m| 12/26 [00:13<00:13,  1.06it/s]Epoch: 5/10. Loss: 0.9273:  50%|[36m█████     [0m| 13/26 [00:13<00:13,  1.07s/it]Epoch: 5/10. Loss: 0.9407:  50%|[36m█████     [0m| 13/26 [00:14<00:13,  1.07s/it]Epoch: 5/10. Loss: 0.9407:  54%|[36m█████▍    [0m| 14/26 [00:14<00:12,  1.02s/it]Epoch: 5/10. Loss: 1.0075:  54%|[36m█████▍    [0m| 14/26 [00:15<00:12,  1.02s/it]Epoch: 5/10. Loss: 1.0075:  58%|[36m█████▊    [0m| 15/26 [00:15<00:12,  1.15s/it]Epoch: 5/10. Loss: 1.0034:  58%|[36m█████▊    [0m| 15/26 [00:17<00:12,  1.15s/it]Epoch: 5/10. Loss: 1.0034:  62%|[36m██████▏   [0m| 16/26 [00:17<00:14,  1.48s/it]Epoch: 5/10. Loss: 0.9641:  62%|[36m██████▏   [0m| 16/26 [00:18<00:14,  1.48s/it]Epoch: 5/10. Loss: 0.9641:  65%|[36m██████▌   [0m| 17/26 [00:18<00:11,  1.32s/it]Epoch: 5/10. Loss: 0.9680:  65%|[36m██████▌   [0m| 17/26 [00:19<00:11,  1.32s/it]Epoch: 5/10. Loss: 0.9680:  69%|[36m██████▉   [0m| 18/26 [00:19<00:09,  1.19s/it]Epoch: 5/10. Loss: 0.9245:  69%|[36m██████▉   [0m| 18/26 [00:20<00:09,  1.19s/it]Epoch: 5/10. Loss: 0.9245:  73%|[36m███████▎  [0m| 19/26 [00:20<00:07,  1.11s/it]Epoch: 5/10. Loss: 1.0461:  73%|[36m███████▎  [0m| 19/26 [00:21<00:07,  1.11s/it]Epoch: 5/10. Loss: 1.0461:  77%|[36m███████▋  [0m| 20/26 [00:21<00:06,  1.05s/it]Epoch: 5/10. Loss: 0.9575:  77%|[36m███████▋  [0m| 20/26 [00:22<00:06,  1.05s/it]Epoch: 5/10. Loss: 0.9575:  81%|[36m████████  [0m| 21/26 [00:22<00:05,  1.06s/it]Epoch: 5/10. Loss: 1.0232:  81%|[36m████████  [0m| 21/26 [00:24<00:05,  1.06s/it]Epoch: 5/10. Loss: 1.0232:  85%|[36m████████▍ [0m| 22/26 [00:24<00:04,  1.19s/it]Epoch: 5/10. Loss: 0.9018:  85%|[36m████████▍ [0m| 22/26 [00:25<00:04,  1.19s/it]Epoch: 5/10. Loss: 0.9018:  88%|[36m████████▊ [0m| 23/26 [00:25<00:03,  1.14s/it]Epoch: 5/10. Loss: 0.9342:  88%|[36m████████▊ [0m| 23/26 [00:26<00:03,  1.14s/it]Epoch: 5/10. Loss: 0.9342:  92%|[36m█████████▏[0m| 24/26 [00:26<00:02,  1.10s/it]Epoch: 5/10. Loss: 0.9767:  92%|[36m█████████▏[0m| 24/26 [00:27<00:02,  1.10s/it]Epoch: 5/10. Loss: 0.9767:  96%|[36m█████████▌[0m| 25/26 [00:27<00:01,  1.07s/it]Epoch: 5/10. Loss: 1.1475:  96%|[36m█████████▌[0m| 25/26 [00:27<00:01,  1.07s/it]Epoch: 5/10. Loss: 1.1475: 100%|[36m██████████[0m| 26/26 [00:27<00:00,  1.06it/s]Epoch: 5/10. Loss: 1.1475: 100%|[36m██████████[0m| 26/26 [00:27<00:00,  1.07s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:05,  1.14it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:07,  1.44s/it] 43%|[33m████▎     [0m| 3/7 [00:03<00:04,  1.03s/it] 57%|[33m█████▋    [0m| 4/7 [00:04<00:03,  1.13s/it] 71%|[33m███████▏  [0m| 5/7 [00:04<00:01,  1.17it/s] 86%|[33m████████▌ [0m| 6/7 [00:05<00:00,  1.17it/s]100%|[33m██████████[0m| 7/7 [00:06<00:00,  1.50it/s]100%|[33m██████████[0m| 7/7 [00:06<00:00,  1.16it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 6/10. Loss: 0.8959:   0%|[36m          [0m| 0/26 [00:03<?, ?it/s]Epoch: 6/10. Loss: 0.8959:   4%|[36m▍         [0m| 1/26 [00:03<01:18,  3.12s/it]Epoch: 6/10. Loss: 1.0172:   4%|[36m▍         [0m| 1/26 [00:04<01:18,  3.12s/it]Epoch: 6/10. Loss: 1.0172:   8%|[36m▊         [0m| 2/26 [00:04<00:47,  1.99s/it]Epoch: 6/10. Loss: 1.0734:   8%|[36m▊         [0m| 2/26 [00:05<00:47,  1.99s/it]Epoch: 6/10. Loss: 1.0734:  12%|[36m█▏        [0m| 3/26 [00:05<00:36,  1.60s/it]Epoch: 6/10. Loss: 0.8829:  12%|[36m█▏        [0m| 3/26 [00:06<00:36,  1.60s/it]Epoch: 6/10. Loss: 0.8829:  15%|[36m█▌        [0m| 4/26 [00:06<00:29,  1.34s/it]Epoch: 6/10. Loss: 0.9304:  15%|[36m█▌        [0m| 4/26 [00:07<00:29,  1.34s/it]Epoch: 6/10. Loss: 0.9304:  19%|[36m█▉        [0m| 5/26 [00:07<00:29,  1.40s/it]Epoch: 6/10. Loss: 0.8512:  19%|[36m█▉        [0m| 5/26 [00:09<00:29,  1.40s/it]Epoch: 6/10. Loss: 0.8512:  23%|[36m██▎       [0m| 6/26 [00:09<00:27,  1.37s/it]Epoch: 6/10. Loss: 0.9213:  23%|[36m██▎       [0m| 6/26 [00:11<00:27,  1.37s/it]Epoch: 6/10. Loss: 0.9213:  27%|[36m██▋       [0m| 7/26 [00:11<00:32,  1.73s/it]Epoch: 6/10. Loss: 1.0200:  27%|[36m██▋       [0m| 7/26 [00:12<00:32,  1.73s/it]Epoch: 6/10. Loss: 1.0200:  31%|[36m███       [0m| 8/26 [00:12<00:27,  1.51s/it]Epoch: 6/10. Loss: 0.9607:  31%|[36m███       [0m| 8/26 [00:13<00:27,  1.51s/it]Epoch: 6/10. Loss: 0.9607:  35%|[36m███▍      [0m| 9/26 [00:13<00:24,  1.41s/it]Epoch: 6/10. Loss: 0.9909:  35%|[36m███▍      [0m| 9/26 [00:14<00:24,  1.41s/it]Epoch: 6/10. Loss: 0.9909:  38%|[36m███▊      [0m| 10/26 [00:14<00:20,  1.27s/it]Epoch: 6/10. Loss: 0.9977:  38%|[36m███▊      [0m| 10/26 [00:15<00:20,  1.27s/it]Epoch: 6/10. Loss: 0.9977:  42%|[36m████▏     [0m| 11/26 [00:15<00:17,  1.16s/it]Epoch: 6/10. Loss: 1.0304:  42%|[36m████▏     [0m| 11/26 [00:16<00:17,  1.16s/it]Epoch: 6/10. Loss: 1.0304:  46%|[36m████▌     [0m| 12/26 [00:16<00:15,  1.08s/it]Epoch: 6/10. Loss: 0.9798:  46%|[36m████▌     [0m| 12/26 [00:17<00:15,  1.08s/it]Epoch: 6/10. Loss: 0.9798:  50%|[36m█████     [0m| 13/26 [00:17<00:13,  1.04s/it]Epoch: 6/10. Loss: 1.0517:  50%|[36m█████     [0m| 13/26 [00:18<00:13,  1.04s/it]Epoch: 6/10. Loss: 1.0517:  54%|[36m█████▍    [0m| 14/26 [00:18<00:11,  1.01it/s]Epoch: 6/10. Loss: 0.9315:  54%|[36m█████▍    [0m| 14/26 [00:19<00:11,  1.01it/s]Epoch: 6/10. Loss: 0.9315:  58%|[36m█████▊    [0m| 15/26 [00:19<00:12,  1.11s/it]Epoch: 6/10. Loss: 0.9837:  58%|[36m█████▊    [0m| 15/26 [00:21<00:12,  1.11s/it]Epoch: 6/10. Loss: 0.9837:  62%|[36m██████▏   [0m| 16/26 [00:21<00:11,  1.16s/it]Epoch: 6/10. Loss: 1.0498:  62%|[36m██████▏   [0m| 16/26 [00:21<00:11,  1.16s/it]Epoch: 6/10. Loss: 1.0498:  65%|[36m██████▌   [0m| 17/26 [00:22<00:09,  1.07s/it]Epoch: 6/10. Loss: 0.9633:  65%|[36m██████▌   [0m| 17/26 [00:22<00:09,  1.07s/it]Epoch: 6/10. Loss: 0.9633:  69%|[36m██████▉   [0m| 18/26 [00:22<00:08,  1.04s/it]Epoch: 6/10. Loss: 0.9401:  69%|[36m██████▉   [0m| 18/26 [00:24<00:08,  1.04s/it]Epoch: 6/10. Loss: 0.9401:  73%|[36m███████▎  [0m| 19/26 [00:24<00:08,  1.23s/it]Epoch: 6/10. Loss: 0.9158:  73%|[36m███████▎  [0m| 19/26 [00:25<00:08,  1.23s/it]Epoch: 6/10. Loss: 0.9158:  77%|[36m███████▋  [0m| 20/26 [00:25<00:06,  1.15s/it]Epoch: 6/10. Loss: 0.9953:  77%|[36m███████▋  [0m| 20/26 [00:26<00:06,  1.15s/it]Epoch: 6/10. Loss: 0.9953:  81%|[36m████████  [0m| 21/26 [00:26<00:05,  1.08s/it]Epoch: 6/10. Loss: 0.9036:  81%|[36m████████  [0m| 21/26 [00:29<00:05,  1.08s/it]Epoch: 6/10. Loss: 0.9036:  85%|[36m████████▍ [0m| 22/26 [00:29<00:06,  1.69s/it]Epoch: 6/10. Loss: 0.9302:  85%|[36m████████▍ [0m| 22/26 [00:31<00:06,  1.69s/it]Epoch: 6/10. Loss: 0.9302:  88%|[36m████████▊ [0m| 23/26 [00:31<00:05,  1.76s/it]Epoch: 6/10. Loss: 0.9619:  88%|[36m████████▊ [0m| 23/26 [00:32<00:05,  1.76s/it]Epoch: 6/10. Loss: 0.9619:  92%|[36m█████████▏[0m| 24/26 [00:32<00:03,  1.54s/it]Epoch: 6/10. Loss: 0.8928:  92%|[36m█████████▏[0m| 24/26 [00:33<00:03,  1.54s/it]Epoch: 6/10. Loss: 0.8928:  96%|[36m█████████▌[0m| 25/26 [00:33<00:01,  1.36s/it]Epoch: 6/10. Loss: 0.8450:  96%|[36m█████████▌[0m| 25/26 [00:34<00:01,  1.36s/it]Epoch: 6/10. Loss: 0.8450: 100%|[36m██████████[0m| 26/26 [00:34<00:00,  1.19s/it]Epoch: 6/10. Loss: 0.8450: 100%|[36m██████████[0m| 26/26 [00:34<00:00,  1.32s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:05,  1.15it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:06,  1.21s/it] 43%|[33m████▎     [0m| 3/7 [00:02<00:03,  1.10it/s] 57%|[33m█████▋    [0m| 4/7 [00:04<00:03,  1.21s/it] 71%|[33m███████▏  [0m| 5/7 [00:04<00:01,  1.09it/s] 86%|[33m████████▌ [0m| 6/7 [00:05<00:00,  1.11it/s]100%|[33m██████████[0m| 7/7 [00:06<00:00,  1.42it/s]100%|[33m██████████[0m| 7/7 [00:06<00:00,  1.15it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 7/10. Loss: 0.8881:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 7/10. Loss: 0.8881:   4%|[36m▍         [0m| 1/26 [00:00<00:23,  1.04it/s]Epoch: 7/10. Loss: 0.8438:   4%|[36m▍         [0m| 1/26 [00:01<00:23,  1.04it/s]Epoch: 7/10. Loss: 0.8438:   8%|[36m▊         [0m| 2/26 [00:02<00:24,  1.02s/it]Epoch: 7/10. Loss: 1.0582:   8%|[36m▊         [0m| 2/26 [00:02<00:24,  1.02s/it]Epoch: 7/10. Loss: 1.0582:  12%|[36m█▏        [0m| 3/26 [00:02<00:21,  1.06it/s]Epoch: 7/10. Loss: 0.8879:  12%|[36m█▏        [0m| 3/26 [00:03<00:21,  1.06it/s]Epoch: 7/10. Loss: 0.8879:  15%|[36m█▌        [0m| 4/26 [00:03<00:21,  1.05it/s]Epoch: 7/10. Loss: 0.8991:  15%|[36m█▌        [0m| 4/26 [00:05<00:21,  1.05it/s]Epoch: 7/10. Loss: 0.8991:  19%|[36m█▉        [0m| 5/26 [00:05<00:21,  1.04s/it]Epoch: 7/10. Loss: 0.9580:  19%|[36m█▉        [0m| 5/26 [00:05<00:21,  1.04s/it]Epoch: 7/10. Loss: 0.9580:  23%|[36m██▎       [0m| 6/26 [00:05<00:19,  1.03it/s]Epoch: 7/10. Loss: 0.8956:  23%|[36m██▎       [0m| 6/26 [00:06<00:19,  1.03it/s]Epoch: 7/10. Loss: 0.8956:  27%|[36m██▋       [0m| 7/26 [00:06<00:18,  1.05it/s]Epoch: 7/10. Loss: 1.0761:  27%|[36m██▋       [0m| 7/26 [00:07<00:18,  1.05it/s]Epoch: 7/10. Loss: 1.0761:  31%|[36m███       [0m| 8/26 [00:07<00:18,  1.01s/it]Epoch: 7/10. Loss: 0.9240:  31%|[36m███       [0m| 8/26 [00:09<00:18,  1.01s/it]Epoch: 7/10. Loss: 0.9240:  35%|[36m███▍      [0m| 9/26 [00:09<00:18,  1.11s/it]Epoch: 7/10. Loss: 0.9725:  35%|[36m███▍      [0m| 9/26 [00:10<00:18,  1.11s/it]Epoch: 7/10. Loss: 0.9725:  38%|[36m███▊      [0m| 10/26 [00:10<00:20,  1.30s/it]Epoch: 7/10. Loss: 1.0461:  38%|[36m███▊      [0m| 10/26 [00:11<00:20,  1.30s/it]Epoch: 7/10. Loss: 1.0461:  42%|[36m████▏     [0m| 11/26 [00:11<00:17,  1.19s/it]Epoch: 7/10. Loss: 0.8908:  42%|[36m████▏     [0m| 11/26 [00:12<00:17,  1.19s/it]Epoch: 7/10. Loss: 0.8908:  46%|[36m████▌     [0m| 12/26 [00:12<00:15,  1.10s/it]Epoch: 7/10. Loss: 0.9213:  46%|[36m████▌     [0m| 12/26 [00:14<00:15,  1.10s/it]Epoch: 7/10. Loss: 0.9213:  50%|[36m█████     [0m| 13/26 [00:14<00:15,  1.16s/it]Epoch: 7/10. Loss: 0.8932:  50%|[36m█████     [0m| 13/26 [00:15<00:15,  1.16s/it]Epoch: 7/10. Loss: 0.8932:  54%|[36m█████▍    [0m| 14/26 [00:15<00:13,  1.15s/it]Epoch: 7/10. Loss: 0.8958:  54%|[36m█████▍    [0m| 14/26 [00:16<00:13,  1.15s/it]Epoch: 7/10. Loss: 0.8958:  58%|[36m█████▊    [0m| 15/26 [00:16<00:12,  1.16s/it]Epoch: 7/10. Loss: 0.9158:  58%|[36m█████▊    [0m| 15/26 [00:18<00:12,  1.16s/it]Epoch: 7/10. Loss: 0.9158:  62%|[36m██████▏   [0m| 16/26 [00:19<00:15,  1.59s/it]Epoch: 7/10. Loss: 0.9993:  62%|[36m██████▏   [0m| 16/26 [00:20<00:15,  1.59s/it]Epoch: 7/10. Loss: 0.9993:  65%|[36m██████▌   [0m| 17/26 [00:20<00:13,  1.46s/it]Epoch: 7/10. Loss: 0.9131:  65%|[36m██████▌   [0m| 17/26 [00:21<00:13,  1.46s/it]Epoch: 7/10. Loss: 0.9131:  69%|[36m██████▉   [0m| 18/26 [00:21<00:11,  1.41s/it]Epoch: 7/10. Loss: 0.8833:  69%|[36m██████▉   [0m| 18/26 [00:22<00:11,  1.41s/it]Epoch: 7/10. Loss: 0.8833:  73%|[36m███████▎  [0m| 19/26 [00:22<00:08,  1.28s/it]Epoch: 7/10. Loss: 0.8702:  73%|[36m███████▎  [0m| 19/26 [00:23<00:08,  1.28s/it]Epoch: 7/10. Loss: 0.8702:  77%|[36m███████▋  [0m| 20/26 [00:23<00:07,  1.27s/it]Epoch: 7/10. Loss: 0.8573:  77%|[36m███████▋  [0m| 20/26 [00:24<00:07,  1.27s/it]Epoch: 7/10. Loss: 0.8573:  81%|[36m████████  [0m| 21/26 [00:24<00:05,  1.15s/it]Epoch: 7/10. Loss: 0.8212:  81%|[36m████████  [0m| 21/26 [00:26<00:05,  1.15s/it]Epoch: 7/10. Loss: 0.8212:  85%|[36m████████▍ [0m| 22/26 [00:26<00:05,  1.30s/it]Epoch: 7/10. Loss: 0.9249:  85%|[36m████████▍ [0m| 22/26 [00:27<00:05,  1.30s/it]Epoch: 7/10. Loss: 0.9249:  88%|[36m████████▊ [0m| 23/26 [00:27<00:03,  1.32s/it]Epoch: 7/10. Loss: 0.8438:  88%|[36m████████▊ [0m| 23/26 [00:28<00:03,  1.32s/it]Epoch: 7/10. Loss: 0.8438:  92%|[36m█████████▏[0m| 24/26 [00:28<00:02,  1.28s/it]Epoch: 7/10. Loss: 0.9094:  92%|[36m█████████▏[0m| 24/26 [00:29<00:02,  1.28s/it]Epoch: 7/10. Loss: 0.9094:  96%|[36m█████████▌[0m| 25/26 [00:29<00:01,  1.18s/it]Epoch: 7/10. Loss: 0.9274:  96%|[36m█████████▌[0m| 25/26 [00:30<00:01,  1.18s/it]Epoch: 7/10. Loss: 0.9274: 100%|[36m██████████[0m| 26/26 [00:30<00:00,  1.09s/it]Epoch: 7/10. Loss: 0.9274: 100%|[36m██████████[0m| 26/26 [00:30<00:00,  1.18s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:05,  1.17it/s] 29%|[33m██▊       [0m| 2/7 [00:03<00:08,  1.72s/it] 43%|[33m████▎     [0m| 3/7 [00:03<00:04,  1.19s/it] 57%|[33m█████▋    [0m| 4/7 [00:05<00:03,  1.27s/it] 71%|[33m███████▏  [0m| 5/7 [00:05<00:01,  1.04it/s] 86%|[33m████████▌ [0m| 6/7 [00:06<00:00,  1.07it/s]100%|[33m██████████[0m| 7/7 [00:06<00:00,  1.37it/s]100%|[33m██████████[0m| 7/7 [00:06<00:00,  1.04it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 8/10. Loss: 0.9038:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 8/10. Loss: 0.9038:   4%|[36m▍         [0m| 1/26 [00:00<00:23,  1.05it/s]Epoch: 8/10. Loss: 0.8931:   4%|[36m▍         [0m| 1/26 [00:02<00:23,  1.05it/s]Epoch: 8/10. Loss: 0.8931:   8%|[36m▊         [0m| 2/26 [00:02<00:25,  1.05s/it]Epoch: 8/10. Loss: 0.8316:   8%|[36m▊         [0m| 2/26 [00:03<00:25,  1.05s/it]Epoch: 8/10. Loss: 0.8316:  12%|[36m█▏        [0m| 3/26 [00:03<00:23,  1.02s/it]Epoch: 8/10. Loss: 0.8267:  12%|[36m█▏        [0m| 3/26 [00:03<00:23,  1.02s/it]Epoch: 8/10. Loss: 0.8267:  15%|[36m█▌        [0m| 4/26 [00:04<00:21,  1.01it/s]Epoch: 8/10. Loss: 0.8330:  15%|[36m█▌        [0m| 4/26 [00:04<00:21,  1.01it/s]Epoch: 8/10. Loss: 0.8330:  19%|[36m█▉        [0m| 5/26 [00:04<00:20,  1.03it/s]Epoch: 8/10. Loss: 0.8807:  19%|[36m█▉        [0m| 5/26 [00:05<00:20,  1.03it/s]Epoch: 8/10. Loss: 0.8807:  23%|[36m██▎       [0m| 6/26 [00:06<00:20,  1.01s/it]Epoch: 8/10. Loss: 0.8993:  23%|[36m██▎       [0m| 6/26 [00:06<00:20,  1.01s/it]Epoch: 8/10. Loss: 0.8993:  27%|[36m██▋       [0m| 7/26 [00:06<00:17,  1.06it/s]Epoch: 8/10. Loss: 0.8713:  27%|[36m██▋       [0m| 7/26 [00:07<00:17,  1.06it/s]Epoch: 8/10. Loss: 0.8713:  31%|[36m███       [0m| 8/26 [00:07<00:16,  1.08it/s]Epoch: 8/10. Loss: 0.9002:  31%|[36m███       [0m| 8/26 [00:08<00:16,  1.08it/s]Epoch: 8/10. Loss: 0.9002:  35%|[36m███▍      [0m| 9/26 [00:08<00:15,  1.09it/s]Epoch: 8/10. Loss: 0.8384:  35%|[36m███▍      [0m| 9/26 [00:09<00:15,  1.09it/s]Epoch: 8/10. Loss: 0.8384:  38%|[36m███▊      [0m| 10/26 [00:09<00:15,  1.07it/s]Epoch: 8/10. Loss: 0.8342:  38%|[36m███▊      [0m| 10/26 [00:10<00:15,  1.07it/s]Epoch: 8/10. Loss: 0.8342:  42%|[36m████▏     [0m| 11/26 [00:10<00:14,  1.03it/s]Epoch: 8/10. Loss: 0.7708:  42%|[36m████▏     [0m| 11/26 [00:11<00:14,  1.03it/s]Epoch: 8/10. Loss: 0.7708:  46%|[36m████▌     [0m| 12/26 [00:11<00:15,  1.07s/it]Epoch: 8/10. Loss: 0.7828:  46%|[36m████▌     [0m| 12/26 [00:12<00:15,  1.07s/it]Epoch: 8/10. Loss: 0.7828:  50%|[36m█████     [0m| 13/26 [00:12<00:13,  1.01s/it]Epoch: 8/10. Loss: 0.8971:  50%|[36m█████     [0m| 13/26 [00:13<00:13,  1.01s/it]Epoch: 8/10. Loss: 0.8971:  54%|[36m█████▍    [0m| 14/26 [00:13<00:11,  1.04it/s]Epoch: 8/10. Loss: 0.9762:  54%|[36m█████▍    [0m| 14/26 [00:14<00:11,  1.04it/s]Epoch: 8/10. Loss: 0.9762:  58%|[36m█████▊    [0m| 15/26 [00:14<00:10,  1.10it/s]Epoch: 8/10. Loss: 0.9830:  58%|[36m█████▊    [0m| 15/26 [00:15<00:10,  1.10it/s]Epoch: 8/10. Loss: 0.9830:  62%|[36m██████▏   [0m| 16/26 [00:15<00:09,  1.09it/s]Epoch: 8/10. Loss: 0.9826:  62%|[36m██████▏   [0m| 16/26 [00:16<00:09,  1.09it/s]Epoch: 8/10. Loss: 0.9826:  65%|[36m██████▌   [0m| 17/26 [00:16<00:08,  1.06it/s]Epoch: 8/10. Loss: 0.7804:  65%|[36m██████▌   [0m| 17/26 [00:17<00:08,  1.06it/s]Epoch: 8/10. Loss: 0.7804:  69%|[36m██████▉   [0m| 18/26 [00:17<00:07,  1.05it/s]Epoch: 8/10. Loss: 0.8972:  69%|[36m██████▉   [0m| 18/26 [00:18<00:07,  1.05it/s]Epoch: 8/10. Loss: 0.8972:  73%|[36m███████▎  [0m| 19/26 [00:18<00:06,  1.04it/s]Epoch: 8/10. Loss: 0.9650:  73%|[36m███████▎  [0m| 19/26 [00:19<00:06,  1.04it/s]Epoch: 8/10. Loss: 0.9650:  77%|[36m███████▋  [0m| 20/26 [00:19<00:05,  1.09it/s]Epoch: 8/10. Loss: 0.8864:  77%|[36m███████▋  [0m| 20/26 [00:20<00:05,  1.09it/s]Epoch: 8/10. Loss: 0.8864:  81%|[36m████████  [0m| 21/26 [00:20<00:04,  1.09it/s]Epoch: 8/10. Loss: 0.7552:  81%|[36m████████  [0m| 21/26 [00:21<00:04,  1.09it/s]Epoch: 8/10. Loss: 0.7552:  85%|[36m████████▍ [0m| 22/26 [00:21<00:03,  1.07it/s]Epoch: 8/10. Loss: 0.9019:  85%|[36m████████▍ [0m| 22/26 [00:21<00:03,  1.07it/s]Epoch: 8/10. Loss: 0.9019:  88%|[36m████████▊ [0m| 23/26 [00:21<00:02,  1.08it/s]Epoch: 8/10. Loss: 0.8645:  88%|[36m████████▊ [0m| 23/26 [00:22<00:02,  1.08it/s]Epoch: 8/10. Loss: 0.8645:  92%|[36m█████████▏[0m| 24/26 [00:22<00:01,  1.07it/s]Epoch: 8/10. Loss: 1.0771:  92%|[36m█████████▏[0m| 24/26 [00:24<00:01,  1.07it/s]Epoch: 8/10. Loss: 1.0771:  96%|[36m█████████▌[0m| 25/26 [00:24<00:00,  1.00it/s]Epoch: 8/10. Loss: 0.8814:  96%|[36m█████████▌[0m| 25/26 [00:24<00:00,  1.00it/s]Epoch: 8/10. Loss: 0.8814: 100%|[36m██████████[0m| 26/26 [00:24<00:00,  1.14it/s]Epoch: 8/10. Loss: 0.8814: 100%|[36m██████████[0m| 26/26 [00:24<00:00,  1.05it/s]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:05,  1.01it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:06,  1.33s/it] 43%|[33m████▎     [0m| 3/7 [00:03<00:03,  1.04it/s] 57%|[33m█████▋    [0m| 4/7 [00:04<00:03,  1.13s/it] 71%|[33m███████▏  [0m| 5/7 [00:04<00:01,  1.15it/s] 86%|[33m████████▌ [0m| 6/7 [00:05<00:00,  1.14it/s]100%|[33m██████████[0m| 7/7 [00:06<00:00,  1.43it/s]100%|[33m██████████[0m| 7/7 [00:06<00:00,  1.15it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 9/10. Loss: 0.9526:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 9/10. Loss: 0.9526:   4%|[36m▍         [0m| 1/26 [00:00<00:24,  1.01it/s]Epoch: 9/10. Loss: 0.9887:   4%|[36m▍         [0m| 1/26 [00:02<00:24,  1.01it/s]Epoch: 9/10. Loss: 0.9887:   8%|[36m▊         [0m| 2/26 [00:02<00:25,  1.05s/it]Epoch: 9/10. Loss: 0.9082:   8%|[36m▊         [0m| 2/26 [00:03<00:25,  1.05s/it]Epoch: 9/10. Loss: 0.9082:  12%|[36m█▏        [0m| 3/26 [00:03<00:23,  1.03s/it]Epoch: 9/10. Loss: 0.9054:  12%|[36m█▏        [0m| 3/26 [00:04<00:23,  1.03s/it]Epoch: 9/10. Loss: 0.9054:  15%|[36m█▌        [0m| 4/26 [00:04<00:27,  1.26s/it]Epoch: 9/10. Loss: 0.9301:  15%|[36m█▌        [0m| 4/26 [00:05<00:27,  1.26s/it]Epoch: 9/10. Loss: 0.9301:  19%|[36m█▉        [0m| 5/26 [00:05<00:22,  1.07s/it]Epoch: 9/10. Loss: 0.9009:  19%|[36m█▉        [0m| 5/26 [00:06<00:22,  1.07s/it]Epoch: 9/10. Loss: 0.9009:  23%|[36m██▎       [0m| 6/26 [00:06<00:21,  1.07s/it]Epoch: 9/10. Loss: 0.9379:  23%|[36m██▎       [0m| 6/26 [00:07<00:21,  1.07s/it]Epoch: 9/10. Loss: 0.9379:  27%|[36m██▋       [0m| 7/26 [00:07<00:19,  1.04s/it]Epoch: 9/10. Loss: 0.8501:  27%|[36m██▋       [0m| 7/26 [00:08<00:19,  1.04s/it]Epoch: 9/10. Loss: 0.8501:  31%|[36m███       [0m| 8/26 [00:08<00:18,  1.01s/it]Epoch: 9/10. Loss: 0.8861:  31%|[36m███       [0m| 8/26 [00:09<00:18,  1.01s/it]Epoch: 9/10. Loss: 0.8861:  35%|[36m███▍      [0m| 9/26 [00:09<00:16,  1.03it/s]Epoch: 9/10. Loss: 0.9324:  35%|[36m███▍      [0m| 9/26 [00:11<00:16,  1.03it/s]Epoch: 9/10. Loss: 0.9324:  38%|[36m███▊      [0m| 10/26 [00:11<00:20,  1.26s/it]Epoch: 9/10. Loss: 0.9532:  38%|[36m███▊      [0m| 10/26 [00:12<00:20,  1.26s/it]Epoch: 9/10. Loss: 0.9532:  42%|[36m████▏     [0m| 11/26 [00:12<00:19,  1.29s/it]Epoch: 9/10. Loss: 0.8697:  42%|[36m████▏     [0m| 11/26 [00:13<00:19,  1.29s/it]Epoch: 9/10. Loss: 0.8697:  46%|[36m████▌     [0m| 12/26 [00:13<00:17,  1.26s/it]Epoch: 9/10. Loss: 0.8176:  46%|[36m████▌     [0m| 12/26 [00:14<00:17,  1.26s/it]Epoch: 9/10. Loss: 0.8176:  50%|[36m█████     [0m| 13/26 [00:14<00:15,  1.17s/it]Epoch: 9/10. Loss: 0.8731:  50%|[36m█████     [0m| 13/26 [00:15<00:15,  1.17s/it]Epoch: 9/10. Loss: 0.8731:  54%|[36m█████▍    [0m| 14/26 [00:15<00:13,  1.11s/it]Epoch: 9/10. Loss: 0.8977:  54%|[36m█████▍    [0m| 14/26 [00:16<00:13,  1.11s/it]Epoch: 9/10. Loss: 0.8977:  58%|[36m█████▊    [0m| 15/26 [00:16<00:11,  1.08s/it]Epoch: 9/10. Loss: 0.8991:  58%|[36m█████▊    [0m| 15/26 [00:17<00:11,  1.08s/it]Epoch: 9/10. Loss: 0.8991:  62%|[36m██████▏   [0m| 16/26 [00:17<00:10,  1.04s/it]Epoch: 9/10. Loss: 0.8125:  62%|[36m██████▏   [0m| 16/26 [00:18<00:10,  1.04s/it]Epoch: 9/10. Loss: 0.8125:  65%|[36m██████▌   [0m| 17/26 [00:18<00:08,  1.03it/s]Epoch: 9/10. Loss: 0.9428:  65%|[36m██████▌   [0m| 17/26 [00:19<00:08,  1.03it/s]Epoch: 9/10. Loss: 0.9428:  69%|[36m██████▉   [0m| 18/26 [00:19<00:08,  1.06s/it]Epoch: 9/10. Loss: 0.8098:  69%|[36m██████▉   [0m| 18/26 [00:20<00:08,  1.06s/it]Epoch: 9/10. Loss: 0.8098:  73%|[36m███████▎  [0m| 19/26 [00:20<00:07,  1.03s/it]Epoch: 9/10. Loss: 0.9311:  73%|[36m███████▎  [0m| 19/26 [00:21<00:07,  1.03s/it]Epoch: 9/10. Loss: 0.9311:  77%|[36m███████▋  [0m| 20/26 [00:21<00:05,  1.01it/s]Epoch: 9/10. Loss: 0.8099:  77%|[36m███████▋  [0m| 20/26 [00:22<00:05,  1.01it/s]Epoch: 9/10. Loss: 0.8099:  81%|[36m████████  [0m| 21/26 [00:22<00:04,  1.03it/s]Epoch: 9/10. Loss: 0.9047:  81%|[36m████████  [0m| 21/26 [00:24<00:04,  1.03it/s]Epoch: 9/10. Loss: 0.9047:  85%|[36m████████▍ [0m| 22/26 [00:24<00:04,  1.23s/it]Epoch: 9/10. Loss: 0.7792:  85%|[36m████████▍ [0m| 22/26 [00:25<00:04,  1.23s/it]Epoch: 9/10. Loss: 0.7792:  88%|[36m████████▊ [0m| 23/26 [00:25<00:03,  1.09s/it]Epoch: 9/10. Loss: 0.9245:  88%|[36m████████▊ [0m| 23/26 [00:25<00:03,  1.09s/it]Epoch: 9/10. Loss: 0.9245:  92%|[36m█████████▏[0m| 24/26 [00:25<00:02,  1.02s/it]Epoch: 9/10. Loss: 0.7891:  92%|[36m█████████▏[0m| 24/26 [00:26<00:02,  1.02s/it]Epoch: 9/10. Loss: 0.7891:  96%|[36m█████████▌[0m| 25/26 [00:26<00:00,  1.01it/s]Epoch: 9/10. Loss: 0.9123:  96%|[36m█████████▌[0m| 25/26 [00:27<00:00,  1.01it/s]Epoch: 9/10. Loss: 0.9123: 100%|[36m██████████[0m| 26/26 [00:27<00:00,  1.12it/s]Epoch: 9/10. Loss: 0.9123: 100%|[36m██████████[0m| 26/26 [00:27<00:00,  1.06s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:05,  1.15it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:05,  1.19s/it] 43%|[33m████▎     [0m| 3/7 [00:02<00:03,  1.12it/s] 57%|[33m█████▋    [0m| 4/7 [00:04<00:03,  1.09s/it] 71%|[33m███████▏  [0m| 5/7 [00:04<00:01,  1.19it/s] 86%|[33m████████▌ [0m| 6/7 [00:05<00:00,  1.16it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.48it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.20it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 0/10. Loss: 1.1709:   0%|[36m          [0m| 0/26 [00:01<?, ?it/s]Epoch: 0/10. Loss: 1.1709:   4%|[36m▍         [0m| 1/26 [00:01<00:28,  1.13s/it]Epoch: 0/10. Loss: 11.1196:   4%|[36m▍         [0m| 1/26 [00:02<00:28,  1.13s/it]Epoch: 0/10. Loss: 11.1196:   8%|[36m▊         [0m| 2/26 [00:02<00:26,  1.09s/it]Epoch: 0/10. Loss: 3.4805:   8%|[36m▊         [0m| 2/26 [00:03<00:26,  1.09s/it] Epoch: 0/10. Loss: 3.4805:  12%|[36m█▏        [0m| 3/26 [00:03<00:23,  1.01s/it]Epoch: 0/10. Loss: 2.0347:  12%|[36m█▏        [0m| 3/26 [00:03<00:23,  1.01s/it]Epoch: 0/10. Loss: 2.0347:  15%|[36m█▌        [0m| 4/26 [00:03<00:21,  1.04it/s]Epoch: 0/10. Loss: 2.8757:  15%|[36m█▌        [0m| 4/26 [00:04<00:21,  1.04it/s]Epoch: 0/10. Loss: 2.8757:  19%|[36m█▉        [0m| 5/26 [00:04<00:19,  1.10it/s]Epoch: 0/10. Loss: 4.6634:  19%|[36m█▉        [0m| 5/26 [00:05<00:19,  1.10it/s]Epoch: 0/10. Loss: 4.6634:  23%|[36m██▎       [0m| 6/26 [00:05<00:18,  1.09it/s]Epoch: 0/10. Loss: 1.9872:  23%|[36m██▎       [0m| 6/26 [00:06<00:18,  1.09it/s]Epoch: 0/10. Loss: 1.9872:  27%|[36m██▋       [0m| 7/26 [00:06<00:18,  1.05it/s]Epoch: 0/10. Loss: 2.0583:  27%|[36m██▋       [0m| 7/26 [00:07<00:18,  1.05it/s]Epoch: 0/10. Loss: 2.0583:  31%|[36m███       [0m| 8/26 [00:07<00:18,  1.03s/it]Epoch: 0/10. Loss: 2.3387:  31%|[36m███       [0m| 8/26 [00:08<00:18,  1.03s/it]Epoch: 0/10. Loss: 2.3387:  35%|[36m███▍      [0m| 9/26 [00:08<00:16,  1.04it/s]Epoch: 0/10. Loss: 1.4427:  35%|[36m███▍      [0m| 9/26 [00:09<00:16,  1.04it/s]Epoch: 0/10. Loss: 1.4427:  38%|[36m███▊      [0m| 10/26 [00:09<00:15,  1.05it/s]Epoch: 0/10. Loss: 2.2169:  38%|[36m███▊      [0m| 10/26 [00:10<00:15,  1.05it/s]Epoch: 0/10. Loss: 2.2169:  42%|[36m████▏     [0m| 11/26 [00:10<00:13,  1.09it/s]Epoch: 0/10. Loss: 1.7027:  42%|[36m████▏     [0m| 11/26 [00:11<00:13,  1.09it/s]Epoch: 0/10. Loss: 1.7027:  46%|[36m████▌     [0m| 12/26 [00:11<00:13,  1.07it/s]Epoch: 0/10. Loss: 1.2314:  46%|[36m████▌     [0m| 12/26 [00:12<00:13,  1.07it/s]Epoch: 0/10. Loss: 1.2314:  50%|[36m█████     [0m| 13/26 [00:12<00:12,  1.05it/s]Epoch: 0/10. Loss: 1.1086:  50%|[36m█████     [0m| 13/26 [00:13<00:12,  1.05it/s]Epoch: 0/10. Loss: 1.1086:  54%|[36m█████▍    [0m| 14/26 [00:13<00:11,  1.06it/s]Epoch: 0/10. Loss: 1.0618:  54%|[36m█████▍    [0m| 14/26 [00:14<00:11,  1.06it/s]Epoch: 0/10. Loss: 1.0618:  58%|[36m█████▊    [0m| 15/26 [00:14<00:09,  1.11it/s]Epoch: 0/10. Loss: 1.0044:  58%|[36m█████▊    [0m| 15/26 [00:15<00:09,  1.11it/s]Epoch: 0/10. Loss: 1.0044:  62%|[36m██████▏   [0m| 16/26 [00:15<00:09,  1.10it/s]Epoch: 0/10. Loss: 1.0097:  62%|[36m██████▏   [0m| 16/26 [00:16<00:09,  1.10it/s]Epoch: 0/10. Loss: 1.0097:  65%|[36m██████▌   [0m| 17/26 [00:16<00:08,  1.12it/s]Epoch: 0/10. Loss: 2.9898:  65%|[36m██████▌   [0m| 17/26 [00:17<00:08,  1.12it/s]Epoch: 0/10. Loss: 2.9898:  69%|[36m██████▉   [0m| 18/26 [00:17<00:07,  1.03it/s]Epoch: 0/10. Loss: 1.0044:  69%|[36m██████▉   [0m| 18/26 [00:17<00:07,  1.03it/s]Epoch: 0/10. Loss: 1.0044:  73%|[36m███████▎  [0m| 19/26 [00:17<00:06,  1.09it/s]Epoch: 0/10. Loss: 1.7255:  73%|[36m███████▎  [0m| 19/26 [00:18<00:06,  1.09it/s]Epoch: 0/10. Loss: 1.7255:  77%|[36m███████▋  [0m| 20/26 [00:18<00:05,  1.06it/s]Epoch: 0/10. Loss: 1.0813:  77%|[36m███████▋  [0m| 20/26 [00:22<00:05,  1.06it/s]Epoch: 0/10. Loss: 1.0813:  81%|[36m████████  [0m| 21/26 [00:22<00:08,  1.78s/it]Epoch: 0/10. Loss: 1.1112:  81%|[36m████████  [0m| 21/26 [00:26<00:08,  1.78s/it]Epoch: 0/10. Loss: 1.1112:  85%|[36m████████▍ [0m| 22/26 [00:26<00:09,  2.35s/it]Epoch: 0/10. Loss: 0.9574:  85%|[36m████████▍ [0m| 22/26 [00:27<00:09,  2.35s/it]Epoch: 0/10. Loss: 0.9574:  88%|[36m████████▊ [0m| 23/26 [00:27<00:05,  1.94s/it]Epoch: 0/10. Loss: 1.3279:  88%|[36m████████▊ [0m| 23/26 [00:28<00:05,  1.94s/it]Epoch: 0/10. Loss: 1.3279:  92%|[36m█████████▏[0m| 24/26 [00:28<00:03,  1.66s/it]Epoch: 0/10. Loss: 0.9696:  92%|[36m█████████▏[0m| 24/26 [00:30<00:03,  1.66s/it]Epoch: 0/10. Loss: 0.9696:  96%|[36m█████████▌[0m| 25/26 [00:30<00:01,  1.69s/it]Epoch: 0/10. Loss: 1.8848:  96%|[36m█████████▌[0m| 25/26 [00:30<00:01,  1.69s/it]Epoch: 0/10. Loss: 1.8848: 100%|[36m██████████[0m| 26/26 [00:30<00:00,  1.40s/it]Epoch: 0/10. Loss: 1.8848: 100%|[36m██████████[0m| 26/26 [00:30<00:00,  1.19s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:05,  1.12it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:05,  1.10s/it] 43%|[33m████▎     [0m| 3/7 [00:02<00:03,  1.06it/s] 57%|[33m█████▋    [0m| 4/7 [00:05<00:04,  1.51s/it] 71%|[33m███████▏  [0m| 5/7 [00:05<00:02,  1.12s/it] 86%|[33m████████▌ [0m| 6/7 [00:06<00:01,  1.05s/it]100%|[33m██████████[0m| 7/7 [00:06<00:00,  1.25it/s]100%|[33m██████████[0m| 7/7 [00:06<00:00,  1.01it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 1/10. Loss: 1.1028:   0%|[36m          [0m| 0/26 [00:02<?, ?it/s]Epoch: 1/10. Loss: 1.1028:   4%|[36m▍         [0m| 1/26 [00:02<01:01,  2.44s/it]Epoch: 1/10. Loss: 1.1549:   4%|[36m▍         [0m| 1/26 [00:03<01:01,  2.44s/it]Epoch: 1/10. Loss: 1.1549:   8%|[36m▊         [0m| 2/26 [00:03<00:40,  1.70s/it]Epoch: 1/10. Loss: 1.1784:   8%|[36m▊         [0m| 2/26 [00:04<00:40,  1.70s/it]Epoch: 1/10. Loss: 1.1784:  12%|[36m█▏        [0m| 3/26 [00:04<00:34,  1.51s/it]Epoch: 1/10. Loss: 1.0296:  12%|[36m█▏        [0m| 3/26 [00:05<00:34,  1.51s/it]Epoch: 1/10. Loss: 1.0296:  15%|[36m█▌        [0m| 4/26 [00:05<00:28,  1.31s/it]Epoch: 1/10. Loss: 1.0003:  15%|[36m█▌        [0m| 4/26 [00:06<00:28,  1.31s/it]Epoch: 1/10. Loss: 1.0003:  19%|[36m█▉        [0m| 5/26 [00:06<00:25,  1.23s/it]Epoch: 1/10. Loss: 1.1125:  19%|[36m█▉        [0m| 5/26 [00:08<00:25,  1.23s/it]Epoch: 1/10. Loss: 1.1125:  23%|[36m██▎       [0m| 6/26 [00:08<00:27,  1.36s/it]Epoch: 1/10. Loss: 1.0962:  23%|[36m██▎       [0m| 6/26 [00:11<00:27,  1.36s/it]Epoch: 1/10. Loss: 1.0962:  27%|[36m██▋       [0m| 7/26 [00:11<00:36,  1.90s/it]Epoch: 1/10. Loss: 0.9684:  27%|[36m██▋       [0m| 7/26 [00:13<00:36,  1.90s/it]Epoch: 1/10. Loss: 0.9684:  31%|[36m███       [0m| 8/26 [00:13<00:33,  1.84s/it]Epoch: 1/10. Loss: 1.0109:  31%|[36m███       [0m| 8/26 [00:14<00:33,  1.84s/it]Epoch: 1/10. Loss: 1.0109:  35%|[36m███▍      [0m| 9/26 [00:14<00:29,  1.74s/it]Epoch: 1/10. Loss: 1.3236:  35%|[36m███▍      [0m| 9/26 [00:15<00:29,  1.74s/it]Epoch: 1/10. Loss: 1.3236:  38%|[36m███▊      [0m| 10/26 [00:15<00:24,  1.52s/it]Epoch: 1/10. Loss: 0.9767:  38%|[36m███▊      [0m| 10/26 [00:16<00:24,  1.52s/it]Epoch: 1/10. Loss: 0.9767:  42%|[36m████▏     [0m| 11/26 [00:16<00:19,  1.32s/it]Epoch: 1/10. Loss: 1.0721:  42%|[36m████▏     [0m| 11/26 [00:18<00:19,  1.32s/it]Epoch: 1/10. Loss: 1.0721:  46%|[36m████▌     [0m| 12/26 [00:18<00:18,  1.33s/it]Epoch: 1/10. Loss: 1.0948:  46%|[36m████▌     [0m| 12/26 [00:19<00:18,  1.33s/it]Epoch: 1/10. Loss: 1.0948:  50%|[36m█████     [0m| 13/26 [00:19<00:15,  1.23s/it]Epoch: 1/10. Loss: 1.1212:  50%|[36m█████     [0m| 13/26 [00:19<00:15,  1.23s/it]Epoch: 1/10. Loss: 1.1212:  54%|[36m█████▍    [0m| 14/26 [00:19<00:13,  1.13s/it]Epoch: 1/10. Loss: 1.0106:  54%|[36m█████▍    [0m| 14/26 [00:21<00:13,  1.13s/it]Epoch: 1/10. Loss: 1.0106:  58%|[36m█████▊    [0m| 15/26 [00:21<00:12,  1.15s/it]Epoch: 1/10. Loss: 1.4903:  58%|[36m█████▊    [0m| 15/26 [00:22<00:12,  1.15s/it]Epoch: 1/10. Loss: 1.4903:  62%|[36m██████▏   [0m| 16/26 [00:22<00:10,  1.06s/it]Epoch: 1/10. Loss: 1.2786:  62%|[36m██████▏   [0m| 16/26 [00:22<00:10,  1.06s/it]Epoch: 1/10. Loss: 1.2786:  65%|[36m██████▌   [0m| 17/26 [00:22<00:09,  1.02s/it]Epoch: 1/10. Loss: 0.9996:  65%|[36m██████▌   [0m| 17/26 [00:23<00:09,  1.02s/it]Epoch: 1/10. Loss: 0.9996:  69%|[36m██████▉   [0m| 18/26 [00:23<00:07,  1.02it/s]Epoch: 1/10. Loss: 1.1155:  69%|[36m██████▉   [0m| 18/26 [00:24<00:07,  1.02it/s]Epoch: 1/10. Loss: 1.1155:  73%|[36m███████▎  [0m| 19/26 [00:24<00:06,  1.05it/s]Epoch: 1/10. Loss: 1.0219:  73%|[36m███████▎  [0m| 19/26 [00:25<00:06,  1.05it/s]Epoch: 1/10. Loss: 1.0219:  77%|[36m███████▋  [0m| 20/26 [00:25<00:05,  1.07it/s]Epoch: 1/10. Loss: 1.0827:  77%|[36m███████▋  [0m| 20/26 [00:26<00:05,  1.07it/s]Epoch: 1/10. Loss: 1.0827:  81%|[36m████████  [0m| 21/26 [00:26<00:04,  1.05it/s]Epoch: 1/10. Loss: 0.9141:  81%|[36m████████  [0m| 21/26 [00:27<00:04,  1.05it/s]Epoch: 1/10. Loss: 0.9141:  85%|[36m████████▍ [0m| 22/26 [00:27<00:03,  1.11it/s]Epoch: 1/10. Loss: 0.9833:  85%|[36m████████▍ [0m| 22/26 [00:28<00:03,  1.11it/s]Epoch: 1/10. Loss: 0.9833:  88%|[36m████████▊ [0m| 23/26 [00:28<00:02,  1.11it/s]Epoch: 1/10. Loss: 0.9486:  88%|[36m████████▊ [0m| 23/26 [00:29<00:02,  1.11it/s]Epoch: 1/10. Loss: 0.9486:  92%|[36m█████████▏[0m| 24/26 [00:29<00:01,  1.11it/s]Epoch: 1/10. Loss: 1.0090:  92%|[36m█████████▏[0m| 24/26 [00:30<00:01,  1.11it/s]Epoch: 1/10. Loss: 1.0090:  96%|[36m█████████▌[0m| 25/26 [00:30<00:00,  1.09it/s]Epoch: 1/10. Loss: 1.0008:  96%|[36m█████████▌[0m| 25/26 [00:30<00:00,  1.09it/s]Epoch: 1/10. Loss: 1.0008: 100%|[36m██████████[0m| 26/26 [00:30<00:00,  1.18it/s]Epoch: 1/10. Loss: 1.0008: 100%|[36m██████████[0m| 26/26 [00:30<00:00,  1.19s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:05,  1.14it/s] 29%|[33m██▊       [0m| 2/7 [00:01<00:04,  1.01it/s] 43%|[33m████▎     [0m| 3/7 [00:02<00:03,  1.13it/s] 57%|[33m█████▋    [0m| 4/7 [00:04<00:03,  1.06s/it] 71%|[33m███████▏  [0m| 5/7 [00:04<00:01,  1.19it/s] 86%|[33m████████▌ [0m| 6/7 [00:05<00:00,  1.16it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.50it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.24it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 2/10. Loss: 1.1200:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 2/10. Loss: 1.1200:   4%|[36m▍         [0m| 1/26 [00:00<00:21,  1.17it/s]Epoch: 2/10. Loss: 1.1182:   4%|[36m▍         [0m| 1/26 [00:01<00:21,  1.17it/s]Epoch: 2/10. Loss: 1.1182:   8%|[36m▊         [0m| 2/26 [00:01<00:20,  1.19it/s]Epoch: 2/10. Loss: 1.1008:   8%|[36m▊         [0m| 2/26 [00:02<00:20,  1.19it/s]Epoch: 2/10. Loss: 1.1008:  12%|[36m█▏        [0m| 3/26 [00:02<00:20,  1.11it/s]Epoch: 2/10. Loss: 0.9805:  12%|[36m█▏        [0m| 3/26 [00:03<00:20,  1.11it/s]Epoch: 2/10. Loss: 0.9805:  15%|[36m█▌        [0m| 4/26 [00:03<00:21,  1.03it/s]Epoch: 2/10. Loss: 1.2416:  15%|[36m█▌        [0m| 4/26 [00:04<00:21,  1.03it/s]Epoch: 2/10. Loss: 1.2416:  19%|[36m█▉        [0m| 5/26 [00:04<00:19,  1.10it/s]Epoch: 2/10. Loss: 1.0015:  19%|[36m█▉        [0m| 5/26 [00:05<00:19,  1.10it/s]Epoch: 2/10. Loss: 1.0015:  23%|[36m██▎       [0m| 6/26 [00:05<00:18,  1.08it/s]Epoch: 2/10. Loss: 1.2066:  23%|[36m██▎       [0m| 6/26 [00:06<00:18,  1.08it/s]Epoch: 2/10. Loss: 1.2066:  27%|[36m██▋       [0m| 7/26 [00:06<00:18,  1.06it/s]Epoch: 2/10. Loss: 0.9907:  27%|[36m██▋       [0m| 7/26 [00:07<00:18,  1.06it/s]Epoch: 2/10. Loss: 0.9907:  31%|[36m███       [0m| 8/26 [00:07<00:16,  1.09it/s]Epoch: 2/10. Loss: 1.0611:  31%|[36m███       [0m| 8/26 [00:10<00:16,  1.09it/s]Epoch: 2/10. Loss: 1.0611:  35%|[36m███▍      [0m| 9/26 [00:10<00:28,  1.65s/it]Epoch: 2/10. Loss: 0.9842:  35%|[36m███▍      [0m| 9/26 [00:11<00:28,  1.65s/it]Epoch: 2/10. Loss: 0.9842:  38%|[36m███▊      [0m| 10/26 [00:11<00:22,  1.39s/it]Epoch: 2/10. Loss: 1.0429:  38%|[36m███▊      [0m| 10/26 [00:12<00:22,  1.39s/it]Epoch: 2/10. Loss: 1.0429:  42%|[36m████▏     [0m| 11/26 [00:12<00:18,  1.22s/it]Epoch: 2/10. Loss: 1.0940:  42%|[36m████▏     [0m| 11/26 [00:13<00:18,  1.22s/it]Epoch: 2/10. Loss: 1.0940:  46%|[36m████▌     [0m| 12/26 [00:13<00:15,  1.13s/it]Epoch: 2/10. Loss: 1.0810:  46%|[36m████▌     [0m| 12/26 [00:14<00:15,  1.13s/it]Epoch: 2/10. Loss: 1.0810:  50%|[36m█████     [0m| 13/26 [00:14<00:13,  1.06s/it]Epoch: 2/10. Loss: 1.0246:  50%|[36m█████     [0m| 13/26 [00:14<00:13,  1.06s/it]Epoch: 2/10. Loss: 1.0246:  54%|[36m█████▍    [0m| 14/26 [00:14<00:12,  1.01s/it]Epoch: 2/10. Loss: 1.0335:  54%|[36m█████▍    [0m| 14/26 [00:15<00:12,  1.01s/it]Epoch: 2/10. Loss: 1.0335:  58%|[36m█████▊    [0m| 15/26 [00:15<00:10,  1.03it/s]Epoch: 2/10. Loss: 0.9594:  58%|[36m█████▊    [0m| 15/26 [00:16<00:10,  1.03it/s]Epoch: 2/10. Loss: 0.9594:  62%|[36m██████▏   [0m| 16/26 [00:16<00:09,  1.06it/s]Epoch: 2/10. Loss: 1.5385:  62%|[36m██████▏   [0m| 16/26 [00:17<00:09,  1.06it/s]Epoch: 2/10. Loss: 1.5385:  65%|[36m██████▌   [0m| 17/26 [00:17<00:08,  1.07it/s]Epoch: 2/10. Loss: 1.0416:  65%|[36m██████▌   [0m| 17/26 [00:18<00:08,  1.07it/s]Epoch: 2/10. Loss: 1.0416:  69%|[36m██████▉   [0m| 18/26 [00:18<00:07,  1.05it/s]Epoch: 2/10. Loss: 1.0006:  69%|[36m██████▉   [0m| 18/26 [00:19<00:07,  1.05it/s]Epoch: 2/10. Loss: 1.0006:  73%|[36m███████▎  [0m| 19/26 [00:19<00:06,  1.00it/s]Epoch: 2/10. Loss: 1.0649:  73%|[36m███████▎  [0m| 19/26 [00:20<00:06,  1.00it/s]Epoch: 2/10. Loss: 1.0649:  77%|[36m███████▋  [0m| 20/26 [00:20<00:05,  1.03it/s]Epoch: 2/10. Loss: 1.0265:  77%|[36m███████▋  [0m| 20/26 [00:21<00:05,  1.03it/s]Epoch: 2/10. Loss: 1.0265:  81%|[36m████████  [0m| 21/26 [00:21<00:04,  1.11it/s]Epoch: 2/10. Loss: 1.5780:  81%|[36m████████  [0m| 21/26 [00:22<00:04,  1.11it/s]Epoch: 2/10. Loss: 1.5780:  85%|[36m████████▍ [0m| 22/26 [00:22<00:03,  1.17it/s]Epoch: 2/10. Loss: 1.0252:  85%|[36m████████▍ [0m| 22/26 [00:23<00:03,  1.17it/s]Epoch: 2/10. Loss: 1.0252:  88%|[36m████████▊ [0m| 23/26 [00:23<00:02,  1.14it/s]Epoch: 2/10. Loss: 1.0498:  88%|[36m████████▊ [0m| 23/26 [00:23<00:02,  1.14it/s]Epoch: 2/10. Loss: 1.0498:  92%|[36m█████████▏[0m| 24/26 [00:23<00:01,  1.13it/s]Epoch: 2/10. Loss: 0.9988:  92%|[36m█████████▏[0m| 24/26 [00:25<00:01,  1.13it/s]Epoch: 2/10. Loss: 0.9988:  96%|[36m█████████▌[0m| 25/26 [00:25<00:00,  1.03it/s]Epoch: 2/10. Loss: 0.9882:  96%|[36m█████████▌[0m| 25/26 [00:26<00:00,  1.03it/s]Epoch: 2/10. Loss: 0.9882: 100%|[36m██████████[0m| 26/26 [00:26<00:00,  1.04s/it]Epoch: 2/10. Loss: 0.9882: 100%|[36m██████████[0m| 26/26 [00:26<00:00,  1.01s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:01<00:09,  1.58s/it] 29%|[33m██▊       [0m| 2/7 [00:02<00:06,  1.28s/it] 43%|[33m████▎     [0m| 3/7 [00:03<00:04,  1.04s/it] 57%|[33m█████▋    [0m| 4/7 [00:05<00:03,  1.30s/it] 71%|[33m███████▏  [0m| 5/7 [00:05<00:01,  1.01it/s] 86%|[33m████████▌ [0m| 6/7 [00:06<00:00,  1.01it/s]100%|[33m██████████[0m| 7/7 [00:06<00:00,  1.33it/s]100%|[33m██████████[0m| 7/7 [00:06<00:00,  1.03it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 3/10. Loss: 1.0048:   0%|[36m          [0m| 0/26 [00:02<?, ?it/s]Epoch: 3/10. Loss: 1.0048:   4%|[36m▍         [0m| 1/26 [00:02<01:08,  2.76s/it]Epoch: 3/10. Loss: 1.0487:   4%|[36m▍         [0m| 1/26 [00:04<01:08,  2.76s/it]Epoch: 3/10. Loss: 1.0487:   8%|[36m▊         [0m| 2/26 [00:04<00:46,  1.93s/it]Epoch: 3/10. Loss: 1.0039:   8%|[36m▊         [0m| 2/26 [00:05<00:46,  1.93s/it]Epoch: 3/10. Loss: 1.0039:  12%|[36m█▏        [0m| 3/26 [00:05<00:38,  1.67s/it]Epoch: 3/10. Loss: 1.0163:  12%|[36m█▏        [0m| 3/26 [00:06<00:38,  1.67s/it]Epoch: 3/10. Loss: 1.0163:  15%|[36m█▌        [0m| 4/26 [00:06<00:30,  1.37s/it]Epoch: 3/10. Loss: 1.1506:  15%|[36m█▌        [0m| 4/26 [00:07<00:30,  1.37s/it]Epoch: 3/10. Loss: 1.1506:  19%|[36m█▉        [0m| 5/26 [00:07<00:23,  1.12s/it]Epoch: 3/10. Loss: 1.0308:  19%|[36m█▉        [0m| 5/26 [00:07<00:23,  1.12s/it]Epoch: 3/10. Loss: 1.0308:  23%|[36m██▎       [0m| 6/26 [00:08<00:21,  1.06s/it]Epoch: 3/10. Loss: 1.0237:  23%|[36m██▎       [0m| 6/26 [00:08<00:21,  1.06s/it]Epoch: 3/10. Loss: 1.0237:  27%|[36m██▋       [0m| 7/26 [00:08<00:19,  1.02s/it]Epoch: 3/10. Loss: 1.2139:  27%|[36m██▋       [0m| 7/26 [00:09<00:19,  1.02s/it]Epoch: 3/10. Loss: 1.2139:  31%|[36m███       [0m| 8/26 [00:09<00:17,  1.03it/s]Epoch: 3/10. Loss: 1.0368:  31%|[36m███       [0m| 8/26 [00:10<00:17,  1.03it/s]Epoch: 3/10. Loss: 1.0368:  35%|[36m███▍      [0m| 9/26 [00:10<00:17,  1.03s/it]Epoch: 3/10. Loss: 1.2828:  35%|[36m███▍      [0m| 9/26 [00:11<00:17,  1.03s/it]Epoch: 3/10. Loss: 1.2828:  38%|[36m███▊      [0m| 10/26 [00:12<00:16,  1.03s/it]Epoch: 3/10. Loss: 1.1814:  38%|[36m███▊      [0m| 10/26 [00:12<00:16,  1.03s/it]Epoch: 3/10. Loss: 1.1814:  42%|[36m████▏     [0m| 11/26 [00:12<00:14,  1.05it/s]Epoch: 3/10. Loss: 0.9485:  42%|[36m████▏     [0m| 11/26 [00:13<00:14,  1.05it/s]Epoch: 3/10. Loss: 0.9485:  46%|[36m████▌     [0m| 12/26 [00:13<00:13,  1.04it/s]Epoch: 3/10. Loss: 0.8545:  46%|[36m████▌     [0m| 12/26 [00:14<00:13,  1.04it/s]Epoch: 3/10. Loss: 0.8545:  50%|[36m█████     [0m| 13/26 [00:14<00:13,  1.01s/it]Epoch: 3/10. Loss: 1.0143:  50%|[36m█████     [0m| 13/26 [00:16<00:13,  1.01s/it]Epoch: 3/10. Loss: 1.0143:  54%|[36m█████▍    [0m| 14/26 [00:16<00:14,  1.20s/it]Epoch: 3/10. Loss: 1.0247:  54%|[36m█████▍    [0m| 14/26 [00:17<00:14,  1.20s/it]Epoch: 3/10. Loss: 1.0247:  58%|[36m█████▊    [0m| 15/26 [00:17<00:12,  1.10s/it]Epoch: 3/10. Loss: 1.0421:  58%|[36m█████▊    [0m| 15/26 [00:18<00:12,  1.10s/it]Epoch: 3/10. Loss: 1.0421:  62%|[36m██████▏   [0m| 16/26 [00:18<00:12,  1.24s/it]Epoch: 3/10. Loss: 0.9508:  62%|[36m██████▏   [0m| 16/26 [00:19<00:12,  1.24s/it]Epoch: 3/10. Loss: 0.9508:  65%|[36m██████▌   [0m| 17/26 [00:19<00:10,  1.15s/it]Epoch: 3/10. Loss: 0.9201:  65%|[36m██████▌   [0m| 17/26 [00:21<00:10,  1.15s/it]Epoch: 3/10. Loss: 0.9201:  69%|[36m██████▉   [0m| 18/26 [00:21<00:09,  1.20s/it]Epoch: 3/10. Loss: 0.9031:  69%|[36m██████▉   [0m| 18/26 [00:22<00:09,  1.20s/it]Epoch: 3/10. Loss: 0.9031:  73%|[36m███████▎  [0m| 19/26 [00:22<00:07,  1.14s/it]Epoch: 3/10. Loss: 1.0256:  73%|[36m███████▎  [0m| 19/26 [00:23<00:07,  1.14s/it]Epoch: 3/10. Loss: 1.0256:  77%|[36m███████▋  [0m| 20/26 [00:23<00:06,  1.05s/it]Epoch: 3/10. Loss: 0.8786:  77%|[36m███████▋  [0m| 20/26 [00:26<00:06,  1.05s/it]Epoch: 3/10. Loss: 0.8786:  81%|[36m████████  [0m| 21/26 [00:26<00:08,  1.69s/it]Epoch: 3/10. Loss: 0.9248:  81%|[36m████████  [0m| 21/26 [00:27<00:08,  1.69s/it]Epoch: 3/10. Loss: 0.9248:  85%|[36m████████▍ [0m| 22/26 [00:27<00:05,  1.43s/it]Epoch: 3/10. Loss: 1.0341:  85%|[36m████████▍ [0m| 22/26 [00:28<00:05,  1.43s/it]Epoch: 3/10. Loss: 1.0341:  88%|[36m████████▊ [0m| 23/26 [00:28<00:03,  1.31s/it]Epoch: 3/10. Loss: 1.0083:  88%|[36m████████▊ [0m| 23/26 [00:28<00:03,  1.31s/it]Epoch: 3/10. Loss: 1.0083:  92%|[36m█████████▏[0m| 24/26 [00:28<00:02,  1.17s/it]Epoch: 3/10. Loss: 0.9719:  92%|[36m█████████▏[0m| 24/26 [00:29<00:02,  1.17s/it]Epoch: 3/10. Loss: 0.9719:  96%|[36m█████████▌[0m| 25/26 [00:29<00:01,  1.09s/it]Epoch: 3/10. Loss: 0.8911:  96%|[36m█████████▌[0m| 25/26 [00:30<00:01,  1.09s/it]Epoch: 3/10. Loss: 0.8911: 100%|[36m██████████[0m| 26/26 [00:30<00:00,  1.10it/s]Epoch: 3/10. Loss: 0.8911: 100%|[36m██████████[0m| 26/26 [00:30<00:00,  1.17s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:01<00:08,  1.34s/it] 29%|[33m██▊       [0m| 2/7 [00:02<00:06,  1.36s/it] 43%|[33m████▎     [0m| 3/7 [00:03<00:04,  1.16s/it] 57%|[33m█████▋    [0m| 4/7 [00:05<00:04,  1.52s/it] 71%|[33m███████▏  [0m| 5/7 [00:06<00:02,  1.14s/it] 86%|[33m████████▌ [0m| 6/7 [00:07<00:01,  1.05s/it]100%|[33m██████████[0m| 7/7 [00:08<00:00,  1.11s/it]100%|[33m██████████[0m| 7/7 [00:08<00:00,  1.18s/it]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 4/10. Loss: 0.9153:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 4/10. Loss: 0.9153:   4%|[36m▍         [0m| 1/26 [00:00<00:20,  1.22it/s]Epoch: 4/10. Loss: 0.9535:   4%|[36m▍         [0m| 1/26 [00:02<00:20,  1.22it/s]Epoch: 4/10. Loss: 0.9535:   8%|[36m▊         [0m| 2/26 [00:02<00:31,  1.31s/it]Epoch: 4/10. Loss: 0.9003:   8%|[36m▊         [0m| 2/26 [00:03<00:31,  1.31s/it]Epoch: 4/10. Loss: 0.9003:  12%|[36m█▏        [0m| 3/26 [00:03<00:27,  1.19s/it]Epoch: 4/10. Loss: 1.2112:  12%|[36m█▏        [0m| 3/26 [00:05<00:27,  1.19s/it]Epoch: 4/10. Loss: 1.2112:  15%|[36m█▌        [0m| 4/26 [00:05<00:30,  1.40s/it]Epoch: 4/10. Loss: 1.1611:  15%|[36m█▌        [0m| 4/26 [00:06<00:30,  1.40s/it]Epoch: 4/10. Loss: 1.1611:  19%|[36m█▉        [0m| 5/26 [00:06<00:26,  1.26s/it]Epoch: 4/10. Loss: 0.9687:  19%|[36m█▉        [0m| 5/26 [00:07<00:26,  1.26s/it]Epoch: 4/10. Loss: 0.9687:  23%|[36m██▎       [0m| 6/26 [00:07<00:22,  1.15s/it]Epoch: 4/10. Loss: 0.9527:  23%|[36m██▎       [0m| 6/26 [00:08<00:22,  1.15s/it]Epoch: 4/10. Loss: 0.9527:  27%|[36m██▋       [0m| 7/26 [00:08<00:20,  1.07s/it]Epoch: 4/10. Loss: 0.9633:  27%|[36m██▋       [0m| 7/26 [00:08<00:20,  1.07s/it]Epoch: 4/10. Loss: 0.9633:  31%|[36m███       [0m| 8/26 [00:08<00:18,  1.00s/it]Epoch: 4/10. Loss: 0.9737:  31%|[36m███       [0m| 8/26 [00:09<00:18,  1.00s/it]Epoch: 4/10. Loss: 0.9737:  35%|[36m███▍      [0m| 9/26 [00:09<00:15,  1.07it/s]Epoch: 4/10. Loss: 0.8963:  35%|[36m███▍      [0m| 9/26 [00:11<00:15,  1.07it/s]Epoch: 4/10. Loss: 0.8963:  38%|[36m███▊      [0m| 10/26 [00:11<00:19,  1.21s/it]Epoch: 4/10. Loss: 0.9712:  38%|[36m███▊      [0m| 10/26 [00:12<00:19,  1.21s/it]Epoch: 4/10. Loss: 0.9712:  42%|[36m████▏     [0m| 11/26 [00:12<00:18,  1.22s/it]Epoch: 4/10. Loss: 0.9337:  42%|[36m████▏     [0m| 11/26 [00:13<00:18,  1.22s/it]Epoch: 4/10. Loss: 0.9337:  46%|[36m████▌     [0m| 12/26 [00:13<00:15,  1.12s/it]Epoch: 4/10. Loss: 0.9662:  46%|[36m████▌     [0m| 12/26 [00:14<00:15,  1.12s/it]Epoch: 4/10. Loss: 0.9662:  50%|[36m█████     [0m| 13/26 [00:14<00:13,  1.04s/it]Epoch: 4/10. Loss: 1.0312:  50%|[36m█████     [0m| 13/26 [00:15<00:13,  1.04s/it]Epoch: 4/10. Loss: 1.0312:  54%|[36m█████▍    [0m| 14/26 [00:15<00:11,  1.02it/s]Epoch: 4/10. Loss: 0.9430:  54%|[36m█████▍    [0m| 14/26 [00:16<00:11,  1.02it/s]Epoch: 4/10. Loss: 0.9430:  58%|[36m█████▊    [0m| 15/26 [00:16<00:10,  1.01it/s]Epoch: 4/10. Loss: 0.9413:  58%|[36m█████▊    [0m| 15/26 [00:17<00:10,  1.01it/s]Epoch: 4/10. Loss: 0.9413:  62%|[36m██████▏   [0m| 16/26 [00:17<00:10,  1.02s/it]Epoch: 4/10. Loss: 0.9488:  62%|[36m██████▏   [0m| 16/26 [00:18<00:10,  1.02s/it]Epoch: 4/10. Loss: 0.9488:  65%|[36m██████▌   [0m| 17/26 [00:18<00:08,  1.01it/s]Epoch: 4/10. Loss: 0.9801:  65%|[36m██████▌   [0m| 17/26 [00:19<00:08,  1.01it/s]Epoch: 4/10. Loss: 0.9801:  69%|[36m██████▉   [0m| 18/26 [00:19<00:07,  1.05it/s]Epoch: 4/10. Loss: 1.1350:  69%|[36m██████▉   [0m| 18/26 [00:19<00:07,  1.05it/s]Epoch: 4/10. Loss: 1.1350:  73%|[36m███████▎  [0m| 19/26 [00:19<00:06,  1.15it/s]Epoch: 4/10. Loss: 0.9163:  73%|[36m███████▎  [0m| 19/26 [00:21<00:06,  1.15it/s]Epoch: 4/10. Loss: 0.9163:  77%|[36m███████▋  [0m| 20/26 [00:21<00:07,  1.20s/it]Epoch: 4/10. Loss: 0.8819:  77%|[36m███████▋  [0m| 20/26 [00:22<00:07,  1.20s/it]Epoch: 4/10. Loss: 0.8819:  81%|[36m████████  [0m| 21/26 [00:22<00:05,  1.08s/it]Epoch: 4/10. Loss: 0.9687:  81%|[36m████████  [0m| 21/26 [00:23<00:05,  1.08s/it]Epoch: 4/10. Loss: 0.9687:  85%|[36m████████▍ [0m| 22/26 [00:23<00:04,  1.08s/it]Epoch: 4/10. Loss: 1.0037:  85%|[36m████████▍ [0m| 22/26 [00:24<00:04,  1.08s/it]Epoch: 4/10. Loss: 1.0037:  88%|[36m████████▊ [0m| 23/26 [00:24<00:03,  1.03s/it]Epoch: 4/10. Loss: 0.9841:  88%|[36m████████▊ [0m| 23/26 [00:25<00:03,  1.03s/it]Epoch: 4/10. Loss: 0.9841:  92%|[36m█████████▏[0m| 24/26 [00:25<00:02,  1.03s/it]Epoch: 4/10. Loss: 0.9196:  92%|[36m█████████▏[0m| 24/26 [00:26<00:02,  1.03s/it]Epoch: 4/10. Loss: 0.9196:  96%|[36m█████████▌[0m| 25/26 [00:26<00:00,  1.02it/s]Epoch: 4/10. Loss: 0.9919:  96%|[36m█████████▌[0m| 25/26 [00:27<00:00,  1.02it/s]Epoch: 4/10. Loss: 0.9919: 100%|[36m██████████[0m| 26/26 [00:27<00:00,  1.14it/s]Epoch: 4/10. Loss: 0.9919: 100%|[36m██████████[0m| 26/26 [00:27<00:00,  1.05s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:05,  1.16it/s] 29%|[33m██▊       [0m| 2/7 [00:01<00:04,  1.01it/s] 43%|[33m████▎     [0m| 3/7 [00:02<00:03,  1.12it/s] 57%|[33m█████▋    [0m| 4/7 [00:04<00:03,  1.07s/it] 71%|[33m███████▏  [0m| 5/7 [00:04<00:01,  1.18it/s] 86%|[33m████████▌ [0m| 6/7 [00:05<00:00,  1.15it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.49it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.23it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 5/10. Loss: 0.9895:   0%|[36m          [0m| 0/26 [00:01<?, ?it/s]Epoch: 5/10. Loss: 0.9895:   4%|[36m▍         [0m| 1/26 [00:01<00:36,  1.46s/it]Epoch: 5/10. Loss: 0.9728:   4%|[36m▍         [0m| 1/26 [00:02<00:36,  1.46s/it]Epoch: 5/10. Loss: 0.9728:   8%|[36m▊         [0m| 2/26 [00:02<00:30,  1.28s/it]Epoch: 5/10. Loss: 0.8844:   8%|[36m▊         [0m| 2/26 [00:03<00:30,  1.28s/it]Epoch: 5/10. Loss: 0.8844:  12%|[36m█▏        [0m| 3/26 [00:03<00:25,  1.09s/it]Epoch: 5/10. Loss: 1.0284:  12%|[36m█▏        [0m| 3/26 [00:04<00:25,  1.09s/it]Epoch: 5/10. Loss: 1.0284:  15%|[36m█▌        [0m| 4/26 [00:04<00:24,  1.09s/it]Epoch: 5/10. Loss: 0.9633:  15%|[36m█▌        [0m| 4/26 [00:05<00:24,  1.09s/it]Epoch: 5/10. Loss: 0.9633:  19%|[36m█▉        [0m| 5/26 [00:05<00:21,  1.03s/it]Epoch: 5/10. Loss: 0.8547:  19%|[36m█▉        [0m| 5/26 [00:06<00:21,  1.03s/it]Epoch: 5/10. Loss: 0.8547:  23%|[36m██▎       [0m| 6/26 [00:06<00:20,  1.04s/it]Epoch: 5/10. Loss: 0.9168:  23%|[36m██▎       [0m| 6/26 [00:07<00:20,  1.04s/it]Epoch: 5/10. Loss: 0.9168:  27%|[36m██▋       [0m| 7/26 [00:07<00:18,  1.02it/s]Epoch: 5/10. Loss: 0.9823:  27%|[36m██▋       [0m| 7/26 [00:08<00:18,  1.02it/s]Epoch: 5/10. Loss: 0.9823:  31%|[36m███       [0m| 8/26 [00:08<00:16,  1.06it/s]Epoch: 5/10. Loss: 0.9155:  31%|[36m███       [0m| 8/26 [00:09<00:16,  1.06it/s]Epoch: 5/10. Loss: 0.9155:  35%|[36m███▍      [0m| 9/26 [00:09<00:16,  1.04it/s]Epoch: 5/10. Loss: 1.0776:  35%|[36m███▍      [0m| 9/26 [00:10<00:16,  1.04it/s]Epoch: 5/10. Loss: 1.0776:  38%|[36m███▊      [0m| 10/26 [00:10<00:15,  1.05it/s]Epoch: 5/10. Loss: 0.8431:  38%|[36m███▊      [0m| 10/26 [00:11<00:15,  1.05it/s]Epoch: 5/10. Loss: 0.8431:  42%|[36m████▏     [0m| 11/26 [00:11<00:14,  1.06it/s]Epoch: 5/10. Loss: 1.0569:  42%|[36m████▏     [0m| 11/26 [00:12<00:14,  1.06it/s]Epoch: 5/10. Loss: 1.0569:  46%|[36m████▌     [0m| 12/26 [00:12<00:13,  1.05it/s]Epoch: 5/10. Loss: 1.0170:  46%|[36m████▌     [0m| 12/26 [00:13<00:13,  1.05it/s]Epoch: 5/10. Loss: 1.0170:  50%|[36m█████     [0m| 13/26 [00:13<00:13,  1.03s/it]Epoch: 5/10. Loss: 0.8850:  50%|[36m█████     [0m| 13/26 [00:14<00:13,  1.03s/it]Epoch: 5/10. Loss: 0.8850:  54%|[36m█████▍    [0m| 14/26 [00:14<00:11,  1.01it/s]Epoch: 5/10. Loss: 0.9445:  54%|[36m█████▍    [0m| 14/26 [00:14<00:11,  1.01it/s]Epoch: 5/10. Loss: 0.9445:  58%|[36m█████▊    [0m| 15/26 [00:14<00:09,  1.12it/s]Epoch: 5/10. Loss: 0.8333:  58%|[36m█████▊    [0m| 15/26 [00:15<00:09,  1.12it/s]Epoch: 5/10. Loss: 0.8333:  62%|[36m██████▏   [0m| 16/26 [00:15<00:09,  1.07it/s]Epoch: 5/10. Loss: 0.9944:  62%|[36m██████▏   [0m| 16/26 [00:16<00:09,  1.07it/s]Epoch: 5/10. Loss: 0.9944:  65%|[36m██████▌   [0m| 17/26 [00:16<00:07,  1.13it/s]Epoch: 5/10. Loss: 0.8867:  65%|[36m██████▌   [0m| 17/26 [00:18<00:07,  1.13it/s]Epoch: 5/10. Loss: 0.8867:  69%|[36m██████▉   [0m| 18/26 [00:18<00:08,  1.03s/it]Epoch: 5/10. Loss: 0.9001:  69%|[36m██████▉   [0m| 18/26 [00:18<00:08,  1.03s/it]Epoch: 5/10. Loss: 0.9001:  73%|[36m███████▎  [0m| 19/26 [00:18<00:06,  1.03it/s]Epoch: 5/10. Loss: 0.9582:  73%|[36m███████▎  [0m| 19/26 [00:19<00:06,  1.03it/s]Epoch: 5/10. Loss: 0.9582:  77%|[36m███████▋  [0m| 20/26 [00:19<00:05,  1.03it/s]Epoch: 5/10. Loss: 1.0137:  77%|[36m███████▋  [0m| 20/26 [00:21<00:05,  1.03it/s]Epoch: 5/10. Loss: 1.0137:  81%|[36m████████  [0m| 21/26 [00:21<00:05,  1.10s/it]Epoch: 5/10. Loss: 0.9874:  81%|[36m████████  [0m| 21/26 [00:21<00:05,  1.10s/it]Epoch: 5/10. Loss: 0.9874:  85%|[36m████████▍ [0m| 22/26 [00:21<00:03,  1.01it/s]Epoch: 5/10. Loss: 0.9898:  85%|[36m████████▍ [0m| 22/26 [00:22<00:03,  1.01it/s]Epoch: 5/10. Loss: 0.9898:  88%|[36m████████▊ [0m| 23/26 [00:22<00:02,  1.03it/s]Epoch: 5/10. Loss: 0.9379:  88%|[36m████████▊ [0m| 23/26 [00:23<00:02,  1.03it/s]Epoch: 5/10. Loss: 0.9379:  92%|[36m█████████▏[0m| 24/26 [00:23<00:01,  1.01it/s]Epoch: 5/10. Loss: 0.9052:  92%|[36m█████████▏[0m| 24/26 [00:24<00:01,  1.01it/s]Epoch: 5/10. Loss: 0.9052:  96%|[36m█████████▌[0m| 25/26 [00:24<00:00,  1.06it/s]Epoch: 5/10. Loss: 0.9588:  96%|[36m█████████▌[0m| 25/26 [00:25<00:00,  1.06it/s]Epoch: 5/10. Loss: 0.9588: 100%|[36m██████████[0m| 26/26 [00:25<00:00,  1.16it/s]Epoch: 5/10. Loss: 0.9588: 100%|[36m██████████[0m| 26/26 [00:25<00:00,  1.02it/s]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:05,  1.15it/s] 29%|[33m██▊       [0m| 2/7 [00:01<00:04,  1.00it/s] 43%|[33m████▎     [0m| 3/7 [00:02<00:03,  1.12it/s] 57%|[33m█████▋    [0m| 4/7 [00:04<00:03,  1.06s/it] 71%|[33m███████▏  [0m| 5/7 [00:04<00:01,  1.23it/s] 86%|[33m████████▌ [0m| 6/7 [00:05<00:00,  1.22it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.60it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.28it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 6/10. Loss: 0.9301:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 6/10. Loss: 0.9301:   4%|[36m▍         [0m| 1/26 [00:00<00:20,  1.21it/s]Epoch: 6/10. Loss: 0.9117:   4%|[36m▍         [0m| 1/26 [00:01<00:20,  1.21it/s]Epoch: 6/10. Loss: 0.9117:   8%|[36m▊         [0m| 2/26 [00:01<00:20,  1.17it/s]Epoch: 6/10. Loss: 1.0556:   8%|[36m▊         [0m| 2/26 [00:02<00:20,  1.17it/s]Epoch: 6/10. Loss: 1.0556:  12%|[36m█▏        [0m| 3/26 [00:02<00:23,  1.00s/it]Epoch: 6/10. Loss: 0.9174:  12%|[36m█▏        [0m| 3/26 [00:03<00:23,  1.00s/it]Epoch: 6/10. Loss: 0.9174:  15%|[36m█▌        [0m| 4/26 [00:03<00:21,  1.01it/s]Epoch: 6/10. Loss: 0.9251:  15%|[36m█▌        [0m| 4/26 [00:04<00:21,  1.01it/s]Epoch: 6/10. Loss: 0.9251:  19%|[36m█▉        [0m| 5/26 [00:04<00:19,  1.08it/s]Epoch: 6/10. Loss: 0.8745:  19%|[36m█▉        [0m| 5/26 [00:05<00:19,  1.08it/s]Epoch: 6/10. Loss: 0.8745:  23%|[36m██▎       [0m| 6/26 [00:05<00:19,  1.03it/s]Epoch: 6/10. Loss: 0.9429:  23%|[36m██▎       [0m| 6/26 [00:06<00:19,  1.03it/s]Epoch: 6/10. Loss: 0.9429:  27%|[36m██▋       [0m| 7/26 [00:06<00:17,  1.07it/s]Epoch: 6/10. Loss: 0.9535:  27%|[36m██▋       [0m| 7/26 [00:07<00:17,  1.07it/s]Epoch: 6/10. Loss: 0.9535:  31%|[36m███       [0m| 8/26 [00:07<00:15,  1.14it/s]Epoch: 6/10. Loss: 1.0507:  31%|[36m███       [0m| 8/26 [00:09<00:15,  1.14it/s]Epoch: 6/10. Loss: 1.0507:  35%|[36m███▍      [0m| 9/26 [00:09<00:19,  1.13s/it]Epoch: 6/10. Loss: 1.0760:  35%|[36m███▍      [0m| 9/26 [00:10<00:19,  1.13s/it]Epoch: 6/10. Loss: 1.0760:  38%|[36m███▊      [0m| 10/26 [00:10<00:19,  1.20s/it]Epoch: 6/10. Loss: 0.8656:  38%|[36m███▊      [0m| 10/26 [00:11<00:19,  1.20s/it]Epoch: 6/10. Loss: 0.8656:  42%|[36m████▏     [0m| 11/26 [00:11<00:16,  1.11s/it]Epoch: 6/10. Loss: 0.9340:  42%|[36m████▏     [0m| 11/26 [00:12<00:16,  1.11s/it]Epoch: 6/10. Loss: 0.9340:  46%|[36m████▌     [0m| 12/26 [00:12<00:14,  1.04s/it]Epoch: 6/10. Loss: 0.9454:  46%|[36m████▌     [0m| 12/26 [00:13<00:14,  1.04s/it]Epoch: 6/10. Loss: 0.9454:  50%|[36m█████     [0m| 13/26 [00:13<00:15,  1.16s/it]Epoch: 6/10. Loss: 0.8700:  50%|[36m█████     [0m| 13/26 [00:14<00:15,  1.16s/it]Epoch: 6/10. Loss: 0.8700:  54%|[36m█████▍    [0m| 14/26 [00:14<00:12,  1.07s/it]Epoch: 6/10. Loss: 1.0117:  54%|[36m█████▍    [0m| 14/26 [00:15<00:12,  1.07s/it]Epoch: 6/10. Loss: 1.0117:  58%|[36m█████▊    [0m| 15/26 [00:15<00:11,  1.00s/it]Epoch: 6/10. Loss: 0.9466:  58%|[36m█████▊    [0m| 15/26 [00:16<00:11,  1.00s/it]Epoch: 6/10. Loss: 0.9466:  62%|[36m██████▏   [0m| 16/26 [00:16<00:09,  1.07it/s]Epoch: 6/10. Loss: 0.8190:  62%|[36m██████▏   [0m| 16/26 [00:17<00:09,  1.07it/s]Epoch: 6/10. Loss: 0.8190:  65%|[36m██████▌   [0m| 17/26 [00:17<00:08,  1.05it/s]Epoch: 6/10. Loss: 0.9050:  65%|[36m██████▌   [0m| 17/26 [00:18<00:08,  1.05it/s]Epoch: 6/10. Loss: 0.9050:  69%|[36m██████▉   [0m| 18/26 [00:18<00:07,  1.03it/s]Epoch: 6/10. Loss: 0.8683:  69%|[36m██████▉   [0m| 18/26 [00:19<00:07,  1.03it/s]Epoch: 6/10. Loss: 0.8683:  73%|[36m███████▎  [0m| 19/26 [00:19<00:07,  1.09s/it]Epoch: 6/10. Loss: 0.9430:  73%|[36m███████▎  [0m| 19/26 [00:20<00:07,  1.09s/it]Epoch: 6/10. Loss: 0.9430:  77%|[36m███████▋  [0m| 20/26 [00:20<00:06,  1.06s/it]Epoch: 6/10. Loss: 0.7731:  77%|[36m███████▋  [0m| 20/26 [00:21<00:06,  1.06s/it]Epoch: 6/10. Loss: 0.7731:  81%|[36m████████  [0m| 21/26 [00:21<00:05,  1.02s/it]Epoch: 6/10. Loss: 0.9258:  81%|[36m████████  [0m| 21/26 [00:22<00:05,  1.02s/it]Epoch: 6/10. Loss: 0.9258:  85%|[36m████████▍ [0m| 22/26 [00:22<00:03,  1.00it/s]Epoch: 6/10. Loss: 1.0422:  85%|[36m████████▍ [0m| 22/26 [00:23<00:03,  1.00it/s]Epoch: 6/10. Loss: 1.0422:  88%|[36m████████▊ [0m| 23/26 [00:23<00:02,  1.01it/s]Epoch: 6/10. Loss: 0.9118:  88%|[36m████████▊ [0m| 23/26 [00:24<00:02,  1.01it/s]Epoch: 6/10. Loss: 0.9118:  92%|[36m█████████▏[0m| 24/26 [00:24<00:02,  1.05s/it]Epoch: 6/10. Loss: 0.9539:  92%|[36m█████████▏[0m| 24/26 [00:25<00:02,  1.05s/it]Epoch: 6/10. Loss: 0.9539:  96%|[36m█████████▌[0m| 25/26 [00:25<00:01,  1.01s/it]Epoch: 6/10. Loss: 0.9042:  96%|[36m█████████▌[0m| 25/26 [00:26<00:01,  1.01s/it]Epoch: 6/10. Loss: 0.9042: 100%|[36m██████████[0m| 26/26 [00:26<00:00,  1.09s/it]Epoch: 6/10. Loss: 0.9042: 100%|[36m██████████[0m| 26/26 [00:26<00:00,  1.03s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:01<00:09,  1.64s/it] 29%|[33m██▊       [0m| 2/7 [00:02<00:06,  1.33s/it] 43%|[33m████▎     [0m| 3/7 [00:03<00:04,  1.10s/it] 57%|[33m█████▋    [0m| 4/7 [00:04<00:03,  1.18s/it] 71%|[33m███████▏  [0m| 5/7 [00:05<00:01,  1.11it/s] 86%|[33m████████▌ [0m| 6/7 [00:06<00:00,  1.11it/s]100%|[33m██████████[0m| 7/7 [00:06<00:00,  1.46it/s]100%|[33m██████████[0m| 7/7 [00:06<00:00,  1.09it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 7/10. Loss: 0.9482:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 7/10. Loss: 0.9482:   4%|[36m▍         [0m| 1/26 [00:00<00:21,  1.19it/s]Epoch: 7/10. Loss: 0.9108:   4%|[36m▍         [0m| 1/26 [00:01<00:21,  1.19it/s]Epoch: 7/10. Loss: 0.9108:   8%|[36m▊         [0m| 2/26 [00:01<00:21,  1.12it/s]Epoch: 7/10. Loss: 0.8658:   8%|[36m▊         [0m| 2/26 [00:02<00:21,  1.12it/s]Epoch: 7/10. Loss: 0.8658:  12%|[36m█▏        [0m| 3/26 [00:02<00:20,  1.10it/s]Epoch: 7/10. Loss: 0.9437:  12%|[36m█▏        [0m| 3/26 [00:03<00:20,  1.10it/s]Epoch: 7/10. Loss: 0.9437:  15%|[36m█▌        [0m| 4/26 [00:03<00:20,  1.06it/s]Epoch: 7/10. Loss: 0.9670:  15%|[36m█▌        [0m| 4/26 [00:04<00:20,  1.06it/s]Epoch: 7/10. Loss: 0.9670:  19%|[36m█▉        [0m| 5/26 [00:04<00:17,  1.18it/s]Epoch: 7/10. Loss: 0.8371:  19%|[36m█▉        [0m| 5/26 [00:05<00:17,  1.18it/s]Epoch: 7/10. Loss: 0.8371:  23%|[36m██▎       [0m| 6/26 [00:05<00:16,  1.19it/s]Epoch: 7/10. Loss: 0.8442:  23%|[36m██▎       [0m| 6/26 [00:06<00:16,  1.19it/s]Epoch: 7/10. Loss: 0.8442:  27%|[36m██▋       [0m| 7/26 [00:06<00:16,  1.15it/s]Epoch: 7/10. Loss: 1.1434:  27%|[36m██▋       [0m| 7/26 [00:07<00:16,  1.15it/s]Epoch: 7/10. Loss: 1.1434:  31%|[36m███       [0m| 8/26 [00:07<00:16,  1.12it/s]Epoch: 7/10. Loss: 0.9250:  31%|[36m███       [0m| 8/26 [00:08<00:16,  1.12it/s]Epoch: 7/10. Loss: 0.9250:  35%|[36m███▍      [0m| 9/26 [00:08<00:15,  1.09it/s]Epoch: 7/10. Loss: 0.8310:  35%|[36m███▍      [0m| 9/26 [00:08<00:15,  1.09it/s]Epoch: 7/10. Loss: 0.8310:  38%|[36m███▊      [0m| 10/26 [00:08<00:14,  1.11it/s]Epoch: 7/10. Loss: 0.8683:  38%|[36m███▊      [0m| 10/26 [00:09<00:14,  1.11it/s]Epoch: 7/10. Loss: 0.8683:  42%|[36m████▏     [0m| 11/26 [00:09<00:13,  1.11it/s]Epoch: 7/10. Loss: 0.8935:  42%|[36m████▏     [0m| 11/26 [00:10<00:13,  1.11it/s]Epoch: 7/10. Loss: 0.8935:  46%|[36m████▌     [0m| 12/26 [00:10<00:12,  1.12it/s]Epoch: 7/10. Loss: 0.9553:  46%|[36m████▌     [0m| 12/26 [00:12<00:12,  1.12it/s]Epoch: 7/10. Loss: 0.9553:  50%|[36m█████     [0m| 13/26 [00:12<00:13,  1.07s/it]Epoch: 7/10. Loss: 0.9428:  50%|[36m█████     [0m| 13/26 [00:12<00:13,  1.07s/it]Epoch: 7/10. Loss: 0.9428:  54%|[36m█████▍    [0m| 14/26 [00:12<00:11,  1.03it/s]Epoch: 7/10. Loss: 0.8819:  54%|[36m█████▍    [0m| 14/26 [00:13<00:11,  1.03it/s]Epoch: 7/10. Loss: 0.8819:  58%|[36m█████▊    [0m| 15/26 [00:13<00:10,  1.06it/s]Epoch: 7/10. Loss: 0.9058:  58%|[36m█████▊    [0m| 15/26 [00:14<00:10,  1.06it/s]Epoch: 7/10. Loss: 0.9058:  62%|[36m██████▏   [0m| 16/26 [00:14<00:09,  1.08it/s]Epoch: 7/10. Loss: 0.9371:  62%|[36m██████▏   [0m| 16/26 [00:15<00:09,  1.08it/s]Epoch: 7/10. Loss: 0.9371:  65%|[36m██████▌   [0m| 17/26 [00:15<00:08,  1.06it/s]Epoch: 7/10. Loss: 0.9421:  65%|[36m██████▌   [0m| 17/26 [00:16<00:08,  1.06it/s]Epoch: 7/10. Loss: 0.9421:  69%|[36m██████▉   [0m| 18/26 [00:16<00:08,  1.02s/it]Epoch: 7/10. Loss: 0.8067:  69%|[36m██████▉   [0m| 18/26 [00:17<00:08,  1.02s/it]Epoch: 7/10. Loss: 0.8067:  73%|[36m███████▎  [0m| 19/26 [00:17<00:07,  1.04s/it]Epoch: 7/10. Loss: 0.8264:  73%|[36m███████▎  [0m| 19/26 [00:18<00:07,  1.04s/it]Epoch: 7/10. Loss: 0.8264:  77%|[36m███████▋  [0m| 20/26 [00:18<00:06,  1.02s/it]Epoch: 7/10. Loss: 0.8870:  77%|[36m███████▋  [0m| 20/26 [00:19<00:06,  1.02s/it]Epoch: 7/10. Loss: 0.8870:  81%|[36m████████  [0m| 21/26 [00:19<00:04,  1.02it/s]Epoch: 7/10. Loss: 0.9261:  81%|[36m████████  [0m| 21/26 [00:20<00:04,  1.02it/s]Epoch: 7/10. Loss: 0.9261:  85%|[36m████████▍ [0m| 22/26 [00:20<00:03,  1.11it/s]Epoch: 7/10. Loss: 0.7436:  85%|[36m████████▍ [0m| 22/26 [00:21<00:03,  1.11it/s]Epoch: 7/10. Loss: 0.7436:  88%|[36m████████▊ [0m| 23/26 [00:21<00:02,  1.06it/s]Epoch: 7/10. Loss: 0.8986:  88%|[36m████████▊ [0m| 23/26 [00:22<00:02,  1.06it/s]Epoch: 7/10. Loss: 0.8986:  92%|[36m█████████▏[0m| 24/26 [00:22<00:01,  1.05it/s]Epoch: 7/10. Loss: 0.8831:  92%|[36m█████████▏[0m| 24/26 [00:23<00:01,  1.05it/s]Epoch: 7/10. Loss: 0.8831:  96%|[36m█████████▌[0m| 25/26 [00:23<00:00,  1.01it/s]Epoch: 7/10. Loss: 0.8876:  96%|[36m█████████▌[0m| 25/26 [00:24<00:00,  1.01it/s]Epoch: 7/10. Loss: 0.8876: 100%|[36m██████████[0m| 26/26 [00:24<00:00,  1.16it/s]Epoch: 7/10. Loss: 0.8876: 100%|[36m██████████[0m| 26/26 [00:24<00:00,  1.08it/s]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:04,  1.27it/s] 29%|[33m██▊       [0m| 2/7 [00:01<00:04,  1.10it/s] 43%|[33m████▎     [0m| 3/7 [00:02<00:03,  1.24it/s] 57%|[33m█████▋    [0m| 4/7 [00:03<00:02,  1.04it/s] 71%|[33m███████▏  [0m| 5/7 [00:04<00:01,  1.32it/s] 86%|[33m████████▌ [0m| 6/7 [00:04<00:00,  1.28it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.65it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.36it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 8/10. Loss: 0.9892:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 8/10. Loss: 0.9892:   4%|[36m▍         [0m| 1/26 [00:01<00:25,  1.01s/it]Epoch: 8/10. Loss: 0.8885:   4%|[36m▍         [0m| 1/26 [00:01<00:25,  1.01s/it]Epoch: 8/10. Loss: 0.8885:   8%|[36m▊         [0m| 2/26 [00:01<00:21,  1.10it/s]Epoch: 8/10. Loss: 0.8619:   8%|[36m▊         [0m| 2/26 [00:02<00:21,  1.10it/s]Epoch: 8/10. Loss: 0.8619:  12%|[36m█▏        [0m| 3/26 [00:02<00:21,  1.05it/s]Epoch: 8/10. Loss: 0.8531:  12%|[36m█▏        [0m| 3/26 [00:03<00:21,  1.05it/s]Epoch: 8/10. Loss: 0.8531:  15%|[36m█▌        [0m| 4/26 [00:03<00:20,  1.07it/s]Epoch: 8/10. Loss: 0.8774:  15%|[36m█▌        [0m| 4/26 [00:04<00:20,  1.07it/s]Epoch: 8/10. Loss: 0.8774:  19%|[36m█▉        [0m| 5/26 [00:04<00:20,  1.03it/s]Epoch: 8/10. Loss: 0.9393:  19%|[36m█▉        [0m| 5/26 [00:05<00:20,  1.03it/s]Epoch: 8/10. Loss: 0.9393:  23%|[36m██▎       [0m| 6/26 [00:05<00:18,  1.10it/s]Epoch: 8/10. Loss: 0.8656:  23%|[36m██▎       [0m| 6/26 [00:06<00:18,  1.10it/s]Epoch: 8/10. Loss: 0.8656:  27%|[36m██▋       [0m| 7/26 [00:06<00:17,  1.10it/s]Epoch: 8/10. Loss: 0.8322:  27%|[36m██▋       [0m| 7/26 [00:07<00:17,  1.10it/s]Epoch: 8/10. Loss: 0.8322:  31%|[36m███       [0m| 8/26 [00:07<00:15,  1.13it/s]Epoch: 8/10. Loss: 0.8479:  31%|[36m███       [0m| 8/26 [00:08<00:15,  1.13it/s]Epoch: 8/10. Loss: 0.8479:  35%|[36m███▍      [0m| 9/26 [00:08<00:15,  1.11it/s]Epoch: 8/10. Loss: 0.9186:  35%|[36m███▍      [0m| 9/26 [00:09<00:15,  1.11it/s]Epoch: 8/10. Loss: 0.9186:  38%|[36m███▊      [0m| 10/26 [00:09<00:13,  1.16it/s]Epoch: 8/10. Loss: 0.8254:  38%|[36m███▊      [0m| 10/26 [00:10<00:13,  1.16it/s]Epoch: 8/10. Loss: 0.8254:  42%|[36m████▏     [0m| 11/26 [00:10<00:15,  1.06s/it]Epoch: 8/10. Loss: 0.8787:  42%|[36m████▏     [0m| 11/26 [00:11<00:15,  1.06s/it]Epoch: 8/10. Loss: 0.8787:  46%|[36m████▌     [0m| 12/26 [00:11<00:14,  1.06s/it]Epoch: 8/10. Loss: 0.8770:  46%|[36m████▌     [0m| 12/26 [00:12<00:14,  1.06s/it]Epoch: 8/10. Loss: 0.8770:  50%|[36m█████     [0m| 13/26 [00:12<00:14,  1.08s/it]Epoch: 8/10. Loss: 0.8329:  50%|[36m█████     [0m| 13/26 [00:14<00:14,  1.08s/it]Epoch: 8/10. Loss: 0.8329:  54%|[36m█████▍    [0m| 14/26 [00:14<00:15,  1.28s/it]Epoch: 8/10. Loss: 1.0270:  54%|[36m█████▍    [0m| 14/26 [00:15<00:15,  1.28s/it]Epoch: 8/10. Loss: 1.0270:  58%|[36m█████▊    [0m| 15/26 [00:15<00:12,  1.16s/it]Epoch: 8/10. Loss: 0.8985:  58%|[36m█████▊    [0m| 15/26 [00:16<00:12,  1.16s/it]Epoch: 8/10. Loss: 0.8985:  62%|[36m██████▏   [0m| 16/26 [00:16<00:10,  1.09s/it]Epoch: 8/10. Loss: 0.7922:  62%|[36m██████▏   [0m| 16/26 [00:17<00:10,  1.09s/it]Epoch: 8/10. Loss: 0.7922:  65%|[36m██████▌   [0m| 17/26 [00:17<00:09,  1.10s/it]Epoch: 8/10. Loss: 0.8794:  65%|[36m██████▌   [0m| 17/26 [00:18<00:09,  1.10s/it]Epoch: 8/10. Loss: 0.8794:  69%|[36m██████▉   [0m| 18/26 [00:18<00:08,  1.04s/it]Epoch: 8/10. Loss: 0.9145:  69%|[36m██████▉   [0m| 18/26 [00:19<00:08,  1.04s/it]Epoch: 8/10. Loss: 0.9145:  73%|[36m███████▎  [0m| 19/26 [00:19<00:08,  1.22s/it]Epoch: 8/10. Loss: 0.8205:  73%|[36m███████▎  [0m| 19/26 [00:20<00:08,  1.22s/it]Epoch: 8/10. Loss: 0.8205:  77%|[36m███████▋  [0m| 20/26 [00:20<00:06,  1.13s/it]Epoch: 8/10. Loss: 0.9446:  77%|[36m███████▋  [0m| 20/26 [00:21<00:06,  1.13s/it]Epoch: 8/10. Loss: 0.9446:  81%|[36m████████  [0m| 21/26 [00:21<00:05,  1.09s/it]Epoch: 8/10. Loss: 0.8146:  81%|[36m████████  [0m| 21/26 [00:22<00:05,  1.09s/it]Epoch: 8/10. Loss: 0.8146:  85%|[36m████████▍ [0m| 22/26 [00:22<00:04,  1.02s/it]Epoch: 8/10. Loss: 0.8231:  85%|[36m████████▍ [0m| 22/26 [00:24<00:04,  1.02s/it]Epoch: 8/10. Loss: 0.8231:  88%|[36m████████▊ [0m| 23/26 [00:24<00:03,  1.31s/it]Epoch: 8/10. Loss: 0.9515:  88%|[36m████████▊ [0m| 23/26 [00:25<00:03,  1.31s/it]Epoch: 8/10. Loss: 0.9515:  92%|[36m█████████▏[0m| 24/26 [00:25<00:02,  1.22s/it]Epoch: 8/10. Loss: 1.0204:  92%|[36m█████████▏[0m| 24/26 [00:26<00:02,  1.22s/it]Epoch: 8/10. Loss: 1.0204:  96%|[36m█████████▌[0m| 25/26 [00:26<00:01,  1.10s/it]Epoch: 8/10. Loss: 0.9188:  96%|[36m█████████▌[0m| 25/26 [00:27<00:01,  1.10s/it]Epoch: 8/10. Loss: 0.9188: 100%|[36m██████████[0m| 26/26 [00:27<00:00,  1.01s/it]Epoch: 8/10. Loss: 0.9188: 100%|[36m██████████[0m| 26/26 [00:27<00:00,  1.05s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:04,  1.21it/s] 29%|[33m██▊       [0m| 2/7 [00:01<00:04,  1.05it/s] 43%|[33m████▎     [0m| 3/7 [00:02<00:03,  1.19it/s] 57%|[33m█████▋    [0m| 4/7 [00:03<00:02,  1.01it/s] 71%|[33m███████▏  [0m| 5/7 [00:04<00:01,  1.28it/s] 86%|[33m████████▌ [0m| 6/7 [00:05<00:00,  1.04it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.37it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.21it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 9/10. Loss: 0.8930:   0%|[36m          [0m| 0/26 [00:01<?, ?it/s]Epoch: 9/10. Loss: 0.8930:   4%|[36m▍         [0m| 1/26 [00:01<00:41,  1.65s/it]Epoch: 9/10. Loss: 0.8733:   4%|[36m▍         [0m| 1/26 [00:02<00:41,  1.65s/it]Epoch: 9/10. Loss: 0.8733:   8%|[36m▊         [0m| 2/26 [00:02<00:30,  1.25s/it]Epoch: 9/10. Loss: 0.8805:   8%|[36m▊         [0m| 2/26 [00:03<00:30,  1.25s/it]Epoch: 9/10. Loss: 0.8805:  12%|[36m█▏        [0m| 3/26 [00:03<00:27,  1.21s/it]Epoch: 9/10. Loss: 0.9305:  12%|[36m█▏        [0m| 3/26 [00:04<00:27,  1.21s/it]Epoch: 9/10. Loss: 0.9305:  15%|[36m█▌        [0m| 4/26 [00:04<00:22,  1.05s/it]Epoch: 9/10. Loss: 0.8244:  15%|[36m█▌        [0m| 4/26 [00:05<00:22,  1.05s/it]Epoch: 9/10. Loss: 0.8244:  19%|[36m█▉        [0m| 5/26 [00:05<00:20,  1.03it/s]Epoch: 9/10. Loss: 1.0718:  19%|[36m█▉        [0m| 5/26 [00:06<00:20,  1.03it/s]Epoch: 9/10. Loss: 1.0718:  23%|[36m██▎       [0m| 6/26 [00:06<00:18,  1.09it/s]Epoch: 9/10. Loss: 0.9605:  23%|[36m██▎       [0m| 6/26 [00:07<00:18,  1.09it/s]Epoch: 9/10. Loss: 0.9605:  27%|[36m██▋       [0m| 7/26 [00:07<00:17,  1.11it/s]Epoch: 9/10. Loss: 0.9707:  27%|[36m██▋       [0m| 7/26 [00:07<00:17,  1.11it/s]Epoch: 9/10. Loss: 0.9707:  31%|[36m███       [0m| 8/26 [00:07<00:15,  1.14it/s]Epoch: 9/10. Loss: 0.8556:  31%|[36m███       [0m| 8/26 [00:08<00:15,  1.14it/s]Epoch: 9/10. Loss: 0.8556:  35%|[36m███▍      [0m| 9/26 [00:08<00:14,  1.16it/s]Epoch: 9/10. Loss: 0.9587:  35%|[36m███▍      [0m| 9/26 [00:09<00:14,  1.16it/s]Epoch: 9/10. Loss: 0.9587:  38%|[36m███▊      [0m| 10/26 [00:09<00:14,  1.12it/s]Epoch: 9/10. Loss: 0.9198:  38%|[36m███▊      [0m| 10/26 [00:10<00:14,  1.12it/s]Epoch: 9/10. Loss: 0.9198:  42%|[36m████▏     [0m| 11/26 [00:10<00:13,  1.11it/s]Epoch: 9/10. Loss: 0.9041:  42%|[36m████▏     [0m| 11/26 [00:13<00:13,  1.11it/s]Epoch: 9/10. Loss: 0.9041:  46%|[36m████▌     [0m| 12/26 [00:13<00:21,  1.54s/it]Epoch: 9/10. Loss: 0.9255:  46%|[36m████▌     [0m| 12/26 [00:15<00:21,  1.54s/it]Epoch: 9/10. Loss: 0.9255:  50%|[36m█████     [0m| 13/26 [00:15<00:21,  1.67s/it]Epoch: 9/10. Loss: 0.9249:  50%|[36m█████     [0m| 13/26 [00:16<00:21,  1.67s/it]Epoch: 9/10. Loss: 0.9249:  54%|[36m█████▍    [0m| 14/26 [00:16<00:17,  1.50s/it]Epoch: 9/10. Loss: 0.9162:  54%|[36m█████▍    [0m| 14/26 [00:17<00:17,  1.50s/it]Epoch: 9/10. Loss: 0.9162:  58%|[36m█████▊    [0m| 15/26 [00:17<00:14,  1.36s/it]Epoch: 9/10. Loss: 0.9183:  58%|[36m█████▊    [0m| 15/26 [00:19<00:14,  1.36s/it]Epoch: 9/10. Loss: 0.9183:  62%|[36m██████▏   [0m| 16/26 [00:19<00:15,  1.52s/it]Epoch: 9/10. Loss: 0.9198:  62%|[36m██████▏   [0m| 16/26 [00:21<00:15,  1.52s/it]Epoch: 9/10. Loss: 0.9198:  65%|[36m██████▌   [0m| 17/26 [00:21<00:15,  1.72s/it]Epoch: 9/10. Loss: 0.8794:  65%|[36m██████▌   [0m| 17/26 [00:23<00:15,  1.72s/it]Epoch: 9/10. Loss: 0.8794:  69%|[36m██████▉   [0m| 18/26 [00:23<00:14,  1.85s/it]Epoch: 9/10. Loss: 0.8388:  69%|[36m██████▉   [0m| 18/26 [00:28<00:14,  1.85s/it]Epoch: 9/10. Loss: 0.8388:  73%|[36m███████▎  [0m| 19/26 [00:28<00:18,  2.70s/it]Epoch: 9/10. Loss: 0.9604:  73%|[36m███████▎  [0m| 19/26 [00:29<00:18,  2.70s/it]Epoch: 9/10. Loss: 0.9604:  77%|[36m███████▋  [0m| 20/26 [00:29<00:13,  2.20s/it]Epoch: 9/10. Loss: 0.9317:  77%|[36m███████▋  [0m| 20/26 [00:30<00:13,  2.20s/it]Epoch: 9/10. Loss: 0.9317:  81%|[36m████████  [0m| 21/26 [00:30<00:09,  1.81s/it]Epoch: 9/10. Loss: 0.7698:  81%|[36m████████  [0m| 21/26 [00:32<00:09,  1.81s/it]Epoch: 9/10. Loss: 0.7698:  85%|[36m████████▍ [0m| 22/26 [00:32<00:07,  1.88s/it]Epoch: 9/10. Loss: 0.8094:  85%|[36m████████▍ [0m| 22/26 [00:35<00:07,  1.88s/it]Epoch: 9/10. Loss: 0.8094:  88%|[36m████████▊ [0m| 23/26 [00:35<00:06,  2.06s/it]Epoch: 9/10. Loss: 0.9446:  88%|[36m████████▊ [0m| 23/26 [00:36<00:06,  2.06s/it]Epoch: 9/10. Loss: 0.9446:  92%|[36m█████████▏[0m| 24/26 [00:36<00:03,  1.73s/it]Epoch: 9/10. Loss: 0.8175:  92%|[36m█████████▏[0m| 24/26 [00:36<00:03,  1.73s/it]Epoch: 9/10. Loss: 0.8175:  96%|[36m█████████▌[0m| 25/26 [00:36<00:01,  1.45s/it]Epoch: 9/10. Loss: 0.7714:  96%|[36m█████████▌[0m| 25/26 [00:37<00:01,  1.45s/it]Epoch: 9/10. Loss: 0.7714: 100%|[36m██████████[0m| 26/26 [00:37<00:00,  1.20s/it]Epoch: 9/10. Loss: 0.7714: 100%|[36m██████████[0m| 26/26 [00:37<00:00,  1.44s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:04,  1.24it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:06,  1.33s/it] 43%|[33m████▎     [0m| 3/7 [00:03<00:04,  1.05s/it] 57%|[33m█████▋    [0m| 4/7 [00:04<00:04,  1.33s/it] 71%|[33m███████▏  [0m| 5/7 [00:05<00:02,  1.00s/it] 86%|[33m████████▌ [0m| 6/7 [00:06<00:00,  1.04it/s]100%|[33m██████████[0m| 7/7 [00:06<00:00,  1.29it/s]100%|[33m██████████[0m| 7/7 [00:06<00:00,  1.05it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 0/10. Loss: 1.0728:   0%|[36m          [0m| 0/26 [00:01<?, ?it/s]Epoch: 0/10. Loss: 1.0728:   4%|[36m▍         [0m| 1/26 [00:01<00:25,  1.03s/it]Epoch: 0/10. Loss: 4.5699:   4%|[36m▍         [0m| 1/26 [00:01<00:25,  1.03s/it]Epoch: 0/10. Loss: 4.5699:   8%|[36m▊         [0m| 2/26 [00:01<00:23,  1.01it/s]Epoch: 0/10. Loss: 2.1361:   8%|[36m▊         [0m| 2/26 [00:02<00:23,  1.01it/s]Epoch: 0/10. Loss: 2.1361:  12%|[36m█▏        [0m| 3/26 [00:02<00:22,  1.02it/s]Epoch: 0/10. Loss: 1.6529:  12%|[36m█▏        [0m| 3/26 [00:04<00:22,  1.02it/s]Epoch: 0/10. Loss: 1.6529:  15%|[36m█▌        [0m| 4/26 [00:04<00:25,  1.14s/it]Epoch: 0/10. Loss: 1.3482:  15%|[36m█▌        [0m| 4/26 [00:05<00:25,  1.14s/it]Epoch: 0/10. Loss: 1.3482:  19%|[36m█▉        [0m| 5/26 [00:05<00:22,  1.07s/it]Epoch: 0/10. Loss: 1.1698:  19%|[36m█▉        [0m| 5/26 [00:06<00:22,  1.07s/it]Epoch: 0/10. Loss: 1.1698:  23%|[36m██▎       [0m| 6/26 [00:06<00:20,  1.03s/it]Epoch: 0/10. Loss: 1.1308:  23%|[36m██▎       [0m| 6/26 [00:07<00:20,  1.03s/it]Epoch: 0/10. Loss: 1.1308:  27%|[36m██▋       [0m| 7/26 [00:07<00:18,  1.01it/s]Epoch: 0/10. Loss: 1.2214:  27%|[36m██▋       [0m| 7/26 [00:07<00:18,  1.01it/s]Epoch: 0/10. Loss: 1.2214:  31%|[36m███       [0m| 8/26 [00:07<00:16,  1.08it/s]Epoch: 0/10. Loss: 1.2716:  31%|[36m███       [0m| 8/26 [00:08<00:16,  1.08it/s]Epoch: 0/10. Loss: 1.2716:  35%|[36m███▍      [0m| 9/26 [00:08<00:15,  1.11it/s]Epoch: 0/10. Loss: 1.1569:  35%|[36m███▍      [0m| 9/26 [00:09<00:15,  1.11it/s]Epoch: 0/10. Loss: 1.1569:  38%|[36m███▊      [0m| 10/26 [00:09<00:15,  1.05it/s]Epoch: 0/10. Loss: 1.1697:  38%|[36m███▊      [0m| 10/26 [00:10<00:15,  1.05it/s]Epoch: 0/10. Loss: 1.1697:  42%|[36m████▏     [0m| 11/26 [00:10<00:14,  1.05it/s]Epoch: 0/10. Loss: 1.3285:  42%|[36m████▏     [0m| 11/26 [00:11<00:14,  1.05it/s]Epoch: 0/10. Loss: 1.3285:  46%|[36m████▌     [0m| 12/26 [00:11<00:13,  1.06it/s]Epoch: 0/10. Loss: 1.3371:  46%|[36m████▌     [0m| 12/26 [00:13<00:13,  1.06it/s]Epoch: 0/10. Loss: 1.3371:  50%|[36m█████     [0m| 13/26 [00:13<00:13,  1.05s/it]Epoch: 0/10. Loss: 1.0505:  50%|[36m█████     [0m| 13/26 [00:13<00:13,  1.05s/it]Epoch: 0/10. Loss: 1.0505:  54%|[36m█████▍    [0m| 14/26 [00:13<00:11,  1.05it/s]Epoch: 0/10. Loss: 1.0977:  54%|[36m█████▍    [0m| 14/26 [00:14<00:11,  1.05it/s]Epoch: 0/10. Loss: 1.0977:  58%|[36m█████▊    [0m| 15/26 [00:14<00:09,  1.11it/s]Epoch: 0/10. Loss: 1.1976:  58%|[36m█████▊    [0m| 15/26 [00:15<00:09,  1.11it/s]Epoch: 0/10. Loss: 1.1976:  62%|[36m██████▏   [0m| 16/26 [00:15<00:09,  1.01it/s]Epoch: 0/10. Loss: 1.0683:  62%|[36m██████▏   [0m| 16/26 [00:16<00:09,  1.01it/s]Epoch: 0/10. Loss: 1.0683:  65%|[36m██████▌   [0m| 17/26 [00:16<00:09,  1.03s/it]Epoch: 0/10. Loss: 1.1317:  65%|[36m██████▌   [0m| 17/26 [00:17<00:09,  1.03s/it]Epoch: 0/10. Loss: 1.1317:  69%|[36m██████▉   [0m| 18/26 [00:17<00:08,  1.00s/it]Epoch: 0/10. Loss: 1.1099:  69%|[36m██████▉   [0m| 18/26 [00:18<00:08,  1.00s/it]Epoch: 0/10. Loss: 1.1099:  73%|[36m███████▎  [0m| 19/26 [00:18<00:06,  1.07it/s]Epoch: 0/10. Loss: 1.0017:  73%|[36m███████▎  [0m| 19/26 [00:19<00:06,  1.07it/s]Epoch: 0/10. Loss: 1.0017:  77%|[36m███████▋  [0m| 20/26 [00:19<00:05,  1.11it/s]Epoch: 0/10. Loss: 1.0098:  77%|[36m███████▋  [0m| 20/26 [00:20<00:05,  1.11it/s]Epoch: 0/10. Loss: 1.0098:  81%|[36m████████  [0m| 21/26 [00:20<00:04,  1.11it/s]Epoch: 0/10. Loss: 1.0540:  81%|[36m████████  [0m| 21/26 [00:21<00:04,  1.11it/s]Epoch: 0/10. Loss: 1.0540:  85%|[36m████████▍ [0m| 22/26 [00:21<00:03,  1.05it/s]Epoch: 0/10. Loss: 1.1557:  85%|[36m████████▍ [0m| 22/26 [00:22<00:03,  1.05it/s]Epoch: 0/10. Loss: 1.1557:  88%|[36m████████▊ [0m| 23/26 [00:22<00:02,  1.09it/s]Epoch: 0/10. Loss: 1.0773:  88%|[36m████████▊ [0m| 23/26 [00:23<00:02,  1.09it/s]Epoch: 0/10. Loss: 1.0773:  92%|[36m█████████▏[0m| 24/26 [00:23<00:01,  1.09it/s]Epoch: 0/10. Loss: 1.0280:  92%|[36m█████████▏[0m| 24/26 [00:24<00:01,  1.09it/s]Epoch: 0/10. Loss: 1.0280:  96%|[36m█████████▌[0m| 25/26 [00:24<00:01,  1.01s/it]Epoch: 0/10. Loss: 1.0383:  96%|[36m█████████▌[0m| 25/26 [00:24<00:01,  1.01s/it]Epoch: 0/10. Loss: 1.0383: 100%|[36m██████████[0m| 26/26 [00:24<00:00,  1.15it/s]Epoch: 0/10. Loss: 1.0383: 100%|[36m██████████[0m| 26/26 [00:24<00:00,  1.05it/s]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:04,  1.21it/s] 29%|[33m██▊       [0m| 2/7 [00:01<00:04,  1.04it/s] 43%|[33m████▎     [0m| 3/7 [00:02<00:03,  1.18it/s] 57%|[33m█████▋    [0m| 4/7 [00:03<00:03,  1.01s/it] 71%|[33m███████▏  [0m| 5/7 [00:04<00:01,  1.26it/s] 86%|[33m████████▌ [0m| 6/7 [00:05<00:01,  1.07s/it]100%|[33m██████████[0m| 7/7 [00:06<00:00,  1.24it/s]100%|[33m██████████[0m| 7/7 [00:06<00:00,  1.14it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 1/10. Loss: 1.0226:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 1/10. Loss: 1.0226:   4%|[36m▍         [0m| 1/26 [00:00<00:16,  1.55it/s]Epoch: 1/10. Loss: 1.0363:   4%|[36m▍         [0m| 1/26 [00:01<00:16,  1.55it/s]Epoch: 1/10. Loss: 1.0363:   8%|[36m▊         [0m| 2/26 [00:01<00:19,  1.22it/s]Epoch: 1/10. Loss: 1.0076:   8%|[36m▊         [0m| 2/26 [00:02<00:19,  1.22it/s]Epoch: 1/10. Loss: 1.0076:  12%|[36m█▏        [0m| 3/26 [00:02<00:20,  1.13it/s]Epoch: 1/10. Loss: 1.0125:  12%|[36m█▏        [0m| 3/26 [00:03<00:20,  1.13it/s]Epoch: 1/10. Loss: 1.0125:  15%|[36m█▌        [0m| 4/26 [00:03<00:20,  1.09it/s]Epoch: 1/10. Loss: 1.0725:  15%|[36m█▌        [0m| 4/26 [00:04<00:20,  1.09it/s]Epoch: 1/10. Loss: 1.0725:  19%|[36m█▉        [0m| 5/26 [00:04<00:18,  1.14it/s]Epoch: 1/10. Loss: 1.0710:  19%|[36m█▉        [0m| 5/26 [00:05<00:18,  1.14it/s]Epoch: 1/10. Loss: 1.0710:  23%|[36m██▎       [0m| 6/26 [00:05<00:18,  1.07it/s]Epoch: 1/10. Loss: 1.0399:  23%|[36m██▎       [0m| 6/26 [00:06<00:18,  1.07it/s]Epoch: 1/10. Loss: 1.0399:  27%|[36m██▋       [0m| 7/26 [00:06<00:19,  1.01s/it]Epoch: 1/10. Loss: 0.9926:  27%|[36m██▋       [0m| 7/26 [00:07<00:19,  1.01s/it]Epoch: 1/10. Loss: 0.9926:  31%|[36m███       [0m| 8/26 [00:07<00:17,  1.01it/s]Epoch: 1/10. Loss: 1.0018:  31%|[36m███       [0m| 8/26 [00:10<00:17,  1.01it/s]Epoch: 1/10. Loss: 1.0018:  35%|[36m███▍      [0m| 9/26 [00:10<00:27,  1.61s/it]Epoch: 1/10. Loss: 1.0361:  35%|[36m███▍      [0m| 9/26 [00:12<00:27,  1.61s/it]Epoch: 1/10. Loss: 1.0361:  38%|[36m███▊      [0m| 10/26 [00:12<00:26,  1.63s/it]Epoch: 1/10. Loss: 0.9716:  38%|[36m███▊      [0m| 10/26 [00:13<00:26,  1.63s/it]Epoch: 1/10. Loss: 0.9716:  42%|[36m████▏     [0m| 11/26 [00:13<00:21,  1.45s/it]Epoch: 1/10. Loss: 1.0874:  42%|[36m████▏     [0m| 11/26 [00:13<00:21,  1.45s/it]Epoch: 1/10. Loss: 1.0874:  46%|[36m████▌     [0m| 12/26 [00:13<00:17,  1.25s/it]Epoch: 1/10. Loss: 1.0103:  46%|[36m████▌     [0m| 12/26 [00:14<00:17,  1.25s/it]Epoch: 1/10. Loss: 1.0103:  50%|[36m█████     [0m| 13/26 [00:14<00:14,  1.15s/it]Epoch: 1/10. Loss: 0.9948:  50%|[36m█████     [0m| 13/26 [00:15<00:14,  1.15s/it]Epoch: 1/10. Loss: 0.9948:  54%|[36m█████▍    [0m| 14/26 [00:15<00:13,  1.11s/it]Epoch: 1/10. Loss: 0.9920:  54%|[36m█████▍    [0m| 14/26 [00:16<00:13,  1.11s/it]Epoch: 1/10. Loss: 0.9920:  58%|[36m█████▊    [0m| 15/26 [00:16<00:11,  1.07s/it]Epoch: 1/10. Loss: 0.9791:  58%|[36m█████▊    [0m| 15/26 [00:17<00:11,  1.07s/it]Epoch: 1/10. Loss: 0.9791:  62%|[36m██████▏   [0m| 16/26 [00:17<00:10,  1.00s/it]Epoch: 1/10. Loss: 1.0032:  62%|[36m██████▏   [0m| 16/26 [00:18<00:10,  1.00s/it]Epoch: 1/10. Loss: 1.0032:  65%|[36m██████▌   [0m| 17/26 [00:18<00:09,  1.00s/it]Epoch: 1/10. Loss: 0.9813:  65%|[36m██████▌   [0m| 17/26 [00:19<00:09,  1.00s/it]Epoch: 1/10. Loss: 0.9813:  69%|[36m██████▉   [0m| 18/26 [00:19<00:07,  1.02it/s]Epoch: 1/10. Loss: 1.0460:  69%|[36m██████▉   [0m| 18/26 [00:20<00:07,  1.02it/s]Epoch: 1/10. Loss: 1.0460:  73%|[36m███████▎  [0m| 19/26 [00:20<00:06,  1.03it/s]Epoch: 1/10. Loss: 0.9917:  73%|[36m███████▎  [0m| 19/26 [00:21<00:06,  1.03it/s]Epoch: 1/10. Loss: 0.9917:  77%|[36m███████▋  [0m| 20/26 [00:21<00:05,  1.10it/s]Epoch: 1/10. Loss: 0.9584:  77%|[36m███████▋  [0m| 20/26 [00:24<00:05,  1.10it/s]Epoch: 1/10. Loss: 0.9584:  81%|[36m████████  [0m| 21/26 [00:24<00:08,  1.67s/it]Epoch: 1/10. Loss: 1.0171:  81%|[36m████████  [0m| 21/26 [00:26<00:08,  1.67s/it]Epoch: 1/10. Loss: 1.0171:  85%|[36m████████▍ [0m| 22/26 [00:26<00:07,  1.76s/it]Epoch: 1/10. Loss: 0.9759:  85%|[36m████████▍ [0m| 22/26 [00:27<00:07,  1.76s/it]Epoch: 1/10. Loss: 0.9759:  88%|[36m████████▊ [0m| 23/26 [00:27<00:04,  1.51s/it]Epoch: 1/10. Loss: 0.9890:  88%|[36m████████▊ [0m| 23/26 [00:28<00:04,  1.51s/it]Epoch: 1/10. Loss: 0.9890:  92%|[36m█████████▏[0m| 24/26 [00:28<00:02,  1.30s/it]Epoch: 1/10. Loss: 1.1053:  92%|[36m█████████▏[0m| 24/26 [00:30<00:02,  1.30s/it]Epoch: 1/10. Loss: 1.1053:  96%|[36m█████████▌[0m| 25/26 [00:30<00:01,  1.48s/it]Epoch: 1/10. Loss: 1.0489:  96%|[36m█████████▌[0m| 25/26 [00:31<00:01,  1.48s/it]Epoch: 1/10. Loss: 1.0489: 100%|[36m██████████[0m| 26/26 [00:31<00:00,  1.23s/it]Epoch: 1/10. Loss: 1.0489: 100%|[36m██████████[0m| 26/26 [00:31<00:00,  1.19s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:05,  1.15it/s] 29%|[33m██▊       [0m| 2/7 [00:01<00:05,  1.01s/it] 43%|[33m████▎     [0m| 3/7 [00:02<00:03,  1.14it/s] 57%|[33m█████▋    [0m| 4/7 [00:03<00:03,  1.02s/it] 71%|[33m███████▏  [0m| 5/7 [00:04<00:01,  1.24it/s] 86%|[33m████████▌ [0m| 6/7 [00:05<00:00,  1.20it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.54it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.27it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 2/10. Loss: 1.0554:   0%|[36m          [0m| 0/26 [00:02<?, ?it/s]Epoch: 2/10. Loss: 1.0554:   4%|[36m▍         [0m| 1/26 [00:02<00:52,  2.11s/it]Epoch: 2/10. Loss: 1.0404:   4%|[36m▍         [0m| 1/26 [00:04<00:52,  2.11s/it]Epoch: 2/10. Loss: 1.0404:   8%|[36m▊         [0m| 2/26 [00:04<00:54,  2.25s/it]Epoch: 2/10. Loss: 1.0788:   8%|[36m▊         [0m| 2/26 [00:06<00:54,  2.25s/it]Epoch: 2/10. Loss: 1.0788:  12%|[36m█▏        [0m| 3/26 [00:06<00:52,  2.29s/it]Epoch: 2/10. Loss: 1.2609:  12%|[36m█▏        [0m| 3/26 [00:08<00:52,  2.29s/it]Epoch: 2/10. Loss: 1.2609:  15%|[36m█▌        [0m| 4/26 [00:08<00:41,  1.90s/it]Epoch: 2/10. Loss: 1.0814:  15%|[36m█▌        [0m| 4/26 [00:09<00:41,  1.90s/it]Epoch: 2/10. Loss: 1.0814:  19%|[36m█▉        [0m| 5/26 [00:09<00:36,  1.74s/it]Epoch: 2/10. Loss: 1.0277:  19%|[36m█▉        [0m| 5/26 [00:10<00:36,  1.74s/it]Epoch: 2/10. Loss: 1.0277:  23%|[36m██▎       [0m| 6/26 [00:10<00:28,  1.44s/it]Epoch: 2/10. Loss: 1.0042:  23%|[36m██▎       [0m| 6/26 [00:14<00:28,  1.44s/it]Epoch: 2/10. Loss: 1.0042:  27%|[36m██▋       [0m| 7/26 [00:14<00:40,  2.15s/it]Epoch: 2/10. Loss: 1.0545:  27%|[36m██▋       [0m| 7/26 [00:15<00:40,  2.15s/it]Epoch: 2/10. Loss: 1.0545:  31%|[36m███       [0m| 8/26 [00:15<00:35,  1.98s/it]Epoch: 2/10. Loss: 1.0020:  31%|[36m███       [0m| 8/26 [00:19<00:35,  1.98s/it]Epoch: 2/10. Loss: 1.0020:  35%|[36m███▍      [0m| 9/26 [00:19<00:41,  2.42s/it]Epoch: 2/10. Loss: 0.8823:  35%|[36m███▍      [0m| 9/26 [00:19<00:41,  2.42s/it]Epoch: 2/10. Loss: 0.8823:  38%|[36m███▊      [0m| 10/26 [00:19<00:30,  1.93s/it]Epoch: 2/10. Loss: 1.0084:  38%|[36m███▊      [0m| 10/26 [00:20<00:30,  1.93s/it]Epoch: 2/10. Loss: 1.0084:  42%|[36m████▏     [0m| 11/26 [00:20<00:24,  1.61s/it]Epoch: 2/10. Loss: 1.0176:  42%|[36m████▏     [0m| 11/26 [00:21<00:24,  1.61s/it]Epoch: 2/10. Loss: 1.0176:  46%|[36m████▌     [0m| 12/26 [00:21<00:18,  1.36s/it]Epoch: 2/10. Loss: 1.1755:  46%|[36m████▌     [0m| 12/26 [00:22<00:18,  1.36s/it]Epoch: 2/10. Loss: 1.1755:  50%|[36m█████     [0m| 13/26 [00:22<00:15,  1.23s/it]Epoch: 2/10. Loss: 0.9832:  50%|[36m█████     [0m| 13/26 [00:24<00:15,  1.23s/it]Epoch: 2/10. Loss: 0.9832:  54%|[36m█████▍    [0m| 14/26 [00:24<00:17,  1.43s/it]Epoch: 2/10. Loss: 1.0078:  54%|[36m█████▍    [0m| 14/26 [00:25<00:17,  1.43s/it]Epoch: 2/10. Loss: 1.0078:  58%|[36m█████▊    [0m| 15/26 [00:25<00:14,  1.32s/it]Epoch: 2/10. Loss: 1.0199:  58%|[36m█████▊    [0m| 15/26 [00:26<00:14,  1.32s/it]Epoch: 2/10. Loss: 1.0199:  62%|[36m██████▏   [0m| 16/26 [00:26<00:12,  1.21s/it]Epoch: 2/10. Loss: 1.0105:  62%|[36m██████▏   [0m| 16/26 [00:27<00:12,  1.21s/it]Epoch: 2/10. Loss: 1.0105:  65%|[36m██████▌   [0m| 17/26 [00:27<00:10,  1.14s/it]Epoch: 2/10. Loss: 0.9898:  65%|[36m██████▌   [0m| 17/26 [00:28<00:10,  1.14s/it]Epoch: 2/10. Loss: 0.9898:  69%|[36m██████▉   [0m| 18/26 [00:28<00:08,  1.10s/it]Epoch: 2/10. Loss: 0.9348:  69%|[36m██████▉   [0m| 18/26 [00:29<00:08,  1.10s/it]Epoch: 2/10. Loss: 0.9348:  73%|[36m███████▎  [0m| 19/26 [00:29<00:06,  1.01it/s]Epoch: 2/10. Loss: 1.0777:  73%|[36m███████▎  [0m| 19/26 [00:29<00:06,  1.01it/s]Epoch: 2/10. Loss: 1.0777:  77%|[36m███████▋  [0m| 20/26 [00:29<00:05,  1.03it/s]Epoch: 2/10. Loss: 1.0270:  77%|[36m███████▋  [0m| 20/26 [00:30<00:05,  1.03it/s]Epoch: 2/10. Loss: 1.0270:  81%|[36m████████  [0m| 21/26 [00:30<00:04,  1.06it/s]Epoch: 2/10. Loss: 1.0016:  81%|[36m████████  [0m| 21/26 [00:31<00:04,  1.06it/s]Epoch: 2/10. Loss: 1.0016:  85%|[36m████████▍ [0m| 22/26 [00:31<00:03,  1.04it/s]Epoch: 2/10. Loss: 0.9260:  85%|[36m████████▍ [0m| 22/26 [00:32<00:03,  1.04it/s]Epoch: 2/10. Loss: 0.9260:  88%|[36m████████▊ [0m| 23/26 [00:32<00:02,  1.08it/s]Epoch: 2/10. Loss: 0.9767:  88%|[36m████████▊ [0m| 23/26 [00:33<00:02,  1.08it/s]Epoch: 2/10. Loss: 0.9767:  92%|[36m█████████▏[0m| 24/26 [00:33<00:01,  1.06it/s]Epoch: 2/10. Loss: 0.9698:  92%|[36m█████████▏[0m| 24/26 [00:34<00:01,  1.06it/s]Epoch: 2/10. Loss: 0.9698:  96%|[36m█████████▌[0m| 25/26 [00:34<00:00,  1.11it/s]Epoch: 2/10. Loss: 0.8988:  96%|[36m█████████▌[0m| 25/26 [00:35<00:00,  1.11it/s]Epoch: 2/10. Loss: 0.8988: 100%|[36m██████████[0m| 26/26 [00:35<00:00,  1.20it/s]Epoch: 2/10. Loss: 0.8988: 100%|[36m██████████[0m| 26/26 [00:35<00:00,  1.35s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:04,  1.27it/s] 29%|[33m██▊       [0m| 2/7 [00:01<00:04,  1.12it/s] 43%|[33m████▎     [0m| 3/7 [00:02<00:03,  1.27it/s] 57%|[33m█████▋    [0m| 4/7 [00:03<00:02,  1.08it/s] 71%|[33m███████▏  [0m| 5/7 [00:03<00:01,  1.38it/s] 86%|[33m████████▌ [0m| 6/7 [00:04<00:00,  1.35it/s]100%|[33m██████████[0m| 7/7 [00:04<00:00,  1.73it/s]100%|[33m██████████[0m| 7/7 [00:04<00:00,  1.42it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 3/10. Loss: 1.0396:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 3/10. Loss: 1.0396:   4%|[36m▍         [0m| 1/26 [00:00<00:23,  1.07it/s]Epoch: 3/10. Loss: 1.0529:   4%|[36m▍         [0m| 1/26 [00:01<00:23,  1.07it/s]Epoch: 3/10. Loss: 1.0529:   8%|[36m▊         [0m| 2/26 [00:01<00:21,  1.13it/s]Epoch: 3/10. Loss: 0.9344:   8%|[36m▊         [0m| 2/26 [00:02<00:21,  1.13it/s]Epoch: 3/10. Loss: 0.9344:  12%|[36m█▏        [0m| 3/26 [00:02<00:21,  1.06it/s]Epoch: 3/10. Loss: 0.9524:  12%|[36m█▏        [0m| 3/26 [00:03<00:21,  1.06it/s]Epoch: 3/10. Loss: 0.9524:  15%|[36m█▌        [0m| 4/26 [00:03<00:21,  1.03it/s]Epoch: 3/10. Loss: 0.9615:  15%|[36m█▌        [0m| 4/26 [00:04<00:21,  1.03it/s]Epoch: 3/10. Loss: 0.9615:  19%|[36m█▉        [0m| 5/26 [00:04<00:19,  1.06it/s]Epoch: 3/10. Loss: 0.9580:  19%|[36m█▉        [0m| 5/26 [00:05<00:19,  1.06it/s]Epoch: 3/10. Loss: 0.9580:  23%|[36m██▎       [0m| 6/26 [00:05<00:18,  1.06it/s]Epoch: 3/10. Loss: 0.9152:  23%|[36m██▎       [0m| 6/26 [00:06<00:18,  1.06it/s]Epoch: 3/10. Loss: 0.9152:  27%|[36m██▋       [0m| 7/26 [00:06<00:18,  1.05it/s]Epoch: 3/10. Loss: 1.0457:  27%|[36m██▋       [0m| 7/26 [00:07<00:18,  1.05it/s]Epoch: 3/10. Loss: 1.0457:  31%|[36m███       [0m| 8/26 [00:07<00:18,  1.00s/it]Epoch: 3/10. Loss: 1.0062:  31%|[36m███       [0m| 8/26 [00:08<00:18,  1.00s/it]Epoch: 3/10. Loss: 1.0062:  35%|[36m███▍      [0m| 9/26 [00:08<00:16,  1.05it/s]Epoch: 3/10. Loss: 0.9855:  35%|[36m███▍      [0m| 9/26 [00:09<00:16,  1.05it/s]Epoch: 3/10. Loss: 0.9855:  38%|[36m███▊      [0m| 10/26 [00:09<00:15,  1.01it/s]Epoch: 3/10. Loss: 0.9863:  38%|[36m███▊      [0m| 10/26 [00:10<00:15,  1.01it/s]Epoch: 3/10. Loss: 0.9863:  42%|[36m████▏     [0m| 11/26 [00:10<00:15,  1.02s/it]Epoch: 3/10. Loss: 0.9659:  42%|[36m████▏     [0m| 11/26 [00:11<00:15,  1.02s/it]Epoch: 3/10. Loss: 0.9659:  46%|[36m████▌     [0m| 12/26 [00:11<00:14,  1.01s/it]Epoch: 3/10. Loss: 0.8940:  46%|[36m████▌     [0m| 12/26 [00:12<00:14,  1.01s/it]Epoch: 3/10. Loss: 0.8940:  50%|[36m█████     [0m| 13/26 [00:12<00:12,  1.04it/s]Epoch: 3/10. Loss: 0.9807:  50%|[36m█████     [0m| 13/26 [00:13<00:12,  1.04it/s]Epoch: 3/10. Loss: 0.9807:  54%|[36m█████▍    [0m| 14/26 [00:13<00:10,  1.10it/s]Epoch: 3/10. Loss: 1.0509:  54%|[36m█████▍    [0m| 14/26 [00:14<00:10,  1.10it/s]Epoch: 3/10. Loss: 1.0509:  58%|[36m█████▊    [0m| 15/26 [00:14<00:09,  1.10it/s]Epoch: 3/10. Loss: 0.9600:  58%|[36m█████▊    [0m| 15/26 [00:15<00:09,  1.10it/s]Epoch: 3/10. Loss: 0.9600:  62%|[36m██████▏   [0m| 16/26 [00:15<00:09,  1.09it/s]Epoch: 3/10. Loss: 1.0347:  62%|[36m██████▏   [0m| 16/26 [00:16<00:09,  1.09it/s]Epoch: 3/10. Loss: 1.0347:  65%|[36m██████▌   [0m| 17/26 [00:16<00:08,  1.04it/s]Epoch: 3/10. Loss: 1.0310:  65%|[36m██████▌   [0m| 17/26 [00:17<00:08,  1.04it/s]Epoch: 3/10. Loss: 1.0310:  69%|[36m██████▉   [0m| 18/26 [00:17<00:07,  1.12it/s]Epoch: 3/10. Loss: 1.0806:  69%|[36m██████▉   [0m| 18/26 [00:18<00:07,  1.12it/s]Epoch: 3/10. Loss: 1.0806:  73%|[36m███████▎  [0m| 19/26 [00:18<00:08,  1.22s/it]Epoch: 3/10. Loss: 0.9250:  73%|[36m███████▎  [0m| 19/26 [00:19<00:08,  1.22s/it]Epoch: 3/10. Loss: 0.9250:  77%|[36m███████▋  [0m| 20/26 [00:19<00:06,  1.13s/it]Epoch: 3/10. Loss: 0.8833:  77%|[36m███████▋  [0m| 20/26 [00:20<00:06,  1.13s/it]Epoch: 3/10. Loss: 0.8833:  81%|[36m████████  [0m| 21/26 [00:20<00:05,  1.11s/it]Epoch: 3/10. Loss: 0.8260:  81%|[36m████████  [0m| 21/26 [00:23<00:05,  1.11s/it]Epoch: 3/10. Loss: 0.8260:  85%|[36m████████▍ [0m| 22/26 [00:23<00:05,  1.43s/it]Epoch: 3/10. Loss: 0.8693:  85%|[36m████████▍ [0m| 22/26 [00:24<00:05,  1.43s/it]Epoch: 3/10. Loss: 0.8693:  88%|[36m████████▊ [0m| 23/26 [00:24<00:03,  1.27s/it]Epoch: 3/10. Loss: 0.9133:  88%|[36m████████▊ [0m| 23/26 [00:24<00:03,  1.27s/it]Epoch: 3/10. Loss: 0.9133:  92%|[36m█████████▏[0m| 24/26 [00:24<00:02,  1.12s/it]Epoch: 3/10. Loss: 0.9498:  92%|[36m█████████▏[0m| 24/26 [00:25<00:02,  1.12s/it]Epoch: 3/10. Loss: 0.9498:  96%|[36m█████████▌[0m| 25/26 [00:25<00:01,  1.08s/it]Epoch: 3/10. Loss: 1.0152:  96%|[36m█████████▌[0m| 25/26 [00:27<00:01,  1.08s/it]Epoch: 3/10. Loss: 1.0152: 100%|[36m██████████[0m| 26/26 [00:27<00:00,  1.22s/it]Epoch: 3/10. Loss: 1.0152: 100%|[36m██████████[0m| 26/26 [00:27<00:00,  1.05s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:04,  1.21it/s] 29%|[33m██▊       [0m| 2/7 [00:01<00:04,  1.07it/s] 43%|[33m████▎     [0m| 3/7 [00:02<00:03,  1.22it/s] 57%|[33m█████▋    [0m| 4/7 [00:03<00:03,  1.01s/it] 71%|[33m███████▏  [0m| 5/7 [00:04<00:01,  1.28it/s] 86%|[33m████████▌ [0m| 6/7 [00:05<00:00,  1.26it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.52it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.30it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 4/10. Loss: 0.9580:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 4/10. Loss: 0.9580:   4%|[36m▍         [0m| 1/26 [00:00<00:19,  1.31it/s]Epoch: 4/10. Loss: 1.0540:   4%|[36m▍         [0m| 1/26 [00:01<00:19,  1.31it/s]Epoch: 4/10. Loss: 1.0540:   8%|[36m▊         [0m| 2/26 [00:01<00:21,  1.11it/s]Epoch: 4/10. Loss: 0.9880:   8%|[36m▊         [0m| 2/26 [00:02<00:21,  1.11it/s]Epoch: 4/10. Loss: 0.9880:  12%|[36m█▏        [0m| 3/26 [00:02<00:21,  1.06it/s]Epoch: 4/10. Loss: 0.8949:  12%|[36m█▏        [0m| 3/26 [00:03<00:21,  1.06it/s]Epoch: 4/10. Loss: 0.8949:  15%|[36m█▌        [0m| 4/26 [00:03<00:19,  1.10it/s]Epoch: 4/10. Loss: 0.8474:  15%|[36m█▌        [0m| 4/26 [00:04<00:19,  1.10it/s]Epoch: 4/10. Loss: 0.8474:  19%|[36m█▉        [0m| 5/26 [00:04<00:20,  1.03it/s]Epoch: 4/10. Loss: 0.8407:  19%|[36m█▉        [0m| 5/26 [00:06<00:20,  1.03it/s]Epoch: 4/10. Loss: 0.8407:  23%|[36m██▎       [0m| 6/26 [00:06<00:21,  1.10s/it]Epoch: 4/10. Loss: 0.9170:  23%|[36m██▎       [0m| 6/26 [00:07<00:21,  1.10s/it]Epoch: 4/10. Loss: 0.9170:  27%|[36m██▋       [0m| 7/26 [00:07<00:20,  1.06s/it]Epoch: 4/10. Loss: 1.0069:  27%|[36m██▋       [0m| 7/26 [00:07<00:20,  1.06s/it]Epoch: 4/10. Loss: 1.0069:  31%|[36m███       [0m| 8/26 [00:07<00:18,  1.01s/it]Epoch: 4/10. Loss: 0.9574:  31%|[36m███       [0m| 8/26 [00:08<00:18,  1.01s/it]Epoch: 4/10. Loss: 0.9574:  35%|[36m███▍      [0m| 9/26 [00:08<00:17,  1.01s/it]Epoch: 4/10. Loss: 0.7815:  35%|[36m███▍      [0m| 9/26 [00:09<00:17,  1.01s/it]Epoch: 4/10. Loss: 0.7815:  38%|[36m███▊      [0m| 10/26 [00:09<00:15,  1.01it/s]Epoch: 4/10. Loss: 0.8527:  38%|[36m███▊      [0m| 10/26 [00:10<00:15,  1.01it/s]Epoch: 4/10. Loss: 0.8527:  42%|[36m████▏     [0m| 11/26 [00:10<00:14,  1.00it/s]Epoch: 4/10. Loss: 1.0155:  42%|[36m████▏     [0m| 11/26 [00:11<00:14,  1.00it/s]Epoch: 4/10. Loss: 1.0155:  46%|[36m████▌     [0m| 12/26 [00:11<00:13,  1.03it/s]Epoch: 4/10. Loss: 0.8946:  46%|[36m████▌     [0m| 12/26 [00:12<00:13,  1.03it/s]Epoch: 4/10. Loss: 0.8946:  50%|[36m█████     [0m| 13/26 [00:12<00:12,  1.05it/s]Epoch: 4/10. Loss: 0.9528:  50%|[36m█████     [0m| 13/26 [00:13<00:12,  1.05it/s]Epoch: 4/10. Loss: 0.9528:  54%|[36m█████▍    [0m| 14/26 [00:13<00:11,  1.08it/s]Epoch: 4/10. Loss: 0.9214:  54%|[36m█████▍    [0m| 14/26 [00:14<00:11,  1.08it/s]Epoch: 4/10. Loss: 0.9214:  58%|[36m█████▊    [0m| 15/26 [00:14<00:09,  1.14it/s]Epoch: 4/10. Loss: 0.8760:  58%|[36m█████▊    [0m| 15/26 [00:15<00:09,  1.14it/s]Epoch: 4/10. Loss: 0.8760:  62%|[36m██████▏   [0m| 16/26 [00:15<00:08,  1.19it/s]Epoch: 4/10. Loss: 0.8533:  62%|[36m██████▏   [0m| 16/26 [00:15<00:08,  1.19it/s]Epoch: 4/10. Loss: 0.8533:  65%|[36m██████▌   [0m| 17/26 [00:15<00:07,  1.24it/s]Epoch: 4/10. Loss: 0.9880:  65%|[36m██████▌   [0m| 17/26 [00:16<00:07,  1.24it/s]Epoch: 4/10. Loss: 0.9880:  69%|[36m██████▉   [0m| 18/26 [00:16<00:06,  1.17it/s]Epoch: 4/10. Loss: 0.9894:  69%|[36m██████▉   [0m| 18/26 [00:17<00:06,  1.17it/s]Epoch: 4/10. Loss: 0.9894:  73%|[36m███████▎  [0m| 19/26 [00:17<00:06,  1.08it/s]Epoch: 4/10. Loss: 0.8759:  73%|[36m███████▎  [0m| 19/26 [00:18<00:06,  1.08it/s]Epoch: 4/10. Loss: 0.8759:  77%|[36m███████▋  [0m| 20/26 [00:18<00:05,  1.14it/s]Epoch: 4/10. Loss: 0.9421:  77%|[36m███████▋  [0m| 20/26 [00:19<00:05,  1.14it/s]Epoch: 4/10. Loss: 0.9421:  81%|[36m████████  [0m| 21/26 [00:19<00:04,  1.12it/s]Epoch: 4/10. Loss: 0.9544:  81%|[36m████████  [0m| 21/26 [00:20<00:04,  1.12it/s]Epoch: 4/10. Loss: 0.9544:  85%|[36m████████▍ [0m| 22/26 [00:20<00:03,  1.10it/s]Epoch: 4/10. Loss: 1.0014:  85%|[36m████████▍ [0m| 22/26 [00:21<00:03,  1.10it/s]Epoch: 4/10. Loss: 1.0014:  88%|[36m████████▊ [0m| 23/26 [00:21<00:02,  1.07it/s]Epoch: 4/10. Loss: 0.9738:  88%|[36m████████▊ [0m| 23/26 [00:22<00:02,  1.07it/s]Epoch: 4/10. Loss: 0.9738:  92%|[36m█████████▏[0m| 24/26 [00:22<00:01,  1.02it/s]Epoch: 4/10. Loss: 0.9022:  92%|[36m█████████▏[0m| 24/26 [00:23<00:01,  1.02it/s]Epoch: 4/10. Loss: 0.9022:  96%|[36m█████████▌[0m| 25/26 [00:23<00:00,  1.08it/s]Epoch: 4/10. Loss: 0.9149:  96%|[36m█████████▌[0m| 25/26 [00:24<00:00,  1.08it/s]Epoch: 4/10. Loss: 0.9149: 100%|[36m██████████[0m| 26/26 [00:24<00:00,  1.15it/s]Epoch: 4/10. Loss: 0.9149: 100%|[36m██████████[0m| 26/26 [00:24<00:00,  1.08it/s]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:05,  1.20it/s] 29%|[33m██▊       [0m| 2/7 [00:01<00:04,  1.06it/s] 43%|[33m████▎     [0m| 3/7 [00:02<00:03,  1.20it/s] 57%|[33m█████▋    [0m| 4/7 [00:03<00:02,  1.02it/s] 71%|[33m███████▏  [0m| 5/7 [00:04<00:01,  1.29it/s] 86%|[33m████████▌ [0m| 6/7 [00:05<00:00,  1.25it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.61it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.33it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 5/10. Loss: 0.8573:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 5/10. Loss: 0.8573:   4%|[36m▍         [0m| 1/26 [00:00<00:20,  1.21it/s]Epoch: 5/10. Loss: 1.0328:   4%|[36m▍         [0m| 1/26 [00:01<00:20,  1.21it/s]Epoch: 5/10. Loss: 1.0328:   8%|[36m▊         [0m| 2/26 [00:01<00:24,  1.00s/it]Epoch: 5/10. Loss: 0.9215:   8%|[36m▊         [0m| 2/26 [00:02<00:24,  1.00s/it]Epoch: 5/10. Loss: 0.9215:  12%|[36m█▏        [0m| 3/26 [00:02<00:23,  1.01s/it]Epoch: 5/10. Loss: 0.9074:  12%|[36m█▏        [0m| 3/26 [00:04<00:23,  1.01s/it]Epoch: 5/10. Loss: 0.9074:  15%|[36m█▌        [0m| 4/26 [00:04<00:22,  1.03s/it]Epoch: 5/10. Loss: 0.9875:  15%|[36m█▌        [0m| 4/26 [00:04<00:22,  1.03s/it]Epoch: 5/10. Loss: 0.9875:  19%|[36m█▉        [0m| 5/26 [00:04<00:19,  1.06it/s]Epoch: 5/10. Loss: 0.9680:  19%|[36m█▉        [0m| 5/26 [00:06<00:19,  1.06it/s]Epoch: 5/10. Loss: 0.9680:  23%|[36m██▎       [0m| 6/26 [00:06<00:23,  1.16s/it]Epoch: 5/10. Loss: 0.8760:  23%|[36m██▎       [0m| 6/26 [00:07<00:23,  1.16s/it]Epoch: 5/10. Loss: 0.8760:  27%|[36m██▋       [0m| 7/26 [00:07<00:20,  1.07s/it]Epoch: 5/10. Loss: 0.8669:  27%|[36m██▋       [0m| 7/26 [00:07<00:20,  1.07s/it]Epoch: 5/10. Loss: 0.8669:  31%|[36m███       [0m| 8/26 [00:07<00:17,  1.04it/s]Epoch: 5/10. Loss: 0.7524:  31%|[36m███       [0m| 8/26 [00:08<00:17,  1.04it/s]Epoch: 5/10. Loss: 0.7524:  35%|[36m███▍      [0m| 9/26 [00:08<00:15,  1.08it/s]Epoch: 5/10. Loss: 0.9470:  35%|[36m███▍      [0m| 9/26 [00:11<00:15,  1.08it/s]Epoch: 5/10. Loss: 0.9470:  38%|[36m███▊      [0m| 10/26 [00:11<00:21,  1.33s/it]Epoch: 5/10. Loss: 0.9281:  38%|[36m███▊      [0m| 10/26 [00:12<00:21,  1.33s/it]Epoch: 5/10. Loss: 0.9281:  42%|[36m████▏     [0m| 11/26 [00:12<00:19,  1.32s/it]Epoch: 5/10. Loss: 0.8449:  42%|[36m████▏     [0m| 11/26 [00:13<00:19,  1.32s/it]Epoch: 5/10. Loss: 0.8449:  46%|[36m████▌     [0m| 12/26 [00:13<00:16,  1.18s/it]Epoch: 5/10. Loss: 0.8992:  46%|[36m████▌     [0m| 12/26 [00:14<00:16,  1.18s/it]Epoch: 5/10. Loss: 0.8992:  50%|[36m█████     [0m| 13/26 [00:14<00:14,  1.13s/it]Epoch: 5/10. Loss: 0.8423:  50%|[36m█████     [0m| 13/26 [00:15<00:14,  1.13s/it]Epoch: 5/10. Loss: 0.8423:  54%|[36m█████▍    [0m| 14/26 [00:15<00:12,  1.06s/it]Epoch: 5/10. Loss: 0.9151:  54%|[36m█████▍    [0m| 14/26 [00:16<00:12,  1.06s/it]Epoch: 5/10. Loss: 0.9151:  58%|[36m█████▊    [0m| 15/26 [00:16<00:11,  1.02s/it]Epoch: 5/10. Loss: 0.8562:  58%|[36m█████▊    [0m| 15/26 [00:16<00:11,  1.02s/it]Epoch: 5/10. Loss: 0.8562:  62%|[36m██████▏   [0m| 16/26 [00:16<00:09,  1.04it/s]Epoch: 5/10. Loss: 0.8529:  62%|[36m██████▏   [0m| 16/26 [00:17<00:09,  1.04it/s]Epoch: 5/10. Loss: 0.8529:  65%|[36m██████▌   [0m| 17/26 [00:17<00:07,  1.14it/s]Epoch: 5/10. Loss: 0.8950:  65%|[36m██████▌   [0m| 17/26 [00:18<00:07,  1.14it/s]Epoch: 5/10. Loss: 0.8950:  69%|[36m██████▉   [0m| 18/26 [00:18<00:07,  1.09it/s]Epoch: 5/10. Loss: 0.9382:  69%|[36m██████▉   [0m| 18/26 [00:19<00:07,  1.09it/s]Epoch: 5/10. Loss: 0.9382:  73%|[36m███████▎  [0m| 19/26 [00:19<00:06,  1.08it/s]Epoch: 5/10. Loss: 1.0215:  73%|[36m███████▎  [0m| 19/26 [00:20<00:06,  1.08it/s]Epoch: 5/10. Loss: 1.0215:  77%|[36m███████▋  [0m| 20/26 [00:20<00:05,  1.03it/s]Epoch: 5/10. Loss: 0.8048:  77%|[36m███████▋  [0m| 20/26 [00:21<00:05,  1.03it/s]Epoch: 5/10. Loss: 0.8048:  81%|[36m████████  [0m| 21/26 [00:21<00:04,  1.04it/s]Epoch: 5/10. Loss: 0.9241:  81%|[36m████████  [0m| 21/26 [00:22<00:04,  1.04it/s]Epoch: 5/10. Loss: 0.9241:  85%|[36m████████▍ [0m| 22/26 [00:22<00:03,  1.03it/s]Epoch: 5/10. Loss: 0.9494:  85%|[36m████████▍ [0m| 22/26 [00:23<00:03,  1.03it/s]Epoch: 5/10. Loss: 0.9494:  88%|[36m████████▊ [0m| 23/26 [00:23<00:02,  1.02it/s]Epoch: 5/10. Loss: 0.9598:  88%|[36m████████▊ [0m| 23/26 [00:24<00:02,  1.02it/s]Epoch: 5/10. Loss: 0.9598:  92%|[36m█████████▏[0m| 24/26 [00:24<00:02,  1.03s/it]Epoch: 5/10. Loss: 0.7978:  92%|[36m█████████▏[0m| 24/26 [00:25<00:02,  1.03s/it]Epoch: 5/10. Loss: 0.7978:  96%|[36m█████████▌[0m| 25/26 [00:25<00:00,  1.02it/s]Epoch: 5/10. Loss: 0.9019:  96%|[36m█████████▌[0m| 25/26 [00:26<00:00,  1.02it/s]Epoch: 5/10. Loss: 0.9019: 100%|[36m██████████[0m| 26/26 [00:26<00:00,  1.13it/s]Epoch: 5/10. Loss: 0.9019: 100%|[36m██████████[0m| 26/26 [00:26<00:00,  1.01s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:04,  1.21it/s] 29%|[33m██▊       [0m| 2/7 [00:01<00:04,  1.05it/s] 43%|[33m████▎     [0m| 3/7 [00:02<00:03,  1.18it/s] 57%|[33m█████▋    [0m| 4/7 [00:03<00:03,  1.00s/it] 71%|[33m███████▏  [0m| 5/7 [00:04<00:01,  1.25it/s] 86%|[33m████████▌ [0m| 6/7 [00:05<00:00,  1.21it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.56it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.29it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 6/10. Loss: 0.8816:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 6/10. Loss: 0.8816:   4%|[36m▍         [0m| 1/26 [00:00<00:21,  1.18it/s]Epoch: 6/10. Loss: 0.8541:   4%|[36m▍         [0m| 1/26 [00:01<00:21,  1.18it/s]Epoch: 6/10. Loss: 0.8541:   8%|[36m▊         [0m| 2/26 [00:01<00:18,  1.28it/s]Epoch: 6/10. Loss: 0.7907:   8%|[36m▊         [0m| 2/26 [00:02<00:18,  1.28it/s]Epoch: 6/10. Loss: 0.7907:  12%|[36m█▏        [0m| 3/26 [00:02<00:22,  1.01it/s]Epoch: 6/10. Loss: 0.8587:  12%|[36m█▏        [0m| 3/26 [00:03<00:22,  1.01it/s]Epoch: 6/10. Loss: 0.8587:  15%|[36m█▌        [0m| 4/26 [00:03<00:21,  1.01it/s]Epoch: 6/10. Loss: 0.7685:  15%|[36m█▌        [0m| 4/26 [00:04<00:21,  1.01it/s]Epoch: 6/10. Loss: 0.7685:  19%|[36m█▉        [0m| 5/26 [00:04<00:19,  1.06it/s]Epoch: 6/10. Loss: 0.7618:  19%|[36m█▉        [0m| 5/26 [00:05<00:19,  1.06it/s]Epoch: 6/10. Loss: 0.7618:  23%|[36m██▎       [0m| 6/26 [00:05<00:18,  1.08it/s]Epoch: 6/10. Loss: 0.8851:  23%|[36m██▎       [0m| 6/26 [00:06<00:18,  1.08it/s]Epoch: 6/10. Loss: 0.8851:  27%|[36m██▋       [0m| 7/26 [00:06<00:18,  1.05it/s]Epoch: 6/10. Loss: 0.8552:  27%|[36m██▋       [0m| 7/26 [00:07<00:18,  1.05it/s]Epoch: 6/10. Loss: 0.8552:  31%|[36m███       [0m| 8/26 [00:07<00:16,  1.10it/s]Epoch: 6/10. Loss: 0.8470:  31%|[36m███       [0m| 8/26 [00:08<00:16,  1.10it/s]Epoch: 6/10. Loss: 0.8470:  35%|[36m███▍      [0m| 9/26 [00:08<00:15,  1.09it/s]Epoch: 6/10. Loss: 0.9396:  35%|[36m███▍      [0m| 9/26 [00:09<00:15,  1.09it/s]Epoch: 6/10. Loss: 0.9396:  38%|[36m███▊      [0m| 10/26 [00:09<00:14,  1.07it/s]Epoch: 6/10. Loss: 0.6911:  38%|[36m███▊      [0m| 10/26 [00:10<00:14,  1.07it/s]Epoch: 6/10. Loss: 0.6911:  42%|[36m████▏     [0m| 11/26 [00:10<00:13,  1.12it/s]Epoch: 6/10. Loss: 0.9158:  42%|[36m████▏     [0m| 11/26 [00:11<00:13,  1.12it/s]Epoch: 6/10. Loss: 0.9158:  46%|[36m████▌     [0m| 12/26 [00:11<00:13,  1.03it/s]Epoch: 6/10. Loss: 0.9121:  46%|[36m████▌     [0m| 12/26 [00:12<00:13,  1.03it/s]Epoch: 6/10. Loss: 0.9121:  50%|[36m█████     [0m| 13/26 [00:12<00:11,  1.10it/s]Epoch: 6/10. Loss: 0.8244:  50%|[36m█████     [0m| 13/26 [00:13<00:11,  1.10it/s]Epoch: 6/10. Loss: 0.8244:  54%|[36m█████▍    [0m| 14/26 [00:13<00:14,  1.23s/it]Epoch: 6/10. Loss: 0.9076:  54%|[36m█████▍    [0m| 14/26 [00:14<00:14,  1.23s/it]Epoch: 6/10. Loss: 0.9076:  58%|[36m█████▊    [0m| 15/26 [00:14<00:12,  1.14s/it]Epoch: 6/10. Loss: 0.8391:  58%|[36m█████▊    [0m| 15/26 [00:15<00:12,  1.14s/it]Epoch: 6/10. Loss: 0.8391:  62%|[36m██████▏   [0m| 16/26 [00:15<00:10,  1.06s/it]Epoch: 6/10. Loss: 0.9666:  62%|[36m██████▏   [0m| 16/26 [00:16<00:10,  1.06s/it]Epoch: 6/10. Loss: 0.9666:  65%|[36m██████▌   [0m| 17/26 [00:16<00:09,  1.03s/it]Epoch: 6/10. Loss: 0.8631:  65%|[36m██████▌   [0m| 17/26 [00:17<00:09,  1.03s/it]Epoch: 6/10. Loss: 0.8631:  69%|[36m██████▉   [0m| 18/26 [00:17<00:08,  1.00s/it]Epoch: 6/10. Loss: 0.8248:  69%|[36m██████▉   [0m| 18/26 [00:18<00:08,  1.00s/it]Epoch: 6/10. Loss: 0.8248:  73%|[36m███████▎  [0m| 19/26 [00:18<00:06,  1.06it/s]Epoch: 6/10. Loss: 0.8907:  73%|[36m███████▎  [0m| 19/26 [00:19<00:06,  1.06it/s]Epoch: 6/10. Loss: 0.8907:  77%|[36m███████▋  [0m| 20/26 [00:19<00:06,  1.01s/it]Epoch: 6/10. Loss: 0.8620:  77%|[36m███████▋  [0m| 20/26 [00:20<00:06,  1.01s/it]Epoch: 6/10. Loss: 0.8620:  81%|[36m████████  [0m| 21/26 [00:20<00:05,  1.02s/it]Epoch: 6/10. Loss: 0.8764:  81%|[36m████████  [0m| 21/26 [00:21<00:05,  1.02s/it]Epoch: 6/10. Loss: 0.8764:  85%|[36m████████▍ [0m| 22/26 [00:21<00:04,  1.01s/it]Epoch: 6/10. Loss: 0.8632:  85%|[36m████████▍ [0m| 22/26 [00:22<00:04,  1.01s/it]Epoch: 6/10. Loss: 0.8632:  88%|[36m████████▊ [0m| 23/26 [00:22<00:02,  1.06it/s]Epoch: 6/10. Loss: 0.9124:  88%|[36m████████▊ [0m| 23/26 [00:23<00:02,  1.06it/s]Epoch: 6/10. Loss: 0.9124:  92%|[36m█████████▏[0m| 24/26 [00:23<00:01,  1.01it/s]Epoch: 6/10. Loss: 0.9539:  92%|[36m█████████▏[0m| 24/26 [00:24<00:01,  1.01it/s]Epoch: 6/10. Loss: 0.9539:  96%|[36m█████████▌[0m| 25/26 [00:24<00:00,  1.04it/s]Epoch: 6/10. Loss: 0.8533:  96%|[36m█████████▌[0m| 25/26 [00:25<00:00,  1.04it/s]Epoch: 6/10. Loss: 0.8533: 100%|[36m██████████[0m| 26/26 [00:25<00:00,  1.17it/s]Epoch: 6/10. Loss: 0.8533: 100%|[36m██████████[0m| 26/26 [00:25<00:00,  1.04it/s]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:05,  1.17it/s] 29%|[33m██▊       [0m| 2/7 [00:01<00:04,  1.04it/s] 43%|[33m████▎     [0m| 3/7 [00:02<00:03,  1.16it/s] 57%|[33m█████▋    [0m| 4/7 [00:05<00:05,  1.74s/it] 71%|[33m███████▏  [0m| 5/7 [00:07<00:03,  1.73s/it] 86%|[33m████████▌ [0m| 6/7 [00:08<00:01,  1.45s/it]100%|[33m██████████[0m| 7/7 [00:08<00:00,  1.08s/it]100%|[33m██████████[0m| 7/7 [00:08<00:00,  1.24s/it]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 7/10. Loss: 0.8758:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 7/10. Loss: 0.8758:   4%|[36m▍         [0m| 1/26 [00:00<00:20,  1.22it/s]Epoch: 7/10. Loss: 0.8544:   4%|[36m▍         [0m| 1/26 [00:01<00:20,  1.22it/s]Epoch: 7/10. Loss: 0.8544:   8%|[36m▊         [0m| 2/26 [00:01<00:21,  1.12it/s]Epoch: 7/10. Loss: 0.8971:   8%|[36m▊         [0m| 2/26 [00:02<00:21,  1.12it/s]Epoch: 7/10. Loss: 0.8971:  12%|[36m█▏        [0m| 3/26 [00:02<00:20,  1.12it/s]Epoch: 7/10. Loss: 0.8378:  12%|[36m█▏        [0m| 3/26 [00:03<00:20,  1.12it/s]Epoch: 7/10. Loss: 0.8378:  15%|[36m█▌        [0m| 4/26 [00:03<00:19,  1.13it/s]Epoch: 7/10. Loss: 0.8228:  15%|[36m█▌        [0m| 4/26 [00:04<00:19,  1.13it/s]Epoch: 7/10. Loss: 0.8228:  19%|[36m█▉        [0m| 5/26 [00:04<00:18,  1.12it/s]Epoch: 7/10. Loss: 0.8334:  19%|[36m█▉        [0m| 5/26 [00:05<00:18,  1.12it/s]Epoch: 7/10. Loss: 0.8334:  23%|[36m██▎       [0m| 6/26 [00:05<00:18,  1.10it/s]Epoch: 7/10. Loss: 0.9611:  23%|[36m██▎       [0m| 6/26 [00:07<00:18,  1.10it/s]Epoch: 7/10. Loss: 0.9611:  27%|[36m██▋       [0m| 7/26 [00:07<00:23,  1.25s/it]Epoch: 7/10. Loss: 0.8822:  27%|[36m██▋       [0m| 7/26 [00:08<00:23,  1.25s/it]Epoch: 7/10. Loss: 0.8822:  31%|[36m███       [0m| 8/26 [00:08<00:23,  1.32s/it]Epoch: 7/10. Loss: 0.7813:  31%|[36m███       [0m| 8/26 [00:09<00:23,  1.32s/it]Epoch: 7/10. Loss: 0.7813:  35%|[36m███▍      [0m| 9/26 [00:09<00:20,  1.19s/it]Epoch: 7/10. Loss: 0.8387:  35%|[36m███▍      [0m| 9/26 [00:10<00:20,  1.19s/it]Epoch: 7/10. Loss: 0.8387:  38%|[36m███▊      [0m| 10/26 [00:10<00:18,  1.13s/it]Epoch: 7/10. Loss: 0.8253:  38%|[36m███▊      [0m| 10/26 [00:11<00:18,  1.13s/it]Epoch: 7/10. Loss: 0.8253:  42%|[36m████▏     [0m| 11/26 [00:11<00:16,  1.08s/it]Epoch: 7/10. Loss: 0.8774:  42%|[36m████▏     [0m| 11/26 [00:13<00:16,  1.08s/it]Epoch: 7/10. Loss: 0.8774:  46%|[36m████▌     [0m| 12/26 [00:13<00:16,  1.20s/it]Epoch: 7/10. Loss: 0.8543:  46%|[36m████▌     [0m| 12/26 [00:14<00:16,  1.20s/it]Epoch: 7/10. Loss: 0.8543:  50%|[36m█████     [0m| 13/26 [00:14<00:14,  1.10s/it]Epoch: 7/10. Loss: 0.7827:  50%|[36m█████     [0m| 13/26 [00:15<00:14,  1.10s/it]Epoch: 7/10. Loss: 0.7827:  54%|[36m█████▍    [0m| 14/26 [00:15<00:13,  1.10s/it]Epoch: 7/10. Loss: 0.8368:  54%|[36m█████▍    [0m| 14/26 [00:17<00:13,  1.10s/it]Epoch: 7/10. Loss: 0.8368:  58%|[36m█████▊    [0m| 15/26 [00:17<00:14,  1.35s/it]Epoch: 7/10. Loss: 0.8449:  58%|[36m█████▊    [0m| 15/26 [00:17<00:14,  1.35s/it]Epoch: 7/10. Loss: 0.8449:  62%|[36m██████▏   [0m| 16/26 [00:17<00:11,  1.19s/it]Epoch: 7/10. Loss: 1.0074:  62%|[36m██████▏   [0m| 16/26 [00:19<00:11,  1.19s/it]Epoch: 7/10. Loss: 1.0074:  65%|[36m██████▌   [0m| 17/26 [00:19<00:11,  1.28s/it]Epoch: 7/10. Loss: 0.8783:  65%|[36m██████▌   [0m| 17/26 [00:20<00:11,  1.28s/it]Epoch: 7/10. Loss: 0.8783:  69%|[36m██████▉   [0m| 18/26 [00:20<00:09,  1.17s/it]Epoch: 7/10. Loss: 0.8429:  69%|[36m██████▉   [0m| 18/26 [00:21<00:09,  1.17s/it]Epoch: 7/10. Loss: 0.8429:  73%|[36m███████▎  [0m| 19/26 [00:21<00:07,  1.08s/it]Epoch: 7/10. Loss: 0.8613:  73%|[36m███████▎  [0m| 19/26 [00:22<00:07,  1.08s/it]Epoch: 7/10. Loss: 0.8613:  77%|[36m███████▋  [0m| 20/26 [00:22<00:06,  1.06s/it]Epoch: 7/10. Loss: 0.9139:  77%|[36m███████▋  [0m| 20/26 [00:23<00:06,  1.06s/it]Epoch: 7/10. Loss: 0.9139:  81%|[36m████████  [0m| 21/26 [00:23<00:05,  1.02s/it]Epoch: 7/10. Loss: 0.8740:  81%|[36m████████  [0m| 21/26 [00:24<00:05,  1.02s/it]Epoch: 7/10. Loss: 0.8740:  85%|[36m████████▍ [0m| 22/26 [00:24<00:04,  1.11s/it]Epoch: 7/10. Loss: 0.8702:  85%|[36m████████▍ [0m| 22/26 [00:25<00:04,  1.11s/it]Epoch: 7/10. Loss: 0.8702:  88%|[36m████████▊ [0m| 23/26 [00:25<00:03,  1.09s/it]Epoch: 7/10. Loss: 0.8118:  88%|[36m████████▊ [0m| 23/26 [00:26<00:03,  1.09s/it]Epoch: 7/10. Loss: 0.8118:  92%|[36m█████████▏[0m| 24/26 [00:26<00:01,  1.03it/s]Epoch: 7/10. Loss: 0.8044:  92%|[36m█████████▏[0m| 24/26 [00:27<00:01,  1.03it/s]Epoch: 7/10. Loss: 0.8044:  96%|[36m█████████▌[0m| 25/26 [00:27<00:01,  1.05s/it]Epoch: 7/10. Loss: 0.7932:  96%|[36m█████████▌[0m| 25/26 [00:28<00:01,  1.05s/it]Epoch: 7/10. Loss: 0.7932: 100%|[36m██████████[0m| 26/26 [00:28<00:00,  1.04it/s]Epoch: 7/10. Loss: 0.7932: 100%|[36m██████████[0m| 26/26 [00:28<00:00,  1.08s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:01<00:08,  1.43s/it] 29%|[33m██▊       [0m| 2/7 [00:04<00:12,  2.49s/it] 43%|[33m████▎     [0m| 3/7 [00:05<00:06,  1.69s/it] 57%|[33m█████▋    [0m| 4/7 [00:06<00:04,  1.53s/it] 71%|[33m███████▏  [0m| 5/7 [00:07<00:02,  1.14s/it] 86%|[33m████████▌ [0m| 6/7 [00:08<00:01,  1.06s/it]100%|[33m██████████[0m| 7/7 [00:08<00:00,  1.22it/s]100%|[33m██████████[0m| 7/7 [00:08<00:00,  1.19s/it]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 8/10. Loss: 0.8085:   0%|[36m          [0m| 0/26 [00:02<?, ?it/s]Epoch: 8/10. Loss: 0.8085:   4%|[36m▍         [0m| 1/26 [00:02<01:04,  2.56s/it]Epoch: 8/10. Loss: 0.7796:   4%|[36m▍         [0m| 1/26 [00:03<01:04,  2.56s/it]Epoch: 8/10. Loss: 0.7796:   8%|[36m▊         [0m| 2/26 [00:03<00:38,  1.62s/it]Epoch: 8/10. Loss: 0.7890:   8%|[36m▊         [0m| 2/26 [00:04<00:38,  1.62s/it]Epoch: 8/10. Loss: 0.7890:  12%|[36m█▏        [0m| 3/26 [00:04<00:31,  1.35s/it]Epoch: 8/10. Loss: 0.8986:  12%|[36m█▏        [0m| 3/26 [00:05<00:31,  1.35s/it]Epoch: 8/10. Loss: 0.8986:  15%|[36m█▌        [0m| 4/26 [00:05<00:26,  1.20s/it]Epoch: 8/10. Loss: 0.8269:  15%|[36m█▌        [0m| 4/26 [00:06<00:26,  1.20s/it]Epoch: 8/10. Loss: 0.8269:  19%|[36m█▉        [0m| 5/26 [00:06<00:21,  1.02s/it]Epoch: 8/10. Loss: 0.7667:  19%|[36m█▉        [0m| 5/26 [00:07<00:21,  1.02s/it]Epoch: 8/10. Loss: 0.7667:  23%|[36m██▎       [0m| 6/26 [00:07<00:19,  1.05it/s]Epoch: 8/10. Loss: 0.8288:  23%|[36m██▎       [0m| 6/26 [00:08<00:19,  1.05it/s]Epoch: 8/10. Loss: 0.8288:  27%|[36m██▋       [0m| 7/26 [00:08<00:21,  1.13s/it]Epoch: 8/10. Loss: 0.8844:  27%|[36m██▋       [0m| 7/26 [00:09<00:21,  1.13s/it]Epoch: 8/10. Loss: 0.8844:  31%|[36m███       [0m| 8/26 [00:09<00:19,  1.09s/it]Epoch: 8/10. Loss: 0.8143:  31%|[36m███       [0m| 8/26 [00:10<00:19,  1.09s/it]Epoch: 8/10. Loss: 0.8143:  35%|[36m███▍      [0m| 9/26 [00:10<00:20,  1.18s/it]Epoch: 8/10. Loss: 0.7781:  35%|[36m███▍      [0m| 9/26 [00:11<00:20,  1.18s/it]Epoch: 8/10. Loss: 0.7781:  38%|[36m███▊      [0m| 10/26 [00:11<00:17,  1.09s/it]Epoch: 8/10. Loss: 0.8679:  38%|[36m███▊      [0m| 10/26 [00:12<00:17,  1.09s/it]Epoch: 8/10. Loss: 0.8679:  42%|[36m████▏     [0m| 11/26 [00:12<00:16,  1.09s/it]Epoch: 8/10. Loss: 0.8854:  42%|[36m████▏     [0m| 11/26 [00:13<00:16,  1.09s/it]Epoch: 8/10. Loss: 0.8854:  46%|[36m████▌     [0m| 12/26 [00:13<00:14,  1.06s/it]Epoch: 8/10. Loss: 0.8511:  46%|[36m████▌     [0m| 12/26 [00:15<00:14,  1.06s/it]Epoch: 8/10. Loss: 0.8511:  50%|[36m█████     [0m| 13/26 [00:15<00:15,  1.17s/it]Epoch: 8/10. Loss: 0.8054:  50%|[36m█████     [0m| 13/26 [00:16<00:15,  1.17s/it]Epoch: 8/10. Loss: 0.8054:  54%|[36m█████▍    [0m| 14/26 [00:16<00:15,  1.31s/it]Epoch: 8/10. Loss: 0.7776:  54%|[36m█████▍    [0m| 14/26 [00:17<00:15,  1.31s/it]Epoch: 8/10. Loss: 0.7776:  58%|[36m█████▊    [0m| 15/26 [00:17<00:12,  1.17s/it]Epoch: 8/10. Loss: 0.8631:  58%|[36m█████▊    [0m| 15/26 [00:18<00:12,  1.17s/it]Epoch: 8/10. Loss: 0.8631:  62%|[36m██████▏   [0m| 16/26 [00:18<00:10,  1.06s/it]Epoch: 8/10. Loss: 0.7579:  62%|[36m██████▏   [0m| 16/26 [00:20<00:10,  1.06s/it]Epoch: 8/10. Loss: 0.7579:  65%|[36m██████▌   [0m| 17/26 [00:20<00:11,  1.28s/it]Epoch: 8/10. Loss: 0.8493:  65%|[36m██████▌   [0m| 17/26 [00:21<00:11,  1.28s/it]Epoch: 8/10. Loss: 0.8493:  69%|[36m██████▉   [0m| 18/26 [00:21<00:09,  1.17s/it]Epoch: 8/10. Loss: 0.8337:  69%|[36m██████▉   [0m| 18/26 [00:22<00:09,  1.17s/it]Epoch: 8/10. Loss: 0.8337:  73%|[36m███████▎  [0m| 19/26 [00:22<00:07,  1.10s/it]Epoch: 8/10. Loss: 0.8792:  73%|[36m███████▎  [0m| 19/26 [00:22<00:07,  1.10s/it]Epoch: 8/10. Loss: 0.8792:  77%|[36m███████▋  [0m| 20/26 [00:22<00:05,  1.00it/s]Epoch: 8/10. Loss: 0.7851:  77%|[36m███████▋  [0m| 20/26 [00:23<00:05,  1.00it/s]Epoch: 8/10. Loss: 0.7851:  81%|[36m████████  [0m| 21/26 [00:23<00:04,  1.07it/s]Epoch: 8/10. Loss: 0.9028:  81%|[36m████████  [0m| 21/26 [00:26<00:04,  1.07it/s]Epoch: 8/10. Loss: 0.9028:  85%|[36m████████▍ [0m| 22/26 [00:26<00:05,  1.46s/it]Epoch: 8/10. Loss: 0.9688:  85%|[36m████████▍ [0m| 22/26 [00:27<00:05,  1.46s/it]Epoch: 8/10. Loss: 0.9688:  88%|[36m████████▊ [0m| 23/26 [00:27<00:04,  1.43s/it]Epoch: 8/10. Loss: 0.7011:  88%|[36m████████▊ [0m| 23/26 [00:31<00:04,  1.43s/it]Epoch: 8/10. Loss: 0.7011:  92%|[36m█████████▏[0m| 24/26 [00:31<00:04,  2.04s/it]Epoch: 8/10. Loss: 0.7977:  92%|[36m█████████▏[0m| 24/26 [00:32<00:04,  2.04s/it]Epoch: 8/10. Loss: 0.7977:  96%|[36m█████████▌[0m| 25/26 [00:32<00:01,  1.71s/it]Epoch: 8/10. Loss: 0.8211:  96%|[36m█████████▌[0m| 25/26 [00:32<00:01,  1.71s/it]Epoch: 8/10. Loss: 0.8211: 100%|[36m██████████[0m| 26/26 [00:32<00:00,  1.41s/it]Epoch: 8/10. Loss: 0.8211: 100%|[36m██████████[0m| 26/26 [00:32<00:00,  1.27s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:05,  1.16it/s] 29%|[33m██▊       [0m| 2/7 [00:01<00:04,  1.03it/s] 43%|[33m████▎     [0m| 3/7 [00:02<00:03,  1.16it/s] 57%|[33m█████▋    [0m| 4/7 [00:04<00:03,  1.21s/it] 71%|[33m███████▏  [0m| 5/7 [00:04<00:01,  1.07it/s] 86%|[33m████████▌ [0m| 6/7 [00:06<00:01,  1.06s/it]100%|[33m██████████[0m| 7/7 [00:06<00:00,  1.25it/s]100%|[33m██████████[0m| 7/7 [00:06<00:00,  1.09it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 9/10. Loss: 0.8892:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 9/10. Loss: 0.8892:   4%|[36m▍         [0m| 1/26 [00:01<00:25,  1.00s/it]Epoch: 9/10. Loss: 0.7105:   4%|[36m▍         [0m| 1/26 [00:01<00:25,  1.00s/it]Epoch: 9/10. Loss: 0.7105:   8%|[36m▊         [0m| 2/26 [00:01<00:21,  1.10it/s]Epoch: 9/10. Loss: 0.8320:   8%|[36m▊         [0m| 2/26 [00:03<00:21,  1.10it/s]Epoch: 9/10. Loss: 0.8320:  12%|[36m█▏        [0m| 3/26 [00:03<00:26,  1.14s/it]Epoch: 9/10. Loss: 0.7663:  12%|[36m█▏        [0m| 3/26 [00:04<00:26,  1.14s/it]Epoch: 9/10. Loss: 0.7663:  15%|[36m█▌        [0m| 4/26 [00:04<00:21,  1.00it/s]Epoch: 9/10. Loss: 0.9167:  15%|[36m█▌        [0m| 4/26 [00:04<00:21,  1.00it/s]Epoch: 9/10. Loss: 0.9167:  19%|[36m█▉        [0m| 5/26 [00:04<00:20,  1.04it/s]Epoch: 9/10. Loss: 0.9053:  19%|[36m█▉        [0m| 5/26 [00:05<00:20,  1.04it/s]Epoch: 9/10. Loss: 0.9053:  23%|[36m██▎       [0m| 6/26 [00:05<00:19,  1.02it/s]Epoch: 9/10. Loss: 0.7722:  23%|[36m██▎       [0m| 6/26 [00:06<00:19,  1.02it/s]Epoch: 9/10. Loss: 0.7722:  27%|[36m██▋       [0m| 7/26 [00:06<00:17,  1.09it/s]Epoch: 9/10. Loss: 0.7681:  27%|[36m██▋       [0m| 7/26 [00:07<00:17,  1.09it/s]Epoch: 9/10. Loss: 0.7681:  31%|[36m███       [0m| 8/26 [00:07<00:16,  1.11it/s]Epoch: 9/10. Loss: 0.8089:  31%|[36m███       [0m| 8/26 [00:08<00:16,  1.11it/s]Epoch: 9/10. Loss: 0.8089:  35%|[36m███▍      [0m| 9/26 [00:08<00:17,  1.01s/it]Epoch: 9/10. Loss: 0.7871:  35%|[36m███▍      [0m| 9/26 [00:09<00:17,  1.01s/it]Epoch: 9/10. Loss: 0.7871:  38%|[36m███▊      [0m| 10/26 [00:09<00:15,  1.05it/s]Epoch: 9/10. Loss: 0.7468:  38%|[36m███▊      [0m| 10/26 [00:13<00:15,  1.05it/s]Epoch: 9/10. Loss: 0.7468:  42%|[36m████▏     [0m| 11/26 [00:13<00:25,  1.70s/it]Epoch: 9/10. Loss: 0.8191:  42%|[36m████▏     [0m| 11/26 [00:14<00:25,  1.70s/it]Epoch: 9/10. Loss: 0.8191:  46%|[36m████▌     [0m| 12/26 [00:14<00:23,  1.70s/it]Epoch: 9/10. Loss: 0.7297:  46%|[36m████▌     [0m| 12/26 [00:15<00:23,  1.70s/it]Epoch: 9/10. Loss: 0.7297:  50%|[36m█████     [0m| 13/26 [00:15<00:20,  1.56s/it]Epoch: 9/10. Loss: 0.7637:  50%|[36m█████     [0m| 13/26 [00:16<00:20,  1.56s/it]Epoch: 9/10. Loss: 0.7637:  54%|[36m█████▍    [0m| 14/26 [00:16<00:16,  1.35s/it]Epoch: 9/10. Loss: 0.8547:  54%|[36m█████▍    [0m| 14/26 [00:17<00:16,  1.35s/it]Epoch: 9/10. Loss: 0.8547:  58%|[36m█████▊    [0m| 15/26 [00:17<00:13,  1.22s/it]Epoch: 9/10. Loss: 0.7718:  58%|[36m█████▊    [0m| 15/26 [00:18<00:13,  1.22s/it]Epoch: 9/10. Loss: 0.7718:  62%|[36m██████▏   [0m| 16/26 [00:18<00:11,  1.15s/it]Epoch: 9/10. Loss: 0.9075:  62%|[36m██████▏   [0m| 16/26 [00:19<00:11,  1.15s/it]Epoch: 9/10. Loss: 0.9075:  65%|[36m██████▌   [0m| 17/26 [00:19<00:09,  1.05s/it]Epoch: 9/10. Loss: 0.7961:  65%|[36m██████▌   [0m| 17/26 [00:20<00:09,  1.05s/it]Epoch: 9/10. Loss: 0.7961:  69%|[36m██████▉   [0m| 18/26 [00:20<00:09,  1.13s/it]Epoch: 9/10. Loss: 0.7474:  69%|[36m██████▉   [0m| 18/26 [00:23<00:09,  1.13s/it]Epoch: 9/10. Loss: 0.7474:  73%|[36m███████▎  [0m| 19/26 [00:23<00:11,  1.58s/it]Epoch: 9/10. Loss: 0.7506:  73%|[36m███████▎  [0m| 19/26 [00:24<00:11,  1.58s/it]Epoch: 9/10. Loss: 0.7506:  77%|[36m███████▋  [0m| 20/26 [00:24<00:08,  1.39s/it]Epoch: 9/10. Loss: 0.8124:  77%|[36m███████▋  [0m| 20/26 [00:26<00:08,  1.39s/it]Epoch: 9/10. Loss: 0.8124:  81%|[36m████████  [0m| 21/26 [00:26<00:07,  1.47s/it]Epoch: 9/10. Loss: 0.7406:  81%|[36m████████  [0m| 21/26 [00:27<00:07,  1.47s/it]Epoch: 9/10. Loss: 0.7406:  85%|[36m████████▍ [0m| 22/26 [00:27<00:05,  1.31s/it]Epoch: 9/10. Loss: 0.7123:  85%|[36m████████▍ [0m| 22/26 [00:27<00:05,  1.31s/it]Epoch: 9/10. Loss: 0.7123:  88%|[36m████████▊ [0m| 23/26 [00:27<00:03,  1.15s/it]Epoch: 9/10. Loss: 0.8119:  88%|[36m████████▊ [0m| 23/26 [00:28<00:03,  1.15s/it]Epoch: 9/10. Loss: 0.8119:  92%|[36m█████████▏[0m| 24/26 [00:28<00:02,  1.11s/it]Epoch: 9/10. Loss: 0.8211:  92%|[36m█████████▏[0m| 24/26 [00:29<00:02,  1.11s/it]Epoch: 9/10. Loss: 0.8211:  96%|[36m█████████▌[0m| 25/26 [00:29<00:01,  1.06s/it]Epoch: 9/10. Loss: 0.7603:  96%|[36m█████████▌[0m| 25/26 [00:30<00:01,  1.06s/it]Epoch: 9/10. Loss: 0.7603: 100%|[36m██████████[0m| 26/26 [00:30<00:00,  1.02it/s]Epoch: 9/10. Loss: 0.7603: 100%|[36m██████████[0m| 26/26 [00:30<00:00,  1.18s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:04,  1.30it/s] 29%|[33m██▊       [0m| 2/7 [00:01<00:04,  1.03it/s] 43%|[33m████▎     [0m| 3/7 [00:02<00:03,  1.20it/s] 57%|[33m█████▋    [0m| 4/7 [00:06<00:05,  1.97s/it] 71%|[33m███████▏  [0m| 5/7 [00:07<00:03,  1.60s/it] 86%|[33m████████▌ [0m| 6/7 [00:08<00:01,  1.35s/it]100%|[33m██████████[0m| 7/7 [00:08<00:00,  1.01it/s]100%|[33m██████████[0m| 7/7 [00:08<00:00,  1.19s/it]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 0/10. Loss: 1.1084:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 0/10. Loss: 1.1084:   4%|[36m▍         [0m| 1/26 [00:01<00:27,  1.10s/it]Epoch: 0/10. Loss: 2.0169:   4%|[36m▍         [0m| 1/26 [00:02<00:27,  1.10s/it]Epoch: 0/10. Loss: 2.0169:   8%|[36m▊         [0m| 2/26 [00:02<00:24,  1.00s/it]Epoch: 0/10. Loss: 2.0619:   8%|[36m▊         [0m| 2/26 [00:02<00:24,  1.00s/it]Epoch: 0/10. Loss: 2.0619:  12%|[36m█▏        [0m| 3/26 [00:02<00:22,  1.03it/s]Epoch: 0/10. Loss: 2.0082:  12%|[36m█▏        [0m| 3/26 [00:04<00:22,  1.03it/s]Epoch: 0/10. Loss: 2.0082:  15%|[36m█▌        [0m| 4/26 [00:04<00:23,  1.07s/it]Epoch: 0/10. Loss: 1.3004:  15%|[36m█▌        [0m| 4/26 [00:05<00:23,  1.07s/it]Epoch: 0/10. Loss: 1.3004:  19%|[36m█▉        [0m| 5/26 [00:05<00:21,  1.04s/it]Epoch: 0/10. Loss: 1.2030:  19%|[36m█▉        [0m| 5/26 [00:06<00:21,  1.04s/it]Epoch: 0/10. Loss: 1.2030:  23%|[36m██▎       [0m| 6/26 [00:06<00:19,  1.01it/s]Epoch: 0/10. Loss: 1.2775:  23%|[36m██▎       [0m| 6/26 [00:07<00:19,  1.01it/s]Epoch: 0/10. Loss: 1.2775:  27%|[36m██▋       [0m| 7/26 [00:07<00:18,  1.00it/s]Epoch: 0/10. Loss: 1.4063:  27%|[36m██▋       [0m| 7/26 [00:08<00:18,  1.00it/s]Epoch: 0/10. Loss: 1.4063:  31%|[36m███       [0m| 8/26 [00:08<00:23,  1.29s/it]Epoch: 0/10. Loss: 1.2805:  31%|[36m███       [0m| 8/26 [00:10<00:23,  1.29s/it]Epoch: 0/10. Loss: 1.2805:  35%|[36m███▍      [0m| 9/26 [00:10<00:20,  1.23s/it]Epoch: 0/10. Loss: 1.0741:  35%|[36m███▍      [0m| 9/26 [00:11<00:20,  1.23s/it]Epoch: 0/10. Loss: 1.0741:  38%|[36m███▊      [0m| 10/26 [00:11<00:18,  1.17s/it]Epoch: 0/10. Loss: 1.2170:  38%|[36m███▊      [0m| 10/26 [00:11<00:18,  1.17s/it]Epoch: 0/10. Loss: 1.2170:  42%|[36m████▏     [0m| 11/26 [00:12<00:16,  1.09s/it]Epoch: 0/10. Loss: 1.1428:  42%|[36m████▏     [0m| 11/26 [00:12<00:16,  1.09s/it]Epoch: 0/10. Loss: 1.1428:  46%|[36m████▌     [0m| 12/26 [00:12<00:14,  1.01s/it]Epoch: 0/10. Loss: 1.1566:  46%|[36m████▌     [0m| 12/26 [00:13<00:14,  1.01s/it]Epoch: 0/10. Loss: 1.1566:  50%|[36m█████     [0m| 13/26 [00:13<00:13,  1.00s/it]Epoch: 0/10. Loss: 1.1960:  50%|[36m█████     [0m| 13/26 [00:14<00:13,  1.00s/it]Epoch: 0/10. Loss: 1.1960:  54%|[36m█████▍    [0m| 14/26 [00:14<00:12,  1.01s/it]Epoch: 0/10. Loss: 0.9727:  54%|[36m█████▍    [0m| 14/26 [00:15<00:12,  1.01s/it]Epoch: 0/10. Loss: 0.9727:  58%|[36m█████▊    [0m| 15/26 [00:15<00:11,  1.01s/it]Epoch: 0/10. Loss: 1.4164:  58%|[36m█████▊    [0m| 15/26 [00:16<00:11,  1.01s/it]Epoch: 0/10. Loss: 1.4164:  62%|[36m██████▏   [0m| 16/26 [00:16<00:10,  1.04s/it]Epoch: 0/10. Loss: 1.4868:  62%|[36m██████▏   [0m| 16/26 [00:18<00:10,  1.04s/it]Epoch: 0/10. Loss: 1.4868:  65%|[36m██████▌   [0m| 17/26 [00:18<00:10,  1.14s/it]Epoch: 0/10. Loss: 1.0448:  65%|[36m██████▌   [0m| 17/26 [00:19<00:10,  1.14s/it]Epoch: 0/10. Loss: 1.0448:  69%|[36m██████▉   [0m| 18/26 [00:19<00:09,  1.13s/it]Epoch: 0/10. Loss: 1.0914:  69%|[36m██████▉   [0m| 18/26 [00:20<00:09,  1.13s/it]Epoch: 0/10. Loss: 1.0914:  73%|[36m███████▎  [0m| 19/26 [00:20<00:07,  1.08s/it]Epoch: 0/10. Loss: 1.3849:  73%|[36m███████▎  [0m| 19/26 [00:21<00:07,  1.08s/it]Epoch: 0/10. Loss: 1.3849:  77%|[36m███████▋  [0m| 20/26 [00:21<00:06,  1.09s/it]Epoch: 0/10. Loss: 1.0263:  77%|[36m███████▋  [0m| 20/26 [00:22<00:06,  1.09s/it]Epoch: 0/10. Loss: 1.0263:  81%|[36m████████  [0m| 21/26 [00:22<00:05,  1.06s/it]Epoch: 0/10. Loss: 1.1056:  81%|[36m████████  [0m| 21/26 [00:23<00:05,  1.06s/it]Epoch: 0/10. Loss: 1.1056:  85%|[36m████████▍ [0m| 22/26 [00:23<00:04,  1.16s/it]Epoch: 0/10. Loss: 1.1238:  85%|[36m████████▍ [0m| 22/26 [00:24<00:04,  1.16s/it]Epoch: 0/10. Loss: 1.1238:  88%|[36m████████▊ [0m| 23/26 [00:24<00:03,  1.11s/it]Epoch: 0/10. Loss: 1.0378:  88%|[36m████████▊ [0m| 23/26 [00:25<00:03,  1.11s/it]Epoch: 0/10. Loss: 1.0378:  92%|[36m█████████▏[0m| 24/26 [00:25<00:02,  1.08s/it]Epoch: 0/10. Loss: 1.2863:  92%|[36m█████████▏[0m| 24/26 [00:26<00:02,  1.08s/it]Epoch: 0/10. Loss: 1.2863:  96%|[36m█████████▌[0m| 25/26 [00:26<00:01,  1.07s/it]Epoch: 0/10. Loss: 1.0389:  96%|[36m█████████▌[0m| 25/26 [00:27<00:01,  1.07s/it]Epoch: 0/10. Loss: 1.0389: 100%|[36m██████████[0m| 26/26 [00:27<00:00,  1.02it/s]Epoch: 0/10. Loss: 1.0389: 100%|[36m██████████[0m| 26/26 [00:27<00:00,  1.07s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:05,  1.15it/s] 29%|[33m██▊       [0m| 2/7 [00:03<00:10,  2.16s/it] 43%|[33m████▎     [0m| 3/7 [00:04<00:06,  1.58s/it] 57%|[33m█████▋    [0m| 4/7 [00:08<00:07,  2.56s/it] 71%|[33m███████▏  [0m| 5/7 [00:09<00:03,  1.81s/it] 86%|[33m████████▌ [0m| 6/7 [00:10<00:01,  1.65s/it]100%|[33m██████████[0m| 7/7 [00:11<00:00,  1.48s/it]100%|[33m██████████[0m| 7/7 [00:11<00:00,  1.69s/it]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 1/10. Loss: 1.0600:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 1/10. Loss: 1.0600:   4%|[36m▍         [0m| 1/26 [00:00<00:23,  1.07it/s]Epoch: 1/10. Loss: 0.9885:   4%|[36m▍         [0m| 1/26 [00:03<00:23,  1.07it/s]Epoch: 1/10. Loss: 0.9885:   8%|[36m▊         [0m| 2/26 [00:03<00:42,  1.79s/it]Epoch: 1/10. Loss: 1.0676:   8%|[36m▊         [0m| 2/26 [00:04<00:42,  1.79s/it]Epoch: 1/10. Loss: 1.0676:  12%|[36m█▏        [0m| 3/26 [00:04<00:32,  1.43s/it]Epoch: 1/10. Loss: 1.3693:  12%|[36m█▏        [0m| 3/26 [00:05<00:32,  1.43s/it]Epoch: 1/10. Loss: 1.3693:  15%|[36m█▌        [0m| 4/26 [00:05<00:29,  1.33s/it]Epoch: 1/10. Loss: 1.3004:  15%|[36m█▌        [0m| 4/26 [00:06<00:29,  1.33s/it]Epoch: 1/10. Loss: 1.3004:  19%|[36m█▉        [0m| 5/26 [00:06<00:24,  1.17s/it]Epoch: 1/10. Loss: 1.0505:  19%|[36m█▉        [0m| 5/26 [00:07<00:24,  1.17s/it]Epoch: 1/10. Loss: 1.0505:  23%|[36m██▎       [0m| 6/26 [00:07<00:21,  1.08s/it]Epoch: 1/10. Loss: 1.1489:  23%|[36m██▎       [0m| 6/26 [00:08<00:21,  1.08s/it]Epoch: 1/10. Loss: 1.1489:  27%|[36m██▋       [0m| 7/26 [00:08<00:21,  1.15s/it]Epoch: 1/10. Loss: 0.9450:  27%|[36m██▋       [0m| 7/26 [00:09<00:21,  1.15s/it]Epoch: 1/10. Loss: 0.9450:  31%|[36m███       [0m| 8/26 [00:09<00:19,  1.11s/it]Epoch: 1/10. Loss: 1.1003:  31%|[36m███       [0m| 8/26 [00:10<00:19,  1.11s/it]Epoch: 1/10. Loss: 1.1003:  35%|[36m███▍      [0m| 9/26 [00:10<00:19,  1.13s/it]Epoch: 1/10. Loss: 1.1369:  35%|[36m███▍      [0m| 9/26 [00:11<00:19,  1.13s/it]Epoch: 1/10. Loss: 1.1369:  38%|[36m███▊      [0m| 10/26 [00:11<00:17,  1.07s/it]Epoch: 1/10. Loss: 0.9784:  38%|[36m███▊      [0m| 10/26 [00:12<00:17,  1.07s/it]Epoch: 1/10. Loss: 0.9784:  42%|[36m████▏     [0m| 11/26 [00:12<00:15,  1.06s/it]Epoch: 1/10. Loss: 1.0310:  42%|[36m████▏     [0m| 11/26 [00:13<00:15,  1.06s/it]Epoch: 1/10. Loss: 1.0310:  46%|[36m████▌     [0m| 12/26 [00:13<00:13,  1.01it/s]Epoch: 1/10. Loss: 1.1196:  46%|[36m████▌     [0m| 12/26 [00:14<00:13,  1.01it/s]Epoch: 1/10. Loss: 1.1196:  50%|[36m█████     [0m| 13/26 [00:14<00:13,  1.03s/it]Epoch: 1/10. Loss: 1.1844:  50%|[36m█████     [0m| 13/26 [00:18<00:13,  1.03s/it]Epoch: 1/10. Loss: 1.1844:  54%|[36m█████▍    [0m| 14/26 [00:18<00:20,  1.74s/it]Epoch: 1/10. Loss: 1.1049:  54%|[36m█████▍    [0m| 14/26 [00:19<00:20,  1.74s/it]Epoch: 1/10. Loss: 1.1049:  58%|[36m█████▊    [0m| 15/26 [00:19<00:16,  1.54s/it]Epoch: 1/10. Loss: 1.0365:  58%|[36m█████▊    [0m| 15/26 [00:20<00:16,  1.54s/it]Epoch: 1/10. Loss: 1.0365:  62%|[36m██████▏   [0m| 16/26 [00:20<00:13,  1.36s/it]Epoch: 1/10. Loss: 1.1385:  62%|[36m██████▏   [0m| 16/26 [00:21<00:13,  1.36s/it]Epoch: 1/10. Loss: 1.1385:  65%|[36m██████▌   [0m| 17/26 [00:21<00:11,  1.32s/it]Epoch: 1/10. Loss: 1.1167:  65%|[36m██████▌   [0m| 17/26 [00:22<00:11,  1.32s/it]Epoch: 1/10. Loss: 1.1167:  69%|[36m██████▉   [0m| 18/26 [00:22<00:10,  1.26s/it]Epoch: 1/10. Loss: 1.1929:  69%|[36m██████▉   [0m| 18/26 [00:23<00:10,  1.26s/it]Epoch: 1/10. Loss: 1.1929:  73%|[36m███████▎  [0m| 19/26 [00:23<00:07,  1.12s/it]Epoch: 1/10. Loss: 0.9942:  73%|[36m███████▎  [0m| 19/26 [00:24<00:07,  1.12s/it]Epoch: 1/10. Loss: 0.9942:  77%|[36m███████▋  [0m| 20/26 [00:24<00:06,  1.11s/it]Epoch: 1/10. Loss: 1.0115:  77%|[36m███████▋  [0m| 20/26 [00:25<00:06,  1.11s/it]Epoch: 1/10. Loss: 1.0115:  81%|[36m████████  [0m| 21/26 [00:25<00:05,  1.12s/it]Epoch: 1/10. Loss: 1.1446:  81%|[36m████████  [0m| 21/26 [00:26<00:05,  1.12s/it]Epoch: 1/10. Loss: 1.1446:  85%|[36m████████▍ [0m| 22/26 [00:26<00:04,  1.07s/it]Epoch: 1/10. Loss: 1.1295:  85%|[36m████████▍ [0m| 22/26 [00:29<00:04,  1.07s/it]Epoch: 1/10. Loss: 1.1295:  88%|[36m████████▊ [0m| 23/26 [00:29<00:04,  1.66s/it]Epoch: 1/10. Loss: 1.0500:  88%|[36m████████▊ [0m| 23/26 [00:30<00:04,  1.66s/it]Epoch: 1/10. Loss: 1.0500:  92%|[36m█████████▏[0m| 24/26 [00:30<00:02,  1.48s/it]Epoch: 1/10. Loss: 1.0536:  92%|[36m█████████▏[0m| 24/26 [00:31<00:02,  1.48s/it]Epoch: 1/10. Loss: 1.0536:  96%|[36m█████████▌[0m| 25/26 [00:31<00:01,  1.37s/it]Epoch: 1/10. Loss: 1.0743:  96%|[36m█████████▌[0m| 25/26 [00:32<00:01,  1.37s/it]Epoch: 1/10. Loss: 1.0743: 100%|[36m██████████[0m| 26/26 [00:32<00:00,  1.15s/it]Epoch: 1/10. Loss: 1.0743: 100%|[36m██████████[0m| 26/26 [00:32<00:00,  1.24s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:05,  1.16it/s] 29%|[33m██▊       [0m| 2/7 [00:01<00:04,  1.01it/s] 43%|[33m████▎     [0m| 3/7 [00:02<00:03,  1.14it/s] 57%|[33m█████▋    [0m| 4/7 [00:03<00:03,  1.05s/it] 71%|[33m███████▏  [0m| 5/7 [00:04<00:01,  1.17it/s] 86%|[33m████████▌ [0m| 6/7 [00:05<00:00,  1.13it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.46it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.22it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 2/10. Loss: 1.0376:   0%|[36m          [0m| 0/26 [00:01<?, ?it/s]Epoch: 2/10. Loss: 1.0376:   4%|[36m▍         [0m| 1/26 [00:01<00:43,  1.74s/it]Epoch: 2/10. Loss: 0.9872:   4%|[36m▍         [0m| 1/26 [00:02<00:43,  1.74s/it]Epoch: 2/10. Loss: 0.9872:   8%|[36m▊         [0m| 2/26 [00:02<00:31,  1.30s/it]Epoch: 2/10. Loss: 1.1196:   8%|[36m▊         [0m| 2/26 [00:03<00:31,  1.30s/it]Epoch: 2/10. Loss: 1.1196:  12%|[36m█▏        [0m| 3/26 [00:03<00:28,  1.24s/it]Epoch: 2/10. Loss: 1.0142:  12%|[36m█▏        [0m| 3/26 [00:04<00:28,  1.24s/it]Epoch: 2/10. Loss: 1.0142:  15%|[36m█▌        [0m| 4/26 [00:04<00:24,  1.13s/it]Epoch: 2/10. Loss: 0.9937:  15%|[36m█▌        [0m| 4/26 [00:06<00:24,  1.13s/it]Epoch: 2/10. Loss: 0.9937:  19%|[36m█▉        [0m| 5/26 [00:06<00:26,  1.26s/it]Epoch: 2/10. Loss: 1.0009:  19%|[36m█▉        [0m| 5/26 [00:07<00:26,  1.26s/it]Epoch: 2/10. Loss: 1.0009:  23%|[36m██▎       [0m| 6/26 [00:07<00:22,  1.13s/it]Epoch: 2/10. Loss: 0.9480:  23%|[36m██▎       [0m| 6/26 [00:08<00:22,  1.13s/it]Epoch: 2/10. Loss: 0.9480:  27%|[36m██▋       [0m| 7/26 [00:08<00:21,  1.11s/it]Epoch: 2/10. Loss: 1.0811:  27%|[36m██▋       [0m| 7/26 [00:09<00:21,  1.11s/it]Epoch: 2/10. Loss: 1.0811:  31%|[36m███       [0m| 8/26 [00:09<00:19,  1.10s/it]Epoch: 2/10. Loss: 0.9866:  31%|[36m███       [0m| 8/26 [00:10<00:19,  1.10s/it]Epoch: 2/10. Loss: 0.9866:  35%|[36m███▍      [0m| 9/26 [00:10<00:18,  1.08s/it]Epoch: 2/10. Loss: 1.1439:  35%|[36m███▍      [0m| 9/26 [00:11<00:18,  1.08s/it]Epoch: 2/10. Loss: 1.1439:  38%|[36m███▊      [0m| 10/26 [00:11<00:16,  1.05s/it]Epoch: 2/10. Loss: 1.0474:  38%|[36m███▊      [0m| 10/26 [00:12<00:16,  1.05s/it]Epoch: 2/10. Loss: 1.0474:  42%|[36m████▏     [0m| 11/26 [00:12<00:15,  1.06s/it]Epoch: 2/10. Loss: 0.9991:  42%|[36m████▏     [0m| 11/26 [00:13<00:15,  1.06s/it]Epoch: 2/10. Loss: 0.9991:  46%|[36m████▌     [0m| 12/26 [00:13<00:15,  1.13s/it]Epoch: 2/10. Loss: 1.0434:  46%|[36m████▌     [0m| 12/26 [00:14<00:15,  1.13s/it]Epoch: 2/10. Loss: 1.0434:  50%|[36m█████     [0m| 13/26 [00:14<00:14,  1.11s/it]Epoch: 2/10. Loss: 1.0251:  50%|[36m█████     [0m| 13/26 [00:15<00:14,  1.11s/it]Epoch: 2/10. Loss: 1.0251:  54%|[36m█████▍    [0m| 14/26 [00:15<00:12,  1.05s/it]Epoch: 2/10. Loss: 0.9971:  54%|[36m█████▍    [0m| 14/26 [00:17<00:12,  1.05s/it]Epoch: 2/10. Loss: 0.9971:  58%|[36m█████▊    [0m| 15/26 [00:17<00:14,  1.34s/it]Epoch: 2/10. Loss: 1.0074:  58%|[36m█████▊    [0m| 15/26 [00:18<00:14,  1.34s/it]Epoch: 2/10. Loss: 1.0074:  62%|[36m██████▏   [0m| 16/26 [00:18<00:12,  1.27s/it]Epoch: 2/10. Loss: 1.0126:  62%|[36m██████▏   [0m| 16/26 [00:20<00:12,  1.27s/it]Epoch: 2/10. Loss: 1.0126:  65%|[36m██████▌   [0m| 17/26 [00:20<00:11,  1.28s/it]Epoch: 2/10. Loss: 1.0445:  65%|[36m██████▌   [0m| 17/26 [00:20<00:11,  1.28s/it]Epoch: 2/10. Loss: 1.0445:  69%|[36m██████▉   [0m| 18/26 [00:20<00:09,  1.14s/it]Epoch: 2/10. Loss: 1.0943:  69%|[36m██████▉   [0m| 18/26 [00:21<00:09,  1.14s/it]Epoch: 2/10. Loss: 1.0943:  73%|[36m███████▎  [0m| 19/26 [00:21<00:07,  1.07s/it]Epoch: 2/10. Loss: 1.0026:  73%|[36m███████▎  [0m| 19/26 [00:22<00:07,  1.07s/it]Epoch: 2/10. Loss: 1.0026:  77%|[36m███████▋  [0m| 20/26 [00:23<00:06,  1.09s/it]Epoch: 2/10. Loss: 0.9843:  77%|[36m███████▋  [0m| 20/26 [00:24<00:06,  1.09s/it]Epoch: 2/10. Loss: 0.9843:  81%|[36m████████  [0m| 21/26 [00:24<00:05,  1.07s/it]Epoch: 2/10. Loss: 1.0155:  81%|[36m████████  [0m| 21/26 [00:25<00:05,  1.07s/it]Epoch: 2/10. Loss: 1.0155:  85%|[36m████████▍ [0m| 22/26 [00:25<00:04,  1.09s/it]Epoch: 2/10. Loss: 1.1001:  85%|[36m████████▍ [0m| 22/26 [00:26<00:04,  1.09s/it]Epoch: 2/10. Loss: 1.1001:  88%|[36m████████▊ [0m| 23/26 [00:26<00:03,  1.06s/it]Epoch: 2/10. Loss: 1.1060:  88%|[36m████████▊ [0m| 23/26 [00:26<00:03,  1.06s/it]Epoch: 2/10. Loss: 1.1060:  92%|[36m█████████▏[0m| 24/26 [00:26<00:01,  1.02it/s]Epoch: 2/10. Loss: 1.0647:  92%|[36m█████████▏[0m| 24/26 [00:27<00:01,  1.02it/s]Epoch: 2/10. Loss: 1.0647:  96%|[36m█████████▌[0m| 25/26 [00:27<00:00,  1.06it/s]Epoch: 2/10. Loss: 1.0049:  96%|[36m█████████▌[0m| 25/26 [00:28<00:00,  1.06it/s]Epoch: 2/10. Loss: 1.0049: 100%|[36m██████████[0m| 26/26 [00:28<00:00,  1.10it/s]Epoch: 2/10. Loss: 1.0049: 100%|[36m██████████[0m| 26/26 [00:28<00:00,  1.10s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:04,  1.20it/s] 29%|[33m██▊       [0m| 2/7 [00:01<00:04,  1.07it/s] 43%|[33m████▎     [0m| 3/7 [00:02<00:03,  1.20it/s] 57%|[33m█████▋    [0m| 4/7 [00:03<00:02,  1.01it/s] 71%|[33m███████▏  [0m| 5/7 [00:04<00:01,  1.26it/s] 86%|[33m████████▌ [0m| 6/7 [00:05<00:00,  1.18it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.50it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.28it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 3/10. Loss: 1.0372:   0%|[36m          [0m| 0/26 [00:01<?, ?it/s]Epoch: 3/10. Loss: 1.0372:   4%|[36m▍         [0m| 1/26 [00:01<00:27,  1.08s/it]Epoch: 3/10. Loss: 1.1554:   4%|[36m▍         [0m| 1/26 [00:02<00:27,  1.08s/it]Epoch: 3/10. Loss: 1.1554:   8%|[36m▊         [0m| 2/26 [00:02<00:24,  1.03s/it]Epoch: 3/10. Loss: 1.0284:   8%|[36m▊         [0m| 2/26 [00:03<00:24,  1.03s/it]Epoch: 3/10. Loss: 1.0284:  12%|[36m█▏        [0m| 3/26 [00:03<00:23,  1.01s/it]Epoch: 3/10. Loss: 0.9840:  12%|[36m█▏        [0m| 3/26 [00:04<00:23,  1.01s/it]Epoch: 3/10. Loss: 0.9840:  15%|[36m█▌        [0m| 4/26 [00:04<00:22,  1.00s/it]Epoch: 3/10. Loss: 1.1102:  15%|[36m█▌        [0m| 4/26 [00:04<00:22,  1.00s/it]Epoch: 3/10. Loss: 1.1102:  19%|[36m█▉        [0m| 5/26 [00:04<00:20,  1.05it/s]Epoch: 3/10. Loss: 1.0948:  19%|[36m█▉        [0m| 5/26 [00:05<00:20,  1.05it/s]Epoch: 3/10. Loss: 1.0948:  23%|[36m██▎       [0m| 6/26 [00:05<00:19,  1.03it/s]Epoch: 3/10. Loss: 1.1662:  23%|[36m██▎       [0m| 6/26 [00:06<00:19,  1.03it/s]Epoch: 3/10. Loss: 1.1662:  27%|[36m██▋       [0m| 7/26 [00:06<00:18,  1.04it/s]Epoch: 3/10. Loss: 0.9757:  27%|[36m██▋       [0m| 7/26 [00:07<00:18,  1.04it/s]Epoch: 3/10. Loss: 0.9757:  31%|[36m███       [0m| 8/26 [00:07<00:17,  1.01it/s]Epoch: 3/10. Loss: 1.1018:  31%|[36m███       [0m| 8/26 [00:09<00:17,  1.01it/s]Epoch: 3/10. Loss: 1.1018:  35%|[36m███▍      [0m| 9/26 [00:09<00:19,  1.13s/it]Epoch: 3/10. Loss: 1.0327:  35%|[36m███▍      [0m| 9/26 [00:10<00:19,  1.13s/it]Epoch: 3/10. Loss: 1.0327:  38%|[36m███▊      [0m| 10/26 [00:10<00:17,  1.08s/it]Epoch: 3/10. Loss: 1.0362:  38%|[36m███▊      [0m| 10/26 [00:11<00:17,  1.08s/it]Epoch: 3/10. Loss: 1.0362:  42%|[36m████▏     [0m| 11/26 [00:11<00:15,  1.03s/it]Epoch: 3/10. Loss: 0.9915:  42%|[36m████▏     [0m| 11/26 [00:12<00:15,  1.03s/it]Epoch: 3/10. Loss: 0.9915:  46%|[36m████▌     [0m| 12/26 [00:12<00:14,  1.03s/it]Epoch: 3/10. Loss: 0.9672:  46%|[36m████▌     [0m| 12/26 [00:13<00:14,  1.03s/it]Epoch: 3/10. Loss: 0.9672:  50%|[36m█████     [0m| 13/26 [00:13<00:12,  1.05it/s]Epoch: 3/10. Loss: 1.0389:  50%|[36m█████     [0m| 13/26 [00:15<00:12,  1.05it/s]Epoch: 3/10. Loss: 1.0389:  54%|[36m█████▍    [0m| 14/26 [00:15<00:16,  1.34s/it]Epoch: 3/10. Loss: 1.0251:  54%|[36m█████▍    [0m| 14/26 [00:16<00:16,  1.34s/it]Epoch: 3/10. Loss: 1.0251:  58%|[36m█████▊    [0m| 15/26 [00:16<00:13,  1.22s/it]Epoch: 3/10. Loss: 1.0033:  58%|[36m█████▊    [0m| 15/26 [00:17<00:13,  1.22s/it]Epoch: 3/10. Loss: 1.0033:  62%|[36m██████▏   [0m| 16/26 [00:17<00:12,  1.25s/it]Epoch: 3/10. Loss: 1.1250:  62%|[36m██████▏   [0m| 16/26 [00:18<00:12,  1.25s/it]Epoch: 3/10. Loss: 1.1250:  65%|[36m██████▌   [0m| 17/26 [00:19<00:11,  1.31s/it]Epoch: 3/10. Loss: 0.9801:  65%|[36m██████▌   [0m| 17/26 [00:19<00:11,  1.31s/it]Epoch: 3/10. Loss: 0.9801:  69%|[36m██████▉   [0m| 18/26 [00:19<00:09,  1.21s/it]Epoch: 3/10. Loss: 1.0249:  69%|[36m██████▉   [0m| 18/26 [00:21<00:09,  1.21s/it]Epoch: 3/10. Loss: 1.0249:  73%|[36m███████▎  [0m| 19/26 [00:21<00:08,  1.18s/it]Epoch: 3/10. Loss: 0.9804:  73%|[36m███████▎  [0m| 19/26 [00:21<00:08,  1.18s/it]Epoch: 3/10. Loss: 0.9804:  77%|[36m███████▋  [0m| 20/26 [00:21<00:06,  1.06s/it]Epoch: 3/10. Loss: 1.0266:  77%|[36m███████▋  [0m| 20/26 [00:22<00:06,  1.06s/it]Epoch: 3/10. Loss: 1.0266:  81%|[36m████████  [0m| 21/26 [00:22<00:05,  1.08s/it]Epoch: 3/10. Loss: 0.9212:  81%|[36m████████  [0m| 21/26 [00:23<00:05,  1.08s/it]Epoch: 3/10. Loss: 0.9212:  85%|[36m████████▍ [0m| 22/26 [00:23<00:04,  1.04s/it]Epoch: 3/10. Loss: 1.0518:  85%|[36m████████▍ [0m| 22/26 [00:25<00:04,  1.04s/it]Epoch: 3/10. Loss: 1.0518:  88%|[36m████████▊ [0m| 23/26 [00:25<00:03,  1.08s/it]Epoch: 3/10. Loss: 1.1132:  88%|[36m████████▊ [0m| 23/26 [00:26<00:03,  1.08s/it]Epoch: 3/10. Loss: 1.1132:  92%|[36m█████████▏[0m| 24/26 [00:26<00:02,  1.05s/it]Epoch: 3/10. Loss: 1.0148:  92%|[36m█████████▏[0m| 24/26 [00:26<00:02,  1.05s/it]Epoch: 3/10. Loss: 1.0148:  96%|[36m█████████▌[0m| 25/26 [00:27<00:01,  1.02s/it]Epoch: 3/10. Loss: 1.0576:  96%|[36m█████████▌[0m| 25/26 [00:27<00:01,  1.02s/it]Epoch: 3/10. Loss: 1.0576: 100%|[36m██████████[0m| 26/26 [00:27<00:00,  1.06it/s]Epoch: 3/10. Loss: 1.0576: 100%|[36m██████████[0m| 26/26 [00:27<00:00,  1.07s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:05,  1.17it/s] 29%|[33m██▊       [0m| 2/7 [00:01<00:04,  1.05it/s] 43%|[33m████▎     [0m| 3/7 [00:02<00:03,  1.17it/s] 57%|[33m█████▋    [0m| 4/7 [00:03<00:03,  1.01s/it] 71%|[33m███████▏  [0m| 5/7 [00:04<00:01,  1.24it/s] 86%|[33m████████▌ [0m| 6/7 [00:05<00:00,  1.17it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.51it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.27it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 4/10. Loss: 1.0193:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 4/10. Loss: 1.0193:   4%|[36m▍         [0m| 1/26 [00:00<00:23,  1.07it/s]Epoch: 4/10. Loss: 1.0305:   4%|[36m▍         [0m| 1/26 [00:01<00:23,  1.07it/s]Epoch: 4/10. Loss: 1.0305:   8%|[36m▊         [0m| 2/26 [00:01<00:24,  1.01s/it]Epoch: 4/10. Loss: 1.0943:   8%|[36m▊         [0m| 2/26 [00:03<00:24,  1.01s/it]Epoch: 4/10. Loss: 1.0943:  12%|[36m█▏        [0m| 3/26 [00:03<00:25,  1.11s/it]Epoch: 4/10. Loss: 0.9931:  12%|[36m█▏        [0m| 3/26 [00:04<00:25,  1.11s/it]Epoch: 4/10. Loss: 0.9931:  15%|[36m█▌        [0m| 4/26 [00:04<00:22,  1.04s/it]Epoch: 4/10. Loss: 1.0163:  15%|[36m█▌        [0m| 4/26 [00:05<00:22,  1.04s/it]Epoch: 4/10. Loss: 1.0163:  19%|[36m█▉        [0m| 5/26 [00:05<00:21,  1.03s/it]Epoch: 4/10. Loss: 1.0182:  19%|[36m█▉        [0m| 5/26 [00:06<00:21,  1.03s/it]Epoch: 4/10. Loss: 1.0182:  23%|[36m██▎       [0m| 6/26 [00:06<00:20,  1.01s/it]Epoch: 4/10. Loss: 1.0404:  23%|[36m██▎       [0m| 6/26 [00:07<00:20,  1.01s/it]Epoch: 4/10. Loss: 1.0404:  27%|[36m██▋       [0m| 7/26 [00:07<00:19,  1.00s/it]Epoch: 4/10. Loss: 0.9966:  27%|[36m██▋       [0m| 7/26 [00:08<00:19,  1.00s/it]Epoch: 4/10. Loss: 0.9966:  31%|[36m███       [0m| 8/26 [00:08<00:18,  1.02s/it]Epoch: 4/10. Loss: 0.9506:  31%|[36m███       [0m| 8/26 [00:08<00:18,  1.02s/it]Epoch: 4/10. Loss: 0.9506:  35%|[36m███▍      [0m| 9/26 [00:09<00:16,  1.04it/s]Epoch: 4/10. Loss: 1.0381:  35%|[36m███▍      [0m| 9/26 [00:09<00:16,  1.04it/s]Epoch: 4/10. Loss: 1.0381:  38%|[36m███▊      [0m| 10/26 [00:09<00:14,  1.09it/s]Epoch: 4/10. Loss: 0.9260:  38%|[36m███▊      [0m| 10/26 [00:12<00:14,  1.09it/s]Epoch: 4/10. Loss: 0.9260:  42%|[36m████▏     [0m| 11/26 [00:12<00:20,  1.35s/it]Epoch: 4/10. Loss: 0.9382:  42%|[36m████▏     [0m| 11/26 [00:13<00:20,  1.35s/it]Epoch: 4/10. Loss: 0.9382:  46%|[36m████▌     [0m| 12/26 [00:13<00:17,  1.23s/it]Epoch: 4/10. Loss: 0.9755:  46%|[36m████▌     [0m| 12/26 [00:14<00:17,  1.23s/it]Epoch: 4/10. Loss: 0.9755:  50%|[36m█████     [0m| 13/26 [00:14<00:14,  1.14s/it]Epoch: 4/10. Loss: 1.0275:  50%|[36m█████     [0m| 13/26 [00:16<00:14,  1.14s/it]Epoch: 4/10. Loss: 1.0275:  54%|[36m█████▍    [0m| 14/26 [00:16<00:18,  1.53s/it]Epoch: 4/10. Loss: 1.0718:  54%|[36m█████▍    [0m| 14/26 [00:17<00:18,  1.53s/it]Epoch: 4/10. Loss: 1.0718:  58%|[36m█████▊    [0m| 15/26 [00:17<00:15,  1.39s/it]Epoch: 4/10. Loss: 1.0238:  58%|[36m█████▊    [0m| 15/26 [00:18<00:15,  1.39s/it]Epoch: 4/10. Loss: 1.0238:  62%|[36m██████▏   [0m| 16/26 [00:18<00:13,  1.31s/it]Epoch: 4/10. Loss: 0.9929:  62%|[36m██████▏   [0m| 16/26 [00:19<00:13,  1.31s/it]Epoch: 4/10. Loss: 0.9929:  65%|[36m██████▌   [0m| 17/26 [00:19<00:10,  1.15s/it]Epoch: 4/10. Loss: 1.0377:  65%|[36m██████▌   [0m| 17/26 [00:20<00:10,  1.15s/it]Epoch: 4/10. Loss: 1.0377:  69%|[36m██████▉   [0m| 18/26 [00:20<00:08,  1.08s/it]Epoch: 4/10. Loss: 0.9892:  69%|[36m██████▉   [0m| 18/26 [00:21<00:08,  1.08s/it]Epoch: 4/10. Loss: 0.9892:  73%|[36m███████▎  [0m| 19/26 [00:21<00:07,  1.06s/it]Epoch: 4/10. Loss: 0.9903:  73%|[36m███████▎  [0m| 19/26 [00:23<00:07,  1.06s/it]Epoch: 4/10. Loss: 0.9903:  77%|[36m███████▋  [0m| 20/26 [00:23<00:08,  1.35s/it]Epoch: 4/10. Loss: 1.0356:  77%|[36m███████▋  [0m| 20/26 [00:24<00:08,  1.35s/it]Epoch: 4/10. Loss: 1.0356:  81%|[36m████████  [0m| 21/26 [00:24<00:06,  1.21s/it]Epoch: 4/10. Loss: 1.0105:  81%|[36m████████  [0m| 21/26 [00:25<00:06,  1.21s/it]Epoch: 4/10. Loss: 1.0105:  85%|[36m████████▍ [0m| 22/26 [00:25<00:05,  1.30s/it]Epoch: 4/10. Loss: 0.9650:  85%|[36m████████▍ [0m| 22/26 [00:28<00:05,  1.30s/it]Epoch: 4/10. Loss: 0.9650:  88%|[36m████████▊ [0m| 23/26 [00:28<00:05,  1.80s/it]Epoch: 4/10. Loss: 1.0167:  88%|[36m████████▊ [0m| 23/26 [00:30<00:05,  1.80s/it]Epoch: 4/10. Loss: 1.0167:  92%|[36m█████████▏[0m| 24/26 [00:30<00:03,  1.67s/it]Epoch: 4/10. Loss: 1.0539:  92%|[36m█████████▏[0m| 24/26 [00:31<00:03,  1.67s/it]Epoch: 4/10. Loss: 1.0539:  96%|[36m█████████▌[0m| 25/26 [00:31<00:01,  1.46s/it]Epoch: 4/10. Loss: 1.0087:  96%|[36m█████████▌[0m| 25/26 [00:31<00:01,  1.46s/it]Epoch: 4/10. Loss: 1.0087: 100%|[36m██████████[0m| 26/26 [00:31<00:00,  1.26s/it]Epoch: 4/10. Loss: 1.0087: 100%|[36m██████████[0m| 26/26 [00:31<00:00,  1.23s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:05,  1.10it/s] 29%|[33m██▊       [0m| 2/7 [00:01<00:05,  1.00s/it] 43%|[33m████▎     [0m| 3/7 [00:02<00:03,  1.11it/s] 57%|[33m█████▋    [0m| 4/7 [00:04<00:03,  1.05s/it] 71%|[33m███████▏  [0m| 5/7 [00:04<00:01,  1.20it/s] 86%|[33m████████▌ [0m| 6/7 [00:05<00:00,  1.15it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.48it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.23it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 5/10. Loss: 0.9944:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 5/10. Loss: 0.9944:   4%|[36m▍         [0m| 1/26 [00:00<00:24,  1.01it/s]Epoch: 5/10. Loss: 1.0329:   4%|[36m▍         [0m| 1/26 [00:02<00:24,  1.01it/s]Epoch: 5/10. Loss: 1.0329:   8%|[36m▊         [0m| 2/26 [00:02<00:25,  1.04s/it]Epoch: 5/10. Loss: 0.9258:   8%|[36m▊         [0m| 2/26 [00:02<00:25,  1.04s/it]Epoch: 5/10. Loss: 0.9258:  12%|[36m█▏        [0m| 3/26 [00:02<00:21,  1.09it/s]Epoch: 5/10. Loss: 1.0028:  12%|[36m█▏        [0m| 3/26 [00:04<00:21,  1.09it/s]Epoch: 5/10. Loss: 1.0028:  15%|[36m█▌        [0m| 4/26 [00:04<00:28,  1.30s/it]Epoch: 5/10. Loss: 1.0650:  15%|[36m█▌        [0m| 4/26 [00:06<00:28,  1.30s/it]Epoch: 5/10. Loss: 1.0650:  19%|[36m█▉        [0m| 5/26 [00:06<00:28,  1.34s/it]Epoch: 5/10. Loss: 1.0232:  19%|[36m█▉        [0m| 5/26 [00:07<00:28,  1.34s/it]Epoch: 5/10. Loss: 1.0232:  23%|[36m██▎       [0m| 6/26 [00:07<00:24,  1.24s/it]Epoch: 5/10. Loss: 1.0201:  23%|[36m██▎       [0m| 6/26 [00:08<00:24,  1.24s/it]Epoch: 5/10. Loss: 1.0201:  27%|[36m██▋       [0m| 7/26 [00:08<00:21,  1.14s/it]Epoch: 5/10. Loss: 0.9892:  27%|[36m██▋       [0m| 7/26 [00:09<00:21,  1.14s/it]Epoch: 5/10. Loss: 0.9892:  31%|[36m███       [0m| 8/26 [00:09<00:23,  1.31s/it]Epoch: 5/10. Loss: 0.9989:  31%|[36m███       [0m| 8/26 [00:10<00:23,  1.31s/it]Epoch: 5/10. Loss: 0.9989:  35%|[36m███▍      [0m| 9/26 [00:10<00:21,  1.28s/it]Epoch: 5/10. Loss: 0.9532:  35%|[36m███▍      [0m| 9/26 [00:11<00:21,  1.28s/it]Epoch: 5/10. Loss: 0.9532:  38%|[36m███▊      [0m| 10/26 [00:12<00:19,  1.20s/it]Epoch: 5/10. Loss: 0.9677:  38%|[36m███▊      [0m| 10/26 [00:12<00:19,  1.20s/it]Epoch: 5/10. Loss: 0.9677:  42%|[36m████▏     [0m| 11/26 [00:13<00:17,  1.14s/it]Epoch: 5/10. Loss: 1.0096:  42%|[36m████▏     [0m| 11/26 [00:13<00:17,  1.14s/it]Epoch: 5/10. Loss: 1.0096:  46%|[36m████▌     [0m| 12/26 [00:14<00:15,  1.10s/it]Epoch: 5/10. Loss: 0.9658:  46%|[36m████▌     [0m| 12/26 [00:18<00:15,  1.10s/it]Epoch: 5/10. Loss: 0.9658:  50%|[36m█████     [0m| 13/26 [00:18<00:28,  2.23s/it]Epoch: 5/10. Loss: 0.9953:  50%|[36m█████     [0m| 13/26 [00:20<00:28,  2.23s/it]Epoch: 5/10. Loss: 0.9953:  54%|[36m█████▍    [0m| 14/26 [00:20<00:25,  2.12s/it]Epoch: 5/10. Loss: 0.9624:  54%|[36m█████▍    [0m| 14/26 [00:21<00:25,  2.12s/it]Epoch: 5/10. Loss: 0.9624:  58%|[36m█████▊    [0m| 15/26 [00:21<00:19,  1.79s/it]Epoch: 5/10. Loss: 1.0964:  58%|[36m█████▊    [0m| 15/26 [00:22<00:19,  1.79s/it]Epoch: 5/10. Loss: 1.0964:  62%|[36m██████▏   [0m| 16/26 [00:22<00:15,  1.55s/it]Epoch: 5/10. Loss: 1.0591:  62%|[36m██████▏   [0m| 16/26 [00:25<00:15,  1.55s/it]Epoch: 5/10. Loss: 1.0591:  65%|[36m██████▌   [0m| 17/26 [00:25<00:17,  1.91s/it]Epoch: 5/10. Loss: 1.0097:  65%|[36m██████▌   [0m| 17/26 [00:26<00:17,  1.91s/it]Epoch: 5/10. Loss: 1.0097:  69%|[36m██████▉   [0m| 18/26 [00:26<00:13,  1.73s/it]Epoch: 5/10. Loss: 0.9206:  69%|[36m██████▉   [0m| 18/26 [00:27<00:13,  1.73s/it]Epoch: 5/10. Loss: 0.9206:  73%|[36m███████▎  [0m| 19/26 [00:27<00:10,  1.52s/it]Epoch: 5/10. Loss: 0.9722:  73%|[36m███████▎  [0m| 19/26 [00:28<00:10,  1.52s/it]Epoch: 5/10. Loss: 0.9722:  77%|[36m███████▋  [0m| 20/26 [00:28<00:07,  1.31s/it]Epoch: 5/10. Loss: 0.9521:  77%|[36m███████▋  [0m| 20/26 [00:29<00:07,  1.31s/it]Epoch: 5/10. Loss: 0.9521:  81%|[36m████████  [0m| 21/26 [00:29<00:06,  1.22s/it]Epoch: 5/10. Loss: 1.0503:  81%|[36m████████  [0m| 21/26 [00:30<00:06,  1.22s/it]Epoch: 5/10. Loss: 1.0503:  85%|[36m████████▍ [0m| 22/26 [00:30<00:04,  1.20s/it]Epoch: 5/10. Loss: 0.9654:  85%|[36m████████▍ [0m| 22/26 [00:31<00:04,  1.20s/it]Epoch: 5/10. Loss: 0.9654:  88%|[36m████████▊ [0m| 23/26 [00:31<00:03,  1.14s/it]Epoch: 5/10. Loss: 0.9765:  88%|[36m████████▊ [0m| 23/26 [00:32<00:03,  1.14s/it]Epoch: 5/10. Loss: 0.9765:  92%|[36m█████████▏[0m| 24/26 [00:33<00:02,  1.16s/it]Epoch: 5/10. Loss: 1.0627:  92%|[36m█████████▏[0m| 24/26 [00:33<00:02,  1.16s/it]Epoch: 5/10. Loss: 1.0627:  96%|[36m█████████▌[0m| 25/26 [00:33<00:01,  1.10s/it]Epoch: 5/10. Loss: 1.0219:  96%|[36m█████████▌[0m| 25/26 [00:34<00:01,  1.10s/it]Epoch: 5/10. Loss: 1.0219: 100%|[36m██████████[0m| 26/26 [00:34<00:00,  1.03it/s]Epoch: 5/10. Loss: 1.0219: 100%|[36m██████████[0m| 26/26 [00:34<00:00,  1.33s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:04<00:28,  4.81s/it] 29%|[33m██▊       [0m| 2/7 [00:07<00:17,  3.49s/it] 43%|[33m████▎     [0m| 3/7 [00:08<00:08,  2.25s/it] 57%|[33m█████▋    [0m| 4/7 [00:09<00:05,  1.88s/it] 71%|[33m███████▏  [0m| 5/7 [00:09<00:02,  1.36s/it] 86%|[33m████████▌ [0m| 6/7 [00:11<00:01,  1.50s/it]100%|[33m██████████[0m| 7/7 [00:11<00:00,  1.10s/it]100%|[33m██████████[0m| 7/7 [00:11<00:00,  1.71s/it]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 6/10. Loss: 0.9425:   0%|[36m          [0m| 0/26 [00:01<?, ?it/s]Epoch: 6/10. Loss: 0.9425:   4%|[36m▍         [0m| 1/26 [00:01<00:41,  1.66s/it]Epoch: 6/10. Loss: 1.0296:   4%|[36m▍         [0m| 1/26 [00:02<00:41,  1.66s/it]Epoch: 6/10. Loss: 1.0296:   8%|[36m▊         [0m| 2/26 [00:02<00:29,  1.23s/it]Epoch: 6/10. Loss: 0.9629:   8%|[36m▊         [0m| 2/26 [00:03<00:29,  1.23s/it]Epoch: 6/10. Loss: 0.9629:  12%|[36m█▏        [0m| 3/26 [00:03<00:25,  1.10s/it]Epoch: 6/10. Loss: 0.9741:  12%|[36m█▏        [0m| 3/26 [00:05<00:25,  1.10s/it]Epoch: 6/10. Loss: 0.9741:  15%|[36m█▌        [0m| 4/26 [00:05<00:30,  1.39s/it]Epoch: 6/10. Loss: 0.9645:  15%|[36m█▌        [0m| 4/26 [00:06<00:30,  1.39s/it]Epoch: 6/10. Loss: 0.9645:  19%|[36m█▉        [0m| 5/26 [00:06<00:26,  1.25s/it]Epoch: 6/10. Loss: 1.0377:  19%|[36m█▉        [0m| 5/26 [00:09<00:26,  1.25s/it]Epoch: 6/10. Loss: 1.0377:  23%|[36m██▎       [0m| 6/26 [00:09<00:34,  1.75s/it]Epoch: 6/10. Loss: 1.0408:  23%|[36m██▎       [0m| 6/26 [00:11<00:34,  1.75s/it]Epoch: 6/10. Loss: 1.0408:  27%|[36m██▋       [0m| 7/26 [00:11<00:35,  1.87s/it]Epoch: 6/10. Loss: 1.0383:  27%|[36m██▋       [0m| 7/26 [00:12<00:35,  1.87s/it]Epoch: 6/10. Loss: 1.0383:  31%|[36m███       [0m| 8/26 [00:12<00:29,  1.61s/it]Epoch: 6/10. Loss: 1.0993:  31%|[36m███       [0m| 8/26 [00:13<00:29,  1.61s/it]Epoch: 6/10. Loss: 1.0993:  35%|[36m███▍      [0m| 9/26 [00:13<00:24,  1.42s/it]Epoch: 6/10. Loss: 1.0284:  35%|[36m███▍      [0m| 9/26 [00:14<00:24,  1.42s/it]Epoch: 6/10. Loss: 1.0284:  38%|[36m███▊      [0m| 10/26 [00:14<00:21,  1.34s/it]Epoch: 6/10. Loss: 1.0292:  38%|[36m███▊      [0m| 10/26 [00:15<00:21,  1.34s/it]Epoch: 6/10. Loss: 1.0292:  42%|[36m████▏     [0m| 11/26 [00:15<00:18,  1.26s/it]Epoch: 6/10. Loss: 1.0443:  42%|[36m████▏     [0m| 11/26 [00:16<00:18,  1.26s/it]Epoch: 6/10. Loss: 1.0443:  46%|[36m████▌     [0m| 12/26 [00:16<00:18,  1.32s/it]Epoch: 6/10. Loss: 1.0758:  46%|[36m████▌     [0m| 12/26 [00:18<00:18,  1.32s/it]Epoch: 6/10. Loss: 1.0758:  50%|[36m█████     [0m| 13/26 [00:18<00:16,  1.28s/it]Epoch: 6/10. Loss: 0.9863:  50%|[36m█████     [0m| 13/26 [00:19<00:16,  1.28s/it]Epoch: 6/10. Loss: 0.9863:  54%|[36m█████▍    [0m| 14/26 [00:19<00:14,  1.21s/it]Epoch: 6/10. Loss: 1.1024:  54%|[36m█████▍    [0m| 14/26 [00:22<00:14,  1.21s/it]Epoch: 6/10. Loss: 1.1024:  58%|[36m█████▊    [0m| 15/26 [00:22<00:19,  1.81s/it]Epoch: 6/10. Loss: 1.0804:  58%|[36m█████▊    [0m| 15/26 [00:23<00:19,  1.81s/it]Epoch: 6/10. Loss: 1.0804:  62%|[36m██████▏   [0m| 16/26 [00:23<00:17,  1.70s/it]Epoch: 6/10. Loss: 1.0477:  62%|[36m██████▏   [0m| 16/26 [00:24<00:17,  1.70s/it]Epoch: 6/10. Loss: 1.0477:  65%|[36m██████▌   [0m| 17/26 [00:24<00:13,  1.49s/it]Epoch: 6/10. Loss: 1.0404:  65%|[36m██████▌   [0m| 17/26 [00:25<00:13,  1.49s/it]Epoch: 6/10. Loss: 1.0404:  69%|[36m██████▉   [0m| 18/26 [00:25<00:10,  1.34s/it]Epoch: 6/10. Loss: 0.9893:  69%|[36m██████▉   [0m| 18/26 [00:27<00:10,  1.34s/it]Epoch: 6/10. Loss: 0.9893:  73%|[36m███████▎  [0m| 19/26 [00:27<00:09,  1.39s/it]Epoch: 6/10. Loss: 0.9968:  73%|[36m███████▎  [0m| 19/26 [00:28<00:09,  1.39s/it]Epoch: 6/10. Loss: 0.9968:  77%|[36m███████▋  [0m| 20/26 [00:28<00:07,  1.28s/it]Epoch: 6/10. Loss: 0.9731:  77%|[36m███████▋  [0m| 20/26 [00:31<00:07,  1.28s/it]Epoch: 6/10. Loss: 0.9731:  81%|[36m████████  [0m| 21/26 [00:31<00:08,  1.70s/it]Epoch: 6/10. Loss: 1.0271:  81%|[36m████████  [0m| 21/26 [00:32<00:08,  1.70s/it]Epoch: 6/10. Loss: 1.0271:  85%|[36m████████▍ [0m| 22/26 [00:32<00:06,  1.52s/it]Epoch: 6/10. Loss: 1.0967:  85%|[36m████████▍ [0m| 22/26 [00:33<00:06,  1.52s/it]Epoch: 6/10. Loss: 1.0967:  88%|[36m████████▊ [0m| 23/26 [00:33<00:04,  1.44s/it]Epoch: 6/10. Loss: 1.0026:  88%|[36m████████▊ [0m| 23/26 [00:34<00:04,  1.44s/it]Epoch: 6/10. Loss: 1.0026:  92%|[36m█████████▏[0m| 24/26 [00:34<00:02,  1.37s/it]Epoch: 6/10. Loss: 1.0283:  92%|[36m█████████▏[0m| 24/26 [00:35<00:02,  1.37s/it]Epoch: 6/10. Loss: 1.0283:  96%|[36m█████████▌[0m| 25/26 [00:35<00:01,  1.27s/it]Epoch: 6/10. Loss: 1.0029:  96%|[36m█████████▌[0m| 25/26 [00:36<00:01,  1.27s/it]Epoch: 6/10. Loss: 1.0029: 100%|[36m██████████[0m| 26/26 [00:36<00:00,  1.11s/it]Epoch: 6/10. Loss: 1.0029: 100%|[36m██████████[0m| 26/26 [00:36<00:00,  1.40s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:04<00:24,  4.03s/it] 29%|[33m██▊       [0m| 2/7 [00:08<00:22,  4.46s/it] 43%|[33m████▎     [0m| 3/7 [00:09<00:11,  2.86s/it] 57%|[33m█████▋    [0m| 4/7 [00:11<00:07,  2.41s/it] 71%|[33m███████▏  [0m| 5/7 [00:11<00:03,  1.71s/it] 86%|[33m████████▌ [0m| 6/7 [00:12<00:01,  1.44s/it]100%|[33m██████████[0m| 7/7 [00:13<00:00,  1.06s/it]100%|[33m██████████[0m| 7/7 [00:13<00:00,  1.88s/it]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 7/10. Loss: 0.9572:   0%|[36m          [0m| 0/26 [00:01<?, ?it/s]Epoch: 7/10. Loss: 0.9572:   4%|[36m▍         [0m| 1/26 [00:01<00:40,  1.63s/it]Epoch: 7/10. Loss: 0.9899:   4%|[36m▍         [0m| 1/26 [00:02<00:40,  1.63s/it]Epoch: 7/10. Loss: 0.9899:   8%|[36m▊         [0m| 2/26 [00:02<00:26,  1.12s/it]Epoch: 7/10. Loss: 0.9989:   8%|[36m▊         [0m| 2/26 [00:03<00:26,  1.12s/it]Epoch: 7/10. Loss: 0.9989:  12%|[36m█▏        [0m| 3/26 [00:03<00:25,  1.09s/it]Epoch: 7/10. Loss: 1.1030:  12%|[36m█▏        [0m| 3/26 [00:04<00:25,  1.09s/it]Epoch: 7/10. Loss: 1.1030:  15%|[36m█▌        [0m| 4/26 [00:04<00:27,  1.25s/it]Epoch: 7/10. Loss: 1.0238:  15%|[36m█▌        [0m| 4/26 [00:06<00:27,  1.25s/it]Epoch: 7/10. Loss: 1.0238:  19%|[36m█▉        [0m| 5/26 [00:06<00:27,  1.31s/it]Epoch: 7/10. Loss: 1.0188:  19%|[36m█▉        [0m| 5/26 [00:07<00:27,  1.31s/it]Epoch: 7/10. Loss: 1.0188:  23%|[36m██▎       [0m| 6/26 [00:07<00:24,  1.20s/it]Epoch: 7/10. Loss: 1.0540:  23%|[36m██▎       [0m| 6/26 [00:08<00:24,  1.20s/it]Epoch: 7/10. Loss: 1.0540:  27%|[36m██▋       [0m| 7/26 [00:08<00:21,  1.15s/it]Epoch: 7/10. Loss: 1.0220:  27%|[36m██▋       [0m| 7/26 [00:09<00:21,  1.15s/it]Epoch: 7/10. Loss: 1.0220:  31%|[36m███       [0m| 8/26 [00:09<00:19,  1.09s/it]Epoch: 7/10. Loss: 0.9658:  31%|[36m███       [0m| 8/26 [00:10<00:19,  1.09s/it]Epoch: 7/10. Loss: 0.9658:  35%|[36m███▍      [0m| 9/26 [00:10<00:18,  1.08s/it]Epoch: 7/10. Loss: 0.9831:  35%|[36m███▍      [0m| 9/26 [00:11<00:18,  1.08s/it]Epoch: 7/10. Loss: 0.9831:  38%|[36m███▊      [0m| 10/26 [00:11<00:16,  1.06s/it]Epoch: 7/10. Loss: 0.9645:  38%|[36m███▊      [0m| 10/26 [00:12<00:16,  1.06s/it]Epoch: 7/10. Loss: 0.9645:  42%|[36m████▏     [0m| 11/26 [00:12<00:15,  1.04s/it]Epoch: 7/10. Loss: 0.9716:  42%|[36m████▏     [0m| 11/26 [00:16<00:15,  1.04s/it]Epoch: 7/10. Loss: 0.9716:  46%|[36m████▌     [0m| 12/26 [00:16<00:26,  1.87s/it]Epoch: 7/10. Loss: 0.9491:  46%|[36m████▌     [0m| 12/26 [00:17<00:26,  1.87s/it]Epoch: 7/10. Loss: 0.9491:  50%|[36m█████     [0m| 13/26 [00:17<00:20,  1.57s/it]Epoch: 7/10. Loss: 1.0401:  50%|[36m█████     [0m| 13/26 [00:18<00:20,  1.57s/it]Epoch: 7/10. Loss: 1.0401:  54%|[36m█████▍    [0m| 14/26 [00:18<00:18,  1.51s/it]Epoch: 7/10. Loss: 0.9963:  54%|[36m█████▍    [0m| 14/26 [00:19<00:18,  1.51s/it]Epoch: 7/10. Loss: 0.9963:  58%|[36m█████▊    [0m| 15/26 [00:19<00:14,  1.36s/it]Epoch: 7/10. Loss: 0.9830:  58%|[36m█████▊    [0m| 15/26 [00:20<00:14,  1.36s/it]Epoch: 7/10. Loss: 0.9830:  62%|[36m██████▏   [0m| 16/26 [00:20<00:12,  1.24s/it]Epoch: 7/10. Loss: 0.9977:  62%|[36m██████▏   [0m| 16/26 [00:21<00:12,  1.24s/it]Epoch: 7/10. Loss: 0.9977:  65%|[36m██████▌   [0m| 17/26 [00:21<00:11,  1.23s/it]Epoch: 7/10. Loss: 0.9978:  65%|[36m██████▌   [0m| 17/26 [00:22<00:11,  1.23s/it]Epoch: 7/10. Loss: 0.9978:  69%|[36m██████▉   [0m| 18/26 [00:22<00:09,  1.15s/it]Epoch: 7/10. Loss: 0.9901:  69%|[36m██████▉   [0m| 18/26 [00:23<00:09,  1.15s/it]Epoch: 7/10. Loss: 0.9901:  73%|[36m███████▎  [0m| 19/26 [00:23<00:07,  1.10s/it]Epoch: 7/10. Loss: 0.9864:  73%|[36m███████▎  [0m| 19/26 [00:24<00:07,  1.10s/it]Epoch: 7/10. Loss: 0.9864:  77%|[36m███████▋  [0m| 20/26 [00:24<00:06,  1.05s/it]Epoch: 7/10. Loss: 0.9672:  77%|[36m███████▋  [0m| 20/26 [00:26<00:06,  1.05s/it]Epoch: 7/10. Loss: 0.9672:  81%|[36m████████  [0m| 21/26 [00:26<00:07,  1.47s/it]Epoch: 7/10. Loss: 1.0004:  81%|[36m████████  [0m| 21/26 [00:29<00:07,  1.47s/it]Epoch: 7/10. Loss: 1.0004:  85%|[36m████████▍ [0m| 22/26 [00:29<00:07,  1.86s/it]Epoch: 7/10. Loss: 1.0076:  85%|[36m████████▍ [0m| 22/26 [00:30<00:07,  1.86s/it]Epoch: 7/10. Loss: 1.0076:  88%|[36m████████▊ [0m| 23/26 [00:30<00:05,  1.67s/it]Epoch: 7/10. Loss: 0.9603:  88%|[36m████████▊ [0m| 23/26 [00:32<00:05,  1.67s/it]Epoch: 7/10. Loss: 0.9603:  92%|[36m█████████▏[0m| 24/26 [00:32<00:03,  1.74s/it]Epoch: 7/10. Loss: 0.9790:  92%|[36m█████████▏[0m| 24/26 [00:33<00:03,  1.74s/it]Epoch: 7/10. Loss: 0.9790:  96%|[36m█████████▌[0m| 25/26 [00:33<00:01,  1.52s/it]Epoch: 7/10. Loss: 0.9590:  96%|[36m█████████▌[0m| 25/26 [00:34<00:01,  1.52s/it]Epoch: 7/10. Loss: 0.9590: 100%|[36m██████████[0m| 26/26 [00:34<00:00,  1.25s/it]Epoch: 7/10. Loss: 0.9590: 100%|[36m██████████[0m| 26/26 [00:34<00:00,  1.33s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:01<00:06,  1.09s/it] 29%|[33m██▊       [0m| 2/7 [00:02<00:05,  1.14s/it] 43%|[33m████▎     [0m| 3/7 [00:03<00:04,  1.01s/it] 57%|[33m█████▋    [0m| 4/7 [00:07<00:07,  2.33s/it] 71%|[33m███████▏  [0m| 5/7 [00:08<00:03,  1.87s/it] 86%|[33m████████▌ [0m| 6/7 [00:10<00:01,  1.91s/it]100%|[33m██████████[0m| 7/7 [00:11<00:00,  1.47s/it]100%|[33m██████████[0m| 7/7 [00:11<00:00,  1.58s/it]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 8/10. Loss: 1.0284:   0%|[36m          [0m| 0/26 [00:01<?, ?it/s]Epoch: 8/10. Loss: 1.0284:   4%|[36m▍         [0m| 1/26 [00:01<00:27,  1.12s/it]Epoch: 8/10. Loss: 1.0870:   4%|[36m▍         [0m| 1/26 [00:01<00:27,  1.12s/it]Epoch: 8/10. Loss: 1.0870:   8%|[36m▊         [0m| 2/26 [00:02<00:23,  1.01it/s]Epoch: 8/10. Loss: 0.9997:   8%|[36m▊         [0m| 2/26 [00:02<00:23,  1.01it/s]Epoch: 8/10. Loss: 0.9997:  12%|[36m█▏        [0m| 3/26 [00:02<00:22,  1.02it/s]Epoch: 8/10. Loss: 0.9607:  12%|[36m█▏        [0m| 3/26 [00:04<00:22,  1.02it/s]Epoch: 8/10. Loss: 0.9607:  15%|[36m█▌        [0m| 4/26 [00:04<00:23,  1.08s/it]Epoch: 8/10. Loss: 0.9123:  15%|[36m█▌        [0m| 4/26 [00:05<00:23,  1.08s/it]Epoch: 8/10. Loss: 0.9123:  19%|[36m█▉        [0m| 5/26 [00:05<00:22,  1.09s/it]Epoch: 8/10. Loss: 0.9190:  19%|[36m█▉        [0m| 5/26 [00:06<00:22,  1.09s/it]Epoch: 8/10. Loss: 0.9190:  23%|[36m██▎       [0m| 6/26 [00:06<00:22,  1.13s/it]Epoch: 8/10. Loss: 0.9979:  23%|[36m██▎       [0m| 6/26 [00:07<00:22,  1.13s/it]Epoch: 8/10. Loss: 0.9979:  27%|[36m██▋       [0m| 7/26 [00:07<00:19,  1.04s/it]Epoch: 8/10. Loss: 1.0079:  27%|[36m██▋       [0m| 7/26 [00:08<00:19,  1.04s/it]Epoch: 8/10. Loss: 1.0079:  31%|[36m███       [0m| 8/26 [00:08<00:17,  1.01it/s]Epoch: 8/10. Loss: 1.0178:  31%|[36m███       [0m| 8/26 [00:09<00:17,  1.01it/s]Epoch: 8/10. Loss: 1.0178:  35%|[36m███▍      [0m| 9/26 [00:09<00:17,  1.02s/it]Epoch: 8/10. Loss: 0.9389:  35%|[36m███▍      [0m| 9/26 [00:10<00:17,  1.02s/it]Epoch: 8/10. Loss: 0.9389:  38%|[36m███▊      [0m| 10/26 [00:10<00:16,  1.05s/it]Epoch: 8/10. Loss: 0.9543:  38%|[36m███▊      [0m| 10/26 [00:12<00:16,  1.05s/it]Epoch: 8/10. Loss: 0.9543:  42%|[36m████▏     [0m| 11/26 [00:12<00:19,  1.31s/it]Epoch: 8/10. Loss: 0.9691:  42%|[36m████▏     [0m| 11/26 [00:13<00:19,  1.31s/it]Epoch: 8/10. Loss: 0.9691:  46%|[36m████▌     [0m| 12/26 [00:13<00:16,  1.18s/it]Epoch: 8/10. Loss: 1.0701:  46%|[36m████▌     [0m| 12/26 [00:15<00:16,  1.18s/it]Epoch: 8/10. Loss: 1.0701:  50%|[36m█████     [0m| 13/26 [00:15<00:18,  1.40s/it]Epoch: 8/10. Loss: 1.0088:  50%|[36m█████     [0m| 13/26 [00:16<00:18,  1.40s/it]Epoch: 8/10. Loss: 1.0088:  54%|[36m█████▍    [0m| 14/26 [00:16<00:15,  1.27s/it]Epoch: 8/10. Loss: 0.9586:  54%|[36m█████▍    [0m| 14/26 [00:17<00:15,  1.27s/it]Epoch: 8/10. Loss: 0.9586:  58%|[36m█████▊    [0m| 15/26 [00:17<00:13,  1.25s/it]Epoch: 8/10. Loss: 0.9233:  58%|[36m█████▊    [0m| 15/26 [00:18<00:13,  1.25s/it]Epoch: 8/10. Loss: 0.9233:  62%|[36m██████▏   [0m| 16/26 [00:18<00:11,  1.16s/it]Epoch: 8/10. Loss: 0.9641:  62%|[36m██████▏   [0m| 16/26 [00:19<00:11,  1.16s/it]Epoch: 8/10. Loss: 0.9641:  65%|[36m██████▌   [0m| 17/26 [00:19<00:10,  1.17s/it]Epoch: 8/10. Loss: 0.9672:  65%|[36m██████▌   [0m| 17/26 [00:21<00:10,  1.17s/it]Epoch: 8/10. Loss: 0.9672:  69%|[36m██████▉   [0m| 18/26 [00:21<00:11,  1.50s/it]Epoch: 8/10. Loss: 0.9762:  69%|[36m██████▉   [0m| 18/26 [00:22<00:11,  1.50s/it]Epoch: 8/10. Loss: 0.9762:  73%|[36m███████▎  [0m| 19/26 [00:22<00:09,  1.31s/it]Epoch: 8/10. Loss: 0.9550:  73%|[36m███████▎  [0m| 19/26 [00:23<00:09,  1.31s/it]Epoch: 8/10. Loss: 0.9550:  77%|[36m███████▋  [0m| 20/26 [00:23<00:07,  1.33s/it]Epoch: 8/10. Loss: 0.9346:  77%|[36m███████▋  [0m| 20/26 [00:25<00:07,  1.33s/it]Epoch: 8/10. Loss: 0.9346:  81%|[36m████████  [0m| 21/26 [00:25<00:07,  1.52s/it]Epoch: 8/10. Loss: 0.9310:  81%|[36m████████  [0m| 21/26 [00:27<00:07,  1.52s/it]Epoch: 8/10. Loss: 0.9310:  85%|[36m████████▍ [0m| 22/26 [00:27<00:05,  1.44s/it]Epoch: 8/10. Loss: 0.9651:  85%|[36m████████▍ [0m| 22/26 [00:28<00:05,  1.44s/it]Epoch: 8/10. Loss: 0.9651:  88%|[36m████████▊ [0m| 23/26 [00:28<00:03,  1.33s/it]Epoch: 8/10. Loss: 0.9721:  88%|[36m████████▊ [0m| 23/26 [00:30<00:03,  1.33s/it]Epoch: 8/10. Loss: 0.9721:  92%|[36m█████████▏[0m| 24/26 [00:30<00:02,  1.47s/it]Epoch: 8/10. Loss: 0.9431:  92%|[36m█████████▏[0m| 24/26 [00:33<00:02,  1.47s/it]Epoch: 8/10. Loss: 0.9431:  96%|[36m█████████▌[0m| 25/26 [00:33<00:02,  2.13s/it]Epoch: 8/10. Loss: 0.9330:  96%|[36m█████████▌[0m| 25/26 [00:34<00:02,  2.13s/it]Epoch: 8/10. Loss: 0.9330: 100%|[36m██████████[0m| 26/26 [00:34<00:00,  1.74s/it]Epoch: 8/10. Loss: 0.9330: 100%|[36m██████████[0m| 26/26 [00:34<00:00,  1.33s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:01<00:06,  1.11s/it] 29%|[33m██▊       [0m| 2/7 [00:03<00:09,  1.99s/it] 43%|[33m████▎     [0m| 3/7 [00:04<00:06,  1.65s/it] 57%|[33m█████▋    [0m| 4/7 [00:06<00:05,  1.73s/it] 71%|[33m███████▏  [0m| 5/7 [00:07<00:02,  1.28s/it] 86%|[33m████████▌ [0m| 6/7 [00:08<00:01,  1.17s/it]100%|[33m██████████[0m| 7/7 [00:08<00:00,  1.13it/s]100%|[33m██████████[0m| 7/7 [00:08<00:00,  1.22s/it]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 9/10. Loss: 0.9519:   0%|[36m          [0m| 0/26 [00:01<?, ?it/s]Epoch: 9/10. Loss: 0.9519:   4%|[36m▍         [0m| 1/26 [00:01<00:30,  1.23s/it]Epoch: 9/10. Loss: 0.9429:   4%|[36m▍         [0m| 1/26 [00:02<00:30,  1.23s/it]Epoch: 9/10. Loss: 0.9429:   8%|[36m▊         [0m| 2/26 [00:02<00:26,  1.09s/it]Epoch: 9/10. Loss: 0.8495:   8%|[36m▊         [0m| 2/26 [00:03<00:26,  1.09s/it]Epoch: 9/10. Loss: 0.8495:  12%|[36m█▏        [0m| 3/26 [00:03<00:26,  1.16s/it]Epoch: 9/10. Loss: 0.9335:  12%|[36m█▏        [0m| 3/26 [00:04<00:26,  1.16s/it]Epoch: 9/10. Loss: 0.9335:  15%|[36m█▌        [0m| 4/26 [00:04<00:24,  1.11s/it]Epoch: 9/10. Loss: 0.9471:  15%|[36m█▌        [0m| 4/26 [00:07<00:24,  1.11s/it]Epoch: 9/10. Loss: 0.9471:  19%|[36m█▉        [0m| 5/26 [00:07<00:34,  1.63s/it]Epoch: 9/10. Loss: 0.8325:  19%|[36m█▉        [0m| 5/26 [00:08<00:34,  1.63s/it]Epoch: 9/10. Loss: 0.8325:  23%|[36m██▎       [0m| 6/26 [00:08<00:31,  1.57s/it]Epoch: 9/10. Loss: 0.9797:  23%|[36m██▎       [0m| 6/26 [00:09<00:31,  1.57s/it]Epoch: 9/10. Loss: 0.9797:  27%|[36m██▋       [0m| 7/26 [00:09<00:26,  1.40s/it]Epoch: 9/10. Loss: 0.8699:  27%|[36m██▋       [0m| 7/26 [00:10<00:26,  1.40s/it]Epoch: 9/10. Loss: 0.8699:  31%|[36m███       [0m| 8/26 [00:10<00:22,  1.25s/it]Epoch: 9/10. Loss: 1.0198:  31%|[36m███       [0m| 8/26 [00:15<00:22,  1.25s/it]Epoch: 9/10. Loss: 1.0198:  35%|[36m███▍      [0m| 9/26 [00:15<00:43,  2.55s/it]Epoch: 9/10. Loss: 1.0012:  35%|[36m███▍      [0m| 9/26 [00:19<00:43,  2.55s/it]Epoch: 9/10. Loss: 1.0012:  38%|[36m███▊      [0m| 10/26 [00:19<00:47,  2.98s/it]Epoch: 9/10. Loss: 0.9626:  38%|[36m███▊      [0m| 10/26 [00:22<00:47,  2.98s/it]Epoch: 9/10. Loss: 0.9626:  42%|[36m████▏     [0m| 11/26 [00:22<00:42,  2.80s/it]Epoch: 9/10. Loss: 0.9225:  42%|[36m████▏     [0m| 11/26 [00:23<00:42,  2.80s/it]Epoch: 9/10. Loss: 0.9225:  46%|[36m████▌     [0m| 12/26 [00:23<00:33,  2.43s/it]Epoch: 9/10. Loss: 0.9877:  46%|[36m████▌     [0m| 12/26 [00:24<00:33,  2.43s/it]Epoch: 9/10. Loss: 0.9877:  50%|[36m█████     [0m| 13/26 [00:24<00:25,  1.95s/it]Epoch: 9/10. Loss: 0.9094:  50%|[36m█████     [0m| 13/26 [00:25<00:25,  1.95s/it]Epoch: 9/10. Loss: 0.9094:  54%|[36m█████▍    [0m| 14/26 [00:25<00:20,  1.69s/it]Epoch: 9/10. Loss: 0.9191:  54%|[36m█████▍    [0m| 14/26 [00:26<00:20,  1.69s/it]Epoch: 9/10. Loss: 0.9191:  58%|[36m█████▊    [0m| 15/26 [00:26<00:16,  1.50s/it]Epoch: 9/10. Loss: 0.9666:  58%|[36m█████▊    [0m| 15/26 [00:27<00:16,  1.50s/it]Epoch: 9/10. Loss: 0.9666:  62%|[36m██████▏   [0m| 16/26 [00:27<00:13,  1.37s/it]Epoch: 9/10. Loss: 0.9288:  62%|[36m██████▏   [0m| 16/26 [00:28<00:13,  1.37s/it]Epoch: 9/10. Loss: 0.9288:  65%|[36m██████▌   [0m| 17/26 [00:28<00:11,  1.23s/it]Epoch: 9/10. Loss: 0.9672:  65%|[36m██████▌   [0m| 17/26 [00:29<00:11,  1.23s/it]Epoch: 9/10. Loss: 0.9672:  69%|[36m██████▉   [0m| 18/26 [00:29<00:09,  1.16s/it]Epoch: 9/10. Loss: 0.9628:  69%|[36m██████▉   [0m| 18/26 [00:30<00:09,  1.16s/it]Epoch: 9/10. Loss: 0.9628:  73%|[36m███████▎  [0m| 19/26 [00:30<00:07,  1.11s/it]Epoch: 9/10. Loss: 1.0005:  73%|[36m███████▎  [0m| 19/26 [00:31<00:07,  1.11s/it]Epoch: 9/10. Loss: 1.0005:  77%|[36m███████▋  [0m| 20/26 [00:31<00:06,  1.00s/it]Epoch: 9/10. Loss: 0.9569:  77%|[36m███████▋  [0m| 20/26 [00:33<00:06,  1.00s/it]Epoch: 9/10. Loss: 0.9569:  81%|[36m████████  [0m| 21/26 [00:33<00:06,  1.23s/it]Epoch: 9/10. Loss: 0.9606:  81%|[36m████████  [0m| 21/26 [00:34<00:06,  1.23s/it]Epoch: 9/10. Loss: 0.9606:  85%|[36m████████▍ [0m| 22/26 [00:34<00:05,  1.28s/it]Epoch: 9/10. Loss: 1.0051:  85%|[36m████████▍ [0m| 22/26 [00:35<00:05,  1.28s/it]Epoch: 9/10. Loss: 1.0051:  88%|[36m████████▊ [0m| 23/26 [00:35<00:03,  1.18s/it]Epoch: 9/10. Loss: 0.9007:  88%|[36m████████▊ [0m| 23/26 [00:37<00:03,  1.18s/it]Epoch: 9/10. Loss: 0.9007:  92%|[36m█████████▏[0m| 24/26 [00:37<00:02,  1.44s/it]Epoch: 9/10. Loss: 0.9458:  92%|[36m█████████▏[0m| 24/26 [00:38<00:02,  1.44s/it]Epoch: 9/10. Loss: 0.9458:  96%|[36m█████████▌[0m| 25/26 [00:38<00:01,  1.41s/it]Epoch: 9/10. Loss: 0.9814:  96%|[36m█████████▌[0m| 25/26 [00:39<00:01,  1.41s/it]Epoch: 9/10. Loss: 0.9814: 100%|[36m██████████[0m| 26/26 [00:39<00:00,  1.19s/it]Epoch: 9/10. Loss: 0.9814: 100%|[36m██████████[0m| 26/26 [00:39<00:00,  1.53s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:01<00:06,  1.13s/it] 29%|[33m██▊       [0m| 2/7 [00:02<00:05,  1.12s/it] 43%|[33m████▎     [0m| 3/7 [00:03<00:04,  1.07s/it] 57%|[33m█████▋    [0m| 4/7 [00:04<00:03,  1.21s/it] 71%|[33m███████▏  [0m| 5/7 [00:05<00:01,  1.05it/s] 86%|[33m████████▌ [0m| 6/7 [00:06<00:00,  1.05it/s]100%|[33m██████████[0m| 7/7 [00:06<00:00,  1.39it/s]100%|[33m██████████[0m| 7/7 [00:06<00:00,  1.10it/s]
/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/models/inception.py:43: FutureWarning: The default weight initialization of inception_v3 will be changed in future releases of torchvision. If you wish to keep the old behavior (which leads to long initialization times due to scipy/scipy#11299), please set init_weights=True.
  warnings.warn(
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 0/10. Loss: 1.0797:   0%|[36m          [0m| 0/26 [00:01<?, ?it/s]Epoch: 0/10. Loss: 1.0797:   4%|[36m▍         [0m| 1/26 [00:01<00:28,  1.13s/it]Epoch: 0/10. Loss: 4.2087:   4%|[36m▍         [0m| 1/26 [00:01<00:28,  1.13s/it]Epoch: 0/10. Loss: 4.2087:   8%|[36m▊         [0m| 2/26 [00:01<00:23,  1.03it/s]Epoch: 0/10. Loss: 1.9610:   8%|[36m▊         [0m| 2/26 [00:02<00:23,  1.03it/s]Epoch: 0/10. Loss: 1.9610:  12%|[36m█▏        [0m| 3/26 [00:02<00:22,  1.03it/s]Epoch: 0/10. Loss: 1.4107:  12%|[36m█▏        [0m| 3/26 [00:03<00:22,  1.03it/s]Epoch: 0/10. Loss: 1.4107:  15%|[36m█▌        [0m| 4/26 [00:03<00:20,  1.09it/s]Epoch: 0/10. Loss: 2.1488:  15%|[36m█▌        [0m| 4/26 [00:04<00:20,  1.09it/s]Epoch: 0/10. Loss: 2.1488:  19%|[36m█▉        [0m| 5/26 [00:04<00:19,  1.06it/s]Epoch: 0/10. Loss: 1.9641:  19%|[36m█▉        [0m| 5/26 [00:05<00:19,  1.06it/s]Epoch: 0/10. Loss: 1.9641:  23%|[36m██▎       [0m| 6/26 [00:05<00:19,  1.05it/s]Epoch: 0/10. Loss: 1.4095:  23%|[36m██▎       [0m| 6/26 [00:06<00:19,  1.05it/s]Epoch: 0/10. Loss: 1.4095:  27%|[36m██▋       [0m| 7/26 [00:06<00:17,  1.06it/s]Epoch: 0/10. Loss: 1.1455:  27%|[36m██▋       [0m| 7/26 [00:07<00:17,  1.06it/s]Epoch: 0/10. Loss: 1.1455:  31%|[36m███       [0m| 8/26 [00:07<00:18,  1.02s/it]Epoch: 0/10. Loss: 1.0714:  31%|[36m███       [0m| 8/26 [00:08<00:18,  1.02s/it]Epoch: 0/10. Loss: 1.0714:  35%|[36m███▍      [0m| 9/26 [00:08<00:17,  1.01s/it]Epoch: 0/10. Loss: 1.7350:  35%|[36m███▍      [0m| 9/26 [00:09<00:17,  1.01s/it]Epoch: 0/10. Loss: 1.7350:  38%|[36m███▊      [0m| 10/26 [00:09<00:15,  1.03it/s]Epoch: 0/10. Loss: 1.0463:  38%|[36m███▊      [0m| 10/26 [00:11<00:15,  1.03it/s]Epoch: 0/10. Loss: 1.0463:  42%|[36m████▏     [0m| 11/26 [00:11<00:20,  1.35s/it]Epoch: 0/10. Loss: 2.0610:  42%|[36m████▏     [0m| 11/26 [00:13<00:20,  1.35s/it]Epoch: 0/10. Loss: 2.0610:  46%|[36m████▌     [0m| 12/26 [00:13<00:18,  1.32s/it]Epoch: 0/10. Loss: 1.2708:  46%|[36m████▌     [0m| 12/26 [00:14<00:18,  1.32s/it]Epoch: 0/10. Loss: 1.2708:  50%|[36m█████     [0m| 13/26 [00:14<00:15,  1.21s/it]Epoch: 0/10. Loss: 1.4592:  50%|[36m█████     [0m| 13/26 [00:15<00:15,  1.21s/it]Epoch: 0/10. Loss: 1.4592:  54%|[36m█████▍    [0m| 14/26 [00:15<00:13,  1.12s/it]Epoch: 0/10. Loss: 1.3960:  54%|[36m█████▍    [0m| 14/26 [00:15<00:13,  1.12s/it]Epoch: 0/10. Loss: 1.3960:  58%|[36m█████▊    [0m| 15/26 [00:15<00:11,  1.03s/it]Epoch: 0/10. Loss: 1.2372:  58%|[36m█████▊    [0m| 15/26 [00:16<00:11,  1.03s/it]Epoch: 0/10. Loss: 1.2372:  62%|[36m██████▏   [0m| 16/26 [00:16<00:10,  1.05s/it]Epoch: 0/10. Loss: 1.6638:  62%|[36m██████▏   [0m| 16/26 [00:17<00:10,  1.05s/it]Epoch: 0/10. Loss: 1.6638:  65%|[36m██████▌   [0m| 17/26 [00:17<00:09,  1.00s/it]Epoch: 0/10. Loss: 1.4460:  65%|[36m██████▌   [0m| 17/26 [00:18<00:09,  1.00s/it]Epoch: 0/10. Loss: 1.4460:  69%|[36m██████▉   [0m| 18/26 [00:18<00:07,  1.02it/s]Epoch: 0/10. Loss: 1.3080:  69%|[36m██████▉   [0m| 18/26 [00:19<00:07,  1.02it/s]Epoch: 0/10. Loss: 1.3080:  73%|[36m███████▎  [0m| 19/26 [00:19<00:06,  1.08it/s]Epoch: 0/10. Loss: 1.4726:  73%|[36m███████▎  [0m| 19/26 [00:20<00:06,  1.08it/s]Epoch: 0/10. Loss: 1.4726:  77%|[36m███████▋  [0m| 20/26 [00:20<00:06,  1.00s/it]Epoch: 0/10. Loss: 1.2391:  77%|[36m███████▋  [0m| 20/26 [00:21<00:06,  1.00s/it]Epoch: 0/10. Loss: 1.2391:  81%|[36m████████  [0m| 21/26 [00:22<00:05,  1.07s/it]Epoch: 0/10. Loss: 1.1172:  81%|[36m████████  [0m| 21/26 [00:23<00:05,  1.07s/it]Epoch: 0/10. Loss: 1.1172:  85%|[36m████████▍ [0m| 22/26 [00:23<00:04,  1.12s/it]Epoch: 0/10. Loss: 1.6642:  85%|[36m████████▍ [0m| 22/26 [00:24<00:04,  1.12s/it]Epoch: 0/10. Loss: 1.6642:  88%|[36m████████▊ [0m| 23/26 [00:24<00:03,  1.11s/it]Epoch: 0/10. Loss: 1.2678:  88%|[36m████████▊ [0m| 23/26 [00:25<00:03,  1.11s/it]Epoch: 0/10. Loss: 1.2678:  92%|[36m█████████▏[0m| 24/26 [00:25<00:02,  1.09s/it]Epoch: 0/10. Loss: 1.0736:  92%|[36m█████████▏[0m| 24/26 [00:26<00:02,  1.09s/it]Epoch: 0/10. Loss: 1.0736:  96%|[36m█████████▌[0m| 25/26 [00:26<00:01,  1.04s/it]Epoch: 0/10. Loss: 1.3140:  96%|[36m█████████▌[0m| 25/26 [00:27<00:01,  1.04s/it]Epoch: 0/10. Loss: 1.3140: 100%|[36m██████████[0m| 26/26 [00:27<00:00,  1.19s/it]Epoch: 0/10. Loss: 1.3140: 100%|[36m██████████[0m| 26/26 [00:27<00:00,  1.07s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:05,  1.13it/s] 29%|[33m██▊       [0m| 2/7 [00:01<00:05,  1.00s/it] 43%|[33m████▎     [0m| 3/7 [00:02<00:03,  1.12it/s] 57%|[33m█████▋    [0m| 4/7 [00:04<00:03,  1.10s/it] 71%|[33m███████▏  [0m| 5/7 [00:04<00:01,  1.16it/s] 86%|[33m████████▌ [0m| 6/7 [00:06<00:01,  1.09s/it]100%|[33m██████████[0m| 7/7 [00:06<00:00,  1.20it/s]100%|[33m██████████[0m| 7/7 [00:06<00:00,  1.09it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 1/10. Loss: 1.1990:   0%|[36m          [0m| 0/26 [00:01<?, ?it/s]Epoch: 1/10. Loss: 1.1990:   4%|[36m▍         [0m| 1/26 [00:01<00:25,  1.03s/it]Epoch: 1/10. Loss: 1.0662:   4%|[36m▍         [0m| 1/26 [00:01<00:25,  1.03s/it]Epoch: 1/10. Loss: 1.0662:   8%|[36m▊         [0m| 2/26 [00:01<00:23,  1.03it/s]Epoch: 1/10. Loss: 1.0862:   8%|[36m▊         [0m| 2/26 [00:02<00:23,  1.03it/s]Epoch: 1/10. Loss: 1.0862:  12%|[36m█▏        [0m| 3/26 [00:02<00:22,  1.00it/s]Epoch: 1/10. Loss: 1.0656:  12%|[36m█▏        [0m| 3/26 [00:03<00:22,  1.00it/s]Epoch: 1/10. Loss: 1.0656:  15%|[36m█▌        [0m| 4/26 [00:03<00:20,  1.05it/s]Epoch: 1/10. Loss: 1.3007:  15%|[36m█▌        [0m| 4/26 [00:04<00:20,  1.05it/s]Epoch: 1/10. Loss: 1.3007:  19%|[36m█▉        [0m| 5/26 [00:04<00:19,  1.06it/s]Epoch: 1/10. Loss: 1.1781:  19%|[36m█▉        [0m| 5/26 [00:05<00:19,  1.06it/s]Epoch: 1/10. Loss: 1.1781:  23%|[36m██▎       [0m| 6/26 [00:05<00:20,  1.00s/it]Epoch: 1/10. Loss: 1.0894:  23%|[36m██▎       [0m| 6/26 [00:06<00:20,  1.00s/it]Epoch: 1/10. Loss: 1.0894:  27%|[36m██▋       [0m| 7/26 [00:06<00:18,  1.01it/s]Epoch: 1/10. Loss: 1.0534:  27%|[36m██▋       [0m| 7/26 [00:08<00:18,  1.01it/s]Epoch: 1/10. Loss: 1.0534:  31%|[36m███       [0m| 8/26 [00:08<00:19,  1.09s/it]Epoch: 1/10. Loss: 1.1715:  31%|[36m███       [0m| 8/26 [00:10<00:19,  1.09s/it]Epoch: 1/10. Loss: 1.1715:  35%|[36m███▍      [0m| 9/26 [00:10<00:22,  1.34s/it]Epoch: 1/10. Loss: 1.0808:  35%|[36m███▍      [0m| 9/26 [00:10<00:22,  1.34s/it]Epoch: 1/10. Loss: 1.0808:  38%|[36m███▊      [0m| 10/26 [00:10<00:18,  1.18s/it]Epoch: 1/10. Loss: 1.0303:  38%|[36m███▊      [0m| 10/26 [00:11<00:18,  1.18s/it]Epoch: 1/10. Loss: 1.0303:  42%|[36m████▏     [0m| 11/26 [00:11<00:16,  1.13s/it]Epoch: 1/10. Loss: 1.5007:  42%|[36m████▏     [0m| 11/26 [00:12<00:16,  1.13s/it]Epoch: 1/10. Loss: 1.5007:  46%|[36m████▌     [0m| 12/26 [00:12<00:15,  1.09s/it]Epoch: 1/10. Loss: 1.2532:  46%|[36m████▌     [0m| 12/26 [00:13<00:15,  1.09s/it]Epoch: 1/10. Loss: 1.2532:  50%|[36m█████     [0m| 13/26 [00:13<00:13,  1.03s/it]Epoch: 1/10. Loss: 0.9864:  50%|[36m█████     [0m| 13/26 [00:14<00:13,  1.03s/it]Epoch: 1/10. Loss: 0.9864:  54%|[36m█████▍    [0m| 14/26 [00:14<00:12,  1.03s/it]Epoch: 1/10. Loss: 0.9988:  54%|[36m█████▍    [0m| 14/26 [00:15<00:12,  1.03s/it]Epoch: 1/10. Loss: 0.9988:  58%|[36m█████▊    [0m| 15/26 [00:15<00:11,  1.00s/it]Epoch: 1/10. Loss: 1.3339:  58%|[36m█████▊    [0m| 15/26 [00:16<00:11,  1.00s/it]Epoch: 1/10. Loss: 1.3339:  62%|[36m██████▏   [0m| 16/26 [00:16<00:09,  1.02it/s]Epoch: 1/10. Loss: 1.2095:  62%|[36m██████▏   [0m| 16/26 [00:17<00:09,  1.02it/s]Epoch: 1/10. Loss: 1.2095:  65%|[36m██████▌   [0m| 17/26 [00:17<00:08,  1.04it/s]Epoch: 1/10. Loss: 0.9957:  65%|[36m██████▌   [0m| 17/26 [00:18<00:08,  1.04it/s]Epoch: 1/10. Loss: 0.9957:  69%|[36m██████▉   [0m| 18/26 [00:18<00:07,  1.08it/s]Epoch: 1/10. Loss: 0.9988:  69%|[36m██████▉   [0m| 18/26 [00:19<00:07,  1.08it/s]Epoch: 1/10. Loss: 0.9988:  73%|[36m███████▎  [0m| 19/26 [00:19<00:06,  1.03it/s]Epoch: 1/10. Loss: 1.3883:  73%|[36m███████▎  [0m| 19/26 [00:20<00:06,  1.03it/s]Epoch: 1/10. Loss: 1.3883:  77%|[36m███████▋  [0m| 20/26 [00:20<00:05,  1.07it/s]Epoch: 1/10. Loss: 1.0087:  77%|[36m███████▋  [0m| 20/26 [00:21<00:05,  1.07it/s]Epoch: 1/10. Loss: 1.0087:  81%|[36m████████  [0m| 21/26 [00:21<00:04,  1.08it/s]Epoch: 1/10. Loss: 1.2710:  81%|[36m████████  [0m| 21/26 [00:22<00:04,  1.08it/s]Epoch: 1/10. Loss: 1.2710:  85%|[36m████████▍ [0m| 22/26 [00:22<00:03,  1.13it/s]Epoch: 1/10. Loss: 1.2530:  85%|[36m████████▍ [0m| 22/26 [00:23<00:03,  1.13it/s]Epoch: 1/10. Loss: 1.2530:  88%|[36m████████▊ [0m| 23/26 [00:23<00:03,  1.01s/it]Epoch: 1/10. Loss: 1.1662:  88%|[36m████████▊ [0m| 23/26 [00:24<00:03,  1.01s/it]Epoch: 1/10. Loss: 1.1662:  92%|[36m█████████▏[0m| 24/26 [00:24<00:02,  1.02s/it]Epoch: 1/10. Loss: 1.2000:  92%|[36m█████████▏[0m| 24/26 [00:25<00:02,  1.02s/it]Epoch: 1/10. Loss: 1.2000:  96%|[36m█████████▌[0m| 25/26 [00:25<00:00,  1.01it/s]Epoch: 1/10. Loss: 1.2114:  96%|[36m█████████▌[0m| 25/26 [00:25<00:00,  1.01it/s]Epoch: 1/10. Loss: 1.2114: 100%|[36m██████████[0m| 26/26 [00:25<00:00,  1.17it/s]Epoch: 1/10. Loss: 1.2114: 100%|[36m██████████[0m| 26/26 [00:25<00:00,  1.00it/s]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:05,  1.12it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:05,  1.05s/it] 43%|[33m████▎     [0m| 3/7 [00:04<00:06,  1.51s/it] 57%|[33m█████▋    [0m| 4/7 [00:05<00:04,  1.42s/it] 71%|[33m███████▏  [0m| 5/7 [00:05<00:02,  1.09s/it] 86%|[33m████████▌ [0m| 6/7 [00:06<00:01,  1.02s/it]100%|[33m██████████[0m| 7/7 [00:07<00:00,  1.30it/s]100%|[33m██████████[0m| 7/7 [00:07<00:00,  1.00s/it]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 2/10. Loss: 1.1814:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 2/10. Loss: 1.1814:   4%|[36m▍         [0m| 1/26 [00:00<00:23,  1.04it/s]Epoch: 2/10. Loss: 0.9814:   4%|[36m▍         [0m| 1/26 [00:02<00:23,  1.04it/s]Epoch: 2/10. Loss: 0.9814:   8%|[36m▊         [0m| 2/26 [00:02<00:24,  1.03s/it]Epoch: 2/10. Loss: 1.0350:   8%|[36m▊         [0m| 2/26 [00:05<00:24,  1.03s/it]Epoch: 2/10. Loss: 1.0350:  12%|[36m█▏        [0m| 3/26 [00:05<00:52,  2.27s/it]Epoch: 2/10. Loss: 1.3176:  12%|[36m█▏        [0m| 3/26 [00:06<00:52,  2.27s/it]Epoch: 2/10. Loss: 1.3176:  15%|[36m█▌        [0m| 4/26 [00:06<00:38,  1.75s/it]Epoch: 2/10. Loss: 1.1217:  15%|[36m█▌        [0m| 4/26 [00:08<00:38,  1.75s/it]Epoch: 2/10. Loss: 1.1217:  19%|[36m█▉        [0m| 5/26 [00:08<00:38,  1.83s/it]Epoch: 2/10. Loss: 1.2372:  19%|[36m█▉        [0m| 5/26 [00:09<00:38,  1.83s/it]Epoch: 2/10. Loss: 1.2372:  23%|[36m██▎       [0m| 6/26 [00:09<00:31,  1.58s/it]Epoch: 2/10. Loss: 1.2469:  23%|[36m██▎       [0m| 6/26 [00:10<00:31,  1.58s/it]Epoch: 2/10. Loss: 1.2469:  27%|[36m██▋       [0m| 7/26 [00:10<00:26,  1.37s/it]Epoch: 2/10. Loss: 1.1018:  27%|[36m██▋       [0m| 7/26 [00:11<00:26,  1.37s/it]Epoch: 2/10. Loss: 1.1018:  31%|[36m███       [0m| 8/26 [00:11<00:21,  1.22s/it]Epoch: 2/10. Loss: 1.0778:  31%|[36m███       [0m| 8/26 [00:12<00:21,  1.22s/it]Epoch: 2/10. Loss: 1.0778:  35%|[36m███▍      [0m| 9/26 [00:12<00:18,  1.10s/it]Epoch: 2/10. Loss: 1.0463:  35%|[36m███▍      [0m| 9/26 [00:13<00:18,  1.10s/it]Epoch: 2/10. Loss: 1.0463:  38%|[36m███▊      [0m| 10/26 [00:13<00:16,  1.05s/it]Epoch: 2/10. Loss: 1.0786:  38%|[36m███▊      [0m| 10/26 [00:14<00:16,  1.05s/it]Epoch: 2/10. Loss: 1.0786:  42%|[36m████▏     [0m| 11/26 [00:14<00:16,  1.08s/it]Epoch: 2/10. Loss: 1.2270:  42%|[36m████▏     [0m| 11/26 [00:15<00:16,  1.08s/it]Epoch: 2/10. Loss: 1.2270:  46%|[36m████▌     [0m| 12/26 [00:15<00:13,  1.01it/s]Epoch: 2/10. Loss: 1.1468:  46%|[36m████▌     [0m| 12/26 [00:16<00:13,  1.01it/s]Epoch: 2/10. Loss: 1.1468:  50%|[36m█████     [0m| 13/26 [00:16<00:13,  1.01s/it]Epoch: 2/10. Loss: 1.0976:  50%|[36m█████     [0m| 13/26 [00:17<00:13,  1.01s/it]Epoch: 2/10. Loss: 1.0976:  54%|[36m█████▍    [0m| 14/26 [00:17<00:11,  1.03it/s]Epoch: 2/10. Loss: 1.1318:  54%|[36m█████▍    [0m| 14/26 [00:18<00:11,  1.03it/s]Epoch: 2/10. Loss: 1.1318:  58%|[36m█████▊    [0m| 15/26 [00:18<00:10,  1.02it/s]Epoch: 2/10. Loss: 1.0225:  58%|[36m█████▊    [0m| 15/26 [00:19<00:10,  1.02it/s]Epoch: 2/10. Loss: 1.0225:  62%|[36m██████▏   [0m| 16/26 [00:19<00:09,  1.03it/s]Epoch: 2/10. Loss: 1.1995:  62%|[36m██████▏   [0m| 16/26 [00:20<00:09,  1.03it/s]Epoch: 2/10. Loss: 1.1995:  65%|[36m██████▌   [0m| 17/26 [00:20<00:08,  1.04it/s]Epoch: 2/10. Loss: 1.0388:  65%|[36m██████▌   [0m| 17/26 [00:21<00:08,  1.04it/s]Epoch: 2/10. Loss: 1.0388:  69%|[36m██████▉   [0m| 18/26 [00:21<00:08,  1.00s/it]Epoch: 2/10. Loss: 1.4323:  69%|[36m██████▉   [0m| 18/26 [00:22<00:08,  1.00s/it]Epoch: 2/10. Loss: 1.4323:  73%|[36m███████▎  [0m| 19/26 [00:22<00:06,  1.01it/s]Epoch: 2/10. Loss: 1.0193:  73%|[36m███████▎  [0m| 19/26 [00:23<00:06,  1.01it/s]Epoch: 2/10. Loss: 1.0193:  77%|[36m███████▋  [0m| 20/26 [00:23<00:05,  1.00it/s]Epoch: 2/10. Loss: 1.0006:  77%|[36m███████▋  [0m| 20/26 [00:24<00:05,  1.00it/s]Epoch: 2/10. Loss: 1.0006:  81%|[36m████████  [0m| 21/26 [00:24<00:05,  1.01s/it]Epoch: 2/10. Loss: 0.9892:  81%|[36m████████  [0m| 21/26 [00:25<00:05,  1.01s/it]Epoch: 2/10. Loss: 0.9892:  85%|[36m████████▍ [0m| 22/26 [00:25<00:03,  1.02it/s]Epoch: 2/10. Loss: 0.9784:  85%|[36m████████▍ [0m| 22/26 [00:26<00:03,  1.02it/s]Epoch: 2/10. Loss: 0.9784:  88%|[36m████████▊ [0m| 23/26 [00:26<00:02,  1.04it/s]Epoch: 2/10. Loss: 1.1755:  88%|[36m████████▊ [0m| 23/26 [00:27<00:02,  1.04it/s]Epoch: 2/10. Loss: 1.1755:  92%|[36m█████████▏[0m| 24/26 [00:27<00:02,  1.01s/it]Epoch: 2/10. Loss: 0.9800:  92%|[36m█████████▏[0m| 24/26 [00:28<00:02,  1.01s/it]Epoch: 2/10. Loss: 0.9800:  96%|[36m█████████▌[0m| 25/26 [00:28<00:00,  1.02it/s]Epoch: 2/10. Loss: 1.4027:  96%|[36m█████████▌[0m| 25/26 [00:28<00:00,  1.02it/s]Epoch: 2/10. Loss: 1.4027: 100%|[36m██████████[0m| 26/26 [00:28<00:00,  1.17it/s]Epoch: 2/10. Loss: 1.4027: 100%|[36m██████████[0m| 26/26 [00:28<00:00,  1.10s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:05,  1.03it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:06,  1.24s/it] 43%|[33m████▎     [0m| 3/7 [00:03<00:04,  1.03s/it] 57%|[33m█████▋    [0m| 4/7 [00:04<00:03,  1.23s/it] 71%|[33m███████▏  [0m| 5/7 [00:05<00:01,  1.06it/s] 86%|[33m████████▌ [0m| 6/7 [00:07<00:01,  1.30s/it]100%|[33m██████████[0m| 7/7 [00:07<00:00,  1.04it/s]100%|[33m██████████[0m| 7/7 [00:07<00:00,  1.06s/it]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 3/10. Loss: 0.9975:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 3/10. Loss: 0.9975:   4%|[36m▍         [0m| 1/26 [00:00<00:23,  1.06it/s]Epoch: 3/10. Loss: 1.1217:   4%|[36m▍         [0m| 1/26 [00:04<00:23,  1.06it/s]Epoch: 3/10. Loss: 1.1217:   8%|[36m▊         [0m| 2/26 [00:04<01:01,  2.58s/it]Epoch: 3/10. Loss: 1.1266:   8%|[36m▊         [0m| 2/26 [00:05<01:01,  2.58s/it]Epoch: 3/10. Loss: 1.1266:  12%|[36m█▏        [0m| 3/26 [00:05<00:40,  1.74s/it]Epoch: 3/10. Loss: 1.2164:  12%|[36m█▏        [0m| 3/26 [00:06<00:40,  1.74s/it]Epoch: 3/10. Loss: 1.2164:  15%|[36m█▌        [0m| 4/26 [00:06<00:30,  1.41s/it]Epoch: 3/10. Loss: 1.3307:  15%|[36m█▌        [0m| 4/26 [00:08<00:30,  1.41s/it]Epoch: 3/10. Loss: 1.3307:  19%|[36m█▉        [0m| 5/26 [00:08<00:32,  1.57s/it]Epoch: 3/10. Loss: 1.1914:  19%|[36m█▉        [0m| 5/26 [00:08<00:32,  1.57s/it]Epoch: 3/10. Loss: 1.1914:  23%|[36m██▎       [0m| 6/26 [00:08<00:25,  1.29s/it]Epoch: 3/10. Loss: 1.1430:  23%|[36m██▎       [0m| 6/26 [00:10<00:25,  1.29s/it]Epoch: 3/10. Loss: 1.1430:  27%|[36m██▋       [0m| 7/26 [00:10<00:25,  1.34s/it]Epoch: 3/10. Loss: 1.0734:  27%|[36m██▋       [0m| 7/26 [00:11<00:25,  1.34s/it]Epoch: 3/10. Loss: 1.0734:  31%|[36m███       [0m| 8/26 [00:11<00:22,  1.27s/it]Epoch: 3/10. Loss: 1.0375:  31%|[36m███       [0m| 8/26 [00:12<00:22,  1.27s/it]Epoch: 3/10. Loss: 1.0375:  35%|[36m███▍      [0m| 9/26 [00:12<00:19,  1.18s/it]Epoch: 3/10. Loss: 1.1190:  35%|[36m███▍      [0m| 9/26 [00:13<00:19,  1.18s/it]Epoch: 3/10. Loss: 1.1190:  38%|[36m███▊      [0m| 10/26 [00:13<00:17,  1.09s/it]Epoch: 3/10. Loss: 1.3113:  38%|[36m███▊      [0m| 10/26 [00:14<00:17,  1.09s/it]Epoch: 3/10. Loss: 1.3113:  42%|[36m████▏     [0m| 11/26 [00:14<00:16,  1.07s/it]Epoch: 3/10. Loss: 0.9774:  42%|[36m████▏     [0m| 11/26 [00:15<00:16,  1.07s/it]Epoch: 3/10. Loss: 0.9774:  46%|[36m████▌     [0m| 12/26 [00:15<00:14,  1.01s/it]Epoch: 3/10. Loss: 1.0288:  46%|[36m████▌     [0m| 12/26 [00:16<00:14,  1.01s/it]Epoch: 3/10. Loss: 1.0288:  50%|[36m█████     [0m| 13/26 [00:16<00:14,  1.13s/it]Epoch: 3/10. Loss: 0.9877:  50%|[36m█████     [0m| 13/26 [00:18<00:14,  1.13s/it]Epoch: 3/10. Loss: 0.9877:  54%|[36m█████▍    [0m| 14/26 [00:18<00:14,  1.22s/it]Epoch: 3/10. Loss: 1.0205:  54%|[36m█████▍    [0m| 14/26 [00:19<00:14,  1.22s/it]Epoch: 3/10. Loss: 1.0205:  58%|[36m█████▊    [0m| 15/26 [00:19<00:15,  1.37s/it]Epoch: 3/10. Loss: 1.1966:  58%|[36m█████▊    [0m| 15/26 [00:20<00:15,  1.37s/it]Epoch: 3/10. Loss: 1.1966:  62%|[36m██████▏   [0m| 16/26 [00:20<00:12,  1.23s/it]Epoch: 3/10. Loss: 1.4091:  62%|[36m██████▏   [0m| 16/26 [00:21<00:12,  1.23s/it]Epoch: 3/10. Loss: 1.4091:  65%|[36m██████▌   [0m| 17/26 [00:21<00:10,  1.18s/it]Epoch: 3/10. Loss: 1.0519:  65%|[36m██████▌   [0m| 17/26 [00:23<00:10,  1.18s/it]Epoch: 3/10. Loss: 1.0519:  69%|[36m██████▉   [0m| 18/26 [00:23<00:10,  1.26s/it]Epoch: 3/10. Loss: 1.0621:  69%|[36m██████▉   [0m| 18/26 [00:24<00:10,  1.26s/it]Epoch: 3/10. Loss: 1.0621:  73%|[36m███████▎  [0m| 19/26 [00:24<00:08,  1.17s/it]Epoch: 3/10. Loss: 1.0270:  73%|[36m███████▎  [0m| 19/26 [00:25<00:08,  1.17s/it]Epoch: 3/10. Loss: 1.0270:  77%|[36m███████▋  [0m| 20/26 [00:25<00:08,  1.34s/it]Epoch: 3/10. Loss: 1.3390:  77%|[36m███████▋  [0m| 20/26 [00:27<00:08,  1.34s/it]Epoch: 3/10. Loss: 1.3390:  81%|[36m████████  [0m| 21/26 [00:27<00:07,  1.44s/it]Epoch: 3/10. Loss: 1.0432:  81%|[36m████████  [0m| 21/26 [00:28<00:07,  1.44s/it]Epoch: 3/10. Loss: 1.0432:  85%|[36m████████▍ [0m| 22/26 [00:28<00:05,  1.29s/it]Epoch: 3/10. Loss: 1.0548:  85%|[36m████████▍ [0m| 22/26 [00:29<00:05,  1.29s/it]Epoch: 3/10. Loss: 1.0548:  88%|[36m████████▊ [0m| 23/26 [00:29<00:03,  1.19s/it]Epoch: 3/10. Loss: 1.1656:  88%|[36m████████▊ [0m| 23/26 [00:30<00:03,  1.19s/it]Epoch: 3/10. Loss: 1.1656:  92%|[36m█████████▏[0m| 24/26 [00:30<00:02,  1.14s/it]Epoch: 3/10. Loss: 1.3404:  92%|[36m█████████▏[0m| 24/26 [00:31<00:02,  1.14s/it]Epoch: 3/10. Loss: 1.3404:  96%|[36m█████████▌[0m| 25/26 [00:31<00:01,  1.07s/it]Epoch: 3/10. Loss: 1.1416:  96%|[36m█████████▌[0m| 25/26 [00:32<00:01,  1.07s/it]Epoch: 3/10. Loss: 1.1416: 100%|[36m██████████[0m| 26/26 [00:32<00:00,  1.06it/s]Epoch: 3/10. Loss: 1.1416: 100%|[36m██████████[0m| 26/26 [00:32<00:00,  1.23s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:05,  1.14it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:05,  1.12s/it] 43%|[33m████▎     [0m| 3/7 [00:02<00:03,  1.04it/s] 57%|[33m█████▋    [0m| 4/7 [00:04<00:03,  1.15s/it] 71%|[33m███████▏  [0m| 5/7 [00:04<00:01,  1.10it/s] 86%|[33m████████▌ [0m| 6/7 [00:05<00:00,  1.11it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.45it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.17it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 4/10. Loss: 1.1694:   0%|[36m          [0m| 0/26 [00:01<?, ?it/s]Epoch: 4/10. Loss: 1.1694:   4%|[36m▍         [0m| 1/26 [00:01<00:25,  1.03s/it]Epoch: 4/10. Loss: 1.0790:   4%|[36m▍         [0m| 1/26 [00:01<00:25,  1.03s/it]Epoch: 4/10. Loss: 1.0790:   8%|[36m▊         [0m| 2/26 [00:01<00:23,  1.03it/s]Epoch: 4/10. Loss: 1.0733:   8%|[36m▊         [0m| 2/26 [00:02<00:23,  1.03it/s]Epoch: 4/10. Loss: 1.0733:  12%|[36m█▏        [0m| 3/26 [00:02<00:22,  1.03it/s]Epoch: 4/10. Loss: 1.2655:  12%|[36m█▏        [0m| 3/26 [00:05<00:22,  1.03it/s]Epoch: 4/10. Loss: 1.2655:  15%|[36m█▌        [0m| 4/26 [00:05<00:31,  1.45s/it]Epoch: 4/10. Loss: 1.0662:  15%|[36m█▌        [0m| 4/26 [00:06<00:31,  1.45s/it]Epoch: 4/10. Loss: 1.0662:  19%|[36m█▉        [0m| 5/26 [00:06<00:26,  1.27s/it]Epoch: 4/10. Loss: 0.9722:  19%|[36m█▉        [0m| 5/26 [00:06<00:26,  1.27s/it]Epoch: 4/10. Loss: 0.9722:  23%|[36m██▎       [0m| 6/26 [00:06<00:22,  1.12s/it]Epoch: 4/10. Loss: 1.0785:  23%|[36m██▎       [0m| 6/26 [00:07<00:22,  1.12s/it]Epoch: 4/10. Loss: 1.0785:  27%|[36m██▋       [0m| 7/26 [00:07<00:19,  1.03s/it]Epoch: 4/10. Loss: 1.0563:  27%|[36m██▋       [0m| 7/26 [00:08<00:19,  1.03s/it]Epoch: 4/10. Loss: 1.0563:  31%|[36m███       [0m| 8/26 [00:08<00:18,  1.04s/it]Epoch: 4/10. Loss: 1.0678:  31%|[36m███       [0m| 8/26 [00:09<00:18,  1.04s/it]Epoch: 4/10. Loss: 1.0678:  35%|[36m███▍      [0m| 9/26 [00:09<00:16,  1.02it/s]Epoch: 4/10. Loss: 1.1937:  35%|[36m███▍      [0m| 9/26 [00:11<00:16,  1.02it/s]Epoch: 4/10. Loss: 1.1937:  38%|[36m███▊      [0m| 10/26 [00:11<00:18,  1.14s/it]Epoch: 4/10. Loss: 1.0254:  38%|[36m███▊      [0m| 10/26 [00:12<00:18,  1.14s/it]Epoch: 4/10. Loss: 1.0254:  42%|[36m████▏     [0m| 11/26 [00:12<00:16,  1.09s/it]Epoch: 4/10. Loss: 1.1810:  42%|[36m████▏     [0m| 11/26 [00:12<00:16,  1.09s/it]Epoch: 4/10. Loss: 1.1810:  46%|[36m████▌     [0m| 12/26 [00:12<00:13,  1.01it/s]Epoch: 4/10. Loss: 1.0058:  46%|[36m████▌     [0m| 12/26 [00:13<00:13,  1.01it/s]Epoch: 4/10. Loss: 1.0058:  50%|[36m█████     [0m| 13/26 [00:13<00:12,  1.02it/s]Epoch: 4/10. Loss: 0.9759:  50%|[36m█████     [0m| 13/26 [00:14<00:12,  1.02it/s]Epoch: 4/10. Loss: 0.9759:  54%|[36m█████▍    [0m| 14/26 [00:14<00:11,  1.04it/s]Epoch: 4/10. Loss: 1.0359:  54%|[36m█████▍    [0m| 14/26 [00:17<00:11,  1.04it/s]Epoch: 4/10. Loss: 1.0359:  58%|[36m█████▊    [0m| 15/26 [00:17<00:16,  1.47s/it]Epoch: 4/10. Loss: 0.9834:  58%|[36m█████▊    [0m| 15/26 [00:18<00:16,  1.47s/it]Epoch: 4/10. Loss: 0.9834:  62%|[36m██████▏   [0m| 16/26 [00:18<00:13,  1.39s/it]Epoch: 4/10. Loss: 1.0190:  62%|[36m██████▏   [0m| 16/26 [00:19<00:13,  1.39s/it]Epoch: 4/10. Loss: 1.0190:  65%|[36m██████▌   [0m| 17/26 [00:19<00:10,  1.20s/it]Epoch: 4/10. Loss: 0.9845:  65%|[36m██████▌   [0m| 17/26 [00:20<00:10,  1.20s/it]Epoch: 4/10. Loss: 0.9845:  69%|[36m██████▉   [0m| 18/26 [00:20<00:08,  1.12s/it]Epoch: 4/10. Loss: 1.0776:  69%|[36m██████▉   [0m| 18/26 [00:21<00:08,  1.12s/it]Epoch: 4/10. Loss: 1.0776:  73%|[36m███████▎  [0m| 19/26 [00:21<00:07,  1.04s/it]Epoch: 4/10. Loss: 1.1954:  73%|[36m███████▎  [0m| 19/26 [00:22<00:07,  1.04s/it]Epoch: 4/10. Loss: 1.1954:  77%|[36m███████▋  [0m| 20/26 [00:22<00:06,  1.10s/it]Epoch: 4/10. Loss: 1.0443:  77%|[36m███████▋  [0m| 20/26 [00:25<00:06,  1.10s/it]Epoch: 4/10. Loss: 1.0443:  81%|[36m████████  [0m| 21/26 [00:25<00:08,  1.66s/it]Epoch: 4/10. Loss: 0.9804:  81%|[36m████████  [0m| 21/26 [00:27<00:08,  1.66s/it]Epoch: 4/10. Loss: 0.9804:  85%|[36m████████▍ [0m| 22/26 [00:27<00:06,  1.71s/it]Epoch: 4/10. Loss: 1.0156:  85%|[36m████████▍ [0m| 22/26 [00:29<00:06,  1.71s/it]Epoch: 4/10. Loss: 1.0156:  88%|[36m████████▊ [0m| 23/26 [00:29<00:05,  1.94s/it]Epoch: 4/10. Loss: 1.0410:  88%|[36m████████▊ [0m| 23/26 [00:31<00:05,  1.94s/it]Epoch: 4/10. Loss: 1.0410:  92%|[36m█████████▏[0m| 24/26 [00:31<00:04,  2.02s/it]Epoch: 4/10. Loss: 1.1840:  92%|[36m█████████▏[0m| 24/26 [00:34<00:04,  2.02s/it]Epoch: 4/10. Loss: 1.1840:  96%|[36m█████████▌[0m| 25/26 [00:34<00:02,  2.25s/it]Epoch: 4/10. Loss: 1.3441:  96%|[36m█████████▌[0m| 25/26 [00:35<00:02,  2.25s/it]Epoch: 4/10. Loss: 1.3441: 100%|[36m██████████[0m| 26/26 [00:35<00:00,  1.77s/it]Epoch: 4/10. Loss: 1.3441: 100%|[36m██████████[0m| 26/26 [00:35<00:00,  1.36s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:05,  1.18it/s] 29%|[33m██▊       [0m| 2/7 [00:01<00:04,  1.02it/s] 43%|[33m████▎     [0m| 3/7 [00:02<00:03,  1.13it/s] 57%|[33m█████▋    [0m| 4/7 [00:04<00:03,  1.05s/it] 71%|[33m███████▏  [0m| 5/7 [00:04<00:01,  1.18it/s] 86%|[33m████████▌ [0m| 6/7 [00:05<00:00,  1.15it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.50it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.24it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 5/10. Loss: 1.0352:   0%|[36m          [0m| 0/26 [00:01<?, ?it/s]Epoch: 5/10. Loss: 1.0352:   4%|[36m▍         [0m| 1/26 [00:01<00:25,  1.03s/it]Epoch: 5/10. Loss: 1.2589:   4%|[36m▍         [0m| 1/26 [00:02<00:25,  1.03s/it]Epoch: 5/10. Loss: 1.2589:   8%|[36m▊         [0m| 2/26 [00:02<00:28,  1.18s/it]Epoch: 5/10. Loss: 1.1000:   8%|[36m▊         [0m| 2/26 [00:03<00:28,  1.18s/it]Epoch: 5/10. Loss: 1.1000:  12%|[36m█▏        [0m| 3/26 [00:03<00:23,  1.04s/it]Epoch: 5/10. Loss: 1.1292:  12%|[36m█▏        [0m| 3/26 [00:04<00:23,  1.04s/it]Epoch: 5/10. Loss: 1.1292:  15%|[36m█▌        [0m| 4/26 [00:04<00:27,  1.26s/it]Epoch: 5/10. Loss: 1.1475:  15%|[36m█▌        [0m| 4/26 [00:05<00:27,  1.26s/it]Epoch: 5/10. Loss: 1.1475:  19%|[36m█▉        [0m| 5/26 [00:05<00:23,  1.13s/it]Epoch: 5/10. Loss: 1.0347:  19%|[36m█▉        [0m| 5/26 [00:06<00:23,  1.13s/it]Epoch: 5/10. Loss: 1.0347:  23%|[36m██▎       [0m| 6/26 [00:06<00:21,  1.09s/it]Epoch: 5/10. Loss: 1.4345:  23%|[36m██▎       [0m| 6/26 [00:07<00:21,  1.09s/it]Epoch: 5/10. Loss: 1.4345:  27%|[36m██▋       [0m| 7/26 [00:07<00:21,  1.15s/it]Epoch: 5/10. Loss: 0.9861:  27%|[36m██▋       [0m| 7/26 [00:08<00:21,  1.15s/it]Epoch: 5/10. Loss: 0.9861:  31%|[36m███       [0m| 8/26 [00:08<00:19,  1.10s/it]Epoch: 5/10. Loss: 1.0496:  31%|[36m███       [0m| 8/26 [00:09<00:19,  1.10s/it]Epoch: 5/10. Loss: 1.0496:  35%|[36m███▍      [0m| 9/26 [00:09<00:17,  1.05s/it]Epoch: 5/10. Loss: 0.9734:  35%|[36m███▍      [0m| 9/26 [00:10<00:17,  1.05s/it]Epoch: 5/10. Loss: 0.9734:  38%|[36m███▊      [0m| 10/26 [00:10<00:16,  1.03s/it]Epoch: 5/10. Loss: 1.1738:  38%|[36m███▊      [0m| 10/26 [00:11<00:16,  1.03s/it]Epoch: 5/10. Loss: 1.1738:  42%|[36m████▏     [0m| 11/26 [00:11<00:15,  1.04s/it]Epoch: 5/10. Loss: 1.7074:  42%|[36m████▏     [0m| 11/26 [00:12<00:15,  1.04s/it]Epoch: 5/10. Loss: 1.7074:  46%|[36m████▌     [0m| 12/26 [00:12<00:13,  1.01it/s]Epoch: 5/10. Loss: 1.4814:  46%|[36m████▌     [0m| 12/26 [00:14<00:13,  1.01it/s]Epoch: 5/10. Loss: 1.4814:  50%|[36m█████     [0m| 13/26 [00:14<00:17,  1.34s/it]Epoch: 5/10. Loss: 1.0643:  50%|[36m█████     [0m| 13/26 [00:17<00:17,  1.34s/it]Epoch: 5/10. Loss: 1.0643:  54%|[36m█████▍    [0m| 14/26 [00:17<00:20,  1.74s/it]Epoch: 5/10. Loss: 1.2738:  54%|[36m█████▍    [0m| 14/26 [00:20<00:20,  1.74s/it]Epoch: 5/10. Loss: 1.2738:  58%|[36m█████▊    [0m| 15/26 [00:20<00:23,  2.11s/it]Epoch: 5/10. Loss: 1.0014:  58%|[36m█████▊    [0m| 15/26 [00:21<00:23,  2.11s/it]Epoch: 5/10. Loss: 1.0014:  62%|[36m██████▏   [0m| 16/26 [00:21<00:17,  1.70s/it]Epoch: 5/10. Loss: 1.1369:  62%|[36m██████▏   [0m| 16/26 [00:22<00:17,  1.70s/it]Epoch: 5/10. Loss: 1.1369:  65%|[36m██████▌   [0m| 17/26 [00:22<00:12,  1.43s/it]Epoch: 5/10. Loss: 1.2301:  65%|[36m██████▌   [0m| 17/26 [00:23<00:12,  1.43s/it]Epoch: 5/10. Loss: 1.2301:  69%|[36m██████▉   [0m| 18/26 [00:23<00:10,  1.27s/it]Epoch: 5/10. Loss: 1.0811:  69%|[36m██████▉   [0m| 18/26 [00:24<00:10,  1.27s/it]Epoch: 5/10. Loss: 1.0811:  73%|[36m███████▎  [0m| 19/26 [00:24<00:08,  1.25s/it]Epoch: 5/10. Loss: 1.0757:  73%|[36m███████▎  [0m| 19/26 [00:25<00:08,  1.25s/it]Epoch: 5/10. Loss: 1.0757:  77%|[36m███████▋  [0m| 20/26 [00:25<00:07,  1.18s/it]Epoch: 5/10. Loss: 1.1260:  77%|[36m███████▋  [0m| 20/26 [00:26<00:07,  1.18s/it]Epoch: 5/10. Loss: 1.1260:  81%|[36m████████  [0m| 21/26 [00:26<00:06,  1.23s/it]Epoch: 5/10. Loss: 1.7071:  81%|[36m████████  [0m| 21/26 [00:27<00:06,  1.23s/it]Epoch: 5/10. Loss: 1.7071:  85%|[36m████████▍ [0m| 22/26 [00:27<00:04,  1.15s/it]Epoch: 5/10. Loss: 1.5258:  85%|[36m████████▍ [0m| 22/26 [00:28<00:04,  1.15s/it]Epoch: 5/10. Loss: 1.5258:  88%|[36m████████▊ [0m| 23/26 [00:28<00:03,  1.08s/it]Epoch: 5/10. Loss: 1.3028:  88%|[36m████████▊ [0m| 23/26 [00:29<00:03,  1.08s/it]Epoch: 5/10. Loss: 1.3028:  92%|[36m█████████▏[0m| 24/26 [00:29<00:01,  1.02it/s]Epoch: 5/10. Loss: 1.3636:  92%|[36m█████████▏[0m| 24/26 [00:30<00:01,  1.02it/s]Epoch: 5/10. Loss: 1.3636:  96%|[36m█████████▌[0m| 25/26 [00:30<00:00,  1.05it/s]Epoch: 5/10. Loss: 0.9775:  96%|[36m█████████▌[0m| 25/26 [00:32<00:00,  1.05it/s]Epoch: 5/10. Loss: 0.9775: 100%|[36m██████████[0m| 26/26 [00:32<00:00,  1.25s/it]Epoch: 5/10. Loss: 0.9775: 100%|[36m██████████[0m| 26/26 [00:32<00:00,  1.23s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:01<00:07,  1.18s/it] 29%|[33m██▊       [0m| 2/7 [00:03<00:09,  1.82s/it] 43%|[33m████▎     [0m| 3/7 [00:04<00:05,  1.35s/it] 57%|[33m█████▋    [0m| 4/7 [00:05<00:04,  1.40s/it] 71%|[33m███████▏  [0m| 5/7 [00:06<00:02,  1.06s/it] 86%|[33m████████▌ [0m| 6/7 [00:07<00:01,  1.22s/it]100%|[33m██████████[0m| 7/7 [00:07<00:00,  1.10it/s]100%|[33m██████████[0m| 7/7 [00:07<00:00,  1.14s/it]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 6/10. Loss: 0.9314:   0%|[36m          [0m| 0/26 [00:02<?, ?it/s]Epoch: 6/10. Loss: 0.9314:   4%|[36m▍         [0m| 1/26 [00:02<00:52,  2.08s/it]Epoch: 6/10. Loss: 1.0955:   4%|[36m▍         [0m| 1/26 [00:04<00:52,  2.08s/it]Epoch: 6/10. Loss: 1.0955:   8%|[36m▊         [0m| 2/26 [00:04<00:51,  2.15s/it]Epoch: 6/10. Loss: 1.1056:   8%|[36m▊         [0m| 2/26 [00:05<00:51,  2.15s/it]Epoch: 6/10. Loss: 1.1056:  12%|[36m█▏        [0m| 3/26 [00:05<00:41,  1.82s/it]Epoch: 6/10. Loss: 0.9955:  12%|[36m█▏        [0m| 3/26 [00:10<00:41,  1.82s/it]Epoch: 6/10. Loss: 0.9955:  15%|[36m█▌        [0m| 4/26 [00:10<01:05,  2.98s/it]Epoch: 6/10. Loss: 1.0606:  15%|[36m█▌        [0m| 4/26 [00:13<01:05,  2.98s/it]Epoch: 6/10. Loss: 1.0606:  19%|[36m█▉        [0m| 5/26 [00:13<01:00,  2.90s/it]Epoch: 6/10. Loss: 1.3238:  19%|[36m█▉        [0m| 5/26 [00:14<01:00,  2.90s/it]Epoch: 6/10. Loss: 1.3238:  23%|[36m██▎       [0m| 6/26 [00:14<00:44,  2.25s/it]Epoch: 6/10. Loss: 1.0933:  23%|[36m██▎       [0m| 6/26 [00:15<00:44,  2.25s/it]Epoch: 6/10. Loss: 1.0933:  27%|[36m██▋       [0m| 7/26 [00:15<00:34,  1.81s/it]Epoch: 6/10. Loss: 1.1802:  27%|[36m██▋       [0m| 7/26 [00:16<00:34,  1.81s/it]Epoch: 6/10. Loss: 1.1802:  31%|[36m███       [0m| 8/26 [00:16<00:31,  1.74s/it]Epoch: 6/10. Loss: 1.0676:  31%|[36m███       [0m| 8/26 [00:17<00:31,  1.74s/it]Epoch: 6/10. Loss: 1.0676:  35%|[36m███▍      [0m| 9/26 [00:17<00:26,  1.58s/it]Epoch: 6/10. Loss: 1.2610:  35%|[36m███▍      [0m| 9/26 [00:20<00:26,  1.58s/it]Epoch: 6/10. Loss: 1.2610:  38%|[36m███▊      [0m| 10/26 [00:20<00:30,  1.88s/it]Epoch: 6/10. Loss: 1.0081:  38%|[36m███▊      [0m| 10/26 [00:21<00:30,  1.88s/it]Epoch: 6/10. Loss: 1.0081:  42%|[36m████▏     [0m| 11/26 [00:21<00:23,  1.59s/it]Epoch: 6/10. Loss: 1.0304:  42%|[36m████▏     [0m| 11/26 [00:22<00:23,  1.59s/it]Epoch: 6/10. Loss: 1.0304:  46%|[36m████▌     [0m| 12/26 [00:22<00:19,  1.40s/it]Epoch: 6/10. Loss: 1.4097:  46%|[36m████▌     [0m| 12/26 [00:25<00:19,  1.40s/it]Epoch: 6/10. Loss: 1.4097:  50%|[36m█████     [0m| 13/26 [00:25<00:25,  1.98s/it]Epoch: 6/10. Loss: 1.4877:  50%|[36m█████     [0m| 13/26 [00:26<00:25,  1.98s/it]Epoch: 6/10. Loss: 1.4877:  54%|[36m█████▍    [0m| 14/26 [00:26<00:20,  1.69s/it]Epoch: 6/10. Loss: 1.0315:  54%|[36m█████▍    [0m| 14/26 [00:29<00:20,  1.69s/it]Epoch: 6/10. Loss: 1.0315:  58%|[36m█████▊    [0m| 15/26 [00:29<00:22,  2.00s/it]Epoch: 6/10. Loss: 1.2413:  58%|[36m█████▊    [0m| 15/26 [00:30<00:22,  2.00s/it]Epoch: 6/10. Loss: 1.2413:  62%|[36m██████▏   [0m| 16/26 [00:30<00:16,  1.69s/it]Epoch: 6/10. Loss: 1.3761:  62%|[36m██████▏   [0m| 16/26 [00:32<00:16,  1.69s/it]Epoch: 6/10. Loss: 1.3761:  65%|[36m██████▌   [0m| 17/26 [00:32<00:15,  1.70s/it]Epoch: 6/10. Loss: 1.1196:  65%|[36m██████▌   [0m| 17/26 [00:33<00:15,  1.70s/it]Epoch: 6/10. Loss: 1.1196:  69%|[36m██████▉   [0m| 18/26 [00:33<00:13,  1.64s/it]Epoch: 6/10. Loss: 1.2944:  69%|[36m██████▉   [0m| 18/26 [00:34<00:13,  1.64s/it]Epoch: 6/10. Loss: 1.2944:  73%|[36m███████▎  [0m| 19/26 [00:34<00:10,  1.45s/it]Epoch: 6/10. Loss: 1.1607:  73%|[36m███████▎  [0m| 19/26 [00:35<00:10,  1.45s/it]Epoch: 6/10. Loss: 1.1607:  77%|[36m███████▋  [0m| 20/26 [00:35<00:07,  1.33s/it]Epoch: 6/10. Loss: 1.1091:  77%|[36m███████▋  [0m| 20/26 [00:36<00:07,  1.33s/it]Epoch: 6/10. Loss: 1.1091:  81%|[36m████████  [0m| 21/26 [00:36<00:05,  1.18s/it]Epoch: 6/10. Loss: 1.0490:  81%|[36m████████  [0m| 21/26 [00:37<00:05,  1.18s/it]Epoch: 6/10. Loss: 1.0490:  85%|[36m████████▍ [0m| 22/26 [00:37<00:04,  1.10s/it]Epoch: 6/10. Loss: 1.0241:  85%|[36m████████▍ [0m| 22/26 [00:40<00:04,  1.10s/it]Epoch: 6/10. Loss: 1.0241:  88%|[36m████████▊ [0m| 23/26 [00:40<00:04,  1.58s/it]Epoch: 6/10. Loss: 1.0223:  88%|[36m████████▊ [0m| 23/26 [00:40<00:04,  1.58s/it]Epoch: 6/10. Loss: 1.0223:  92%|[36m█████████▏[0m| 24/26 [00:40<00:02,  1.35s/it]Epoch: 6/10. Loss: 1.1247:  92%|[36m█████████▏[0m| 24/26 [00:41<00:02,  1.35s/it]Epoch: 6/10. Loss: 1.1247:  96%|[36m█████████▌[0m| 25/26 [00:41<00:01,  1.23s/it]Epoch: 6/10. Loss: 1.0698:  96%|[36m█████████▌[0m| 25/26 [00:42<00:01,  1.23s/it]Epoch: 6/10. Loss: 1.0698: 100%|[36m██████████[0m| 26/26 [00:43<00:00,  1.20s/it]Epoch: 6/10. Loss: 1.0698: 100%|[36m██████████[0m| 26/26 [00:43<00:00,  1.65s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:01<00:07,  1.27s/it] 29%|[33m██▊       [0m| 2/7 [00:06<00:17,  3.41s/it] 43%|[33m████▎     [0m| 3/7 [00:09<00:13,  3.28s/it] 57%|[33m█████▋    [0m| 4/7 [00:12<00:09,  3.24s/it] 71%|[33m███████▏  [0m| 5/7 [00:13<00:04,  2.29s/it] 86%|[33m████████▌ [0m| 6/7 [00:15<00:02,  2.27s/it]100%|[33m██████████[0m| 7/7 [00:17<00:00,  2.32s/it]100%|[33m██████████[0m| 7/7 [00:17<00:00,  2.54s/it]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 7/10. Loss: 1.1932:   0%|[36m          [0m| 0/26 [00:02<?, ?it/s]Epoch: 7/10. Loss: 1.1932:   4%|[36m▍         [0m| 1/26 [00:02<01:12,  2.89s/it]Epoch: 7/10. Loss: 0.9808:   4%|[36m▍         [0m| 1/26 [00:03<01:12,  2.89s/it]Epoch: 7/10. Loss: 0.9808:   8%|[36m▊         [0m| 2/26 [00:03<00:41,  1.72s/it]Epoch: 7/10. Loss: 0.9569:   8%|[36m▊         [0m| 2/26 [00:07<00:41,  1.72s/it]Epoch: 7/10. Loss: 0.9569:  12%|[36m█▏        [0m| 3/26 [00:07<00:58,  2.54s/it]Epoch: 7/10. Loss: 1.0266:  12%|[36m█▏        [0m| 3/26 [00:08<00:58,  2.54s/it]Epoch: 7/10. Loss: 1.0266:  15%|[36m█▌        [0m| 4/26 [00:08<00:42,  1.94s/it]Epoch: 7/10. Loss: 1.0439:  15%|[36m█▌        [0m| 4/26 [00:09<00:42,  1.94s/it]Epoch: 7/10. Loss: 1.0439:  19%|[36m█▉        [0m| 5/26 [00:09<00:33,  1.61s/it]Epoch: 7/10. Loss: 1.1207:  19%|[36m█▉        [0m| 5/26 [00:10<00:33,  1.61s/it]Epoch: 7/10. Loss: 1.1207:  23%|[36m██▎       [0m| 6/26 [00:10<00:27,  1.38s/it]Epoch: 7/10. Loss: 1.0733:  23%|[36m██▎       [0m| 6/26 [00:11<00:27,  1.38s/it]Epoch: 7/10. Loss: 1.0733:  27%|[36m██▋       [0m| 7/26 [00:11<00:22,  1.20s/it]Epoch: 7/10. Loss: 1.0949:  27%|[36m██▋       [0m| 7/26 [00:11<00:22,  1.20s/it]Epoch: 7/10. Loss: 1.0949:  31%|[36m███       [0m| 8/26 [00:11<00:19,  1.08s/it]Epoch: 7/10. Loss: 0.9814:  31%|[36m███       [0m| 8/26 [00:12<00:19,  1.08s/it]Epoch: 7/10. Loss: 0.9814:  35%|[36m███▍      [0m| 9/26 [00:12<00:17,  1.04s/it]Epoch: 7/10. Loss: 1.1770:  35%|[36m███▍      [0m| 9/26 [00:13<00:17,  1.04s/it]Epoch: 7/10. Loss: 1.1770:  38%|[36m███▊      [0m| 10/26 [00:13<00:15,  1.01it/s]Epoch: 7/10. Loss: 1.0593:  38%|[36m███▊      [0m| 10/26 [00:15<00:15,  1.01it/s]Epoch: 7/10. Loss: 1.0593:  42%|[36m████▏     [0m| 11/26 [00:15<00:18,  1.26s/it]Epoch: 7/10. Loss: 0.9600:  42%|[36m████▏     [0m| 11/26 [00:16<00:18,  1.26s/it]Epoch: 7/10. Loss: 0.9600:  46%|[36m████▌     [0m| 12/26 [00:16<00:16,  1.19s/it]Epoch: 7/10. Loss: 1.0280:  46%|[36m████▌     [0m| 12/26 [00:17<00:16,  1.19s/it]Epoch: 7/10. Loss: 1.0280:  50%|[36m█████     [0m| 13/26 [00:17<00:15,  1.21s/it]Epoch: 7/10. Loss: 1.0004:  50%|[36m█████     [0m| 13/26 [00:18<00:15,  1.21s/it]Epoch: 7/10. Loss: 1.0004:  54%|[36m█████▍    [0m| 14/26 [00:19<00:14,  1.17s/it]Epoch: 7/10. Loss: 1.0624:  54%|[36m█████▍    [0m| 14/26 [00:19<00:14,  1.17s/it]Epoch: 7/10. Loss: 1.0624:  58%|[36m█████▊    [0m| 15/26 [00:19<00:12,  1.10s/it]Epoch: 7/10. Loss: 0.9784:  58%|[36m█████▊    [0m| 15/26 [00:20<00:12,  1.10s/it]Epoch: 7/10. Loss: 0.9784:  62%|[36m██████▏   [0m| 16/26 [00:20<00:10,  1.04s/it]Epoch: 7/10. Loss: 1.0170:  62%|[36m██████▏   [0m| 16/26 [00:21<00:10,  1.04s/it]Epoch: 7/10. Loss: 1.0170:  65%|[36m██████▌   [0m| 17/26 [00:21<00:08,  1.01it/s]Epoch: 7/10. Loss: 1.0363:  65%|[36m██████▌   [0m| 17/26 [00:23<00:08,  1.01it/s]Epoch: 7/10. Loss: 1.0363:  69%|[36m██████▉   [0m| 18/26 [00:23<00:08,  1.11s/it]Epoch: 7/10. Loss: 1.1851:  69%|[36m██████▉   [0m| 18/26 [00:24<00:08,  1.11s/it]Epoch: 7/10. Loss: 1.1851:  73%|[36m███████▎  [0m| 19/26 [00:24<00:07,  1.10s/it]Epoch: 7/10. Loss: 0.9657:  73%|[36m███████▎  [0m| 19/26 [00:25<00:07,  1.10s/it]Epoch: 7/10. Loss: 0.9657:  77%|[36m███████▋  [0m| 20/26 [00:25<00:06,  1.03s/it]Epoch: 7/10. Loss: 1.0254:  77%|[36m███████▋  [0m| 20/26 [00:28<00:06,  1.03s/it]Epoch: 7/10. Loss: 1.0254:  81%|[36m████████  [0m| 21/26 [00:28<00:09,  1.85s/it]Epoch: 7/10. Loss: 1.0524:  81%|[36m████████  [0m| 21/26 [00:30<00:09,  1.85s/it]Epoch: 7/10. Loss: 1.0524:  85%|[36m████████▍ [0m| 22/26 [00:30<00:07,  1.88s/it]Epoch: 7/10. Loss: 1.1614:  85%|[36m████████▍ [0m| 22/26 [00:31<00:07,  1.88s/it]Epoch: 7/10. Loss: 1.1614:  88%|[36m████████▊ [0m| 23/26 [00:31<00:04,  1.59s/it]Epoch: 7/10. Loss: 1.1142:  88%|[36m████████▊ [0m| 23/26 [00:32<00:04,  1.59s/it]Epoch: 7/10. Loss: 1.1142:  92%|[36m█████████▏[0m| 24/26 [00:32<00:02,  1.48s/it]Epoch: 7/10. Loss: 0.9620:  92%|[36m█████████▏[0m| 24/26 [00:33<00:02,  1.48s/it]Epoch: 7/10. Loss: 0.9620:  96%|[36m█████████▌[0m| 25/26 [00:33<00:01,  1.29s/it]Epoch: 7/10. Loss: 0.9799:  96%|[36m█████████▌[0m| 25/26 [00:34<00:01,  1.29s/it]Epoch: 7/10. Loss: 0.9799: 100%|[36m██████████[0m| 26/26 [00:34<00:00,  1.11s/it]Epoch: 7/10. Loss: 0.9799: 100%|[36m██████████[0m| 26/26 [00:34<00:00,  1.32s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:05,  1.07it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:05,  1.03s/it] 43%|[33m████▎     [0m| 3/7 [00:02<00:03,  1.04it/s] 57%|[33m█████▋    [0m| 4/7 [00:04<00:03,  1.11s/it] 71%|[33m███████▏  [0m| 5/7 [00:04<00:01,  1.14it/s] 86%|[33m████████▌ [0m| 6/7 [00:06<00:01,  1.07s/it]100%|[33m██████████[0m| 7/7 [00:06<00:00,  1.23it/s]100%|[33m██████████[0m| 7/7 [00:06<00:00,  1.09it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 8/10. Loss: 1.1075:   0%|[36m          [0m| 0/26 [00:01<?, ?it/s]Epoch: 8/10. Loss: 1.1075:   4%|[36m▍         [0m| 1/26 [00:01<00:28,  1.15s/it]Epoch: 8/10. Loss: 1.0152:   4%|[36m▍         [0m| 1/26 [00:02<00:28,  1.15s/it]Epoch: 8/10. Loss: 1.0152:   8%|[36m▊         [0m| 2/26 [00:02<00:23,  1.00it/s]Epoch: 8/10. Loss: 1.0132:   8%|[36m▊         [0m| 2/26 [00:03<00:23,  1.00it/s]Epoch: 8/10. Loss: 1.0132:  12%|[36m█▏        [0m| 3/26 [00:03<00:23,  1.02s/it]Epoch: 8/10. Loss: 1.1155:  12%|[36m█▏        [0m| 3/26 [00:03<00:23,  1.02s/it]Epoch: 8/10. Loss: 1.1155:  15%|[36m█▌        [0m| 4/26 [00:03<00:20,  1.09it/s]Epoch: 8/10. Loss: 1.0762:  15%|[36m█▌        [0m| 4/26 [00:04<00:20,  1.09it/s]Epoch: 8/10. Loss: 1.0762:  19%|[36m█▉        [0m| 5/26 [00:04<00:19,  1.06it/s]Epoch: 8/10. Loss: 1.0059:  19%|[36m█▉        [0m| 5/26 [00:05<00:19,  1.06it/s]Epoch: 8/10. Loss: 1.0059:  23%|[36m██▎       [0m| 6/26 [00:05<00:18,  1.09it/s]Epoch: 8/10. Loss: 1.3447:  23%|[36m██▎       [0m| 6/26 [00:06<00:18,  1.09it/s]Epoch: 8/10. Loss: 1.3447:  27%|[36m██▋       [0m| 7/26 [00:06<00:18,  1.03it/s]Epoch: 8/10. Loss: 0.9911:  27%|[36m██▋       [0m| 7/26 [00:07<00:18,  1.03it/s]Epoch: 8/10. Loss: 0.9911:  31%|[36m███       [0m| 8/26 [00:07<00:17,  1.02it/s]Epoch: 8/10. Loss: 1.1159:  31%|[36m███       [0m| 8/26 [00:08<00:17,  1.02it/s]Epoch: 8/10. Loss: 1.1159:  35%|[36m███▍      [0m| 9/26 [00:08<00:16,  1.01it/s]Epoch: 8/10. Loss: 1.0304:  35%|[36m███▍      [0m| 9/26 [00:09<00:16,  1.01it/s]Epoch: 8/10. Loss: 1.0304:  38%|[36m███▊      [0m| 10/26 [00:09<00:16,  1.04s/it]Epoch: 8/10. Loss: 1.0504:  38%|[36m███▊      [0m| 10/26 [00:11<00:16,  1.04s/it]Epoch: 8/10. Loss: 1.0504:  42%|[36m████▏     [0m| 11/26 [00:11<00:16,  1.08s/it]Epoch: 8/10. Loss: 1.0282:  42%|[36m████▏     [0m| 11/26 [00:11<00:16,  1.08s/it]Epoch: 8/10. Loss: 1.0282:  46%|[36m████▌     [0m| 12/26 [00:11<00:14,  1.02s/it]Epoch: 8/10. Loss: 1.0368:  46%|[36m████▌     [0m| 12/26 [00:12<00:14,  1.02s/it]Epoch: 8/10. Loss: 1.0368:  50%|[36m█████     [0m| 13/26 [00:12<00:13,  1.00s/it]Epoch: 8/10. Loss: 1.0258:  50%|[36m█████     [0m| 13/26 [00:13<00:13,  1.00s/it]Epoch: 8/10. Loss: 1.0258:  54%|[36m█████▍    [0m| 14/26 [00:13<00:12,  1.01s/it]Epoch: 8/10. Loss: 1.0304:  54%|[36m█████▍    [0m| 14/26 [00:14<00:12,  1.01s/it]Epoch: 8/10. Loss: 1.0304:  58%|[36m█████▊    [0m| 15/26 [00:14<00:10,  1.03it/s]Epoch: 8/10. Loss: 1.1061:  58%|[36m█████▊    [0m| 15/26 [00:15<00:10,  1.03it/s]Epoch: 8/10. Loss: 1.1061:  62%|[36m██████▏   [0m| 16/26 [00:15<00:09,  1.00it/s]Epoch: 8/10. Loss: 0.9791:  62%|[36m██████▏   [0m| 16/26 [00:16<00:09,  1.00it/s]Epoch: 8/10. Loss: 0.9791:  65%|[36m██████▌   [0m| 17/26 [00:16<00:08,  1.02it/s]Epoch: 8/10. Loss: 1.0267:  65%|[36m██████▌   [0m| 17/26 [00:17<00:08,  1.02it/s]Epoch: 8/10. Loss: 1.0267:  69%|[36m██████▉   [0m| 18/26 [00:17<00:07,  1.06it/s]Epoch: 8/10. Loss: 1.0579:  69%|[36m██████▉   [0m| 18/26 [00:18<00:07,  1.06it/s]Epoch: 8/10. Loss: 1.0579:  73%|[36m███████▎  [0m| 19/26 [00:19<00:07,  1.05s/it]Epoch: 8/10. Loss: 1.1303:  73%|[36m███████▎  [0m| 19/26 [00:19<00:07,  1.05s/it]Epoch: 8/10. Loss: 1.1303:  77%|[36m███████▋  [0m| 20/26 [00:20<00:06,  1.03s/it]Epoch: 8/10. Loss: 1.0830:  77%|[36m███████▋  [0m| 20/26 [00:20<00:06,  1.03s/it]Epoch: 8/10. Loss: 1.0830:  81%|[36m████████  [0m| 21/26 [00:20<00:04,  1.00it/s]Epoch: 8/10. Loss: 1.1615:  81%|[36m████████  [0m| 21/26 [00:21<00:04,  1.00it/s]Epoch: 8/10. Loss: 1.1615:  85%|[36m████████▍ [0m| 22/26 [00:21<00:03,  1.02it/s]Epoch: 8/10. Loss: 0.9818:  85%|[36m████████▍ [0m| 22/26 [00:22<00:03,  1.02it/s]Epoch: 8/10. Loss: 0.9818:  88%|[36m████████▊ [0m| 23/26 [00:22<00:02,  1.05it/s]Epoch: 8/10. Loss: 0.9479:  88%|[36m████████▊ [0m| 23/26 [00:23<00:02,  1.05it/s]Epoch: 8/10. Loss: 0.9479:  92%|[36m█████████▏[0m| 24/26 [00:23<00:01,  1.04it/s]Epoch: 8/10. Loss: 0.9699:  92%|[36m█████████▏[0m| 24/26 [00:24<00:01,  1.04it/s]Epoch: 8/10. Loss: 0.9699:  96%|[36m█████████▌[0m| 25/26 [00:24<00:00,  1.08it/s]Epoch: 8/10. Loss: 1.1093:  96%|[36m█████████▌[0m| 25/26 [00:26<00:00,  1.08it/s]Epoch: 8/10. Loss: 1.1093: 100%|[36m██████████[0m| 26/26 [00:26<00:00,  1.15s/it]Epoch: 8/10. Loss: 1.1093: 100%|[36m██████████[0m| 26/26 [00:26<00:00,  1.01s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:01<00:11,  1.84s/it] 29%|[33m██▊       [0m| 2/7 [00:03<00:09,  1.92s/it] 43%|[33m████▎     [0m| 3/7 [00:06<00:09,  2.36s/it] 57%|[33m█████▋    [0m| 4/7 [00:08<00:06,  2.09s/it] 71%|[33m███████▏  [0m| 5/7 [00:08<00:03,  1.50s/it] 86%|[33m████████▌ [0m| 6/7 [00:09<00:01,  1.31s/it]100%|[33m██████████[0m| 7/7 [00:10<00:00,  1.09s/it]100%|[33m██████████[0m| 7/7 [00:10<00:00,  1.49s/it]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 9/10. Loss: 1.0850:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 9/10. Loss: 1.0850:   4%|[36m▍         [0m| 1/26 [00:00<00:22,  1.11it/s]Epoch: 9/10. Loss: 1.1233:   4%|[36m▍         [0m| 1/26 [00:01<00:22,  1.11it/s]Epoch: 9/10. Loss: 1.1233:   8%|[36m▊         [0m| 2/26 [00:01<00:22,  1.07it/s]Epoch: 9/10. Loss: 1.0709:   8%|[36m▊         [0m| 2/26 [00:02<00:22,  1.07it/s]Epoch: 9/10. Loss: 1.0709:  12%|[36m█▏        [0m| 3/26 [00:02<00:21,  1.06it/s]Epoch: 9/10. Loss: 1.0623:  12%|[36m█▏        [0m| 3/26 [00:03<00:21,  1.06it/s]Epoch: 9/10. Loss: 1.0623:  15%|[36m█▌        [0m| 4/26 [00:03<00:20,  1.07it/s]Epoch: 9/10. Loss: 1.1214:  15%|[36m█▌        [0m| 4/26 [00:04<00:20,  1.07it/s]Epoch: 9/10. Loss: 1.1214:  19%|[36m█▉        [0m| 5/26 [00:04<00:19,  1.06it/s]Epoch: 9/10. Loss: 1.1248:  19%|[36m█▉        [0m| 5/26 [00:05<00:19,  1.06it/s]Epoch: 9/10. Loss: 1.1248:  23%|[36m██▎       [0m| 6/26 [00:05<00:20,  1.01s/it]Epoch: 9/10. Loss: 1.0408:  23%|[36m██▎       [0m| 6/26 [00:06<00:20,  1.01s/it]Epoch: 9/10. Loss: 1.0408:  27%|[36m██▋       [0m| 7/26 [00:06<00:18,  1.00it/s]Epoch: 9/10. Loss: 0.9340:  27%|[36m██▋       [0m| 7/26 [00:07<00:18,  1.00it/s]Epoch: 9/10. Loss: 0.9340:  31%|[36m███       [0m| 8/26 [00:07<00:17,  1.02it/s]Epoch: 9/10. Loss: 1.1366:  31%|[36m███       [0m| 8/26 [00:08<00:17,  1.02it/s]Epoch: 9/10. Loss: 1.1366:  35%|[36m███▍      [0m| 9/26 [00:08<00:16,  1.04it/s]Epoch: 9/10. Loss: 1.0297:  35%|[36m███▍      [0m| 9/26 [00:09<00:16,  1.04it/s]Epoch: 9/10. Loss: 1.0297:  38%|[36m███▊      [0m| 10/26 [00:09<00:15,  1.00it/s]Epoch: 9/10. Loss: 1.0315:  38%|[36m███▊      [0m| 10/26 [00:10<00:15,  1.00it/s]Epoch: 9/10. Loss: 1.0315:  42%|[36m████▏     [0m| 11/26 [00:10<00:15,  1.00s/it]Epoch: 9/10. Loss: 1.0930:  42%|[36m████▏     [0m| 11/26 [00:11<00:15,  1.00s/it]Epoch: 9/10. Loss: 1.0930:  46%|[36m████▌     [0m| 12/26 [00:11<00:13,  1.02it/s]Epoch: 9/10. Loss: 1.0843:  46%|[36m████▌     [0m| 12/26 [00:12<00:13,  1.02it/s]Epoch: 9/10. Loss: 1.0843:  50%|[36m█████     [0m| 13/26 [00:12<00:12,  1.03it/s]Epoch: 9/10. Loss: 1.0392:  50%|[36m█████     [0m| 13/26 [00:13<00:12,  1.03it/s]Epoch: 9/10. Loss: 1.0392:  54%|[36m█████▍    [0m| 14/26 [00:13<00:11,  1.01it/s]Epoch: 9/10. Loss: 1.1345:  54%|[36m█████▍    [0m| 14/26 [00:14<00:11,  1.01it/s]Epoch: 9/10. Loss: 1.1345:  58%|[36m█████▊    [0m| 15/26 [00:14<00:10,  1.01it/s]Epoch: 9/10. Loss: 1.2029:  58%|[36m█████▊    [0m| 15/26 [00:15<00:10,  1.01it/s]Epoch: 9/10. Loss: 1.2029:  62%|[36m██████▏   [0m| 16/26 [00:15<00:09,  1.04it/s]Epoch: 9/10. Loss: 1.0073:  62%|[36m██████▏   [0m| 16/26 [00:16<00:09,  1.04it/s]Epoch: 9/10. Loss: 1.0073:  65%|[36m██████▌   [0m| 17/26 [00:16<00:08,  1.01it/s]Epoch: 9/10. Loss: 1.1738:  65%|[36m██████▌   [0m| 17/26 [00:17<00:08,  1.01it/s]Epoch: 9/10. Loss: 1.1738:  69%|[36m██████▉   [0m| 18/26 [00:17<00:07,  1.09it/s]Epoch: 9/10. Loss: 1.0201:  69%|[36m██████▉   [0m| 18/26 [00:18<00:07,  1.09it/s]Epoch: 9/10. Loss: 1.0201:  73%|[36m███████▎  [0m| 19/26 [00:18<00:06,  1.07it/s]Epoch: 9/10. Loss: 1.0878:  73%|[36m███████▎  [0m| 19/26 [00:19<00:06,  1.07it/s]Epoch: 9/10. Loss: 1.0878:  77%|[36m███████▋  [0m| 20/26 [00:19<00:05,  1.14it/s]Epoch: 9/10. Loss: 1.0130:  77%|[36m███████▋  [0m| 20/26 [00:19<00:05,  1.14it/s]Epoch: 9/10. Loss: 1.0130:  81%|[36m████████  [0m| 21/26 [00:20<00:04,  1.12it/s]Epoch: 9/10. Loss: 0.9795:  81%|[36m████████  [0m| 21/26 [00:21<00:04,  1.12it/s]Epoch: 9/10. Loss: 0.9795:  85%|[36m████████▍ [0m| 22/26 [00:21<00:03,  1.07it/s]Epoch: 9/10. Loss: 1.0281:  85%|[36m████████▍ [0m| 22/26 [00:22<00:03,  1.07it/s]Epoch: 9/10. Loss: 1.0281:  88%|[36m████████▊ [0m| 23/26 [00:22<00:02,  1.02it/s]Epoch: 9/10. Loss: 1.1709:  88%|[36m████████▊ [0m| 23/26 [00:23<00:02,  1.02it/s]Epoch: 9/10. Loss: 1.1709:  92%|[36m█████████▏[0m| 24/26 [00:23<00:02,  1.06s/it]Epoch: 9/10. Loss: 1.3217:  92%|[36m█████████▏[0m| 24/26 [00:24<00:02,  1.06s/it]Epoch: 9/10. Loss: 1.3217:  96%|[36m█████████▌[0m| 25/26 [00:24<00:01,  1.01s/it]Epoch: 9/10. Loss: 1.0617:  96%|[36m█████████▌[0m| 25/26 [00:24<00:01,  1.01s/it]Epoch: 9/10. Loss: 1.0617: 100%|[36m██████████[0m| 26/26 [00:24<00:00,  1.12it/s]Epoch: 9/10. Loss: 1.0617: 100%|[36m██████████[0m| 26/26 [00:24<00:00,  1.04it/s]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:05,  1.16it/s] 29%|[33m██▊       [0m| 2/7 [00:01<00:04,  1.03it/s] 43%|[33m████▎     [0m| 3/7 [00:02<00:03,  1.08it/s] 57%|[33m█████▋    [0m| 4/7 [00:04<00:03,  1.13s/it] 71%|[33m███████▏  [0m| 5/7 [00:04<00:01,  1.12it/s] 86%|[33m████████▌ [0m| 6/7 [00:05<00:00,  1.10it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.44it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.19it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 0/10. Loss: 1.1856:   0%|[36m          [0m| 0/26 [00:02<?, ?it/s]Epoch: 0/10. Loss: 1.1856:   4%|[36m▍         [0m| 1/26 [00:02<00:56,  2.26s/it]Epoch: 0/10. Loss: 3.3657:   4%|[36m▍         [0m| 1/26 [00:04<00:56,  2.26s/it]Epoch: 0/10. Loss: 3.3657:   8%|[36m▊         [0m| 2/26 [00:04<00:48,  2.03s/it]Epoch: 0/10. Loss: 2.8536:   8%|[36m▊         [0m| 2/26 [00:05<00:48,  2.03s/it]Epoch: 0/10. Loss: 2.8536:  12%|[36m█▏        [0m| 3/26 [00:05<00:37,  1.65s/it]Epoch: 0/10. Loss: 2.7873:  12%|[36m█▏        [0m| 3/26 [00:06<00:37,  1.65s/it]Epoch: 0/10. Loss: 2.7873:  15%|[36m█▌        [0m| 4/26 [00:06<00:31,  1.41s/it]Epoch: 0/10. Loss: 2.2164:  15%|[36m█▌        [0m| 4/26 [00:08<00:31,  1.41s/it]Epoch: 0/10. Loss: 2.2164:  19%|[36m█▉        [0m| 5/26 [00:08<00:33,  1.61s/it]Epoch: 0/10. Loss: 1.4406:  19%|[36m█▉        [0m| 5/26 [00:10<00:33,  1.61s/it]Epoch: 0/10. Loss: 1.4406:  23%|[36m██▎       [0m| 6/26 [00:10<00:38,  1.91s/it]Epoch: 0/10. Loss: 1.2610:  23%|[36m██▎       [0m| 6/26 [00:14<00:38,  1.91s/it]Epoch: 0/10. Loss: 1.2610:  27%|[36m██▋       [0m| 7/26 [00:14<00:45,  2.40s/it]Epoch: 0/10. Loss: 1.2615:  27%|[36m██▋       [0m| 7/26 [00:14<00:45,  2.40s/it]Epoch: 0/10. Loss: 1.2615:  31%|[36m███       [0m| 8/26 [00:14<00:33,  1.86s/it]Epoch: 0/10. Loss: 1.2471:  31%|[36m███       [0m| 8/26 [00:15<00:33,  1.86s/it]Epoch: 0/10. Loss: 1.2471:  35%|[36m███▍      [0m| 9/26 [00:15<00:26,  1.56s/it]Epoch: 0/10. Loss: 1.3344:  35%|[36m███▍      [0m| 9/26 [00:16<00:26,  1.56s/it]Epoch: 0/10. Loss: 1.3344:  38%|[36m███▊      [0m| 10/26 [00:17<00:23,  1.44s/it]Epoch: 0/10. Loss: 1.1451:  38%|[36m███▊      [0m| 10/26 [00:20<00:23,  1.44s/it]Epoch: 0/10. Loss: 1.1451:  42%|[36m████▏     [0m| 11/26 [00:20<00:29,  1.94s/it]Epoch: 0/10. Loss: 1.1424:  42%|[36m████▏     [0m| 11/26 [00:21<00:29,  1.94s/it]Epoch: 0/10. Loss: 1.1424:  46%|[36m████▌     [0m| 12/26 [00:21<00:25,  1.81s/it]Epoch: 0/10. Loss: 1.0662:  46%|[36m████▌     [0m| 12/26 [00:22<00:25,  1.81s/it]Epoch: 0/10. Loss: 1.0662:  50%|[36m█████     [0m| 13/26 [00:22<00:19,  1.51s/it]Epoch: 0/10. Loss: 1.0488:  50%|[36m█████     [0m| 13/26 [00:23<00:19,  1.51s/it]Epoch: 0/10. Loss: 1.0488:  54%|[36m█████▍    [0m| 14/26 [00:23<00:15,  1.30s/it]Epoch: 0/10. Loss: 1.0432:  54%|[36m█████▍    [0m| 14/26 [00:24<00:15,  1.30s/it]Epoch: 0/10. Loss: 1.0432:  58%|[36m█████▊    [0m| 15/26 [00:24<00:13,  1.20s/it]Epoch: 0/10. Loss: 1.1087:  58%|[36m█████▊    [0m| 15/26 [00:27<00:13,  1.20s/it]Epoch: 0/10. Loss: 1.1087:  62%|[36m██████▏   [0m| 16/26 [00:27<00:17,  1.78s/it]Epoch: 0/10. Loss: 1.0508:  62%|[36m██████▏   [0m| 16/26 [00:28<00:17,  1.78s/it]Epoch: 0/10. Loss: 1.0508:  65%|[36m██████▌   [0m| 17/26 [00:28<00:14,  1.62s/it]Epoch: 0/10. Loss: 1.0454:  65%|[36m██████▌   [0m| 17/26 [00:32<00:14,  1.62s/it]Epoch: 0/10. Loss: 1.0454:  69%|[36m██████▉   [0m| 18/26 [00:32<00:18,  2.32s/it]Epoch: 0/10. Loss: 1.1585:  69%|[36m██████▉   [0m| 18/26 [00:34<00:18,  2.32s/it]Epoch: 0/10. Loss: 1.1585:  73%|[36m███████▎  [0m| 19/26 [00:34<00:15,  2.19s/it]Epoch: 0/10. Loss: 1.0791:  73%|[36m███████▎  [0m| 19/26 [00:36<00:15,  2.19s/it]Epoch: 0/10. Loss: 1.0791:  77%|[36m███████▋  [0m| 20/26 [00:36<00:12,  2.07s/it]Epoch: 0/10. Loss: 1.0054:  77%|[36m███████▋  [0m| 20/26 [00:37<00:12,  2.07s/it]Epoch: 0/10. Loss: 1.0054:  81%|[36m████████  [0m| 21/26 [00:37<00:08,  1.70s/it]Epoch: 0/10. Loss: 1.1855:  81%|[36m████████  [0m| 21/26 [00:38<00:08,  1.70s/it]Epoch: 0/10. Loss: 1.1855:  85%|[36m████████▍ [0m| 22/26 [00:38<00:06,  1.73s/it]Epoch: 0/10. Loss: 1.1555:  85%|[36m████████▍ [0m| 22/26 [00:40<00:06,  1.73s/it]Epoch: 0/10. Loss: 1.1555:  88%|[36m████████▊ [0m| 23/26 [00:40<00:05,  1.78s/it]Epoch: 0/10. Loss: 1.1416:  88%|[36m████████▊ [0m| 23/26 [00:41<00:05,  1.78s/it]Epoch: 0/10. Loss: 1.1416:  92%|[36m█████████▏[0m| 24/26 [00:41<00:03,  1.51s/it]Epoch: 0/10. Loss: 1.0163:  92%|[36m█████████▏[0m| 24/26 [00:42<00:03,  1.51s/it]Epoch: 0/10. Loss: 1.0163:  96%|[36m█████████▌[0m| 25/26 [00:42<00:01,  1.33s/it]Epoch: 0/10. Loss: 1.0792:  96%|[36m█████████▌[0m| 25/26 [00:44<00:01,  1.33s/it]Epoch: 0/10. Loss: 1.0792: 100%|[36m██████████[0m| 26/26 [00:44<00:00,  1.48s/it]Epoch: 0/10. Loss: 1.0792: 100%|[36m██████████[0m| 26/26 [00:44<00:00,  1.71s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:01<00:06,  1.01s/it] 29%|[33m██▊       [0m| 2/7 [00:02<00:05,  1.07s/it] 43%|[33m████▎     [0m| 3/7 [00:02<00:03,  1.06it/s] 57%|[33m█████▋    [0m| 4/7 [00:04<00:03,  1.08s/it] 71%|[33m███████▏  [0m| 5/7 [00:04<00:01,  1.16it/s] 86%|[33m████████▌ [0m| 6/7 [00:05<00:00,  1.09it/s]100%|[33m██████████[0m| 7/7 [00:06<00:00,  1.39it/s]100%|[33m██████████[0m| 7/7 [00:06<00:00,  1.16it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 1/10. Loss: 1.1243:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 1/10. Loss: 1.1243:   4%|[36m▍         [0m| 1/26 [00:00<00:23,  1.04it/s]Epoch: 1/10. Loss: 0.9944:   4%|[36m▍         [0m| 1/26 [00:01<00:23,  1.04it/s]Epoch: 1/10. Loss: 0.9944:   8%|[36m▊         [0m| 2/26 [00:01<00:23,  1.01it/s]Epoch: 1/10. Loss: 0.9976:   8%|[36m▊         [0m| 2/26 [00:02<00:23,  1.01it/s]Epoch: 1/10. Loss: 0.9976:  12%|[36m█▏        [0m| 3/26 [00:02<00:22,  1.02it/s]Epoch: 1/10. Loss: 1.1233:  12%|[36m█▏        [0m| 3/26 [00:03<00:22,  1.02it/s]Epoch: 1/10. Loss: 1.1233:  15%|[36m█▌        [0m| 4/26 [00:03<00:20,  1.09it/s]Epoch: 1/10. Loss: 1.0589:  15%|[36m█▌        [0m| 4/26 [00:07<00:20,  1.09it/s]Epoch: 1/10. Loss: 1.0589:  19%|[36m█▉        [0m| 5/26 [00:07<00:37,  1.78s/it]Epoch: 1/10. Loss: 0.9810:  19%|[36m█▉        [0m| 5/26 [00:08<00:37,  1.78s/it]Epoch: 1/10. Loss: 0.9810:  23%|[36m██▎       [0m| 6/26 [00:08<00:33,  1.67s/it]Epoch: 1/10. Loss: 0.9194:  23%|[36m██▎       [0m| 6/26 [00:09<00:33,  1.67s/it]Epoch: 1/10. Loss: 0.9194:  27%|[36m██▋       [0m| 7/26 [00:09<00:27,  1.43s/it]Epoch: 1/10. Loss: 0.9889:  27%|[36m██▋       [0m| 7/26 [00:11<00:27,  1.43s/it]Epoch: 1/10. Loss: 0.9889:  31%|[36m███       [0m| 8/26 [00:11<00:27,  1.54s/it]Epoch: 1/10. Loss: 1.0045:  31%|[36m███       [0m| 8/26 [00:12<00:27,  1.54s/it]Epoch: 1/10. Loss: 1.0045:  35%|[36m███▍      [0m| 9/26 [00:12<00:22,  1.35s/it]Epoch: 1/10. Loss: 1.0732:  35%|[36m███▍      [0m| 9/26 [00:17<00:22,  1.35s/it]Epoch: 1/10. Loss: 1.0732:  38%|[36m███▊      [0m| 10/26 [00:17<00:43,  2.70s/it]Epoch: 1/10. Loss: 0.9962:  38%|[36m███▊      [0m| 10/26 [00:19<00:43,  2.70s/it]Epoch: 1/10. Loss: 0.9962:  42%|[36m████▏     [0m| 11/26 [00:19<00:35,  2.35s/it]Epoch: 1/10. Loss: 0.9916:  42%|[36m████▏     [0m| 11/26 [00:21<00:35,  2.35s/it]Epoch: 1/10. Loss: 0.9916:  46%|[36m████▌     [0m| 12/26 [00:21<00:30,  2.21s/it]Epoch: 1/10. Loss: 1.0579:  46%|[36m████▌     [0m| 12/26 [00:22<00:30,  2.21s/it]Epoch: 1/10. Loss: 1.0579:  50%|[36m█████     [0m| 13/26 [00:22<00:23,  1.81s/it]Epoch: 1/10. Loss: 1.0460:  50%|[36m█████     [0m| 13/26 [00:23<00:23,  1.81s/it]Epoch: 1/10. Loss: 1.0460:  54%|[36m█████▍    [0m| 14/26 [00:23<00:18,  1.57s/it]Epoch: 1/10. Loss: 0.9834:  54%|[36m█████▍    [0m| 14/26 [00:24<00:18,  1.57s/it]Epoch: 1/10. Loss: 0.9834:  58%|[36m█████▊    [0m| 15/26 [00:24<00:15,  1.44s/it]Epoch: 1/10. Loss: 1.0550:  58%|[36m█████▊    [0m| 15/26 [00:25<00:15,  1.44s/it]Epoch: 1/10. Loss: 1.0550:  62%|[36m██████▏   [0m| 16/26 [00:25<00:13,  1.31s/it]Epoch: 1/10. Loss: 1.0359:  62%|[36m██████▏   [0m| 16/26 [00:26<00:13,  1.31s/it]Epoch: 1/10. Loss: 1.0359:  65%|[36m██████▌   [0m| 17/26 [00:26<00:10,  1.18s/it]Epoch: 1/10. Loss: 0.9677:  65%|[36m██████▌   [0m| 17/26 [00:27<00:10,  1.18s/it]Epoch: 1/10. Loss: 0.9677:  69%|[36m██████▉   [0m| 18/26 [00:27<00:08,  1.11s/it]Epoch: 1/10. Loss: 0.9856:  69%|[36m██████▉   [0m| 18/26 [00:28<00:08,  1.11s/it]Epoch: 1/10. Loss: 0.9856:  73%|[36m███████▎  [0m| 19/26 [00:28<00:07,  1.06s/it]Epoch: 1/10. Loss: 0.9623:  73%|[36m███████▎  [0m| 19/26 [00:29<00:07,  1.06s/it]Epoch: 1/10. Loss: 0.9623:  77%|[36m███████▋  [0m| 20/26 [00:29<00:06,  1.04s/it]Epoch: 1/10. Loss: 1.0490:  77%|[36m███████▋  [0m| 20/26 [00:30<00:06,  1.04s/it]Epoch: 1/10. Loss: 1.0490:  81%|[36m████████  [0m| 21/26 [00:30<00:05,  1.09s/it]Epoch: 1/10. Loss: 0.9286:  81%|[36m████████  [0m| 21/26 [00:31<00:05,  1.09s/it]Epoch: 1/10. Loss: 0.9286:  85%|[36m████████▍ [0m| 22/26 [00:31<00:04,  1.02s/it]Epoch: 1/10. Loss: 1.0305:  85%|[36m████████▍ [0m| 22/26 [00:32<00:04,  1.02s/it]Epoch: 1/10. Loss: 1.0305:  88%|[36m████████▊ [0m| 23/26 [00:32<00:03,  1.04s/it]Epoch: 1/10. Loss: 1.1200:  88%|[36m████████▊ [0m| 23/26 [00:33<00:03,  1.04s/it]Epoch: 1/10. Loss: 1.1200:  92%|[36m█████████▏[0m| 24/26 [00:33<00:01,  1.03it/s]Epoch: 1/10. Loss: 1.0051:  92%|[36m█████████▏[0m| 24/26 [00:33<00:01,  1.03it/s]Epoch: 1/10. Loss: 1.0051:  96%|[36m█████████▌[0m| 25/26 [00:33<00:00,  1.10it/s]Epoch: 1/10. Loss: 0.9435:  96%|[36m█████████▌[0m| 25/26 [00:34<00:00,  1.10it/s]Epoch: 1/10. Loss: 0.9435: 100%|[36m██████████[0m| 26/26 [00:34<00:00,  1.14it/s]Epoch: 1/10. Loss: 0.9435: 100%|[36m██████████[0m| 26/26 [00:34<00:00,  1.33s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:01<00:06,  1.11s/it] 29%|[33m██▊       [0m| 2/7 [00:02<00:05,  1.03s/it] 43%|[33m████▎     [0m| 3/7 [00:02<00:03,  1.13it/s] 57%|[33m█████▋    [0m| 4/7 [00:04<00:03,  1.05s/it] 71%|[33m███████▏  [0m| 5/7 [00:04<00:01,  1.19it/s] 86%|[33m████████▌ [0m| 6/7 [00:05<00:00,  1.16it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.50it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.22it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 2/10. Loss: 1.0133:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 2/10. Loss: 1.0133:   4%|[36m▍         [0m| 1/26 [00:00<00:24,  1.01it/s]Epoch: 2/10. Loss: 1.0193:   4%|[36m▍         [0m| 1/26 [00:01<00:24,  1.01it/s]Epoch: 2/10. Loss: 1.0193:   8%|[36m▊         [0m| 2/26 [00:01<00:22,  1.04it/s]Epoch: 2/10. Loss: 1.1783:   8%|[36m▊         [0m| 2/26 [00:02<00:22,  1.04it/s]Epoch: 2/10. Loss: 1.1783:  12%|[36m█▏        [0m| 3/26 [00:02<00:22,  1.03it/s]Epoch: 2/10. Loss: 1.0222:  12%|[36m█▏        [0m| 3/26 [00:04<00:22,  1.03it/s]Epoch: 2/10. Loss: 1.0222:  15%|[36m█▌        [0m| 4/26 [00:04<00:22,  1.03s/it]Epoch: 2/10. Loss: 1.0915:  15%|[36m█▌        [0m| 4/26 [00:04<00:22,  1.03s/it]Epoch: 2/10. Loss: 1.0915:  19%|[36m█▉        [0m| 5/26 [00:04<00:20,  1.02it/s]Epoch: 2/10. Loss: 0.9781:  19%|[36m█▉        [0m| 5/26 [00:05<00:20,  1.02it/s]Epoch: 2/10. Loss: 0.9781:  23%|[36m██▎       [0m| 6/26 [00:05<00:19,  1.01it/s]Epoch: 2/10. Loss: 0.9387:  23%|[36m██▎       [0m| 6/26 [00:06<00:19,  1.01it/s]Epoch: 2/10. Loss: 0.9387:  27%|[36m██▋       [0m| 7/26 [00:06<00:18,  1.03it/s]Epoch: 2/10. Loss: 1.1538:  27%|[36m██▋       [0m| 7/26 [00:07<00:18,  1.03it/s]Epoch: 2/10. Loss: 1.1538:  31%|[36m███       [0m| 8/26 [00:07<00:17,  1.03it/s]Epoch: 2/10. Loss: 1.1636:  31%|[36m███       [0m| 8/26 [00:08<00:17,  1.03it/s]Epoch: 2/10. Loss: 1.1636:  35%|[36m███▍      [0m| 9/26 [00:08<00:15,  1.07it/s]Epoch: 2/10. Loss: 0.9989:  35%|[36m███▍      [0m| 9/26 [00:09<00:15,  1.07it/s]Epoch: 2/10. Loss: 0.9989:  38%|[36m███▊      [0m| 10/26 [00:09<00:13,  1.14it/s]Epoch: 2/10. Loss: 1.0759:  38%|[36m███▊      [0m| 10/26 [00:10<00:13,  1.14it/s]Epoch: 2/10. Loss: 1.0759:  42%|[36m████▏     [0m| 11/26 [00:10<00:12,  1.19it/s]Epoch: 2/10. Loss: 0.9834:  42%|[36m████▏     [0m| 11/26 [00:11<00:12,  1.19it/s]Epoch: 2/10. Loss: 0.9834:  46%|[36m████▌     [0m| 12/26 [00:11<00:12,  1.13it/s]Epoch: 2/10. Loss: 1.0311:  46%|[36m████▌     [0m| 12/26 [00:11<00:12,  1.13it/s]Epoch: 2/10. Loss: 1.0311:  50%|[36m█████     [0m| 13/26 [00:11<00:11,  1.17it/s]Epoch: 2/10. Loss: 0.9715:  50%|[36m█████     [0m| 13/26 [00:13<00:11,  1.17it/s]Epoch: 2/10. Loss: 0.9715:  54%|[36m█████▍    [0m| 14/26 [00:13<00:10,  1.09it/s]Epoch: 2/10. Loss: 1.0066:  54%|[36m█████▍    [0m| 14/26 [00:13<00:10,  1.09it/s]Epoch: 2/10. Loss: 1.0066:  58%|[36m█████▊    [0m| 15/26 [00:13<00:10,  1.09it/s]Epoch: 2/10. Loss: 1.0053:  58%|[36m█████▊    [0m| 15/26 [00:14<00:10,  1.09it/s]Epoch: 2/10. Loss: 1.0053:  62%|[36m██████▏   [0m| 16/26 [00:15<00:09,  1.04it/s]Epoch: 2/10. Loss: 1.0061:  62%|[36m██████▏   [0m| 16/26 [00:15<00:09,  1.04it/s]Epoch: 2/10. Loss: 1.0061:  65%|[36m██████▌   [0m| 17/26 [00:15<00:08,  1.10it/s]Epoch: 2/10. Loss: 1.1778:  65%|[36m██████▌   [0m| 17/26 [00:16<00:08,  1.10it/s]Epoch: 2/10. Loss: 1.1778:  69%|[36m██████▉   [0m| 18/26 [00:16<00:07,  1.06it/s]Epoch: 2/10. Loss: 1.0128:  69%|[36m██████▉   [0m| 18/26 [00:17<00:07,  1.06it/s]Epoch: 2/10. Loss: 1.0128:  73%|[36m███████▎  [0m| 19/26 [00:17<00:06,  1.07it/s]Epoch: 2/10. Loss: 0.9778:  73%|[36m███████▎  [0m| 19/26 [00:18<00:06,  1.07it/s]Epoch: 2/10. Loss: 0.9778:  77%|[36m███████▋  [0m| 20/26 [00:18<00:05,  1.06it/s]Epoch: 2/10. Loss: 1.0272:  77%|[36m███████▋  [0m| 20/26 [00:19<00:05,  1.06it/s]Epoch: 2/10. Loss: 1.0272:  81%|[36m████████  [0m| 21/26 [00:19<00:04,  1.09it/s]Epoch: 2/10. Loss: 1.0079:  81%|[36m████████  [0m| 21/26 [00:20<00:04,  1.09it/s]Epoch: 2/10. Loss: 1.0079:  85%|[36m████████▍ [0m| 22/26 [00:20<00:03,  1.10it/s]Epoch: 2/10. Loss: 0.9259:  85%|[36m████████▍ [0m| 22/26 [00:21<00:03,  1.10it/s]Epoch: 2/10. Loss: 0.9259:  88%|[36m████████▊ [0m| 23/26 [00:21<00:02,  1.02it/s]Epoch: 2/10. Loss: 1.0489:  88%|[36m████████▊ [0m| 23/26 [00:22<00:02,  1.02it/s]Epoch: 2/10. Loss: 1.0489:  92%|[36m█████████▏[0m| 24/26 [00:22<00:02,  1.04s/it]Epoch: 2/10. Loss: 1.0171:  92%|[36m█████████▏[0m| 24/26 [00:23<00:02,  1.04s/it]Epoch: 2/10. Loss: 1.0171:  96%|[36m█████████▌[0m| 25/26 [00:23<00:01,  1.01s/it]Epoch: 2/10. Loss: 1.0245:  96%|[36m█████████▌[0m| 25/26 [00:24<00:01,  1.01s/it]Epoch: 2/10. Loss: 1.0245: 100%|[36m██████████[0m| 26/26 [00:24<00:00,  1.11it/s]Epoch: 2/10. Loss: 1.0245: 100%|[36m██████████[0m| 26/26 [00:24<00:00,  1.07it/s]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:04,  1.24it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:05,  1.06s/it] 43%|[33m████▎     [0m| 3/7 [00:04<00:06,  1.54s/it] 57%|[33m█████▋    [0m| 4/7 [00:05<00:04,  1.56s/it] 71%|[33m███████▏  [0m| 5/7 [00:06<00:02,  1.17s/it] 86%|[33m████████▌ [0m| 6/7 [00:07<00:01,  1.09s/it]100%|[33m██████████[0m| 7/7 [00:07<00:00,  1.22it/s]100%|[33m██████████[0m| 7/7 [00:07<00:00,  1.06s/it]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 3/10. Loss: 0.9710:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 3/10. Loss: 0.9710:   4%|[36m▍         [0m| 1/26 [00:00<00:19,  1.29it/s]Epoch: 3/10. Loss: 1.0254:   4%|[36m▍         [0m| 1/26 [00:01<00:19,  1.29it/s]Epoch: 3/10. Loss: 1.0254:   8%|[36m▊         [0m| 2/26 [00:01<00:23,  1.03it/s]Epoch: 3/10. Loss: 1.0852:   8%|[36m▊         [0m| 2/26 [00:02<00:23,  1.03it/s]Epoch: 3/10. Loss: 1.0852:  12%|[36m█▏        [0m| 3/26 [00:02<00:20,  1.11it/s]Epoch: 3/10. Loss: 1.0603:  12%|[36m█▏        [0m| 3/26 [00:03<00:20,  1.11it/s]Epoch: 3/10. Loss: 1.0603:  15%|[36m█▌        [0m| 4/26 [00:03<00:18,  1.17it/s]Epoch: 3/10. Loss: 0.9812:  15%|[36m█▌        [0m| 4/26 [00:04<00:18,  1.17it/s]Epoch: 3/10. Loss: 0.9812:  19%|[36m█▉        [0m| 5/26 [00:04<00:18,  1.16it/s]Epoch: 3/10. Loss: 0.9702:  19%|[36m█▉        [0m| 5/26 [00:05<00:18,  1.16it/s]Epoch: 3/10. Loss: 0.9702:  23%|[36m██▎       [0m| 6/26 [00:05<00:18,  1.10it/s]Epoch: 3/10. Loss: 1.0390:  23%|[36m██▎       [0m| 6/26 [00:06<00:18,  1.10it/s]Epoch: 3/10. Loss: 1.0390:  27%|[36m██▋       [0m| 7/26 [00:06<00:18,  1.05it/s]Epoch: 3/10. Loss: 0.9957:  27%|[36m██▋       [0m| 7/26 [00:07<00:18,  1.05it/s]Epoch: 3/10. Loss: 0.9957:  31%|[36m███       [0m| 8/26 [00:07<00:17,  1.02it/s]Epoch: 3/10. Loss: 1.0322:  31%|[36m███       [0m| 8/26 [00:08<00:17,  1.02it/s]Epoch: 3/10. Loss: 1.0322:  35%|[36m███▍      [0m| 9/26 [00:08<00:16,  1.05it/s]Epoch: 3/10. Loss: 1.0892:  35%|[36m███▍      [0m| 9/26 [00:09<00:16,  1.05it/s]Epoch: 3/10. Loss: 1.0892:  38%|[36m███▊      [0m| 10/26 [00:09<00:15,  1.06it/s]Epoch: 3/10. Loss: 0.8793:  38%|[36m███▊      [0m| 10/26 [00:10<00:15,  1.06it/s]Epoch: 3/10. Loss: 0.8793:  42%|[36m████▏     [0m| 11/26 [00:10<00:13,  1.09it/s]Epoch: 3/10. Loss: 1.1662:  42%|[36m████▏     [0m| 11/26 [00:11<00:13,  1.09it/s]Epoch: 3/10. Loss: 1.1662:  46%|[36m████▌     [0m| 12/26 [00:11<00:13,  1.03it/s]Epoch: 3/10. Loss: 1.0009:  46%|[36m████▌     [0m| 12/26 [00:12<00:13,  1.03it/s]Epoch: 3/10. Loss: 1.0009:  50%|[36m█████     [0m| 13/26 [00:12<00:12,  1.02it/s]Epoch: 3/10. Loss: 0.8293:  50%|[36m█████     [0m| 13/26 [00:13<00:12,  1.02it/s]Epoch: 3/10. Loss: 0.8293:  54%|[36m█████▍    [0m| 14/26 [00:13<00:11,  1.03it/s]Epoch: 3/10. Loss: 0.9397:  54%|[36m█████▍    [0m| 14/26 [00:13<00:11,  1.03it/s]Epoch: 3/10. Loss: 0.9397:  58%|[36m█████▊    [0m| 15/26 [00:13<00:10,  1.10it/s]Epoch: 3/10. Loss: 0.9593:  58%|[36m█████▊    [0m| 15/26 [00:14<00:10,  1.10it/s]Epoch: 3/10. Loss: 0.9593:  62%|[36m██████▏   [0m| 16/26 [00:14<00:09,  1.11it/s]Epoch: 3/10. Loss: 0.9314:  62%|[36m██████▏   [0m| 16/26 [00:16<00:09,  1.11it/s]Epoch: 3/10. Loss: 0.9314:  65%|[36m██████▌   [0m| 17/26 [00:16<00:09,  1.09s/it]Epoch: 3/10. Loss: 0.9559:  65%|[36m██████▌   [0m| 17/26 [00:17<00:09,  1.09s/it]Epoch: 3/10. Loss: 0.9559:  69%|[36m██████▉   [0m| 18/26 [00:17<00:08,  1.05s/it]Epoch: 3/10. Loss: 0.9285:  69%|[36m██████▉   [0m| 18/26 [00:18<00:08,  1.05s/it]Epoch: 3/10. Loss: 0.9285:  73%|[36m███████▎  [0m| 19/26 [00:18<00:06,  1.01it/s]Epoch: 3/10. Loss: 1.0041:  73%|[36m███████▎  [0m| 19/26 [00:19<00:06,  1.01it/s]Epoch: 3/10. Loss: 1.0041:  77%|[36m███████▋  [0m| 20/26 [00:19<00:05,  1.04it/s]Epoch: 3/10. Loss: 0.8997:  77%|[36m███████▋  [0m| 20/26 [00:19<00:05,  1.04it/s]Epoch: 3/10. Loss: 0.8997:  81%|[36m████████  [0m| 21/26 [00:19<00:04,  1.06it/s]Epoch: 3/10. Loss: 0.9649:  81%|[36m████████  [0m| 21/26 [00:20<00:04,  1.06it/s]Epoch: 3/10. Loss: 0.9649:  85%|[36m████████▍ [0m| 22/26 [00:20<00:03,  1.10it/s]Epoch: 3/10. Loss: 0.8152:  85%|[36m████████▍ [0m| 22/26 [00:21<00:03,  1.10it/s]Epoch: 3/10. Loss: 0.8152:  88%|[36m████████▊ [0m| 23/26 [00:21<00:02,  1.08it/s]Epoch: 3/10. Loss: 0.9753:  88%|[36m████████▊ [0m| 23/26 [00:22<00:02,  1.08it/s]Epoch: 3/10. Loss: 0.9753:  92%|[36m█████████▏[0m| 24/26 [00:22<00:01,  1.06it/s]Epoch: 3/10. Loss: 0.9903:  92%|[36m█████████▏[0m| 24/26 [00:23<00:01,  1.06it/s]Epoch: 3/10. Loss: 0.9903:  96%|[36m█████████▌[0m| 25/26 [00:23<00:00,  1.05it/s]Epoch: 3/10. Loss: 1.0271:  96%|[36m█████████▌[0m| 25/26 [00:24<00:00,  1.05it/s]Epoch: 3/10. Loss: 1.0271: 100%|[36m██████████[0m| 26/26 [00:24<00:00,  1.17it/s]Epoch: 3/10. Loss: 1.0271: 100%|[36m██████████[0m| 26/26 [00:24<00:00,  1.07it/s]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:05,  1.20it/s] 29%|[33m██▊       [0m| 2/7 [00:01<00:04,  1.05it/s] 43%|[33m████▎     [0m| 3/7 [00:02<00:03,  1.18it/s] 57%|[33m█████▋    [0m| 4/7 [00:03<00:03,  1.03s/it] 71%|[33m███████▏  [0m| 5/7 [00:04<00:01,  1.23it/s] 86%|[33m████████▌ [0m| 6/7 [00:05<00:00,  1.19it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.54it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.28it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 4/10. Loss: 0.9181:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 4/10. Loss: 0.9181:   4%|[36m▍         [0m| 1/26 [00:00<00:22,  1.11it/s]Epoch: 4/10. Loss: 0.8517:   4%|[36m▍         [0m| 1/26 [00:01<00:22,  1.11it/s]Epoch: 4/10. Loss: 0.8517:   8%|[36m▊         [0m| 2/26 [00:01<00:21,  1.11it/s]Epoch: 4/10. Loss: 0.8817:   8%|[36m▊         [0m| 2/26 [00:02<00:21,  1.11it/s]Epoch: 4/10. Loss: 0.8817:  12%|[36m█▏        [0m| 3/26 [00:02<00:19,  1.15it/s]Epoch: 4/10. Loss: 0.8300:  12%|[36m█▏        [0m| 3/26 [00:03<00:19,  1.15it/s]Epoch: 4/10. Loss: 0.8300:  15%|[36m█▌        [0m| 4/26 [00:03<00:19,  1.15it/s]Epoch: 4/10. Loss: 0.9633:  15%|[36m█▌        [0m| 4/26 [00:04<00:19,  1.15it/s]Epoch: 4/10. Loss: 0.9633:  19%|[36m█▉        [0m| 5/26 [00:04<00:18,  1.15it/s]Epoch: 4/10. Loss: 0.9333:  19%|[36m█▉        [0m| 5/26 [00:05<00:18,  1.15it/s]Epoch: 4/10. Loss: 0.9333:  23%|[36m██▎       [0m| 6/26 [00:05<00:18,  1.08it/s]Epoch: 4/10. Loss: 0.9159:  23%|[36m██▎       [0m| 6/26 [00:06<00:18,  1.08it/s]Epoch: 4/10. Loss: 0.9159:  27%|[36m██▋       [0m| 7/26 [00:06<00:18,  1.05it/s]Epoch: 4/10. Loss: 1.0622:  27%|[36m██▋       [0m| 7/26 [00:07<00:18,  1.05it/s]Epoch: 4/10. Loss: 1.0622:  31%|[36m███       [0m| 8/26 [00:07<00:17,  1.01it/s]Epoch: 4/10. Loss: 0.9220:  31%|[36m███       [0m| 8/26 [00:08<00:17,  1.01it/s]Epoch: 4/10. Loss: 0.9220:  35%|[36m███▍      [0m| 9/26 [00:08<00:17,  1.05s/it]Epoch: 4/10. Loss: 0.9654:  35%|[36m███▍      [0m| 9/26 [00:09<00:17,  1.05s/it]Epoch: 4/10. Loss: 0.9654:  38%|[36m███▊      [0m| 10/26 [00:09<00:16,  1.03s/it]Epoch: 4/10. Loss: 0.9594:  38%|[36m███▊      [0m| 10/26 [00:10<00:16,  1.03s/it]Epoch: 4/10. Loss: 0.9594:  42%|[36m████▏     [0m| 11/26 [00:10<00:15,  1.01s/it]Epoch: 4/10. Loss: 0.9534:  42%|[36m████▏     [0m| 11/26 [00:12<00:15,  1.01s/it]Epoch: 4/10. Loss: 0.9534:  46%|[36m████▌     [0m| 12/26 [00:12<00:19,  1.37s/it]Epoch: 4/10. Loss: 0.9047:  46%|[36m████▌     [0m| 12/26 [00:13<00:19,  1.37s/it]Epoch: 4/10. Loss: 0.9047:  50%|[36m█████     [0m| 13/26 [00:13<00:16,  1.24s/it]Epoch: 4/10. Loss: 0.8618:  50%|[36m█████     [0m| 13/26 [00:15<00:16,  1.24s/it]Epoch: 4/10. Loss: 0.8618:  54%|[36m█████▍    [0m| 14/26 [00:15<00:16,  1.37s/it]Epoch: 4/10. Loss: 0.9135:  54%|[36m█████▍    [0m| 14/26 [00:16<00:16,  1.37s/it]Epoch: 4/10. Loss: 0.9135:  58%|[36m█████▊    [0m| 15/26 [00:16<00:13,  1.21s/it]Epoch: 4/10. Loss: 0.9817:  58%|[36m█████▊    [0m| 15/26 [00:17<00:13,  1.21s/it]Epoch: 4/10. Loss: 0.9817:  62%|[36m██████▏   [0m| 16/26 [00:17<00:11,  1.14s/it]Epoch: 4/10. Loss: 0.9186:  62%|[36m██████▏   [0m| 16/26 [00:17<00:11,  1.14s/it]Epoch: 4/10. Loss: 0.9186:  65%|[36m██████▌   [0m| 17/26 [00:17<00:09,  1.02s/it]Epoch: 4/10. Loss: 0.9242:  65%|[36m██████▌   [0m| 17/26 [00:18<00:09,  1.02s/it]Epoch: 4/10. Loss: 0.9242:  69%|[36m██████▉   [0m| 18/26 [00:18<00:08,  1.01s/it]Epoch: 4/10. Loss: 0.9522:  69%|[36m██████▉   [0m| 18/26 [00:19<00:08,  1.01s/it]Epoch: 4/10. Loss: 0.9522:  73%|[36m███████▎  [0m| 19/26 [00:19<00:07,  1.01s/it]Epoch: 4/10. Loss: 0.9289:  73%|[36m███████▎  [0m| 19/26 [00:20<00:07,  1.01s/it]Epoch: 4/10. Loss: 0.9289:  77%|[36m███████▋  [0m| 20/26 [00:20<00:06,  1.02s/it]Epoch: 4/10. Loss: 0.8894:  77%|[36m███████▋  [0m| 20/26 [00:21<00:06,  1.02s/it]Epoch: 4/10. Loss: 0.8894:  81%|[36m████████  [0m| 21/26 [00:21<00:04,  1.01it/s]Epoch: 4/10. Loss: 0.8144:  81%|[36m████████  [0m| 21/26 [00:22<00:04,  1.01it/s]Epoch: 4/10. Loss: 0.8144:  85%|[36m████████▍ [0m| 22/26 [00:22<00:03,  1.02it/s]Epoch: 4/10. Loss: 0.9245:  85%|[36m████████▍ [0m| 22/26 [00:23<00:03,  1.02it/s]Epoch: 4/10. Loss: 0.9245:  88%|[36m████████▊ [0m| 23/26 [00:23<00:02,  1.08it/s]Epoch: 4/10. Loss: 0.9616:  88%|[36m████████▊ [0m| 23/26 [00:24<00:02,  1.08it/s]Epoch: 4/10. Loss: 0.9616:  92%|[36m█████████▏[0m| 24/26 [00:24<00:01,  1.08it/s]Epoch: 4/10. Loss: 0.8759:  92%|[36m█████████▏[0m| 24/26 [00:25<00:01,  1.08it/s]Epoch: 4/10. Loss: 0.8759:  96%|[36m█████████▌[0m| 25/26 [00:25<00:00,  1.09it/s]Epoch: 4/10. Loss: 0.8151:  96%|[36m█████████▌[0m| 25/26 [00:26<00:00,  1.09it/s]Epoch: 4/10. Loss: 0.8151: 100%|[36m██████████[0m| 26/26 [00:26<00:00,  1.19it/s]Epoch: 4/10. Loss: 0.8151: 100%|[36m██████████[0m| 26/26 [00:26<00:00,  1.01s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:05,  1.18it/s] 29%|[33m██▊       [0m| 2/7 [00:01<00:04,  1.05it/s] 43%|[33m████▎     [0m| 3/7 [00:02<00:03,  1.17it/s] 57%|[33m█████▋    [0m| 4/7 [00:03<00:03,  1.03s/it] 71%|[33m███████▏  [0m| 5/7 [00:04<00:01,  1.15it/s] 86%|[33m████████▌ [0m| 6/7 [00:05<00:00,  1.13it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.47it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.23it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 5/10. Loss: 0.8836:   0%|[36m          [0m| 0/26 [00:01<?, ?it/s]Epoch: 5/10. Loss: 0.8836:   4%|[36m▍         [0m| 1/26 [00:01<00:26,  1.06s/it]Epoch: 5/10. Loss: 0.8805:   4%|[36m▍         [0m| 1/26 [00:02<00:26,  1.06s/it]Epoch: 5/10. Loss: 0.8805:   8%|[36m▊         [0m| 2/26 [00:02<00:29,  1.24s/it]Epoch: 5/10. Loss: 0.8489:   8%|[36m▊         [0m| 2/26 [00:03<00:29,  1.24s/it]Epoch: 5/10. Loss: 0.8489:  12%|[36m█▏        [0m| 3/26 [00:03<00:24,  1.05s/it]Epoch: 5/10. Loss: 0.8305:  12%|[36m█▏        [0m| 3/26 [00:04<00:24,  1.05s/it]Epoch: 5/10. Loss: 0.8305:  15%|[36m█▌        [0m| 4/26 [00:04<00:22,  1.01s/it]Epoch: 5/10. Loss: 0.9177:  15%|[36m█▌        [0m| 4/26 [00:05<00:22,  1.01s/it]Epoch: 5/10. Loss: 0.9177:  19%|[36m█▉        [0m| 5/26 [00:05<00:22,  1.08s/it]Epoch: 5/10. Loss: 0.8273:  19%|[36m█▉        [0m| 5/26 [00:06<00:22,  1.08s/it]Epoch: 5/10. Loss: 0.8273:  23%|[36m██▎       [0m| 6/26 [00:06<00:20,  1.03s/it]Epoch: 5/10. Loss: 1.0037:  23%|[36m██▎       [0m| 6/26 [00:07<00:20,  1.03s/it]Epoch: 5/10. Loss: 1.0037:  27%|[36m██▋       [0m| 7/26 [00:07<00:18,  1.04it/s]Epoch: 5/10. Loss: 0.9757:  27%|[36m██▋       [0m| 7/26 [00:08<00:18,  1.04it/s]Epoch: 5/10. Loss: 0.9757:  31%|[36m███       [0m| 8/26 [00:08<00:17,  1.03it/s]Epoch: 5/10. Loss: 0.9292:  31%|[36m███       [0m| 8/26 [00:09<00:17,  1.03it/s]Epoch: 5/10. Loss: 0.9292:  35%|[36m███▍      [0m| 9/26 [00:09<00:16,  1.05it/s]Epoch: 5/10. Loss: 0.8903:  35%|[36m███▍      [0m| 9/26 [00:10<00:16,  1.05it/s]Epoch: 5/10. Loss: 0.8903:  38%|[36m███▊      [0m| 10/26 [00:10<00:15,  1.05it/s]Epoch: 5/10. Loss: 0.8458:  38%|[36m███▊      [0m| 10/26 [00:10<00:15,  1.05it/s]Epoch: 5/10. Loss: 0.8458:  42%|[36m████▏     [0m| 11/26 [00:10<00:13,  1.13it/s]Epoch: 5/10. Loss: 0.8005:  42%|[36m████▏     [0m| 11/26 [00:11<00:13,  1.13it/s]Epoch: 5/10. Loss: 0.8005:  46%|[36m████▌     [0m| 12/26 [00:11<00:12,  1.10it/s]Epoch: 5/10. Loss: 0.8123:  46%|[36m████▌     [0m| 12/26 [00:12<00:12,  1.10it/s]Epoch: 5/10. Loss: 0.8123:  50%|[36m█████     [0m| 13/26 [00:12<00:11,  1.13it/s]Epoch: 5/10. Loss: 0.7908:  50%|[36m█████     [0m| 13/26 [00:14<00:11,  1.13it/s]Epoch: 5/10. Loss: 0.7908:  54%|[36m█████▍    [0m| 14/26 [00:14<00:13,  1.16s/it]Epoch: 5/10. Loss: 0.8670:  54%|[36m█████▍    [0m| 14/26 [00:15<00:13,  1.16s/it]Epoch: 5/10. Loss: 0.8670:  58%|[36m█████▊    [0m| 15/26 [00:15<00:12,  1.13s/it]Epoch: 5/10. Loss: 0.8532:  58%|[36m█████▊    [0m| 15/26 [00:16<00:12,  1.13s/it]Epoch: 5/10. Loss: 0.8532:  62%|[36m██████▏   [0m| 16/26 [00:16<00:10,  1.01s/it]Epoch: 5/10. Loss: 0.8207:  62%|[36m██████▏   [0m| 16/26 [00:17<00:10,  1.01s/it]Epoch: 5/10. Loss: 0.8207:  65%|[36m██████▌   [0m| 17/26 [00:17<00:09,  1.08s/it]Epoch: 5/10. Loss: 0.8297:  65%|[36m██████▌   [0m| 17/26 [00:18<00:09,  1.08s/it]Epoch: 5/10. Loss: 0.8297:  69%|[36m██████▉   [0m| 18/26 [00:18<00:07,  1.00it/s]Epoch: 5/10. Loss: 0.8685:  69%|[36m██████▉   [0m| 18/26 [00:19<00:07,  1.00it/s]Epoch: 5/10. Loss: 0.8685:  73%|[36m███████▎  [0m| 19/26 [00:19<00:07,  1.08s/it]Epoch: 5/10. Loss: 0.8510:  73%|[36m███████▎  [0m| 19/26 [00:20<00:07,  1.08s/it]Epoch: 5/10. Loss: 0.8510:  77%|[36m███████▋  [0m| 20/26 [00:20<00:06,  1.03s/it]Epoch: 5/10. Loss: 0.7911:  77%|[36m███████▋  [0m| 20/26 [00:22<00:06,  1.03s/it]Epoch: 5/10. Loss: 0.7911:  81%|[36m████████  [0m| 21/26 [00:22<00:07,  1.45s/it]Epoch: 5/10. Loss: 0.9231:  81%|[36m████████  [0m| 21/26 [00:24<00:07,  1.45s/it]Epoch: 5/10. Loss: 0.9231:  85%|[36m████████▍ [0m| 22/26 [00:24<00:05,  1.46s/it]Epoch: 5/10. Loss: 0.8254:  85%|[36m████████▍ [0m| 22/26 [00:25<00:05,  1.46s/it]Epoch: 5/10. Loss: 0.8254:  88%|[36m████████▊ [0m| 23/26 [00:25<00:03,  1.27s/it]Epoch: 5/10. Loss: 0.8457:  88%|[36m████████▊ [0m| 23/26 [00:25<00:03,  1.27s/it]Epoch: 5/10. Loss: 0.8457:  92%|[36m█████████▏[0m| 24/26 [00:25<00:02,  1.12s/it]Epoch: 5/10. Loss: 0.8211:  92%|[36m█████████▏[0m| 24/26 [00:27<00:02,  1.12s/it]Epoch: 5/10. Loss: 0.8211:  96%|[36m█████████▌[0m| 25/26 [00:27<00:01,  1.16s/it]Epoch: 5/10. Loss: 0.9146:  96%|[36m█████████▌[0m| 25/26 [00:27<00:01,  1.16s/it]Epoch: 5/10. Loss: 0.9146: 100%|[36m██████████[0m| 26/26 [00:27<00:00,  1.06s/it]Epoch: 5/10. Loss: 0.9146: 100%|[36m██████████[0m| 26/26 [00:27<00:00,  1.08s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:05,  1.04it/s] 29%|[33m██▊       [0m| 2/7 [00:04<00:11,  2.39s/it] 43%|[33m████▎     [0m| 3/7 [00:05<00:06,  1.73s/it] 57%|[33m█████▋    [0m| 4/7 [00:06<00:05,  1.70s/it] 71%|[33m███████▏  [0m| 5/7 [00:07<00:02,  1.25s/it] 86%|[33m████████▌ [0m| 6/7 [00:08<00:01,  1.15s/it]100%|[33m██████████[0m| 7/7 [00:08<00:00,  1.16it/s]100%|[33m██████████[0m| 7/7 [00:08<00:00,  1.23s/it]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 6/10. Loss: 0.8368:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 6/10. Loss: 0.8368:   4%|[36m▍         [0m| 1/26 [00:00<00:22,  1.09it/s]Epoch: 6/10. Loss: 0.7371:   4%|[36m▍         [0m| 1/26 [00:01<00:22,  1.09it/s]Epoch: 6/10. Loss: 0.7371:   8%|[36m▊         [0m| 2/26 [00:01<00:22,  1.05it/s]Epoch: 6/10. Loss: 0.8467:   8%|[36m▊         [0m| 2/26 [00:02<00:22,  1.05it/s]Epoch: 6/10. Loss: 0.8467:  12%|[36m█▏        [0m| 3/26 [00:02<00:20,  1.11it/s]Epoch: 6/10. Loss: 0.9809:  12%|[36m█▏        [0m| 3/26 [00:03<00:20,  1.11it/s]Epoch: 6/10. Loss: 0.9809:  15%|[36m█▌        [0m| 4/26 [00:03<00:21,  1.03it/s]Epoch: 6/10. Loss: 0.7766:  15%|[36m█▌        [0m| 4/26 [00:04<00:21,  1.03it/s]Epoch: 6/10. Loss: 0.7766:  19%|[36m█▉        [0m| 5/26 [00:04<00:20,  1.05it/s]Epoch: 6/10. Loss: 0.8590:  19%|[36m█▉        [0m| 5/26 [00:05<00:20,  1.05it/s]Epoch: 6/10. Loss: 0.8590:  23%|[36m██▎       [0m| 6/26 [00:05<00:18,  1.06it/s]Epoch: 6/10. Loss: 0.7967:  23%|[36m██▎       [0m| 6/26 [00:06<00:18,  1.06it/s]Epoch: 6/10. Loss: 0.7967:  27%|[36m██▋       [0m| 7/26 [00:06<00:17,  1.10it/s]Epoch: 6/10. Loss: 0.8750:  27%|[36m██▋       [0m| 7/26 [00:07<00:17,  1.10it/s]Epoch: 6/10. Loss: 0.8750:  31%|[36m███       [0m| 8/26 [00:07<00:16,  1.09it/s]Epoch: 6/10. Loss: 0.7946:  31%|[36m███       [0m| 8/26 [00:09<00:16,  1.09it/s]Epoch: 6/10. Loss: 0.7946:  35%|[36m███▍      [0m| 9/26 [00:09<00:20,  1.22s/it]Epoch: 6/10. Loss: 0.9112:  35%|[36m███▍      [0m| 9/26 [00:10<00:20,  1.22s/it]Epoch: 6/10. Loss: 0.9112:  38%|[36m███▊      [0m| 10/26 [00:10<00:20,  1.30s/it]Epoch: 6/10. Loss: 0.8064:  38%|[36m███▊      [0m| 10/26 [00:12<00:20,  1.30s/it]Epoch: 6/10. Loss: 0.8064:  42%|[36m████▏     [0m| 11/26 [00:12<00:19,  1.33s/it]Epoch: 6/10. Loss: 0.8954:  42%|[36m████▏     [0m| 11/26 [00:13<00:19,  1.33s/it]Epoch: 6/10. Loss: 0.8954:  46%|[36m████▌     [0m| 12/26 [00:13<00:17,  1.26s/it]Epoch: 6/10. Loss: 0.8767:  46%|[36m████▌     [0m| 12/26 [00:14<00:17,  1.26s/it]Epoch: 6/10. Loss: 0.8767:  50%|[36m█████     [0m| 13/26 [00:14<00:16,  1.29s/it]Epoch: 6/10. Loss: 0.8028:  50%|[36m█████     [0m| 13/26 [00:15<00:16,  1.29s/it]Epoch: 6/10. Loss: 0.8028:  54%|[36m█████▍    [0m| 14/26 [00:15<00:13,  1.15s/it]Epoch: 6/10. Loss: 0.7202:  54%|[36m█████▍    [0m| 14/26 [00:16<00:13,  1.15s/it]Epoch: 6/10. Loss: 0.7202:  58%|[36m█████▊    [0m| 15/26 [00:16<00:12,  1.10s/it]Epoch: 6/10. Loss: 0.8189:  58%|[36m█████▊    [0m| 15/26 [00:18<00:12,  1.10s/it]Epoch: 6/10. Loss: 0.8189:  62%|[36m██████▏   [0m| 16/26 [00:18<00:15,  1.53s/it]Epoch: 6/10. Loss: 0.9117:  62%|[36m██████▏   [0m| 16/26 [00:19<00:15,  1.53s/it]Epoch: 6/10. Loss: 0.9117:  65%|[36m██████▌   [0m| 17/26 [00:19<00:12,  1.36s/it]Epoch: 6/10. Loss: 1.0006:  65%|[36m██████▌   [0m| 17/26 [00:20<00:12,  1.36s/it]Epoch: 6/10. Loss: 1.0006:  69%|[36m██████▉   [0m| 18/26 [00:20<00:09,  1.21s/it]Epoch: 6/10. Loss: 0.8312:  69%|[36m██████▉   [0m| 18/26 [00:21<00:09,  1.21s/it]Epoch: 6/10. Loss: 0.8312:  73%|[36m███████▎  [0m| 19/26 [00:21<00:08,  1.19s/it]Epoch: 6/10. Loss: 0.8997:  73%|[36m███████▎  [0m| 19/26 [00:22<00:08,  1.19s/it]Epoch: 6/10. Loss: 0.8997:  77%|[36m███████▋  [0m| 20/26 [00:22<00:06,  1.11s/it]Epoch: 6/10. Loss: 0.7328:  77%|[36m███████▋  [0m| 20/26 [00:23<00:06,  1.11s/it]Epoch: 6/10. Loss: 0.7328:  81%|[36m████████  [0m| 21/26 [00:23<00:05,  1.01s/it]Epoch: 6/10. Loss: 0.9225:  81%|[36m████████  [0m| 21/26 [00:24<00:05,  1.01s/it]Epoch: 6/10. Loss: 0.9225:  85%|[36m████████▍ [0m| 22/26 [00:24<00:04,  1.10s/it]Epoch: 6/10. Loss: 0.7811:  85%|[36m████████▍ [0m| 22/26 [00:26<00:04,  1.10s/it]Epoch: 6/10. Loss: 0.7811:  88%|[36m████████▊ [0m| 23/26 [00:26<00:03,  1.21s/it]Epoch: 6/10. Loss: 0.8016:  88%|[36m████████▊ [0m| 23/26 [00:27<00:03,  1.21s/it]Epoch: 6/10. Loss: 0.8016:  92%|[36m█████████▏[0m| 24/26 [00:27<00:02,  1.28s/it]Epoch: 6/10. Loss: 0.9046:  92%|[36m█████████▏[0m| 24/26 [00:28<00:02,  1.28s/it]Epoch: 6/10. Loss: 0.9046:  96%|[36m█████████▌[0m| 25/26 [00:28<00:01,  1.15s/it]Epoch: 6/10. Loss: 0.9231:  96%|[36m█████████▌[0m| 25/26 [00:29<00:01,  1.15s/it]Epoch: 6/10. Loss: 0.9231: 100%|[36m██████████[0m| 26/26 [00:29<00:00,  1.01it/s]Epoch: 6/10. Loss: 0.9231: 100%|[36m██████████[0m| 26/26 [00:29<00:00,  1.13s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:05,  1.16it/s] 29%|[33m██▊       [0m| 2/7 [00:01<00:05,  1.00s/it] 43%|[33m████▎     [0m| 3/7 [00:02<00:03,  1.12it/s] 57%|[33m█████▋    [0m| 4/7 [00:04<00:03,  1.05s/it] 71%|[33m███████▏  [0m| 5/7 [00:04<00:01,  1.19it/s] 86%|[33m████████▌ [0m| 6/7 [00:05<00:00,  1.17it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.55it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.25it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 7/10. Loss: 0.7610:   0%|[36m          [0m| 0/26 [00:02<?, ?it/s]Epoch: 7/10. Loss: 0.7610:   4%|[36m▍         [0m| 1/26 [00:02<00:53,  2.13s/it]Epoch: 7/10. Loss: 0.7638:   4%|[36m▍         [0m| 1/26 [00:03<00:53,  2.13s/it]Epoch: 7/10. Loss: 0.7638:   8%|[36m▊         [0m| 2/26 [00:03<00:34,  1.44s/it]Epoch: 7/10. Loss: 0.8156:   8%|[36m▊         [0m| 2/26 [00:03<00:34,  1.44s/it]Epoch: 7/10. Loss: 0.8156:  12%|[36m█▏        [0m| 3/26 [00:03<00:26,  1.14s/it]Epoch: 7/10. Loss: 0.8354:  12%|[36m█▏        [0m| 3/26 [00:04<00:26,  1.14s/it]Epoch: 7/10. Loss: 0.8354:  15%|[36m█▌        [0m| 4/26 [00:04<00:23,  1.08s/it]Epoch: 7/10. Loss: 0.7601:  15%|[36m█▌        [0m| 4/26 [00:05<00:23,  1.08s/it]Epoch: 7/10. Loss: 0.7601:  19%|[36m█▉        [0m| 5/26 [00:05<00:21,  1.02s/it]Epoch: 7/10. Loss: 0.8211:  19%|[36m█▉        [0m| 5/26 [00:06<00:21,  1.02s/it]Epoch: 7/10. Loss: 0.8211:  23%|[36m██▎       [0m| 6/26 [00:06<00:18,  1.11it/s]Epoch: 7/10. Loss: 0.6877:  23%|[36m██▎       [0m| 6/26 [00:07<00:18,  1.11it/s]Epoch: 7/10. Loss: 0.6877:  27%|[36m██▋       [0m| 7/26 [00:07<00:17,  1.07it/s]Epoch: 7/10. Loss: 0.7444:  27%|[36m██▋       [0m| 7/26 [00:08<00:17,  1.07it/s]Epoch: 7/10. Loss: 0.7444:  31%|[36m███       [0m| 8/26 [00:08<00:17,  1.03it/s]Epoch: 7/10. Loss: 0.7666:  31%|[36m███       [0m| 8/26 [00:09<00:17,  1.03it/s]Epoch: 7/10. Loss: 0.7666:  35%|[36m███▍      [0m| 9/26 [00:09<00:16,  1.04it/s]Epoch: 7/10. Loss: 0.7654:  35%|[36m███▍      [0m| 9/26 [00:10<00:16,  1.04it/s]Epoch: 7/10. Loss: 0.7654:  38%|[36m███▊      [0m| 10/26 [00:10<00:14,  1.11it/s]Epoch: 7/10. Loss: 0.6517:  38%|[36m███▊      [0m| 10/26 [00:10<00:14,  1.11it/s]Epoch: 7/10. Loss: 0.6517:  42%|[36m████▏     [0m| 11/26 [00:11<00:13,  1.15it/s]Epoch: 7/10. Loss: 0.8469:  42%|[36m████▏     [0m| 11/26 [00:11<00:13,  1.15it/s]Epoch: 7/10. Loss: 0.8469:  46%|[36m████▌     [0m| 12/26 [00:12<00:12,  1.10it/s]Epoch: 7/10. Loss: 0.7982:  46%|[36m████▌     [0m| 12/26 [00:13<00:12,  1.10it/s]Epoch: 7/10. Loss: 0.7982:  50%|[36m█████     [0m| 13/26 [00:13<00:12,  1.03it/s]Epoch: 7/10. Loss: 0.8452:  50%|[36m█████     [0m| 13/26 [00:13<00:12,  1.03it/s]Epoch: 7/10. Loss: 0.8452:  54%|[36m█████▍    [0m| 14/26 [00:13<00:11,  1.06it/s]Epoch: 7/10. Loss: 0.7178:  54%|[36m█████▍    [0m| 14/26 [00:14<00:11,  1.06it/s]Epoch: 7/10. Loss: 0.7178:  58%|[36m█████▊    [0m| 15/26 [00:14<00:10,  1.05it/s]Epoch: 7/10. Loss: 0.7734:  58%|[36m█████▊    [0m| 15/26 [00:15<00:10,  1.05it/s]Epoch: 7/10. Loss: 0.7734:  62%|[36m██████▏   [0m| 16/26 [00:15<00:09,  1.06it/s]Epoch: 7/10. Loss: 0.7092:  62%|[36m██████▏   [0m| 16/26 [00:17<00:09,  1.06it/s]Epoch: 7/10. Loss: 0.7092:  65%|[36m██████▌   [0m| 17/26 [00:17<00:11,  1.28s/it]Epoch: 7/10. Loss: 0.6352:  65%|[36m██████▌   [0m| 17/26 [00:18<00:11,  1.28s/it]Epoch: 7/10. Loss: 0.6352:  69%|[36m██████▉   [0m| 18/26 [00:18<00:09,  1.13s/it]Epoch: 7/10. Loss: 0.7501:  69%|[36m██████▉   [0m| 18/26 [00:20<00:09,  1.13s/it]Epoch: 7/10. Loss: 0.7501:  73%|[36m███████▎  [0m| 19/26 [00:20<00:08,  1.20s/it]Epoch: 7/10. Loss: 0.8077:  73%|[36m███████▎  [0m| 19/26 [00:20<00:08,  1.20s/it]Epoch: 7/10. Loss: 0.8077:  77%|[36m███████▋  [0m| 20/26 [00:20<00:06,  1.08s/it]Epoch: 7/10. Loss: 0.7113:  77%|[36m███████▋  [0m| 20/26 [00:21<00:06,  1.08s/it]Epoch: 7/10. Loss: 0.7113:  81%|[36m████████  [0m| 21/26 [00:21<00:05,  1.01s/it]Epoch: 7/10. Loss: 0.8072:  81%|[36m████████  [0m| 21/26 [00:22<00:05,  1.01s/it]Epoch: 7/10. Loss: 0.8072:  85%|[36m████████▍ [0m| 22/26 [00:22<00:03,  1.01it/s]Epoch: 7/10. Loss: 0.7425:  85%|[36m████████▍ [0m| 22/26 [00:23<00:03,  1.01it/s]Epoch: 7/10. Loss: 0.7425:  88%|[36m████████▊ [0m| 23/26 [00:23<00:03,  1.05s/it]Epoch: 7/10. Loss: 0.7993:  88%|[36m████████▊ [0m| 23/26 [00:24<00:03,  1.05s/it]Epoch: 7/10. Loss: 0.7993:  92%|[36m█████████▏[0m| 24/26 [00:24<00:02,  1.05s/it]Epoch: 7/10. Loss: 0.8590:  92%|[36m█████████▏[0m| 24/26 [00:28<00:02,  1.05s/it]Epoch: 7/10. Loss: 0.8590:  96%|[36m█████████▌[0m| 25/26 [00:28<00:01,  1.95s/it]Epoch: 7/10. Loss: 0.8702:  96%|[36m█████████▌[0m| 25/26 [00:30<00:01,  1.95s/it]Epoch: 7/10. Loss: 0.8702: 100%|[36m██████████[0m| 26/26 [00:30<00:00,  1.75s/it]Epoch: 7/10. Loss: 0.8702: 100%|[36m██████████[0m| 26/26 [00:30<00:00,  1.16s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:05,  1.13it/s] 29%|[33m██▊       [0m| 2/7 [00:01<00:05,  1.02s/it] 43%|[33m████▎     [0m| 3/7 [00:02<00:03,  1.10it/s] 57%|[33m█████▋    [0m| 4/7 [00:04<00:03,  1.07s/it] 71%|[33m███████▏  [0m| 5/7 [00:04<00:01,  1.16it/s] 86%|[33m████████▌ [0m| 6/7 [00:05<00:00,  1.13it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.48it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.21it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 8/10. Loss: 0.7549:   0%|[36m          [0m| 0/26 [00:01<?, ?it/s]Epoch: 8/10. Loss: 0.7549:   4%|[36m▍         [0m| 1/26 [00:01<00:34,  1.37s/it]Epoch: 8/10. Loss: 0.7993:   4%|[36m▍         [0m| 1/26 [00:02<00:34,  1.37s/it]Epoch: 8/10. Loss: 0.7993:   8%|[36m▊         [0m| 2/26 [00:02<00:27,  1.13s/it]Epoch: 8/10. Loss: 0.7112:   8%|[36m▊         [0m| 2/26 [00:03<00:27,  1.13s/it]Epoch: 8/10. Loss: 0.7112:  12%|[36m█▏        [0m| 3/26 [00:03<00:23,  1.03s/it]Epoch: 8/10. Loss: 0.8143:  12%|[36m█▏        [0m| 3/26 [00:04<00:23,  1.03s/it]Epoch: 8/10. Loss: 0.8143:  15%|[36m█▌        [0m| 4/26 [00:04<00:21,  1.02it/s]Epoch: 8/10. Loss: 0.7316:  15%|[36m█▌        [0m| 4/26 [00:04<00:21,  1.02it/s]Epoch: 8/10. Loss: 0.7316:  19%|[36m█▉        [0m| 5/26 [00:04<00:19,  1.10it/s]Epoch: 8/10. Loss: 0.8162:  19%|[36m█▉        [0m| 5/26 [00:05<00:19,  1.10it/s]Epoch: 8/10. Loss: 0.8162:  23%|[36m██▎       [0m| 6/26 [00:05<00:17,  1.11it/s]Epoch: 8/10. Loss: 0.7594:  23%|[36m██▎       [0m| 6/26 [00:06<00:17,  1.11it/s]Epoch: 8/10. Loss: 0.7594:  27%|[36m██▋       [0m| 7/26 [00:06<00:16,  1.16it/s]Epoch: 8/10. Loss: 0.7311:  27%|[36m██▋       [0m| 7/26 [00:07<00:16,  1.16it/s]Epoch: 8/10. Loss: 0.7311:  31%|[36m███       [0m| 8/26 [00:07<00:17,  1.04it/s]Epoch: 8/10. Loss: 0.7764:  31%|[36m███       [0m| 8/26 [00:08<00:17,  1.04it/s]Epoch: 8/10. Loss: 0.7764:  35%|[36m███▍      [0m| 9/26 [00:08<00:16,  1.03it/s]Epoch: 8/10. Loss: 0.6917:  35%|[36m███▍      [0m| 9/26 [00:09<00:16,  1.03it/s]Epoch: 8/10. Loss: 0.6917:  38%|[36m███▊      [0m| 10/26 [00:09<00:15,  1.04it/s]Epoch: 8/10. Loss: 0.7694:  38%|[36m███▊      [0m| 10/26 [00:10<00:15,  1.04it/s]Epoch: 8/10. Loss: 0.7694:  42%|[36m████▏     [0m| 11/26 [00:10<00:13,  1.10it/s]Epoch: 8/10. Loss: 0.8529:  42%|[36m████▏     [0m| 11/26 [00:11<00:13,  1.10it/s]Epoch: 8/10. Loss: 0.8529:  46%|[36m████▌     [0m| 12/26 [00:11<00:13,  1.03it/s]Epoch: 8/10. Loss: 0.7300:  46%|[36m████▌     [0m| 12/26 [00:12<00:13,  1.03it/s]Epoch: 8/10. Loss: 0.7300:  50%|[36m█████     [0m| 13/26 [00:12<00:12,  1.04it/s]Epoch: 8/10. Loss: 0.7120:  50%|[36m█████     [0m| 13/26 [00:13<00:12,  1.04it/s]Epoch: 8/10. Loss: 0.7120:  54%|[36m█████▍    [0m| 14/26 [00:13<00:11,  1.06it/s]Epoch: 8/10. Loss: 0.7976:  54%|[36m█████▍    [0m| 14/26 [00:14<00:11,  1.06it/s]Epoch: 8/10. Loss: 0.7976:  58%|[36m█████▊    [0m| 15/26 [00:14<00:09,  1.11it/s]Epoch: 8/10. Loss: 0.7323:  58%|[36m█████▊    [0m| 15/26 [00:15<00:09,  1.11it/s]Epoch: 8/10. Loss: 0.7323:  62%|[36m██████▏   [0m| 16/26 [00:15<00:08,  1.13it/s]Epoch: 8/10. Loss: 0.7946:  62%|[36m██████▏   [0m| 16/26 [00:15<00:08,  1.13it/s]Epoch: 8/10. Loss: 0.7946:  65%|[36m██████▌   [0m| 17/26 [00:15<00:07,  1.14it/s]Epoch: 8/10. Loss: 0.7282:  65%|[36m██████▌   [0m| 17/26 [00:16<00:07,  1.14it/s]Epoch: 8/10. Loss: 0.7282:  69%|[36m██████▉   [0m| 18/26 [00:16<00:06,  1.15it/s]Epoch: 8/10. Loss: 0.6980:  69%|[36m██████▉   [0m| 18/26 [00:17<00:06,  1.15it/s]Epoch: 8/10. Loss: 0.6980:  73%|[36m███████▎  [0m| 19/26 [00:17<00:06,  1.05it/s]Epoch: 8/10. Loss: 0.6878:  73%|[36m███████▎  [0m| 19/26 [00:19<00:06,  1.05it/s]Epoch: 8/10. Loss: 0.6878:  77%|[36m███████▋  [0m| 20/26 [00:19<00:06,  1.00s/it]Epoch: 8/10. Loss: 0.8762:  77%|[36m███████▋  [0m| 20/26 [00:19<00:06,  1.00s/it]Epoch: 8/10. Loss: 0.8762:  81%|[36m████████  [0m| 21/26 [00:19<00:04,  1.03it/s]Epoch: 8/10. Loss: 0.7656:  81%|[36m████████  [0m| 21/26 [00:20<00:04,  1.03it/s]Epoch: 8/10. Loss: 0.7656:  85%|[36m████████▍ [0m| 22/26 [00:20<00:03,  1.05it/s]Epoch: 8/10. Loss: 0.7939:  85%|[36m████████▍ [0m| 22/26 [00:21<00:03,  1.05it/s]Epoch: 8/10. Loss: 0.7939:  88%|[36m████████▊ [0m| 23/26 [00:21<00:02,  1.13it/s]Epoch: 8/10. Loss: 0.7332:  88%|[36m████████▊ [0m| 23/26 [00:22<00:02,  1.13it/s]Epoch: 8/10. Loss: 0.7332:  92%|[36m█████████▏[0m| 24/26 [00:22<00:01,  1.09it/s]Epoch: 8/10. Loss: 0.6396:  92%|[36m█████████▏[0m| 24/26 [00:23<00:01,  1.09it/s]Epoch: 8/10. Loss: 0.6396:  96%|[36m█████████▌[0m| 25/26 [00:23<00:00,  1.07it/s]Epoch: 8/10. Loss: 0.6868:  96%|[36m█████████▌[0m| 25/26 [00:24<00:00,  1.07it/s]Epoch: 8/10. Loss: 0.6868: 100%|[36m██████████[0m| 26/26 [00:24<00:00,  1.17it/s]Epoch: 8/10. Loss: 0.6868: 100%|[36m██████████[0m| 26/26 [00:24<00:00,  1.07it/s]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:04,  1.31it/s] 29%|[33m██▊       [0m| 2/7 [00:01<00:04,  1.13it/s] 43%|[33m████▎     [0m| 3/7 [00:02<00:03,  1.27it/s] 57%|[33m█████▋    [0m| 4/7 [00:03<00:02,  1.00it/s] 71%|[33m███████▏  [0m| 5/7 [00:04<00:01,  1.25it/s] 86%|[33m████████▌ [0m| 6/7 [00:05<00:00,  1.20it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.57it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.32it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 9/10. Loss: 0.7093:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 9/10. Loss: 0.7093:   4%|[36m▍         [0m| 1/26 [00:00<00:23,  1.05it/s]Epoch: 9/10. Loss: 0.6988:   4%|[36m▍         [0m| 1/26 [00:01<00:23,  1.05it/s]Epoch: 9/10. Loss: 0.6988:   8%|[36m▊         [0m| 2/26 [00:01<00:21,  1.09it/s]Epoch: 9/10. Loss: 0.7422:   8%|[36m▊         [0m| 2/26 [00:02<00:21,  1.09it/s]Epoch: 9/10. Loss: 0.7422:  12%|[36m█▏        [0m| 3/26 [00:02<00:20,  1.12it/s]Epoch: 9/10. Loss: 0.6872:  12%|[36m█▏        [0m| 3/26 [00:03<00:20,  1.12it/s]Epoch: 9/10. Loss: 0.6872:  15%|[36m█▌        [0m| 4/26 [00:03<00:21,  1.00it/s]Epoch: 9/10. Loss: 0.7074:  15%|[36m█▌        [0m| 4/26 [00:04<00:21,  1.00it/s]Epoch: 9/10. Loss: 0.7074:  19%|[36m█▉        [0m| 5/26 [00:04<00:19,  1.06it/s]Epoch: 9/10. Loss: 0.7957:  19%|[36m█▉        [0m| 5/26 [00:05<00:19,  1.06it/s]Epoch: 9/10. Loss: 0.7957:  23%|[36m██▎       [0m| 6/26 [00:05<00:18,  1.08it/s]Epoch: 9/10. Loss: 0.6012:  23%|[36m██▎       [0m| 6/26 [00:06<00:18,  1.08it/s]Epoch: 9/10. Loss: 0.6012:  27%|[36m██▋       [0m| 7/26 [00:06<00:16,  1.15it/s]Epoch: 9/10. Loss: 0.7146:  27%|[36m██▋       [0m| 7/26 [00:07<00:16,  1.15it/s]Epoch: 9/10. Loss: 0.7146:  31%|[36m███       [0m| 8/26 [00:07<00:15,  1.17it/s]Epoch: 9/10. Loss: 0.7754:  31%|[36m███       [0m| 8/26 [00:08<00:15,  1.17it/s]Epoch: 9/10. Loss: 0.7754:  35%|[36m███▍      [0m| 9/26 [00:08<00:14,  1.14it/s]Epoch: 9/10. Loss: 0.7233:  35%|[36m███▍      [0m| 9/26 [00:09<00:14,  1.14it/s]Epoch: 9/10. Loss: 0.7233:  38%|[36m███▊      [0m| 10/26 [00:09<00:14,  1.10it/s]Epoch: 9/10. Loss: 0.6434:  38%|[36m███▊      [0m| 10/26 [00:09<00:14,  1.10it/s]Epoch: 9/10. Loss: 0.6434:  42%|[36m████▏     [0m| 11/26 [00:09<00:13,  1.12it/s]Epoch: 9/10. Loss: 0.7417:  42%|[36m████▏     [0m| 11/26 [00:10<00:13,  1.12it/s]Epoch: 9/10. Loss: 0.7417:  46%|[36m████▌     [0m| 12/26 [00:10<00:12,  1.09it/s]Epoch: 9/10. Loss: 0.7446:  46%|[36m████▌     [0m| 12/26 [00:11<00:12,  1.09it/s]Epoch: 9/10. Loss: 0.7446:  50%|[36m█████     [0m| 13/26 [00:11<00:12,  1.05it/s]Epoch: 9/10. Loss: 0.7242:  50%|[36m█████     [0m| 13/26 [00:12<00:12,  1.05it/s]Epoch: 9/10. Loss: 0.7242:  54%|[36m█████▍    [0m| 14/26 [00:12<00:11,  1.05it/s]Epoch: 9/10. Loss: 0.7317:  54%|[36m█████▍    [0m| 14/26 [00:13<00:11,  1.05it/s]Epoch: 9/10. Loss: 0.7317:  58%|[36m█████▊    [0m| 15/26 [00:13<00:10,  1.04it/s]Epoch: 9/10. Loss: 0.6611:  58%|[36m█████▊    [0m| 15/26 [00:14<00:10,  1.04it/s]Epoch: 9/10. Loss: 0.6611:  62%|[36m██████▏   [0m| 16/26 [00:14<00:09,  1.03it/s]Epoch: 9/10. Loss: 0.7233:  62%|[36m██████▏   [0m| 16/26 [00:15<00:09,  1.03it/s]Epoch: 9/10. Loss: 0.7233:  65%|[36m██████▌   [0m| 17/26 [00:15<00:08,  1.02it/s]Epoch: 9/10. Loss: 0.6623:  65%|[36m██████▌   [0m| 17/26 [00:16<00:08,  1.02it/s]Epoch: 9/10. Loss: 0.6623:  69%|[36m██████▉   [0m| 18/26 [00:16<00:07,  1.02it/s]Epoch: 9/10. Loss: 0.7363:  69%|[36m██████▉   [0m| 18/26 [00:17<00:07,  1.02it/s]Epoch: 9/10. Loss: 0.7363:  73%|[36m███████▎  [0m| 19/26 [00:17<00:07,  1.00s/it]Epoch: 9/10. Loss: 0.7198:  73%|[36m███████▎  [0m| 19/26 [00:18<00:07,  1.00s/it]Epoch: 9/10. Loss: 0.7198:  77%|[36m███████▋  [0m| 20/26 [00:18<00:05,  1.04it/s]Epoch: 9/10. Loss: 0.6862:  77%|[36m███████▋  [0m| 20/26 [00:22<00:05,  1.04it/s]Epoch: 9/10. Loss: 0.6862:  81%|[36m████████  [0m| 21/26 [00:22<00:08,  1.78s/it]Epoch: 9/10. Loss: 0.7074:  81%|[36m████████  [0m| 21/26 [00:25<00:08,  1.78s/it]Epoch: 9/10. Loss: 0.7074:  85%|[36m████████▍ [0m| 22/26 [00:25<00:09,  2.28s/it]Epoch: 9/10. Loss: 0.6486:  85%|[36m████████▍ [0m| 22/26 [00:26<00:09,  2.28s/it]Epoch: 9/10. Loss: 0.6486:  88%|[36m████████▊ [0m| 23/26 [00:26<00:05,  1.86s/it]Epoch: 9/10. Loss: 0.7163:  88%|[36m████████▊ [0m| 23/26 [00:27<00:05,  1.86s/it]Epoch: 9/10. Loss: 0.7163:  92%|[36m█████████▏[0m| 24/26 [00:27<00:03,  1.62s/it]Epoch: 9/10. Loss: 0.8839:  92%|[36m█████████▏[0m| 24/26 [00:30<00:03,  1.62s/it]Epoch: 9/10. Loss: 0.8839:  96%|[36m█████████▌[0m| 25/26 [00:30<00:02,  2.07s/it]Epoch: 9/10. Loss: 0.6719:  96%|[36m█████████▌[0m| 25/26 [00:31<00:02,  2.07s/it]Epoch: 9/10. Loss: 0.6719: 100%|[36m██████████[0m| 26/26 [00:31<00:00,  1.71s/it]Epoch: 9/10. Loss: 0.6719: 100%|[36m██████████[0m| 26/26 [00:31<00:00,  1.22s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:04,  1.25it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:05,  1.06s/it] 43%|[33m████▎     [0m| 3/7 [00:02<00:03,  1.11it/s] 57%|[33m█████▋    [0m| 4/7 [00:04<00:03,  1.16s/it] 71%|[33m███████▏  [0m| 5/7 [00:04<00:01,  1.09it/s] 86%|[33m████████▌ [0m| 6/7 [00:05<00:00,  1.07it/s]100%|[33m██████████[0m| 7/7 [00:06<00:00,  1.41it/s]100%|[33m██████████[0m| 7/7 [00:06<00:00,  1.17it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 0/10. Loss: 1.0962:   0%|[36m          [0m| 0/26 [00:02<?, ?it/s]Epoch: 0/10. Loss: 1.0962:   4%|[36m▍         [0m| 1/26 [00:02<00:51,  2.08s/it]Epoch: 0/10. Loss: 6121204.5000:   4%|[36m▍         [0m| 1/26 [00:04<00:51,  2.08s/it]Epoch: 0/10. Loss: 6121204.5000:   8%|[36m▊         [0m| 2/26 [00:04<00:47,  2.00s/it]Epoch: 0/10. Loss: 74.0849:   8%|[36m▊         [0m| 2/26 [00:04<00:47,  2.00s/it]     Epoch: 0/10. Loss: 74.0849:  12%|[36m█▏        [0m| 3/26 [00:04<00:34,  1.49s/it]Epoch: 0/10. Loss: 10851.3672:  12%|[36m█▏        [0m| 3/26 [00:05<00:34,  1.49s/it]Epoch: 0/10. Loss: 10851.3672:  15%|[36m█▌        [0m| 4/26 [00:05<00:28,  1.31s/it]Epoch: 0/10. Loss: 731.7651:  15%|[36m█▌        [0m| 4/26 [00:06<00:28,  1.31s/it]  Epoch: 0/10. Loss: 731.7651:  19%|[36m█▉        [0m| 5/26 [00:06<00:25,  1.19s/it]Epoch: 0/10. Loss: 9761.4395:  19%|[36m█▉        [0m| 5/26 [00:07<00:25,  1.19s/it]Epoch: 0/10. Loss: 9761.4395:  23%|[36m██▎       [0m| 6/26 [00:07<00:22,  1.11s/it]Epoch: 0/10. Loss: 66.4751:  23%|[36m██▎       [0m| 6/26 [00:08<00:22,  1.11s/it]  Epoch: 0/10. Loss: 66.4751:  27%|[36m██▋       [0m| 7/26 [00:08<00:19,  1.01s/it]Epoch: 0/10. Loss: 50.6673:  27%|[36m██▋       [0m| 7/26 [00:09<00:19,  1.01s/it]Epoch: 0/10. Loss: 50.6673:  31%|[36m███       [0m| 8/26 [00:09<00:17,  1.02it/s]Epoch: 0/10. Loss: 95.4379:  31%|[36m███       [0m| 8/26 [00:12<00:17,  1.02it/s]Epoch: 0/10. Loss: 95.4379:  35%|[36m███▍      [0m| 9/26 [00:12<00:24,  1.45s/it]Epoch: 0/10. Loss: 2066.3298:  35%|[36m███▍      [0m| 9/26 [00:12<00:24,  1.45s/it]Epoch: 0/10. Loss: 2066.3298:  38%|[36m███▊      [0m| 10/26 [00:12<00:20,  1.27s/it]Epoch: 0/10. Loss: 1143.9945:  38%|[36m███▊      [0m| 10/26 [00:14<00:20,  1.27s/it]Epoch: 0/10. Loss: 1143.9945:  42%|[36m████▏     [0m| 11/26 [00:14<00:18,  1.26s/it]Epoch: 0/10. Loss: 163.2183:  42%|[36m████▏     [0m| 11/26 [00:16<00:18,  1.26s/it] Epoch: 0/10. Loss: 163.2183:  46%|[36m████▌     [0m| 12/26 [00:16<00:23,  1.67s/it]Epoch: 0/10. Loss: 158.4253:  46%|[36m████▌     [0m| 12/26 [00:18<00:23,  1.67s/it]Epoch: 0/10. Loss: 158.4253:  50%|[36m█████     [0m| 13/26 [00:18<00:21,  1.69s/it]Epoch: 0/10. Loss: 49.0669:  50%|[36m█████     [0m| 13/26 [00:19<00:21,  1.69s/it] Epoch: 0/10. Loss: 49.0669:  54%|[36m█████▍    [0m| 14/26 [00:19<00:17,  1.45s/it]Epoch: 0/10. Loss: 8.4783:  54%|[36m█████▍    [0m| 14/26 [00:20<00:17,  1.45s/it] Epoch: 0/10. Loss: 8.4783:  58%|[36m█████▊    [0m| 15/26 [00:20<00:14,  1.28s/it]Epoch: 0/10. Loss: 2.6299:  58%|[36m█████▊    [0m| 15/26 [00:23<00:14,  1.28s/it]Epoch: 0/10. Loss: 2.6299:  62%|[36m██████▏   [0m| 16/26 [00:23<00:17,  1.73s/it]Epoch: 0/10. Loss: 1.9057:  62%|[36m██████▏   [0m| 16/26 [00:24<00:17,  1.73s/it]Epoch: 0/10. Loss: 1.9057:  65%|[36m██████▌   [0m| 17/26 [00:24<00:16,  1.79s/it]Epoch: 0/10. Loss: 4.6697:  65%|[36m██████▌   [0m| 17/26 [00:25<00:16,  1.79s/it]Epoch: 0/10. Loss: 4.6697:  69%|[36m██████▉   [0m| 18/26 [00:25<00:12,  1.53s/it]Epoch: 0/10. Loss: 1.1989:  69%|[36m██████▉   [0m| 18/26 [00:26<00:12,  1.53s/it]Epoch: 0/10. Loss: 1.1989:  73%|[36m███████▎  [0m| 19/26 [00:26<00:09,  1.37s/it]Epoch: 0/10. Loss: 1.0659:  73%|[36m███████▎  [0m| 19/26 [00:27<00:09,  1.37s/it]Epoch: 0/10. Loss: 1.0659:  77%|[36m███████▋  [0m| 20/26 [00:27<00:07,  1.22s/it]Epoch: 0/10. Loss: 1.1880:  77%|[36m███████▋  [0m| 20/26 [00:29<00:07,  1.22s/it]Epoch: 0/10. Loss: 1.1880:  81%|[36m████████  [0m| 21/26 [00:29<00:06,  1.27s/it]Epoch: 0/10. Loss: 1.1024:  81%|[36m████████  [0m| 21/26 [00:29<00:06,  1.27s/it]Epoch: 0/10. Loss: 1.1024:  85%|[36m████████▍ [0m| 22/26 [00:29<00:04,  1.13s/it]Epoch: 0/10. Loss: 1.0793:  85%|[36m████████▍ [0m| 22/26 [00:31<00:04,  1.13s/it]Epoch: 0/10. Loss: 1.0793:  88%|[36m████████▊ [0m| 23/26 [00:31<00:03,  1.12s/it]Epoch: 0/10. Loss: 1.0522:  88%|[36m████████▊ [0m| 23/26 [00:32<00:03,  1.12s/it]Epoch: 0/10. Loss: 1.0522:  92%|[36m█████████▏[0m| 24/26 [00:32<00:02,  1.30s/it]Epoch: 0/10. Loss: 1.1056:  92%|[36m█████████▏[0m| 24/26 [00:34<00:02,  1.30s/it]Epoch: 0/10. Loss: 1.1056:  96%|[36m█████████▌[0m| 25/26 [00:34<00:01,  1.47s/it]Epoch: 0/10. Loss: 1.0627:  96%|[36m█████████▌[0m| 25/26 [00:35<00:01,  1.47s/it]Epoch: 0/10. Loss: 1.0627: 100%|[36m██████████[0m| 26/26 [00:35<00:00,  1.19s/it]Epoch: 0/10. Loss: 1.0627: 100%|[36m██████████[0m| 26/26 [00:35<00:00,  1.35s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:02<00:12,  2.00s/it] 29%|[33m██▊       [0m| 2/7 [00:07<00:20,  4.11s/it] 43%|[33m████▎     [0m| 3/7 [00:08<00:11,  2.86s/it] 57%|[33m█████▋    [0m| 4/7 [00:12<00:09,  3.04s/it] 71%|[33m███████▏  [0m| 5/7 [00:14<00:05,  2.71s/it] 86%|[33m████████▌ [0m| 6/7 [00:15<00:02,  2.22s/it]100%|[33m██████████[0m| 7/7 [00:16<00:00,  1.62s/it]100%|[33m██████████[0m| 7/7 [00:16<00:00,  2.30s/it]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 1/10. Loss: 1.0479:   0%|[36m          [0m| 0/26 [00:03<?, ?it/s]Epoch: 1/10. Loss: 1.0479:   4%|[36m▍         [0m| 1/26 [00:03<01:21,  3.27s/it]Epoch: 1/10. Loss: 1.0091:   4%|[36m▍         [0m| 1/26 [00:04<01:21,  3.27s/it]Epoch: 1/10. Loss: 1.0091:   8%|[36m▊         [0m| 2/26 [00:04<00:54,  2.29s/it]Epoch: 1/10. Loss: 1.0610:   8%|[36m▊         [0m| 2/26 [00:05<00:54,  2.29s/it]Epoch: 1/10. Loss: 1.0610:  12%|[36m█▏        [0m| 3/26 [00:05<00:38,  1.68s/it]Epoch: 1/10. Loss: 1.0061:  12%|[36m█▏        [0m| 3/26 [00:08<00:38,  1.68s/it]Epoch: 1/10. Loss: 1.0061:  15%|[36m█▌        [0m| 4/26 [00:08<00:42,  1.94s/it]Epoch: 1/10. Loss: 1.0257:  15%|[36m█▌        [0m| 4/26 [00:09<00:42,  1.94s/it]Epoch: 1/10. Loss: 1.0257:  19%|[36m█▉        [0m| 5/26 [00:09<00:33,  1.60s/it]Epoch: 1/10. Loss: 1.0452:  19%|[36m█▉        [0m| 5/26 [00:10<00:33,  1.60s/it]Epoch: 1/10. Loss: 1.0452:  23%|[36m██▎       [0m| 6/26 [00:10<00:30,  1.51s/it]Epoch: 1/10. Loss: 1.0630:  23%|[36m██▎       [0m| 6/26 [00:11<00:30,  1.51s/it]Epoch: 1/10. Loss: 1.0630:  27%|[36m██▋       [0m| 7/26 [00:11<00:25,  1.36s/it]Epoch: 1/10. Loss: 1.0265:  27%|[36m██▋       [0m| 7/26 [00:12<00:25,  1.36s/it]Epoch: 1/10. Loss: 1.0265:  31%|[36m███       [0m| 8/26 [00:12<00:22,  1.24s/it]Epoch: 1/10. Loss: 1.0066:  31%|[36m███       [0m| 8/26 [00:15<00:22,  1.24s/it]Epoch: 1/10. Loss: 1.0066:  35%|[36m███▍      [0m| 9/26 [00:15<00:30,  1.79s/it]Epoch: 1/10. Loss: 1.0658:  35%|[36m███▍      [0m| 9/26 [00:16<00:30,  1.79s/it]Epoch: 1/10. Loss: 1.0658:  38%|[36m███▊      [0m| 10/26 [00:16<00:25,  1.57s/it]Epoch: 1/10. Loss: 1.0279:  38%|[36m███▊      [0m| 10/26 [00:18<00:25,  1.57s/it]Epoch: 1/10. Loss: 1.0279:  42%|[36m████▏     [0m| 11/26 [00:18<00:22,  1.53s/it]Epoch: 1/10. Loss: 0.9892:  42%|[36m████▏     [0m| 11/26 [00:19<00:22,  1.53s/it]Epoch: 1/10. Loss: 0.9892:  46%|[36m████▌     [0m| 12/26 [00:19<00:19,  1.38s/it]Epoch: 1/10. Loss: 1.0371:  46%|[36m████▌     [0m| 12/26 [00:20<00:19,  1.38s/it]Epoch: 1/10. Loss: 1.0371:  50%|[36m█████     [0m| 13/26 [00:20<00:17,  1.33s/it]Epoch: 1/10. Loss: 1.0405:  50%|[36m█████     [0m| 13/26 [00:21<00:17,  1.33s/it]Epoch: 1/10. Loss: 1.0405:  54%|[36m█████▍    [0m| 14/26 [00:21<00:15,  1.26s/it]Epoch: 1/10. Loss: 0.9867:  54%|[36m█████▍    [0m| 14/26 [00:22<00:15,  1.26s/it]Epoch: 1/10. Loss: 0.9867:  58%|[36m█████▊    [0m| 15/26 [00:22<00:12,  1.17s/it]Epoch: 1/10. Loss: 1.0501:  58%|[36m█████▊    [0m| 15/26 [00:24<00:12,  1.17s/it]Epoch: 1/10. Loss: 1.0501:  62%|[36m██████▏   [0m| 16/26 [00:24<00:14,  1.48s/it]Epoch: 1/10. Loss: 0.9459:  62%|[36m██████▏   [0m| 16/26 [00:25<00:14,  1.48s/it]Epoch: 1/10. Loss: 0.9459:  65%|[36m██████▌   [0m| 17/26 [00:25<00:12,  1.35s/it]Epoch: 1/10. Loss: 1.0253:  65%|[36m██████▌   [0m| 17/26 [00:26<00:12,  1.35s/it]Epoch: 1/10. Loss: 1.0253:  69%|[36m██████▉   [0m| 18/26 [00:26<00:09,  1.18s/it]Epoch: 1/10. Loss: 1.0694:  69%|[36m██████▉   [0m| 18/26 [00:27<00:09,  1.18s/it]Epoch: 1/10. Loss: 1.0694:  73%|[36m███████▎  [0m| 19/26 [00:27<00:07,  1.06s/it]Epoch: 1/10. Loss: 1.0143:  73%|[36m███████▎  [0m| 19/26 [00:28<00:07,  1.06s/it]Epoch: 1/10. Loss: 1.0143:  77%|[36m███████▋  [0m| 20/26 [00:28<00:06,  1.05s/it]Epoch: 1/10. Loss: 0.9509:  77%|[36m███████▋  [0m| 20/26 [00:29<00:06,  1.05s/it]Epoch: 1/10. Loss: 0.9509:  81%|[36m████████  [0m| 21/26 [00:29<00:05,  1.14s/it]Epoch: 1/10. Loss: 0.9612:  81%|[36m████████  [0m| 21/26 [00:30<00:05,  1.14s/it]Epoch: 1/10. Loss: 0.9612:  85%|[36m████████▍ [0m| 22/26 [00:30<00:04,  1.03s/it]Epoch: 1/10. Loss: 1.0295:  85%|[36m████████▍ [0m| 22/26 [00:31<00:04,  1.03s/it]Epoch: 1/10. Loss: 1.0295:  88%|[36m████████▊ [0m| 23/26 [00:31<00:03,  1.01s/it]Epoch: 1/10. Loss: 0.9867:  88%|[36m████████▊ [0m| 23/26 [00:32<00:03,  1.01s/it]Epoch: 1/10. Loss: 0.9867:  92%|[36m█████████▏[0m| 24/26 [00:32<00:01,  1.06it/s]Epoch: 1/10. Loss: 0.9757:  92%|[36m█████████▏[0m| 24/26 [00:32<00:01,  1.06it/s]Epoch: 1/10. Loss: 0.9757:  96%|[36m█████████▌[0m| 25/26 [00:32<00:00,  1.08it/s]Epoch: 1/10. Loss: 1.0338:  96%|[36m█████████▌[0m| 25/26 [00:34<00:00,  1.08it/s]Epoch: 1/10. Loss: 1.0338: 100%|[36m██████████[0m| 26/26 [00:34<00:00,  1.24s/it]Epoch: 1/10. Loss: 1.0338: 100%|[36m██████████[0m| 26/26 [00:34<00:00,  1.34s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:05,  1.20it/s] 29%|[33m██▊       [0m| 2/7 [00:01<00:04,  1.05it/s] 43%|[33m████▎     [0m| 3/7 [00:02<00:03,  1.22it/s] 57%|[33m█████▋    [0m| 4/7 [00:03<00:02,  1.04it/s] 71%|[33m███████▏  [0m| 5/7 [00:04<00:01,  1.34it/s] 86%|[33m████████▌ [0m| 6/7 [00:05<00:00,  1.14it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.49it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.28it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 2/10. Loss: 1.0174:   0%|[36m          [0m| 0/26 [00:03<?, ?it/s]Epoch: 2/10. Loss: 1.0174:   4%|[36m▍         [0m| 1/26 [00:03<01:28,  3.53s/it]Epoch: 2/10. Loss: 0.9751:   4%|[36m▍         [0m| 1/26 [00:04<01:28,  3.53s/it]Epoch: 2/10. Loss: 0.9751:   8%|[36m▊         [0m| 2/26 [00:04<00:48,  2.00s/it]Epoch: 2/10. Loss: 0.9643:   8%|[36m▊         [0m| 2/26 [00:05<00:48,  2.00s/it]Epoch: 2/10. Loss: 0.9643:  12%|[36m█▏        [0m| 3/26 [00:05<00:39,  1.73s/it]Epoch: 2/10. Loss: 1.0239:  12%|[36m█▏        [0m| 3/26 [00:06<00:39,  1.73s/it]Epoch: 2/10. Loss: 1.0239:  15%|[36m█▌        [0m| 4/26 [00:06<00:30,  1.40s/it]Epoch: 2/10. Loss: 0.9917:  15%|[36m█▌        [0m| 4/26 [00:08<00:30,  1.40s/it]Epoch: 2/10. Loss: 0.9917:  19%|[36m█▉        [0m| 5/26 [00:08<00:30,  1.45s/it]Epoch: 2/10. Loss: 0.9576:  19%|[36m█▉        [0m| 5/26 [00:10<00:30,  1.45s/it]Epoch: 2/10. Loss: 0.9576:  23%|[36m██▎       [0m| 6/26 [00:10<00:34,  1.71s/it]Epoch: 2/10. Loss: 1.0491:  23%|[36m██▎       [0m| 6/26 [00:12<00:34,  1.71s/it]Epoch: 2/10. Loss: 1.0491:  27%|[36m██▋       [0m| 7/26 [00:13<00:37,  1.96s/it]Epoch: 2/10. Loss: 0.9980:  27%|[36m██▋       [0m| 7/26 [00:14<00:37,  1.96s/it]Epoch: 2/10. Loss: 0.9980:  31%|[36m███       [0m| 8/26 [00:14<00:34,  1.90s/it]Epoch: 2/10. Loss: 1.0583:  31%|[36m███       [0m| 8/26 [00:16<00:34,  1.90s/it]Epoch: 2/10. Loss: 1.0583:  35%|[36m███▍      [0m| 9/26 [00:16<00:30,  1.80s/it]Epoch: 2/10. Loss: 1.0523:  35%|[36m███▍      [0m| 9/26 [00:17<00:30,  1.80s/it]Epoch: 2/10. Loss: 1.0523:  38%|[36m███▊      [0m| 10/26 [00:17<00:25,  1.56s/it]Epoch: 2/10. Loss: 0.9850:  38%|[36m███▊      [0m| 10/26 [00:18<00:25,  1.56s/it]Epoch: 2/10. Loss: 0.9850:  42%|[36m████▏     [0m| 11/26 [00:18<00:22,  1.53s/it]Epoch: 2/10. Loss: 1.0582:  42%|[36m████▏     [0m| 11/26 [00:19<00:22,  1.53s/it]Epoch: 2/10. Loss: 1.0582:  46%|[36m████▌     [0m| 12/26 [00:19<00:19,  1.39s/it]Epoch: 2/10. Loss: 0.9486:  46%|[36m████▌     [0m| 12/26 [00:21<00:19,  1.39s/it]Epoch: 2/10. Loss: 0.9486:  50%|[36m█████     [0m| 13/26 [00:21<00:16,  1.30s/it]Epoch: 2/10. Loss: 1.0844:  50%|[36m█████     [0m| 13/26 [00:24<00:16,  1.30s/it]Epoch: 2/10. Loss: 1.0844:  54%|[36m█████▍    [0m| 14/26 [00:24<00:22,  1.88s/it]Epoch: 2/10. Loss: 1.0185:  54%|[36m█████▍    [0m| 14/26 [00:25<00:22,  1.88s/it]Epoch: 2/10. Loss: 1.0185:  58%|[36m█████▊    [0m| 15/26 [00:25<00:17,  1.59s/it]Epoch: 2/10. Loss: 1.0167:  58%|[36m█████▊    [0m| 15/26 [00:26<00:17,  1.59s/it]Epoch: 2/10. Loss: 1.0167:  62%|[36m██████▏   [0m| 16/26 [00:26<00:14,  1.40s/it]Epoch: 2/10. Loss: 0.9842:  62%|[36m██████▏   [0m| 16/26 [00:27<00:14,  1.40s/it]Epoch: 2/10. Loss: 0.9842:  65%|[36m██████▌   [0m| 17/26 [00:27<00:11,  1.27s/it]Epoch: 2/10. Loss: 1.0272:  65%|[36m██████▌   [0m| 17/26 [00:27<00:11,  1.27s/it]Epoch: 2/10. Loss: 1.0272:  69%|[36m██████▉   [0m| 18/26 [00:27<00:09,  1.17s/it]Epoch: 2/10. Loss: 0.9818:  69%|[36m██████▉   [0m| 18/26 [00:28<00:09,  1.17s/it]Epoch: 2/10. Loss: 0.9818:  73%|[36m███████▎  [0m| 19/26 [00:28<00:07,  1.09s/it]Epoch: 2/10. Loss: 1.0422:  73%|[36m███████▎  [0m| 19/26 [00:31<00:07,  1.09s/it]Epoch: 2/10. Loss: 1.0422:  77%|[36m███████▋  [0m| 20/26 [00:31<00:08,  1.45s/it]Epoch: 2/10. Loss: 1.0690:  77%|[36m███████▋  [0m| 20/26 [00:32<00:08,  1.45s/it]Epoch: 2/10. Loss: 1.0690:  81%|[36m████████  [0m| 21/26 [00:32<00:06,  1.30s/it]Epoch: 2/10. Loss: 0.9962:  81%|[36m████████  [0m| 21/26 [00:33<00:06,  1.30s/it]Epoch: 2/10. Loss: 0.9962:  85%|[36m████████▍ [0m| 22/26 [00:33<00:04,  1.22s/it]Epoch: 2/10. Loss: 1.0429:  85%|[36m████████▍ [0m| 22/26 [00:34<00:04,  1.22s/it]Epoch: 2/10. Loss: 1.0429:  88%|[36m████████▊ [0m| 23/26 [00:34<00:03,  1.25s/it]Epoch: 2/10. Loss: 1.0084:  88%|[36m████████▊ [0m| 23/26 [00:36<00:03,  1.25s/it]Epoch: 2/10. Loss: 1.0084:  92%|[36m█████████▏[0m| 24/26 [00:36<00:02,  1.33s/it]Epoch: 2/10. Loss: 1.0735:  92%|[36m█████████▏[0m| 24/26 [00:36<00:02,  1.33s/it]Epoch: 2/10. Loss: 1.0735:  96%|[36m█████████▌[0m| 25/26 [00:36<00:01,  1.18s/it]Epoch: 2/10. Loss: 0.9912:  96%|[36m█████████▌[0m| 25/26 [00:38<00:01,  1.18s/it]Epoch: 2/10. Loss: 0.9912: 100%|[36m██████████[0m| 26/26 [00:38<00:00,  1.37s/it]Epoch: 2/10. Loss: 0.9912: 100%|[36m██████████[0m| 26/26 [00:38<00:00,  1.49s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:05,  1.19it/s] 29%|[33m██▊       [0m| 2/7 [00:01<00:04,  1.02it/s] 43%|[33m████▎     [0m| 3/7 [00:02<00:03,  1.12it/s] 57%|[33m█████▋    [0m| 4/7 [00:03<00:03,  1.01s/it] 71%|[33m███████▏  [0m| 5/7 [00:04<00:01,  1.26it/s] 86%|[33m████████▌ [0m| 6/7 [00:05<00:00,  1.22it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.56it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.28it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 3/10. Loss: 1.0220:   0%|[36m          [0m| 0/26 [00:01<?, ?it/s]Epoch: 3/10. Loss: 1.0220:   4%|[36m▍         [0m| 1/26 [00:01<00:29,  1.17s/it]Epoch: 3/10. Loss: 1.0107:   4%|[36m▍         [0m| 1/26 [00:01<00:29,  1.17s/it]Epoch: 3/10. Loss: 1.0107:   8%|[36m▊         [0m| 2/26 [00:01<00:21,  1.09it/s]Epoch: 3/10. Loss: 1.0515:   8%|[36m▊         [0m| 2/26 [00:02<00:21,  1.09it/s]Epoch: 3/10. Loss: 1.0515:  12%|[36m█▏        [0m| 3/26 [00:02<00:20,  1.13it/s]Epoch: 3/10. Loss: 1.0083:  12%|[36m█▏        [0m| 3/26 [00:05<00:20,  1.13it/s]Epoch: 3/10. Loss: 1.0083:  15%|[36m█▌        [0m| 4/26 [00:05<00:37,  1.70s/it]Epoch: 3/10. Loss: 0.9658:  15%|[36m█▌        [0m| 4/26 [00:08<00:37,  1.70s/it]Epoch: 3/10. Loss: 0.9658:  19%|[36m█▉        [0m| 5/26 [00:08<00:42,  2.04s/it]Epoch: 3/10. Loss: 0.9997:  19%|[36m█▉        [0m| 5/26 [00:09<00:42,  2.04s/it]Epoch: 3/10. Loss: 0.9997:  23%|[36m██▎       [0m| 6/26 [00:09<00:32,  1.63s/it]Epoch: 3/10. Loss: 0.9811:  23%|[36m██▎       [0m| 6/26 [00:09<00:32,  1.63s/it]Epoch: 3/10. Loss: 0.9811:  27%|[36m██▋       [0m| 7/26 [00:09<00:25,  1.34s/it]Epoch: 3/10. Loss: 1.0347:  27%|[36m██▋       [0m| 7/26 [00:10<00:25,  1.34s/it]Epoch: 3/10. Loss: 1.0347:  31%|[36m███       [0m| 8/26 [00:10<00:20,  1.16s/it]Epoch: 3/10. Loss: 0.9898:  31%|[36m███       [0m| 8/26 [00:11<00:20,  1.16s/it]Epoch: 3/10. Loss: 0.9898:  35%|[36m███▍      [0m| 9/26 [00:11<00:18,  1.09s/it]Epoch: 3/10. Loss: 1.0511:  35%|[36m███▍      [0m| 9/26 [00:12<00:18,  1.09s/it]Epoch: 3/10. Loss: 1.0511:  38%|[36m███▊      [0m| 10/26 [00:12<00:18,  1.13s/it]Epoch: 3/10. Loss: 1.0238:  38%|[36m███▊      [0m| 10/26 [00:13<00:18,  1.13s/it]Epoch: 3/10. Loss: 1.0238:  42%|[36m████▏     [0m| 11/26 [00:13<00:15,  1.06s/it]Epoch: 3/10. Loss: 0.9945:  42%|[36m████▏     [0m| 11/26 [00:14<00:15,  1.06s/it]Epoch: 3/10. Loss: 0.9945:  46%|[36m████▌     [0m| 12/26 [00:14<00:14,  1.04s/it]Epoch: 3/10. Loss: 1.0021:  46%|[36m████▌     [0m| 12/26 [00:15<00:14,  1.04s/it]Epoch: 3/10. Loss: 1.0021:  50%|[36m█████     [0m| 13/26 [00:15<00:12,  1.02it/s]Epoch: 3/10. Loss: 1.0766:  50%|[36m█████     [0m| 13/26 [00:16<00:12,  1.02it/s]Epoch: 3/10. Loss: 1.0766:  54%|[36m█████▍    [0m| 14/26 [00:16<00:11,  1.06it/s]Epoch: 3/10. Loss: 1.0064:  54%|[36m█████▍    [0m| 14/26 [00:17<00:11,  1.06it/s]Epoch: 3/10. Loss: 1.0064:  58%|[36m█████▊    [0m| 15/26 [00:17<00:10,  1.03it/s]Epoch: 3/10. Loss: 0.9716:  58%|[36m█████▊    [0m| 15/26 [00:18<00:10,  1.03it/s]Epoch: 3/10. Loss: 0.9716:  62%|[36m██████▏   [0m| 16/26 [00:18<00:09,  1.04it/s]Epoch: 3/10. Loss: 1.0532:  62%|[36m██████▏   [0m| 16/26 [00:19<00:09,  1.04it/s]Epoch: 3/10. Loss: 1.0532:  65%|[36m██████▌   [0m| 17/26 [00:19<00:08,  1.07it/s]Epoch: 3/10. Loss: 0.9865:  65%|[36m██████▌   [0m| 17/26 [00:20<00:08,  1.07it/s]Epoch: 3/10. Loss: 0.9865:  69%|[36m██████▉   [0m| 18/26 [00:20<00:07,  1.07it/s]Epoch: 3/10. Loss: 1.0606:  69%|[36m██████▉   [0m| 18/26 [00:21<00:07,  1.07it/s]Epoch: 3/10. Loss: 1.0606:  73%|[36m███████▎  [0m| 19/26 [00:21<00:06,  1.04it/s]Epoch: 3/10. Loss: 1.0208:  73%|[36m███████▎  [0m| 19/26 [00:22<00:06,  1.04it/s]Epoch: 3/10. Loss: 1.0208:  77%|[36m███████▋  [0m| 20/26 [00:22<00:05,  1.06it/s]Epoch: 3/10. Loss: 1.0299:  77%|[36m███████▋  [0m| 20/26 [00:23<00:05,  1.06it/s]Epoch: 3/10. Loss: 1.0299:  81%|[36m████████  [0m| 21/26 [00:23<00:04,  1.07it/s]Epoch: 3/10. Loss: 1.0133:  81%|[36m████████  [0m| 21/26 [00:24<00:04,  1.07it/s]Epoch: 3/10. Loss: 1.0133:  85%|[36m████████▍ [0m| 22/26 [00:24<00:03,  1.00it/s]Epoch: 3/10. Loss: 1.0143:  85%|[36m████████▍ [0m| 22/26 [00:25<00:03,  1.00it/s]Epoch: 3/10. Loss: 1.0143:  88%|[36m████████▊ [0m| 23/26 [00:25<00:03,  1.00s/it]Epoch: 3/10. Loss: 1.0245:  88%|[36m████████▊ [0m| 23/26 [00:26<00:03,  1.00s/it]Epoch: 3/10. Loss: 1.0245:  92%|[36m█████████▏[0m| 24/26 [00:26<00:02,  1.23s/it]Epoch: 3/10. Loss: 1.0183:  92%|[36m█████████▏[0m| 24/26 [00:27<00:02,  1.23s/it]Epoch: 3/10. Loss: 1.0183:  96%|[36m█████████▌[0m| 25/26 [00:27<00:01,  1.13s/it]Epoch: 3/10. Loss: 0.9956:  96%|[36m█████████▌[0m| 25/26 [00:28<00:01,  1.13s/it]Epoch: 3/10. Loss: 0.9956: 100%|[36m██████████[0m| 26/26 [00:28<00:00,  1.01it/s]Epoch: 3/10. Loss: 0.9956: 100%|[36m██████████[0m| 26/26 [00:28<00:00,  1.10s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:05,  1.08it/s] 29%|[33m██▊       [0m| 2/7 [00:01<00:05,  1.01s/it] 43%|[33m████▎     [0m| 3/7 [00:02<00:03,  1.13it/s] 57%|[33m█████▋    [0m| 4/7 [00:03<00:03,  1.03s/it] 71%|[33m███████▏  [0m| 5/7 [00:04<00:01,  1.24it/s] 86%|[33m████████▌ [0m| 6/7 [00:05<00:00,  1.19it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.55it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.26it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 4/10. Loss: 0.9904:   0%|[36m          [0m| 0/26 [00:01<?, ?it/s]Epoch: 4/10. Loss: 0.9904:   4%|[36m▍         [0m| 1/26 [00:01<00:26,  1.05s/it]Epoch: 4/10. Loss: 0.9886:   4%|[36m▍         [0m| 1/26 [00:01<00:26,  1.05s/it]Epoch: 4/10. Loss: 0.9886:   8%|[36m▊         [0m| 2/26 [00:01<00:22,  1.05it/s]Epoch: 4/10. Loss: 1.0520:   8%|[36m▊         [0m| 2/26 [00:02<00:22,  1.05it/s]Epoch: 4/10. Loss: 1.0520:  12%|[36m█▏        [0m| 3/26 [00:02<00:21,  1.09it/s]Epoch: 4/10. Loss: 1.0794:  12%|[36m█▏        [0m| 3/26 [00:04<00:21,  1.09it/s]Epoch: 4/10. Loss: 1.0794:  15%|[36m█▌        [0m| 4/26 [00:04<00:28,  1.30s/it]Epoch: 4/10. Loss: 0.9756:  15%|[36m█▌        [0m| 4/26 [00:05<00:28,  1.30s/it]Epoch: 4/10. Loss: 0.9756:  19%|[36m█▉        [0m| 5/26 [00:05<00:23,  1.13s/it]Epoch: 4/10. Loss: 1.0074:  19%|[36m█▉        [0m| 5/26 [00:06<00:23,  1.13s/it]Epoch: 4/10. Loss: 1.0074:  23%|[36m██▎       [0m| 6/26 [00:06<00:20,  1.04s/it]Epoch: 4/10. Loss: 1.0040:  23%|[36m██▎       [0m| 6/26 [00:07<00:20,  1.04s/it]Epoch: 4/10. Loss: 1.0040:  27%|[36m██▋       [0m| 7/26 [00:07<00:19,  1.04s/it]Epoch: 4/10. Loss: 1.0615:  27%|[36m██▋       [0m| 7/26 [00:08<00:19,  1.04s/it]Epoch: 4/10. Loss: 1.0615:  31%|[36m███       [0m| 8/26 [00:08<00:18,  1.01s/it]Epoch: 4/10. Loss: 0.9859:  31%|[36m███       [0m| 8/26 [00:09<00:18,  1.01s/it]Epoch: 4/10. Loss: 0.9859:  35%|[36m███▍      [0m| 9/26 [00:09<00:17,  1.03s/it]Epoch: 4/10. Loss: 0.9759:  35%|[36m███▍      [0m| 9/26 [00:11<00:17,  1.03s/it]Epoch: 4/10. Loss: 0.9759:  38%|[36m███▊      [0m| 10/26 [00:11<00:23,  1.44s/it]Epoch: 4/10. Loss: 0.9859:  38%|[36m███▊      [0m| 10/26 [00:12<00:23,  1.44s/it]Epoch: 4/10. Loss: 0.9859:  42%|[36m████▏     [0m| 11/26 [00:12<00:19,  1.31s/it]Epoch: 4/10. Loss: 1.0270:  42%|[36m████▏     [0m| 11/26 [00:13<00:19,  1.31s/it]Epoch: 4/10. Loss: 1.0270:  46%|[36m████▌     [0m| 12/26 [00:13<00:17,  1.22s/it]Epoch: 4/10. Loss: 1.0019:  46%|[36m████▌     [0m| 12/26 [00:15<00:17,  1.22s/it]Epoch: 4/10. Loss: 1.0019:  50%|[36m█████     [0m| 13/26 [00:15<00:18,  1.41s/it]Epoch: 4/10. Loss: 1.0732:  50%|[36m█████     [0m| 13/26 [00:16<00:18,  1.41s/it]Epoch: 4/10. Loss: 1.0732:  54%|[36m█████▍    [0m| 14/26 [00:16<00:15,  1.33s/it]Epoch: 4/10. Loss: 1.0260:  54%|[36m█████▍    [0m| 14/26 [00:17<00:15,  1.33s/it]Epoch: 4/10. Loss: 1.0260:  58%|[36m█████▊    [0m| 15/26 [00:17<00:13,  1.22s/it]Epoch: 4/10. Loss: 1.0303:  58%|[36m█████▊    [0m| 15/26 [00:18<00:13,  1.22s/it]Epoch: 4/10. Loss: 1.0303:  62%|[36m██████▏   [0m| 16/26 [00:18<00:10,  1.09s/it]Epoch: 4/10. Loss: 0.9836:  62%|[36m██████▏   [0m| 16/26 [00:19<00:10,  1.09s/it]Epoch: 4/10. Loss: 0.9836:  65%|[36m██████▌   [0m| 17/26 [00:19<00:09,  1.02s/it]Epoch: 4/10. Loss: 1.0469:  65%|[36m██████▌   [0m| 17/26 [00:20<00:09,  1.02s/it]Epoch: 4/10. Loss: 1.0469:  69%|[36m██████▉   [0m| 18/26 [00:20<00:07,  1.00it/s]Epoch: 4/10. Loss: 0.9525:  69%|[36m██████▉   [0m| 18/26 [00:21<00:07,  1.00it/s]Epoch: 4/10. Loss: 0.9525:  73%|[36m███████▎  [0m| 19/26 [00:21<00:06,  1.02it/s]Epoch: 4/10. Loss: 1.0771:  73%|[36m███████▎  [0m| 19/26 [00:22<00:06,  1.02it/s]Epoch: 4/10. Loss: 1.0771:  77%|[36m███████▋  [0m| 20/26 [00:22<00:05,  1.02it/s]Epoch: 4/10. Loss: 1.0016:  77%|[36m███████▋  [0m| 20/26 [00:24<00:05,  1.02it/s]Epoch: 4/10. Loss: 1.0016:  81%|[36m████████  [0m| 21/26 [00:24<00:07,  1.48s/it]Epoch: 4/10. Loss: 1.0132:  81%|[36m████████  [0m| 21/26 [00:26<00:07,  1.48s/it]Epoch: 4/10. Loss: 1.0132:  85%|[36m████████▍ [0m| 22/26 [00:26<00:06,  1.52s/it]Epoch: 4/10. Loss: 1.0502:  85%|[36m████████▍ [0m| 22/26 [00:27<00:06,  1.52s/it]Epoch: 4/10. Loss: 1.0502:  88%|[36m████████▊ [0m| 23/26 [00:27<00:04,  1.37s/it]Epoch: 4/10. Loss: 1.0158:  88%|[36m████████▊ [0m| 23/26 [00:28<00:04,  1.37s/it]Epoch: 4/10. Loss: 1.0158:  92%|[36m█████████▏[0m| 24/26 [00:28<00:02,  1.17s/it]Epoch: 4/10. Loss: 1.0012:  92%|[36m█████████▏[0m| 24/26 [00:28<00:02,  1.17s/it]Epoch: 4/10. Loss: 1.0012:  96%|[36m█████████▌[0m| 25/26 [00:28<00:01,  1.03s/it]Epoch: 4/10. Loss: 0.9903:  96%|[36m█████████▌[0m| 25/26 [00:31<00:01,  1.03s/it]Epoch: 4/10. Loss: 0.9903: 100%|[36m██████████[0m| 26/26 [00:31<00:00,  1.32s/it]Epoch: 4/10. Loss: 0.9903: 100%|[36m██████████[0m| 26/26 [00:31<00:00,  1.19s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:02<00:13,  2.27s/it] 29%|[33m██▊       [0m| 2/7 [00:03<00:07,  1.54s/it] 43%|[33m████▎     [0m| 3/7 [00:04<00:04,  1.18s/it] 57%|[33m█████▋    [0m| 4/7 [00:06<00:04,  1.59s/it] 71%|[33m███████▏  [0m| 5/7 [00:06<00:02,  1.16s/it] 86%|[33m████████▌ [0m| 6/7 [00:07<00:01,  1.14s/it]100%|[33m██████████[0m| 7/7 [00:08<00:00,  1.12it/s]100%|[33m██████████[0m| 7/7 [00:08<00:00,  1.17s/it]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 5/10. Loss: 1.0332:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 5/10. Loss: 1.0332:   4%|[36m▍         [0m| 1/26 [00:00<00:23,  1.08it/s]Epoch: 5/10. Loss: 0.9934:   4%|[36m▍         [0m| 1/26 [00:02<00:23,  1.08it/s]Epoch: 5/10. Loss: 0.9934:   8%|[36m▊         [0m| 2/26 [00:02<00:26,  1.10s/it]Epoch: 5/10. Loss: 1.0308:   8%|[36m▊         [0m| 2/26 [00:03<00:26,  1.10s/it]Epoch: 5/10. Loss: 1.0308:  12%|[36m█▏        [0m| 3/26 [00:03<00:23,  1.03s/it]Epoch: 5/10. Loss: 1.0060:  12%|[36m█▏        [0m| 3/26 [00:04<00:23,  1.03s/it]Epoch: 5/10. Loss: 1.0060:  15%|[36m█▌        [0m| 4/26 [00:04<00:28,  1.31s/it]Epoch: 5/10. Loss: 1.0802:  15%|[36m█▌        [0m| 4/26 [00:05<00:28,  1.31s/it]Epoch: 5/10. Loss: 1.0802:  19%|[36m█▉        [0m| 5/26 [00:05<00:24,  1.14s/it]Epoch: 5/10. Loss: 1.0413:  19%|[36m█▉        [0m| 5/26 [00:06<00:24,  1.14s/it]Epoch: 5/10. Loss: 1.0413:  23%|[36m██▎       [0m| 6/26 [00:06<00:20,  1.02s/it]Epoch: 5/10. Loss: 1.0063:  23%|[36m██▎       [0m| 6/26 [00:07<00:20,  1.02s/it]Epoch: 5/10. Loss: 1.0063:  27%|[36m██▋       [0m| 7/26 [00:07<00:18,  1.03it/s]Epoch: 5/10. Loss: 0.9972:  27%|[36m██▋       [0m| 7/26 [00:08<00:18,  1.03it/s]Epoch: 5/10. Loss: 0.9972:  31%|[36m███       [0m| 8/26 [00:08<00:16,  1.08it/s]Epoch: 5/10. Loss: 1.0334:  31%|[36m███       [0m| 8/26 [00:09<00:16,  1.08it/s]Epoch: 5/10. Loss: 1.0334:  35%|[36m███▍      [0m| 9/26 [00:09<00:15,  1.10it/s]Epoch: 5/10. Loss: 1.0114:  35%|[36m███▍      [0m| 9/26 [00:09<00:15,  1.10it/s]Epoch: 5/10. Loss: 1.0114:  38%|[36m███▊      [0m| 10/26 [00:09<00:14,  1.10it/s]Epoch: 5/10. Loss: 1.0109:  38%|[36m███▊      [0m| 10/26 [00:10<00:14,  1.10it/s]Epoch: 5/10. Loss: 1.0109:  42%|[36m████▏     [0m| 11/26 [00:10<00:14,  1.07it/s]Epoch: 5/10. Loss: 1.0053:  42%|[36m████▏     [0m| 11/26 [00:11<00:14,  1.07it/s]Epoch: 5/10. Loss: 1.0053:  46%|[36m████▌     [0m| 12/26 [00:11<00:12,  1.13it/s]Epoch: 5/10. Loss: 0.9943:  46%|[36m████▌     [0m| 12/26 [00:12<00:12,  1.13it/s]Epoch: 5/10. Loss: 0.9943:  50%|[36m█████     [0m| 13/26 [00:12<00:11,  1.09it/s]Epoch: 5/10. Loss: 1.0135:  50%|[36m█████     [0m| 13/26 [00:13<00:11,  1.09it/s]Epoch: 5/10. Loss: 1.0135:  54%|[36m█████▍    [0m| 14/26 [00:13<00:10,  1.14it/s]Epoch: 5/10. Loss: 0.9966:  54%|[36m█████▍    [0m| 14/26 [00:14<00:10,  1.14it/s]Epoch: 5/10. Loss: 0.9966:  58%|[36m█████▊    [0m| 15/26 [00:14<00:09,  1.11it/s]Epoch: 5/10. Loss: 1.0424:  58%|[36m█████▊    [0m| 15/26 [00:15<00:09,  1.11it/s]Epoch: 5/10. Loss: 1.0424:  62%|[36m██████▏   [0m| 16/26 [00:15<00:09,  1.10it/s]Epoch: 5/10. Loss: 0.9657:  62%|[36m██████▏   [0m| 16/26 [00:16<00:09,  1.10it/s]Epoch: 5/10. Loss: 0.9657:  65%|[36m██████▌   [0m| 17/26 [00:16<00:07,  1.13it/s]Epoch: 5/10. Loss: 0.9773:  65%|[36m██████▌   [0m| 17/26 [00:17<00:07,  1.13it/s]Epoch: 5/10. Loss: 0.9773:  69%|[36m██████▉   [0m| 18/26 [00:17<00:07,  1.07it/s]Epoch: 5/10. Loss: 0.9752:  69%|[36m██████▉   [0m| 18/26 [00:18<00:07,  1.07it/s]Epoch: 5/10. Loss: 0.9752:  73%|[36m███████▎  [0m| 19/26 [00:18<00:06,  1.11it/s]Epoch: 5/10. Loss: 0.9793:  73%|[36m███████▎  [0m| 19/26 [00:19<00:06,  1.11it/s]Epoch: 5/10. Loss: 0.9793:  77%|[36m███████▋  [0m| 20/26 [00:19<00:05,  1.09it/s]Epoch: 5/10. Loss: 1.0665:  77%|[36m███████▋  [0m| 20/26 [00:19<00:05,  1.09it/s]Epoch: 5/10. Loss: 1.0665:  81%|[36m████████  [0m| 21/26 [00:19<00:04,  1.10it/s]Epoch: 5/10. Loss: 1.0294:  81%|[36m████████  [0m| 21/26 [00:20<00:04,  1.10it/s]Epoch: 5/10. Loss: 1.0294:  85%|[36m████████▍ [0m| 22/26 [00:20<00:03,  1.11it/s]Epoch: 5/10. Loss: 1.0636:  85%|[36m████████▍ [0m| 22/26 [00:21<00:03,  1.11it/s]Epoch: 5/10. Loss: 1.0636:  88%|[36m████████▊ [0m| 23/26 [00:21<00:02,  1.08it/s]Epoch: 5/10. Loss: 0.9916:  88%|[36m████████▊ [0m| 23/26 [00:22<00:02,  1.08it/s]Epoch: 5/10. Loss: 0.9916:  92%|[36m█████████▏[0m| 24/26 [00:22<00:01,  1.15it/s]Epoch: 5/10. Loss: 1.0331:  92%|[36m█████████▏[0m| 24/26 [00:23<00:01,  1.15it/s]Epoch: 5/10. Loss: 1.0331:  96%|[36m█████████▌[0m| 25/26 [00:23<00:00,  1.11it/s]Epoch: 5/10. Loss: 1.0267:  96%|[36m█████████▌[0m| 25/26 [00:24<00:00,  1.11it/s]Epoch: 5/10. Loss: 1.0267: 100%|[36m██████████[0m| 26/26 [00:24<00:00,  1.15it/s]Epoch: 5/10. Loss: 1.0267: 100%|[36m██████████[0m| 26/26 [00:24<00:00,  1.07it/s]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:05,  1.18it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:07,  1.58s/it] 43%|[33m████▎     [0m| 3/7 [00:03<00:04,  1.19s/it] 57%|[33m█████▋    [0m| 4/7 [00:07<00:07,  2.38s/it] 71%|[33m███████▏  [0m| 5/7 [00:08<00:03,  1.67s/it] 86%|[33m████████▌ [0m| 6/7 [00:09<00:01,  1.40s/it]100%|[33m██████████[0m| 7/7 [00:09<00:00,  1.02s/it]100%|[33m██████████[0m| 7/7 [00:09<00:00,  1.34s/it]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 6/10. Loss: 1.0129:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 6/10. Loss: 1.0129:   4%|[36m▍         [0m| 1/26 [00:00<00:19,  1.30it/s]Epoch: 6/10. Loss: 0.9958:   4%|[36m▍         [0m| 1/26 [00:01<00:19,  1.30it/s]Epoch: 6/10. Loss: 0.9958:   8%|[36m▊         [0m| 2/26 [00:01<00:21,  1.09it/s]Epoch: 6/10. Loss: 1.0053:   8%|[36m▊         [0m| 2/26 [00:02<00:21,  1.09it/s]Epoch: 6/10. Loss: 1.0053:  12%|[36m█▏        [0m| 3/26 [00:02<00:19,  1.17it/s]Epoch: 6/10. Loss: 1.0299:  12%|[36m█▏        [0m| 3/26 [00:03<00:19,  1.17it/s]Epoch: 6/10. Loss: 1.0299:  15%|[36m█▌        [0m| 4/26 [00:03<00:18,  1.21it/s]Epoch: 6/10. Loss: 1.0371:  15%|[36m█▌        [0m| 4/26 [00:04<00:18,  1.21it/s]Epoch: 6/10. Loss: 1.0371:  19%|[36m█▉        [0m| 5/26 [00:04<00:17,  1.21it/s]Epoch: 6/10. Loss: 1.0208:  19%|[36m█▉        [0m| 5/26 [00:05<00:17,  1.21it/s]Epoch: 6/10. Loss: 1.0208:  23%|[36m██▎       [0m| 6/26 [00:05<00:16,  1.18it/s]Epoch: 6/10. Loss: 1.0251:  23%|[36m██▎       [0m| 6/26 [00:05<00:16,  1.18it/s]Epoch: 6/10. Loss: 1.0251:  27%|[36m██▋       [0m| 7/26 [00:05<00:16,  1.16it/s]Epoch: 6/10. Loss: 1.0503:  27%|[36m██▋       [0m| 7/26 [00:07<00:16,  1.16it/s]Epoch: 6/10. Loss: 1.0503:  31%|[36m███       [0m| 8/26 [00:07<00:18,  1.02s/it]Epoch: 6/10. Loss: 0.9983:  31%|[36m███       [0m| 8/26 [00:08<00:18,  1.02s/it]Epoch: 6/10. Loss: 0.9983:  35%|[36m███▍      [0m| 9/26 [00:08<00:16,  1.06it/s]Epoch: 6/10. Loss: 1.0210:  35%|[36m███▍      [0m| 9/26 [00:08<00:16,  1.06it/s]Epoch: 6/10. Loss: 1.0210:  38%|[36m███▊      [0m| 10/26 [00:08<00:14,  1.10it/s]Epoch: 6/10. Loss: 1.0063:  38%|[36m███▊      [0m| 10/26 [00:10<00:14,  1.10it/s]Epoch: 6/10. Loss: 1.0063:  42%|[36m████▏     [0m| 11/26 [00:10<00:16,  1.08s/it]Epoch: 6/10. Loss: 0.9953:  42%|[36m████▏     [0m| 11/26 [00:11<00:16,  1.08s/it]Epoch: 6/10. Loss: 0.9953:  46%|[36m████▌     [0m| 12/26 [00:11<00:14,  1.06s/it]Epoch: 6/10. Loss: 1.0419:  46%|[36m████▌     [0m| 12/26 [00:12<00:14,  1.06s/it]Epoch: 6/10. Loss: 1.0419:  50%|[36m█████     [0m| 13/26 [00:12<00:13,  1.03s/it]Epoch: 6/10. Loss: 1.0135:  50%|[36m█████     [0m| 13/26 [00:13<00:13,  1.03s/it]Epoch: 6/10. Loss: 1.0135:  54%|[36m█████▍    [0m| 14/26 [00:13<00:12,  1.01s/it]Epoch: 6/10. Loss: 0.9976:  54%|[36m█████▍    [0m| 14/26 [00:14<00:12,  1.01s/it]Epoch: 6/10. Loss: 0.9976:  58%|[36m█████▊    [0m| 15/26 [00:14<00:10,  1.04it/s]Epoch: 6/10. Loss: 1.0231:  58%|[36m█████▊    [0m| 15/26 [00:15<00:10,  1.04it/s]Epoch: 6/10. Loss: 1.0231:  62%|[36m██████▏   [0m| 16/26 [00:15<00:09,  1.02it/s]Epoch: 6/10. Loss: 1.0049:  62%|[36m██████▏   [0m| 16/26 [00:16<00:09,  1.02it/s]Epoch: 6/10. Loss: 1.0049:  65%|[36m██████▌   [0m| 17/26 [00:16<00:08,  1.07it/s]Epoch: 6/10. Loss: 1.0142:  65%|[36m██████▌   [0m| 17/26 [00:17<00:08,  1.07it/s]Epoch: 6/10. Loss: 1.0142:  69%|[36m██████▉   [0m| 18/26 [00:17<00:07,  1.05it/s]Epoch: 6/10. Loss: 1.0193:  69%|[36m██████▉   [0m| 18/26 [00:17<00:07,  1.05it/s]Epoch: 6/10. Loss: 1.0193:  73%|[36m███████▎  [0m| 19/26 [00:17<00:06,  1.11it/s]Epoch: 6/10. Loss: 0.9953:  73%|[36m███████▎  [0m| 19/26 [00:18<00:06,  1.11it/s]Epoch: 6/10. Loss: 0.9953:  77%|[36m███████▋  [0m| 20/26 [00:18<00:05,  1.13it/s]Epoch: 6/10. Loss: 0.9413:  77%|[36m███████▋  [0m| 20/26 [00:19<00:05,  1.13it/s]Epoch: 6/10. Loss: 0.9413:  81%|[36m████████  [0m| 21/26 [00:19<00:04,  1.20it/s]Epoch: 6/10. Loss: 1.0090:  81%|[36m████████  [0m| 21/26 [00:20<00:04,  1.20it/s]Epoch: 6/10. Loss: 1.0090:  85%|[36m████████▍ [0m| 22/26 [00:20<00:03,  1.08it/s]Epoch: 6/10. Loss: 1.0417:  85%|[36m████████▍ [0m| 22/26 [00:21<00:03,  1.08it/s]Epoch: 6/10. Loss: 1.0417:  88%|[36m████████▊ [0m| 23/26 [00:21<00:02,  1.13it/s]Epoch: 6/10. Loss: 0.9759:  88%|[36m████████▊ [0m| 23/26 [00:22<00:02,  1.13it/s]Epoch: 6/10. Loss: 0.9759:  92%|[36m█████████▏[0m| 24/26 [00:22<00:01,  1.14it/s]Epoch: 6/10. Loss: 1.0720:  92%|[36m█████████▏[0m| 24/26 [00:23<00:01,  1.14it/s]Epoch: 6/10. Loss: 1.0720:  96%|[36m█████████▌[0m| 25/26 [00:23<00:00,  1.13it/s]Epoch: 6/10. Loss: 1.1278:  96%|[36m█████████▌[0m| 25/26 [00:23<00:00,  1.13it/s]Epoch: 6/10. Loss: 1.1278: 100%|[36m██████████[0m| 26/26 [00:23<00:00,  1.22it/s]Epoch: 6/10. Loss: 1.1278: 100%|[36m██████████[0m| 26/26 [00:23<00:00,  1.10it/s]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:01<00:06,  1.01s/it] 29%|[33m██▊       [0m| 2/7 [00:02<00:05,  1.11s/it] 43%|[33m████▎     [0m| 3/7 [00:02<00:03,  1.05it/s] 57%|[33m█████▋    [0m| 4/7 [00:04<00:03,  1.10s/it] 71%|[33m███████▏  [0m| 5/7 [00:04<00:01,  1.16it/s] 86%|[33m████████▌ [0m| 6/7 [00:06<00:01,  1.24s/it]100%|[33m██████████[0m| 7/7 [00:06<00:00,  1.10it/s]100%|[33m██████████[0m| 7/7 [00:06<00:00,  1.01it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 7/10. Loss: 0.9616:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 7/10. Loss: 0.9616:   4%|[36m▍         [0m| 1/26 [00:00<00:22,  1.10it/s]Epoch: 7/10. Loss: 1.0260:   4%|[36m▍         [0m| 1/26 [00:01<00:22,  1.10it/s]Epoch: 7/10. Loss: 1.0260:   8%|[36m▊         [0m| 2/26 [00:01<00:21,  1.13it/s]Epoch: 7/10. Loss: 1.0255:   8%|[36m▊         [0m| 2/26 [00:02<00:21,  1.13it/s]Epoch: 7/10. Loss: 1.0255:  12%|[36m█▏        [0m| 3/26 [00:02<00:20,  1.13it/s]Epoch: 7/10. Loss: 1.0566:  12%|[36m█▏        [0m| 3/26 [00:03<00:20,  1.13it/s]Epoch: 7/10. Loss: 1.0566:  15%|[36m█▌        [0m| 4/26 [00:03<00:19,  1.11it/s]Epoch: 7/10. Loss: 1.0090:  15%|[36m█▌        [0m| 4/26 [00:04<00:19,  1.11it/s]Epoch: 7/10. Loss: 1.0090:  19%|[36m█▉        [0m| 5/26 [00:04<00:18,  1.16it/s]Epoch: 7/10. Loss: 0.9869:  19%|[36m█▉        [0m| 5/26 [00:05<00:18,  1.16it/s]Epoch: 7/10. Loss: 0.9869:  23%|[36m██▎       [0m| 6/26 [00:05<00:17,  1.17it/s]Epoch: 7/10. Loss: 0.9636:  23%|[36m██▎       [0m| 6/26 [00:06<00:17,  1.17it/s]Epoch: 7/10. Loss: 0.9636:  27%|[36m██▋       [0m| 7/26 [00:06<00:16,  1.16it/s]Epoch: 7/10. Loss: 1.0359:  27%|[36m██▋       [0m| 7/26 [00:07<00:16,  1.16it/s]Epoch: 7/10. Loss: 1.0359:  31%|[36m███       [0m| 8/26 [00:07<00:15,  1.13it/s]Epoch: 7/10. Loss: 1.0331:  31%|[36m███       [0m| 8/26 [00:08<00:15,  1.13it/s]Epoch: 7/10. Loss: 1.0331:  35%|[36m███▍      [0m| 9/26 [00:08<00:18,  1.11s/it]Epoch: 7/10. Loss: 1.0240:  35%|[36m███▍      [0m| 9/26 [00:09<00:18,  1.11s/it]Epoch: 7/10. Loss: 1.0240:  38%|[36m███▊      [0m| 10/26 [00:09<00:16,  1.02s/it]Epoch: 7/10. Loss: 1.0217:  38%|[36m███▊      [0m| 10/26 [00:10<00:16,  1.02s/it]Epoch: 7/10. Loss: 1.0217:  42%|[36m████▏     [0m| 11/26 [00:10<00:17,  1.15s/it]Epoch: 7/10. Loss: 0.9943:  42%|[36m████▏     [0m| 11/26 [00:11<00:17,  1.15s/it]Epoch: 7/10. Loss: 0.9943:  46%|[36m████▌     [0m| 12/26 [00:11<00:14,  1.03s/it]Epoch: 7/10. Loss: 1.0788:  46%|[36m████▌     [0m| 12/26 [00:12<00:14,  1.03s/it]Epoch: 7/10. Loss: 1.0788:  50%|[36m█████     [0m| 13/26 [00:12<00:12,  1.04it/s]Epoch: 7/10. Loss: 0.9924:  50%|[36m█████     [0m| 13/26 [00:13<00:12,  1.04it/s]Epoch: 7/10. Loss: 0.9924:  54%|[36m█████▍    [0m| 14/26 [00:13<00:11,  1.06it/s]Epoch: 7/10. Loss: 1.0333:  54%|[36m█████▍    [0m| 14/26 [00:14<00:11,  1.06it/s]Epoch: 7/10. Loss: 1.0333:  58%|[36m█████▊    [0m| 15/26 [00:14<00:10,  1.01it/s]Epoch: 7/10. Loss: 1.0291:  58%|[36m█████▊    [0m| 15/26 [00:15<00:10,  1.01it/s]Epoch: 7/10. Loss: 1.0291:  62%|[36m██████▏   [0m| 16/26 [00:15<00:09,  1.03it/s]Epoch: 7/10. Loss: 1.0006:  62%|[36m██████▏   [0m| 16/26 [00:16<00:09,  1.03it/s]Epoch: 7/10. Loss: 1.0006:  65%|[36m██████▌   [0m| 17/26 [00:16<00:08,  1.09it/s]Epoch: 7/10. Loss: 1.0246:  65%|[36m██████▌   [0m| 17/26 [00:17<00:08,  1.09it/s]Epoch: 7/10. Loss: 1.0246:  69%|[36m██████▉   [0m| 18/26 [00:17<00:07,  1.07it/s]Epoch: 7/10. Loss: 1.0223:  69%|[36m██████▉   [0m| 18/26 [00:17<00:07,  1.07it/s]Epoch: 7/10. Loss: 1.0223:  73%|[36m███████▎  [0m| 19/26 [00:17<00:06,  1.15it/s]Epoch: 7/10. Loss: 1.0280:  73%|[36m███████▎  [0m| 19/26 [00:18<00:06,  1.15it/s]Epoch: 7/10. Loss: 1.0280:  77%|[36m███████▋  [0m| 20/26 [00:18<00:05,  1.13it/s]Epoch: 7/10. Loss: 0.9912:  77%|[36m███████▋  [0m| 20/26 [00:19<00:05,  1.13it/s]Epoch: 7/10. Loss: 0.9912:  81%|[36m████████  [0m| 21/26 [00:19<00:04,  1.16it/s]Epoch: 7/10. Loss: 0.9721:  81%|[36m████████  [0m| 21/26 [00:20<00:04,  1.16it/s]Epoch: 7/10. Loss: 0.9721:  85%|[36m████████▍ [0m| 22/26 [00:20<00:03,  1.10it/s]Epoch: 7/10. Loss: 1.0513:  85%|[36m████████▍ [0m| 22/26 [00:21<00:03,  1.10it/s]Epoch: 7/10. Loss: 1.0513:  88%|[36m████████▊ [0m| 23/26 [00:21<00:02,  1.16it/s]Epoch: 7/10. Loss: 0.9999:  88%|[36m████████▊ [0m| 23/26 [00:22<00:02,  1.16it/s]Epoch: 7/10. Loss: 0.9999:  92%|[36m█████████▏[0m| 24/26 [00:22<00:01,  1.03it/s]Epoch: 7/10. Loss: 0.9858:  92%|[36m█████████▏[0m| 24/26 [00:23<00:01,  1.03it/s]Epoch: 7/10. Loss: 0.9858:  96%|[36m█████████▌[0m| 25/26 [00:23<00:00,  1.04it/s]Epoch: 7/10. Loss: 1.0428:  96%|[36m█████████▌[0m| 25/26 [00:24<00:00,  1.04it/s]Epoch: 7/10. Loss: 1.0428: 100%|[36m██████████[0m| 26/26 [00:24<00:00,  1.11it/s]Epoch: 7/10. Loss: 1.0428: 100%|[36m██████████[0m| 26/26 [00:24<00:00,  1.07it/s]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:05,  1.14it/s] 29%|[33m██▊       [0m| 2/7 [00:03<00:09,  1.90s/it] 43%|[33m████▎     [0m| 3/7 [00:04<00:05,  1.40s/it] 57%|[33m█████▋    [0m| 4/7 [00:05<00:04,  1.34s/it] 71%|[33m███████▏  [0m| 5/7 [00:05<00:02,  1.01s/it] 86%|[33m████████▌ [0m| 6/7 [00:07<00:01,  1.12s/it]100%|[33m██████████[0m| 7/7 [00:07<00:00,  1.22it/s]100%|[33m██████████[0m| 7/7 [00:07<00:00,  1.07s/it]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 8/10. Loss: 0.9888:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 8/10. Loss: 0.9888:   4%|[36m▍         [0m| 1/26 [00:00<00:22,  1.11it/s]Epoch: 8/10. Loss: 0.9764:   4%|[36m▍         [0m| 1/26 [00:01<00:22,  1.11it/s]Epoch: 8/10. Loss: 0.9764:   8%|[36m▊         [0m| 2/26 [00:01<00:18,  1.27it/s]Epoch: 8/10. Loss: 1.0457:   8%|[36m▊         [0m| 2/26 [00:02<00:18,  1.27it/s]Epoch: 8/10. Loss: 1.0457:  12%|[36m█▏        [0m| 3/26 [00:02<00:19,  1.19it/s]Epoch: 8/10. Loss: 0.9870:  12%|[36m█▏        [0m| 3/26 [00:03<00:19,  1.19it/s]Epoch: 8/10. Loss: 0.9870:  15%|[36m█▌        [0m| 4/26 [00:03<00:18,  1.16it/s]Epoch: 8/10. Loss: 1.0280:  15%|[36m█▌        [0m| 4/26 [00:04<00:18,  1.16it/s]Epoch: 8/10. Loss: 1.0280:  19%|[36m█▉        [0m| 5/26 [00:04<00:17,  1.17it/s]Epoch: 8/10. Loss: 1.0339:  19%|[36m█▉        [0m| 5/26 [00:05<00:17,  1.17it/s]Epoch: 8/10. Loss: 1.0339:  23%|[36m██▎       [0m| 6/26 [00:05<00:17,  1.15it/s]Epoch: 8/10. Loss: 1.0401:  23%|[36m██▎       [0m| 6/26 [00:06<00:17,  1.15it/s]Epoch: 8/10. Loss: 1.0401:  27%|[36m██▋       [0m| 7/26 [00:06<00:17,  1.11it/s]Epoch: 8/10. Loss: 1.0056:  27%|[36m██▋       [0m| 7/26 [00:06<00:17,  1.11it/s]Epoch: 8/10. Loss: 1.0056:  31%|[36m███       [0m| 8/26 [00:06<00:15,  1.13it/s]Epoch: 8/10. Loss: 1.0006:  31%|[36m███       [0m| 8/26 [00:07<00:15,  1.13it/s]Epoch: 8/10. Loss: 1.0006:  35%|[36m███▍      [0m| 9/26 [00:07<00:14,  1.17it/s]Epoch: 8/10. Loss: 1.0533:  35%|[36m███▍      [0m| 9/26 [00:08<00:14,  1.17it/s]Epoch: 8/10. Loss: 1.0533:  38%|[36m███▊      [0m| 10/26 [00:08<00:13,  1.17it/s]Epoch: 8/10. Loss: 1.0743:  38%|[36m███▊      [0m| 10/26 [00:09<00:13,  1.17it/s]Epoch: 8/10. Loss: 1.0743:  42%|[36m████▏     [0m| 11/26 [00:09<00:14,  1.06it/s]Epoch: 8/10. Loss: 0.9589:  42%|[36m████▏     [0m| 11/26 [00:10<00:14,  1.06it/s]Epoch: 8/10. Loss: 0.9589:  46%|[36m████▌     [0m| 12/26 [00:10<00:13,  1.05it/s]Epoch: 8/10. Loss: 1.0239:  46%|[36m████▌     [0m| 12/26 [00:11<00:13,  1.05it/s]Epoch: 8/10. Loss: 1.0239:  50%|[36m█████     [0m| 13/26 [00:11<00:12,  1.07it/s]Epoch: 8/10. Loss: 0.9803:  50%|[36m█████     [0m| 13/26 [00:13<00:12,  1.07it/s]Epoch: 8/10. Loss: 0.9803:  54%|[36m█████▍    [0m| 14/26 [00:13<00:14,  1.20s/it]Epoch: 8/10. Loss: 1.0069:  54%|[36m█████▍    [0m| 14/26 [00:15<00:14,  1.20s/it]Epoch: 8/10. Loss: 1.0069:  58%|[36m█████▊    [0m| 15/26 [00:15<00:15,  1.44s/it]Epoch: 8/10. Loss: 1.0163:  58%|[36m█████▊    [0m| 15/26 [00:16<00:15,  1.44s/it]Epoch: 8/10. Loss: 1.0163:  62%|[36m██████▏   [0m| 16/26 [00:16<00:12,  1.26s/it]Epoch: 8/10. Loss: 0.9946:  62%|[36m██████▏   [0m| 16/26 [00:17<00:12,  1.26s/it]Epoch: 8/10. Loss: 0.9946:  65%|[36m██████▌   [0m| 17/26 [00:17<00:11,  1.28s/it]Epoch: 8/10. Loss: 0.9925:  65%|[36m██████▌   [0m| 17/26 [00:18<00:11,  1.28s/it]Epoch: 8/10. Loss: 0.9925:  69%|[36m██████▉   [0m| 18/26 [00:18<00:09,  1.15s/it]Epoch: 8/10. Loss: 0.9921:  69%|[36m██████▉   [0m| 18/26 [00:19<00:09,  1.15s/it]Epoch: 8/10. Loss: 0.9921:  73%|[36m███████▎  [0m| 19/26 [00:19<00:07,  1.08s/it]Epoch: 8/10. Loss: 1.0024:  73%|[36m███████▎  [0m| 19/26 [00:22<00:07,  1.08s/it]Epoch: 8/10. Loss: 1.0024:  77%|[36m███████▋  [0m| 20/26 [00:22<00:10,  1.68s/it]Epoch: 8/10. Loss: 1.0459:  77%|[36m███████▋  [0m| 20/26 [00:24<00:10,  1.68s/it]Epoch: 8/10. Loss: 1.0459:  81%|[36m████████  [0m| 21/26 [00:24<00:08,  1.66s/it]Epoch: 8/10. Loss: 0.9707:  81%|[36m████████  [0m| 21/26 [00:25<00:08,  1.66s/it]Epoch: 8/10. Loss: 0.9707:  85%|[36m████████▍ [0m| 22/26 [00:25<00:05,  1.47s/it]Epoch: 8/10. Loss: 1.1112:  85%|[36m████████▍ [0m| 22/26 [00:26<00:05,  1.47s/it]Epoch: 8/10. Loss: 1.1112:  88%|[36m████████▊ [0m| 23/26 [00:26<00:04,  1.38s/it]Epoch: 8/10. Loss: 1.0820:  88%|[36m████████▊ [0m| 23/26 [00:27<00:04,  1.38s/it]Epoch: 8/10. Loss: 1.0820:  92%|[36m█████████▏[0m| 24/26 [00:27<00:02,  1.27s/it]Epoch: 8/10. Loss: 1.0121:  92%|[36m█████████▏[0m| 24/26 [00:28<00:02,  1.27s/it]Epoch: 8/10. Loss: 1.0121:  96%|[36m█████████▌[0m| 25/26 [00:28<00:01,  1.12s/it]Epoch: 8/10. Loss: 0.9694:  96%|[36m█████████▌[0m| 25/26 [00:28<00:01,  1.12s/it]Epoch: 8/10. Loss: 0.9694: 100%|[36m██████████[0m| 26/26 [00:28<00:00,  1.01it/s]Epoch: 8/10. Loss: 0.9694: 100%|[36m██████████[0m| 26/26 [00:28<00:00,  1.10s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:05,  1.18it/s] 29%|[33m██▊       [0m| 2/7 [00:01<00:04,  1.03it/s] 43%|[33m████▎     [0m| 3/7 [00:02<00:03,  1.16it/s] 57%|[33m█████▋    [0m| 4/7 [00:03<00:03,  1.04s/it] 71%|[33m███████▏  [0m| 5/7 [00:04<00:01,  1.22it/s] 86%|[33m████████▌ [0m| 6/7 [00:05<00:00,  1.21it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.60it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.29it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 9/10. Loss: 1.0585:   0%|[36m          [0m| 0/26 [00:02<?, ?it/s]Epoch: 9/10. Loss: 1.0585:   4%|[36m▍         [0m| 1/26 [00:02<01:11,  2.87s/it]Epoch: 9/10. Loss: 0.9927:   4%|[36m▍         [0m| 1/26 [00:03<01:11,  2.87s/it]Epoch: 9/10. Loss: 0.9927:   8%|[36m▊         [0m| 2/26 [00:03<00:39,  1.63s/it]Epoch: 9/10. Loss: 0.9870:   8%|[36m▊         [0m| 2/26 [00:04<00:39,  1.63s/it]Epoch: 9/10. Loss: 0.9870:  12%|[36m█▏        [0m| 3/26 [00:04<00:29,  1.29s/it]Epoch: 9/10. Loss: 0.9797:  12%|[36m█▏        [0m| 3/26 [00:05<00:29,  1.29s/it]Epoch: 9/10. Loss: 0.9797:  15%|[36m█▌        [0m| 4/26 [00:05<00:24,  1.10s/it]Epoch: 9/10. Loss: 1.0369:  15%|[36m█▌        [0m| 4/26 [00:06<00:24,  1.10s/it]Epoch: 9/10. Loss: 1.0369:  19%|[36m█▉        [0m| 5/26 [00:06<00:21,  1.04s/it]Epoch: 9/10. Loss: 1.0662:  19%|[36m█▉        [0m| 5/26 [00:07<00:21,  1.04s/it]Epoch: 9/10. Loss: 1.0662:  23%|[36m██▎       [0m| 6/26 [00:07<00:19,  1.02it/s]Epoch: 9/10. Loss: 1.0217:  23%|[36m██▎       [0m| 6/26 [00:07<00:19,  1.02it/s]Epoch: 9/10. Loss: 1.0217:  27%|[36m██▋       [0m| 7/26 [00:07<00:17,  1.07it/s]Epoch: 9/10. Loss: 0.9732:  27%|[36m██▋       [0m| 7/26 [00:08<00:17,  1.07it/s]Epoch: 9/10. Loss: 0.9732:  31%|[36m███       [0m| 8/26 [00:08<00:16,  1.09it/s]Epoch: 9/10. Loss: 1.0154:  31%|[36m███       [0m| 8/26 [00:09<00:16,  1.09it/s]Epoch: 9/10. Loss: 1.0154:  35%|[36m███▍      [0m| 9/26 [00:09<00:15,  1.10it/s]Epoch: 9/10. Loss: 1.0304:  35%|[36m███▍      [0m| 9/26 [00:10<00:15,  1.10it/s]Epoch: 9/10. Loss: 1.0304:  38%|[36m███▊      [0m| 10/26 [00:10<00:14,  1.10it/s]Epoch: 9/10. Loss: 0.9963:  38%|[36m███▊      [0m| 10/26 [00:11<00:14,  1.10it/s]Epoch: 9/10. Loss: 0.9963:  42%|[36m████▏     [0m| 11/26 [00:11<00:14,  1.04it/s]Epoch: 9/10. Loss: 1.0003:  42%|[36m████▏     [0m| 11/26 [00:13<00:14,  1.04it/s]Epoch: 9/10. Loss: 1.0003:  46%|[36m████▌     [0m| 12/26 [00:13<00:16,  1.14s/it]Epoch: 9/10. Loss: 1.0015:  46%|[36m████▌     [0m| 12/26 [00:14<00:16,  1.14s/it]Epoch: 9/10. Loss: 1.0015:  50%|[36m█████     [0m| 13/26 [00:14<00:14,  1.10s/it]Epoch: 9/10. Loss: 1.0080:  50%|[36m█████     [0m| 13/26 [00:15<00:14,  1.10s/it]Epoch: 9/10. Loss: 1.0080:  54%|[36m█████▍    [0m| 14/26 [00:15<00:12,  1.03s/it]Epoch: 9/10. Loss: 1.0844:  54%|[36m█████▍    [0m| 14/26 [00:16<00:12,  1.03s/it]Epoch: 9/10. Loss: 1.0844:  58%|[36m█████▊    [0m| 15/26 [00:16<00:10,  1.01it/s]Epoch: 9/10. Loss: 1.0513:  58%|[36m█████▊    [0m| 15/26 [00:16<00:10,  1.01it/s]Epoch: 9/10. Loss: 1.0513:  62%|[36m██████▏   [0m| 16/26 [00:16<00:09,  1.05it/s]Epoch: 9/10. Loss: 0.9992:  62%|[36m██████▏   [0m| 16/26 [00:17<00:09,  1.05it/s]Epoch: 9/10. Loss: 0.9992:  65%|[36m██████▌   [0m| 17/26 [00:17<00:08,  1.12it/s]Epoch: 9/10. Loss: 1.0367:  65%|[36m██████▌   [0m| 17/26 [00:18<00:08,  1.12it/s]Epoch: 9/10. Loss: 1.0367:  69%|[36m██████▉   [0m| 18/26 [00:18<00:06,  1.16it/s]Epoch: 9/10. Loss: 1.0227:  69%|[36m██████▉   [0m| 18/26 [00:19<00:06,  1.16it/s]Epoch: 9/10. Loss: 1.0227:  73%|[36m███████▎  [0m| 19/26 [00:19<00:05,  1.17it/s]Epoch: 9/10. Loss: 1.0210:  73%|[36m███████▎  [0m| 19/26 [00:20<00:05,  1.17it/s]Epoch: 9/10. Loss: 1.0210:  77%|[36m███████▋  [0m| 20/26 [00:20<00:05,  1.13it/s]Epoch: 9/10. Loss: 1.0188:  77%|[36m███████▋  [0m| 20/26 [00:21<00:05,  1.13it/s]Epoch: 9/10. Loss: 1.0188:  81%|[36m████████  [0m| 21/26 [00:21<00:04,  1.08it/s]Epoch: 9/10. Loss: 1.0092:  81%|[36m████████  [0m| 21/26 [00:22<00:04,  1.08it/s]Epoch: 9/10. Loss: 1.0092:  85%|[36m████████▍ [0m| 22/26 [00:22<00:03,  1.10it/s]Epoch: 9/10. Loss: 0.9965:  85%|[36m████████▍ [0m| 22/26 [00:23<00:03,  1.10it/s]Epoch: 9/10. Loss: 0.9965:  88%|[36m████████▊ [0m| 23/26 [00:23<00:02,  1.08it/s]Epoch: 9/10. Loss: 0.9575:  88%|[36m████████▊ [0m| 23/26 [00:23<00:02,  1.08it/s]Epoch: 9/10. Loss: 0.9575:  92%|[36m█████████▏[0m| 24/26 [00:23<00:01,  1.09it/s]Epoch: 9/10. Loss: 1.0487:  92%|[36m█████████▏[0m| 24/26 [00:24<00:01,  1.09it/s]Epoch: 9/10. Loss: 1.0487:  96%|[36m█████████▌[0m| 25/26 [00:24<00:00,  1.08it/s]Epoch: 9/10. Loss: 0.9944:  96%|[36m█████████▌[0m| 25/26 [00:25<00:00,  1.08it/s]Epoch: 9/10. Loss: 0.9944: 100%|[36m██████████[0m| 26/26 [00:25<00:00,  1.22it/s]Epoch: 9/10. Loss: 0.9944: 100%|[36m██████████[0m| 26/26 [00:25<00:00,  1.02it/s]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:04,  1.30it/s] 29%|[33m██▊       [0m| 2/7 [00:01<00:04,  1.09it/s] 43%|[33m████▎     [0m| 3/7 [00:02<00:03,  1.20it/s] 57%|[33m█████▋    [0m| 4/7 [00:03<00:03,  1.01s/it] 71%|[33m███████▏  [0m| 5/7 [00:04<00:01,  1.25it/s] 86%|[33m████████▌ [0m| 6/7 [00:05<00:00,  1.21it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.59it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.31it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 0/10. Loss: 7.0447:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 0/10. Loss: 7.0447:   4%|[36m▍         [0m| 1/26 [00:01<00:26,  1.05s/it]Epoch: 0/10. Loss: 3.6285:   4%|[36m▍         [0m| 1/26 [00:01<00:26,  1.05s/it]Epoch: 0/10. Loss: 3.6285:   8%|[36m▊         [0m| 2/26 [00:01<00:23,  1.02it/s]Epoch: 0/10. Loss: 1.9714:   8%|[36m▊         [0m| 2/26 [00:02<00:23,  1.02it/s]Epoch: 0/10. Loss: 1.9714:  12%|[36m█▏        [0m| 3/26 [00:02<00:21,  1.06it/s]Epoch: 0/10. Loss: 1.1364:  12%|[36m█▏        [0m| 3/26 [00:03<00:21,  1.06it/s]Epoch: 0/10. Loss: 1.1364:  15%|[36m█▌        [0m| 4/26 [00:03<00:22,  1.00s/it]Epoch: 0/10. Loss: 1.1463:  15%|[36m█▌        [0m| 4/26 [00:04<00:22,  1.00s/it]Epoch: 0/10. Loss: 1.1463:  19%|[36m█▉        [0m| 5/26 [00:04<00:21,  1.01s/it]Epoch: 0/10. Loss: 1.2223:  19%|[36m█▉        [0m| 5/26 [00:06<00:21,  1.01s/it]Epoch: 0/10. Loss: 1.2223:  23%|[36m██▎       [0m| 6/26 [00:06<00:20,  1.02s/it]Epoch: 0/10. Loss: 1.1980:  23%|[36m██▎       [0m| 6/26 [00:06<00:20,  1.02s/it]Epoch: 0/10. Loss: 1.1980:  27%|[36m██▋       [0m| 7/26 [00:06<00:18,  1.01it/s]Epoch: 0/10. Loss: 1.0297:  27%|[36m██▋       [0m| 7/26 [00:08<00:18,  1.01it/s]Epoch: 0/10. Loss: 1.0297:  31%|[36m███       [0m| 8/26 [00:08<00:18,  1.03s/it]Epoch: 0/10. Loss: 1.0796:  31%|[36m███       [0m| 8/26 [00:09<00:18,  1.03s/it]Epoch: 0/10. Loss: 1.0796:  35%|[36m███▍      [0m| 9/26 [00:09<00:17,  1.04s/it]Epoch: 0/10. Loss: 1.2073:  35%|[36m███▍      [0m| 9/26 [00:10<00:17,  1.04s/it]Epoch: 0/10. Loss: 1.2073:  38%|[36m███▊      [0m| 10/26 [00:10<00:16,  1.00s/it]Epoch: 0/10. Loss: 1.1299:  38%|[36m███▊      [0m| 10/26 [00:10<00:16,  1.00s/it]Epoch: 0/10. Loss: 1.1299:  42%|[36m████▏     [0m| 11/26 [00:10<00:14,  1.03it/s]Epoch: 0/10. Loss: 0.9597:  42%|[36m████▏     [0m| 11/26 [00:12<00:14,  1.03it/s]Epoch: 0/10. Loss: 0.9597:  46%|[36m████▌     [0m| 12/26 [00:12<00:14,  1.01s/it]Epoch: 0/10. Loss: 1.0358:  46%|[36m████▌     [0m| 12/26 [00:13<00:14,  1.01s/it]Epoch: 0/10. Loss: 1.0358:  50%|[36m█████     [0m| 13/26 [00:13<00:13,  1.04s/it]Epoch: 0/10. Loss: 1.1362:  50%|[36m█████     [0m| 13/26 [00:14<00:13,  1.04s/it]Epoch: 0/10. Loss: 1.1362:  54%|[36m█████▍    [0m| 14/26 [00:14<00:14,  1.19s/it]Epoch: 0/10. Loss: 1.0914:  54%|[36m█████▍    [0m| 14/26 [00:15<00:14,  1.19s/it]Epoch: 0/10. Loss: 1.0914:  58%|[36m█████▊    [0m| 15/26 [00:15<00:11,  1.07s/it]Epoch: 0/10. Loss: 1.0328:  58%|[36m█████▊    [0m| 15/26 [00:16<00:11,  1.07s/it]Epoch: 0/10. Loss: 1.0328:  62%|[36m██████▏   [0m| 16/26 [00:16<00:10,  1.05s/it]Epoch: 0/10. Loss: 1.0287:  62%|[36m██████▏   [0m| 16/26 [00:17<00:10,  1.05s/it]Epoch: 0/10. Loss: 1.0287:  65%|[36m██████▌   [0m| 17/26 [00:17<00:08,  1.04it/s]Epoch: 0/10. Loss: 1.0512:  65%|[36m██████▌   [0m| 17/26 [00:18<00:08,  1.04it/s]Epoch: 0/10. Loss: 1.0512:  69%|[36m██████▉   [0m| 18/26 [00:18<00:07,  1.08it/s]Epoch: 0/10. Loss: 0.9943:  69%|[36m██████▉   [0m| 18/26 [00:19<00:07,  1.08it/s]Epoch: 0/10. Loss: 0.9943:  73%|[36m███████▎  [0m| 19/26 [00:19<00:06,  1.05it/s]Epoch: 0/10. Loss: 0.9837:  73%|[36m███████▎  [0m| 19/26 [00:20<00:06,  1.05it/s]Epoch: 0/10. Loss: 0.9837:  77%|[36m███████▋  [0m| 20/26 [00:20<00:05,  1.04it/s]Epoch: 0/10. Loss: 0.9889:  77%|[36m███████▋  [0m| 20/26 [00:21<00:05,  1.04it/s]Epoch: 0/10. Loss: 0.9889:  81%|[36m████████  [0m| 21/26 [00:21<00:05,  1.02s/it]Epoch: 0/10. Loss: 0.9706:  81%|[36m████████  [0m| 21/26 [00:22<00:05,  1.02s/it]Epoch: 0/10. Loss: 0.9706:  85%|[36m████████▍ [0m| 22/26 [00:22<00:04,  1.03s/it]Epoch: 0/10. Loss: 1.0065:  85%|[36m████████▍ [0m| 22/26 [00:23<00:04,  1.03s/it]Epoch: 0/10. Loss: 1.0065:  88%|[36m████████▊ [0m| 23/26 [00:23<00:03,  1.02s/it]Epoch: 0/10. Loss: 0.9328:  88%|[36m████████▊ [0m| 23/26 [00:24<00:03,  1.02s/it]Epoch: 0/10. Loss: 0.9328:  92%|[36m█████████▏[0m| 24/26 [00:24<00:01,  1.02it/s]Epoch: 0/10. Loss: 0.9323:  92%|[36m█████████▏[0m| 24/26 [00:24<00:01,  1.02it/s]Epoch: 0/10. Loss: 0.9323:  96%|[36m█████████▌[0m| 25/26 [00:25<00:00,  1.06it/s]Epoch: 0/10. Loss: 1.0231:  96%|[36m█████████▌[0m| 25/26 [00:25<00:00,  1.06it/s]Epoch: 0/10. Loss: 1.0231: 100%|[36m██████████[0m| 26/26 [00:26<00:00,  1.05it/s]Epoch: 0/10. Loss: 1.0231: 100%|[36m██████████[0m| 26/26 [00:26<00:00,  1.00s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:05,  1.19it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:05,  1.10s/it] 43%|[33m████▎     [0m| 3/7 [00:02<00:03,  1.03it/s] 57%|[33m█████▋    [0m| 4/7 [00:04<00:03,  1.16s/it] 71%|[33m███████▏  [0m| 5/7 [00:04<00:01,  1.09it/s] 86%|[33m████████▌ [0m| 6/7 [00:05<00:00,  1.08it/s]100%|[33m██████████[0m| 7/7 [00:06<00:00,  1.31it/s]100%|[33m██████████[0m| 7/7 [00:06<00:00,  1.12it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 1/10. Loss: 0.9401:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 1/10. Loss: 0.9401:   4%|[36m▍         [0m| 1/26 [00:00<00:21,  1.16it/s]Epoch: 1/10. Loss: 0.9641:   4%|[36m▍         [0m| 1/26 [00:01<00:21,  1.16it/s]Epoch: 1/10. Loss: 0.9641:   8%|[36m▊         [0m| 2/26 [00:01<00:23,  1.03it/s]Epoch: 1/10. Loss: 0.9752:   8%|[36m▊         [0m| 2/26 [00:02<00:23,  1.03it/s]Epoch: 1/10. Loss: 0.9752:  12%|[36m█▏        [0m| 3/26 [00:02<00:21,  1.08it/s]Epoch: 1/10. Loss: 0.9357:  12%|[36m█▏        [0m| 3/26 [00:05<00:21,  1.08it/s]Epoch: 1/10. Loss: 0.9357:  15%|[36m█▌        [0m| 4/26 [00:05<00:36,  1.65s/it]Epoch: 1/10. Loss: 0.9672:  15%|[36m█▌        [0m| 4/26 [00:07<00:36,  1.65s/it]Epoch: 1/10. Loss: 0.9672:  19%|[36m█▉        [0m| 5/26 [00:07<00:35,  1.71s/it]Epoch: 1/10. Loss: 0.9146:  19%|[36m█▉        [0m| 5/26 [00:08<00:35,  1.71s/it]Epoch: 1/10. Loss: 0.9146:  23%|[36m██▎       [0m| 6/26 [00:08<00:29,  1.46s/it]Epoch: 1/10. Loss: 1.0128:  23%|[36m██▎       [0m| 6/26 [00:09<00:29,  1.46s/it]Epoch: 1/10. Loss: 1.0128:  27%|[36m██▋       [0m| 7/26 [00:09<00:25,  1.33s/it]Epoch: 1/10. Loss: 0.9860:  27%|[36m██▋       [0m| 7/26 [00:10<00:25,  1.33s/it]Epoch: 1/10. Loss: 0.9860:  31%|[36m███       [0m| 8/26 [00:10<00:21,  1.17s/it]Epoch: 1/10. Loss: 0.9534:  31%|[36m███       [0m| 8/26 [00:11<00:21,  1.17s/it]Epoch: 1/10. Loss: 0.9534:  35%|[36m███▍      [0m| 9/26 [00:11<00:19,  1.15s/it]Epoch: 1/10. Loss: 0.9800:  35%|[36m███▍      [0m| 9/26 [00:12<00:19,  1.15s/it]Epoch: 1/10. Loss: 0.9800:  38%|[36m███▊      [0m| 10/26 [00:12<00:17,  1.08s/it]Epoch: 1/10. Loss: 0.9593:  38%|[36m███▊      [0m| 10/26 [00:13<00:17,  1.08s/it]Epoch: 1/10. Loss: 0.9593:  42%|[36m████▏     [0m| 11/26 [00:13<00:15,  1.06s/it]Epoch: 1/10. Loss: 0.9735:  42%|[36m████▏     [0m| 11/26 [00:13<00:15,  1.06s/it]Epoch: 1/10. Loss: 0.9735:  46%|[36m████▌     [0m| 12/26 [00:13<00:13,  1.06it/s]Epoch: 1/10. Loss: 1.0074:  46%|[36m████▌     [0m| 12/26 [00:15<00:13,  1.06it/s]Epoch: 1/10. Loss: 1.0074:  50%|[36m█████     [0m| 13/26 [00:15<00:13,  1.03s/it]Epoch: 1/10. Loss: 0.9982:  50%|[36m█████     [0m| 13/26 [00:16<00:13,  1.03s/it]Epoch: 1/10. Loss: 0.9982:  54%|[36m█████▍    [0m| 14/26 [00:16<00:12,  1.00s/it]Epoch: 1/10. Loss: 0.9237:  54%|[36m█████▍    [0m| 14/26 [00:17<00:12,  1.00s/it]Epoch: 1/10. Loss: 0.9237:  58%|[36m█████▊    [0m| 15/26 [00:17<00:11,  1.02s/it]Epoch: 1/10. Loss: 0.8749:  58%|[36m█████▊    [0m| 15/26 [00:18<00:11,  1.02s/it]Epoch: 1/10. Loss: 0.8749:  62%|[36m██████▏   [0m| 16/26 [00:18<00:10,  1.07s/it]Epoch: 1/10. Loss: 0.9001:  62%|[36m██████▏   [0m| 16/26 [00:19<00:10,  1.07s/it]Epoch: 1/10. Loss: 0.9001:  65%|[36m██████▌   [0m| 17/26 [00:19<00:09,  1.01s/it]Epoch: 1/10. Loss: 0.9182:  65%|[36m██████▌   [0m| 17/26 [00:20<00:09,  1.01s/it]Epoch: 1/10. Loss: 0.9182:  69%|[36m██████▉   [0m| 18/26 [00:20<00:08,  1.04s/it]Epoch: 1/10. Loss: 1.0420:  69%|[36m██████▉   [0m| 18/26 [00:22<00:08,  1.04s/it]Epoch: 1/10. Loss: 1.0420:  73%|[36m███████▎  [0m| 19/26 [00:22<00:08,  1.26s/it]Epoch: 1/10. Loss: 0.8957:  73%|[36m███████▎  [0m| 19/26 [00:23<00:08,  1.26s/it]Epoch: 1/10. Loss: 0.8957:  77%|[36m███████▋  [0m| 20/26 [00:23<00:07,  1.29s/it]Epoch: 1/10. Loss: 0.8853:  77%|[36m███████▋  [0m| 20/26 [00:24<00:07,  1.29s/it]Epoch: 1/10. Loss: 0.8853:  81%|[36m████████  [0m| 21/26 [00:24<00:06,  1.29s/it]Epoch: 1/10. Loss: 0.9398:  81%|[36m████████  [0m| 21/26 [00:25<00:06,  1.29s/it]Epoch: 1/10. Loss: 0.9398:  85%|[36m████████▍ [0m| 22/26 [00:25<00:04,  1.23s/it]Epoch: 1/10. Loss: 0.9213:  85%|[36m████████▍ [0m| 22/26 [00:26<00:04,  1.23s/it]Epoch: 1/10. Loss: 0.9213:  88%|[36m████████▊ [0m| 23/26 [00:26<00:03,  1.16s/it]Epoch: 1/10. Loss: 0.8657:  88%|[36m████████▊ [0m| 23/26 [00:28<00:03,  1.16s/it]Epoch: 1/10. Loss: 0.8657:  92%|[36m█████████▏[0m| 24/26 [00:28<00:02,  1.23s/it]Epoch: 1/10. Loss: 0.8596:  92%|[36m█████████▏[0m| 24/26 [00:29<00:02,  1.23s/it]Epoch: 1/10. Loss: 0.8596:  96%|[36m█████████▌[0m| 25/26 [00:29<00:01,  1.20s/it]Epoch: 1/10. Loss: 1.0364:  96%|[36m█████████▌[0m| 25/26 [00:29<00:01,  1.20s/it]Epoch: 1/10. Loss: 1.0364: 100%|[36m██████████[0m| 26/26 [00:29<00:00,  1.01s/it]Epoch: 1/10. Loss: 1.0364: 100%|[36m██████████[0m| 26/26 [00:29<00:00,  1.15s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:05,  1.12it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:05,  1.04s/it] 43%|[33m████▎     [0m| 3/7 [00:02<00:03,  1.06it/s] 57%|[33m█████▋    [0m| 4/7 [00:04<00:03,  1.10s/it] 71%|[33m███████▏  [0m| 5/7 [00:04<00:01,  1.13it/s] 86%|[33m████████▌ [0m| 6/7 [00:05<00:00,  1.11it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.44it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.18it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 2/10. Loss: 0.8492:   0%|[36m          [0m| 0/26 [00:02<?, ?it/s]Epoch: 2/10. Loss: 0.8492:   4%|[36m▍         [0m| 1/26 [00:02<00:55,  2.21s/it]Epoch: 2/10. Loss: 0.9596:   4%|[36m▍         [0m| 1/26 [00:03<00:55,  2.21s/it]Epoch: 2/10. Loss: 0.9596:   8%|[36m▊         [0m| 2/26 [00:03<00:39,  1.66s/it]Epoch: 2/10. Loss: 0.9205:   8%|[36m▊         [0m| 2/26 [00:04<00:39,  1.66s/it]Epoch: 2/10. Loss: 0.9205:  12%|[36m█▏        [0m| 3/26 [00:04<00:28,  1.26s/it]Epoch: 2/10. Loss: 1.0098:  12%|[36m█▏        [0m| 3/26 [00:05<00:28,  1.26s/it]Epoch: 2/10. Loss: 1.0098:  15%|[36m█▌        [0m| 4/26 [00:05<00:25,  1.18s/it]Epoch: 2/10. Loss: 0.9720:  15%|[36m█▌        [0m| 4/26 [00:06<00:25,  1.18s/it]Epoch: 2/10. Loss: 0.9720:  19%|[36m█▉        [0m| 5/26 [00:06<00:23,  1.10s/it]Epoch: 2/10. Loss: 0.8943:  19%|[36m█▉        [0m| 5/26 [00:07<00:23,  1.10s/it]Epoch: 2/10. Loss: 0.8943:  23%|[36m██▎       [0m| 6/26 [00:07<00:21,  1.06s/it]Epoch: 2/10. Loss: 0.8707:  23%|[36m██▎       [0m| 6/26 [00:08<00:21,  1.06s/it]Epoch: 2/10. Loss: 0.8707:  27%|[36m██▋       [0m| 7/26 [00:08<00:20,  1.07s/it]Epoch: 2/10. Loss: 1.0272:  27%|[36m██▋       [0m| 7/26 [00:09<00:20,  1.07s/it]Epoch: 2/10. Loss: 1.0272:  31%|[36m███       [0m| 8/26 [00:09<00:19,  1.07s/it]Epoch: 2/10. Loss: 1.0680:  31%|[36m███       [0m| 8/26 [00:10<00:19,  1.07s/it]Epoch: 2/10. Loss: 1.0680:  35%|[36m███▍      [0m| 9/26 [00:10<00:17,  1.06s/it]Epoch: 2/10. Loss: 0.9664:  35%|[36m███▍      [0m| 9/26 [00:11<00:17,  1.06s/it]Epoch: 2/10. Loss: 0.9664:  38%|[36m███▊      [0m| 10/26 [00:11<00:17,  1.11s/it]Epoch: 2/10. Loss: 0.9734:  38%|[36m███▊      [0m| 10/26 [00:12<00:17,  1.11s/it]Epoch: 2/10. Loss: 0.9734:  42%|[36m████▏     [0m| 11/26 [00:12<00:16,  1.07s/it]Epoch: 2/10. Loss: 0.8895:  42%|[36m████▏     [0m| 11/26 [00:13<00:16,  1.07s/it]Epoch: 2/10. Loss: 0.8895:  46%|[36m████▌     [0m| 12/26 [00:13<00:14,  1.04s/it]Epoch: 2/10. Loss: 0.9420:  46%|[36m████▌     [0m| 12/26 [00:14<00:14,  1.04s/it]Epoch: 2/10. Loss: 0.9420:  50%|[36m█████     [0m| 13/26 [00:14<00:13,  1.03s/it]Epoch: 2/10. Loss: 0.9001:  50%|[36m█████     [0m| 13/26 [00:15<00:13,  1.03s/it]Epoch: 2/10. Loss: 0.9001:  54%|[36m█████▍    [0m| 14/26 [00:15<00:13,  1.11s/it]Epoch: 2/10. Loss: 0.8560:  54%|[36m█████▍    [0m| 14/26 [00:16<00:13,  1.11s/it]Epoch: 2/10. Loss: 0.8560:  58%|[36m█████▊    [0m| 15/26 [00:16<00:10,  1.01it/s]Epoch: 2/10. Loss: 0.9867:  58%|[36m█████▊    [0m| 15/26 [00:17<00:10,  1.01it/s]Epoch: 2/10. Loss: 0.9867:  62%|[36m██████▏   [0m| 16/26 [00:17<00:10,  1.01s/it]Epoch: 2/10. Loss: 0.7753:  62%|[36m██████▏   [0m| 16/26 [00:18<00:10,  1.01s/it]Epoch: 2/10. Loss: 0.7753:  65%|[36m██████▌   [0m| 17/26 [00:18<00:09,  1.02s/it]Epoch: 2/10. Loss: 0.8584:  65%|[36m██████▌   [0m| 17/26 [00:19<00:09,  1.02s/it]Epoch: 2/10. Loss: 0.8584:  69%|[36m██████▉   [0m| 18/26 [00:19<00:08,  1.04s/it]Epoch: 2/10. Loss: 0.9059:  69%|[36m██████▉   [0m| 18/26 [00:20<00:08,  1.04s/it]Epoch: 2/10. Loss: 0.9059:  73%|[36m███████▎  [0m| 19/26 [00:20<00:07,  1.03s/it]Epoch: 2/10. Loss: 1.0005:  73%|[36m███████▎  [0m| 19/26 [00:21<00:07,  1.03s/it]Epoch: 2/10. Loss: 1.0005:  77%|[36m███████▋  [0m| 20/26 [00:21<00:05,  1.04it/s]Epoch: 2/10. Loss: 0.9431:  77%|[36m███████▋  [0m| 20/26 [00:22<00:05,  1.04it/s]Epoch: 2/10. Loss: 0.9431:  81%|[36m████████  [0m| 21/26 [00:22<00:05,  1.08s/it]Epoch: 2/10. Loss: 0.8701:  81%|[36m████████  [0m| 21/26 [00:26<00:05,  1.08s/it]Epoch: 2/10. Loss: 0.8701:  85%|[36m████████▍ [0m| 22/26 [00:26<00:07,  1.88s/it]Epoch: 2/10. Loss: 1.0746:  85%|[36m████████▍ [0m| 22/26 [00:28<00:07,  1.88s/it]Epoch: 2/10. Loss: 1.0746:  88%|[36m████████▊ [0m| 23/26 [00:28<00:05,  1.81s/it]Epoch: 2/10. Loss: 0.8758:  88%|[36m████████▊ [0m| 23/26 [00:30<00:05,  1.81s/it]Epoch: 2/10. Loss: 0.8758:  92%|[36m█████████▏[0m| 24/26 [00:30<00:03,  1.92s/it]Epoch: 2/10. Loss: 1.0052:  92%|[36m█████████▏[0m| 24/26 [00:33<00:03,  1.92s/it]Epoch: 2/10. Loss: 1.0052:  96%|[36m█████████▌[0m| 25/26 [00:33<00:02,  2.28s/it]Epoch: 2/10. Loss: 0.9620:  96%|[36m█████████▌[0m| 25/26 [00:34<00:02,  2.28s/it]Epoch: 2/10. Loss: 0.9620: 100%|[36m██████████[0m| 26/26 [00:34<00:00,  1.98s/it]Epoch: 2/10. Loss: 0.9620: 100%|[36m██████████[0m| 26/26 [00:34<00:00,  1.34s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:05,  1.12it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:05,  1.02s/it] 43%|[33m████▎     [0m| 3/7 [00:02<00:03,  1.07it/s] 57%|[33m█████▋    [0m| 4/7 [00:04<00:03,  1.08s/it] 71%|[33m███████▏  [0m| 5/7 [00:04<00:01,  1.15it/s] 86%|[33m████████▌ [0m| 6/7 [00:05<00:00,  1.07it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.40it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.17it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 3/10. Loss: 0.8494:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 3/10. Loss: 0.8494:   4%|[36m▍         [0m| 1/26 [00:00<00:21,  1.15it/s]Epoch: 3/10. Loss: 1.0153:   4%|[36m▍         [0m| 1/26 [00:01<00:21,  1.15it/s]Epoch: 3/10. Loss: 1.0153:   8%|[36m▊         [0m| 2/26 [00:01<00:21,  1.10it/s]Epoch: 3/10. Loss: 0.9397:   8%|[36m▊         [0m| 2/26 [00:02<00:21,  1.10it/s]Epoch: 3/10. Loss: 0.9397:  12%|[36m█▏        [0m| 3/26 [00:03<00:24,  1.05s/it]Epoch: 3/10. Loss: 0.9056:  12%|[36m█▏        [0m| 3/26 [00:04<00:24,  1.05s/it]Epoch: 3/10. Loss: 0.9056:  15%|[36m█▌        [0m| 4/26 [00:04<00:23,  1.08s/it]Epoch: 3/10. Loss: 1.0102:  15%|[36m█▌        [0m| 4/26 [00:05<00:23,  1.08s/it]Epoch: 3/10. Loss: 1.0102:  19%|[36m█▉        [0m| 5/26 [00:05<00:22,  1.06s/it]Epoch: 3/10. Loss: 0.9205:  19%|[36m█▉        [0m| 5/26 [00:06<00:22,  1.06s/it]Epoch: 3/10. Loss: 0.9205:  23%|[36m██▎       [0m| 6/26 [00:06<00:21,  1.10s/it]Epoch: 3/10. Loss: 0.9263:  23%|[36m██▎       [0m| 6/26 [00:07<00:21,  1.10s/it]Epoch: 3/10. Loss: 0.9263:  27%|[36m██▋       [0m| 7/26 [00:07<00:20,  1.08s/it]Epoch: 3/10. Loss: 0.9180:  27%|[36m██▋       [0m| 7/26 [00:08<00:20,  1.08s/it]Epoch: 3/10. Loss: 0.9180:  31%|[36m███       [0m| 8/26 [00:08<00:18,  1.01s/it]Epoch: 3/10. Loss: 0.9877:  31%|[36m███       [0m| 8/26 [00:09<00:18,  1.01s/it]Epoch: 3/10. Loss: 0.9877:  35%|[36m███▍      [0m| 9/26 [00:09<00:16,  1.03it/s]Epoch: 3/10. Loss: 0.9088:  35%|[36m███▍      [0m| 9/26 [00:10<00:16,  1.03it/s]Epoch: 3/10. Loss: 0.9088:  38%|[36m███▊      [0m| 10/26 [00:10<00:15,  1.04it/s]Epoch: 3/10. Loss: 0.8953:  38%|[36m███▊      [0m| 10/26 [00:11<00:15,  1.04it/s]Epoch: 3/10. Loss: 0.8953:  42%|[36m████▏     [0m| 11/26 [00:11<00:15,  1.05s/it]Epoch: 3/10. Loss: 0.9327:  42%|[36m████▏     [0m| 11/26 [00:12<00:15,  1.05s/it]Epoch: 3/10. Loss: 0.9327:  46%|[36m████▌     [0m| 12/26 [00:12<00:14,  1.04s/it]Epoch: 3/10. Loss: 1.0141:  46%|[36m████▌     [0m| 12/26 [00:13<00:14,  1.04s/it]Epoch: 3/10. Loss: 1.0141:  50%|[36m█████     [0m| 13/26 [00:13<00:13,  1.00s/it]Epoch: 3/10. Loss: 0.8802:  50%|[36m█████     [0m| 13/26 [00:14<00:13,  1.00s/it]Epoch: 3/10. Loss: 0.8802:  54%|[36m█████▍    [0m| 14/26 [00:14<00:12,  1.03s/it]Epoch: 3/10. Loss: 0.9184:  54%|[36m█████▍    [0m| 14/26 [00:15<00:12,  1.03s/it]Epoch: 3/10. Loss: 0.9184:  58%|[36m█████▊    [0m| 15/26 [00:15<00:11,  1.02s/it]Epoch: 3/10. Loss: 0.9151:  58%|[36m█████▊    [0m| 15/26 [00:16<00:11,  1.02s/it]Epoch: 3/10. Loss: 0.9151:  62%|[36m██████▏   [0m| 16/26 [00:16<00:09,  1.01it/s]Epoch: 3/10. Loss: 0.9331:  62%|[36m██████▏   [0m| 16/26 [00:17<00:09,  1.01it/s]Epoch: 3/10. Loss: 0.9331:  65%|[36m██████▌   [0m| 17/26 [00:17<00:08,  1.05it/s]Epoch: 3/10. Loss: 0.9764:  65%|[36m██████▌   [0m| 17/26 [00:17<00:08,  1.05it/s]Epoch: 3/10. Loss: 0.9764:  69%|[36m██████▉   [0m| 18/26 [00:17<00:07,  1.08it/s]Epoch: 3/10. Loss: 0.9454:  69%|[36m██████▉   [0m| 18/26 [00:18<00:07,  1.08it/s]Epoch: 3/10. Loss: 0.9454:  73%|[36m███████▎  [0m| 19/26 [00:18<00:06,  1.07it/s]Epoch: 3/10. Loss: 0.9132:  73%|[36m███████▎  [0m| 19/26 [00:19<00:06,  1.07it/s]Epoch: 3/10. Loss: 0.9132:  77%|[36m███████▋  [0m| 20/26 [00:19<00:05,  1.06it/s]Epoch: 3/10. Loss: 0.8802:  77%|[36m███████▋  [0m| 20/26 [00:20<00:05,  1.06it/s]Epoch: 3/10. Loss: 0.8802:  81%|[36m████████  [0m| 21/26 [00:20<00:04,  1.10it/s]Epoch: 3/10. Loss: 1.0513:  81%|[36m████████  [0m| 21/26 [00:21<00:04,  1.10it/s]Epoch: 3/10. Loss: 1.0513:  85%|[36m████████▍ [0m| 22/26 [00:21<00:03,  1.09it/s]Epoch: 3/10. Loss: 0.8842:  85%|[36m████████▍ [0m| 22/26 [00:22<00:03,  1.09it/s]Epoch: 3/10. Loss: 0.8842:  88%|[36m████████▊ [0m| 23/26 [00:22<00:02,  1.03it/s]Epoch: 3/10. Loss: 0.7875:  88%|[36m████████▊ [0m| 23/26 [00:23<00:02,  1.03it/s]Epoch: 3/10. Loss: 0.7875:  92%|[36m█████████▏[0m| 24/26 [00:23<00:01,  1.07it/s]Epoch: 3/10. Loss: 0.9318:  92%|[36m█████████▏[0m| 24/26 [00:24<00:01,  1.07it/s]Epoch: 3/10. Loss: 0.9318:  96%|[36m█████████▌[0m| 25/26 [00:24<00:00,  1.02it/s]Epoch: 3/10. Loss: 0.7919:  96%|[36m█████████▌[0m| 25/26 [00:25<00:00,  1.02it/s]Epoch: 3/10. Loss: 0.7919: 100%|[36m██████████[0m| 26/26 [00:25<00:00,  1.04it/s]Epoch: 3/10. Loss: 0.7919: 100%|[36m██████████[0m| 26/26 [00:25<00:00,  1.01it/s]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:05,  1.09it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:05,  1.03s/it] 43%|[33m████▎     [0m| 3/7 [00:02<00:03,  1.08it/s] 57%|[33m█████▋    [0m| 4/7 [00:04<00:03,  1.09s/it] 71%|[33m███████▏  [0m| 5/7 [00:04<00:01,  1.15it/s] 86%|[33m████████▌ [0m| 6/7 [00:05<00:00,  1.12it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.44it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.19it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 4/10. Loss: 0.8293:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 4/10. Loss: 0.8293:   4%|[36m▍         [0m| 1/26 [00:00<00:22,  1.12it/s]Epoch: 4/10. Loss: 0.9650:   4%|[36m▍         [0m| 1/26 [00:01<00:22,  1.12it/s]Epoch: 4/10. Loss: 0.9650:   8%|[36m▊         [0m| 2/26 [00:01<00:20,  1.17it/s]Epoch: 4/10. Loss: 0.9486:   8%|[36m▊         [0m| 2/26 [00:03<00:20,  1.17it/s]Epoch: 4/10. Loss: 0.9486:  12%|[36m█▏        [0m| 3/26 [00:03<00:33,  1.46s/it]Epoch: 4/10. Loss: 0.8917:  12%|[36m█▏        [0m| 3/26 [00:04<00:33,  1.46s/it]Epoch: 4/10. Loss: 0.8917:  15%|[36m█▌        [0m| 4/26 [00:04<00:27,  1.26s/it]Epoch: 4/10. Loss: 0.9565:  15%|[36m█▌        [0m| 4/26 [00:05<00:27,  1.26s/it]Epoch: 4/10. Loss: 0.9565:  19%|[36m█▉        [0m| 5/26 [00:05<00:24,  1.15s/it]Epoch: 4/10. Loss: 1.0361:  19%|[36m█▉        [0m| 5/26 [00:06<00:24,  1.15s/it]Epoch: 4/10. Loss: 1.0361:  23%|[36m██▎       [0m| 6/26 [00:06<00:21,  1.08s/it]Epoch: 4/10. Loss: 0.8860:  23%|[36m██▎       [0m| 6/26 [00:07<00:21,  1.08s/it]Epoch: 4/10. Loss: 0.8860:  27%|[36m██▋       [0m| 7/26 [00:07<00:20,  1.05s/it]Epoch: 4/10. Loss: 0.9499:  27%|[36m██▋       [0m| 7/26 [00:08<00:20,  1.05s/it]Epoch: 4/10. Loss: 0.9499:  31%|[36m███       [0m| 8/26 [00:08<00:18,  1.03s/it]Epoch: 4/10. Loss: 1.0412:  31%|[36m███       [0m| 8/26 [00:09<00:18,  1.03s/it]Epoch: 4/10. Loss: 1.0412:  35%|[36m███▍      [0m| 9/26 [00:09<00:17,  1.02s/it]Epoch: 4/10. Loss: 0.8019:  35%|[36m███▍      [0m| 9/26 [00:10<00:17,  1.02s/it]Epoch: 4/10. Loss: 0.8019:  38%|[36m███▊      [0m| 10/26 [00:10<00:16,  1.01s/it]Epoch: 4/10. Loss: 0.8512:  38%|[36m███▊      [0m| 10/26 [00:11<00:16,  1.01s/it]Epoch: 4/10. Loss: 0.8512:  42%|[36m████▏     [0m| 11/26 [00:11<00:14,  1.05it/s]Epoch: 4/10. Loss: 0.7857:  42%|[36m████▏     [0m| 11/26 [00:12<00:14,  1.05it/s]Epoch: 4/10. Loss: 0.7857:  46%|[36m████▌     [0m| 12/26 [00:12<00:14,  1.02s/it]Epoch: 4/10. Loss: 0.8305:  46%|[36m████▌     [0m| 12/26 [00:13<00:14,  1.02s/it]Epoch: 4/10. Loss: 0.8305:  50%|[36m█████     [0m| 13/26 [00:13<00:12,  1.01it/s]Epoch: 4/10. Loss: 0.8141:  50%|[36m█████     [0m| 13/26 [00:14<00:12,  1.01it/s]Epoch: 4/10. Loss: 0.8141:  54%|[36m█████▍    [0m| 14/26 [00:14<00:11,  1.03it/s]Epoch: 4/10. Loss: 0.9973:  54%|[36m█████▍    [0m| 14/26 [00:15<00:11,  1.03it/s]Epoch: 4/10. Loss: 0.9973:  58%|[36m█████▊    [0m| 15/26 [00:15<00:10,  1.02it/s]Epoch: 4/10. Loss: 0.9369:  58%|[36m█████▊    [0m| 15/26 [00:16<00:10,  1.02it/s]Epoch: 4/10. Loss: 0.9369:  62%|[36m██████▏   [0m| 16/26 [00:16<00:09,  1.01it/s]Epoch: 4/10. Loss: 0.8816:  62%|[36m██████▏   [0m| 16/26 [00:17<00:09,  1.01it/s]Epoch: 4/10. Loss: 0.8816:  65%|[36m██████▌   [0m| 17/26 [00:17<00:08,  1.02it/s]Epoch: 4/10. Loss: 0.7903:  65%|[36m██████▌   [0m| 17/26 [00:18<00:08,  1.02it/s]Epoch: 4/10. Loss: 0.7903:  69%|[36m██████▉   [0m| 18/26 [00:18<00:07,  1.00it/s]Epoch: 4/10. Loss: 0.8152:  69%|[36m██████▉   [0m| 18/26 [00:19<00:07,  1.00it/s]Epoch: 4/10. Loss: 0.8152:  73%|[36m███████▎  [0m| 19/26 [00:19<00:06,  1.01it/s]Epoch: 4/10. Loss: 0.8072:  73%|[36m███████▎  [0m| 19/26 [00:20<00:06,  1.01it/s]Epoch: 4/10. Loss: 0.8072:  77%|[36m███████▋  [0m| 20/26 [00:20<00:06,  1.00s/it]Epoch: 4/10. Loss: 0.9649:  77%|[36m███████▋  [0m| 20/26 [00:21<00:06,  1.00s/it]Epoch: 4/10. Loss: 0.9649:  81%|[36m████████  [0m| 21/26 [00:21<00:05,  1.01s/it]Epoch: 4/10. Loss: 0.9455:  81%|[36m████████  [0m| 21/26 [00:22<00:05,  1.01s/it]Epoch: 4/10. Loss: 0.9455:  85%|[36m████████▍ [0m| 22/26 [00:22<00:04,  1.06s/it]Epoch: 4/10. Loss: 0.9215:  85%|[36m████████▍ [0m| 22/26 [00:24<00:04,  1.06s/it]Epoch: 4/10. Loss: 0.9215:  88%|[36m████████▊ [0m| 23/26 [00:24<00:03,  1.17s/it]Epoch: 4/10. Loss: 0.8820:  88%|[36m████████▊ [0m| 23/26 [00:25<00:03,  1.17s/it]Epoch: 4/10. Loss: 0.8820:  92%|[36m█████████▏[0m| 24/26 [00:25<00:02,  1.07s/it]Epoch: 4/10. Loss: 0.9503:  92%|[36m█████████▏[0m| 24/26 [00:26<00:02,  1.07s/it]Epoch: 4/10. Loss: 0.9503:  96%|[36m█████████▌[0m| 25/26 [00:26<00:01,  1.06s/it]Epoch: 4/10. Loss: 0.9016:  96%|[36m█████████▌[0m| 25/26 [00:26<00:01,  1.06s/it]Epoch: 4/10. Loss: 0.9016: 100%|[36m██████████[0m| 26/26 [00:26<00:00,  1.01s/it]Epoch: 4/10. Loss: 0.9016: 100%|[36m██████████[0m| 26/26 [00:26<00:00,  1.04s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:05,  1.09it/s] 29%|[33m██▊       [0m| 2/7 [00:01<00:05,  1.01s/it] 43%|[33m████▎     [0m| 3/7 [00:02<00:03,  1.13it/s] 57%|[33m█████▋    [0m| 4/7 [00:06<00:05,  1.90s/it] 71%|[33m███████▏  [0m| 5/7 [00:08<00:04,  2.12s/it] 86%|[33m████████▌ [0m| 6/7 [00:09<00:01,  1.68s/it]100%|[33m██████████[0m| 7/7 [00:09<00:00,  1.21s/it]100%|[33m██████████[0m| 7/7 [00:09<00:00,  1.39s/it]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 5/10. Loss: 0.7905:   0%|[36m          [0m| 0/26 [00:01<?, ?it/s]Epoch: 5/10. Loss: 0.7905:   4%|[36m▍         [0m| 1/26 [00:01<00:32,  1.32s/it]Epoch: 5/10. Loss: 0.9157:   4%|[36m▍         [0m| 1/26 [00:02<00:32,  1.32s/it]Epoch: 5/10. Loss: 0.9157:   8%|[36m▊         [0m| 2/26 [00:02<00:27,  1.16s/it]Epoch: 5/10. Loss: 0.8681:   8%|[36m▊         [0m| 2/26 [00:04<00:27,  1.16s/it]Epoch: 5/10. Loss: 0.8681:  12%|[36m█▏        [0m| 3/26 [00:04<00:41,  1.80s/it]Epoch: 5/10. Loss: 1.0121:  12%|[36m█▏        [0m| 3/26 [00:06<00:41,  1.80s/it]Epoch: 5/10. Loss: 1.0121:  15%|[36m█▌        [0m| 4/26 [00:06<00:38,  1.74s/it]Epoch: 5/10. Loss: 0.8703:  15%|[36m█▌        [0m| 4/26 [00:07<00:38,  1.74s/it]Epoch: 5/10. Loss: 0.8703:  19%|[36m█▉        [0m| 5/26 [00:07<00:31,  1.52s/it]Epoch: 5/10. Loss: 0.8114:  19%|[36m█▉        [0m| 5/26 [00:10<00:31,  1.52s/it]Epoch: 5/10. Loss: 0.8114:  23%|[36m██▎       [0m| 6/26 [00:10<00:38,  1.92s/it]Epoch: 5/10. Loss: 0.8940:  23%|[36m██▎       [0m| 6/26 [00:11<00:38,  1.92s/it]Epoch: 5/10. Loss: 0.8940:  27%|[36m██▋       [0m| 7/26 [00:11<00:30,  1.61s/it]Epoch: 5/10. Loss: 0.9596:  27%|[36m██▋       [0m| 7/26 [00:13<00:30,  1.61s/it]Epoch: 5/10. Loss: 0.9596:  31%|[36m███       [0m| 8/26 [00:13<00:30,  1.70s/it]Epoch: 5/10. Loss: 0.8322:  31%|[36m███       [0m| 8/26 [00:14<00:30,  1.70s/it]Epoch: 5/10. Loss: 0.8322:  35%|[36m███▍      [0m| 9/26 [00:14<00:25,  1.49s/it]Epoch: 5/10. Loss: 0.8181:  35%|[36m███▍      [0m| 9/26 [00:15<00:25,  1.49s/it]Epoch: 5/10. Loss: 0.8181:  38%|[36m███▊      [0m| 10/26 [00:15<00:21,  1.32s/it]Epoch: 5/10. Loss: 0.8094:  38%|[36m███▊      [0m| 10/26 [00:15<00:21,  1.32s/it]Epoch: 5/10. Loss: 0.8094:  42%|[36m████▏     [0m| 11/26 [00:16<00:17,  1.16s/it]Epoch: 5/10. Loss: 0.8347:  42%|[36m████▏     [0m| 11/26 [00:17<00:17,  1.16s/it]Epoch: 5/10. Loss: 0.8347:  46%|[36m████▌     [0m| 12/26 [00:17<00:15,  1.13s/it]Epoch: 5/10. Loss: 0.8850:  46%|[36m████▌     [0m| 12/26 [00:18<00:15,  1.13s/it]Epoch: 5/10. Loss: 0.8850:  50%|[36m█████     [0m| 13/26 [00:18<00:14,  1.10s/it]Epoch: 5/10. Loss: 0.8277:  50%|[36m█████     [0m| 13/26 [00:19<00:14,  1.10s/it]Epoch: 5/10. Loss: 0.8277:  54%|[36m█████▍    [0m| 14/26 [00:19<00:12,  1.04s/it]Epoch: 5/10. Loss: 0.7875:  54%|[36m█████▍    [0m| 14/26 [00:21<00:12,  1.04s/it]Epoch: 5/10. Loss: 0.7875:  58%|[36m█████▊    [0m| 15/26 [00:21<00:15,  1.45s/it]Epoch: 5/10. Loss: 0.9292:  58%|[36m█████▊    [0m| 15/26 [00:22<00:15,  1.45s/it]Epoch: 5/10. Loss: 0.9292:  62%|[36m██████▏   [0m| 16/26 [00:22<00:12,  1.30s/it]Epoch: 5/10. Loss: 0.8028:  62%|[36m██████▏   [0m| 16/26 [00:23<00:12,  1.30s/it]Epoch: 5/10. Loss: 0.8028:  65%|[36m██████▌   [0m| 17/26 [00:23<00:10,  1.21s/it]Epoch: 5/10. Loss: 0.7839:  65%|[36m██████▌   [0m| 17/26 [00:24<00:10,  1.21s/it]Epoch: 5/10. Loss: 0.7839:  69%|[36m██████▉   [0m| 18/26 [00:24<00:09,  1.16s/it]Epoch: 5/10. Loss: 0.9163:  69%|[36m██████▉   [0m| 18/26 [00:25<00:09,  1.16s/it]Epoch: 5/10. Loss: 0.9163:  73%|[36m███████▎  [0m| 19/26 [00:25<00:07,  1.10s/it]Epoch: 5/10. Loss: 0.8357:  73%|[36m███████▎  [0m| 19/26 [00:26<00:07,  1.10s/it]Epoch: 5/10. Loss: 0.8357:  77%|[36m███████▋  [0m| 20/26 [00:26<00:06,  1.11s/it]Epoch: 5/10. Loss: 0.8794:  77%|[36m███████▋  [0m| 20/26 [00:27<00:06,  1.11s/it]Epoch: 5/10. Loss: 0.8794:  81%|[36m████████  [0m| 21/26 [00:27<00:05,  1.10s/it]Epoch: 5/10. Loss: 0.9036:  81%|[36m████████  [0m| 21/26 [00:28<00:05,  1.10s/it]Epoch: 5/10. Loss: 0.9036:  85%|[36m████████▍ [0m| 22/26 [00:28<00:04,  1.09s/it]Epoch: 5/10. Loss: 0.8307:  85%|[36m████████▍ [0m| 22/26 [00:29<00:04,  1.09s/it]Epoch: 5/10. Loss: 0.8307:  88%|[36m████████▊ [0m| 23/26 [00:29<00:03,  1.09s/it]Epoch: 5/10. Loss: 0.9252:  88%|[36m████████▊ [0m| 23/26 [00:30<00:03,  1.09s/it]Epoch: 5/10. Loss: 0.9252:  92%|[36m█████████▏[0m| 24/26 [00:30<00:02,  1.07s/it]Epoch: 5/10. Loss: 0.8164:  92%|[36m█████████▏[0m| 24/26 [00:31<00:02,  1.07s/it]Epoch: 5/10. Loss: 0.8164:  96%|[36m█████████▌[0m| 25/26 [00:31<00:01,  1.05s/it]Epoch: 5/10. Loss: 0.7937:  96%|[36m█████████▌[0m| 25/26 [00:32<00:01,  1.05s/it]Epoch: 5/10. Loss: 0.7937: 100%|[36m██████████[0m| 26/26 [00:32<00:00,  1.04it/s]Epoch: 5/10. Loss: 0.7937: 100%|[36m██████████[0m| 26/26 [00:32<00:00,  1.25s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:05,  1.09it/s] 29%|[33m██▊       [0m| 2/7 [00:01<00:05,  1.01s/it] 43%|[33m████▎     [0m| 3/7 [00:02<00:03,  1.12it/s] 57%|[33m█████▋    [0m| 4/7 [00:04<00:03,  1.04s/it] 71%|[33m███████▏  [0m| 5/7 [00:04<00:01,  1.20it/s] 86%|[33m████████▌ [0m| 6/7 [00:05<00:00,  1.19it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.54it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.25it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 6/10. Loss: 0.8660:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 6/10. Loss: 0.8660:   4%|[36m▍         [0m| 1/26 [00:01<00:25,  1.03s/it]Epoch: 6/10. Loss: 0.7824:   4%|[36m▍         [0m| 1/26 [00:01<00:25,  1.03s/it]Epoch: 6/10. Loss: 0.7824:   8%|[36m▊         [0m| 2/26 [00:01<00:22,  1.07it/s]Epoch: 6/10. Loss: 0.9920:   8%|[36m▊         [0m| 2/26 [00:02<00:22,  1.07it/s]Epoch: 6/10. Loss: 0.9920:  12%|[36m█▏        [0m| 3/26 [00:02<00:20,  1.14it/s]Epoch: 6/10. Loss: 0.8640:  12%|[36m█▏        [0m| 3/26 [00:03<00:20,  1.14it/s]Epoch: 6/10. Loss: 0.8640:  15%|[36m█▌        [0m| 4/26 [00:03<00:21,  1.04it/s]Epoch: 6/10. Loss: 0.7160:  15%|[36m█▌        [0m| 4/26 [00:04<00:21,  1.04it/s]Epoch: 6/10. Loss: 0.7160:  19%|[36m█▉        [0m| 5/26 [00:04<00:20,  1.00it/s]Epoch: 6/10. Loss: 0.8005:  19%|[36m█▉        [0m| 5/26 [00:05<00:20,  1.00it/s]Epoch: 6/10. Loss: 0.8005:  23%|[36m██▎       [0m| 6/26 [00:05<00:19,  1.00it/s]Epoch: 6/10. Loss: 0.7710:  23%|[36m██▎       [0m| 6/26 [00:06<00:19,  1.00it/s]Epoch: 6/10. Loss: 0.7710:  27%|[36m██▋       [0m| 7/26 [00:06<00:18,  1.02it/s]Epoch: 6/10. Loss: 0.8254:  27%|[36m██▋       [0m| 7/26 [00:07<00:18,  1.02it/s]Epoch: 6/10. Loss: 0.8254:  31%|[36m███       [0m| 8/26 [00:07<00:17,  1.02it/s]Epoch: 6/10. Loss: 0.7446:  31%|[36m███       [0m| 8/26 [00:10<00:17,  1.02it/s]Epoch: 6/10. Loss: 0.7446:  35%|[36m███▍      [0m| 9/26 [00:10<00:27,  1.64s/it]Epoch: 6/10. Loss: 0.8291:  35%|[36m███▍      [0m| 9/26 [00:12<00:27,  1.64s/it]Epoch: 6/10. Loss: 0.8291:  38%|[36m███▊      [0m| 10/26 [00:12<00:24,  1.50s/it]Epoch: 6/10. Loss: 0.9173:  38%|[36m███▊      [0m| 10/26 [00:14<00:24,  1.50s/it]Epoch: 6/10. Loss: 0.9173:  42%|[36m████▏     [0m| 11/26 [00:14<00:25,  1.73s/it]Epoch: 6/10. Loss: 0.8627:  42%|[36m████▏     [0m| 11/26 [00:15<00:25,  1.73s/it]Epoch: 6/10. Loss: 0.8627:  46%|[36m████▌     [0m| 12/26 [00:15<00:20,  1.45s/it]Epoch: 6/10. Loss: 0.8291:  46%|[36m████▌     [0m| 12/26 [00:16<00:20,  1.45s/it]Epoch: 6/10. Loss: 0.8291:  50%|[36m█████     [0m| 13/26 [00:16<00:17,  1.35s/it]Epoch: 6/10. Loss: 0.7158:  50%|[36m█████     [0m| 13/26 [00:18<00:17,  1.35s/it]Epoch: 6/10. Loss: 0.7158:  54%|[36m█████▍    [0m| 14/26 [00:18<00:18,  1.53s/it]Epoch: 6/10. Loss: 0.7856:  54%|[36m█████▍    [0m| 14/26 [00:19<00:18,  1.53s/it]Epoch: 6/10. Loss: 0.7856:  58%|[36m█████▊    [0m| 15/26 [00:19<00:14,  1.36s/it]Epoch: 6/10. Loss: 0.7746:  58%|[36m█████▊    [0m| 15/26 [00:20<00:14,  1.36s/it]Epoch: 6/10. Loss: 0.7746:  62%|[36m██████▏   [0m| 16/26 [00:20<00:12,  1.24s/it]Epoch: 6/10. Loss: 0.8428:  62%|[36m██████▏   [0m| 16/26 [00:22<00:12,  1.24s/it]Epoch: 6/10. Loss: 0.8428:  65%|[36m██████▌   [0m| 17/26 [00:22<00:15,  1.71s/it]Epoch: 6/10. Loss: 0.9074:  65%|[36m██████▌   [0m| 17/26 [00:23<00:15,  1.71s/it]Epoch: 6/10. Loss: 0.9074:  69%|[36m██████▉   [0m| 18/26 [00:23<00:12,  1.51s/it]Epoch: 6/10. Loss: 0.8180:  69%|[36m██████▉   [0m| 18/26 [00:24<00:12,  1.51s/it]Epoch: 6/10. Loss: 0.8180:  73%|[36m███████▎  [0m| 19/26 [00:24<00:09,  1.36s/it]Epoch: 6/10. Loss: 0.8382:  73%|[36m███████▎  [0m| 19/26 [00:26<00:09,  1.36s/it]Epoch: 6/10. Loss: 0.8382:  77%|[36m███████▋  [0m| 20/26 [00:26<00:07,  1.30s/it]Epoch: 6/10. Loss: 0.8285:  77%|[36m███████▋  [0m| 20/26 [00:27<00:07,  1.30s/it]Epoch: 6/10. Loss: 0.8285:  81%|[36m████████  [0m| 21/26 [00:27<00:05,  1.20s/it]Epoch: 6/10. Loss: 0.9160:  81%|[36m████████  [0m| 21/26 [00:28<00:05,  1.20s/it]Epoch: 6/10. Loss: 0.9160:  85%|[36m████████▍ [0m| 22/26 [00:28<00:04,  1.19s/it]Epoch: 6/10. Loss: 0.8296:  85%|[36m████████▍ [0m| 22/26 [00:29<00:04,  1.19s/it]Epoch: 6/10. Loss: 0.8296:  88%|[36m████████▊ [0m| 23/26 [00:29<00:03,  1.11s/it]Epoch: 6/10. Loss: 0.8637:  88%|[36m████████▊ [0m| 23/26 [00:30<00:03,  1.11s/it]Epoch: 6/10. Loss: 0.8637:  92%|[36m█████████▏[0m| 24/26 [00:30<00:02,  1.07s/it]Epoch: 6/10. Loss: 0.7940:  92%|[36m█████████▏[0m| 24/26 [00:31<00:02,  1.07s/it]Epoch: 6/10. Loss: 0.7940:  96%|[36m█████████▌[0m| 25/26 [00:31<00:01,  1.02s/it]Epoch: 6/10. Loss: 0.8725:  96%|[36m█████████▌[0m| 25/26 [00:31<00:01,  1.02s/it]Epoch: 6/10. Loss: 0.8725: 100%|[36m██████████[0m| 26/26 [00:31<00:00,  1.07it/s]Epoch: 6/10. Loss: 0.8725: 100%|[36m██████████[0m| 26/26 [00:31<00:00,  1.22s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:05,  1.08it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:05,  1.04s/it] 43%|[33m████▎     [0m| 3/7 [00:02<00:03,  1.09it/s] 57%|[33m█████▋    [0m| 4/7 [00:04<00:03,  1.06s/it] 71%|[33m███████▏  [0m| 5/7 [00:04<00:01,  1.18it/s] 86%|[33m████████▌ [0m| 6/7 [00:05<00:00,  1.16it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.49it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.22it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 7/10. Loss: 0.7830:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 7/10. Loss: 0.7830:   4%|[36m▍         [0m| 1/26 [00:00<00:22,  1.11it/s]Epoch: 7/10. Loss: 0.9417:   4%|[36m▍         [0m| 1/26 [00:02<00:22,  1.11it/s]Epoch: 7/10. Loss: 0.9417:   8%|[36m▊         [0m| 2/26 [00:02<00:25,  1.07s/it]Epoch: 7/10. Loss: 0.9220:   8%|[36m▊         [0m| 2/26 [00:03<00:25,  1.07s/it]Epoch: 7/10. Loss: 0.9220:  12%|[36m█▏        [0m| 3/26 [00:03<00:23,  1.04s/it]Epoch: 7/10. Loss: 0.7748:  12%|[36m█▏        [0m| 3/26 [00:03<00:23,  1.04s/it]Epoch: 7/10. Loss: 0.7748:  15%|[36m█▌        [0m| 4/26 [00:03<00:21,  1.03it/s]Epoch: 7/10. Loss: 0.7908:  15%|[36m█▌        [0m| 4/26 [00:04<00:21,  1.03it/s]Epoch: 7/10. Loss: 0.7908:  19%|[36m█▉        [0m| 5/26 [00:04<00:18,  1.11it/s]Epoch: 7/10. Loss: 0.9230:  19%|[36m█▉        [0m| 5/26 [00:05<00:18,  1.11it/s]Epoch: 7/10. Loss: 0.9230:  23%|[36m██▎       [0m| 6/26 [00:05<00:18,  1.07it/s]Epoch: 7/10. Loss: 0.8721:  23%|[36m██▎       [0m| 6/26 [00:06<00:18,  1.07it/s]Epoch: 7/10. Loss: 0.8721:  27%|[36m██▋       [0m| 7/26 [00:06<00:19,  1.02s/it]Epoch: 7/10. Loss: 0.8932:  27%|[36m██▋       [0m| 7/26 [00:08<00:19,  1.02s/it]Epoch: 7/10. Loss: 0.8932:  31%|[36m███       [0m| 8/26 [00:08<00:19,  1.06s/it]Epoch: 7/10. Loss: 0.8296:  31%|[36m███       [0m| 8/26 [00:08<00:19,  1.06s/it]Epoch: 7/10. Loss: 0.8296:  35%|[36m███▍      [0m| 9/26 [00:08<00:17,  1.01s/it]Epoch: 7/10. Loss: 0.9179:  35%|[36m███▍      [0m| 9/26 [00:09<00:17,  1.01s/it]Epoch: 7/10. Loss: 0.9179:  38%|[36m███▊      [0m| 10/26 [00:09<00:15,  1.04it/s]Epoch: 7/10. Loss: 0.7455:  38%|[36m███▊      [0m| 10/26 [00:10<00:15,  1.04it/s]Epoch: 7/10. Loss: 0.7455:  42%|[36m████▏     [0m| 11/26 [00:10<00:14,  1.03it/s]Epoch: 7/10. Loss: 0.9227:  42%|[36m████▏     [0m| 11/26 [00:11<00:14,  1.03it/s]Epoch: 7/10. Loss: 0.9227:  46%|[36m████▌     [0m| 12/26 [00:11<00:13,  1.05it/s]Epoch: 7/10. Loss: 0.8267:  46%|[36m████▌     [0m| 12/26 [00:12<00:13,  1.05it/s]Epoch: 7/10. Loss: 0.8267:  50%|[36m█████     [0m| 13/26 [00:12<00:12,  1.07it/s]Epoch: 7/10. Loss: 0.8116:  50%|[36m█████     [0m| 13/26 [00:13<00:12,  1.07it/s]Epoch: 7/10. Loss: 0.8116:  54%|[36m█████▍    [0m| 14/26 [00:13<00:11,  1.05it/s]Epoch: 7/10. Loss: 0.8138:  54%|[36m█████▍    [0m| 14/26 [00:14<00:11,  1.05it/s]Epoch: 7/10. Loss: 0.8138:  58%|[36m█████▊    [0m| 15/26 [00:14<00:10,  1.03it/s]Epoch: 7/10. Loss: 0.9083:  58%|[36m█████▊    [0m| 15/26 [00:15<00:10,  1.03it/s]Epoch: 7/10. Loss: 0.9083:  62%|[36m██████▏   [0m| 16/26 [00:15<00:10,  1.07s/it]Epoch: 7/10. Loss: 0.8745:  62%|[36m██████▏   [0m| 16/26 [00:17<00:10,  1.07s/it]Epoch: 7/10. Loss: 0.8745:  65%|[36m██████▌   [0m| 17/26 [00:17<00:10,  1.18s/it]Epoch: 7/10. Loss: 0.9357:  65%|[36m██████▌   [0m| 17/26 [00:18<00:10,  1.18s/it]Epoch: 7/10. Loss: 0.9357:  69%|[36m██████▉   [0m| 18/26 [00:18<00:08,  1.12s/it]Epoch: 7/10. Loss: 0.9067:  69%|[36m██████▉   [0m| 18/26 [00:19<00:08,  1.12s/it]Epoch: 7/10. Loss: 0.9067:  73%|[36m███████▎  [0m| 19/26 [00:19<00:07,  1.09s/it]Epoch: 7/10. Loss: 0.8522:  73%|[36m███████▎  [0m| 19/26 [00:20<00:07,  1.09s/it]Epoch: 7/10. Loss: 0.8522:  77%|[36m███████▋  [0m| 20/26 [00:20<00:06,  1.07s/it]Epoch: 7/10. Loss: 0.8460:  77%|[36m███████▋  [0m| 20/26 [00:22<00:06,  1.07s/it]Epoch: 7/10. Loss: 0.8460:  81%|[36m████████  [0m| 21/26 [00:22<00:06,  1.39s/it]Epoch: 7/10. Loss: 0.8596:  81%|[36m████████  [0m| 21/26 [00:24<00:06,  1.39s/it]Epoch: 7/10. Loss: 0.8596:  85%|[36m████████▍ [0m| 22/26 [00:24<00:06,  1.50s/it]Epoch: 7/10. Loss: 0.7650:  85%|[36m████████▍ [0m| 22/26 [00:25<00:06,  1.50s/it]Epoch: 7/10. Loss: 0.7650:  88%|[36m████████▊ [0m| 23/26 [00:25<00:04,  1.39s/it]Epoch: 7/10. Loss: 0.7818:  88%|[36m████████▊ [0m| 23/26 [00:26<00:04,  1.39s/it]Epoch: 7/10. Loss: 0.7818:  92%|[36m█████████▏[0m| 24/26 [00:26<00:02,  1.27s/it]Epoch: 7/10. Loss: 0.8109:  92%|[36m█████████▏[0m| 24/26 [00:28<00:02,  1.27s/it]Epoch: 7/10. Loss: 0.8109:  96%|[36m█████████▌[0m| 25/26 [00:28<00:01,  1.39s/it]Epoch: 7/10. Loss: 0.8058:  96%|[36m█████████▌[0m| 25/26 [00:28<00:01,  1.39s/it]Epoch: 7/10. Loss: 0.8058: 100%|[36m██████████[0m| 26/26 [00:28<00:00,  1.16s/it]Epoch: 7/10. Loss: 0.8058: 100%|[36m██████████[0m| 26/26 [00:28<00:00,  1.11s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:05,  1.07it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:05,  1.04s/it] 43%|[33m████▎     [0m| 3/7 [00:02<00:03,  1.08it/s] 57%|[33m█████▋    [0m| 4/7 [00:04<00:03,  1.09s/it] 71%|[33m███████▏  [0m| 5/7 [00:04<00:01,  1.15it/s] 86%|[33m████████▌ [0m| 6/7 [00:05<00:00,  1.13it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.45it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.19it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 8/10. Loss: 0.7914:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 8/10. Loss: 0.7914:   4%|[36m▍         [0m| 1/26 [00:01<00:25,  1.03s/it]Epoch: 8/10. Loss: 0.7635:   4%|[36m▍         [0m| 1/26 [00:01<00:25,  1.03s/it]Epoch: 8/10. Loss: 0.7635:   8%|[36m▊         [0m| 2/26 [00:02<00:24,  1.00s/it]Epoch: 8/10. Loss: 0.7895:   8%|[36m▊         [0m| 2/26 [00:05<00:24,  1.00s/it]Epoch: 8/10. Loss: 0.7895:  12%|[36m█▏        [0m| 3/26 [00:05<00:49,  2.14s/it]Epoch: 8/10. Loss: 0.7302:  12%|[36m█▏        [0m| 3/26 [00:06<00:49,  2.14s/it]Epoch: 8/10. Loss: 0.7302:  15%|[36m█▌        [0m| 4/26 [00:06<00:37,  1.70s/it]Epoch: 8/10. Loss: 0.7192:  15%|[36m█▌        [0m| 4/26 [00:07<00:37,  1.70s/it]Epoch: 8/10. Loss: 0.7192:  19%|[36m█▉        [0m| 5/26 [00:07<00:29,  1.38s/it]Epoch: 8/10. Loss: 0.7483:  19%|[36m█▉        [0m| 5/26 [00:08<00:29,  1.38s/it]Epoch: 8/10. Loss: 0.7483:  23%|[36m██▎       [0m| 6/26 [00:08<00:25,  1.26s/it]Epoch: 8/10. Loss: 0.8465:  23%|[36m██▎       [0m| 6/26 [00:10<00:25,  1.26s/it]Epoch: 8/10. Loss: 0.8465:  27%|[36m██▋       [0m| 7/26 [00:10<00:28,  1.50s/it]Epoch: 8/10. Loss: 0.8357:  27%|[36m██▋       [0m| 7/26 [00:11<00:28,  1.50s/it]Epoch: 8/10. Loss: 0.8357:  31%|[36m███       [0m| 8/26 [00:11<00:24,  1.35s/it]Epoch: 8/10. Loss: 0.7682:  31%|[36m███       [0m| 8/26 [00:12<00:24,  1.35s/it]Epoch: 8/10. Loss: 0.7682:  35%|[36m███▍      [0m| 9/26 [00:12<00:21,  1.27s/it]Epoch: 8/10. Loss: 0.7671:  35%|[36m███▍      [0m| 9/26 [00:13<00:21,  1.27s/it]Epoch: 8/10. Loss: 0.7671:  38%|[36m███▊      [0m| 10/26 [00:13<00:18,  1.15s/it]Epoch: 8/10. Loss: 0.6247:  38%|[36m███▊      [0m| 10/26 [00:14<00:18,  1.15s/it]Epoch: 8/10. Loss: 0.6247:  42%|[36m████▏     [0m| 11/26 [00:14<00:16,  1.09s/it]Epoch: 8/10. Loss: 0.8412:  42%|[36m████▏     [0m| 11/26 [00:15<00:16,  1.09s/it]Epoch: 8/10. Loss: 0.8412:  46%|[36m████▌     [0m| 12/26 [00:15<00:14,  1.02s/it]Epoch: 8/10. Loss: 0.8165:  46%|[36m████▌     [0m| 12/26 [00:16<00:14,  1.02s/it]Epoch: 8/10. Loss: 0.8165:  50%|[36m█████     [0m| 13/26 [00:16<00:13,  1.02s/it]Epoch: 8/10. Loss: 0.7585:  50%|[36m█████     [0m| 13/26 [00:17<00:13,  1.02s/it]Epoch: 8/10. Loss: 0.7585:  54%|[36m█████▍    [0m| 14/26 [00:17<00:11,  1.00it/s]Epoch: 8/10. Loss: 0.7396:  54%|[36m█████▍    [0m| 14/26 [00:22<00:11,  1.00it/s]Epoch: 8/10. Loss: 0.7396:  58%|[36m█████▊    [0m| 15/26 [00:22<00:24,  2.26s/it]Epoch: 8/10. Loss: 0.8132:  58%|[36m█████▊    [0m| 15/26 [00:24<00:24,  2.26s/it]Epoch: 8/10. Loss: 0.8132:  62%|[36m██████▏   [0m| 16/26 [00:24<00:23,  2.35s/it]Epoch: 8/10. Loss: 0.8094:  62%|[36m██████▏   [0m| 16/26 [00:25<00:23,  2.35s/it]Epoch: 8/10. Loss: 0.8094:  65%|[36m██████▌   [0m| 17/26 [00:25<00:17,  1.94s/it]Epoch: 8/10. Loss: 0.8557:  65%|[36m██████▌   [0m| 17/26 [00:26<00:17,  1.94s/it]Epoch: 8/10. Loss: 0.8557:  69%|[36m██████▉   [0m| 18/26 [00:26<00:12,  1.58s/it]Epoch: 8/10. Loss: 0.7468:  69%|[36m██████▉   [0m| 18/26 [00:27<00:12,  1.58s/it]Epoch: 8/10. Loss: 0.7468:  73%|[36m███████▎  [0m| 19/26 [00:27<00:09,  1.40s/it]Epoch: 8/10. Loss: 0.8003:  73%|[36m███████▎  [0m| 19/26 [00:28<00:09,  1.40s/it]Epoch: 8/10. Loss: 0.8003:  77%|[36m███████▋  [0m| 20/26 [00:28<00:08,  1.38s/it]Epoch: 8/10. Loss: 0.9732:  77%|[36m███████▋  [0m| 20/26 [00:29<00:08,  1.38s/it]Epoch: 8/10. Loss: 0.9732:  81%|[36m████████  [0m| 21/26 [00:29<00:06,  1.27s/it]Epoch: 8/10. Loss: 0.7408:  81%|[36m████████  [0m| 21/26 [00:31<00:06,  1.27s/it]Epoch: 8/10. Loss: 0.7408:  85%|[36m████████▍ [0m| 22/26 [00:31<00:05,  1.50s/it]Epoch: 8/10. Loss: 0.8084:  85%|[36m████████▍ [0m| 22/26 [00:33<00:05,  1.50s/it]Epoch: 8/10. Loss: 0.8084:  88%|[36m████████▊ [0m| 23/26 [00:33<00:04,  1.38s/it]Epoch: 8/10. Loss: 0.7505:  88%|[36m████████▊ [0m| 23/26 [00:34<00:04,  1.38s/it]Epoch: 8/10. Loss: 0.7505:  92%|[36m█████████▏[0m| 24/26 [00:34<00:02,  1.27s/it]Epoch: 8/10. Loss: 0.7176:  92%|[36m█████████▏[0m| 24/26 [00:35<00:02,  1.27s/it]Epoch: 8/10. Loss: 0.7176:  96%|[36m█████████▌[0m| 25/26 [00:35<00:01,  1.19s/it]Epoch: 8/10. Loss: 0.8387:  96%|[36m█████████▌[0m| 25/26 [00:35<00:01,  1.19s/it]Epoch: 8/10. Loss: 0.8387: 100%|[36m██████████[0m| 26/26 [00:35<00:00,  1.05s/it]Epoch: 8/10. Loss: 0.8387: 100%|[36m██████████[0m| 26/26 [00:35<00:00,  1.38s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:05,  1.10it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:05,  1.03s/it] 43%|[33m████▎     [0m| 3/7 [00:02<00:03,  1.10it/s] 57%|[33m█████▋    [0m| 4/7 [00:05<00:04,  1.50s/it] 71%|[33m███████▏  [0m| 5/7 [00:05<00:02,  1.13s/it] 86%|[33m████████▌ [0m| 6/7 [00:06<00:01,  1.06s/it]100%|[33m██████████[0m| 7/7 [00:06<00:00,  1.25it/s]100%|[33m██████████[0m| 7/7 [00:06<00:00,  1.02it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 9/10. Loss: 0.7517:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 9/10. Loss: 0.7517:   4%|[36m▍         [0m| 1/26 [00:00<00:23,  1.06it/s]Epoch: 9/10. Loss: 0.7512:   4%|[36m▍         [0m| 1/26 [00:02<00:23,  1.06it/s]Epoch: 9/10. Loss: 0.7512:   8%|[36m▊         [0m| 2/26 [00:02<00:25,  1.06s/it]Epoch: 9/10. Loss: 0.7574:   8%|[36m▊         [0m| 2/26 [00:02<00:25,  1.06s/it]Epoch: 9/10. Loss: 0.7574:  12%|[36m█▏        [0m| 3/26 [00:02<00:22,  1.01it/s]Epoch: 9/10. Loss: 0.6200:  12%|[36m█▏        [0m| 3/26 [00:03<00:22,  1.01it/s]Epoch: 9/10. Loss: 0.6200:  15%|[36m█▌        [0m| 4/26 [00:03<00:20,  1.07it/s]Epoch: 9/10. Loss: 0.8583:  15%|[36m█▌        [0m| 4/26 [00:04<00:20,  1.07it/s]Epoch: 9/10. Loss: 0.8583:  19%|[36m█▉        [0m| 5/26 [00:04<00:19,  1.06it/s]Epoch: 9/10. Loss: 0.9062:  19%|[36m█▉        [0m| 5/26 [00:05<00:19,  1.06it/s]Epoch: 9/10. Loss: 0.9062:  23%|[36m██▎       [0m| 6/26 [00:05<00:19,  1.02it/s]Epoch: 9/10. Loss: 0.7241:  23%|[36m██▎       [0m| 6/26 [00:06<00:19,  1.02it/s]Epoch: 9/10. Loss: 0.7241:  27%|[36m██▋       [0m| 7/26 [00:06<00:18,  1.01it/s]Epoch: 9/10. Loss: 0.7178:  27%|[36m██▋       [0m| 7/26 [00:07<00:18,  1.01it/s]Epoch: 9/10. Loss: 0.7178:  31%|[36m███       [0m| 8/26 [00:07<00:17,  1.03it/s]Epoch: 9/10. Loss: 0.8000:  31%|[36m███       [0m| 8/26 [00:08<00:17,  1.03it/s]Epoch: 9/10. Loss: 0.8000:  35%|[36m███▍      [0m| 9/26 [00:08<00:15,  1.07it/s]Epoch: 9/10. Loss: 0.8379:  35%|[36m███▍      [0m| 9/26 [00:09<00:15,  1.07it/s]Epoch: 9/10. Loss: 0.8379:  38%|[36m███▊      [0m| 10/26 [00:09<00:14,  1.07it/s]Epoch: 9/10. Loss: 0.8619:  38%|[36m███▊      [0m| 10/26 [00:10<00:14,  1.07it/s]Epoch: 9/10. Loss: 0.8619:  42%|[36m████▏     [0m| 11/26 [00:10<00:14,  1.05it/s]Epoch: 9/10. Loss: 0.7904:  42%|[36m████▏     [0m| 11/26 [00:11<00:14,  1.05it/s]Epoch: 9/10. Loss: 0.7904:  46%|[36m████▌     [0m| 12/26 [00:11<00:13,  1.03it/s]Epoch: 9/10. Loss: 0.7706:  46%|[36m████▌     [0m| 12/26 [00:12<00:13,  1.03it/s]Epoch: 9/10. Loss: 0.7706:  50%|[36m█████     [0m| 13/26 [00:12<00:13,  1.01s/it]Epoch: 9/10. Loss: 0.7215:  50%|[36m█████     [0m| 13/26 [00:13<00:13,  1.01s/it]Epoch: 9/10. Loss: 0.7215:  54%|[36m█████▍    [0m| 14/26 [00:13<00:11,  1.01it/s]Epoch: 9/10. Loss: 0.8011:  54%|[36m█████▍    [0m| 14/26 [00:14<00:11,  1.01it/s]Epoch: 9/10. Loss: 0.8011:  58%|[36m█████▊    [0m| 15/26 [00:14<00:10,  1.07it/s]Epoch: 9/10. Loss: 0.7362:  58%|[36m█████▊    [0m| 15/26 [00:15<00:10,  1.07it/s]Epoch: 9/10. Loss: 0.7362:  62%|[36m██████▏   [0m| 16/26 [00:15<00:08,  1.11it/s]Epoch: 9/10. Loss: 0.8731:  62%|[36m██████▏   [0m| 16/26 [00:16<00:08,  1.11it/s]Epoch: 9/10. Loss: 0.8731:  65%|[36m██████▌   [0m| 17/26 [00:16<00:08,  1.10it/s]Epoch: 9/10. Loss: 0.7969:  65%|[36m██████▌   [0m| 17/26 [00:17<00:08,  1.10it/s]Epoch: 9/10. Loss: 0.7969:  69%|[36m██████▉   [0m| 18/26 [00:17<00:07,  1.07it/s]Epoch: 9/10. Loss: 0.8894:  69%|[36m██████▉   [0m| 18/26 [00:18<00:07,  1.07it/s]Epoch: 9/10. Loss: 0.8894:  73%|[36m███████▎  [0m| 19/26 [00:18<00:06,  1.06it/s]Epoch: 9/10. Loss: 0.7116:  73%|[36m███████▎  [0m| 19/26 [00:19<00:06,  1.06it/s]Epoch: 9/10. Loss: 0.7116:  77%|[36m███████▋  [0m| 20/26 [00:19<00:05,  1.04it/s]Epoch: 9/10. Loss: 0.7656:  77%|[36m███████▋  [0m| 20/26 [00:19<00:05,  1.04it/s]Epoch: 9/10. Loss: 0.7656:  81%|[36m████████  [0m| 21/26 [00:19<00:04,  1.10it/s]Epoch: 9/10. Loss: 0.8483:  81%|[36m████████  [0m| 21/26 [00:21<00:04,  1.10it/s]Epoch: 9/10. Loss: 0.8483:  85%|[36m████████▍ [0m| 22/26 [00:21<00:04,  1.22s/it]Epoch: 9/10. Loss: 0.8003:  85%|[36m████████▍ [0m| 22/26 [00:22<00:04,  1.22s/it]Epoch: 9/10. Loss: 0.8003:  88%|[36m████████▊ [0m| 23/26 [00:22<00:03,  1.19s/it]Epoch: 9/10. Loss: 0.7736:  88%|[36m████████▊ [0m| 23/26 [00:24<00:03,  1.19s/it]Epoch: 9/10. Loss: 0.7736:  92%|[36m█████████▏[0m| 24/26 [00:24<00:02,  1.35s/it]Epoch: 9/10. Loss: 0.8682:  92%|[36m█████████▏[0m| 24/26 [00:25<00:02,  1.35s/it]Epoch: 9/10. Loss: 0.8682:  96%|[36m█████████▌[0m| 25/26 [00:25<00:01,  1.27s/it]Epoch: 9/10. Loss: 0.7644:  96%|[36m█████████▌[0m| 25/26 [00:26<00:01,  1.27s/it]Epoch: 9/10. Loss: 0.7644: 100%|[36m██████████[0m| 26/26 [00:26<00:00,  1.12s/it]Epoch: 9/10. Loss: 0.7644: 100%|[36m██████████[0m| 26/26 [00:26<00:00,  1.02s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:05,  1.07it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:05,  1.04s/it] 43%|[33m████▎     [0m| 3/7 [00:03<00:04,  1.07s/it] 57%|[33m█████▋    [0m| 4/7 [00:04<00:03,  1.17s/it] 71%|[33m███████▏  [0m| 5/7 [00:04<00:01,  1.09it/s] 86%|[33m████████▌ [0m| 6/7 [00:05<00:00,  1.10it/s]100%|[33m██████████[0m| 7/7 [00:06<00:00,  1.42it/s]100%|[33m██████████[0m| 7/7 [00:06<00:00,  1.14it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 0/10. Loss: 1.0983:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 0/10. Loss: 1.0983:   4%|[36m▍         [0m| 1/26 [00:00<00:23,  1.08it/s]Epoch: 0/10. Loss: 5.0708:   4%|[36m▍         [0m| 1/26 [00:01<00:23,  1.08it/s]Epoch: 0/10. Loss: 5.0708:   8%|[36m▊         [0m| 2/26 [00:01<00:20,  1.19it/s]Epoch: 0/10. Loss: 4.6231:   8%|[36m▊         [0m| 2/26 [00:02<00:20,  1.19it/s]Epoch: 0/10. Loss: 4.6231:  12%|[36m█▏        [0m| 3/26 [00:02<00:21,  1.08it/s]Epoch: 0/10. Loss: 2.6283:  12%|[36m█▏        [0m| 3/26 [00:04<00:21,  1.08it/s]Epoch: 0/10. Loss: 2.6283:  15%|[36m█▌        [0m| 4/26 [00:04<00:24,  1.09s/it]Epoch: 0/10. Loss: 2.2804:  15%|[36m█▌        [0m| 4/26 [00:05<00:24,  1.09s/it]Epoch: 0/10. Loss: 2.2804:  19%|[36m█▉        [0m| 5/26 [00:05<00:22,  1.07s/it]Epoch: 0/10. Loss: 2.0379:  19%|[36m█▉        [0m| 5/26 [00:05<00:22,  1.07s/it]Epoch: 0/10. Loss: 2.0379:  23%|[36m██▎       [0m| 6/26 [00:05<00:18,  1.06it/s]Epoch: 0/10. Loss: 1.7256:  23%|[36m██▎       [0m| 6/26 [00:06<00:18,  1.06it/s]Epoch: 0/10. Loss: 1.7256:  27%|[36m██▋       [0m| 7/26 [00:06<00:18,  1.04it/s]Epoch: 0/10. Loss: 1.0572:  27%|[36m██▋       [0m| 7/26 [00:07<00:18,  1.04it/s]Epoch: 0/10. Loss: 1.0572:  31%|[36m███       [0m| 8/26 [00:07<00:17,  1.00it/s]Epoch: 0/10. Loss: 1.2581:  31%|[36m███       [0m| 8/26 [00:08<00:17,  1.00it/s]Epoch: 0/10. Loss: 1.2581:  35%|[36m███▍      [0m| 9/26 [00:08<00:16,  1.04it/s]Epoch: 0/10. Loss: 1.2704:  35%|[36m███▍      [0m| 9/26 [00:09<00:16,  1.04it/s]Epoch: 0/10. Loss: 1.2704:  38%|[36m███▊      [0m| 10/26 [00:09<00:16,  1.00s/it]Epoch: 0/10. Loss: 1.1969:  38%|[36m███▊      [0m| 10/26 [00:10<00:16,  1.00s/it]Epoch: 0/10. Loss: 1.1969:  42%|[36m████▏     [0m| 11/26 [00:10<00:14,  1.06it/s]Epoch: 0/10. Loss: 1.0381:  42%|[36m████▏     [0m| 11/26 [00:11<00:14,  1.06it/s]Epoch: 0/10. Loss: 1.0381:  46%|[36m████▌     [0m| 12/26 [00:11<00:13,  1.07it/s]Epoch: 0/10. Loss: 1.1362:  46%|[36m████▌     [0m| 12/26 [00:12<00:13,  1.07it/s]Epoch: 0/10. Loss: 1.1362:  50%|[36m█████     [0m| 13/26 [00:12<00:12,  1.04it/s]Epoch: 0/10. Loss: 1.2367:  50%|[36m█████     [0m| 13/26 [00:13<00:12,  1.04it/s]Epoch: 0/10. Loss: 1.2367:  54%|[36m█████▍    [0m| 14/26 [00:13<00:11,  1.07it/s]Epoch: 0/10. Loss: 1.1884:  54%|[36m█████▍    [0m| 14/26 [00:14<00:11,  1.07it/s]Epoch: 0/10. Loss: 1.1884:  58%|[36m█████▊    [0m| 15/26 [00:14<00:10,  1.08it/s]Epoch: 0/10. Loss: 1.1457:  58%|[36m█████▊    [0m| 15/26 [00:15<00:10,  1.08it/s]Epoch: 0/10. Loss: 1.1457:  62%|[36m██████▏   [0m| 16/26 [00:15<00:09,  1.07it/s]Epoch: 0/10. Loss: 1.1009:  62%|[36m██████▏   [0m| 16/26 [00:16<00:09,  1.07it/s]Epoch: 0/10. Loss: 1.1009:  65%|[36m██████▌   [0m| 17/26 [00:16<00:07,  1.13it/s]Epoch: 0/10. Loss: 1.0757:  65%|[36m██████▌   [0m| 17/26 [00:16<00:07,  1.13it/s]Epoch: 0/10. Loss: 1.0757:  69%|[36m██████▉   [0m| 18/26 [00:16<00:06,  1.16it/s]Epoch: 0/10. Loss: 1.0238:  69%|[36m██████▉   [0m| 18/26 [00:17<00:06,  1.16it/s]Epoch: 0/10. Loss: 1.0238:  73%|[36m███████▎  [0m| 19/26 [00:17<00:06,  1.15it/s]Epoch: 0/10. Loss: 1.1521:  73%|[36m███████▎  [0m| 19/26 [00:18<00:06,  1.15it/s]Epoch: 0/10. Loss: 1.1521:  77%|[36m███████▋  [0m| 20/26 [00:18<00:05,  1.15it/s]Epoch: 0/10. Loss: 1.0927:  77%|[36m███████▋  [0m| 20/26 [00:19<00:05,  1.15it/s]Epoch: 0/10. Loss: 1.0927:  81%|[36m████████  [0m| 21/26 [00:19<00:04,  1.07it/s]Epoch: 0/10. Loss: 1.0332:  81%|[36m████████  [0m| 21/26 [00:20<00:04,  1.07it/s]Epoch: 0/10. Loss: 1.0332:  85%|[36m████████▍ [0m| 22/26 [00:20<00:03,  1.00it/s]Epoch: 0/10. Loss: 1.1920:  85%|[36m████████▍ [0m| 22/26 [00:23<00:03,  1.00it/s]Epoch: 0/10. Loss: 1.1920:  88%|[36m████████▊ [0m| 23/26 [00:23<00:04,  1.37s/it]Epoch: 0/10. Loss: 1.1670:  88%|[36m████████▊ [0m| 23/26 [00:23<00:04,  1.37s/it]Epoch: 0/10. Loss: 1.1670:  92%|[36m█████████▏[0m| 24/26 [00:23<00:02,  1.19s/it]Epoch: 0/10. Loss: 1.0335:  92%|[36m█████████▏[0m| 24/26 [00:24<00:02,  1.19s/it]Epoch: 0/10. Loss: 1.0335:  96%|[36m█████████▌[0m| 25/26 [00:24<00:01,  1.13s/it]Epoch: 0/10. Loss: 0.9337:  96%|[36m█████████▌[0m| 25/26 [00:25<00:01,  1.13s/it]Epoch: 0/10. Loss: 0.9337: 100%|[36m██████████[0m| 26/26 [00:25<00:00,  1.00it/s]Epoch: 0/10. Loss: 0.9337: 100%|[36m██████████[0m| 26/26 [00:25<00:00,  1.02it/s]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:02<00:12,  2.07s/it] 29%|[33m██▊       [0m| 2/7 [00:03<00:08,  1.68s/it] 43%|[33m████▎     [0m| 3/7 [00:04<00:05,  1.26s/it] 57%|[33m█████▋    [0m| 4/7 [00:05<00:04,  1.44s/it] 71%|[33m███████▏  [0m| 5/7 [00:06<00:02,  1.07s/it] 86%|[33m████████▌ [0m| 6/7 [00:07<00:01,  1.01s/it]100%|[33m██████████[0m| 7/7 [00:07<00:00,  1.27it/s]100%|[33m██████████[0m| 7/7 [00:07<00:00,  1.08s/it]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 1/10. Loss: 1.0722:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 1/10. Loss: 1.0722:   4%|[36m▍         [0m| 1/26 [00:00<00:21,  1.14it/s]Epoch: 1/10. Loss: 1.1791:   4%|[36m▍         [0m| 1/26 [00:01<00:21,  1.14it/s]Epoch: 1/10. Loss: 1.1791:   8%|[36m▊         [0m| 2/26 [00:01<00:20,  1.18it/s]Epoch: 1/10. Loss: 1.0047:   8%|[36m▊         [0m| 2/26 [00:02<00:20,  1.18it/s]Epoch: 1/10. Loss: 1.0047:  12%|[36m█▏        [0m| 3/26 [00:02<00:19,  1.16it/s]Epoch: 1/10. Loss: 1.1693:  12%|[36m█▏        [0m| 3/26 [00:03<00:19,  1.16it/s]Epoch: 1/10. Loss: 1.1693:  15%|[36m█▌        [0m| 4/26 [00:03<00:20,  1.07it/s]Epoch: 1/10. Loss: 1.1083:  15%|[36m█▌        [0m| 4/26 [00:04<00:20,  1.07it/s]Epoch: 1/10. Loss: 1.1083:  19%|[36m█▉        [0m| 5/26 [00:04<00:21,  1.04s/it]Epoch: 1/10. Loss: 1.1139:  19%|[36m█▉        [0m| 5/26 [00:05<00:21,  1.04s/it]Epoch: 1/10. Loss: 1.1139:  23%|[36m██▎       [0m| 6/26 [00:05<00:19,  1.00it/s]Epoch: 1/10. Loss: 1.0201:  23%|[36m██▎       [0m| 6/26 [00:06<00:19,  1.00it/s]Epoch: 1/10. Loss: 1.0201:  27%|[36m██▋       [0m| 7/26 [00:06<00:17,  1.08it/s]Epoch: 1/10. Loss: 1.0208:  27%|[36m██▋       [0m| 7/26 [00:07<00:17,  1.08it/s]Epoch: 1/10. Loss: 1.0208:  31%|[36m███       [0m| 8/26 [00:07<00:16,  1.10it/s]Epoch: 1/10. Loss: 1.0310:  31%|[36m███       [0m| 8/26 [00:08<00:16,  1.10it/s]Epoch: 1/10. Loss: 1.0310:  35%|[36m███▍      [0m| 9/26 [00:08<00:15,  1.09it/s]Epoch: 1/10. Loss: 1.0527:  35%|[36m███▍      [0m| 9/26 [00:09<00:15,  1.09it/s]Epoch: 1/10. Loss: 1.0527:  38%|[36m███▊      [0m| 10/26 [00:09<00:14,  1.09it/s]Epoch: 1/10. Loss: 1.0049:  38%|[36m███▊      [0m| 10/26 [00:10<00:14,  1.09it/s]Epoch: 1/10. Loss: 1.0049:  42%|[36m████▏     [0m| 11/26 [00:10<00:13,  1.13it/s]Epoch: 1/10. Loss: 1.0341:  42%|[36m████▏     [0m| 11/26 [00:11<00:13,  1.13it/s]Epoch: 1/10. Loss: 1.0341:  46%|[36m████▌     [0m| 12/26 [00:11<00:12,  1.09it/s]Epoch: 1/10. Loss: 1.0364:  46%|[36m████▌     [0m| 12/26 [00:11<00:12,  1.09it/s]Epoch: 1/10. Loss: 1.0364:  50%|[36m█████     [0m| 13/26 [00:11<00:11,  1.11it/s]Epoch: 1/10. Loss: 1.0049:  50%|[36m█████     [0m| 13/26 [00:12<00:11,  1.11it/s]Epoch: 1/10. Loss: 1.0049:  54%|[36m█████▍    [0m| 14/26 [00:12<00:10,  1.15it/s]Epoch: 1/10. Loss: 1.0158:  54%|[36m█████▍    [0m| 14/26 [00:13<00:10,  1.15it/s]Epoch: 1/10. Loss: 1.0158:  58%|[36m█████▊    [0m| 15/26 [00:13<00:09,  1.10it/s]Epoch: 1/10. Loss: 0.9984:  58%|[36m█████▊    [0m| 15/26 [00:14<00:09,  1.10it/s]Epoch: 1/10. Loss: 0.9984:  62%|[36m██████▏   [0m| 16/26 [00:14<00:08,  1.12it/s]Epoch: 1/10. Loss: 1.0533:  62%|[36m██████▏   [0m| 16/26 [00:15<00:08,  1.12it/s]Epoch: 1/10. Loss: 1.0533:  65%|[36m██████▌   [0m| 17/26 [00:15<00:08,  1.09it/s]Epoch: 1/10. Loss: 1.0373:  65%|[36m██████▌   [0m| 17/26 [00:16<00:08,  1.09it/s]Epoch: 1/10. Loss: 1.0373:  69%|[36m██████▉   [0m| 18/26 [00:16<00:07,  1.09it/s]Epoch: 1/10. Loss: 0.9875:  69%|[36m██████▉   [0m| 18/26 [00:17<00:07,  1.09it/s]Epoch: 1/10. Loss: 0.9875:  73%|[36m███████▎  [0m| 19/26 [00:17<00:06,  1.08it/s]Epoch: 1/10. Loss: 1.0347:  73%|[36m███████▎  [0m| 19/26 [00:18<00:06,  1.08it/s]Epoch: 1/10. Loss: 1.0347:  77%|[36m███████▋  [0m| 20/26 [00:18<00:05,  1.13it/s]Epoch: 1/10. Loss: 1.1131:  77%|[36m███████▋  [0m| 20/26 [00:19<00:05,  1.13it/s]Epoch: 1/10. Loss: 1.1131:  81%|[36m████████  [0m| 21/26 [00:19<00:04,  1.06it/s]Epoch: 1/10. Loss: 0.9902:  81%|[36m████████  [0m| 21/26 [00:20<00:04,  1.06it/s]Epoch: 1/10. Loss: 0.9902:  85%|[36m████████▍ [0m| 22/26 [00:20<00:04,  1.17s/it]Epoch: 1/10. Loss: 1.0276:  85%|[36m████████▍ [0m| 22/26 [00:22<00:04,  1.17s/it]Epoch: 1/10. Loss: 1.0276:  88%|[36m████████▊ [0m| 23/26 [00:22<00:03,  1.14s/it]Epoch: 1/10. Loss: 0.9586:  88%|[36m████████▊ [0m| 23/26 [00:23<00:03,  1.14s/it]Epoch: 1/10. Loss: 0.9586:  92%|[36m█████████▏[0m| 24/26 [00:23<00:02,  1.12s/it]Epoch: 1/10. Loss: 0.9612:  92%|[36m█████████▏[0m| 24/26 [00:24<00:02,  1.12s/it]Epoch: 1/10. Loss: 0.9612:  96%|[36m█████████▌[0m| 25/26 [00:24<00:01,  1.05s/it]Epoch: 1/10. Loss: 1.1526:  96%|[36m█████████▌[0m| 25/26 [00:24<00:01,  1.05s/it]Epoch: 1/10. Loss: 1.1526: 100%|[36m██████████[0m| 26/26 [00:24<00:00,  1.06it/s]Epoch: 1/10. Loss: 1.1526: 100%|[36m██████████[0m| 26/26 [00:24<00:00,  1.05it/s]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:05,  1.14it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:05,  1.06s/it] 43%|[33m████▎     [0m| 3/7 [00:02<00:03,  1.08it/s] 57%|[33m█████▋    [0m| 4/7 [00:04<00:03,  1.17s/it] 71%|[33m███████▏  [0m| 5/7 [00:07<00:03,  1.82s/it] 86%|[33m████████▌ [0m| 6/7 [00:09<00:01,  1.78s/it]100%|[33m██████████[0m| 7/7 [00:09<00:00,  1.28s/it]100%|[33m██████████[0m| 7/7 [00:09<00:00,  1.33s/it]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 2/10. Loss: 1.0058:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 2/10. Loss: 1.0058:   4%|[36m▍         [0m| 1/26 [00:00<00:19,  1.31it/s]Epoch: 2/10. Loss: 0.9967:   4%|[36m▍         [0m| 1/26 [00:01<00:19,  1.31it/s]Epoch: 2/10. Loss: 0.9967:   8%|[36m▊         [0m| 2/26 [00:01<00:23,  1.03it/s]Epoch: 2/10. Loss: 0.9426:   8%|[36m▊         [0m| 2/26 [00:02<00:23,  1.03it/s]Epoch: 2/10. Loss: 0.9426:  12%|[36m█▏        [0m| 3/26 [00:02<00:22,  1.04it/s]Epoch: 2/10. Loss: 1.0085:  12%|[36m█▏        [0m| 3/26 [00:05<00:22,  1.04it/s]Epoch: 2/10. Loss: 1.0085:  15%|[36m█▌        [0m| 4/26 [00:05<00:35,  1.61s/it]Epoch: 2/10. Loss: 1.1340:  15%|[36m█▌        [0m| 4/26 [00:06<00:35,  1.61s/it]Epoch: 2/10. Loss: 1.1340:  19%|[36m█▉        [0m| 5/26 [00:06<00:27,  1.33s/it]Epoch: 2/10. Loss: 0.9952:  19%|[36m█▉        [0m| 5/26 [00:07<00:27,  1.33s/it]Epoch: 2/10. Loss: 0.9952:  23%|[36m██▎       [0m| 6/26 [00:07<00:24,  1.21s/it]Epoch: 2/10. Loss: 1.0129:  23%|[36m██▎       [0m| 6/26 [00:08<00:24,  1.21s/it]Epoch: 2/10. Loss: 1.0129:  27%|[36m██▋       [0m| 7/26 [00:08<00:20,  1.08s/it]Epoch: 2/10. Loss: 1.0019:  27%|[36m██▋       [0m| 7/26 [00:09<00:20,  1.08s/it]Epoch: 2/10. Loss: 1.0019:  31%|[36m███       [0m| 8/26 [00:09<00:19,  1.09s/it]Epoch: 2/10. Loss: 0.9692:  31%|[36m███       [0m| 8/26 [00:10<00:19,  1.09s/it]Epoch: 2/10. Loss: 0.9692:  35%|[36m███▍      [0m| 9/26 [00:10<00:18,  1.08s/it]Epoch: 2/10. Loss: 0.9725:  35%|[36m███▍      [0m| 9/26 [00:11<00:18,  1.08s/it]Epoch: 2/10. Loss: 0.9725:  38%|[36m███▊      [0m| 10/26 [00:11<00:16,  1.02s/it]Epoch: 2/10. Loss: 0.9607:  38%|[36m███▊      [0m| 10/26 [00:11<00:16,  1.02s/it]Epoch: 2/10. Loss: 0.9607:  42%|[36m████▏     [0m| 11/26 [00:11<00:14,  1.04it/s]Epoch: 2/10. Loss: 0.9520:  42%|[36m████▏     [0m| 11/26 [00:12<00:14,  1.04it/s]Epoch: 2/10. Loss: 0.9520:  46%|[36m████▌     [0m| 12/26 [00:12<00:13,  1.06it/s]Epoch: 2/10. Loss: 0.8934:  46%|[36m████▌     [0m| 12/26 [00:13<00:13,  1.06it/s]Epoch: 2/10. Loss: 0.8934:  50%|[36m█████     [0m| 13/26 [00:13<00:12,  1.07it/s]Epoch: 2/10. Loss: 1.0253:  50%|[36m█████     [0m| 13/26 [00:14<00:12,  1.07it/s]Epoch: 2/10. Loss: 1.0253:  54%|[36m█████▍    [0m| 14/26 [00:14<00:11,  1.06it/s]Epoch: 2/10. Loss: 0.9533:  54%|[36m█████▍    [0m| 14/26 [00:15<00:11,  1.06it/s]Epoch: 2/10. Loss: 0.9533:  58%|[36m█████▊    [0m| 15/26 [00:15<00:10,  1.06it/s]Epoch: 2/10. Loss: 1.0551:  58%|[36m█████▊    [0m| 15/26 [00:16<00:10,  1.06it/s]Epoch: 2/10. Loss: 1.0551:  62%|[36m██████▏   [0m| 16/26 [00:16<00:09,  1.03it/s]Epoch: 2/10. Loss: 1.0174:  62%|[36m██████▏   [0m| 16/26 [00:17<00:09,  1.03it/s]Epoch: 2/10. Loss: 1.0174:  65%|[36m██████▌   [0m| 17/26 [00:17<00:08,  1.02it/s]Epoch: 2/10. Loss: 0.9107:  65%|[36m██████▌   [0m| 17/26 [00:18<00:08,  1.02it/s]Epoch: 2/10. Loss: 0.9107:  69%|[36m██████▉   [0m| 18/26 [00:18<00:07,  1.04it/s]Epoch: 2/10. Loss: 0.8853:  69%|[36m██████▉   [0m| 18/26 [00:19<00:07,  1.04it/s]Epoch: 2/10. Loss: 0.8853:  73%|[36m███████▎  [0m| 19/26 [00:19<00:06,  1.01it/s]Epoch: 2/10. Loss: 0.9287:  73%|[36m███████▎  [0m| 19/26 [00:20<00:06,  1.01it/s]Epoch: 2/10. Loss: 0.9287:  77%|[36m███████▋  [0m| 20/26 [00:20<00:06,  1.05s/it]Epoch: 2/10. Loss: 1.0225:  77%|[36m███████▋  [0m| 20/26 [00:21<00:06,  1.05s/it]Epoch: 2/10. Loss: 1.0225:  81%|[36m████████  [0m| 21/26 [00:21<00:04,  1.01it/s]Epoch: 2/10. Loss: 0.8647:  81%|[36m████████  [0m| 21/26 [00:22<00:04,  1.01it/s]Epoch: 2/10. Loss: 0.8647:  85%|[36m████████▍ [0m| 22/26 [00:22<00:03,  1.01it/s]Epoch: 2/10. Loss: 1.0761:  85%|[36m████████▍ [0m| 22/26 [00:24<00:03,  1.01it/s]Epoch: 2/10. Loss: 1.0761:  88%|[36m████████▊ [0m| 23/26 [00:24<00:03,  1.23s/it]Epoch: 2/10. Loss: 0.9366:  88%|[36m████████▊ [0m| 23/26 [00:25<00:03,  1.23s/it]Epoch: 2/10. Loss: 0.9366:  92%|[36m█████████▏[0m| 24/26 [00:25<00:02,  1.14s/it]Epoch: 2/10. Loss: 0.9567:  92%|[36m█████████▏[0m| 24/26 [00:26<00:02,  1.14s/it]Epoch: 2/10. Loss: 0.9567:  96%|[36m█████████▌[0m| 25/26 [00:26<00:01,  1.07s/it]Epoch: 2/10. Loss: 1.0784:  96%|[36m█████████▌[0m| 25/26 [00:26<00:01,  1.07s/it]Epoch: 2/10. Loss: 1.0784: 100%|[36m██████████[0m| 26/26 [00:26<00:00,  1.09it/s]Epoch: 2/10. Loss: 1.0784: 100%|[36m██████████[0m| 26/26 [00:26<00:00,  1.03s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:05,  1.07it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:05,  1.01s/it] 43%|[33m████▎     [0m| 3/7 [00:02<00:03,  1.10it/s] 57%|[33m█████▋    [0m| 4/7 [00:04<00:03,  1.06s/it] 71%|[33m███████▏  [0m| 5/7 [00:04<00:01,  1.19it/s] 86%|[33m████████▌ [0m| 6/7 [00:05<00:01,  1.01s/it]100%|[33m██████████[0m| 7/7 [00:06<00:00,  1.28it/s]100%|[33m██████████[0m| 7/7 [00:06<00:00,  1.13it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 3/10. Loss: 0.9458:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 3/10. Loss: 0.9458:   4%|[36m▍         [0m| 1/26 [00:00<00:19,  1.29it/s]Epoch: 3/10. Loss: 0.9092:   4%|[36m▍         [0m| 1/26 [00:02<00:19,  1.29it/s]Epoch: 3/10. Loss: 0.9092:   8%|[36m▊         [0m| 2/26 [00:02<00:31,  1.30s/it]Epoch: 3/10. Loss: 0.8776:   8%|[36m▊         [0m| 2/26 [00:03<00:31,  1.30s/it]Epoch: 3/10. Loss: 0.8776:  12%|[36m█▏        [0m| 3/26 [00:03<00:25,  1.12s/it]Epoch: 3/10. Loss: 0.9725:  12%|[36m█▏        [0m| 3/26 [00:04<00:25,  1.12s/it]Epoch: 3/10. Loss: 0.9725:  15%|[36m█▌        [0m| 4/26 [00:04<00:23,  1.08s/it]Epoch: 3/10. Loss: 1.0077:  15%|[36m█▌        [0m| 4/26 [00:05<00:23,  1.08s/it]Epoch: 3/10. Loss: 1.0077:  19%|[36m█▉        [0m| 5/26 [00:05<00:20,  1.02it/s]Epoch: 3/10. Loss: 0.9947:  19%|[36m█▉        [0m| 5/26 [00:05<00:20,  1.02it/s]Epoch: 3/10. Loss: 0.9947:  23%|[36m██▎       [0m| 6/26 [00:05<00:18,  1.09it/s]Epoch: 3/10. Loss: 0.9060:  23%|[36m██▎       [0m| 6/26 [00:06<00:18,  1.09it/s]Epoch: 3/10. Loss: 0.9060:  27%|[36m██▋       [0m| 7/26 [00:06<00:16,  1.18it/s]Epoch: 3/10. Loss: 0.9666:  27%|[36m██▋       [0m| 7/26 [00:08<00:16,  1.18it/s]Epoch: 3/10. Loss: 0.9666:  31%|[36m███       [0m| 8/26 [00:08<00:23,  1.28s/it]Epoch: 3/10. Loss: 0.8816:  31%|[36m███       [0m| 8/26 [00:09<00:23,  1.28s/it]Epoch: 3/10. Loss: 0.8816:  35%|[36m███▍      [0m| 9/26 [00:09<00:19,  1.15s/it]Epoch: 3/10. Loss: 1.0457:  35%|[36m███▍      [0m| 9/26 [00:10<00:19,  1.15s/it]Epoch: 3/10. Loss: 1.0457:  38%|[36m███▊      [0m| 10/26 [00:10<00:17,  1.09s/it]Epoch: 3/10. Loss: 0.9153:  38%|[36m███▊      [0m| 10/26 [00:11<00:17,  1.09s/it]Epoch: 3/10. Loss: 0.9153:  42%|[36m████▏     [0m| 11/26 [00:11<00:15,  1.02s/it]Epoch: 3/10. Loss: 1.0176:  42%|[36m████▏     [0m| 11/26 [00:12<00:15,  1.02s/it]Epoch: 3/10. Loss: 1.0176:  46%|[36m████▌     [0m| 12/26 [00:12<00:13,  1.01it/s]Epoch: 3/10. Loss: 0.9186:  46%|[36m████▌     [0m| 12/26 [00:13<00:13,  1.01it/s]Epoch: 3/10. Loss: 0.9186:  50%|[36m█████     [0m| 13/26 [00:13<00:12,  1.00it/s]Epoch: 3/10. Loss: 0.9605:  50%|[36m█████     [0m| 13/26 [00:14<00:12,  1.00it/s]Epoch: 3/10. Loss: 0.9605:  54%|[36m█████▍    [0m| 14/26 [00:14<00:11,  1.07it/s]Epoch: 3/10. Loss: 1.0507:  54%|[36m█████▍    [0m| 14/26 [00:15<00:11,  1.07it/s]Epoch: 3/10. Loss: 1.0507:  58%|[36m█████▊    [0m| 15/26 [00:15<00:10,  1.03it/s]Epoch: 3/10. Loss: 1.0043:  58%|[36m█████▊    [0m| 15/26 [00:16<00:10,  1.03it/s]Epoch: 3/10. Loss: 1.0043:  62%|[36m██████▏   [0m| 16/26 [00:16<00:09,  1.05it/s]Epoch: 3/10. Loss: 0.9300:  62%|[36m██████▏   [0m| 16/26 [00:17<00:09,  1.05it/s]Epoch: 3/10. Loss: 0.9300:  65%|[36m██████▌   [0m| 17/26 [00:17<00:08,  1.07it/s]Epoch: 3/10. Loss: 0.9978:  65%|[36m██████▌   [0m| 17/26 [00:18<00:08,  1.07it/s]Epoch: 3/10. Loss: 0.9978:  69%|[36m██████▉   [0m| 18/26 [00:18<00:07,  1.06it/s]Epoch: 3/10. Loss: 0.9664:  69%|[36m██████▉   [0m| 18/26 [00:19<00:07,  1.06it/s]Epoch: 3/10. Loss: 0.9664:  73%|[36m███████▎  [0m| 19/26 [00:19<00:07,  1.02s/it]Epoch: 3/10. Loss: 0.9664:  73%|[36m███████▎  [0m| 19/26 [00:20<00:07,  1.02s/it]Epoch: 3/10. Loss: 0.9664:  77%|[36m███████▋  [0m| 20/26 [00:20<00:05,  1.01it/s]Epoch: 3/10. Loss: 0.9429:  77%|[36m███████▋  [0m| 20/26 [00:21<00:05,  1.01it/s]Epoch: 3/10. Loss: 0.9429:  81%|[36m████████  [0m| 21/26 [00:21<00:04,  1.01it/s]Epoch: 3/10. Loss: 0.9580:  81%|[36m████████  [0m| 21/26 [00:22<00:04,  1.01it/s]Epoch: 3/10. Loss: 0.9580:  85%|[36m████████▍ [0m| 22/26 [00:22<00:03,  1.06it/s]Epoch: 3/10. Loss: 1.0220:  85%|[36m████████▍ [0m| 22/26 [00:22<00:03,  1.06it/s]Epoch: 3/10. Loss: 1.0220:  88%|[36m████████▊ [0m| 23/26 [00:22<00:02,  1.07it/s]Epoch: 3/10. Loss: 1.0234:  88%|[36m████████▊ [0m| 23/26 [00:23<00:02,  1.07it/s]Epoch: 3/10. Loss: 1.0234:  92%|[36m█████████▏[0m| 24/26 [00:23<00:01,  1.08it/s]Epoch: 3/10. Loss: 0.9294:  92%|[36m█████████▏[0m| 24/26 [00:24<00:01,  1.08it/s]Epoch: 3/10. Loss: 0.9294:  96%|[36m█████████▌[0m| 25/26 [00:24<00:00,  1.09it/s]Epoch: 3/10. Loss: 0.8838:  96%|[36m█████████▌[0m| 25/26 [00:25<00:00,  1.09it/s]Epoch: 3/10. Loss: 0.8838: 100%|[36m██████████[0m| 26/26 [00:25<00:00,  1.16it/s]Epoch: 3/10. Loss: 0.8838: 100%|[36m██████████[0m| 26/26 [00:25<00:00,  1.02it/s]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:05,  1.12it/s] 29%|[33m██▊       [0m| 2/7 [00:01<00:05,  1.01s/it] 43%|[33m████▎     [0m| 3/7 [00:02<00:03,  1.12it/s] 57%|[33m█████▋    [0m| 4/7 [00:04<00:03,  1.07s/it] 71%|[33m███████▏  [0m| 5/7 [00:04<00:01,  1.18it/s] 86%|[33m████████▌ [0m| 6/7 [00:05<00:00,  1.17it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.51it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.23it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 4/10. Loss: 1.0138:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 4/10. Loss: 1.0138:   4%|[36m▍         [0m| 1/26 [00:00<00:22,  1.13it/s]Epoch: 4/10. Loss: 0.8980:   4%|[36m▍         [0m| 1/26 [00:01<00:22,  1.13it/s]Epoch: 4/10. Loss: 0.8980:   8%|[36m▊         [0m| 2/26 [00:01<00:20,  1.19it/s]Epoch: 4/10. Loss: 0.9753:   8%|[36m▊         [0m| 2/26 [00:02<00:20,  1.19it/s]Epoch: 4/10. Loss: 0.9753:  12%|[36m█▏        [0m| 3/26 [00:02<00:20,  1.14it/s]Epoch: 4/10. Loss: 0.9537:  12%|[36m█▏        [0m| 3/26 [00:03<00:20,  1.14it/s]Epoch: 4/10. Loss: 0.9537:  15%|[36m█▌        [0m| 4/26 [00:03<00:19,  1.12it/s]Epoch: 4/10. Loss: 0.8782:  15%|[36m█▌        [0m| 4/26 [00:04<00:19,  1.12it/s]Epoch: 4/10. Loss: 0.8782:  19%|[36m█▉        [0m| 5/26 [00:04<00:19,  1.07it/s]Epoch: 4/10. Loss: 1.0797:  19%|[36m█▉        [0m| 5/26 [00:05<00:19,  1.07it/s]Epoch: 4/10. Loss: 1.0797:  23%|[36m██▎       [0m| 6/26 [00:05<00:18,  1.08it/s]Epoch: 4/10. Loss: 0.9361:  23%|[36m██▎       [0m| 6/26 [00:06<00:18,  1.08it/s]Epoch: 4/10. Loss: 0.9361:  27%|[36m██▋       [0m| 7/26 [00:06<00:17,  1.11it/s]Epoch: 4/10. Loss: 0.8837:  27%|[36m██▋       [0m| 7/26 [00:07<00:17,  1.11it/s]Epoch: 4/10. Loss: 0.8837:  31%|[36m███       [0m| 8/26 [00:07<00:15,  1.13it/s]Epoch: 4/10. Loss: 0.8912:  31%|[36m███       [0m| 8/26 [00:07<00:15,  1.13it/s]Epoch: 4/10. Loss: 0.8912:  35%|[36m███▍      [0m| 9/26 [00:07<00:14,  1.15it/s]Epoch: 4/10. Loss: 0.8843:  35%|[36m███▍      [0m| 9/26 [00:09<00:14,  1.15it/s]Epoch: 4/10. Loss: 0.8843:  38%|[36m███▊      [0m| 10/26 [00:09<00:16,  1.04s/it]Epoch: 4/10. Loss: 0.9298:  38%|[36m███▊      [0m| 10/26 [00:10<00:16,  1.04s/it]Epoch: 4/10. Loss: 0.9298:  42%|[36m████▏     [0m| 11/26 [00:10<00:14,  1.01it/s]Epoch: 4/10. Loss: 1.0237:  42%|[36m████▏     [0m| 11/26 [00:11<00:14,  1.01it/s]Epoch: 4/10. Loss: 1.0237:  46%|[36m████▌     [0m| 12/26 [00:11<00:15,  1.14s/it]Epoch: 4/10. Loss: 0.8672:  46%|[36m████▌     [0m| 12/26 [00:12<00:15,  1.14s/it]Epoch: 4/10. Loss: 0.8672:  50%|[36m█████     [0m| 13/26 [00:12<00:13,  1.07s/it]Epoch: 4/10. Loss: 0.8983:  50%|[36m█████     [0m| 13/26 [00:13<00:13,  1.07s/it]Epoch: 4/10. Loss: 0.8983:  54%|[36m█████▍    [0m| 14/26 [00:13<00:13,  1.09s/it]Epoch: 4/10. Loss: 0.9264:  54%|[36m█████▍    [0m| 14/26 [00:14<00:13,  1.09s/it]Epoch: 4/10. Loss: 0.9264:  58%|[36m█████▊    [0m| 15/26 [00:14<00:12,  1.09s/it]Epoch: 4/10. Loss: 0.9413:  58%|[36m█████▊    [0m| 15/26 [00:15<00:12,  1.09s/it]Epoch: 4/10. Loss: 0.9413:  62%|[36m██████▏   [0m| 16/26 [00:15<00:10,  1.03s/it]Epoch: 4/10. Loss: 0.8952:  62%|[36m██████▏   [0m| 16/26 [00:17<00:10,  1.03s/it]Epoch: 4/10. Loss: 0.8952:  65%|[36m██████▌   [0m| 17/26 [00:17<00:10,  1.22s/it]Epoch: 4/10. Loss: 0.9485:  65%|[36m██████▌   [0m| 17/26 [00:18<00:10,  1.22s/it]Epoch: 4/10. Loss: 0.9485:  69%|[36m██████▉   [0m| 18/26 [00:18<00:09,  1.16s/it]Epoch: 4/10. Loss: 1.0279:  69%|[36m██████▉   [0m| 18/26 [00:19<00:09,  1.16s/it]Epoch: 4/10. Loss: 1.0279:  73%|[36m███████▎  [0m| 19/26 [00:19<00:08,  1.16s/it]Epoch: 4/10. Loss: 0.8488:  73%|[36m███████▎  [0m| 19/26 [00:21<00:08,  1.16s/it]Epoch: 4/10. Loss: 0.8488:  77%|[36m███████▋  [0m| 20/26 [00:21<00:07,  1.25s/it]Epoch: 4/10. Loss: 0.8493:  77%|[36m███████▋  [0m| 20/26 [00:21<00:07,  1.25s/it]Epoch: 4/10. Loss: 0.8493:  81%|[36m████████  [0m| 21/26 [00:21<00:05,  1.12s/it]Epoch: 4/10. Loss: 0.9157:  81%|[36m████████  [0m| 21/26 [00:22<00:05,  1.12s/it]Epoch: 4/10. Loss: 0.9157:  85%|[36m████████▍ [0m| 22/26 [00:22<00:04,  1.06s/it]Epoch: 4/10. Loss: 0.8595:  85%|[36m████████▍ [0m| 22/26 [00:23<00:04,  1.06s/it]Epoch: 4/10. Loss: 0.8595:  88%|[36m████████▊ [0m| 23/26 [00:23<00:03,  1.01s/it]Epoch: 4/10. Loss: 0.9364:  88%|[36m████████▊ [0m| 23/26 [00:24<00:03,  1.01s/it]Epoch: 4/10. Loss: 0.9364:  92%|[36m█████████▏[0m| 24/26 [00:24<00:01,  1.01it/s]Epoch: 4/10. Loss: 0.8356:  92%|[36m█████████▏[0m| 24/26 [00:25<00:01,  1.01it/s]Epoch: 4/10. Loss: 0.8356:  96%|[36m█████████▌[0m| 25/26 [00:25<00:01,  1.01s/it]Epoch: 4/10. Loss: 0.9484:  96%|[36m█████████▌[0m| 25/26 [00:26<00:01,  1.01s/it]Epoch: 4/10. Loss: 0.9484: 100%|[36m██████████[0m| 26/26 [00:26<00:00,  1.10it/s]Epoch: 4/10. Loss: 0.9484: 100%|[36m██████████[0m| 26/26 [00:26<00:00,  1.01s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:01<00:07,  1.25s/it] 29%|[33m██▊       [0m| 2/7 [00:02<00:05,  1.13s/it] 43%|[33m████▎     [0m| 3/7 [00:03<00:03,  1.04it/s] 57%|[33m█████▋    [0m| 4/7 [00:05<00:04,  1.45s/it] 71%|[33m███████▏  [0m| 5/7 [00:05<00:02,  1.09s/it] 86%|[33m████████▌ [0m| 6/7 [00:06<00:01,  1.02s/it]100%|[33m██████████[0m| 7/7 [00:06<00:00,  1.29it/s]100%|[33m██████████[0m| 7/7 [00:06<00:00,  1.02it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 5/10. Loss: 0.8425:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 5/10. Loss: 0.8425:   4%|[36m▍         [0m| 1/26 [00:00<00:22,  1.14it/s]Epoch: 5/10. Loss: 0.8989:   4%|[36m▍         [0m| 1/26 [00:03<00:22,  1.14it/s]Epoch: 5/10. Loss: 0.8989:   8%|[36m▊         [0m| 2/26 [00:04<00:53,  2.21s/it]Epoch: 5/10. Loss: 0.8673:   8%|[36m▊         [0m| 2/26 [00:06<00:53,  2.21s/it]Epoch: 5/10. Loss: 0.8673:  12%|[36m█▏        [0m| 3/26 [00:06<00:58,  2.53s/it]Epoch: 5/10. Loss: 0.8836:  12%|[36m█▏        [0m| 3/26 [00:08<00:58,  2.53s/it]Epoch: 5/10. Loss: 0.8836:  15%|[36m█▌        [0m| 4/26 [00:08<00:47,  2.14s/it]Epoch: 5/10. Loss: 1.0715:  15%|[36m█▌        [0m| 4/26 [00:09<00:47,  2.14s/it]Epoch: 5/10. Loss: 1.0715:  19%|[36m█▉        [0m| 5/26 [00:09<00:36,  1.73s/it]Epoch: 5/10. Loss: 0.9442:  19%|[36m█▉        [0m| 5/26 [00:10<00:36,  1.73s/it]Epoch: 5/10. Loss: 0.9442:  23%|[36m██▎       [0m| 6/26 [00:10<00:29,  1.46s/it]Epoch: 5/10. Loss: 0.9057:  23%|[36m██▎       [0m| 6/26 [00:11<00:29,  1.46s/it]Epoch: 5/10. Loss: 0.9057:  27%|[36m██▋       [0m| 7/26 [00:11<00:26,  1.41s/it]Epoch: 5/10. Loss: 0.9511:  27%|[36m██▋       [0m| 7/26 [00:12<00:26,  1.41s/it]Epoch: 5/10. Loss: 0.9511:  31%|[36m███       [0m| 8/26 [00:12<00:23,  1.33s/it]Epoch: 5/10. Loss: 0.9115:  31%|[36m███       [0m| 8/26 [00:13<00:23,  1.33s/it]Epoch: 5/10. Loss: 0.9115:  35%|[36m███▍      [0m| 9/26 [00:13<00:19,  1.16s/it]Epoch: 5/10. Loss: 0.8969:  35%|[36m███▍      [0m| 9/26 [00:14<00:19,  1.16s/it]Epoch: 5/10. Loss: 0.8969:  38%|[36m███▊      [0m| 10/26 [00:14<00:17,  1.06s/it]Epoch: 5/10. Loss: 0.8687:  38%|[36m███▊      [0m| 10/26 [00:15<00:17,  1.06s/it]Epoch: 5/10. Loss: 0.8687:  42%|[36m████▏     [0m| 11/26 [00:15<00:15,  1.06s/it]Epoch: 5/10. Loss: 0.8608:  42%|[36m████▏     [0m| 11/26 [00:16<00:15,  1.06s/it]Epoch: 5/10. Loss: 0.8608:  46%|[36m████▌     [0m| 12/26 [00:16<00:13,  1.04it/s]Epoch: 5/10. Loss: 0.9684:  46%|[36m████▌     [0m| 12/26 [00:17<00:13,  1.04it/s]Epoch: 5/10. Loss: 0.9684:  50%|[36m█████     [0m| 13/26 [00:17<00:11,  1.11it/s]Epoch: 5/10. Loss: 0.9890:  50%|[36m█████     [0m| 13/26 [00:17<00:11,  1.11it/s]Epoch: 5/10. Loss: 0.9890:  54%|[36m█████▍    [0m| 14/26 [00:17<00:10,  1.12it/s]Epoch: 5/10. Loss: 0.8996:  54%|[36m█████▍    [0m| 14/26 [00:18<00:10,  1.12it/s]Epoch: 5/10. Loss: 0.8996:  58%|[36m█████▊    [0m| 15/26 [00:18<00:09,  1.13it/s]Epoch: 5/10. Loss: 0.8489:  58%|[36m█████▊    [0m| 15/26 [00:19<00:09,  1.13it/s]Epoch: 5/10. Loss: 0.8489:  62%|[36m██████▏   [0m| 16/26 [00:19<00:09,  1.05it/s]Epoch: 5/10. Loss: 0.8879:  62%|[36m██████▏   [0m| 16/26 [00:20<00:09,  1.05it/s]Epoch: 5/10. Loss: 0.8879:  65%|[36m██████▌   [0m| 17/26 [00:20<00:08,  1.06it/s]Epoch: 5/10. Loss: 0.9639:  65%|[36m██████▌   [0m| 17/26 [00:21<00:08,  1.06it/s]Epoch: 5/10. Loss: 0.9639:  69%|[36m██████▉   [0m| 18/26 [00:21<00:07,  1.09it/s]Epoch: 5/10. Loss: 1.0006:  69%|[36m██████▉   [0m| 18/26 [00:22<00:07,  1.09it/s]Epoch: 5/10. Loss: 1.0006:  73%|[36m███████▎  [0m| 19/26 [00:22<00:06,  1.14it/s]Epoch: 5/10. Loss: 0.8893:  73%|[36m███████▎  [0m| 19/26 [00:23<00:06,  1.14it/s]Epoch: 5/10. Loss: 0.8893:  77%|[36m███████▋  [0m| 20/26 [00:23<00:05,  1.16it/s]Epoch: 5/10. Loss: 0.8447:  77%|[36m███████▋  [0m| 20/26 [00:24<00:05,  1.16it/s]Epoch: 5/10. Loss: 0.8447:  81%|[36m████████  [0m| 21/26 [00:24<00:04,  1.13it/s]Epoch: 5/10. Loss: 0.8953:  81%|[36m████████  [0m| 21/26 [00:25<00:04,  1.13it/s]Epoch: 5/10. Loss: 0.8953:  85%|[36m████████▍ [0m| 22/26 [00:25<00:03,  1.10it/s]Epoch: 5/10. Loss: 0.9447:  85%|[36m████████▍ [0m| 22/26 [00:27<00:03,  1.10it/s]Epoch: 5/10. Loss: 0.9447:  88%|[36m████████▊ [0m| 23/26 [00:27<00:03,  1.21s/it]Epoch: 5/10. Loss: 0.9458:  88%|[36m████████▊ [0m| 23/26 [00:28<00:03,  1.21s/it]Epoch: 5/10. Loss: 0.9458:  92%|[36m█████████▏[0m| 24/26 [00:28<00:02,  1.13s/it]Epoch: 5/10. Loss: 0.9093:  92%|[36m█████████▏[0m| 24/26 [00:29<00:02,  1.13s/it]Epoch: 5/10. Loss: 0.9093:  96%|[36m█████████▌[0m| 25/26 [00:29<00:01,  1.08s/it]Epoch: 5/10. Loss: 1.0093:  96%|[36m█████████▌[0m| 25/26 [00:29<00:01,  1.08s/it]Epoch: 5/10. Loss: 1.0093: 100%|[36m██████████[0m| 26/26 [00:29<00:00,  1.05it/s]Epoch: 5/10. Loss: 1.0093: 100%|[36m██████████[0m| 26/26 [00:29<00:00,  1.14s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:05,  1.13it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:05,  1.15s/it] 43%|[33m████▎     [0m| 3/7 [00:02<00:03,  1.04it/s] 57%|[33m█████▋    [0m| 4/7 [00:05<00:04,  1.61s/it] 71%|[33m███████▏  [0m| 5/7 [00:06<00:02,  1.19s/it] 86%|[33m████████▌ [0m| 6/7 [00:07<00:01,  1.19s/it]100%|[33m██████████[0m| 7/7 [00:07<00:00,  1.13it/s]100%|[33m██████████[0m| 7/7 [00:07<00:00,  1.07s/it]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 6/10. Loss: 0.9694:   0%|[36m          [0m| 0/26 [00:01<?, ?it/s]Epoch: 6/10. Loss: 0.9694:   4%|[36m▍         [0m| 1/26 [00:01<00:36,  1.44s/it]Epoch: 6/10. Loss: 0.8641:   4%|[36m▍         [0m| 1/26 [00:02<00:36,  1.44s/it]Epoch: 6/10. Loss: 0.8641:   8%|[36m▊         [0m| 2/26 [00:02<00:29,  1.25s/it]Epoch: 6/10. Loss: 0.9014:   8%|[36m▊         [0m| 2/26 [00:07<00:29,  1.25s/it]Epoch: 6/10. Loss: 0.9014:  12%|[36m█▏        [0m| 3/26 [00:07<01:04,  2.80s/it]Epoch: 6/10. Loss: 0.9302:  12%|[36m█▏        [0m| 3/26 [00:08<01:04,  2.80s/it]Epoch: 6/10. Loss: 0.9302:  15%|[36m█▌        [0m| 4/26 [00:08<00:47,  2.14s/it]Epoch: 6/10. Loss: 0.8932:  15%|[36m█▌        [0m| 4/26 [00:09<00:47,  2.14s/it]Epoch: 6/10. Loss: 0.8932:  19%|[36m█▉        [0m| 5/26 [00:09<00:36,  1.73s/it]Epoch: 6/10. Loss: 0.9637:  19%|[36m█▉        [0m| 5/26 [00:10<00:36,  1.73s/it]Epoch: 6/10. Loss: 0.9637:  23%|[36m██▎       [0m| 6/26 [00:10<00:29,  1.49s/it]Epoch: 6/10. Loss: 0.9403:  23%|[36m██▎       [0m| 6/26 [00:11<00:29,  1.49s/it]Epoch: 6/10. Loss: 0.9403:  27%|[36m██▋       [0m| 7/26 [00:11<00:24,  1.30s/it]Epoch: 6/10. Loss: 0.9067:  27%|[36m██▋       [0m| 7/26 [00:12<00:24,  1.30s/it]Epoch: 6/10. Loss: 0.9067:  31%|[36m███       [0m| 8/26 [00:12<00:21,  1.19s/it]Epoch: 6/10. Loss: 0.8455:  31%|[36m███       [0m| 8/26 [00:13<00:21,  1.19s/it]Epoch: 6/10. Loss: 0.8455:  35%|[36m███▍      [0m| 9/26 [00:13<00:18,  1.07s/it]Epoch: 6/10. Loss: 0.9245:  35%|[36m███▍      [0m| 9/26 [00:13<00:18,  1.07s/it]Epoch: 6/10. Loss: 0.9245:  38%|[36m███▊      [0m| 10/26 [00:13<00:15,  1.02it/s]Epoch: 6/10. Loss: 0.8664:  38%|[36m███▊      [0m| 10/26 [00:14<00:15,  1.02it/s]Epoch: 6/10. Loss: 0.8664:  42%|[36m████▏     [0m| 11/26 [00:14<00:14,  1.03it/s]Epoch: 6/10. Loss: 0.8507:  42%|[36m████▏     [0m| 11/26 [00:15<00:14,  1.03it/s]Epoch: 6/10. Loss: 0.8507:  46%|[36m████▌     [0m| 12/26 [00:15<00:14,  1.03s/it]Epoch: 6/10. Loss: 0.8747:  46%|[36m████▌     [0m| 12/26 [00:16<00:14,  1.03s/it]Epoch: 6/10. Loss: 0.8747:  50%|[36m█████     [0m| 13/26 [00:16<00:12,  1.02it/s]Epoch: 6/10. Loss: 0.8455:  50%|[36m█████     [0m| 13/26 [00:17<00:12,  1.02it/s]Epoch: 6/10. Loss: 0.8455:  54%|[36m█████▍    [0m| 14/26 [00:17<00:11,  1.08it/s]Epoch: 6/10. Loss: 0.8805:  54%|[36m█████▍    [0m| 14/26 [00:18<00:11,  1.08it/s]Epoch: 6/10. Loss: 0.8805:  58%|[36m█████▊    [0m| 15/26 [00:18<00:09,  1.12it/s]Epoch: 6/10. Loss: 0.9192:  58%|[36m█████▊    [0m| 15/26 [00:19<00:09,  1.12it/s]Epoch: 6/10. Loss: 0.9192:  62%|[36m██████▏   [0m| 16/26 [00:19<00:09,  1.08it/s]Epoch: 6/10. Loss: 0.9083:  62%|[36m██████▏   [0m| 16/26 [00:20<00:09,  1.08it/s]Epoch: 6/10. Loss: 0.9083:  65%|[36m██████▌   [0m| 17/26 [00:20<00:08,  1.07it/s]Epoch: 6/10. Loss: 0.8505:  65%|[36m██████▌   [0m| 17/26 [00:21<00:08,  1.07it/s]Epoch: 6/10. Loss: 0.8505:  69%|[36m██████▉   [0m| 18/26 [00:21<00:07,  1.01it/s]Epoch: 6/10. Loss: 0.9029:  69%|[36m██████▉   [0m| 18/26 [00:22<00:07,  1.01it/s]Epoch: 6/10. Loss: 0.9029:  73%|[36m███████▎  [0m| 19/26 [00:22<00:06,  1.00it/s]Epoch: 6/10. Loss: 1.0132:  73%|[36m███████▎  [0m| 19/26 [00:23<00:06,  1.00it/s]Epoch: 6/10. Loss: 1.0132:  77%|[36m███████▋  [0m| 20/26 [00:23<00:05,  1.03it/s]Epoch: 6/10. Loss: 0.9292:  77%|[36m███████▋  [0m| 20/26 [00:24<00:05,  1.03it/s]Epoch: 6/10. Loss: 0.9292:  81%|[36m████████  [0m| 21/26 [00:24<00:04,  1.09it/s]Epoch: 6/10. Loss: 0.9233:  81%|[36m████████  [0m| 21/26 [00:25<00:04,  1.09it/s]Epoch: 6/10. Loss: 0.9233:  85%|[36m████████▍ [0m| 22/26 [00:25<00:04,  1.05s/it]Epoch: 6/10. Loss: 0.8617:  85%|[36m████████▍ [0m| 22/26 [00:26<00:04,  1.05s/it]Epoch: 6/10. Loss: 0.8617:  88%|[36m████████▊ [0m| 23/26 [00:26<00:03,  1.10s/it]Epoch: 6/10. Loss: 1.0038:  88%|[36m████████▊ [0m| 23/26 [00:28<00:03,  1.10s/it]Epoch: 6/10. Loss: 1.0038:  92%|[36m█████████▏[0m| 24/26 [00:28<00:02,  1.42s/it]Epoch: 6/10. Loss: 0.8273:  92%|[36m█████████▏[0m| 24/26 [00:30<00:02,  1.42s/it]Epoch: 6/10. Loss: 0.8273:  96%|[36m█████████▌[0m| 25/26 [00:30<00:01,  1.38s/it]Epoch: 6/10. Loss: 0.8804:  96%|[36m█████████▌[0m| 25/26 [00:30<00:01,  1.38s/it]Epoch: 6/10. Loss: 0.8804: 100%|[36m██████████[0m| 26/26 [00:30<00:00,  1.16s/it]Epoch: 6/10. Loss: 0.8804: 100%|[36m██████████[0m| 26/26 [00:30<00:00,  1.19s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:01<00:11,  1.83s/it] 29%|[33m██▊       [0m| 2/7 [00:03<00:08,  1.70s/it] 43%|[33m████▎     [0m| 3/7 [00:04<00:04,  1.22s/it] 57%|[33m█████▋    [0m| 4/7 [00:07<00:06,  2.02s/it] 71%|[33m███████▏  [0m| 5/7 [00:08<00:03,  1.61s/it] 86%|[33m████████▌ [0m| 6/7 [00:09<00:01,  1.39s/it]100%|[33m██████████[0m| 7/7 [00:09<00:00,  1.02s/it]100%|[33m██████████[0m| 7/7 [00:09<00:00,  1.35s/it]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 7/10. Loss: 0.8311:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 7/10. Loss: 0.8311:   4%|[36m▍         [0m| 1/26 [00:00<00:18,  1.34it/s]Epoch: 7/10. Loss: 0.8293:   4%|[36m▍         [0m| 1/26 [00:01<00:18,  1.34it/s]Epoch: 7/10. Loss: 0.8293:   8%|[36m▊         [0m| 2/26 [00:01<00:22,  1.06it/s]Epoch: 7/10. Loss: 0.8763:   8%|[36m▊         [0m| 2/26 [00:03<00:22,  1.06it/s]Epoch: 7/10. Loss: 0.8763:  12%|[36m█▏        [0m| 3/26 [00:03<00:24,  1.06s/it]Epoch: 7/10. Loss: 0.7833:  12%|[36m█▏        [0m| 3/26 [00:03<00:24,  1.06s/it]Epoch: 7/10. Loss: 0.7833:  15%|[36m█▌        [0m| 4/26 [00:03<00:21,  1.04it/s]Epoch: 7/10. Loss: 0.9019:  15%|[36m█▌        [0m| 4/26 [00:05<00:21,  1.04it/s]Epoch: 7/10. Loss: 0.9019:  19%|[36m█▉        [0m| 5/26 [00:05<00:23,  1.11s/it]Epoch: 7/10. Loss: 1.0000:  19%|[36m█▉        [0m| 5/26 [00:06<00:23,  1.11s/it]Epoch: 7/10. Loss: 1.0000:  23%|[36m██▎       [0m| 6/26 [00:06<00:23,  1.18s/it]Epoch: 7/10. Loss: 0.9067:  23%|[36m██▎       [0m| 6/26 [00:07<00:23,  1.18s/it]Epoch: 7/10. Loss: 0.9067:  27%|[36m██▋       [0m| 7/26 [00:08<00:24,  1.28s/it]Epoch: 7/10. Loss: 0.8461:  27%|[36m██▋       [0m| 7/26 [00:09<00:24,  1.28s/it]Epoch: 7/10. Loss: 0.8461:  31%|[36m███       [0m| 8/26 [00:09<00:25,  1.41s/it]Epoch: 7/10. Loss: 0.9254:  31%|[36m███       [0m| 8/26 [00:11<00:25,  1.41s/it]Epoch: 7/10. Loss: 0.9254:  35%|[36m███▍      [0m| 9/26 [00:11<00:27,  1.64s/it]Epoch: 7/10. Loss: 0.8165:  35%|[36m███▍      [0m| 9/26 [00:13<00:27,  1.64s/it]Epoch: 7/10. Loss: 0.8165:  38%|[36m███▊      [0m| 10/26 [00:13<00:27,  1.74s/it]Epoch: 7/10. Loss: 0.8829:  38%|[36m███▊      [0m| 10/26 [00:14<00:27,  1.74s/it]Epoch: 7/10. Loss: 0.8829:  42%|[36m████▏     [0m| 11/26 [00:14<00:22,  1.50s/it]Epoch: 7/10. Loss: 0.9298:  42%|[36m████▏     [0m| 11/26 [00:15<00:22,  1.50s/it]Epoch: 7/10. Loss: 0.9298:  46%|[36m████▌     [0m| 12/26 [00:15<00:18,  1.33s/it]Epoch: 7/10. Loss: 0.9668:  46%|[36m████▌     [0m| 12/26 [00:18<00:18,  1.33s/it]Epoch: 7/10. Loss: 0.9668:  50%|[36m█████     [0m| 13/26 [00:18<00:22,  1.72s/it]Epoch: 7/10. Loss: 0.9090:  50%|[36m█████     [0m| 13/26 [00:19<00:22,  1.72s/it]Epoch: 7/10. Loss: 0.9090:  54%|[36m█████▍    [0m| 14/26 [00:19<00:17,  1.50s/it]Epoch: 7/10. Loss: 0.8994:  54%|[36m█████▍    [0m| 14/26 [00:21<00:17,  1.50s/it]Epoch: 7/10. Loss: 0.8994:  58%|[36m█████▊    [0m| 15/26 [00:21<00:19,  1.74s/it]Epoch: 7/10. Loss: 1.0408:  58%|[36m█████▊    [0m| 15/26 [00:23<00:19,  1.74s/it]Epoch: 7/10. Loss: 1.0408:  62%|[36m██████▏   [0m| 16/26 [00:23<00:17,  1.73s/it]Epoch: 7/10. Loss: 0.9286:  62%|[36m██████▏   [0m| 16/26 [00:24<00:17,  1.73s/it]Epoch: 7/10. Loss: 0.9286:  65%|[36m██████▌   [0m| 17/26 [00:24<00:13,  1.54s/it]Epoch: 7/10. Loss: 0.8344:  65%|[36m██████▌   [0m| 17/26 [00:25<00:13,  1.54s/it]Epoch: 7/10. Loss: 0.8344:  69%|[36m██████▉   [0m| 18/26 [00:25<00:10,  1.35s/it]Epoch: 7/10. Loss: 0.9131:  69%|[36m██████▉   [0m| 18/26 [00:26<00:10,  1.35s/it]Epoch: 7/10. Loss: 0.9131:  73%|[36m███████▎  [0m| 19/26 [00:26<00:09,  1.30s/it]Epoch: 7/10. Loss: 0.8222:  73%|[36m███████▎  [0m| 19/26 [00:27<00:09,  1.30s/it]Epoch: 7/10. Loss: 0.8222:  77%|[36m███████▋  [0m| 20/26 [00:27<00:07,  1.20s/it]Epoch: 7/10. Loss: 0.8892:  77%|[36m███████▋  [0m| 20/26 [00:28<00:07,  1.20s/it]Epoch: 7/10. Loss: 0.8892:  81%|[36m████████  [0m| 21/26 [00:28<00:05,  1.12s/it]Epoch: 7/10. Loss: 0.8278:  81%|[36m████████  [0m| 21/26 [00:29<00:05,  1.12s/it]Epoch: 7/10. Loss: 0.8278:  85%|[36m████████▍ [0m| 22/26 [00:29<00:04,  1.13s/it]Epoch: 7/10. Loss: 0.8587:  85%|[36m████████▍ [0m| 22/26 [00:30<00:04,  1.13s/it]Epoch: 7/10. Loss: 0.8587:  88%|[36m████████▊ [0m| 23/26 [00:30<00:03,  1.15s/it]Epoch: 7/10. Loss: 0.8682:  88%|[36m████████▊ [0m| 23/26 [00:32<00:03,  1.15s/it]Epoch: 7/10. Loss: 0.8682:  92%|[36m█████████▏[0m| 24/26 [00:32<00:02,  1.45s/it]Epoch: 7/10. Loss: 0.7669:  92%|[36m█████████▏[0m| 24/26 [00:33<00:02,  1.45s/it]Epoch: 7/10. Loss: 0.7669:  96%|[36m█████████▌[0m| 25/26 [00:33<00:01,  1.27s/it]Epoch: 7/10. Loss: 0.8830:  96%|[36m█████████▌[0m| 25/26 [00:34<00:01,  1.27s/it]Epoch: 7/10. Loss: 0.8830: 100%|[36m██████████[0m| 26/26 [00:34<00:00,  1.12s/it]Epoch: 7/10. Loss: 0.8830: 100%|[36m██████████[0m| 26/26 [00:34<00:00,  1.33s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:04,  1.23it/s] 29%|[33m██▊       [0m| 2/7 [00:01<00:04,  1.08it/s] 43%|[33m████▎     [0m| 3/7 [00:02<00:03,  1.22it/s] 57%|[33m█████▋    [0m| 4/7 [00:03<00:03,  1.01s/it] 71%|[33m███████▏  [0m| 5/7 [00:04<00:01,  1.25it/s] 86%|[33m████████▌ [0m| 6/7 [00:05<00:00,  1.21it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.56it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.30it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 8/10. Loss: 0.8740:   0%|[36m          [0m| 0/26 [00:01<?, ?it/s]Epoch: 8/10. Loss: 0.8740:   4%|[36m▍         [0m| 1/26 [00:01<00:44,  1.76s/it]Epoch: 8/10. Loss: 0.8740:   4%|[36m▍         [0m| 1/26 [00:02<00:44,  1.76s/it]Epoch: 8/10. Loss: 0.8740:   8%|[36m▊         [0m| 2/26 [00:02<00:33,  1.41s/it]Epoch: 8/10. Loss: 0.8348:   8%|[36m▊         [0m| 2/26 [00:04<00:33,  1.41s/it]Epoch: 8/10. Loss: 0.8348:  12%|[36m█▏        [0m| 3/26 [00:04<00:38,  1.67s/it]Epoch: 8/10. Loss: 0.8379:  12%|[36m█▏        [0m| 3/26 [00:05<00:38,  1.67s/it]Epoch: 8/10. Loss: 0.8379:  15%|[36m█▌        [0m| 4/26 [00:05<00:29,  1.35s/it]Epoch: 8/10. Loss: 0.8492:  15%|[36m█▌        [0m| 4/26 [00:06<00:29,  1.35s/it]Epoch: 8/10. Loss: 0.8492:  19%|[36m█▉        [0m| 5/26 [00:06<00:25,  1.23s/it]Epoch: 8/10. Loss: 0.7980:  19%|[36m█▉        [0m| 5/26 [00:07<00:25,  1.23s/it]Epoch: 8/10. Loss: 0.7980:  23%|[36m██▎       [0m| 6/26 [00:07<00:22,  1.10s/it]Epoch: 8/10. Loss: 0.8093:  23%|[36m██▎       [0m| 6/26 [00:08<00:22,  1.10s/it]Epoch: 8/10. Loss: 0.8093:  27%|[36m██▋       [0m| 7/26 [00:08<00:19,  1.05s/it]Epoch: 8/10. Loss: 0.7408:  27%|[36m██▋       [0m| 7/26 [00:09<00:19,  1.05s/it]Epoch: 8/10. Loss: 0.7408:  31%|[36m███       [0m| 8/26 [00:09<00:18,  1.02s/it]Epoch: 8/10. Loss: 0.8508:  31%|[36m███       [0m| 8/26 [00:10<00:18,  1.02s/it]Epoch: 8/10. Loss: 0.8508:  35%|[36m███▍      [0m| 9/26 [00:10<00:17,  1.00s/it]Epoch: 8/10. Loss: 0.8136:  35%|[36m███▍      [0m| 9/26 [00:11<00:17,  1.00s/it]Epoch: 8/10. Loss: 0.8136:  38%|[36m███▊      [0m| 10/26 [00:11<00:16,  1.02s/it]Epoch: 8/10. Loss: 0.8405:  38%|[36m███▊      [0m| 10/26 [00:13<00:16,  1.02s/it]Epoch: 8/10. Loss: 0.8405:  42%|[36m████▏     [0m| 11/26 [00:13<00:19,  1.31s/it]Epoch: 8/10. Loss: 0.9824:  42%|[36m████▏     [0m| 11/26 [00:15<00:19,  1.31s/it]Epoch: 8/10. Loss: 0.9824:  46%|[36m████▌     [0m| 12/26 [00:15<00:21,  1.51s/it]Epoch: 8/10. Loss: 0.7528:  46%|[36m████▌     [0m| 12/26 [00:18<00:21,  1.51s/it]Epoch: 8/10. Loss: 0.7528:  50%|[36m█████     [0m| 13/26 [00:18<00:24,  1.91s/it]Epoch: 8/10. Loss: 0.8377:  50%|[36m█████     [0m| 13/26 [00:19<00:24,  1.91s/it]Epoch: 8/10. Loss: 0.8377:  54%|[36m█████▍    [0m| 14/26 [00:19<00:18,  1.55s/it]Epoch: 8/10. Loss: 0.9418:  54%|[36m█████▍    [0m| 14/26 [00:19<00:18,  1.55s/it]Epoch: 8/10. Loss: 0.9418:  58%|[36m█████▊    [0m| 15/26 [00:19<00:15,  1.37s/it]Epoch: 8/10. Loss: 0.8173:  58%|[36m█████▊    [0m| 15/26 [00:20<00:15,  1.37s/it]Epoch: 8/10. Loss: 0.8173:  62%|[36m██████▏   [0m| 16/26 [00:20<00:12,  1.22s/it]Epoch: 8/10. Loss: 0.7948:  62%|[36m██████▏   [0m| 16/26 [00:21<00:12,  1.22s/it]Epoch: 8/10. Loss: 0.7948:  65%|[36m██████▌   [0m| 17/26 [00:21<00:10,  1.16s/it]Epoch: 8/10. Loss: 0.8405:  65%|[36m██████▌   [0m| 17/26 [00:22<00:10,  1.16s/it]Epoch: 8/10. Loss: 0.8405:  69%|[36m██████▉   [0m| 18/26 [00:22<00:08,  1.07s/it]Epoch: 8/10. Loss: 0.7740:  69%|[36m██████▉   [0m| 18/26 [00:23<00:08,  1.07s/it]Epoch: 8/10. Loss: 0.7740:  73%|[36m███████▎  [0m| 19/26 [00:23<00:07,  1.06s/it]Epoch: 8/10. Loss: 0.9085:  73%|[36m███████▎  [0m| 19/26 [00:26<00:07,  1.06s/it]Epoch: 8/10. Loss: 0.9085:  77%|[36m███████▋  [0m| 20/26 [00:26<00:08,  1.47s/it]Epoch: 8/10. Loss: 0.7685:  77%|[36m███████▋  [0m| 20/26 [00:27<00:08,  1.47s/it]Epoch: 8/10. Loss: 0.7685:  81%|[36m████████  [0m| 21/26 [00:27<00:07,  1.50s/it]Epoch: 8/10. Loss: 0.8236:  81%|[36m████████  [0m| 21/26 [00:29<00:07,  1.50s/it]Epoch: 8/10. Loss: 0.8236:  85%|[36m████████▍ [0m| 22/26 [00:29<00:06,  1.57s/it]Epoch: 8/10. Loss: 0.7682:  85%|[36m████████▍ [0m| 22/26 [00:30<00:06,  1.57s/it]Epoch: 8/10. Loss: 0.7682:  88%|[36m████████▊ [0m| 23/26 [00:30<00:04,  1.33s/it]Epoch: 8/10. Loss: 0.9359:  88%|[36m████████▊ [0m| 23/26 [00:31<00:04,  1.33s/it]Epoch: 8/10. Loss: 0.9359:  92%|[36m█████████▏[0m| 24/26 [00:31<00:02,  1.16s/it]Epoch: 8/10. Loss: 0.8132:  92%|[36m█████████▏[0m| 24/26 [00:32<00:02,  1.16s/it]Epoch: 8/10. Loss: 0.8132:  96%|[36m█████████▌[0m| 25/26 [00:32<00:01,  1.33s/it]Epoch: 8/10. Loss: 0.7815:  96%|[36m█████████▌[0m| 25/26 [00:33<00:01,  1.33s/it]Epoch: 8/10. Loss: 0.7815: 100%|[36m██████████[0m| 26/26 [00:33<00:00,  1.09s/it]Epoch: 8/10. Loss: 0.7815: 100%|[36m██████████[0m| 26/26 [00:33<00:00,  1.28s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:02<00:12,  2.15s/it] 29%|[33m██▊       [0m| 2/7 [00:03<00:09,  1.94s/it] 43%|[33m████▎     [0m| 3/7 [00:04<00:05,  1.39s/it] 57%|[33m█████▋    [0m| 4/7 [00:08<00:06,  2.21s/it] 71%|[33m███████▏  [0m| 5/7 [00:08<00:03,  1.58s/it] 86%|[33m████████▌ [0m| 6/7 [00:09<00:01,  1.38s/it]100%|[33m██████████[0m| 7/7 [00:10<00:00,  1.21s/it]100%|[33m██████████[0m| 7/7 [00:10<00:00,  1.49s/it]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 9/10. Loss: 0.7646:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 9/10. Loss: 0.7646:   4%|[36m▍         [0m| 1/26 [00:00<00:24,  1.01it/s]Epoch: 9/10. Loss: 0.7628:   4%|[36m▍         [0m| 1/26 [00:02<00:24,  1.01it/s]Epoch: 9/10. Loss: 0.7628:   8%|[36m▊         [0m| 2/26 [00:02<00:25,  1.05s/it]Epoch: 9/10. Loss: 0.8612:   8%|[36m▊         [0m| 2/26 [00:02<00:25,  1.05s/it]Epoch: 9/10. Loss: 0.8612:  12%|[36m█▏        [0m| 3/26 [00:02<00:21,  1.06it/s]Epoch: 9/10. Loss: 0.6997:  12%|[36m█▏        [0m| 3/26 [00:08<00:21,  1.06it/s]Epoch: 9/10. Loss: 0.6997:  15%|[36m█▌        [0m| 4/26 [00:08<00:58,  2.67s/it]Epoch: 9/10. Loss: 0.8562:  15%|[36m█▌        [0m| 4/26 [00:09<00:58,  2.67s/it]Epoch: 9/10. Loss: 0.8562:  19%|[36m█▉        [0m| 5/26 [00:09<00:44,  2.10s/it]Epoch: 9/10. Loss: 0.7964:  19%|[36m█▉        [0m| 5/26 [00:10<00:44,  2.10s/it]Epoch: 9/10. Loss: 0.7964:  23%|[36m██▎       [0m| 6/26 [00:10<00:37,  1.85s/it]Epoch: 9/10. Loss: 0.8040:  23%|[36m██▎       [0m| 6/26 [00:11<00:37,  1.85s/it]Epoch: 9/10. Loss: 0.8040:  27%|[36m██▋       [0m| 7/26 [00:11<00:30,  1.59s/it]Epoch: 9/10. Loss: 0.8301:  27%|[36m██▋       [0m| 7/26 [00:12<00:30,  1.59s/it]Epoch: 9/10. Loss: 0.8301:  31%|[36m███       [0m| 8/26 [00:12<00:24,  1.36s/it]Epoch: 9/10. Loss: 0.8403:  31%|[36m███       [0m| 8/26 [00:14<00:24,  1.36s/it]Epoch: 9/10. Loss: 0.8403:  35%|[36m███▍      [0m| 9/26 [00:14<00:27,  1.64s/it]Epoch: 9/10. Loss: 0.8205:  35%|[36m███▍      [0m| 9/26 [00:15<00:27,  1.64s/it]Epoch: 9/10. Loss: 0.8205:  38%|[36m███▊      [0m| 10/26 [00:15<00:22,  1.43s/it]Epoch: 9/10. Loss: 0.7544:  38%|[36m███▊      [0m| 10/26 [00:16<00:22,  1.43s/it]Epoch: 9/10. Loss: 0.7544:  42%|[36m████▏     [0m| 11/26 [00:16<00:18,  1.24s/it]Epoch: 9/10. Loss: 0.8051:  42%|[36m████▏     [0m| 11/26 [00:17<00:18,  1.24s/it]Epoch: 9/10. Loss: 0.8051:  46%|[36m████▌     [0m| 12/26 [00:17<00:15,  1.12s/it]Epoch: 9/10. Loss: 0.7784:  46%|[36m████▌     [0m| 12/26 [00:18<00:15,  1.12s/it]Epoch: 9/10. Loss: 0.7784:  50%|[36m█████     [0m| 13/26 [00:18<00:13,  1.07s/it]Epoch: 9/10. Loss: 0.8537:  50%|[36m█████     [0m| 13/26 [00:19<00:13,  1.07s/it]Epoch: 9/10. Loss: 0.8537:  54%|[36m█████▍    [0m| 14/26 [00:19<00:12,  1.04s/it]Epoch: 9/10. Loss: 0.8613:  54%|[36m█████▍    [0m| 14/26 [00:20<00:12,  1.04s/it]Epoch: 9/10. Loss: 0.8613:  58%|[36m█████▊    [0m| 15/26 [00:20<00:10,  1.05it/s]Epoch: 9/10. Loss: 0.8428:  58%|[36m█████▊    [0m| 15/26 [00:20<00:10,  1.05it/s]Epoch: 9/10. Loss: 0.8428:  62%|[36m██████▏   [0m| 16/26 [00:20<00:09,  1.09it/s]Epoch: 9/10. Loss: 0.7889:  62%|[36m██████▏   [0m| 16/26 [00:22<00:09,  1.09it/s]Epoch: 9/10. Loss: 0.7889:  65%|[36m██████▌   [0m| 17/26 [00:22<00:09,  1.06s/it]Epoch: 9/10. Loss: 0.6992:  65%|[36m██████▌   [0m| 17/26 [00:23<00:09,  1.06s/it]Epoch: 9/10. Loss: 0.6992:  69%|[36m██████▉   [0m| 18/26 [00:23<00:08,  1.01s/it]Epoch: 9/10. Loss: 0.8291:  69%|[36m██████▉   [0m| 18/26 [00:24<00:08,  1.01s/it]Epoch: 9/10. Loss: 0.8291:  73%|[36m███████▎  [0m| 19/26 [00:24<00:06,  1.06it/s]Epoch: 9/10. Loss: 0.7869:  73%|[36m███████▎  [0m| 19/26 [00:24<00:06,  1.06it/s]Epoch: 9/10. Loss: 0.7869:  77%|[36m███████▋  [0m| 20/26 [00:24<00:05,  1.07it/s]Epoch: 9/10. Loss: 0.7447:  77%|[36m███████▋  [0m| 20/26 [00:26<00:05,  1.07it/s]Epoch: 9/10. Loss: 0.7447:  81%|[36m████████  [0m| 21/26 [00:26<00:05,  1.07s/it]Epoch: 9/10. Loss: 0.8257:  81%|[36m████████  [0m| 21/26 [00:27<00:05,  1.07s/it]Epoch: 9/10. Loss: 0.8257:  85%|[36m████████▍ [0m| 22/26 [00:28<00:04,  1.25s/it]Epoch: 9/10. Loss: 0.7409:  85%|[36m████████▍ [0m| 22/26 [00:28<00:04,  1.25s/it]Epoch: 9/10. Loss: 0.7409:  88%|[36m████████▊ [0m| 23/26 [00:28<00:03,  1.15s/it]Epoch: 9/10. Loss: 0.8232:  88%|[36m████████▊ [0m| 23/26 [00:29<00:03,  1.15s/it]Epoch: 9/10. Loss: 0.8232:  92%|[36m█████████▏[0m| 24/26 [00:29<00:02,  1.09s/it]Epoch: 9/10. Loss: 0.7485:  92%|[36m█████████▏[0m| 24/26 [00:31<00:02,  1.09s/it]Epoch: 9/10. Loss: 0.7485:  96%|[36m█████████▌[0m| 25/26 [00:31<00:01,  1.23s/it]Epoch: 9/10. Loss: 0.8101:  96%|[36m█████████▌[0m| 25/26 [00:32<00:01,  1.23s/it]Epoch: 9/10. Loss: 0.8101: 100%|[36m██████████[0m| 26/26 [00:32<00:00,  1.08s/it]Epoch: 9/10. Loss: 0.8101: 100%|[36m██████████[0m| 26/26 [00:32<00:00,  1.24s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:04,  1.30it/s] 29%|[33m██▊       [0m| 2/7 [00:01<00:04,  1.14it/s] 43%|[33m████▎     [0m| 3/7 [00:02<00:03,  1.28it/s] 57%|[33m█████▋    [0m| 4/7 [00:03<00:02,  1.04it/s] 71%|[33m███████▏  [0m| 5/7 [00:04<00:01,  1.29it/s] 86%|[33m████████▌ [0m| 6/7 [00:04<00:00,  1.23it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.58it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.34it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 0/10. Loss: 1.5093:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 0/10. Loss: 1.5093:   4%|[36m▍         [0m| 1/26 [00:00<00:20,  1.20it/s]Epoch: 0/10. Loss: 7.7544:   4%|[36m▍         [0m| 1/26 [00:02<00:20,  1.20it/s]Epoch: 0/10. Loss: 7.7544:   8%|[36m▊         [0m| 2/26 [00:02<00:27,  1.13s/it]Epoch: 0/10. Loss: 9.8048:   8%|[36m▊         [0m| 2/26 [00:03<00:27,  1.13s/it]Epoch: 0/10. Loss: 9.8048:  12%|[36m█▏        [0m| 3/26 [00:03<00:25,  1.12s/it]Epoch: 0/10. Loss: 5.2478:  12%|[36m█▏        [0m| 3/26 [00:05<00:25,  1.12s/it]Epoch: 0/10. Loss: 5.2478:  15%|[36m█▌        [0m| 4/26 [00:05<00:35,  1.60s/it]Epoch: 0/10. Loss: 3.1773:  15%|[36m█▌        [0m| 4/26 [00:06<00:35,  1.60s/it]Epoch: 0/10. Loss: 3.1773:  19%|[36m█▉        [0m| 5/26 [00:06<00:29,  1.42s/it]Epoch: 0/10. Loss: 2.0087:  19%|[36m█▉        [0m| 5/26 [00:07<00:29,  1.42s/it]Epoch: 0/10. Loss: 2.0087:  23%|[36m██▎       [0m| 6/26 [00:07<00:25,  1.26s/it]Epoch: 0/10. Loss: 0.9660:  23%|[36m██▎       [0m| 6/26 [00:10<00:25,  1.26s/it]Epoch: 0/10. Loss: 0.9660:  27%|[36m██▋       [0m| 7/26 [00:10<00:32,  1.69s/it]Epoch: 0/10. Loss: 1.8471:  27%|[36m██▋       [0m| 7/26 [00:15<00:32,  1.69s/it]Epoch: 0/10. Loss: 1.8471:  31%|[36m███       [0m| 8/26 [00:15<00:48,  2.70s/it]Epoch: 0/10. Loss: 1.9535:  31%|[36m███       [0m| 8/26 [00:16<00:48,  2.70s/it]Epoch: 0/10. Loss: 1.9535:  35%|[36m███▍      [0m| 9/26 [00:16<00:38,  2.25s/it]Epoch: 0/10. Loss: 1.7943:  35%|[36m███▍      [0m| 9/26 [00:17<00:38,  2.25s/it]Epoch: 0/10. Loss: 1.7943:  38%|[36m███▊      [0m| 10/26 [00:17<00:29,  1.86s/it]Epoch: 0/10. Loss: 1.4587:  38%|[36m███▊      [0m| 10/26 [00:18<00:29,  1.86s/it]Epoch: 0/10. Loss: 1.4587:  42%|[36m████▏     [0m| 11/26 [00:18<00:25,  1.70s/it]Epoch: 0/10. Loss: 1.5775:  42%|[36m████▏     [0m| 11/26 [00:20<00:25,  1.70s/it]Epoch: 0/10. Loss: 1.5775:  46%|[36m████▌     [0m| 12/26 [00:20<00:24,  1.77s/it]Epoch: 0/10. Loss: 1.3122:  46%|[36m████▌     [0m| 12/26 [00:21<00:24,  1.77s/it]Epoch: 0/10. Loss: 1.3122:  50%|[36m█████     [0m| 13/26 [00:21<00:19,  1.52s/it]Epoch: 0/10. Loss: 1.0848:  50%|[36m█████     [0m| 13/26 [00:22<00:19,  1.52s/it]Epoch: 0/10. Loss: 1.0848:  54%|[36m█████▍    [0m| 14/26 [00:22<00:17,  1.45s/it]Epoch: 0/10. Loss: 4.5181:  54%|[36m█████▍    [0m| 14/26 [00:23<00:17,  1.45s/it]Epoch: 0/10. Loss: 4.5181:  58%|[36m█████▊    [0m| 15/26 [00:23<00:14,  1.31s/it]Epoch: 0/10. Loss: 1.5091:  58%|[36m█████▊    [0m| 15/26 [00:25<00:14,  1.31s/it]Epoch: 0/10. Loss: 1.5091:  62%|[36m██████▏   [0m| 16/26 [00:25<00:12,  1.30s/it]Epoch: 0/10. Loss: 1.6479:  62%|[36m██████▏   [0m| 16/26 [00:26<00:12,  1.30s/it]Epoch: 0/10. Loss: 1.6479:  65%|[36m██████▌   [0m| 17/26 [00:26<00:13,  1.45s/it]Epoch: 0/10. Loss: 2.1278:  65%|[36m██████▌   [0m| 17/26 [00:28<00:13,  1.45s/it]Epoch: 0/10. Loss: 2.1278:  69%|[36m██████▉   [0m| 18/26 [00:28<00:12,  1.58s/it]Epoch: 0/10. Loss: 1.2674:  69%|[36m██████▉   [0m| 18/26 [00:30<00:12,  1.58s/it]Epoch: 0/10. Loss: 1.2674:  73%|[36m███████▎  [0m| 19/26 [00:30<00:10,  1.53s/it]Epoch: 0/10. Loss: 1.5906:  73%|[36m███████▎  [0m| 19/26 [00:31<00:10,  1.53s/it]Epoch: 0/10. Loss: 1.5906:  77%|[36m███████▋  [0m| 20/26 [00:31<00:08,  1.36s/it]Epoch: 0/10. Loss: 1.6028:  77%|[36m███████▋  [0m| 20/26 [00:32<00:08,  1.36s/it]Epoch: 0/10. Loss: 1.6028:  81%|[36m████████  [0m| 21/26 [00:32<00:06,  1.21s/it]Epoch: 0/10. Loss: 1.8841:  81%|[36m████████  [0m| 21/26 [00:32<00:06,  1.21s/it]Epoch: 0/10. Loss: 1.8841:  85%|[36m████████▍ [0m| 22/26 [00:33<00:04,  1.14s/it]Epoch: 0/10. Loss: 1.0729:  85%|[36m████████▍ [0m| 22/26 [00:33<00:04,  1.14s/it]Epoch: 0/10. Loss: 1.0729:  88%|[36m████████▊ [0m| 23/26 [00:33<00:03,  1.09s/it]Epoch: 0/10. Loss: 1.0639:  88%|[36m████████▊ [0m| 23/26 [00:35<00:03,  1.09s/it]Epoch: 0/10. Loss: 1.0639:  92%|[36m█████████▏[0m| 24/26 [00:35<00:02,  1.30s/it]Epoch: 0/10. Loss: 1.1323:  92%|[36m█████████▏[0m| 24/26 [00:36<00:02,  1.30s/it]Epoch: 0/10. Loss: 1.1323:  96%|[36m█████████▌[0m| 25/26 [00:36<00:01,  1.19s/it]Epoch: 0/10. Loss: 1.0605:  96%|[36m█████████▌[0m| 25/26 [00:37<00:01,  1.19s/it]Epoch: 0/10. Loss: 1.0605: 100%|[36m██████████[0m| 26/26 [00:37<00:00,  1.05s/it]Epoch: 0/10. Loss: 1.0605: 100%|[36m██████████[0m| 26/26 [00:37<00:00,  1.44s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:05,  1.19it/s] 29%|[33m██▊       [0m| 2/7 [00:01<00:04,  1.04it/s] 43%|[33m████▎     [0m| 3/7 [00:02<00:03,  1.16it/s] 57%|[33m█████▋    [0m| 4/7 [00:03<00:03,  1.04s/it] 71%|[33m███████▏  [0m| 5/7 [00:04<00:01,  1.18it/s] 86%|[33m████████▌ [0m| 6/7 [00:05<00:01,  1.02s/it]100%|[33m██████████[0m| 7/7 [00:06<00:00,  1.28it/s]100%|[33m██████████[0m| 7/7 [00:06<00:00,  1.15it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 1/10. Loss: 1.0515:   0%|[36m          [0m| 0/26 [00:01<?, ?it/s]Epoch: 1/10. Loss: 1.0515:   4%|[36m▍         [0m| 1/26 [00:01<00:27,  1.10s/it]Epoch: 1/10. Loss: 1.3306:   4%|[36m▍         [0m| 1/26 [00:02<00:27,  1.10s/it]Epoch: 1/10. Loss: 1.3306:   8%|[36m▊         [0m| 2/26 [00:02<00:24,  1.02s/it]Epoch: 1/10. Loss: 1.2283:   8%|[36m▊         [0m| 2/26 [00:03<00:24,  1.02s/it]Epoch: 1/10. Loss: 1.2283:  12%|[36m█▏        [0m| 3/26 [00:03<00:23,  1.01s/it]Epoch: 1/10. Loss: 1.1993:  12%|[36m█▏        [0m| 3/26 [00:04<00:23,  1.01s/it]Epoch: 1/10. Loss: 1.1993:  15%|[36m█▌        [0m| 4/26 [00:04<00:22,  1.00s/it]Epoch: 1/10. Loss: 1.0510:  15%|[36m█▌        [0m| 4/26 [00:05<00:22,  1.00s/it]Epoch: 1/10. Loss: 1.0510:  19%|[36m█▉        [0m| 5/26 [00:05<00:20,  1.01it/s]Epoch: 1/10. Loss: 1.1042:  19%|[36m█▉        [0m| 5/26 [00:07<00:20,  1.01it/s]Epoch: 1/10. Loss: 1.1042:  23%|[36m██▎       [0m| 6/26 [00:07<00:28,  1.41s/it]Epoch: 1/10. Loss: 1.0165:  23%|[36m██▎       [0m| 6/26 [00:08<00:28,  1.41s/it]Epoch: 1/10. Loss: 1.0165:  27%|[36m██▋       [0m| 7/26 [00:08<00:25,  1.32s/it]Epoch: 1/10. Loss: 1.1094:  27%|[36m██▋       [0m| 7/26 [00:09<00:25,  1.32s/it]Epoch: 1/10. Loss: 1.1094:  31%|[36m███       [0m| 8/26 [00:09<00:21,  1.17s/it]Epoch: 1/10. Loss: 1.0173:  31%|[36m███       [0m| 8/26 [00:10<00:21,  1.17s/it]Epoch: 1/10. Loss: 1.0173:  35%|[36m███▍      [0m| 9/26 [00:10<00:19,  1.17s/it]Epoch: 1/10. Loss: 1.0053:  35%|[36m███▍      [0m| 9/26 [00:11<00:19,  1.17s/it]Epoch: 1/10. Loss: 1.0053:  38%|[36m███▊      [0m| 10/26 [00:11<00:17,  1.11s/it]Epoch: 1/10. Loss: 1.1495:  38%|[36m███▊      [0m| 10/26 [00:12<00:17,  1.11s/it]Epoch: 1/10. Loss: 1.1495:  42%|[36m████▏     [0m| 11/26 [00:12<00:17,  1.17s/it]Epoch: 1/10. Loss: 1.0816:  42%|[36m████▏     [0m| 11/26 [00:13<00:17,  1.17s/it]Epoch: 1/10. Loss: 1.0816:  46%|[36m████▌     [0m| 12/26 [00:13<00:15,  1.12s/it]Epoch: 1/10. Loss: 1.0320:  46%|[36m████▌     [0m| 12/26 [00:14<00:15,  1.12s/it]Epoch: 1/10. Loss: 1.0320:  50%|[36m█████     [0m| 13/26 [00:14<00:14,  1.14s/it]Epoch: 1/10. Loss: 1.0198:  50%|[36m█████     [0m| 13/26 [00:15<00:14,  1.14s/it]Epoch: 1/10. Loss: 1.0198:  54%|[36m█████▍    [0m| 14/26 [00:15<00:13,  1.12s/it]Epoch: 1/10. Loss: 0.9721:  54%|[36m█████▍    [0m| 14/26 [00:17<00:13,  1.12s/it]Epoch: 1/10. Loss: 0.9721:  58%|[36m█████▊    [0m| 15/26 [00:17<00:12,  1.13s/it]Epoch: 1/10. Loss: 0.9105:  58%|[36m█████▊    [0m| 15/26 [00:18<00:12,  1.13s/it]Epoch: 1/10. Loss: 0.9105:  62%|[36m██████▏   [0m| 16/26 [00:18<00:11,  1.12s/it]Epoch: 1/10. Loss: 0.9543:  62%|[36m██████▏   [0m| 16/26 [00:19<00:11,  1.12s/it]Epoch: 1/10. Loss: 0.9543:  65%|[36m██████▌   [0m| 17/26 [00:19<00:09,  1.03s/it]Epoch: 1/10. Loss: 0.9940:  65%|[36m██████▌   [0m| 17/26 [00:19<00:09,  1.03s/it]Epoch: 1/10. Loss: 0.9940:  69%|[36m██████▉   [0m| 18/26 [00:19<00:08,  1.00s/it]Epoch: 1/10. Loss: 1.0678:  69%|[36m██████▉   [0m| 18/26 [00:20<00:08,  1.00s/it]Epoch: 1/10. Loss: 1.0678:  73%|[36m███████▎  [0m| 19/26 [00:20<00:06,  1.07it/s]Epoch: 1/10. Loss: 0.9580:  73%|[36m███████▎  [0m| 19/26 [00:21<00:06,  1.07it/s]Epoch: 1/10. Loss: 0.9580:  77%|[36m███████▋  [0m| 20/26 [00:21<00:05,  1.03it/s]Epoch: 1/10. Loss: 0.9606:  77%|[36m███████▋  [0m| 20/26 [00:22<00:05,  1.03it/s]Epoch: 1/10. Loss: 0.9606:  81%|[36m████████  [0m| 21/26 [00:22<00:04,  1.04it/s]Epoch: 1/10. Loss: 1.0272:  81%|[36m████████  [0m| 21/26 [00:23<00:04,  1.04it/s]Epoch: 1/10. Loss: 1.0272:  85%|[36m████████▍ [0m| 22/26 [00:23<00:03,  1.07it/s]Epoch: 1/10. Loss: 1.0224:  85%|[36m████████▍ [0m| 22/26 [00:24<00:03,  1.07it/s]Epoch: 1/10. Loss: 1.0224:  88%|[36m████████▊ [0m| 23/26 [00:24<00:02,  1.09it/s]Epoch: 1/10. Loss: 0.9546:  88%|[36m████████▊ [0m| 23/26 [00:25<00:02,  1.09it/s]Epoch: 1/10. Loss: 0.9546:  92%|[36m█████████▏[0m| 24/26 [00:25<00:01,  1.10it/s]Epoch: 1/10. Loss: 1.0746:  92%|[36m█████████▏[0m| 24/26 [00:26<00:01,  1.10it/s]Epoch: 1/10. Loss: 1.0746:  96%|[36m█████████▌[0m| 25/26 [00:26<00:01,  1.03s/it]Epoch: 1/10. Loss: 0.9668:  96%|[36m█████████▌[0m| 25/26 [00:27<00:01,  1.03s/it]Epoch: 1/10. Loss: 0.9668: 100%|[36m██████████[0m| 26/26 [00:27<00:00,  1.05it/s]Epoch: 1/10. Loss: 0.9668: 100%|[36m██████████[0m| 26/26 [00:27<00:00,  1.06s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:05,  1.17it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:05,  1.08s/it] 43%|[33m████▎     [0m| 3/7 [00:02<00:03,  1.07it/s] 57%|[33m█████▋    [0m| 4/7 [00:04<00:03,  1.08s/it] 71%|[33m███████▏  [0m| 5/7 [00:07<00:03,  1.87s/it] 86%|[33m████████▌ [0m| 6/7 [00:11<00:02,  2.67s/it]100%|[33m██████████[0m| 7/7 [00:11<00:00,  1.89s/it]100%|[33m██████████[0m| 7/7 [00:11<00:00,  1.71s/it]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 2/10. Loss: 1.0305:   0%|[36m          [0m| 0/26 [00:02<?, ?it/s]Epoch: 2/10. Loss: 1.0305:   4%|[36m▍         [0m| 1/26 [00:02<01:07,  2.69s/it]Epoch: 2/10. Loss: 0.9935:   4%|[36m▍         [0m| 1/26 [00:03<01:07,  2.69s/it]Epoch: 2/10. Loss: 0.9935:   8%|[36m▊         [0m| 2/26 [00:03<00:39,  1.66s/it]Epoch: 2/10. Loss: 0.9688:   8%|[36m▊         [0m| 2/26 [00:04<00:39,  1.66s/it]Epoch: 2/10. Loss: 0.9688:  12%|[36m█▏        [0m| 3/26 [00:04<00:30,  1.30s/it]Epoch: 2/10. Loss: 0.9466:  12%|[36m█▏        [0m| 3/26 [00:05<00:30,  1.30s/it]Epoch: 2/10. Loss: 0.9466:  15%|[36m█▌        [0m| 4/26 [00:05<00:26,  1.21s/it]Epoch: 2/10. Loss: 1.0583:  15%|[36m█▌        [0m| 4/26 [00:06<00:26,  1.21s/it]Epoch: 2/10. Loss: 1.0583:  19%|[36m█▉        [0m| 5/26 [00:06<00:23,  1.10s/it]Epoch: 2/10. Loss: 1.0128:  19%|[36m█▉        [0m| 5/26 [00:07<00:23,  1.10s/it]Epoch: 2/10. Loss: 1.0128:  23%|[36m██▎       [0m| 6/26 [00:07<00:20,  1.02s/it]Epoch: 2/10. Loss: 0.9866:  23%|[36m██▎       [0m| 6/26 [00:08<00:20,  1.02s/it]Epoch: 2/10. Loss: 0.9866:  27%|[36m██▋       [0m| 7/26 [00:08<00:22,  1.20s/it]Epoch: 2/10. Loss: 0.9376:  27%|[36m██▋       [0m| 7/26 [00:10<00:22,  1.20s/it]Epoch: 2/10. Loss: 0.9376:  31%|[36m███       [0m| 8/26 [00:10<00:24,  1.36s/it]Epoch: 2/10. Loss: 0.9970:  31%|[36m███       [0m| 8/26 [00:12<00:24,  1.36s/it]Epoch: 2/10. Loss: 0.9970:  35%|[36m███▍      [0m| 9/26 [00:12<00:23,  1.41s/it]Epoch: 2/10. Loss: 0.9885:  35%|[36m███▍      [0m| 9/26 [00:13<00:23,  1.41s/it]Epoch: 2/10. Loss: 0.9885:  38%|[36m███▊      [0m| 10/26 [00:13<00:20,  1.30s/it]Epoch: 2/10. Loss: 1.0091:  38%|[36m███▊      [0m| 10/26 [00:14<00:20,  1.30s/it]Epoch: 2/10. Loss: 1.0091:  42%|[36m████▏     [0m| 11/26 [00:14<00:17,  1.19s/it]Epoch: 2/10. Loss: 1.0044:  42%|[36m████▏     [0m| 11/26 [00:15<00:17,  1.19s/it]Epoch: 2/10. Loss: 1.0044:  46%|[36m████▌     [0m| 12/26 [00:15<00:15,  1.14s/it]Epoch: 2/10. Loss: 0.9871:  46%|[36m████▌     [0m| 12/26 [00:17<00:15,  1.14s/it]Epoch: 2/10. Loss: 0.9871:  50%|[36m█████     [0m| 13/26 [00:17<00:20,  1.56s/it]Epoch: 2/10. Loss: 0.9785:  50%|[36m█████     [0m| 13/26 [00:18<00:20,  1.56s/it]Epoch: 2/10. Loss: 0.9785:  54%|[36m█████▍    [0m| 14/26 [00:18<00:16,  1.39s/it]Epoch: 2/10. Loss: 1.0340:  54%|[36m█████▍    [0m| 14/26 [00:19<00:16,  1.39s/it]Epoch: 2/10. Loss: 1.0340:  58%|[36m█████▊    [0m| 15/26 [00:19<00:13,  1.24s/it]Epoch: 2/10. Loss: 0.9651:  58%|[36m█████▊    [0m| 15/26 [00:20<00:13,  1.24s/it]Epoch: 2/10. Loss: 0.9651:  62%|[36m██████▏   [0m| 16/26 [00:20<00:11,  1.18s/it]Epoch: 2/10. Loss: 0.9653:  62%|[36m██████▏   [0m| 16/26 [00:21<00:11,  1.18s/it]Epoch: 2/10. Loss: 0.9653:  65%|[36m██████▌   [0m| 17/26 [00:21<00:09,  1.08s/it]Epoch: 2/10. Loss: 0.9722:  65%|[36m██████▌   [0m| 17/26 [00:22<00:09,  1.08s/it]Epoch: 2/10. Loss: 0.9722:  69%|[36m██████▉   [0m| 18/26 [00:22<00:08,  1.12s/it]Epoch: 2/10. Loss: 0.9271:  69%|[36m██████▉   [0m| 18/26 [00:23<00:08,  1.12s/it]Epoch: 2/10. Loss: 0.9271:  73%|[36m███████▎  [0m| 19/26 [00:23<00:07,  1.08s/it]Epoch: 2/10. Loss: 0.9786:  73%|[36m███████▎  [0m| 19/26 [00:24<00:07,  1.08s/it]Epoch: 2/10. Loss: 0.9786:  77%|[36m███████▋  [0m| 20/26 [00:24<00:06,  1.07s/it]Epoch: 2/10. Loss: 1.0121:  77%|[36m███████▋  [0m| 20/26 [00:25<00:06,  1.07s/it]Epoch: 2/10. Loss: 1.0121:  81%|[36m████████  [0m| 21/26 [00:25<00:05,  1.06s/it]Epoch: 2/10. Loss: 0.8971:  81%|[36m████████  [0m| 21/26 [00:26<00:05,  1.06s/it]Epoch: 2/10. Loss: 0.8971:  85%|[36m████████▍ [0m| 22/26 [00:26<00:04,  1.06s/it]Epoch: 2/10. Loss: 0.9678:  85%|[36m████████▍ [0m| 22/26 [00:27<00:04,  1.06s/it]Epoch: 2/10. Loss: 0.9678:  88%|[36m████████▊ [0m| 23/26 [00:27<00:03,  1.08s/it]Epoch: 2/10. Loss: 1.0264:  88%|[36m████████▊ [0m| 23/26 [00:28<00:03,  1.08s/it]Epoch: 2/10. Loss: 1.0264:  92%|[36m█████████▏[0m| 24/26 [00:28<00:02,  1.07s/it]Epoch: 2/10. Loss: 0.9547:  92%|[36m█████████▏[0m| 24/26 [00:29<00:02,  1.07s/it]Epoch: 2/10. Loss: 0.9547:  96%|[36m█████████▌[0m| 25/26 [00:29<00:01,  1.04s/it]Epoch: 2/10. Loss: 1.0686:  96%|[36m█████████▌[0m| 25/26 [00:30<00:01,  1.04s/it]Epoch: 2/10. Loss: 1.0686: 100%|[36m██████████[0m| 26/26 [00:30<00:00,  1.06it/s]Epoch: 2/10. Loss: 1.0686: 100%|[36m██████████[0m| 26/26 [00:30<00:00,  1.18s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:04,  1.22it/s] 29%|[33m██▊       [0m| 2/7 [00:01<00:04,  1.09it/s] 43%|[33m████▎     [0m| 3/7 [00:02<00:03,  1.22it/s] 57%|[33m█████▋    [0m| 4/7 [00:03<00:02,  1.00it/s] 71%|[33m███████▏  [0m| 5/7 [00:04<00:01,  1.28it/s] 86%|[33m████████▌ [0m| 6/7 [00:05<00:00,  1.22it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.55it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.31it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 3/10. Loss: 0.9828:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 3/10. Loss: 0.9828:   4%|[36m▍         [0m| 1/26 [00:00<00:24,  1.03it/s]Epoch: 3/10. Loss: 0.9334:   4%|[36m▍         [0m| 1/26 [00:02<00:24,  1.03it/s]Epoch: 3/10. Loss: 0.9334:   8%|[36m▊         [0m| 2/26 [00:02<00:34,  1.42s/it]Epoch: 3/10. Loss: 0.9513:   8%|[36m▊         [0m| 2/26 [00:03<00:34,  1.42s/it]Epoch: 3/10. Loss: 0.9513:  12%|[36m█▏        [0m| 3/26 [00:03<00:28,  1.23s/it]Epoch: 3/10. Loss: 0.9507:  12%|[36m█▏        [0m| 3/26 [00:04<00:28,  1.23s/it]Epoch: 3/10. Loss: 0.9507:  15%|[36m█▌        [0m| 4/26 [00:04<00:27,  1.24s/it]Epoch: 3/10. Loss: 0.9251:  15%|[36m█▌        [0m| 4/26 [00:06<00:27,  1.24s/it]Epoch: 3/10. Loss: 0.9251:  19%|[36m█▉        [0m| 5/26 [00:06<00:26,  1.26s/it]Epoch: 3/10. Loss: 0.9765:  19%|[36m█▉        [0m| 5/26 [00:07<00:26,  1.26s/it]Epoch: 3/10. Loss: 0.9765:  23%|[36m██▎       [0m| 6/26 [00:07<00:22,  1.13s/it]Epoch: 3/10. Loss: 1.0026:  23%|[36m██▎       [0m| 6/26 [00:08<00:22,  1.13s/it]Epoch: 3/10. Loss: 1.0026:  27%|[36m██▋       [0m| 7/26 [00:08<00:20,  1.05s/it]Epoch: 3/10. Loss: 1.0036:  27%|[36m██▋       [0m| 7/26 [00:10<00:20,  1.05s/it]Epoch: 3/10. Loss: 1.0036:  31%|[36m███       [0m| 8/26 [00:10<00:27,  1.54s/it]Epoch: 3/10. Loss: 0.9510:  31%|[36m███       [0m| 8/26 [00:11<00:27,  1.54s/it]Epoch: 3/10. Loss: 0.9510:  35%|[36m███▍      [0m| 9/26 [00:11<00:24,  1.44s/it]Epoch: 3/10. Loss: 0.9151:  35%|[36m███▍      [0m| 9/26 [00:13<00:24,  1.44s/it]Epoch: 3/10. Loss: 0.9151:  38%|[36m███▊      [0m| 10/26 [00:13<00:24,  1.53s/it]Epoch: 3/10. Loss: 0.9500:  38%|[36m███▊      [0m| 10/26 [00:14<00:24,  1.53s/it]Epoch: 3/10. Loss: 0.9500:  42%|[36m████▏     [0m| 11/26 [00:14<00:19,  1.33s/it]Epoch: 3/10. Loss: 0.8937:  42%|[36m████▏     [0m| 11/26 [00:15<00:19,  1.33s/it]Epoch: 3/10. Loss: 0.8937:  46%|[36m████▌     [0m| 12/26 [00:15<00:17,  1.27s/it]Epoch: 3/10. Loss: 0.9069:  46%|[36m████▌     [0m| 12/26 [00:16<00:17,  1.27s/it]Epoch: 3/10. Loss: 0.9069:  50%|[36m█████     [0m| 13/26 [00:16<00:15,  1.18s/it]Epoch: 3/10. Loss: 0.9166:  50%|[36m█████     [0m| 13/26 [00:17<00:15,  1.18s/it]Epoch: 3/10. Loss: 0.9166:  54%|[36m█████▍    [0m| 14/26 [00:17<00:13,  1.13s/it]Epoch: 3/10. Loss: 1.0881:  54%|[36m█████▍    [0m| 14/26 [00:18<00:13,  1.13s/it]Epoch: 3/10. Loss: 1.0881:  58%|[36m█████▊    [0m| 15/26 [00:18<00:12,  1.10s/it]Epoch: 3/10. Loss: 1.0122:  58%|[36m█████▊    [0m| 15/26 [00:20<00:12,  1.10s/it]Epoch: 3/10. Loss: 1.0122:  62%|[36m██████▏   [0m| 16/26 [00:20<00:12,  1.24s/it]Epoch: 3/10. Loss: 0.9760:  62%|[36m██████▏   [0m| 16/26 [00:21<00:12,  1.24s/it]Epoch: 3/10. Loss: 0.9760:  65%|[36m██████▌   [0m| 17/26 [00:21<00:12,  1.37s/it]Epoch: 3/10. Loss: 0.9353:  65%|[36m██████▌   [0m| 17/26 [00:22<00:12,  1.37s/it]Epoch: 3/10. Loss: 0.9353:  69%|[36m██████▉   [0m| 18/26 [00:22<00:09,  1.25s/it]Epoch: 3/10. Loss: 0.9224:  69%|[36m██████▉   [0m| 18/26 [00:23<00:09,  1.25s/it]Epoch: 3/10. Loss: 0.9224:  73%|[36m███████▎  [0m| 19/26 [00:23<00:08,  1.15s/it]Epoch: 3/10. Loss: 0.9674:  73%|[36m███████▎  [0m| 19/26 [00:24<00:08,  1.15s/it]Epoch: 3/10. Loss: 0.9674:  77%|[36m███████▋  [0m| 20/26 [00:24<00:06,  1.05s/it]Epoch: 3/10. Loss: 0.9455:  77%|[36m███████▋  [0m| 20/26 [00:25<00:06,  1.05s/it]Epoch: 3/10. Loss: 0.9455:  81%|[36m████████  [0m| 21/26 [00:25<00:05,  1.03s/it]Epoch: 3/10. Loss: 1.0469:  81%|[36m████████  [0m| 21/26 [00:26<00:05,  1.03s/it]Epoch: 3/10. Loss: 1.0469:  85%|[36m████████▍ [0m| 22/26 [00:26<00:04,  1.00s/it]Epoch: 3/10. Loss: 1.0114:  85%|[36m████████▍ [0m| 22/26 [00:27<00:04,  1.00s/it]Epoch: 3/10. Loss: 1.0114:  88%|[36m████████▊ [0m| 23/26 [00:27<00:03,  1.01s/it]Epoch: 3/10. Loss: 0.9814:  88%|[36m████████▊ [0m| 23/26 [00:28<00:03,  1.01s/it]Epoch: 3/10. Loss: 0.9814:  92%|[36m█████████▏[0m| 24/26 [00:28<00:02,  1.01s/it]Epoch: 3/10. Loss: 0.9303:  92%|[36m█████████▏[0m| 24/26 [00:29<00:02,  1.01s/it]Epoch: 3/10. Loss: 0.9303:  96%|[36m█████████▌[0m| 25/26 [00:29<00:01,  1.02s/it]Epoch: 3/10. Loss: 1.0814:  96%|[36m█████████▌[0m| 25/26 [00:30<00:01,  1.02s/it]Epoch: 3/10. Loss: 1.0814: 100%|[36m██████████[0m| 26/26 [00:30<00:00,  1.09it/s]Epoch: 3/10. Loss: 1.0814: 100%|[36m██████████[0m| 26/26 [00:30<00:00,  1.16s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:05,  1.17it/s] 29%|[33m██▊       [0m| 2/7 [00:01<00:05,  1.00s/it] 43%|[33m████▎     [0m| 3/7 [00:02<00:03,  1.14it/s] 57%|[33m█████▋    [0m| 4/7 [00:03<00:03,  1.04s/it] 71%|[33m███████▏  [0m| 5/7 [00:04<00:01,  1.22it/s] 86%|[33m████████▌ [0m| 6/7 [00:05<00:01,  1.01s/it]100%|[33m██████████[0m| 7/7 [00:06<00:00,  1.04s/it]100%|[33m██████████[0m| 7/7 [00:06<00:00,  1.01it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 4/10. Loss: 0.9412:   0%|[36m          [0m| 0/26 [00:02<?, ?it/s]Epoch: 4/10. Loss: 0.9412:   4%|[36m▍         [0m| 1/26 [00:02<00:52,  2.12s/it]Epoch: 4/10. Loss: 0.9315:   4%|[36m▍         [0m| 1/26 [00:03<00:52,  2.12s/it]Epoch: 4/10. Loss: 0.9315:   8%|[36m▊         [0m| 2/26 [00:03<00:33,  1.41s/it]Epoch: 4/10. Loss: 0.9104:   8%|[36m▊         [0m| 2/26 [00:03<00:33,  1.41s/it]Epoch: 4/10. Loss: 0.9104:  12%|[36m█▏        [0m| 3/26 [00:03<00:27,  1.18s/it]Epoch: 4/10. Loss: 1.0084:  12%|[36m█▏        [0m| 3/26 [00:05<00:27,  1.18s/it]Epoch: 4/10. Loss: 1.0084:  15%|[36m█▌        [0m| 4/26 [00:05<00:26,  1.19s/it]Epoch: 4/10. Loss: 0.9169:  15%|[36m█▌        [0m| 4/26 [00:06<00:26,  1.19s/it]Epoch: 4/10. Loss: 0.9169:  19%|[36m█▉        [0m| 5/26 [00:06<00:22,  1.07s/it]Epoch: 4/10. Loss: 1.0219:  19%|[36m█▉        [0m| 5/26 [00:06<00:22,  1.07s/it]Epoch: 4/10. Loss: 1.0219:  23%|[36m██▎       [0m| 6/26 [00:06<00:20,  1.04s/it]Epoch: 4/10. Loss: 0.9771:  23%|[36m██▎       [0m| 6/26 [00:08<00:20,  1.04s/it]Epoch: 4/10. Loss: 0.9771:  27%|[36m██▋       [0m| 7/26 [00:08<00:20,  1.08s/it]Epoch: 4/10. Loss: 0.9266:  27%|[36m██▋       [0m| 7/26 [00:08<00:20,  1.08s/it]Epoch: 4/10. Loss: 0.9266:  31%|[36m███       [0m| 8/26 [00:08<00:17,  1.02it/s]Epoch: 4/10. Loss: 0.8840:  31%|[36m███       [0m| 8/26 [00:11<00:17,  1.02it/s]Epoch: 4/10. Loss: 0.8840:  35%|[36m███▍      [0m| 9/26 [00:11<00:24,  1.43s/it]Epoch: 4/10. Loss: 0.8726:  35%|[36m███▍      [0m| 9/26 [00:12<00:24,  1.43s/it]Epoch: 4/10. Loss: 0.8726:  38%|[36m███▊      [0m| 10/26 [00:12<00:20,  1.30s/it]Epoch: 4/10. Loss: 0.9089:  38%|[36m███▊      [0m| 10/26 [00:13<00:20,  1.30s/it]Epoch: 4/10. Loss: 0.9089:  42%|[36m████▏     [0m| 11/26 [00:13<00:18,  1.21s/it]Epoch: 4/10. Loss: 0.9685:  42%|[36m████▏     [0m| 11/26 [00:15<00:18,  1.21s/it]Epoch: 4/10. Loss: 0.9685:  46%|[36m████▌     [0m| 12/26 [00:15<00:22,  1.62s/it]Epoch: 4/10. Loss: 1.0896:  46%|[36m████▌     [0m| 12/26 [00:17<00:22,  1.62s/it]Epoch: 4/10. Loss: 1.0896:  50%|[36m█████     [0m| 13/26 [00:17<00:19,  1.50s/it]Epoch: 4/10. Loss: 0.9465:  50%|[36m█████     [0m| 13/26 [00:17<00:19,  1.50s/it]Epoch: 4/10. Loss: 0.9465:  54%|[36m█████▍    [0m| 14/26 [00:17<00:15,  1.30s/it]Epoch: 4/10. Loss: 0.9293:  54%|[36m█████▍    [0m| 14/26 [00:18<00:15,  1.30s/it]Epoch: 4/10. Loss: 0.9293:  58%|[36m█████▊    [0m| 15/26 [00:18<00:13,  1.19s/it]Epoch: 4/10. Loss: 0.8849:  58%|[36m█████▊    [0m| 15/26 [00:21<00:13,  1.19s/it]Epoch: 4/10. Loss: 0.8849:  62%|[36m██████▏   [0m| 16/26 [00:21<00:14,  1.48s/it]Epoch: 4/10. Loss: 1.0106:  62%|[36m██████▏   [0m| 16/26 [00:22<00:14,  1.48s/it]Epoch: 4/10. Loss: 1.0106:  65%|[36m██████▌   [0m| 17/26 [00:22<00:13,  1.51s/it]Epoch: 4/10. Loss: 0.9437:  65%|[36m██████▌   [0m| 17/26 [00:23<00:13,  1.51s/it]Epoch: 4/10. Loss: 0.9437:  69%|[36m██████▉   [0m| 18/26 [00:23<00:10,  1.35s/it]Epoch: 4/10. Loss: 0.9852:  69%|[36m██████▉   [0m| 18/26 [00:26<00:10,  1.35s/it]Epoch: 4/10. Loss: 0.9852:  73%|[36m███████▎  [0m| 19/26 [00:26<00:12,  1.77s/it]Epoch: 4/10. Loss: 0.9442:  73%|[36m███████▎  [0m| 19/26 [00:27<00:12,  1.77s/it]Epoch: 4/10. Loss: 0.9442:  77%|[36m███████▋  [0m| 20/26 [00:27<00:09,  1.59s/it]Epoch: 4/10. Loss: 0.9942:  77%|[36m███████▋  [0m| 20/26 [00:28<00:09,  1.59s/it]Epoch: 4/10. Loss: 0.9942:  81%|[36m████████  [0m| 21/26 [00:28<00:06,  1.39s/it]Epoch: 4/10. Loss: 0.9215:  81%|[36m████████  [0m| 21/26 [00:29<00:06,  1.39s/it]Epoch: 4/10. Loss: 0.9215:  85%|[36m████████▍ [0m| 22/26 [00:29<00:04,  1.22s/it]Epoch: 4/10. Loss: 0.9790:  85%|[36m████████▍ [0m| 22/26 [00:30<00:04,  1.22s/it]Epoch: 4/10. Loss: 0.9790:  88%|[36m████████▊ [0m| 23/26 [00:30<00:03,  1.17s/it]Epoch: 4/10. Loss: 0.9942:  88%|[36m████████▊ [0m| 23/26 [00:33<00:03,  1.17s/it]Epoch: 4/10. Loss: 0.9942:  92%|[36m█████████▏[0m| 24/26 [00:33<00:03,  1.65s/it]Epoch: 4/10. Loss: 0.9577:  92%|[36m█████████▏[0m| 24/26 [00:33<00:03,  1.65s/it]Epoch: 4/10. Loss: 0.9577:  96%|[36m█████████▌[0m| 25/26 [00:33<00:01,  1.42s/it]Epoch: 4/10. Loss: 0.9337:  96%|[36m█████████▌[0m| 25/26 [00:35<00:01,  1.42s/it]Epoch: 4/10. Loss: 0.9337: 100%|[36m██████████[0m| 26/26 [00:35<00:00,  1.40s/it]Epoch: 4/10. Loss: 0.9337: 100%|[36m██████████[0m| 26/26 [00:35<00:00,  1.36s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:01<00:06,  1.05s/it] 29%|[33m██▊       [0m| 2/7 [00:02<00:05,  1.17s/it] 43%|[33m████▎     [0m| 3/7 [00:05<00:07,  1.92s/it] 57%|[33m█████▋    [0m| 4/7 [00:08<00:07,  2.51s/it] 71%|[33m███████▏  [0m| 5/7 [00:08<00:03,  1.75s/it] 86%|[33m████████▌ [0m| 6/7 [00:09<00:01,  1.48s/it]100%|[33m██████████[0m| 7/7 [00:10<00:00,  1.09s/it]100%|[33m██████████[0m| 7/7 [00:10<00:00,  1.45s/it]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 5/10. Loss: 0.8722:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 5/10. Loss: 0.8722:   4%|[36m▍         [0m| 1/26 [00:00<00:19,  1.27it/s]Epoch: 5/10. Loss: 0.9288:   4%|[36m▍         [0m| 1/26 [00:02<00:19,  1.27it/s]Epoch: 5/10. Loss: 0.9288:   8%|[36m▊         [0m| 2/26 [00:02<00:37,  1.56s/it]Epoch: 5/10. Loss: 0.9876:   8%|[36m▊         [0m| 2/26 [00:03<00:37,  1.56s/it]Epoch: 5/10. Loss: 0.9876:  12%|[36m█▏        [0m| 3/26 [00:03<00:29,  1.26s/it]Epoch: 5/10. Loss: 0.9759:  12%|[36m█▏        [0m| 3/26 [00:04<00:29,  1.26s/it]Epoch: 5/10. Loss: 0.9759:  15%|[36m█▌        [0m| 4/26 [00:04<00:26,  1.21s/it]Epoch: 5/10. Loss: 0.9039:  15%|[36m█▌        [0m| 4/26 [00:05<00:26,  1.21s/it]Epoch: 5/10. Loss: 0.9039:  19%|[36m█▉        [0m| 5/26 [00:05<00:22,  1.08s/it]Epoch: 5/10. Loss: 0.9120:  19%|[36m█▉        [0m| 5/26 [00:08<00:22,  1.08s/it]Epoch: 5/10. Loss: 0.9120:  23%|[36m██▎       [0m| 6/26 [00:08<00:30,  1.55s/it]Epoch: 5/10. Loss: 0.8657:  23%|[36m██▎       [0m| 6/26 [00:10<00:30,  1.55s/it]Epoch: 5/10. Loss: 0.8657:  27%|[36m██▋       [0m| 7/26 [00:10<00:33,  1.79s/it]Epoch: 5/10. Loss: 0.9443:  27%|[36m██▋       [0m| 7/26 [00:11<00:33,  1.79s/it]Epoch: 5/10. Loss: 0.9443:  31%|[36m███       [0m| 8/26 [00:11<00:27,  1.53s/it]Epoch: 5/10. Loss: 0.9798:  31%|[36m███       [0m| 8/26 [00:12<00:27,  1.53s/it]Epoch: 5/10. Loss: 0.9798:  35%|[36m███▍      [0m| 9/26 [00:12<00:23,  1.38s/it]Epoch: 5/10. Loss: 0.8697:  35%|[36m███▍      [0m| 9/26 [00:14<00:23,  1.38s/it]Epoch: 5/10. Loss: 0.8697:  38%|[36m███▊      [0m| 10/26 [00:14<00:25,  1.57s/it]Epoch: 5/10. Loss: 0.9255:  38%|[36m███▊      [0m| 10/26 [00:15<00:25,  1.57s/it]Epoch: 5/10. Loss: 0.9255:  42%|[36m████▏     [0m| 11/26 [00:15<00:20,  1.38s/it]Epoch: 5/10. Loss: 0.9289:  42%|[36m████▏     [0m| 11/26 [00:16<00:20,  1.38s/it]Epoch: 5/10. Loss: 0.9289:  46%|[36m████▌     [0m| 12/26 [00:16<00:17,  1.28s/it]Epoch: 5/10. Loss: 0.9628:  46%|[36m████▌     [0m| 12/26 [00:17<00:17,  1.28s/it]Epoch: 5/10. Loss: 0.9628:  50%|[36m█████     [0m| 13/26 [00:17<00:15,  1.20s/it]Epoch: 5/10. Loss: 0.8737:  50%|[36m█████     [0m| 13/26 [00:18<00:15,  1.20s/it]Epoch: 5/10. Loss: 0.8737:  54%|[36m█████▍    [0m| 14/26 [00:18<00:13,  1.10s/it]Epoch: 5/10. Loss: 0.9077:  54%|[36m█████▍    [0m| 14/26 [00:19<00:13,  1.10s/it]Epoch: 5/10. Loss: 0.9077:  58%|[36m█████▊    [0m| 15/26 [00:19<00:11,  1.09s/it]Epoch: 5/10. Loss: 0.9130:  58%|[36m█████▊    [0m| 15/26 [00:20<00:11,  1.09s/it]Epoch: 5/10. Loss: 0.9130:  62%|[36m██████▏   [0m| 16/26 [00:20<00:10,  1.08s/it]Epoch: 5/10. Loss: 0.9919:  62%|[36m██████▏   [0m| 16/26 [00:21<00:10,  1.08s/it]Epoch: 5/10. Loss: 0.9919:  65%|[36m██████▌   [0m| 17/26 [00:21<00:09,  1.06s/it]Epoch: 5/10. Loss: 0.8904:  65%|[36m██████▌   [0m| 17/26 [00:24<00:09,  1.06s/it]Epoch: 5/10. Loss: 0.8904:  69%|[36m██████▉   [0m| 18/26 [00:24<00:13,  1.75s/it]Epoch: 5/10. Loss: 0.9519:  69%|[36m██████▉   [0m| 18/26 [00:26<00:13,  1.75s/it]Epoch: 5/10. Loss: 0.9519:  73%|[36m███████▎  [0m| 19/26 [00:26<00:11,  1.67s/it]Epoch: 5/10. Loss: 0.9282:  73%|[36m███████▎  [0m| 19/26 [00:27<00:11,  1.67s/it]Epoch: 5/10. Loss: 0.9282:  77%|[36m███████▋  [0m| 20/26 [00:27<00:08,  1.44s/it]Epoch: 5/10. Loss: 0.8987:  77%|[36m███████▋  [0m| 20/26 [00:28<00:08,  1.44s/it]Epoch: 5/10. Loss: 0.8987:  81%|[36m████████  [0m| 21/26 [00:28<00:06,  1.32s/it]Epoch: 5/10. Loss: 0.9198:  81%|[36m████████  [0m| 21/26 [00:29<00:06,  1.32s/it]Epoch: 5/10. Loss: 0.9198:  85%|[36m████████▍ [0m| 22/26 [00:29<00:04,  1.15s/it]Epoch: 5/10. Loss: 0.8837:  85%|[36m████████▍ [0m| 22/26 [00:29<00:04,  1.15s/it]Epoch: 5/10. Loss: 0.8837:  88%|[36m████████▊ [0m| 23/26 [00:29<00:03,  1.05s/it]Epoch: 5/10. Loss: 0.9485:  88%|[36m████████▊ [0m| 23/26 [00:30<00:03,  1.05s/it]Epoch: 5/10. Loss: 0.9485:  92%|[36m█████████▏[0m| 24/26 [00:30<00:02,  1.04s/it]Epoch: 5/10. Loss: 0.9019:  92%|[36m█████████▏[0m| 24/26 [00:31<00:02,  1.04s/it]Epoch: 5/10. Loss: 0.9019:  96%|[36m█████████▌[0m| 25/26 [00:31<00:01,  1.01s/it]Epoch: 5/10. Loss: 0.9159:  96%|[36m█████████▌[0m| 25/26 [00:32<00:01,  1.01s/it]Epoch: 5/10. Loss: 0.9159: 100%|[36m██████████[0m| 26/26 [00:32<00:00,  1.11it/s]Epoch: 5/10. Loss: 0.9159: 100%|[36m██████████[0m| 26/26 [00:32<00:00,  1.25s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:04,  1.25it/s] 29%|[33m██▊       [0m| 2/7 [00:01<00:04,  1.10it/s] 43%|[33m████▎     [0m| 3/7 [00:02<00:03,  1.22it/s] 57%|[33m█████▋    [0m| 4/7 [00:03<00:02,  1.00it/s] 71%|[33m███████▏  [0m| 5/7 [00:04<00:01,  1.26it/s] 86%|[33m████████▌ [0m| 6/7 [00:05<00:00,  1.21it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.55it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.30it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 6/10. Loss: 0.9664:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 6/10. Loss: 0.9664:   4%|[36m▍         [0m| 1/26 [00:00<00:20,  1.21it/s]Epoch: 6/10. Loss: 0.9823:   4%|[36m▍         [0m| 1/26 [00:01<00:20,  1.21it/s]Epoch: 6/10. Loss: 0.9823:   8%|[36m▊         [0m| 2/26 [00:01<00:21,  1.10it/s]Epoch: 6/10. Loss: 0.8506:   8%|[36m▊         [0m| 2/26 [00:02<00:21,  1.10it/s]Epoch: 6/10. Loss: 0.8506:  12%|[36m█▏        [0m| 3/26 [00:02<00:23,  1.03s/it]Epoch: 6/10. Loss: 0.8262:  12%|[36m█▏        [0m| 3/26 [00:03<00:23,  1.03s/it]Epoch: 6/10. Loss: 0.8262:  15%|[36m█▌        [0m| 4/26 [00:03<00:21,  1.03it/s]Epoch: 6/10. Loss: 0.8608:  15%|[36m█▌        [0m| 4/26 [00:04<00:21,  1.03it/s]Epoch: 6/10. Loss: 0.8608:  19%|[36m█▉        [0m| 5/26 [00:04<00:21,  1.00s/it]Epoch: 6/10. Loss: 0.9088:  19%|[36m█▉        [0m| 5/26 [00:05<00:21,  1.00s/it]Epoch: 6/10. Loss: 0.9088:  23%|[36m██▎       [0m| 6/26 [00:05<00:20,  1.01s/it]Epoch: 6/10. Loss: 0.9437:  23%|[36m██▎       [0m| 6/26 [00:06<00:20,  1.01s/it]Epoch: 6/10. Loss: 0.9437:  27%|[36m██▋       [0m| 7/26 [00:06<00:19,  1.02s/it]Epoch: 6/10. Loss: 0.8742:  27%|[36m██▋       [0m| 7/26 [00:07<00:19,  1.02s/it]Epoch: 6/10. Loss: 0.8742:  31%|[36m███       [0m| 8/26 [00:07<00:17,  1.01it/s]Epoch: 6/10. Loss: 0.8953:  31%|[36m███       [0m| 8/26 [00:08<00:17,  1.01it/s]Epoch: 6/10. Loss: 0.8953:  35%|[36m███▍      [0m| 9/26 [00:08<00:16,  1.03it/s]Epoch: 6/10. Loss: 0.8988:  35%|[36m███▍      [0m| 9/26 [00:09<00:16,  1.03it/s]Epoch: 6/10. Loss: 0.8988:  38%|[36m███▊      [0m| 10/26 [00:09<00:15,  1.06it/s]Epoch: 6/10. Loss: 0.8729:  38%|[36m███▊      [0m| 10/26 [00:10<00:15,  1.06it/s]Epoch: 6/10. Loss: 0.8729:  42%|[36m████▏     [0m| 11/26 [00:10<00:14,  1.07it/s]Epoch: 6/10. Loss: 0.9526:  42%|[36m████▏     [0m| 11/26 [00:11<00:14,  1.07it/s]Epoch: 6/10. Loss: 0.9526:  46%|[36m████▌     [0m| 12/26 [00:11<00:13,  1.05it/s]Epoch: 6/10. Loss: 0.8261:  46%|[36m████▌     [0m| 12/26 [00:14<00:13,  1.05it/s]Epoch: 6/10. Loss: 0.8261:  50%|[36m█████     [0m| 13/26 [00:14<00:19,  1.51s/it]Epoch: 6/10. Loss: 0.8786:  50%|[36m█████     [0m| 13/26 [00:15<00:19,  1.51s/it]Epoch: 6/10. Loss: 0.8786:  54%|[36m█████▍    [0m| 14/26 [00:15<00:18,  1.52s/it]Epoch: 6/10. Loss: 0.9201:  54%|[36m█████▍    [0m| 14/26 [00:17<00:18,  1.52s/it]Epoch: 6/10. Loss: 0.9201:  58%|[36m█████▊    [0m| 15/26 [00:17<00:15,  1.44s/it]Epoch: 6/10. Loss: 0.9153:  58%|[36m█████▊    [0m| 15/26 [00:18<00:15,  1.44s/it]Epoch: 6/10. Loss: 0.9153:  62%|[36m██████▏   [0m| 16/26 [00:18<00:12,  1.28s/it]Epoch: 6/10. Loss: 0.8137:  62%|[36m██████▏   [0m| 16/26 [00:19<00:12,  1.28s/it]Epoch: 6/10. Loss: 0.8137:  65%|[36m██████▌   [0m| 17/26 [00:19<00:11,  1.23s/it]Epoch: 6/10. Loss: 0.8314:  65%|[36m██████▌   [0m| 17/26 [00:20<00:11,  1.23s/it]Epoch: 6/10. Loss: 0.8314:  69%|[36m██████▉   [0m| 18/26 [00:20<00:08,  1.12s/it]Epoch: 6/10. Loss: 0.9905:  69%|[36m██████▉   [0m| 18/26 [00:21<00:08,  1.12s/it]Epoch: 6/10. Loss: 0.9905:  73%|[36m███████▎  [0m| 19/26 [00:21<00:07,  1.09s/it]Epoch: 6/10. Loss: 0.9158:  73%|[36m███████▎  [0m| 19/26 [00:22<00:07,  1.09s/it]Epoch: 6/10. Loss: 0.9158:  77%|[36m███████▋  [0m| 20/26 [00:22<00:06,  1.05s/it]Epoch: 6/10. Loss: 0.9326:  77%|[36m███████▋  [0m| 20/26 [00:23<00:06,  1.05s/it]Epoch: 6/10. Loss: 0.9326:  81%|[36m████████  [0m| 21/26 [00:23<00:05,  1.03s/it]Epoch: 6/10. Loss: 0.9097:  81%|[36m████████  [0m| 21/26 [00:23<00:05,  1.03s/it]Epoch: 6/10. Loss: 0.9097:  85%|[36m████████▍ [0m| 22/26 [00:23<00:03,  1.04it/s]Epoch: 6/10. Loss: 0.9014:  85%|[36m████████▍ [0m| 22/26 [00:24<00:03,  1.04it/s]Epoch: 6/10. Loss: 0.9014:  88%|[36m████████▊ [0m| 23/26 [00:24<00:02,  1.05it/s]Epoch: 6/10. Loss: 0.8106:  88%|[36m████████▊ [0m| 23/26 [00:25<00:02,  1.05it/s]Epoch: 6/10. Loss: 0.8106:  92%|[36m█████████▏[0m| 24/26 [00:25<00:02,  1.01s/it]Epoch: 6/10. Loss: 0.9518:  92%|[36m█████████▏[0m| 24/26 [00:26<00:02,  1.01s/it]Epoch: 6/10. Loss: 0.9518:  96%|[36m█████████▌[0m| 25/26 [00:26<00:00,  1.01it/s]Epoch: 6/10. Loss: 1.0158:  96%|[36m█████████▌[0m| 25/26 [00:28<00:00,  1.01it/s]Epoch: 6/10. Loss: 1.0158: 100%|[36m██████████[0m| 26/26 [00:28<00:00,  1.08s/it]Epoch: 6/10. Loss: 1.0158: 100%|[36m██████████[0m| 26/26 [00:28<00:00,  1.08s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:04,  1.22it/s] 29%|[33m██▊       [0m| 2/7 [00:01<00:04,  1.05it/s] 43%|[33m████▎     [0m| 3/7 [00:02<00:03,  1.17it/s] 57%|[33m█████▋    [0m| 4/7 [00:03<00:03,  1.04s/it] 71%|[33m███████▏  [0m| 5/7 [00:04<00:01,  1.20it/s] 86%|[33m████████▌ [0m| 6/7 [00:05<00:00,  1.15it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.48it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.25it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 7/10. Loss: 1.0255:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 7/10. Loss: 1.0255:   4%|[36m▍         [0m| 1/26 [00:00<00:23,  1.05it/s]Epoch: 7/10. Loss: 1.0335:   4%|[36m▍         [0m| 1/26 [00:01<00:23,  1.05it/s]Epoch: 7/10. Loss: 1.0335:   8%|[36m▊         [0m| 2/26 [00:01<00:23,  1.00it/s]Epoch: 7/10. Loss: 0.9616:   8%|[36m▊         [0m| 2/26 [00:02<00:23,  1.00it/s]Epoch: 7/10. Loss: 0.9616:  12%|[36m█▏        [0m| 3/26 [00:02<00:22,  1.01it/s]Epoch: 7/10. Loss: 0.9393:  12%|[36m█▏        [0m| 3/26 [00:03<00:22,  1.01it/s]Epoch: 7/10. Loss: 0.9393:  15%|[36m█▌        [0m| 4/26 [00:03<00:21,  1.03it/s]Epoch: 7/10. Loss: 0.9129:  15%|[36m█▌        [0m| 4/26 [00:04<00:21,  1.03it/s]Epoch: 7/10. Loss: 0.9129:  19%|[36m█▉        [0m| 5/26 [00:04<00:20,  1.04it/s]Epoch: 7/10. Loss: 0.9431:  19%|[36m█▉        [0m| 5/26 [00:05<00:20,  1.04it/s]Epoch: 7/10. Loss: 0.9431:  23%|[36m██▎       [0m| 6/26 [00:05<00:18,  1.09it/s]Epoch: 7/10. Loss: 0.9238:  23%|[36m██▎       [0m| 6/26 [00:06<00:18,  1.09it/s]Epoch: 7/10. Loss: 0.9238:  27%|[36m██▋       [0m| 7/26 [00:06<00:17,  1.10it/s]Epoch: 7/10. Loss: 0.8913:  27%|[36m██▋       [0m| 7/26 [00:07<00:17,  1.10it/s]Epoch: 7/10. Loss: 0.8913:  31%|[36m███       [0m| 8/26 [00:07<00:17,  1.03it/s]Epoch: 7/10. Loss: 0.9244:  31%|[36m███       [0m| 8/26 [00:08<00:17,  1.03it/s]Epoch: 7/10. Loss: 0.9244:  35%|[36m███▍      [0m| 9/26 [00:08<00:16,  1.05it/s]Epoch: 7/10. Loss: 0.8553:  35%|[36m███▍      [0m| 9/26 [00:09<00:16,  1.05it/s]Epoch: 7/10. Loss: 0.8553:  38%|[36m███▊      [0m| 10/26 [00:09<00:15,  1.05it/s]Epoch: 7/10. Loss: 0.9180:  38%|[36m███▊      [0m| 10/26 [00:10<00:15,  1.05it/s]Epoch: 7/10. Loss: 0.9180:  42%|[36m████▏     [0m| 11/26 [00:10<00:14,  1.00it/s]Epoch: 7/10. Loss: 0.9306:  42%|[36m████▏     [0m| 11/26 [00:11<00:14,  1.00it/s]Epoch: 7/10. Loss: 0.9306:  46%|[36m████▌     [0m| 12/26 [00:11<00:13,  1.02it/s]Epoch: 7/10. Loss: 0.8600:  46%|[36m████▌     [0m| 12/26 [00:12<00:13,  1.02it/s]Epoch: 7/10. Loss: 0.8600:  50%|[36m█████     [0m| 13/26 [00:12<00:12,  1.02it/s]Epoch: 7/10. Loss: 0.8586:  50%|[36m█████     [0m| 13/26 [00:13<00:12,  1.02it/s]Epoch: 7/10. Loss: 0.8586:  54%|[36m█████▍    [0m| 14/26 [00:13<00:11,  1.03it/s]Epoch: 7/10. Loss: 0.8996:  54%|[36m█████▍    [0m| 14/26 [00:14<00:11,  1.03it/s]Epoch: 7/10. Loss: 0.8996:  58%|[36m█████▊    [0m| 15/26 [00:14<00:11,  1.03s/it]Epoch: 7/10. Loss: 0.9041:  58%|[36m█████▊    [0m| 15/26 [00:15<00:11,  1.03s/it]Epoch: 7/10. Loss: 0.9041:  62%|[36m██████▏   [0m| 16/26 [00:15<00:09,  1.00it/s]Epoch: 7/10. Loss: 0.8361:  62%|[36m██████▏   [0m| 16/26 [00:16<00:09,  1.00it/s]Epoch: 7/10. Loss: 0.8361:  65%|[36m██████▌   [0m| 17/26 [00:16<00:08,  1.05it/s]Epoch: 7/10. Loss: 0.8459:  65%|[36m██████▌   [0m| 17/26 [00:17<00:08,  1.05it/s]Epoch: 7/10. Loss: 0.8459:  69%|[36m██████▉   [0m| 18/26 [00:17<00:07,  1.05it/s]Epoch: 7/10. Loss: 0.7747:  69%|[36m██████▉   [0m| 18/26 [00:18<00:07,  1.05it/s]Epoch: 7/10. Loss: 0.7747:  73%|[36m███████▎  [0m| 19/26 [00:18<00:06,  1.05it/s]Epoch: 7/10. Loss: 0.8087:  73%|[36m███████▎  [0m| 19/26 [00:19<00:06,  1.05it/s]Epoch: 7/10. Loss: 0.8087:  77%|[36m███████▋  [0m| 20/26 [00:19<00:05,  1.00it/s]Epoch: 7/10. Loss: 0.8200:  77%|[36m███████▋  [0m| 20/26 [00:20<00:05,  1.00it/s]Epoch: 7/10. Loss: 0.8200:  81%|[36m████████  [0m| 21/26 [00:20<00:04,  1.03it/s]Epoch: 7/10. Loss: 0.9409:  81%|[36m████████  [0m| 21/26 [00:21<00:04,  1.03it/s]Epoch: 7/10. Loss: 0.9409:  85%|[36m████████▍ [0m| 22/26 [00:21<00:03,  1.05it/s]Epoch: 7/10. Loss: 0.8341:  85%|[36m████████▍ [0m| 22/26 [00:22<00:03,  1.05it/s]Epoch: 7/10. Loss: 0.8341:  88%|[36m████████▊ [0m| 23/26 [00:22<00:02,  1.10it/s]Epoch: 7/10. Loss: 0.7227:  88%|[36m████████▊ [0m| 23/26 [00:23<00:02,  1.10it/s]Epoch: 7/10. Loss: 0.7227:  92%|[36m█████████▏[0m| 24/26 [00:23<00:01,  1.06it/s]Epoch: 7/10. Loss: 0.9506:  92%|[36m█████████▏[0m| 24/26 [00:23<00:01,  1.06it/s]Epoch: 7/10. Loss: 0.9506:  96%|[36m█████████▌[0m| 25/26 [00:24<00:00,  1.07it/s]Epoch: 7/10. Loss: 0.8707:  96%|[36m█████████▌[0m| 25/26 [00:24<00:00,  1.07it/s]Epoch: 7/10. Loss: 0.8707: 100%|[36m██████████[0m| 26/26 [00:24<00:00,  1.23it/s]Epoch: 7/10. Loss: 0.8707: 100%|[36m██████████[0m| 26/26 [00:24<00:00,  1.06it/s]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:05,  1.19it/s] 29%|[33m██▊       [0m| 2/7 [00:01<00:04,  1.01it/s] 43%|[33m████▎     [0m| 3/7 [00:02<00:03,  1.14it/s] 57%|[33m█████▋    [0m| 4/7 [00:04<00:03,  1.07s/it] 71%|[33m███████▏  [0m| 5/7 [00:04<00:01,  1.18it/s] 86%|[33m████████▌ [0m| 6/7 [00:05<00:00,  1.15it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.48it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.23it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 8/10. Loss: 0.9165:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 8/10. Loss: 0.9165:   4%|[36m▍         [0m| 1/26 [00:00<00:22,  1.12it/s]Epoch: 8/10. Loss: 0.7845:   4%|[36m▍         [0m| 1/26 [00:01<00:22,  1.12it/s]Epoch: 8/10. Loss: 0.7845:   8%|[36m▊         [0m| 2/26 [00:01<00:21,  1.12it/s]Epoch: 8/10. Loss: 0.8491:   8%|[36m▊         [0m| 2/26 [00:02<00:21,  1.12it/s]Epoch: 8/10. Loss: 0.8491:  12%|[36m█▏        [0m| 3/26 [00:02<00:22,  1.04it/s]Epoch: 8/10. Loss: 0.7824:  12%|[36m█▏        [0m| 3/26 [00:03<00:22,  1.04it/s]Epoch: 8/10. Loss: 0.7824:  15%|[36m█▌        [0m| 4/26 [00:03<00:21,  1.03it/s]Epoch: 8/10. Loss: 0.8024:  15%|[36m█▌        [0m| 4/26 [00:07<00:21,  1.03it/s]Epoch: 8/10. Loss: 0.8024:  19%|[36m█▉        [0m| 5/26 [00:07<00:38,  1.83s/it]Epoch: 8/10. Loss: 0.8137:  19%|[36m█▉        [0m| 5/26 [00:07<00:38,  1.83s/it]Epoch: 8/10. Loss: 0.8137:  23%|[36m██▎       [0m| 6/26 [00:07<00:29,  1.46s/it]Epoch: 8/10. Loss: 0.8575:  23%|[36m██▎       [0m| 6/26 [00:11<00:29,  1.46s/it]Epoch: 8/10. Loss: 0.8575:  27%|[36m██▋       [0m| 7/26 [00:11<00:42,  2.24s/it]Epoch: 8/10. Loss: 0.7054:  27%|[36m██▋       [0m| 7/26 [00:13<00:42,  2.24s/it]Epoch: 8/10. Loss: 0.7054:  31%|[36m███       [0m| 8/26 [00:13<00:38,  2.14s/it]Epoch: 8/10. Loss: 0.9490:  31%|[36m███       [0m| 8/26 [00:14<00:38,  2.14s/it]Epoch: 8/10. Loss: 0.9490:  35%|[36m███▍      [0m| 9/26 [00:15<00:32,  1.88s/it]Epoch: 8/10. Loss: 0.7801:  35%|[36m███▍      [0m| 9/26 [00:16<00:32,  1.88s/it]Epoch: 8/10. Loss: 0.7801:  38%|[36m███▊      [0m| 10/26 [00:16<00:28,  1.81s/it]Epoch: 8/10. Loss: 0.8984:  38%|[36m███▊      [0m| 10/26 [00:17<00:28,  1.81s/it]Epoch: 8/10. Loss: 0.8984:  42%|[36m████▏     [0m| 11/26 [00:17<00:23,  1.53s/it]Epoch: 8/10. Loss: 0.8360:  42%|[36m████▏     [0m| 11/26 [00:18<00:23,  1.53s/it]Epoch: 8/10. Loss: 0.8360:  46%|[36m████▌     [0m| 12/26 [00:18<00:19,  1.36s/it]Epoch: 8/10. Loss: 0.9770:  46%|[36m████▌     [0m| 12/26 [00:19<00:19,  1.36s/it]Epoch: 8/10. Loss: 0.9770:  50%|[36m█████     [0m| 13/26 [00:19<00:16,  1.27s/it]Epoch: 8/10. Loss: 0.9218:  50%|[36m█████     [0m| 13/26 [00:20<00:16,  1.27s/it]Epoch: 8/10. Loss: 0.9218:  54%|[36m█████▍    [0m| 14/26 [00:20<00:13,  1.16s/it]Epoch: 8/10. Loss: 0.8982:  54%|[36m█████▍    [0m| 14/26 [00:21<00:13,  1.16s/it]Epoch: 8/10. Loss: 0.8982:  58%|[36m█████▊    [0m| 15/26 [00:21<00:12,  1.15s/it]Epoch: 8/10. Loss: 1.0049:  58%|[36m█████▊    [0m| 15/26 [00:22<00:12,  1.15s/it]Epoch: 8/10. Loss: 1.0049:  62%|[36m██████▏   [0m| 16/26 [00:22<00:10,  1.10s/it]Epoch: 8/10. Loss: 0.9340:  62%|[36m██████▏   [0m| 16/26 [00:23<00:10,  1.10s/it]Epoch: 8/10. Loss: 0.9340:  65%|[36m██████▌   [0m| 17/26 [00:23<00:09,  1.03s/it]Epoch: 8/10. Loss: 0.9265:  65%|[36m██████▌   [0m| 17/26 [00:24<00:09,  1.03s/it]Epoch: 8/10. Loss: 0.9265:  69%|[36m██████▉   [0m| 18/26 [00:24<00:07,  1.03it/s]Epoch: 8/10. Loss: 0.8125:  69%|[36m██████▉   [0m| 18/26 [00:25<00:07,  1.03it/s]Epoch: 8/10. Loss: 0.8125:  73%|[36m███████▎  [0m| 19/26 [00:25<00:06,  1.03it/s]Epoch: 8/10. Loss: 0.8477:  73%|[36m███████▎  [0m| 19/26 [00:26<00:06,  1.03it/s]Epoch: 8/10. Loss: 0.8477:  77%|[36m███████▋  [0m| 20/26 [00:26<00:06,  1.03s/it]Epoch: 8/10. Loss: 0.8633:  77%|[36m███████▋  [0m| 20/26 [00:27<00:06,  1.03s/it]Epoch: 8/10. Loss: 0.8633:  81%|[36m████████  [0m| 21/26 [00:27<00:05,  1.01s/it]Epoch: 8/10. Loss: 0.8396:  81%|[36m████████  [0m| 21/26 [00:28<00:05,  1.01s/it]Epoch: 8/10. Loss: 0.8396:  85%|[36m████████▍ [0m| 22/26 [00:28<00:04,  1.03s/it]Epoch: 8/10. Loss: 0.8587:  85%|[36m████████▍ [0m| 22/26 [00:29<00:04,  1.03s/it]Epoch: 8/10. Loss: 0.8587:  88%|[36m████████▊ [0m| 23/26 [00:29<00:03,  1.06s/it]Epoch: 8/10. Loss: 0.8245:  88%|[36m████████▊ [0m| 23/26 [00:30<00:03,  1.06s/it]Epoch: 8/10. Loss: 0.8245:  92%|[36m█████████▏[0m| 24/26 [00:30<00:02,  1.01s/it]Epoch: 8/10. Loss: 0.9764:  92%|[36m█████████▏[0m| 24/26 [00:31<00:02,  1.01s/it]Epoch: 8/10. Loss: 0.9764:  96%|[36m█████████▌[0m| 25/26 [00:31<00:01,  1.02s/it]Epoch: 8/10. Loss: 0.9493:  96%|[36m█████████▌[0m| 25/26 [00:32<00:01,  1.02s/it]Epoch: 8/10. Loss: 0.9493: 100%|[36m██████████[0m| 26/26 [00:32<00:00,  1.09it/s]Epoch: 8/10. Loss: 0.9493: 100%|[36m██████████[0m| 26/26 [00:32<00:00,  1.24s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:05,  1.16it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:05,  1.03s/it] 43%|[33m████▎     [0m| 3/7 [00:02<00:03,  1.10it/s] 57%|[33m█████▋    [0m| 4/7 [00:04<00:03,  1.22s/it] 71%|[33m███████▏  [0m| 5/7 [00:04<00:01,  1.05it/s] 86%|[33m████████▌ [0m| 6/7 [00:05<00:00,  1.06it/s]100%|[33m██████████[0m| 7/7 [00:06<00:00,  1.40it/s]100%|[33m██████████[0m| 7/7 [00:06<00:00,  1.14it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 9/10. Loss: 0.8947:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 9/10. Loss: 0.8947:   4%|[36m▍         [0m| 1/26 [00:00<00:22,  1.09it/s]Epoch: 9/10. Loss: 0.9593:   4%|[36m▍         [0m| 1/26 [00:01<00:22,  1.09it/s]Epoch: 9/10. Loss: 0.9593:   8%|[36m▊         [0m| 2/26 [00:01<00:20,  1.17it/s]Epoch: 9/10. Loss: 0.9461:   8%|[36m▊         [0m| 2/26 [00:03<00:20,  1.17it/s]Epoch: 9/10. Loss: 0.9461:  12%|[36m█▏        [0m| 3/26 [00:03<00:24,  1.05s/it]Epoch: 9/10. Loss: 0.8475:  12%|[36m█▏        [0m| 3/26 [00:03<00:24,  1.05s/it]Epoch: 9/10. Loss: 0.8475:  15%|[36m█▌        [0m| 4/26 [00:03<00:22,  1.02s/it]Epoch: 9/10. Loss: 0.9461:  15%|[36m█▌        [0m| 4/26 [00:05<00:22,  1.02s/it]Epoch: 9/10. Loss: 0.9461:  19%|[36m█▉        [0m| 5/26 [00:05<00:24,  1.16s/it]Epoch: 9/10. Loss: 0.8549:  19%|[36m█▉        [0m| 5/26 [00:06<00:24,  1.16s/it]Epoch: 9/10. Loss: 0.8549:  23%|[36m██▎       [0m| 6/26 [00:06<00:24,  1.23s/it]Epoch: 9/10. Loss: 0.8952:  23%|[36m██▎       [0m| 6/26 [00:07<00:24,  1.23s/it]Epoch: 9/10. Loss: 0.8952:  27%|[36m██▋       [0m| 7/26 [00:07<00:21,  1.15s/it]Epoch: 9/10. Loss: 0.8530:  27%|[36m██▋       [0m| 7/26 [00:08<00:21,  1.15s/it]Epoch: 9/10. Loss: 0.8530:  31%|[36m███       [0m| 8/26 [00:08<00:18,  1.02s/it]Epoch: 9/10. Loss: 0.8054:  31%|[36m███       [0m| 8/26 [00:09<00:18,  1.02s/it]Epoch: 9/10. Loss: 0.8054:  35%|[36m███▍      [0m| 9/26 [00:09<00:17,  1.03s/it]Epoch: 9/10. Loss: 0.7762:  35%|[36m███▍      [0m| 9/26 [00:10<00:17,  1.03s/it]Epoch: 9/10. Loss: 0.7762:  38%|[36m███▊      [0m| 10/26 [00:10<00:16,  1.03s/it]Epoch: 9/10. Loss: 0.8651:  38%|[36m███▊      [0m| 10/26 [00:11<00:16,  1.03s/it]Epoch: 9/10. Loss: 0.8651:  42%|[36m████▏     [0m| 11/26 [00:11<00:16,  1.10s/it]Epoch: 9/10. Loss: 0.7878:  42%|[36m████▏     [0m| 11/26 [00:12<00:16,  1.10s/it]Epoch: 9/10. Loss: 0.7878:  46%|[36m████▌     [0m| 12/26 [00:12<00:14,  1.06s/it]Epoch: 9/10. Loss: 0.8346:  46%|[36m████▌     [0m| 12/26 [00:14<00:14,  1.06s/it]Epoch: 9/10. Loss: 0.8346:  50%|[36m█████     [0m| 13/26 [00:14<00:15,  1.16s/it]Epoch: 9/10. Loss: 0.8347:  50%|[36m█████     [0m| 13/26 [00:15<00:15,  1.16s/it]Epoch: 9/10. Loss: 0.8347:  54%|[36m█████▍    [0m| 14/26 [00:15<00:13,  1.08s/it]Epoch: 9/10. Loss: 0.9179:  54%|[36m█████▍    [0m| 14/26 [00:18<00:13,  1.08s/it]Epoch: 9/10. Loss: 0.9179:  58%|[36m█████▊    [0m| 15/26 [00:18<00:18,  1.65s/it]Epoch: 9/10. Loss: 0.8671:  58%|[36m█████▊    [0m| 15/26 [00:18<00:18,  1.65s/it]Epoch: 9/10. Loss: 0.8671:  62%|[36m██████▏   [0m| 16/26 [00:19<00:14,  1.44s/it]Epoch: 9/10. Loss: 0.8116:  62%|[36m██████▏   [0m| 16/26 [00:19<00:14,  1.44s/it]Epoch: 9/10. Loss: 0.8116:  65%|[36m██████▌   [0m| 17/26 [00:19<00:11,  1.29s/it]Epoch: 9/10. Loss: 0.8219:  65%|[36m██████▌   [0m| 17/26 [00:20<00:11,  1.29s/it]Epoch: 9/10. Loss: 0.8219:  69%|[36m██████▉   [0m| 18/26 [00:20<00:09,  1.14s/it]Epoch: 9/10. Loss: 0.8210:  69%|[36m██████▉   [0m| 18/26 [00:22<00:09,  1.14s/it]Epoch: 9/10. Loss: 0.8210:  73%|[36m███████▎  [0m| 19/26 [00:22<00:08,  1.28s/it]Epoch: 9/10. Loss: 0.7624:  73%|[36m███████▎  [0m| 19/26 [00:23<00:08,  1.28s/it]Epoch: 9/10. Loss: 0.7624:  77%|[36m███████▋  [0m| 20/26 [00:23<00:07,  1.20s/it]Epoch: 9/10. Loss: 0.8175:  77%|[36m███████▋  [0m| 20/26 [00:24<00:07,  1.20s/it]Epoch: 9/10. Loss: 0.8175:  81%|[36m████████  [0m| 21/26 [00:24<00:05,  1.12s/it]Epoch: 9/10. Loss: 0.9647:  81%|[36m████████  [0m| 21/26 [00:25<00:05,  1.12s/it]Epoch: 9/10. Loss: 0.9647:  85%|[36m████████▍ [0m| 22/26 [00:25<00:04,  1.06s/it]Epoch: 9/10. Loss: 0.8562:  85%|[36m████████▍ [0m| 22/26 [00:26<00:04,  1.06s/it]Epoch: 9/10. Loss: 0.8562:  88%|[36m████████▊ [0m| 23/26 [00:26<00:03,  1.05s/it]Epoch: 9/10. Loss: 0.8550:  88%|[36m████████▊ [0m| 23/26 [00:27<00:03,  1.05s/it]Epoch: 9/10. Loss: 0.8550:  92%|[36m█████████▏[0m| 24/26 [00:27<00:02,  1.04s/it]Epoch: 9/10. Loss: 0.9090:  92%|[36m█████████▏[0m| 24/26 [00:28<00:02,  1.04s/it]Epoch: 9/10. Loss: 0.9090:  96%|[36m█████████▌[0m| 25/26 [00:28<00:01,  1.07s/it]Epoch: 9/10. Loss: 0.7293:  96%|[36m█████████▌[0m| 25/26 [00:29<00:01,  1.07s/it]Epoch: 9/10. Loss: 0.7293: 100%|[36m██████████[0m| 26/26 [00:29<00:00,  1.06it/s]Epoch: 9/10. Loss: 0.7293: 100%|[36m██████████[0m| 26/26 [00:29<00:00,  1.12s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:05,  1.09it/s] 29%|[33m██▊       [0m| 2/7 [00:01<00:05,  1.00s/it] 43%|[33m████▎     [0m| 3/7 [00:02<00:03,  1.10it/s] 57%|[33m█████▋    [0m| 4/7 [00:04<00:03,  1.12s/it] 71%|[33m███████▏  [0m| 5/7 [00:04<00:01,  1.12it/s] 86%|[33m████████▌ [0m| 6/7 [00:05<00:00,  1.10it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.42it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.18it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 0/10. Loss: 1.0552:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 0/10. Loss: 1.0552:   4%|[36m▍         [0m| 1/26 [00:00<00:19,  1.31it/s]Epoch: 0/10. Loss: 4.2356:   4%|[36m▍         [0m| 1/26 [00:02<00:19,  1.31it/s]Epoch: 0/10. Loss: 4.2356:   8%|[36m▊         [0m| 2/26 [00:02<00:31,  1.33s/it]Epoch: 0/10. Loss: 4.0553:   8%|[36m▊         [0m| 2/26 [00:03<00:31,  1.33s/it]Epoch: 0/10. Loss: 4.0553:  12%|[36m█▏        [0m| 3/26 [00:03<00:27,  1.21s/it]Epoch: 0/10. Loss: 1.9056:  12%|[36m█▏        [0m| 3/26 [00:04<00:27,  1.21s/it]Epoch: 0/10. Loss: 1.9056:  15%|[36m█▌        [0m| 4/26 [00:04<00:23,  1.08s/it]Epoch: 0/10. Loss: 0.9998:  15%|[36m█▌        [0m| 4/26 [00:05<00:23,  1.08s/it]Epoch: 0/10. Loss: 0.9998:  19%|[36m█▉        [0m| 5/26 [00:05<00:21,  1.03s/it]Epoch: 0/10. Loss: 1.0628:  19%|[36m█▉        [0m| 5/26 [00:06<00:21,  1.03s/it]Epoch: 0/10. Loss: 1.0628:  23%|[36m██▎       [0m| 6/26 [00:06<00:19,  1.05it/s]Epoch: 0/10. Loss: 2.6412:  23%|[36m██▎       [0m| 6/26 [00:08<00:19,  1.05it/s]Epoch: 0/10. Loss: 2.6412:  27%|[36m██▋       [0m| 7/26 [00:08<00:28,  1.49s/it]Epoch: 0/10. Loss: 1.9262:  27%|[36m██▋       [0m| 7/26 [00:10<00:28,  1.49s/it]Epoch: 0/10. Loss: 1.9262:  31%|[36m███       [0m| 8/26 [00:10<00:28,  1.60s/it]Epoch: 0/10. Loss: 1.5239:  31%|[36m███       [0m| 8/26 [00:11<00:28,  1.60s/it]Epoch: 0/10. Loss: 1.5239:  35%|[36m███▍      [0m| 9/26 [00:11<00:22,  1.34s/it]Epoch: 0/10. Loss: 1.1017:  35%|[36m███▍      [0m| 9/26 [00:12<00:22,  1.34s/it]Epoch: 0/10. Loss: 1.1017:  38%|[36m███▊      [0m| 10/26 [00:12<00:20,  1.27s/it]Epoch: 0/10. Loss: 1.5122:  38%|[36m███▊      [0m| 10/26 [00:13<00:20,  1.27s/it]Epoch: 0/10. Loss: 1.5122:  42%|[36m████▏     [0m| 11/26 [00:13<00:17,  1.17s/it]Epoch: 0/10. Loss: 1.7587:  42%|[36m████▏     [0m| 11/26 [00:14<00:17,  1.17s/it]Epoch: 0/10. Loss: 1.7587:  46%|[36m████▌     [0m| 12/26 [00:14<00:16,  1.16s/it]Epoch: 0/10. Loss: 1.7811:  46%|[36m████▌     [0m| 12/26 [00:15<00:16,  1.16s/it]Epoch: 0/10. Loss: 1.7811:  50%|[36m█████     [0m| 13/26 [00:15<00:14,  1.14s/it]Epoch: 0/10. Loss: 1.8320:  50%|[36m█████     [0m| 13/26 [00:16<00:14,  1.14s/it]Epoch: 0/10. Loss: 1.8320:  54%|[36m█████▍    [0m| 14/26 [00:16<00:12,  1.06s/it]Epoch: 0/10. Loss: 1.4770:  54%|[36m█████▍    [0m| 14/26 [00:17<00:12,  1.06s/it]Epoch: 0/10. Loss: 1.4770:  58%|[36m█████▊    [0m| 15/26 [00:17<00:11,  1.00s/it]Epoch: 0/10. Loss: 1.2619:  58%|[36m█████▊    [0m| 15/26 [00:18<00:11,  1.00s/it]Epoch: 0/10. Loss: 1.2619:  62%|[36m██████▏   [0m| 16/26 [00:18<00:09,  1.05it/s]Epoch: 0/10. Loss: 1.3454:  62%|[36m██████▏   [0m| 16/26 [00:19<00:09,  1.05it/s]Epoch: 0/10. Loss: 1.3454:  65%|[36m██████▌   [0m| 17/26 [00:19<00:08,  1.08it/s]Epoch: 0/10. Loss: 1.3199:  65%|[36m██████▌   [0m| 17/26 [00:20<00:08,  1.08it/s]Epoch: 0/10. Loss: 1.3199:  69%|[36m██████▉   [0m| 18/26 [00:20<00:07,  1.08it/s]Epoch: 0/10. Loss: 1.1750:  69%|[36m██████▉   [0m| 18/26 [00:21<00:07,  1.08it/s]Epoch: 0/10. Loss: 1.1750:  73%|[36m███████▎  [0m| 19/26 [00:21<00:06,  1.01it/s]Epoch: 0/10. Loss: 1.1556:  73%|[36m███████▎  [0m| 19/26 [00:22<00:06,  1.01it/s]Epoch: 0/10. Loss: 1.1556:  77%|[36m███████▋  [0m| 20/26 [00:22<00:05,  1.03it/s]Epoch: 0/10. Loss: 1.4934:  77%|[36m███████▋  [0m| 20/26 [00:23<00:05,  1.03it/s]Epoch: 0/10. Loss: 1.4934:  81%|[36m████████  [0m| 21/26 [00:23<00:04,  1.02it/s]Epoch: 0/10. Loss: 1.1764:  81%|[36m████████  [0m| 21/26 [00:24<00:04,  1.02it/s]Epoch: 0/10. Loss: 1.1764:  85%|[36m████████▍ [0m| 22/26 [00:24<00:03,  1.03it/s]Epoch: 0/10. Loss: 1.0728:  85%|[36m████████▍ [0m| 22/26 [00:24<00:03,  1.03it/s]Epoch: 0/10. Loss: 1.0728:  88%|[36m████████▊ [0m| 23/26 [00:24<00:02,  1.05it/s]Epoch: 0/10. Loss: 1.3343:  88%|[36m████████▊ [0m| 23/26 [00:26<00:02,  1.05it/s]Epoch: 0/10. Loss: 1.3343:  92%|[36m█████████▏[0m| 24/26 [00:26<00:02,  1.02s/it]Epoch: 0/10. Loss: 1.0987:  92%|[36m█████████▏[0m| 24/26 [00:27<00:02,  1.02s/it]Epoch: 0/10. Loss: 1.0987:  96%|[36m█████████▌[0m| 25/26 [00:27<00:01,  1.00s/it]Epoch: 0/10. Loss: 1.1351:  96%|[36m█████████▌[0m| 25/26 [00:27<00:01,  1.00s/it]Epoch: 0/10. Loss: 1.1351: 100%|[36m██████████[0m| 26/26 [00:27<00:00,  1.06it/s]Epoch: 0/10. Loss: 1.1351: 100%|[36m██████████[0m| 26/26 [00:27<00:00,  1.07s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:04,  1.25it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:06,  1.23s/it] 43%|[33m████▎     [0m| 3/7 [00:03<00:04,  1.12s/it] 57%|[33m█████▋    [0m| 4/7 [00:05<00:04,  1.57s/it] 71%|[33m███████▏  [0m| 5/7 [00:06<00:03,  1.51s/it] 86%|[33m████████▌ [0m| 6/7 [00:07<00:01,  1.33s/it]100%|[33m██████████[0m| 7/7 [00:08<00:00,  1.00it/s]100%|[33m██████████[0m| 7/7 [00:08<00:00,  1.18s/it]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 1/10. Loss: 1.1478:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 1/10. Loss: 1.1478:   4%|[36m▍         [0m| 1/26 [00:00<00:24,  1.04it/s]Epoch: 1/10. Loss: 1.0477:   4%|[36m▍         [0m| 1/26 [00:01<00:24,  1.04it/s]Epoch: 1/10. Loss: 1.0477:   8%|[36m▊         [0m| 2/26 [00:01<00:23,  1.00it/s]Epoch: 1/10. Loss: 0.9745:   8%|[36m▊         [0m| 2/26 [00:03<00:23,  1.00it/s]Epoch: 1/10. Loss: 0.9745:  12%|[36m█▏        [0m| 3/26 [00:03<00:26,  1.17s/it]Epoch: 1/10. Loss: 0.9803:  12%|[36m█▏        [0m| 3/26 [00:04<00:26,  1.17s/it]Epoch: 1/10. Loss: 0.9803:  15%|[36m█▌        [0m| 4/26 [00:04<00:24,  1.12s/it]Epoch: 1/10. Loss: 0.9394:  15%|[36m█▌        [0m| 4/26 [00:05<00:24,  1.12s/it]Epoch: 1/10. Loss: 0.9394:  19%|[36m█▉        [0m| 5/26 [00:05<00:21,  1.01s/it]Epoch: 1/10. Loss: 0.9757:  19%|[36m█▉        [0m| 5/26 [00:06<00:21,  1.01s/it]Epoch: 1/10. Loss: 0.9757:  23%|[36m██▎       [0m| 6/26 [00:06<00:20,  1.04s/it]Epoch: 1/10. Loss: 1.0257:  23%|[36m██▎       [0m| 6/26 [00:07<00:20,  1.04s/it]Epoch: 1/10. Loss: 1.0257:  27%|[36m██▋       [0m| 7/26 [00:07<00:19,  1.01s/it]Epoch: 1/10. Loss: 1.0845:  27%|[36m██▋       [0m| 7/26 [00:08<00:19,  1.01s/it]Epoch: 1/10. Loss: 1.0845:  31%|[36m███       [0m| 8/26 [00:08<00:17,  1.04it/s]Epoch: 1/10. Loss: 1.0044:  31%|[36m███       [0m| 8/26 [00:09<00:17,  1.04it/s]Epoch: 1/10. Loss: 1.0044:  35%|[36m███▍      [0m| 9/26 [00:09<00:15,  1.07it/s]Epoch: 1/10. Loss: 0.9795:  35%|[36m███▍      [0m| 9/26 [00:10<00:15,  1.07it/s]Epoch: 1/10. Loss: 0.9795:  38%|[36m███▊      [0m| 10/26 [00:10<00:15,  1.02it/s]Epoch: 1/10. Loss: 0.9638:  38%|[36m███▊      [0m| 10/26 [00:10<00:15,  1.02it/s]Epoch: 1/10. Loss: 0.9638:  42%|[36m████▏     [0m| 11/26 [00:10<00:14,  1.05it/s]Epoch: 1/10. Loss: 1.0574:  42%|[36m████▏     [0m| 11/26 [00:12<00:14,  1.05it/s]Epoch: 1/10. Loss: 1.0574:  46%|[36m████▌     [0m| 12/26 [00:12<00:13,  1.01it/s]Epoch: 1/10. Loss: 0.9847:  46%|[36m████▌     [0m| 12/26 [00:12<00:13,  1.01it/s]Epoch: 1/10. Loss: 0.9847:  50%|[36m█████     [0m| 13/26 [00:12<00:12,  1.04it/s]Epoch: 1/10. Loss: 1.0274:  50%|[36m█████     [0m| 13/26 [00:14<00:12,  1.04it/s]Epoch: 1/10. Loss: 1.0274:  54%|[36m█████▍    [0m| 14/26 [00:14<00:12,  1.01s/it]Epoch: 1/10. Loss: 0.9828:  54%|[36m█████▍    [0m| 14/26 [00:14<00:12,  1.01s/it]Epoch: 1/10. Loss: 0.9828:  58%|[36m█████▊    [0m| 15/26 [00:14<00:10,  1.03it/s]Epoch: 1/10. Loss: 0.9866:  58%|[36m█████▊    [0m| 15/26 [00:15<00:10,  1.03it/s]Epoch: 1/10. Loss: 0.9866:  62%|[36m██████▏   [0m| 16/26 [00:15<00:09,  1.02it/s]Epoch: 1/10. Loss: 1.0420:  62%|[36m██████▏   [0m| 16/26 [00:17<00:09,  1.02it/s]Epoch: 1/10. Loss: 1.0420:  65%|[36m██████▌   [0m| 17/26 [00:17<00:09,  1.02s/it]Epoch: 1/10. Loss: 0.9703:  65%|[36m██████▌   [0m| 17/26 [00:18<00:09,  1.02s/it]Epoch: 1/10. Loss: 0.9703:  69%|[36m██████▉   [0m| 18/26 [00:18<00:08,  1.00s/it]Epoch: 1/10. Loss: 0.9610:  69%|[36m██████▉   [0m| 18/26 [00:18<00:08,  1.00s/it]Epoch: 1/10. Loss: 0.9610:  73%|[36m███████▎  [0m| 19/26 [00:18<00:06,  1.05it/s]Epoch: 1/10. Loss: 0.8751:  73%|[36m███████▎  [0m| 19/26 [00:19<00:06,  1.05it/s]Epoch: 1/10. Loss: 0.8751:  77%|[36m███████▋  [0m| 20/26 [00:19<00:05,  1.07it/s]Epoch: 1/10. Loss: 0.9660:  77%|[36m███████▋  [0m| 20/26 [00:20<00:05,  1.07it/s]Epoch: 1/10. Loss: 0.9660:  81%|[36m████████  [0m| 21/26 [00:20<00:04,  1.14it/s]Epoch: 1/10. Loss: 1.0147:  81%|[36m████████  [0m| 21/26 [00:21<00:04,  1.14it/s]Epoch: 1/10. Loss: 1.0147:  85%|[36m████████▍ [0m| 22/26 [00:21<00:03,  1.15it/s]Epoch: 1/10. Loss: 0.8530:  85%|[36m████████▍ [0m| 22/26 [00:22<00:03,  1.15it/s]Epoch: 1/10. Loss: 0.8530:  88%|[36m████████▊ [0m| 23/26 [00:22<00:02,  1.15it/s]Epoch: 1/10. Loss: 0.9992:  88%|[36m████████▊ [0m| 23/26 [00:23<00:02,  1.15it/s]Epoch: 1/10. Loss: 0.9992:  92%|[36m█████████▏[0m| 24/26 [00:23<00:01,  1.13it/s]Epoch: 1/10. Loss: 1.0047:  92%|[36m█████████▏[0m| 24/26 [00:24<00:01,  1.13it/s]Epoch: 1/10. Loss: 1.0047:  96%|[36m█████████▌[0m| 25/26 [00:24<00:00,  1.06it/s]Epoch: 1/10. Loss: 0.8928:  96%|[36m█████████▌[0m| 25/26 [00:24<00:00,  1.06it/s]Epoch: 1/10. Loss: 0.8928: 100%|[36m██████████[0m| 26/26 [00:24<00:00,  1.14it/s]Epoch: 1/10. Loss: 0.8928: 100%|[36m██████████[0m| 26/26 [00:24<00:00,  1.04it/s]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:04,  1.23it/s] 29%|[33m██▊       [0m| 2/7 [00:01<00:04,  1.03it/s] 43%|[33m████▎     [0m| 3/7 [00:02<00:03,  1.14it/s] 57%|[33m█████▋    [0m| 4/7 [00:03<00:03,  1.03s/it] 71%|[33m███████▏  [0m| 5/7 [00:04<00:01,  1.23it/s] 86%|[33m████████▌ [0m| 6/7 [00:05<00:00,  1.19it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.29it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.19it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 2/10. Loss: 0.8741:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 2/10. Loss: 0.8741:   4%|[36m▍         [0m| 1/26 [00:00<00:18,  1.38it/s]Epoch: 2/10. Loss: 0.8919:   4%|[36m▍         [0m| 1/26 [00:02<00:18,  1.38it/s]Epoch: 2/10. Loss: 0.8919:   8%|[36m▊         [0m| 2/26 [00:02<00:32,  1.33s/it]Epoch: 2/10. Loss: 0.9226:   8%|[36m▊         [0m| 2/26 [00:03<00:32,  1.33s/it]Epoch: 2/10. Loss: 0.9226:  12%|[36m█▏        [0m| 3/26 [00:03<00:25,  1.10s/it]Epoch: 2/10. Loss: 0.8924:  12%|[36m█▏        [0m| 3/26 [00:05<00:25,  1.10s/it]Epoch: 2/10. Loss: 0.8924:  15%|[36m█▌        [0m| 4/26 [00:05<00:33,  1.53s/it]Epoch: 2/10. Loss: 0.9428:  15%|[36m█▌        [0m| 4/26 [00:06<00:33,  1.53s/it]Epoch: 2/10. Loss: 0.9428:  19%|[36m█▉        [0m| 5/26 [00:06<00:27,  1.29s/it]Epoch: 2/10. Loss: 0.9647:  19%|[36m█▉        [0m| 5/26 [00:07<00:27,  1.29s/it]Epoch: 2/10. Loss: 0.9647:  23%|[36m██▎       [0m| 6/26 [00:07<00:23,  1.17s/it]Epoch: 2/10. Loss: 0.9352:  23%|[36m██▎       [0m| 6/26 [00:08<00:23,  1.17s/it]Epoch: 2/10. Loss: 0.9352:  27%|[36m██▋       [0m| 7/26 [00:08<00:22,  1.16s/it]Epoch: 2/10. Loss: 0.9387:  27%|[36m██▋       [0m| 7/26 [00:09<00:22,  1.16s/it]Epoch: 2/10. Loss: 0.9387:  31%|[36m███       [0m| 8/26 [00:09<00:18,  1.03s/it]Epoch: 2/10. Loss: 0.9995:  31%|[36m███       [0m| 8/26 [00:09<00:18,  1.03s/it]Epoch: 2/10. Loss: 0.9995:  35%|[36m███▍      [0m| 9/26 [00:09<00:16,  1.05it/s]Epoch: 2/10. Loss: 0.9819:  35%|[36m███▍      [0m| 9/26 [00:10<00:16,  1.05it/s]Epoch: 2/10. Loss: 0.9819:  38%|[36m███▊      [0m| 10/26 [00:10<00:14,  1.08it/s]Epoch: 2/10. Loss: 0.8797:  38%|[36m███▊      [0m| 10/26 [00:11<00:14,  1.08it/s]Epoch: 2/10. Loss: 0.8797:  42%|[36m████▏     [0m| 11/26 [00:11<00:14,  1.06it/s]Epoch: 2/10. Loss: 0.9036:  42%|[36m████▏     [0m| 11/26 [00:12<00:14,  1.06it/s]Epoch: 2/10. Loss: 0.9036:  46%|[36m████▌     [0m| 12/26 [00:12<00:12,  1.10it/s]Epoch: 2/10. Loss: 0.9931:  46%|[36m████▌     [0m| 12/26 [00:13<00:12,  1.10it/s]Epoch: 2/10. Loss: 0.9931:  50%|[36m█████     [0m| 13/26 [00:13<00:12,  1.02it/s]Epoch: 2/10. Loss: 0.9379:  50%|[36m█████     [0m| 13/26 [00:14<00:12,  1.02it/s]Epoch: 2/10. Loss: 0.9379:  54%|[36m█████▍    [0m| 14/26 [00:14<00:11,  1.06it/s]Epoch: 2/10. Loss: 0.7902:  54%|[36m█████▍    [0m| 14/26 [00:15<00:11,  1.06it/s]Epoch: 2/10. Loss: 0.7902:  58%|[36m█████▊    [0m| 15/26 [00:15<00:09,  1.10it/s]Epoch: 2/10. Loss: 0.9295:  58%|[36m█████▊    [0m| 15/26 [00:16<00:09,  1.10it/s]Epoch: 2/10. Loss: 0.9295:  62%|[36m██████▏   [0m| 16/26 [00:16<00:09,  1.08it/s]Epoch: 2/10. Loss: 1.1254:  62%|[36m██████▏   [0m| 16/26 [00:17<00:09,  1.08it/s]Epoch: 2/10. Loss: 1.1254:  65%|[36m██████▌   [0m| 17/26 [00:17<00:09,  1.00s/it]Epoch: 2/10. Loss: 0.9584:  65%|[36m██████▌   [0m| 17/26 [00:18<00:09,  1.00s/it]Epoch: 2/10. Loss: 0.9584:  69%|[36m██████▉   [0m| 18/26 [00:18<00:08,  1.02s/it]Epoch: 2/10. Loss: 0.9417:  69%|[36m██████▉   [0m| 18/26 [00:19<00:08,  1.02s/it]Epoch: 2/10. Loss: 0.9417:  73%|[36m███████▎  [0m| 19/26 [00:19<00:06,  1.00it/s]Epoch: 2/10. Loss: 0.9155:  73%|[36m███████▎  [0m| 19/26 [00:20<00:06,  1.00it/s]Epoch: 2/10. Loss: 0.9155:  77%|[36m███████▋  [0m| 20/26 [00:20<00:06,  1.08s/it]Epoch: 2/10. Loss: 0.9023:  77%|[36m███████▋  [0m| 20/26 [00:21<00:06,  1.08s/it]Epoch: 2/10. Loss: 0.9023:  81%|[36m████████  [0m| 21/26 [00:21<00:05,  1.05s/it]Epoch: 2/10. Loss: 0.9173:  81%|[36m████████  [0m| 21/26 [00:22<00:05,  1.05s/it]Epoch: 2/10. Loss: 0.9173:  85%|[36m████████▍ [0m| 22/26 [00:22<00:04,  1.00s/it]Epoch: 2/10. Loss: 0.9072:  85%|[36m████████▍ [0m| 22/26 [00:24<00:04,  1.00s/it]Epoch: 2/10. Loss: 0.9072:  88%|[36m████████▊ [0m| 23/26 [00:24<00:03,  1.16s/it]Epoch: 2/10. Loss: 0.9242:  88%|[36m████████▊ [0m| 23/26 [00:25<00:03,  1.16s/it]Epoch: 2/10. Loss: 0.9242:  92%|[36m█████████▏[0m| 24/26 [00:25<00:02,  1.06s/it]Epoch: 2/10. Loss: 0.9648:  92%|[36m█████████▏[0m| 24/26 [00:26<00:02,  1.06s/it]Epoch: 2/10. Loss: 0.9648:  96%|[36m█████████▌[0m| 25/26 [00:26<00:01,  1.08s/it]Epoch: 2/10. Loss: 0.9642:  96%|[36m█████████▌[0m| 25/26 [00:26<00:01,  1.08s/it]Epoch: 2/10. Loss: 0.9642: 100%|[36m██████████[0m| 26/26 [00:26<00:00,  1.05it/s]Epoch: 2/10. Loss: 0.9642: 100%|[36m██████████[0m| 26/26 [00:26<00:00,  1.04s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:01<00:08,  1.34s/it] 29%|[33m██▊       [0m| 2/7 [00:02<00:05,  1.17s/it] 43%|[33m████▎     [0m| 3/7 [00:03<00:03,  1.01it/s] 57%|[33m█████▋    [0m| 4/7 [00:04<00:03,  1.12s/it] 71%|[33m███████▏  [0m| 5/7 [00:04<00:01,  1.14it/s] 86%|[33m████████▌ [0m| 6/7 [00:05<00:00,  1.14it/s]100%|[33m██████████[0m| 7/7 [00:06<00:00,  1.47it/s]100%|[33m██████████[0m| 7/7 [00:06<00:00,  1.15it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 3/10. Loss: 0.9401:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 3/10. Loss: 0.9401:   4%|[36m▍         [0m| 1/26 [00:00<00:23,  1.08it/s]Epoch: 3/10. Loss: 0.9978:   4%|[36m▍         [0m| 1/26 [00:01<00:23,  1.08it/s]Epoch: 3/10. Loss: 0.9978:   8%|[36m▊         [0m| 2/26 [00:01<00:21,  1.10it/s]Epoch: 3/10. Loss: 1.1002:   8%|[36m▊         [0m| 2/26 [00:02<00:21,  1.10it/s]Epoch: 3/10. Loss: 1.1002:  12%|[36m█▏        [0m| 3/26 [00:02<00:21,  1.07it/s]Epoch: 3/10. Loss: 0.9246:  12%|[36m█▏        [0m| 3/26 [00:03<00:21,  1.07it/s]Epoch: 3/10. Loss: 0.9246:  15%|[36m█▌        [0m| 4/26 [00:03<00:20,  1.07it/s]Epoch: 3/10. Loss: 0.8524:  15%|[36m█▌        [0m| 4/26 [00:04<00:20,  1.07it/s]Epoch: 3/10. Loss: 0.8524:  19%|[36m█▉        [0m| 5/26 [00:04<00:19,  1.09it/s]Epoch: 3/10. Loss: 0.9663:  19%|[36m█▉        [0m| 5/26 [00:05<00:19,  1.09it/s]Epoch: 3/10. Loss: 0.9663:  23%|[36m██▎       [0m| 6/26 [00:05<00:17,  1.14it/s]Epoch: 3/10. Loss: 1.0353:  23%|[36m██▎       [0m| 6/26 [00:06<00:17,  1.14it/s]Epoch: 3/10. Loss: 1.0353:  27%|[36m██▋       [0m| 7/26 [00:06<00:17,  1.11it/s]Epoch: 3/10. Loss: 0.9061:  27%|[36m██▋       [0m| 7/26 [00:07<00:17,  1.11it/s]Epoch: 3/10. Loss: 0.9061:  31%|[36m███       [0m| 8/26 [00:07<00:16,  1.09it/s]Epoch: 3/10. Loss: 0.9702:  31%|[36m███       [0m| 8/26 [00:08<00:16,  1.09it/s]Epoch: 3/10. Loss: 0.9702:  35%|[36m███▍      [0m| 9/26 [00:08<00:15,  1.08it/s]Epoch: 3/10. Loss: 0.8893:  35%|[36m███▍      [0m| 9/26 [00:09<00:15,  1.08it/s]Epoch: 3/10. Loss: 0.8893:  38%|[36m███▊      [0m| 10/26 [00:09<00:14,  1.08it/s]Epoch: 3/10. Loss: 0.8159:  38%|[36m███▊      [0m| 10/26 [00:10<00:14,  1.08it/s]Epoch: 3/10. Loss: 0.8159:  42%|[36m████▏     [0m| 11/26 [00:10<00:13,  1.10it/s]Epoch: 3/10. Loss: 0.9900:  42%|[36m████▏     [0m| 11/26 [00:11<00:13,  1.10it/s]Epoch: 3/10. Loss: 0.9900:  46%|[36m████▌     [0m| 12/26 [00:11<00:13,  1.05it/s]Epoch: 3/10. Loss: 0.9962:  46%|[36m████▌     [0m| 12/26 [00:11<00:13,  1.05it/s]Epoch: 3/10. Loss: 0.9962:  50%|[36m█████     [0m| 13/26 [00:11<00:11,  1.12it/s]Epoch: 3/10. Loss: 0.8855:  50%|[36m█████     [0m| 13/26 [00:12<00:11,  1.12it/s]Epoch: 3/10. Loss: 0.8855:  54%|[36m█████▍    [0m| 14/26 [00:12<00:10,  1.13it/s]Epoch: 3/10. Loss: 0.8600:  54%|[36m█████▍    [0m| 14/26 [00:13<00:10,  1.13it/s]Epoch: 3/10. Loss: 0.8600:  58%|[36m█████▊    [0m| 15/26 [00:13<00:09,  1.11it/s]Epoch: 3/10. Loss: 0.8809:  58%|[36m█████▊    [0m| 15/26 [00:14<00:09,  1.11it/s]Epoch: 3/10. Loss: 0.8809:  62%|[36m██████▏   [0m| 16/26 [00:14<00:08,  1.13it/s]Epoch: 3/10. Loss: 0.7916:  62%|[36m██████▏   [0m| 16/26 [00:16<00:08,  1.13it/s]Epoch: 3/10. Loss: 0.7916:  65%|[36m██████▌   [0m| 17/26 [00:16<00:10,  1.17s/it]Epoch: 3/10. Loss: 0.8931:  65%|[36m██████▌   [0m| 17/26 [00:17<00:10,  1.17s/it]Epoch: 3/10. Loss: 0.8931:  69%|[36m██████▉   [0m| 18/26 [00:17<00:10,  1.27s/it]Epoch: 3/10. Loss: 0.8964:  69%|[36m██████▉   [0m| 18/26 [00:18<00:10,  1.27s/it]Epoch: 3/10. Loss: 0.8964:  73%|[36m███████▎  [0m| 19/26 [00:18<00:08,  1.17s/it]Epoch: 3/10. Loss: 0.8395:  73%|[36m███████▎  [0m| 19/26 [00:20<00:08,  1.17s/it]Epoch: 3/10. Loss: 0.8395:  77%|[36m███████▋  [0m| 20/26 [00:20<00:08,  1.40s/it]Epoch: 3/10. Loss: 0.8363:  77%|[36m███████▋  [0m| 20/26 [00:21<00:08,  1.40s/it]Epoch: 3/10. Loss: 0.8363:  81%|[36m████████  [0m| 21/26 [00:21<00:06,  1.26s/it]Epoch: 3/10. Loss: 0.8412:  81%|[36m████████  [0m| 21/26 [00:22<00:06,  1.26s/it]Epoch: 3/10. Loss: 0.8412:  85%|[36m████████▍ [0m| 22/26 [00:22<00:04,  1.17s/it]Epoch: 3/10. Loss: 0.8012:  85%|[36m████████▍ [0m| 22/26 [00:23<00:04,  1.17s/it]Epoch: 3/10. Loss: 0.8012:  88%|[36m████████▊ [0m| 23/26 [00:23<00:03,  1.17s/it]Epoch: 3/10. Loss: 0.8484:  88%|[36m████████▊ [0m| 23/26 [00:24<00:03,  1.17s/it]Epoch: 3/10. Loss: 0.8484:  92%|[36m█████████▏[0m| 24/26 [00:24<00:02,  1.12s/it]Epoch: 3/10. Loss: 0.8929:  92%|[36m█████████▏[0m| 24/26 [00:25<00:02,  1.12s/it]Epoch: 3/10. Loss: 0.8929:  96%|[36m█████████▌[0m| 25/26 [00:25<00:01,  1.05s/it]Epoch: 3/10. Loss: 0.9511:  96%|[36m█████████▌[0m| 25/26 [00:26<00:01,  1.05s/it]Epoch: 3/10. Loss: 0.9511: 100%|[36m██████████[0m| 26/26 [00:26<00:00,  1.06it/s]Epoch: 3/10. Loss: 0.9511: 100%|[36m██████████[0m| 26/26 [00:26<00:00,  1.01s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:05,  1.15it/s] 29%|[33m██▊       [0m| 2/7 [00:01<00:04,  1.01it/s] 43%|[33m████▎     [0m| 3/7 [00:02<00:03,  1.12it/s] 57%|[33m█████▋    [0m| 4/7 [00:04<00:03,  1.05s/it] 71%|[33m███████▏  [0m| 5/7 [00:04<00:01,  1.19it/s] 86%|[33m████████▌ [0m| 6/7 [00:05<00:00,  1.08it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.41it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.20it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 4/10. Loss: 0.7948:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 4/10. Loss: 0.7948:   4%|[36m▍         [0m| 1/26 [00:00<00:20,  1.19it/s]Epoch: 4/10. Loss: 0.8614:   4%|[36m▍         [0m| 1/26 [00:01<00:20,  1.19it/s]Epoch: 4/10. Loss: 0.8614:   8%|[36m▊         [0m| 2/26 [00:01<00:19,  1.26it/s]Epoch: 4/10. Loss: 0.7957:   8%|[36m▊         [0m| 2/26 [00:02<00:19,  1.26it/s]Epoch: 4/10. Loss: 0.7957:  12%|[36m█▏        [0m| 3/26 [00:02<00:19,  1.19it/s]Epoch: 4/10. Loss: 0.7964:  12%|[36m█▏        [0m| 3/26 [00:03<00:19,  1.19it/s]Epoch: 4/10. Loss: 0.7964:  15%|[36m█▌        [0m| 4/26 [00:03<00:18,  1.16it/s]Epoch: 4/10. Loss: 0.7715:  15%|[36m█▌        [0m| 4/26 [00:04<00:18,  1.16it/s]Epoch: 4/10. Loss: 0.7715:  19%|[36m█▉        [0m| 5/26 [00:04<00:19,  1.08it/s]Epoch: 4/10. Loss: 0.8330:  19%|[36m█▉        [0m| 5/26 [00:05<00:19,  1.08it/s]Epoch: 4/10. Loss: 0.8330:  23%|[36m██▎       [0m| 6/26 [00:05<00:19,  1.04it/s]Epoch: 4/10. Loss: 0.7204:  23%|[36m██▎       [0m| 6/26 [00:06<00:19,  1.04it/s]Epoch: 4/10. Loss: 0.7204:  27%|[36m██▋       [0m| 7/26 [00:06<00:21,  1.13s/it]Epoch: 4/10. Loss: 0.9202:  27%|[36m██▋       [0m| 7/26 [00:08<00:21,  1.13s/it]Epoch: 4/10. Loss: 0.9202:  31%|[36m███       [0m| 8/26 [00:08<00:23,  1.29s/it]Epoch: 4/10. Loss: 0.9169:  31%|[36m███       [0m| 8/26 [00:09<00:23,  1.29s/it]Epoch: 4/10. Loss: 0.9169:  35%|[36m███▍      [0m| 9/26 [00:09<00:19,  1.15s/it]Epoch: 4/10. Loss: 0.7683:  35%|[36m███▍      [0m| 9/26 [00:10<00:19,  1.15s/it]Epoch: 4/10. Loss: 0.7683:  38%|[36m███▊      [0m| 10/26 [00:10<00:16,  1.04s/it]Epoch: 4/10. Loss: 0.8082:  38%|[36m███▊      [0m| 10/26 [00:11<00:16,  1.04s/it]Epoch: 4/10. Loss: 0.8082:  42%|[36m████▏     [0m| 11/26 [00:11<00:15,  1.05s/it]Epoch: 4/10. Loss: 0.8614:  42%|[36m████▏     [0m| 11/26 [00:13<00:15,  1.05s/it]Epoch: 4/10. Loss: 0.8614:  46%|[36m████▌     [0m| 12/26 [00:13<00:21,  1.50s/it]Epoch: 4/10. Loss: 0.8732:  46%|[36m████▌     [0m| 12/26 [00:14<00:21,  1.50s/it]Epoch: 4/10. Loss: 0.8732:  50%|[36m█████     [0m| 13/26 [00:14<00:17,  1.33s/it]Epoch: 4/10. Loss: 0.7567:  50%|[36m█████     [0m| 13/26 [00:15<00:17,  1.33s/it]Epoch: 4/10. Loss: 0.7567:  54%|[36m█████▍    [0m| 14/26 [00:15<00:15,  1.28s/it]Epoch: 4/10. Loss: 0.7809:  54%|[36m█████▍    [0m| 14/26 [00:16<00:15,  1.28s/it]Epoch: 4/10. Loss: 0.7809:  58%|[36m█████▊    [0m| 15/26 [00:16<00:12,  1.16s/it]Epoch: 4/10. Loss: 0.8319:  58%|[36m█████▊    [0m| 15/26 [00:18<00:12,  1.16s/it]Epoch: 4/10. Loss: 0.8319:  62%|[36m██████▏   [0m| 16/26 [00:18<00:11,  1.19s/it]Epoch: 4/10. Loss: 0.7398:  62%|[36m██████▏   [0m| 16/26 [00:19<00:11,  1.19s/it]Epoch: 4/10. Loss: 0.7398:  65%|[36m██████▌   [0m| 17/26 [00:19<00:10,  1.15s/it]Epoch: 4/10. Loss: 0.8161:  65%|[36m██████▌   [0m| 17/26 [00:20<00:10,  1.15s/it]Epoch: 4/10. Loss: 0.8161:  69%|[36m██████▉   [0m| 18/26 [00:20<00:08,  1.09s/it]Epoch: 4/10. Loss: 0.8428:  69%|[36m██████▉   [0m| 18/26 [00:21<00:08,  1.09s/it]Epoch: 4/10. Loss: 0.8428:  73%|[36m███████▎  [0m| 19/26 [00:22<00:09,  1.35s/it]Epoch: 4/10. Loss: 0.8840:  73%|[36m███████▎  [0m| 19/26 [00:23<00:09,  1.35s/it]Epoch: 4/10. Loss: 0.8840:  77%|[36m███████▋  [0m| 20/26 [00:23<00:07,  1.27s/it]Epoch: 4/10. Loss: 0.6599:  77%|[36m███████▋  [0m| 20/26 [00:23<00:07,  1.27s/it]Epoch: 4/10. Loss: 0.6599:  81%|[36m████████  [0m| 21/26 [00:24<00:05,  1.17s/it]Epoch: 4/10. Loss: 0.8734:  81%|[36m████████  [0m| 21/26 [00:24<00:05,  1.17s/it]Epoch: 4/10. Loss: 0.8734:  85%|[36m████████▍ [0m| 22/26 [00:24<00:04,  1.09s/it]Epoch: 4/10. Loss: 0.8647:  85%|[36m████████▍ [0m| 22/26 [00:25<00:04,  1.09s/it]Epoch: 4/10. Loss: 0.8647:  88%|[36m████████▊ [0m| 23/26 [00:25<00:03,  1.02s/it]Epoch: 4/10. Loss: 0.7726:  88%|[36m████████▊ [0m| 23/26 [00:26<00:03,  1.02s/it]Epoch: 4/10. Loss: 0.7726:  92%|[36m█████████▏[0m| 24/26 [00:26<00:01,  1.07it/s]Epoch: 4/10. Loss: 0.8317:  92%|[36m█████████▏[0m| 24/26 [00:27<00:01,  1.07it/s]Epoch: 4/10. Loss: 0.8317:  96%|[36m█████████▌[0m| 25/26 [00:27<00:00,  1.09it/s]Epoch: 4/10. Loss: 0.8053:  96%|[36m█████████▌[0m| 25/26 [00:28<00:00,  1.09it/s]Epoch: 4/10. Loss: 0.8053: 100%|[36m██████████[0m| 26/26 [00:28<00:00,  1.18it/s]Epoch: 4/10. Loss: 0.8053: 100%|[36m██████████[0m| 26/26 [00:28<00:00,  1.08s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:05,  1.15it/s] 29%|[33m██▊       [0m| 2/7 [00:01<00:04,  1.01it/s] 43%|[33m████▎     [0m| 3/7 [00:02<00:03,  1.12it/s] 57%|[33m█████▋    [0m| 4/7 [00:04<00:03,  1.05s/it] 71%|[33m███████▏  [0m| 5/7 [00:04<00:01,  1.20it/s] 86%|[33m████████▌ [0m| 6/7 [00:05<00:00,  1.17it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.50it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.24it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 5/10. Loss: 0.8182:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 5/10. Loss: 0.8182:   4%|[36m▍         [0m| 1/26 [00:00<00:22,  1.11it/s]Epoch: 5/10. Loss: 0.8699:   4%|[36m▍         [0m| 1/26 [00:01<00:22,  1.11it/s]Epoch: 5/10. Loss: 0.8699:   8%|[36m▊         [0m| 2/26 [00:01<00:21,  1.13it/s]Epoch: 5/10. Loss: 0.8716:   8%|[36m▊         [0m| 2/26 [00:03<00:21,  1.13it/s]Epoch: 5/10. Loss: 0.8716:  12%|[36m█▏        [0m| 3/26 [00:03<00:30,  1.34s/it]Epoch: 5/10. Loss: 0.6867:  12%|[36m█▏        [0m| 3/26 [00:04<00:30,  1.34s/it]Epoch: 5/10. Loss: 0.6867:  15%|[36m█▌        [0m| 4/26 [00:04<00:25,  1.14s/it]Epoch: 5/10. Loss: 0.7488:  15%|[36m█▌        [0m| 4/26 [00:05<00:25,  1.14s/it]Epoch: 5/10. Loss: 0.7488:  19%|[36m█▉        [0m| 5/26 [00:05<00:21,  1.03s/it]Epoch: 5/10. Loss: 0.7562:  19%|[36m█▉        [0m| 5/26 [00:06<00:21,  1.03s/it]Epoch: 5/10. Loss: 0.7562:  23%|[36m██▎       [0m| 6/26 [00:06<00:20,  1.01s/it]Epoch: 5/10. Loss: 0.8550:  23%|[36m██▎       [0m| 6/26 [00:07<00:20,  1.01s/it]Epoch: 5/10. Loss: 0.8550:  27%|[36m██▋       [0m| 7/26 [00:07<00:20,  1.09s/it]Epoch: 5/10. Loss: 0.6367:  27%|[36m██▋       [0m| 7/26 [00:08<00:20,  1.09s/it]Epoch: 5/10. Loss: 0.6367:  31%|[36m███       [0m| 8/26 [00:08<00:17,  1.04it/s]Epoch: 5/10. Loss: 0.8471:  31%|[36m███       [0m| 8/26 [00:09<00:17,  1.04it/s]Epoch: 5/10. Loss: 0.8471:  35%|[36m███▍      [0m| 9/26 [00:09<00:16,  1.01it/s]Epoch: 5/10. Loss: 0.7541:  35%|[36m███▍      [0m| 9/26 [00:11<00:16,  1.01it/s]Epoch: 5/10. Loss: 0.7541:  38%|[36m███▊      [0m| 10/26 [00:11<00:21,  1.37s/it]Epoch: 5/10. Loss: 0.8769:  38%|[36m███▊      [0m| 10/26 [00:12<00:21,  1.37s/it]Epoch: 5/10. Loss: 0.8769:  42%|[36m████▏     [0m| 11/26 [00:12<00:18,  1.25s/it]Epoch: 5/10. Loss: 0.8260:  42%|[36m████▏     [0m| 11/26 [00:13<00:18,  1.25s/it]Epoch: 5/10. Loss: 0.8260:  46%|[36m████▌     [0m| 12/26 [00:13<00:16,  1.16s/it]Epoch: 5/10. Loss: 0.8144:  46%|[36m████▌     [0m| 12/26 [00:14<00:16,  1.16s/it]Epoch: 5/10. Loss: 0.8144:  50%|[36m█████     [0m| 13/26 [00:14<00:13,  1.05s/it]Epoch: 5/10. Loss: 0.8330:  50%|[36m█████     [0m| 13/26 [00:15<00:13,  1.05s/it]Epoch: 5/10. Loss: 0.8330:  54%|[36m█████▍    [0m| 14/26 [00:15<00:14,  1.19s/it]Epoch: 5/10. Loss: 0.8368:  54%|[36m█████▍    [0m| 14/26 [00:16<00:14,  1.19s/it]Epoch: 5/10. Loss: 0.8368:  58%|[36m█████▊    [0m| 15/26 [00:16<00:12,  1.18s/it]Epoch: 5/10. Loss: 0.7959:  58%|[36m█████▊    [0m| 15/26 [00:17<00:12,  1.18s/it]Epoch: 5/10. Loss: 0.7959:  62%|[36m██████▏   [0m| 16/26 [00:17<00:11,  1.11s/it]Epoch: 5/10. Loss: 0.8389:  62%|[36m██████▏   [0m| 16/26 [00:19<00:11,  1.11s/it]Epoch: 5/10. Loss: 0.8389:  65%|[36m██████▌   [0m| 17/26 [00:19<00:10,  1.15s/it]Epoch: 5/10. Loss: 0.8453:  65%|[36m██████▌   [0m| 17/26 [00:19<00:10,  1.15s/it]Epoch: 5/10. Loss: 0.8453:  69%|[36m██████▉   [0m| 18/26 [00:19<00:08,  1.07s/it]Epoch: 5/10. Loss: 0.7842:  69%|[36m██████▉   [0m| 18/26 [00:20<00:08,  1.07s/it]Epoch: 5/10. Loss: 0.7842:  73%|[36m███████▎  [0m| 19/26 [00:20<00:07,  1.05s/it]Epoch: 5/10. Loss: 0.8388:  73%|[36m███████▎  [0m| 19/26 [00:22<00:07,  1.05s/it]Epoch: 5/10. Loss: 0.8388:  77%|[36m███████▋  [0m| 20/26 [00:22<00:06,  1.06s/it]Epoch: 5/10. Loss: 0.8855:  77%|[36m███████▋  [0m| 20/26 [00:22<00:06,  1.06s/it]Epoch: 5/10. Loss: 0.8855:  81%|[36m████████  [0m| 21/26 [00:22<00:04,  1.00it/s]Epoch: 5/10. Loss: 0.7812:  81%|[36m████████  [0m| 21/26 [00:23<00:04,  1.00it/s]Epoch: 5/10. Loss: 0.7812:  85%|[36m████████▍ [0m| 22/26 [00:23<00:03,  1.05it/s]Epoch: 5/10. Loss: 0.7548:  85%|[36m████████▍ [0m| 22/26 [00:24<00:03,  1.05it/s]Epoch: 5/10. Loss: 0.7548:  88%|[36m████████▊ [0m| 23/26 [00:24<00:02,  1.04it/s]Epoch: 5/10. Loss: 0.8987:  88%|[36m████████▊ [0m| 23/26 [00:25<00:02,  1.04it/s]Epoch: 5/10. Loss: 0.8987:  92%|[36m█████████▏[0m| 24/26 [00:25<00:02,  1.01s/it]Epoch: 5/10. Loss: 0.7695:  92%|[36m█████████▏[0m| 24/26 [00:26<00:02,  1.01s/it]Epoch: 5/10. Loss: 0.7695:  96%|[36m█████████▌[0m| 25/26 [00:26<00:01,  1.00s/it]Epoch: 5/10. Loss: 0.8118:  96%|[36m█████████▌[0m| 25/26 [00:27<00:01,  1.00s/it]Epoch: 5/10. Loss: 0.8118: 100%|[36m██████████[0m| 26/26 [00:27<00:00,  1.11it/s]Epoch: 5/10. Loss: 0.8118: 100%|[36m██████████[0m| 26/26 [00:27<00:00,  1.06s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:05,  1.05it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:07,  1.55s/it] 43%|[33m████▎     [0m| 3/7 [00:03<00:04,  1.19s/it] 57%|[33m█████▋    [0m| 4/7 [00:04<00:03,  1.23s/it] 71%|[33m███████▏  [0m| 5/7 [00:05<00:01,  1.05it/s] 86%|[33m████████▌ [0m| 6/7 [00:06<00:00,  1.08it/s]100%|[33m██████████[0m| 7/7 [00:06<00:00,  1.41it/s]100%|[33m██████████[0m| 7/7 [00:06<00:00,  1.07it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 6/10. Loss: 0.8519:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 6/10. Loss: 0.8519:   4%|[36m▍         [0m| 1/26 [00:00<00:20,  1.22it/s]Epoch: 6/10. Loss: 0.7545:   4%|[36m▍         [0m| 1/26 [00:01<00:20,  1.22it/s]Epoch: 6/10. Loss: 0.7545:   8%|[36m▊         [0m| 2/26 [00:01<00:21,  1.10it/s]Epoch: 6/10. Loss: 0.8293:   8%|[36m▊         [0m| 2/26 [00:02<00:21,  1.10it/s]Epoch: 6/10. Loss: 0.8293:  12%|[36m█▏        [0m| 3/26 [00:02<00:22,  1.00it/s]Epoch: 6/10. Loss: 0.8811:  12%|[36m█▏        [0m| 3/26 [00:03<00:22,  1.00it/s]Epoch: 6/10. Loss: 0.8811:  15%|[36m█▌        [0m| 4/26 [00:03<00:20,  1.05it/s]Epoch: 6/10. Loss: 0.8141:  15%|[36m█▌        [0m| 4/26 [00:06<00:20,  1.05it/s]Epoch: 6/10. Loss: 0.8141:  19%|[36m█▉        [0m| 5/26 [00:06<00:33,  1.61s/it]Epoch: 6/10. Loss: 0.7398:  19%|[36m█▉        [0m| 5/26 [00:07<00:33,  1.61s/it]Epoch: 6/10. Loss: 0.7398:  23%|[36m██▎       [0m| 6/26 [00:07<00:27,  1.36s/it]Epoch: 6/10. Loss: 0.8374:  23%|[36m██▎       [0m| 6/26 [00:08<00:27,  1.36s/it]Epoch: 6/10. Loss: 0.8374:  27%|[36m██▋       [0m| 7/26 [00:08<00:23,  1.24s/it]Epoch: 6/10. Loss: 0.7524:  27%|[36m██▋       [0m| 7/26 [00:09<00:23,  1.24s/it]Epoch: 6/10. Loss: 0.7524:  31%|[36m███       [0m| 8/26 [00:09<00:20,  1.12s/it]Epoch: 6/10. Loss: 0.7883:  31%|[36m███       [0m| 8/26 [00:10<00:20,  1.12s/it]Epoch: 6/10. Loss: 0.7883:  35%|[36m███▍      [0m| 9/26 [00:10<00:18,  1.08s/it]Epoch: 6/10. Loss: 0.7568:  35%|[36m███▍      [0m| 9/26 [00:11<00:18,  1.08s/it]Epoch: 6/10. Loss: 0.7568:  38%|[36m███▊      [0m| 10/26 [00:11<00:16,  1.02s/it]Epoch: 6/10. Loss: 0.7293:  38%|[36m███▊      [0m| 10/26 [00:12<00:16,  1.02s/it]Epoch: 6/10. Loss: 0.7293:  42%|[36m████▏     [0m| 11/26 [00:12<00:15,  1.02s/it]Epoch: 6/10. Loss: 0.7759:  42%|[36m████▏     [0m| 11/26 [00:13<00:15,  1.02s/it]Epoch: 6/10. Loss: 0.7759:  46%|[36m████▌     [0m| 12/26 [00:13<00:13,  1.01it/s]Epoch: 6/10. Loss: 0.7853:  46%|[36m████▌     [0m| 12/26 [00:15<00:13,  1.01it/s]Epoch: 6/10. Loss: 0.7853:  50%|[36m█████     [0m| 13/26 [00:15<00:19,  1.49s/it]Epoch: 6/10. Loss: 0.7461:  50%|[36m█████     [0m| 13/26 [00:17<00:19,  1.49s/it]Epoch: 6/10. Loss: 0.7461:  54%|[36m█████▍    [0m| 14/26 [00:17<00:18,  1.55s/it]Epoch: 6/10. Loss: 0.7018:  54%|[36m█████▍    [0m| 14/26 [00:18<00:18,  1.55s/it]Epoch: 6/10. Loss: 0.7018:  58%|[36m█████▊    [0m| 15/26 [00:18<00:15,  1.37s/it]Epoch: 6/10. Loss: 0.8275:  58%|[36m█████▊    [0m| 15/26 [00:19<00:15,  1.37s/it]Epoch: 6/10. Loss: 0.8275:  62%|[36m██████▏   [0m| 16/26 [00:19<00:12,  1.22s/it]Epoch: 6/10. Loss: 0.7364:  62%|[36m██████▏   [0m| 16/26 [00:20<00:12,  1.22s/it]Epoch: 6/10. Loss: 0.7364:  65%|[36m██████▌   [0m| 17/26 [00:20<00:10,  1.13s/it]Epoch: 6/10. Loss: 0.7777:  65%|[36m██████▌   [0m| 17/26 [00:21<00:10,  1.13s/it]Epoch: 6/10. Loss: 0.7777:  69%|[36m██████▉   [0m| 18/26 [00:21<00:08,  1.10s/it]Epoch: 6/10. Loss: 0.7242:  69%|[36m██████▉   [0m| 18/26 [00:22<00:08,  1.10s/it]Epoch: 6/10. Loss: 0.7242:  73%|[36m███████▎  [0m| 19/26 [00:22<00:07,  1.09s/it]Epoch: 6/10. Loss: 0.8157:  73%|[36m███████▎  [0m| 19/26 [00:23<00:07,  1.09s/it]Epoch: 6/10. Loss: 0.8157:  77%|[36m███████▋  [0m| 20/26 [00:23<00:05,  1.01it/s]Epoch: 6/10. Loss: 0.7797:  77%|[36m███████▋  [0m| 20/26 [00:24<00:05,  1.01it/s]Epoch: 6/10. Loss: 0.7797:  81%|[36m████████  [0m| 21/26 [00:24<00:05,  1.00s/it]Epoch: 6/10. Loss: 0.7250:  81%|[36m████████  [0m| 21/26 [00:25<00:05,  1.00s/it]Epoch: 6/10. Loss: 0.7250:  85%|[36m████████▍ [0m| 22/26 [00:25<00:04,  1.00s/it]Epoch: 6/10. Loss: 0.8030:  85%|[36m████████▍ [0m| 22/26 [00:25<00:04,  1.00s/it]Epoch: 6/10. Loss: 0.8030:  88%|[36m████████▊ [0m| 23/26 [00:25<00:02,  1.07it/s]Epoch: 6/10. Loss: 0.7859:  88%|[36m████████▊ [0m| 23/26 [00:26<00:02,  1.07it/s]Epoch: 6/10. Loss: 0.7859:  92%|[36m█████████▏[0m| 24/26 [00:26<00:01,  1.10it/s]Epoch: 6/10. Loss: 0.7348:  92%|[36m█████████▏[0m| 24/26 [00:27<00:01,  1.10it/s]Epoch: 6/10. Loss: 0.7348:  96%|[36m█████████▌[0m| 25/26 [00:27<00:00,  1.15it/s]Epoch: 6/10. Loss: 0.8926:  96%|[36m█████████▌[0m| 25/26 [00:27<00:00,  1.15it/s]Epoch: 6/10. Loss: 0.8926: 100%|[36m██████████[0m| 26/26 [00:27<00:00,  1.33it/s]Epoch: 6/10. Loss: 0.8926: 100%|[36m██████████[0m| 26/26 [00:27<00:00,  1.08s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:05,  1.12it/s] 29%|[33m██▊       [0m| 2/7 [00:01<00:05,  1.01s/it] 43%|[33m████▎     [0m| 3/7 [00:02<00:03,  1.09it/s] 57%|[33m█████▋    [0m| 4/7 [00:04<00:03,  1.07s/it] 71%|[33m███████▏  [0m| 5/7 [00:04<00:01,  1.16it/s] 86%|[33m████████▌ [0m| 6/7 [00:07<00:01,  1.56s/it]100%|[33m██████████[0m| 7/7 [00:10<00:00,  1.89s/it]100%|[33m██████████[0m| 7/7 [00:10<00:00,  1.44s/it]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 7/10. Loss: 0.6932:   0%|[36m          [0m| 0/26 [00:03<?, ?it/s]Epoch: 7/10. Loss: 0.6932:   4%|[36m▍         [0m| 1/26 [00:03<01:38,  3.94s/it]Epoch: 7/10. Loss: 0.6952:   4%|[36m▍         [0m| 1/26 [00:04<01:38,  3.94s/it]Epoch: 7/10. Loss: 0.6952:   8%|[36m▊         [0m| 2/26 [00:04<00:53,  2.23s/it]Epoch: 7/10. Loss: 0.8348:   8%|[36m▊         [0m| 2/26 [00:06<00:53,  2.23s/it]Epoch: 7/10. Loss: 0.8348:  12%|[36m█▏        [0m| 3/26 [00:06<00:39,  1.73s/it]Epoch: 7/10. Loss: 0.7488:  12%|[36m█▏        [0m| 3/26 [00:08<00:39,  1.73s/it]Epoch: 7/10. Loss: 0.7488:  15%|[36m█▌        [0m| 4/26 [00:08<00:43,  1.97s/it]Epoch: 7/10. Loss: 0.6473:  15%|[36m█▌        [0m| 4/26 [00:10<00:43,  1.97s/it]Epoch: 7/10. Loss: 0.6473:  19%|[36m█▉        [0m| 5/26 [00:10<00:44,  2.12s/it]Epoch: 7/10. Loss: 0.7391:  19%|[36m█▉        [0m| 5/26 [00:11<00:44,  2.12s/it]Epoch: 7/10. Loss: 0.7391:  23%|[36m██▎       [0m| 6/26 [00:11<00:33,  1.66s/it]Epoch: 7/10. Loss: 0.7442:  23%|[36m██▎       [0m| 6/26 [00:12<00:33,  1.66s/it]Epoch: 7/10. Loss: 0.7442:  27%|[36m██▋       [0m| 7/26 [00:12<00:27,  1.46s/it]Epoch: 7/10. Loss: 0.7454:  27%|[36m██▋       [0m| 7/26 [00:13<00:27,  1.46s/it]Epoch: 7/10. Loss: 0.7454:  31%|[36m███       [0m| 8/26 [00:13<00:23,  1.31s/it]Epoch: 7/10. Loss: 0.7945:  31%|[36m███       [0m| 8/26 [00:14<00:23,  1.31s/it]Epoch: 7/10. Loss: 0.7945:  35%|[36m███▍      [0m| 9/26 [00:14<00:20,  1.19s/it]Epoch: 7/10. Loss: 0.6758:  35%|[36m███▍      [0m| 9/26 [00:15<00:20,  1.19s/it]Epoch: 7/10. Loss: 0.6758:  38%|[36m███▊      [0m| 10/26 [00:15<00:17,  1.09s/it]Epoch: 7/10. Loss: 0.8647:  38%|[36m███▊      [0m| 10/26 [00:16<00:17,  1.09s/it]Epoch: 7/10. Loss: 0.8647:  42%|[36m████▏     [0m| 11/26 [00:16<00:15,  1.04s/it]Epoch: 7/10. Loss: 0.8158:  42%|[36m████▏     [0m| 11/26 [00:17<00:15,  1.04s/it]Epoch: 7/10. Loss: 0.8158:  46%|[36m████▌     [0m| 12/26 [00:17<00:13,  1.01it/s]Epoch: 7/10. Loss: 0.6455:  46%|[36m████▌     [0m| 12/26 [00:18<00:13,  1.01it/s]Epoch: 7/10. Loss: 0.6455:  50%|[36m█████     [0m| 13/26 [00:18<00:12,  1.08it/s]Epoch: 7/10. Loss: 0.7488:  50%|[36m█████     [0m| 13/26 [00:19<00:12,  1.08it/s]Epoch: 7/10. Loss: 0.7488:  54%|[36m█████▍    [0m| 14/26 [00:19<00:12,  1.05s/it]Epoch: 7/10. Loss: 0.7955:  54%|[36m█████▍    [0m| 14/26 [00:20<00:12,  1.05s/it]Epoch: 7/10. Loss: 0.7955:  58%|[36m█████▊    [0m| 15/26 [00:20<00:10,  1.01it/s]Epoch: 7/10. Loss: 0.7355:  58%|[36m█████▊    [0m| 15/26 [00:21<00:10,  1.01it/s]Epoch: 7/10. Loss: 0.7355:  62%|[36m██████▏   [0m| 16/26 [00:21<00:10,  1.05s/it]Epoch: 7/10. Loss: 0.7447:  62%|[36m██████▏   [0m| 16/26 [00:22<00:10,  1.05s/it]Epoch: 7/10. Loss: 0.7447:  65%|[36m██████▌   [0m| 17/26 [00:22<00:09,  1.01s/it]Epoch: 7/10. Loss: 0.6745:  65%|[36m██████▌   [0m| 17/26 [00:23<00:09,  1.01s/it]Epoch: 7/10. Loss: 0.6745:  69%|[36m██████▉   [0m| 18/26 [00:23<00:09,  1.17s/it]Epoch: 7/10. Loss: 0.7166:  69%|[36m██████▉   [0m| 18/26 [00:24<00:09,  1.17s/it]Epoch: 7/10. Loss: 0.7166:  73%|[36m███████▎  [0m| 19/26 [00:24<00:07,  1.12s/it]Epoch: 7/10. Loss: 0.7518:  73%|[36m███████▎  [0m| 19/26 [00:25<00:07,  1.12s/it]Epoch: 7/10. Loss: 0.7518:  77%|[36m███████▋  [0m| 20/26 [00:25<00:06,  1.08s/it]Epoch: 7/10. Loss: 0.7038:  77%|[36m███████▋  [0m| 20/26 [00:26<00:06,  1.08s/it]Epoch: 7/10. Loss: 0.7038:  81%|[36m████████  [0m| 21/26 [00:26<00:05,  1.02s/it]Epoch: 7/10. Loss: 0.7458:  81%|[36m████████  [0m| 21/26 [00:27<00:05,  1.02s/it]Epoch: 7/10. Loss: 0.7458:  85%|[36m████████▍ [0m| 22/26 [00:28<00:04,  1.10s/it]Epoch: 7/10. Loss: 0.7353:  85%|[36m████████▍ [0m| 22/26 [00:29<00:04,  1.10s/it]Epoch: 7/10. Loss: 0.7353:  88%|[36m████████▊ [0m| 23/26 [00:29<00:03,  1.23s/it]Epoch: 7/10. Loss: 0.7266:  88%|[36m████████▊ [0m| 23/26 [00:30<00:03,  1.23s/it]Epoch: 7/10. Loss: 0.7266:  92%|[36m█████████▏[0m| 24/26 [00:30<00:02,  1.10s/it]Epoch: 7/10. Loss: 0.6795:  92%|[36m█████████▏[0m| 24/26 [00:31<00:02,  1.10s/it]Epoch: 7/10. Loss: 0.6795:  96%|[36m█████████▌[0m| 25/26 [00:31<00:01,  1.10s/it]Epoch: 7/10. Loss: 0.7937:  96%|[36m█████████▌[0m| 25/26 [00:31<00:01,  1.10s/it]Epoch: 7/10. Loss: 0.7937: 100%|[36m██████████[0m| 26/26 [00:31<00:00,  1.07it/s]Epoch: 7/10. Loss: 0.7937: 100%|[36m██████████[0m| 26/26 [00:31<00:00,  1.23s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:05,  1.00it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:05,  1.04s/it] 43%|[33m████▎     [0m| 3/7 [00:02<00:03,  1.13it/s] 57%|[33m█████▋    [0m| 4/7 [00:03<00:03,  1.01s/it] 71%|[33m███████▏  [0m| 5/7 [00:04<00:01,  1.29it/s] 86%|[33m████████▌ [0m| 6/7 [00:05<00:00,  1.27it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.65it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.30it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 8/10. Loss: 0.8916:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 8/10. Loss: 0.8916:   4%|[36m▍         [0m| 1/26 [00:00<00:21,  1.15it/s]Epoch: 8/10. Loss: 0.8001:   4%|[36m▍         [0m| 1/26 [00:01<00:21,  1.15it/s]Epoch: 8/10. Loss: 0.8001:   8%|[36m▊         [0m| 2/26 [00:01<00:21,  1.13it/s]Epoch: 8/10. Loss: 0.7081:   8%|[36m▊         [0m| 2/26 [00:02<00:21,  1.13it/s]Epoch: 8/10. Loss: 0.7081:  12%|[36m█▏        [0m| 3/26 [00:02<00:20,  1.13it/s]Epoch: 8/10. Loss: 0.6832:  12%|[36m█▏        [0m| 3/26 [00:03<00:20,  1.13it/s]Epoch: 8/10. Loss: 0.6832:  15%|[36m█▌        [0m| 4/26 [00:03<00:20,  1.07it/s]Epoch: 8/10. Loss: 0.6969:  15%|[36m█▌        [0m| 4/26 [00:04<00:20,  1.07it/s]Epoch: 8/10. Loss: 0.6969:  19%|[36m█▉        [0m| 5/26 [00:04<00:22,  1.07s/it]Epoch: 8/10. Loss: 0.7766:  19%|[36m█▉        [0m| 5/26 [00:06<00:22,  1.07s/it]Epoch: 8/10. Loss: 0.7766:  23%|[36m██▎       [0m| 6/26 [00:06<00:21,  1.07s/it]Epoch: 8/10. Loss: 0.6931:  23%|[36m██▎       [0m| 6/26 [00:06<00:21,  1.07s/it]Epoch: 8/10. Loss: 0.6931:  27%|[36m██▋       [0m| 7/26 [00:06<00:19,  1.00s/it]Epoch: 8/10. Loss: 0.7534:  27%|[36m██▋       [0m| 7/26 [00:07<00:19,  1.00s/it]Epoch: 8/10. Loss: 0.7534:  31%|[36m███       [0m| 8/26 [00:07<00:17,  1.01it/s]Epoch: 8/10. Loss: 0.6461:  31%|[36m███       [0m| 8/26 [00:08<00:17,  1.01it/s]Epoch: 8/10. Loss: 0.6461:  35%|[36m███▍      [0m| 9/26 [00:08<00:17,  1.02s/it]Epoch: 8/10. Loss: 0.7584:  35%|[36m███▍      [0m| 9/26 [00:09<00:17,  1.02s/it]Epoch: 8/10. Loss: 0.7584:  38%|[36m███▊      [0m| 10/26 [00:09<00:15,  1.01it/s]Epoch: 8/10. Loss: 0.7043:  38%|[36m███▊      [0m| 10/26 [00:10<00:15,  1.01it/s]Epoch: 8/10. Loss: 0.7043:  42%|[36m████▏     [0m| 11/26 [00:10<00:14,  1.00it/s]Epoch: 8/10. Loss: 0.6690:  42%|[36m████▏     [0m| 11/26 [00:11<00:14,  1.00it/s]Epoch: 8/10. Loss: 0.6690:  46%|[36m████▌     [0m| 12/26 [00:11<00:13,  1.03it/s]Epoch: 8/10. Loss: 0.7372:  46%|[36m████▌     [0m| 12/26 [00:12<00:13,  1.03it/s]Epoch: 8/10. Loss: 0.7372:  50%|[36m█████     [0m| 13/26 [00:12<00:12,  1.03it/s]Epoch: 8/10. Loss: 0.8237:  50%|[36m█████     [0m| 13/26 [00:14<00:12,  1.03it/s]Epoch: 8/10. Loss: 0.8237:  54%|[36m█████▍    [0m| 14/26 [00:14<00:14,  1.17s/it]Epoch: 8/10. Loss: 0.8105:  54%|[36m█████▍    [0m| 14/26 [00:15<00:14,  1.17s/it]Epoch: 8/10. Loss: 0.8105:  58%|[36m█████▊    [0m| 15/26 [00:15<00:12,  1.10s/it]Epoch: 8/10. Loss: 0.7206:  58%|[36m█████▊    [0m| 15/26 [00:16<00:12,  1.10s/it]Epoch: 8/10. Loss: 0.7206:  62%|[36m██████▏   [0m| 16/26 [00:16<00:12,  1.22s/it]Epoch: 8/10. Loss: 0.6517:  62%|[36m██████▏   [0m| 16/26 [00:17<00:12,  1.22s/it]Epoch: 8/10. Loss: 0.6517:  65%|[36m██████▌   [0m| 17/26 [00:17<00:10,  1.12s/it]Epoch: 8/10. Loss: 0.5866:  65%|[36m██████▌   [0m| 17/26 [00:19<00:10,  1.12s/it]Epoch: 8/10. Loss: 0.5866:  69%|[36m██████▉   [0m| 18/26 [00:19<00:11,  1.44s/it]Epoch: 8/10. Loss: 0.7517:  69%|[36m██████▉   [0m| 18/26 [00:20<00:11,  1.44s/it]Epoch: 8/10. Loss: 0.7517:  73%|[36m███████▎  [0m| 19/26 [00:20<00:09,  1.30s/it]Epoch: 8/10. Loss: 0.7571:  73%|[36m███████▎  [0m| 19/26 [00:21<00:09,  1.30s/it]Epoch: 8/10. Loss: 0.7571:  77%|[36m███████▋  [0m| 20/26 [00:21<00:07,  1.17s/it]Epoch: 8/10. Loss: 0.6385:  77%|[36m███████▋  [0m| 20/26 [00:22<00:07,  1.17s/it]Epoch: 8/10. Loss: 0.6385:  81%|[36m████████  [0m| 21/26 [00:22<00:05,  1.07s/it]Epoch: 8/10. Loss: 0.6539:  81%|[36m████████  [0m| 21/26 [00:23<00:05,  1.07s/it]Epoch: 8/10. Loss: 0.6539:  85%|[36m████████▍ [0m| 22/26 [00:23<00:04,  1.03s/it]Epoch: 8/10. Loss: 0.6253:  85%|[36m████████▍ [0m| 22/26 [00:25<00:04,  1.03s/it]Epoch: 8/10. Loss: 0.6253:  88%|[36m████████▊ [0m| 23/26 [00:25<00:04,  1.41s/it]Epoch: 8/10. Loss: 0.5750:  88%|[36m████████▊ [0m| 23/26 [00:26<00:04,  1.41s/it]Epoch: 8/10. Loss: 0.5750:  92%|[36m█████████▏[0m| 24/26 [00:26<00:02,  1.26s/it]Epoch: 8/10. Loss: 0.6870:  92%|[36m█████████▏[0m| 24/26 [00:27<00:02,  1.26s/it]Epoch: 8/10. Loss: 0.6870:  96%|[36m█████████▌[0m| 25/26 [00:27<00:01,  1.16s/it]Epoch: 8/10. Loss: 0.9242:  96%|[36m█████████▌[0m| 25/26 [00:28<00:01,  1.16s/it]Epoch: 8/10. Loss: 0.9242: 100%|[36m██████████[0m| 26/26 [00:28<00:00,  1.01s/it]Epoch: 8/10. Loss: 0.9242: 100%|[36m██████████[0m| 26/26 [00:28<00:00,  1.09s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:05,  1.14it/s] 29%|[33m██▊       [0m| 2/7 [00:01<00:04,  1.02it/s] 43%|[33m████▎     [0m| 3/7 [00:02<00:03,  1.17it/s] 57%|[33m█████▋    [0m| 4/7 [00:04<00:03,  1.17s/it] 71%|[33m███████▏  [0m| 5/7 [00:04<00:01,  1.12it/s] 86%|[33m████████▌ [0m| 6/7 [00:05<00:00,  1.15it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.50it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.22it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 9/10. Loss: 0.6936:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 9/10. Loss: 0.6936:   4%|[36m▍         [0m| 1/26 [00:00<00:19,  1.31it/s]Epoch: 9/10. Loss: 0.7599:   4%|[36m▍         [0m| 1/26 [00:01<00:19,  1.31it/s]Epoch: 9/10. Loss: 0.7599:   8%|[36m▊         [0m| 2/26 [00:01<00:20,  1.19it/s]Epoch: 9/10. Loss: 0.7167:   8%|[36m▊         [0m| 2/26 [00:02<00:20,  1.19it/s]Epoch: 9/10. Loss: 0.7167:  12%|[36m█▏        [0m| 3/26 [00:02<00:23,  1.01s/it]Epoch: 9/10. Loss: 0.7823:  12%|[36m█▏        [0m| 3/26 [00:03<00:23,  1.01s/it]Epoch: 9/10. Loss: 0.7823:  15%|[36m█▌        [0m| 4/26 [00:03<00:21,  1.00it/s]Epoch: 9/10. Loss: 0.7891:  15%|[36m█▌        [0m| 4/26 [00:04<00:21,  1.00it/s]Epoch: 9/10. Loss: 0.7891:  19%|[36m█▉        [0m| 5/26 [00:04<00:19,  1.08it/s]Epoch: 9/10. Loss: 0.6834:  19%|[36m█▉        [0m| 5/26 [00:05<00:19,  1.08it/s]Epoch: 9/10. Loss: 0.6834:  23%|[36m██▎       [0m| 6/26 [00:05<00:18,  1.10it/s]Epoch: 9/10. Loss: 0.6928:  23%|[36m██▎       [0m| 6/26 [00:06<00:18,  1.10it/s]Epoch: 9/10. Loss: 0.6928:  27%|[36m██▋       [0m| 7/26 [00:06<00:17,  1.09it/s]Epoch: 9/10. Loss: 0.6278:  27%|[36m██▋       [0m| 7/26 [00:07<00:17,  1.09it/s]Epoch: 9/10. Loss: 0.6278:  31%|[36m███       [0m| 8/26 [00:07<00:16,  1.11it/s]Epoch: 9/10. Loss: 0.8346:  31%|[36m███       [0m| 8/26 [00:08<00:16,  1.11it/s]Epoch: 9/10. Loss: 0.8346:  35%|[36m███▍      [0m| 9/26 [00:08<00:15,  1.12it/s]Epoch: 9/10. Loss: 0.7415:  35%|[36m███▍      [0m| 9/26 [00:09<00:15,  1.12it/s]Epoch: 9/10. Loss: 0.7415:  38%|[36m███▊      [0m| 10/26 [00:09<00:14,  1.12it/s]Epoch: 9/10. Loss: 0.6610:  38%|[36m███▊      [0m| 10/26 [00:09<00:14,  1.12it/s]Epoch: 9/10. Loss: 0.6610:  42%|[36m████▏     [0m| 11/26 [00:09<00:13,  1.12it/s]Epoch: 9/10. Loss: 0.5941:  42%|[36m████▏     [0m| 11/26 [00:10<00:13,  1.12it/s]Epoch: 9/10. Loss: 0.5941:  46%|[36m████▌     [0m| 12/26 [00:10<00:12,  1.13it/s]Epoch: 9/10. Loss: 0.7187:  46%|[36m████▌     [0m| 12/26 [00:11<00:12,  1.13it/s]Epoch: 9/10. Loss: 0.7187:  50%|[36m█████     [0m| 13/26 [00:11<00:11,  1.10it/s]Epoch: 9/10. Loss: 0.7414:  50%|[36m█████     [0m| 13/26 [00:13<00:11,  1.10it/s]Epoch: 9/10. Loss: 0.7414:  54%|[36m█████▍    [0m| 14/26 [00:13<00:13,  1.11s/it]Epoch: 9/10. Loss: 0.7388:  54%|[36m█████▍    [0m| 14/26 [00:14<00:13,  1.11s/it]Epoch: 9/10. Loss: 0.7388:  58%|[36m█████▊    [0m| 15/26 [00:14<00:12,  1.12s/it]Epoch: 9/10. Loss: 0.8033:  58%|[36m█████▊    [0m| 15/26 [00:15<00:12,  1.12s/it]Epoch: 9/10. Loss: 0.8033:  62%|[36m██████▏   [0m| 16/26 [00:15<00:10,  1.09s/it]Epoch: 9/10. Loss: 0.7415:  62%|[36m██████▏   [0m| 16/26 [00:16<00:10,  1.09s/it]Epoch: 9/10. Loss: 0.7415:  65%|[36m██████▌   [0m| 17/26 [00:16<00:09,  1.04s/it]Epoch: 9/10. Loss: 0.6534:  65%|[36m██████▌   [0m| 17/26 [00:17<00:09,  1.04s/it]Epoch: 9/10. Loss: 0.6534:  69%|[36m██████▉   [0m| 18/26 [00:17<00:08,  1.02s/it]Epoch: 9/10. Loss: 0.7368:  69%|[36m██████▉   [0m| 18/26 [00:18<00:08,  1.02s/it]Epoch: 9/10. Loss: 0.7368:  73%|[36m███████▎  [0m| 19/26 [00:18<00:07,  1.01s/it]Epoch: 9/10. Loss: 0.7230:  73%|[36m███████▎  [0m| 19/26 [00:19<00:07,  1.01s/it]Epoch: 9/10. Loss: 0.7230:  77%|[36m███████▋  [0m| 20/26 [00:19<00:06,  1.00s/it]Epoch: 9/10. Loss: 0.7719:  77%|[36m███████▋  [0m| 20/26 [00:20<00:06,  1.00s/it]Epoch: 9/10. Loss: 0.7719:  81%|[36m████████  [0m| 21/26 [00:20<00:05,  1.02s/it]Epoch: 9/10. Loss: 0.8879:  81%|[36m████████  [0m| 21/26 [00:21<00:05,  1.02s/it]Epoch: 9/10. Loss: 0.8879:  85%|[36m████████▍ [0m| 22/26 [00:21<00:04,  1.01s/it]Epoch: 9/10. Loss: 0.7390:  85%|[36m████████▍ [0m| 22/26 [00:22<00:04,  1.01s/it]Epoch: 9/10. Loss: 0.7390:  88%|[36m████████▊ [0m| 23/26 [00:22<00:03,  1.03s/it]Epoch: 9/10. Loss: 0.6132:  88%|[36m████████▊ [0m| 23/26 [00:23<00:03,  1.03s/it]Epoch: 9/10. Loss: 0.6132:  92%|[36m█████████▏[0m| 24/26 [00:23<00:02,  1.05s/it]Epoch: 9/10. Loss: 0.8663:  92%|[36m█████████▏[0m| 24/26 [00:24<00:02,  1.05s/it]Epoch: 9/10. Loss: 0.8663:  96%|[36m█████████▌[0m| 25/26 [00:24<00:01,  1.03s/it]Epoch: 9/10. Loss: 0.7258:  96%|[36m█████████▌[0m| 25/26 [00:25<00:01,  1.03s/it]Epoch: 9/10. Loss: 0.7258: 100%|[36m██████████[0m| 26/26 [00:25<00:00,  1.09it/s]Epoch: 9/10. Loss: 0.7258: 100%|[36m██████████[0m| 26/26 [00:25<00:00,  1.03it/s]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:05,  1.15it/s] 29%|[33m██▊       [0m| 2/7 [00:01<00:04,  1.01it/s] 43%|[33m████▎     [0m| 3/7 [00:02<00:03,  1.15it/s] 57%|[33m█████▋    [0m| 4/7 [00:04<00:03,  1.07s/it] 71%|[33m███████▏  [0m| 5/7 [00:04<00:01,  1.21it/s] 86%|[33m████████▌ [0m| 6/7 [00:05<00:00,  1.21it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.57it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.27it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 0/10. Loss: 1.0682:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 0/10. Loss: 1.0682:   4%|[36m▍         [0m| 1/26 [00:01<00:25,  1.00s/it]Epoch: 0/10. Loss: 4.9407:   4%|[36m▍         [0m| 1/26 [00:01<00:25,  1.00s/it]Epoch: 0/10. Loss: 4.9407:   8%|[36m▊         [0m| 2/26 [00:02<00:24,  1.01s/it]Epoch: 0/10. Loss: 1.8803:   8%|[36m▊         [0m| 2/26 [00:02<00:24,  1.01s/it]Epoch: 0/10. Loss: 1.8803:  12%|[36m█▏        [0m| 3/26 [00:02<00:22,  1.02it/s]Epoch: 0/10. Loss: 1.2214:  12%|[36m█▏        [0m| 3/26 [00:03<00:22,  1.02it/s]Epoch: 0/10. Loss: 1.2214:  15%|[36m█▌        [0m| 4/26 [00:03<00:20,  1.05it/s]Epoch: 0/10. Loss: 1.1565:  15%|[36m█▌        [0m| 4/26 [00:04<00:20,  1.05it/s]Epoch: 0/10. Loss: 1.1565:  19%|[36m█▉        [0m| 5/26 [00:04<00:20,  1.04it/s]Epoch: 0/10. Loss: 1.0261:  19%|[36m█▉        [0m| 5/26 [00:05<00:20,  1.04it/s]Epoch: 0/10. Loss: 1.0261:  23%|[36m██▎       [0m| 6/26 [00:05<00:19,  1.05it/s]Epoch: 0/10. Loss: 1.1095:  23%|[36m██▎       [0m| 6/26 [00:06<00:19,  1.05it/s]Epoch: 0/10. Loss: 1.1095:  27%|[36m██▋       [0m| 7/26 [00:06<00:17,  1.08it/s]Epoch: 0/10. Loss: 1.8229:  27%|[36m██▋       [0m| 7/26 [00:07<00:17,  1.08it/s]Epoch: 0/10. Loss: 1.8229:  31%|[36m███       [0m| 8/26 [00:07<00:16,  1.06it/s]Epoch: 0/10. Loss: 1.0592:  31%|[36m███       [0m| 8/26 [00:08<00:16,  1.06it/s]Epoch: 0/10. Loss: 1.0592:  35%|[36m███▍      [0m| 9/26 [00:08<00:16,  1.01it/s]Epoch: 0/10. Loss: 1.1570:  35%|[36m███▍      [0m| 9/26 [00:10<00:16,  1.01it/s]Epoch: 0/10. Loss: 1.1570:  38%|[36m███▊      [0m| 10/26 [00:10<00:20,  1.28s/it]Epoch: 0/10. Loss: 1.0628:  38%|[36m███▊      [0m| 10/26 [00:11<00:20,  1.28s/it]Epoch: 0/10. Loss: 1.0628:  42%|[36m████▏     [0m| 11/26 [00:11<00:17,  1.18s/it]Epoch: 0/10. Loss: 1.1061:  42%|[36m████▏     [0m| 11/26 [00:12<00:17,  1.18s/it]Epoch: 0/10. Loss: 1.1061:  46%|[36m████▌     [0m| 12/26 [00:12<00:15,  1.11s/it]Epoch: 0/10. Loss: 1.0321:  46%|[36m████▌     [0m| 12/26 [00:13<00:15,  1.11s/it]Epoch: 0/10. Loss: 1.0321:  50%|[36m█████     [0m| 13/26 [00:13<00:14,  1.09s/it]Epoch: 0/10. Loss: 1.4928:  50%|[36m█████     [0m| 13/26 [00:14<00:14,  1.09s/it]Epoch: 0/10. Loss: 1.4928:  54%|[36m█████▍    [0m| 14/26 [00:14<00:13,  1.12s/it]Epoch: 0/10. Loss: 1.0080:  54%|[36m█████▍    [0m| 14/26 [00:15<00:13,  1.12s/it]Epoch: 0/10. Loss: 1.0080:  58%|[36m█████▊    [0m| 15/26 [00:15<00:11,  1.08s/it]Epoch: 0/10. Loss: 1.1764:  58%|[36m█████▊    [0m| 15/26 [00:16<00:11,  1.08s/it]Epoch: 0/10. Loss: 1.1764:  62%|[36m██████▏   [0m| 16/26 [00:17<00:11,  1.13s/it]Epoch: 0/10. Loss: 1.0068:  62%|[36m██████▏   [0m| 16/26 [00:18<00:11,  1.13s/it]Epoch: 0/10. Loss: 1.0068:  65%|[36m██████▌   [0m| 17/26 [00:18<00:10,  1.20s/it]Epoch: 0/10. Loss: 1.4061:  65%|[36m██████▌   [0m| 17/26 [00:19<00:10,  1.20s/it]Epoch: 0/10. Loss: 1.4061:  69%|[36m██████▉   [0m| 18/26 [00:19<00:09,  1.18s/it]Epoch: 0/10. Loss: 1.1040:  69%|[36m██████▉   [0m| 18/26 [00:20<00:09,  1.18s/it]Epoch: 0/10. Loss: 1.1040:  73%|[36m███████▎  [0m| 19/26 [00:20<00:07,  1.11s/it]Epoch: 0/10. Loss: 1.0286:  73%|[36m███████▎  [0m| 19/26 [00:21<00:07,  1.11s/it]Epoch: 0/10. Loss: 1.0286:  77%|[36m███████▋  [0m| 20/26 [00:21<00:06,  1.06s/it]Epoch: 0/10. Loss: 1.1211:  77%|[36m███████▋  [0m| 20/26 [00:22<00:06,  1.06s/it]Epoch: 0/10. Loss: 1.1211:  81%|[36m████████  [0m| 21/26 [00:22<00:05,  1.00s/it]Epoch: 0/10. Loss: 1.0405:  81%|[36m████████  [0m| 21/26 [00:23<00:05,  1.00s/it]Epoch: 0/10. Loss: 1.0405:  85%|[36m████████▍ [0m| 22/26 [00:23<00:04,  1.17s/it]Epoch: 0/10. Loss: 1.0221:  85%|[36m████████▍ [0m| 22/26 [00:24<00:04,  1.17s/it]Epoch: 0/10. Loss: 1.0221:  88%|[36m████████▊ [0m| 23/26 [00:24<00:03,  1.09s/it]Epoch: 0/10. Loss: 0.9651:  88%|[36m████████▊ [0m| 23/26 [00:25<00:03,  1.09s/it]Epoch: 0/10. Loss: 0.9651:  92%|[36m█████████▏[0m| 24/26 [00:25<00:02,  1.02s/it]Epoch: 0/10. Loss: 1.0878:  92%|[36m█████████▏[0m| 24/26 [00:27<00:02,  1.02s/it]Epoch: 0/10. Loss: 1.0878:  96%|[36m█████████▌[0m| 25/26 [00:27<00:01,  1.15s/it]Epoch: 0/10. Loss: 1.0593:  96%|[36m█████████▌[0m| 25/26 [00:27<00:01,  1.15s/it]Epoch: 0/10. Loss: 1.0593: 100%|[36m██████████[0m| 26/26 [00:27<00:00,  1.03s/it]Epoch: 0/10. Loss: 1.0593: 100%|[36m██████████[0m| 26/26 [00:27<00:00,  1.07s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:05,  1.08it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:05,  1.04s/it] 43%|[33m████▎     [0m| 3/7 [00:02<00:03,  1.08it/s] 57%|[33m█████▋    [0m| 4/7 [00:04<00:03,  1.09s/it] 71%|[33m███████▏  [0m| 5/7 [00:04<00:01,  1.17it/s] 86%|[33m████████▌ [0m| 6/7 [00:05<00:00,  1.17it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.47it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.21it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 1/10. Loss: 1.0373:   0%|[36m          [0m| 0/26 [00:01<?, ?it/s]Epoch: 1/10. Loss: 1.0373:   4%|[36m▍         [0m| 1/26 [00:02<00:50,  2.02s/it]Epoch: 1/10. Loss: 1.1078:   4%|[36m▍         [0m| 1/26 [00:03<00:50,  2.02s/it]Epoch: 1/10. Loss: 1.1078:   8%|[36m▊         [0m| 2/26 [00:03<00:38,  1.60s/it]Epoch: 1/10. Loss: 1.1716:   8%|[36m▊         [0m| 2/26 [00:04<00:38,  1.60s/it]Epoch: 1/10. Loss: 1.1716:  12%|[36m█▏        [0m| 3/26 [00:04<00:30,  1.31s/it]Epoch: 1/10. Loss: 0.9653:  12%|[36m█▏        [0m| 3/26 [00:05<00:30,  1.31s/it]Epoch: 1/10. Loss: 0.9653:  15%|[36m█▌        [0m| 4/26 [00:05<00:27,  1.27s/it]Epoch: 1/10. Loss: 0.9541:  15%|[36m█▌        [0m| 4/26 [00:06<00:27,  1.27s/it]Epoch: 1/10. Loss: 0.9541:  19%|[36m█▉        [0m| 5/26 [00:06<00:25,  1.22s/it]Epoch: 1/10. Loss: 1.1115:  19%|[36m█▉        [0m| 5/26 [00:07<00:25,  1.22s/it]Epoch: 1/10. Loss: 1.1115:  23%|[36m██▎       [0m| 6/26 [00:07<00:22,  1.11s/it]Epoch: 1/10. Loss: 1.0067:  23%|[36m██▎       [0m| 6/26 [00:08<00:22,  1.11s/it]Epoch: 1/10. Loss: 1.0067:  27%|[36m██▋       [0m| 7/26 [00:08<00:20,  1.10s/it]Epoch: 1/10. Loss: 1.0653:  27%|[36m██▋       [0m| 7/26 [00:09<00:20,  1.10s/it]Epoch: 1/10. Loss: 1.0653:  31%|[36m███       [0m| 8/26 [00:09<00:19,  1.07s/it]Epoch: 1/10. Loss: 0.9929:  31%|[36m███       [0m| 8/26 [00:11<00:19,  1.07s/it]Epoch: 1/10. Loss: 0.9929:  35%|[36m███▍      [0m| 9/26 [00:11<00:21,  1.27s/it]Epoch: 1/10. Loss: 0.9100:  35%|[36m███▍      [0m| 9/26 [00:12<00:21,  1.27s/it]Epoch: 1/10. Loss: 0.9100:  38%|[36m███▊      [0m| 10/26 [00:12<00:21,  1.34s/it]Epoch: 1/10. Loss: 1.0441:  38%|[36m███▊      [0m| 10/26 [00:14<00:21,  1.34s/it]Epoch: 1/10. Loss: 1.0441:  42%|[36m████▏     [0m| 11/26 [00:14<00:22,  1.51s/it]Epoch: 1/10. Loss: 1.0287:  42%|[36m████▏     [0m| 11/26 [00:15<00:22,  1.51s/it]Epoch: 1/10. Loss: 1.0287:  46%|[36m████▌     [0m| 12/26 [00:15<00:18,  1.31s/it]Epoch: 1/10. Loss: 1.0497:  46%|[36m████▌     [0m| 12/26 [00:16<00:18,  1.31s/it]Epoch: 1/10. Loss: 1.0497:  50%|[36m█████     [0m| 13/26 [00:16<00:16,  1.27s/it]Epoch: 1/10. Loss: 0.9275:  50%|[36m█████     [0m| 13/26 [00:17<00:16,  1.27s/it]Epoch: 1/10. Loss: 0.9275:  54%|[36m█████▍    [0m| 14/26 [00:17<00:14,  1.17s/it]Epoch: 1/10. Loss: 0.9636:  54%|[36m█████▍    [0m| 14/26 [00:18<00:14,  1.17s/it]Epoch: 1/10. Loss: 0.9636:  58%|[36m█████▊    [0m| 15/26 [00:18<00:12,  1.10s/it]Epoch: 1/10. Loss: 1.1007:  58%|[36m█████▊    [0m| 15/26 [00:19<00:12,  1.10s/it]Epoch: 1/10. Loss: 1.1007:  62%|[36m██████▏   [0m| 16/26 [00:19<00:10,  1.05s/it]Epoch: 1/10. Loss: 0.9779:  62%|[36m██████▏   [0m| 16/26 [00:20<00:10,  1.05s/it]Epoch: 1/10. Loss: 0.9779:  65%|[36m██████▌   [0m| 17/26 [00:20<00:09,  1.01s/it]Epoch: 1/10. Loss: 1.0120:  65%|[36m██████▌   [0m| 17/26 [00:21<00:09,  1.01s/it]Epoch: 1/10. Loss: 1.0120:  69%|[36m██████▉   [0m| 18/26 [00:21<00:08,  1.00s/it]Epoch: 1/10. Loss: 0.9588:  69%|[36m██████▉   [0m| 18/26 [00:23<00:08,  1.00s/it]Epoch: 1/10. Loss: 0.9588:  73%|[36m███████▎  [0m| 19/26 [00:23<00:09,  1.30s/it]Epoch: 1/10. Loss: 1.0094:  73%|[36m███████▎  [0m| 19/26 [00:24<00:09,  1.30s/it]Epoch: 1/10. Loss: 1.0094:  77%|[36m███████▋  [0m| 20/26 [00:24<00:07,  1.17s/it]Epoch: 1/10. Loss: 0.9902:  77%|[36m███████▋  [0m| 20/26 [00:25<00:07,  1.17s/it]Epoch: 1/10. Loss: 0.9902:  81%|[36m████████  [0m| 21/26 [00:25<00:05,  1.14s/it]Epoch: 1/10. Loss: 0.9359:  81%|[36m████████  [0m| 21/26 [00:26<00:05,  1.14s/it]Epoch: 1/10. Loss: 0.9359:  85%|[36m████████▍ [0m| 22/26 [00:26<00:04,  1.05s/it]Epoch: 1/10. Loss: 0.9638:  85%|[36m████████▍ [0m| 22/26 [00:27<00:04,  1.05s/it]Epoch: 1/10. Loss: 0.9638:  88%|[36m████████▊ [0m| 23/26 [00:27<00:03,  1.01s/it]Epoch: 1/10. Loss: 0.9536:  88%|[36m████████▊ [0m| 23/26 [00:28<00:03,  1.01s/it]Epoch: 1/10. Loss: 0.9536:  92%|[36m█████████▏[0m| 24/26 [00:28<00:02,  1.13s/it]Epoch: 1/10. Loss: 0.9584:  92%|[36m█████████▏[0m| 24/26 [00:29<00:02,  1.13s/it]Epoch: 1/10. Loss: 0.9584:  96%|[36m█████████▌[0m| 25/26 [00:29<00:01,  1.13s/it]Epoch: 1/10. Loss: 0.9426:  96%|[36m█████████▌[0m| 25/26 [00:30<00:01,  1.13s/it]Epoch: 1/10. Loss: 0.9426: 100%|[36m██████████[0m| 26/26 [00:30<00:00,  1.03it/s]Epoch: 1/10. Loss: 0.9426: 100%|[36m██████████[0m| 26/26 [00:30<00:00,  1.17s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:05,  1.12it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:05,  1.09s/it] 43%|[33m████▎     [0m| 3/7 [00:03<00:04,  1.01s/it] 57%|[33m█████▋    [0m| 4/7 [00:04<00:03,  1.11s/it] 71%|[33m███████▏  [0m| 5/7 [00:04<00:01,  1.15it/s] 86%|[33m████████▌ [0m| 6/7 [00:05<00:00,  1.15it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.50it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.19it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 2/10. Loss: 0.9484:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 2/10. Loss: 0.9484:   4%|[36m▍         [0m| 1/26 [00:00<00:23,  1.06it/s]Epoch: 2/10. Loss: 0.9389:   4%|[36m▍         [0m| 1/26 [00:01<00:23,  1.06it/s]Epoch: 2/10. Loss: 0.9389:   8%|[36m▊         [0m| 2/26 [00:01<00:22,  1.06it/s]Epoch: 2/10. Loss: 1.0103:   8%|[36m▊         [0m| 2/26 [00:05<00:22,  1.06it/s]Epoch: 2/10. Loss: 1.0103:  12%|[36m█▏        [0m| 3/26 [00:05<00:46,  2.02s/it]Epoch: 2/10. Loss: 0.9499:  12%|[36m█▏        [0m| 3/26 [00:06<00:46,  2.02s/it]Epoch: 2/10. Loss: 0.9499:  15%|[36m█▌        [0m| 4/26 [00:06<00:38,  1.75s/it]Epoch: 2/10. Loss: 0.9337:  15%|[36m█▌        [0m| 4/26 [00:07<00:38,  1.75s/it]Epoch: 2/10. Loss: 0.9337:  19%|[36m█▉        [0m| 5/26 [00:07<00:31,  1.49s/it]Epoch: 2/10. Loss: 0.9632:  19%|[36m█▉        [0m| 5/26 [00:09<00:31,  1.49s/it]Epoch: 2/10. Loss: 0.9632:  23%|[36m██▎       [0m| 6/26 [00:09<00:32,  1.62s/it]Epoch: 2/10. Loss: 0.9540:  23%|[36m██▎       [0m| 6/26 [00:11<00:32,  1.62s/it]Epoch: 2/10. Loss: 0.9540:  27%|[36m██▋       [0m| 7/26 [00:11<00:35,  1.86s/it]Epoch: 2/10. Loss: 0.8823:  27%|[36m██▋       [0m| 7/26 [00:12<00:35,  1.86s/it]Epoch: 2/10. Loss: 0.8823:  31%|[36m███       [0m| 8/26 [00:12<00:27,  1.52s/it]Epoch: 2/10. Loss: 0.8958:  31%|[36m███       [0m| 8/26 [00:13<00:27,  1.52s/it]Epoch: 2/10. Loss: 0.8958:  35%|[36m███▍      [0m| 9/26 [00:13<00:23,  1.39s/it]Epoch: 2/10. Loss: 0.9713:  35%|[36m███▍      [0m| 9/26 [00:14<00:23,  1.39s/it]Epoch: 2/10. Loss: 0.9713:  38%|[36m███▊      [0m| 10/26 [00:14<00:19,  1.24s/it]Epoch: 2/10. Loss: 1.0260:  38%|[36m███▊      [0m| 10/26 [00:15<00:19,  1.24s/it]Epoch: 2/10. Loss: 1.0260:  42%|[36m████▏     [0m| 11/26 [00:15<00:17,  1.15s/it]Epoch: 2/10. Loss: 0.9499:  42%|[36m████▏     [0m| 11/26 [00:16<00:17,  1.15s/it]Epoch: 2/10. Loss: 0.9499:  46%|[36m████▌     [0m| 12/26 [00:16<00:16,  1.17s/it]Epoch: 2/10. Loss: 0.9487:  46%|[36m████▌     [0m| 12/26 [00:17<00:16,  1.17s/it]Epoch: 2/10. Loss: 0.9487:  50%|[36m█████     [0m| 13/26 [00:17<00:14,  1.10s/it]Epoch: 2/10. Loss: 0.9668:  50%|[36m█████     [0m| 13/26 [00:19<00:14,  1.10s/it]Epoch: 2/10. Loss: 0.9668:  54%|[36m█████▍    [0m| 14/26 [00:19<00:14,  1.20s/it]Epoch: 2/10. Loss: 0.8966:  54%|[36m█████▍    [0m| 14/26 [00:20<00:14,  1.20s/it]Epoch: 2/10. Loss: 0.8966:  58%|[36m█████▊    [0m| 15/26 [00:20<00:12,  1.15s/it]Epoch: 2/10. Loss: 0.9373:  58%|[36m█████▊    [0m| 15/26 [00:22<00:12,  1.15s/it]Epoch: 2/10. Loss: 0.9373:  62%|[36m██████▏   [0m| 16/26 [00:22<00:14,  1.44s/it]Epoch: 2/10. Loss: 0.9130:  62%|[36m██████▏   [0m| 16/26 [00:23<00:14,  1.44s/it]Epoch: 2/10. Loss: 0.9130:  65%|[36m██████▌   [0m| 17/26 [00:23<00:11,  1.28s/it]Epoch: 2/10. Loss: 0.9037:  65%|[36m██████▌   [0m| 17/26 [00:24<00:11,  1.28s/it]Epoch: 2/10. Loss: 0.9037:  69%|[36m██████▉   [0m| 18/26 [00:24<00:09,  1.24s/it]Epoch: 2/10. Loss: 0.9285:  69%|[36m██████▉   [0m| 18/26 [00:25<00:09,  1.24s/it]Epoch: 2/10. Loss: 0.9285:  73%|[36m███████▎  [0m| 19/26 [00:25<00:08,  1.18s/it]Epoch: 2/10. Loss: 0.9223:  73%|[36m███████▎  [0m| 19/26 [00:26<00:08,  1.18s/it]Epoch: 2/10. Loss: 0.9223:  77%|[36m███████▋  [0m| 20/26 [00:26<00:06,  1.09s/it]Epoch: 2/10. Loss: 0.9032:  77%|[36m███████▋  [0m| 20/26 [00:27<00:06,  1.09s/it]Epoch: 2/10. Loss: 0.9032:  81%|[36m████████  [0m| 21/26 [00:27<00:05,  1.05s/it]Epoch: 2/10. Loss: 0.8652:  81%|[36m████████  [0m| 21/26 [00:28<00:05,  1.05s/it]Epoch: 2/10. Loss: 0.8652:  85%|[36m████████▍ [0m| 22/26 [00:28<00:04,  1.01s/it]Epoch: 2/10. Loss: 0.9626:  85%|[36m████████▍ [0m| 22/26 [00:29<00:04,  1.01s/it]Epoch: 2/10. Loss: 0.9626:  88%|[36m████████▊ [0m| 23/26 [00:29<00:02,  1.01it/s]Epoch: 2/10. Loss: 0.8174:  88%|[36m████████▊ [0m| 23/26 [00:30<00:02,  1.01it/s]Epoch: 2/10. Loss: 0.8174:  92%|[36m█████████▏[0m| 24/26 [00:30<00:01,  1.01it/s]Epoch: 2/10. Loss: 0.8659:  92%|[36m█████████▏[0m| 24/26 [00:30<00:01,  1.01it/s]Epoch: 2/10. Loss: 0.8659:  96%|[36m█████████▌[0m| 25/26 [00:30<00:00,  1.04it/s]Epoch: 2/10. Loss: 1.0472:  96%|[36m█████████▌[0m| 25/26 [00:31<00:00,  1.04it/s]Epoch: 2/10. Loss: 1.0472: 100%|[36m██████████[0m| 26/26 [00:31<00:00,  1.14it/s]Epoch: 2/10. Loss: 1.0472: 100%|[36m██████████[0m| 26/26 [00:31<00:00,  1.22s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:05,  1.14it/s] 29%|[33m██▊       [0m| 2/7 [00:01<00:04,  1.03it/s] 43%|[33m████▎     [0m| 3/7 [00:02<00:03,  1.14it/s] 57%|[33m█████▋    [0m| 4/7 [00:03<00:03,  1.04s/it] 71%|[33m███████▏  [0m| 5/7 [00:04<00:01,  1.21it/s] 86%|[33m████████▌ [0m| 6/7 [00:05<00:00,  1.18it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.51it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.25it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 3/10. Loss: 0.9148:   0%|[36m          [0m| 0/26 [00:01<?, ?it/s]Epoch: 3/10. Loss: 0.9148:   4%|[36m▍         [0m| 1/26 [00:01<00:49,  1.98s/it]Epoch: 3/10. Loss: 0.9314:   4%|[36m▍         [0m| 1/26 [00:02<00:49,  1.98s/it]Epoch: 3/10. Loss: 0.9314:   8%|[36m▊         [0m| 2/26 [00:02<00:32,  1.34s/it]Epoch: 3/10. Loss: 0.9184:   8%|[36m▊         [0m| 2/26 [00:03<00:32,  1.34s/it]Epoch: 3/10. Loss: 0.9184:  12%|[36m█▏        [0m| 3/26 [00:03<00:28,  1.24s/it]Epoch: 3/10. Loss: 0.8904:  12%|[36m█▏        [0m| 3/26 [00:04<00:28,  1.24s/it]Epoch: 3/10. Loss: 0.8904:  15%|[36m█▌        [0m| 4/26 [00:04<00:24,  1.11s/it]Epoch: 3/10. Loss: 0.8750:  15%|[36m█▌        [0m| 4/26 [00:05<00:24,  1.11s/it]Epoch: 3/10. Loss: 0.8750:  19%|[36m█▉        [0m| 5/26 [00:05<00:22,  1.06s/it]Epoch: 3/10. Loss: 0.8817:  19%|[36m█▉        [0m| 5/26 [00:07<00:22,  1.06s/it]Epoch: 3/10. Loss: 0.8817:  23%|[36m██▎       [0m| 6/26 [00:07<00:22,  1.15s/it]Epoch: 3/10. Loss: 1.0133:  23%|[36m██▎       [0m| 6/26 [00:08<00:22,  1.15s/it]Epoch: 3/10. Loss: 1.0133:  27%|[36m██▋       [0m| 7/26 [00:08<00:20,  1.08s/it]Epoch: 3/10. Loss: 0.9900:  27%|[36m██▋       [0m| 7/26 [00:08<00:20,  1.08s/it]Epoch: 3/10. Loss: 0.9900:  31%|[36m███       [0m| 8/26 [00:08<00:18,  1.00s/it]Epoch: 3/10. Loss: 0.8522:  31%|[36m███       [0m| 8/26 [00:09<00:18,  1.00s/it]Epoch: 3/10. Loss: 0.8522:  35%|[36m███▍      [0m| 9/26 [00:09<00:16,  1.00it/s]Epoch: 3/10. Loss: 0.9326:  35%|[36m███▍      [0m| 9/26 [00:10<00:16,  1.00it/s]Epoch: 3/10. Loss: 0.9326:  38%|[36m███▊      [0m| 10/26 [00:10<00:15,  1.01it/s]Epoch: 3/10. Loss: 0.8647:  38%|[36m███▊      [0m| 10/26 [00:11<00:15,  1.01it/s]Epoch: 3/10. Loss: 0.8647:  42%|[36m████▏     [0m| 11/26 [00:11<00:14,  1.00it/s]Epoch: 3/10. Loss: 0.9447:  42%|[36m████▏     [0m| 11/26 [00:12<00:14,  1.00it/s]Epoch: 3/10. Loss: 0.9447:  46%|[36m████▌     [0m| 12/26 [00:12<00:13,  1.02it/s]Epoch: 3/10. Loss: 0.9101:  46%|[36m████▌     [0m| 12/26 [00:13<00:13,  1.02it/s]Epoch: 3/10. Loss: 0.9101:  50%|[36m█████     [0m| 13/26 [00:13<00:12,  1.06it/s]Epoch: 3/10. Loss: 0.9627:  50%|[36m█████     [0m| 13/26 [00:14<00:12,  1.06it/s]Epoch: 3/10. Loss: 0.9627:  54%|[36m█████▍    [0m| 14/26 [00:14<00:11,  1.07it/s]Epoch: 3/10. Loss: 0.8961:  54%|[36m█████▍    [0m| 14/26 [00:15<00:11,  1.07it/s]Epoch: 3/10. Loss: 0.8961:  58%|[36m█████▊    [0m| 15/26 [00:15<00:10,  1.04it/s]Epoch: 3/10. Loss: 0.9545:  58%|[36m█████▊    [0m| 15/26 [00:16<00:10,  1.04it/s]Epoch: 3/10. Loss: 0.9545:  62%|[36m██████▏   [0m| 16/26 [00:16<00:09,  1.05it/s]Epoch: 3/10. Loss: 0.9958:  62%|[36m██████▏   [0m| 16/26 [00:17<00:09,  1.05it/s]Epoch: 3/10. Loss: 0.9958:  65%|[36m██████▌   [0m| 17/26 [00:17<00:08,  1.04it/s]Epoch: 3/10. Loss: 0.8707:  65%|[36m██████▌   [0m| 17/26 [00:18<00:08,  1.04it/s]Epoch: 3/10. Loss: 0.8707:  69%|[36m██████▉   [0m| 18/26 [00:18<00:08,  1.01s/it]Epoch: 3/10. Loss: 0.8622:  69%|[36m██████▉   [0m| 18/26 [00:19<00:08,  1.01s/it]Epoch: 3/10. Loss: 0.8622:  73%|[36m███████▎  [0m| 19/26 [00:19<00:07,  1.08s/it]Epoch: 3/10. Loss: 0.8543:  73%|[36m███████▎  [0m| 19/26 [00:21<00:07,  1.08s/it]Epoch: 3/10. Loss: 0.8543:  77%|[36m███████▋  [0m| 20/26 [00:21<00:07,  1.22s/it]Epoch: 3/10. Loss: 0.8297:  77%|[36m███████▋  [0m| 20/26 [00:22<00:07,  1.22s/it]Epoch: 3/10. Loss: 0.8297:  81%|[36m████████  [0m| 21/26 [00:22<00:06,  1.27s/it]Epoch: 3/10. Loss: 0.8094:  81%|[36m████████  [0m| 21/26 [00:23<00:06,  1.27s/it]Epoch: 3/10. Loss: 0.8094:  85%|[36m████████▍ [0m| 22/26 [00:23<00:04,  1.19s/it]Epoch: 3/10. Loss: 0.8866:  85%|[36m████████▍ [0m| 22/26 [00:24<00:04,  1.19s/it]Epoch: 3/10. Loss: 0.8866:  88%|[36m████████▊ [0m| 23/26 [00:24<00:03,  1.14s/it]Epoch: 3/10. Loss: 0.8654:  88%|[36m████████▊ [0m| 23/26 [00:25<00:03,  1.14s/it]Epoch: 3/10. Loss: 0.8654:  92%|[36m█████████▏[0m| 24/26 [00:25<00:02,  1.10s/it]Epoch: 3/10. Loss: 1.0314:  92%|[36m█████████▏[0m| 24/26 [00:28<00:02,  1.10s/it]Epoch: 3/10. Loss: 1.0314:  96%|[36m█████████▌[0m| 25/26 [00:28<00:01,  1.54s/it]Epoch: 3/10. Loss: 0.9033:  96%|[36m█████████▌[0m| 25/26 [00:29<00:01,  1.54s/it]Epoch: 3/10. Loss: 0.9033: 100%|[36m██████████[0m| 26/26 [00:29<00:00,  1.42s/it]Epoch: 3/10. Loss: 0.9033: 100%|[36m██████████[0m| 26/26 [00:29<00:00,  1.14s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:01<00:08,  1.49s/it] 29%|[33m██▊       [0m| 2/7 [00:02<00:06,  1.27s/it] 43%|[33m████▎     [0m| 3/7 [00:03<00:05,  1.31s/it] 57%|[33m█████▋    [0m| 4/7 [00:05<00:03,  1.30s/it] 71%|[33m███████▏  [0m| 5/7 [00:05<00:02,  1.00s/it] 86%|[33m████████▌ [0m| 6/7 [00:06<00:00,  1.01it/s]100%|[33m██████████[0m| 7/7 [00:06<00:00,  1.34it/s]100%|[33m██████████[0m| 7/7 [00:06<00:00,  1.01it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 4/10. Loss: 0.9316:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 4/10. Loss: 0.9316:   4%|[36m▍         [0m| 1/26 [00:01<00:25,  1.01s/it]Epoch: 4/10. Loss: 0.8673:   4%|[36m▍         [0m| 1/26 [00:01<00:25,  1.01s/it]Epoch: 4/10. Loss: 0.8673:   8%|[36m▊         [0m| 2/26 [00:01<00:22,  1.05it/s]Epoch: 4/10. Loss: 1.0115:   8%|[36m▊         [0m| 2/26 [00:02<00:22,  1.05it/s]Epoch: 4/10. Loss: 1.0115:  12%|[36m█▏        [0m| 3/26 [00:02<00:21,  1.05it/s]Epoch: 4/10. Loss: 0.9414:  12%|[36m█▏        [0m| 3/26 [00:03<00:21,  1.05it/s]Epoch: 4/10. Loss: 0.9414:  15%|[36m█▌        [0m| 4/26 [00:03<00:20,  1.09it/s]Epoch: 4/10. Loss: 0.9043:  15%|[36m█▌        [0m| 4/26 [00:04<00:20,  1.09it/s]Epoch: 4/10. Loss: 0.9043:  19%|[36m█▉        [0m| 5/26 [00:04<00:19,  1.05it/s]Epoch: 4/10. Loss: 0.9203:  19%|[36m█▉        [0m| 5/26 [00:05<00:19,  1.05it/s]Epoch: 4/10. Loss: 0.9203:  23%|[36m██▎       [0m| 6/26 [00:05<00:19,  1.04it/s]Epoch: 4/10. Loss: 0.8881:  23%|[36m██▎       [0m| 6/26 [00:06<00:19,  1.04it/s]Epoch: 4/10. Loss: 0.8881:  27%|[36m██▋       [0m| 7/26 [00:06<00:19,  1.00s/it]Epoch: 4/10. Loss: 0.8833:  27%|[36m██▋       [0m| 7/26 [00:08<00:19,  1.00s/it]Epoch: 4/10. Loss: 0.8833:  31%|[36m███       [0m| 8/26 [00:08<00:20,  1.17s/it]Epoch: 4/10. Loss: 0.8731:  31%|[36m███       [0m| 8/26 [00:09<00:20,  1.17s/it]Epoch: 4/10. Loss: 0.8731:  35%|[36m███▍      [0m| 9/26 [00:09<00:19,  1.12s/it]Epoch: 4/10. Loss: 0.8826:  35%|[36m███▍      [0m| 9/26 [00:10<00:19,  1.12s/it]Epoch: 4/10. Loss: 0.8826:  38%|[36m███▊      [0m| 10/26 [00:10<00:18,  1.14s/it]Epoch: 4/10. Loss: 0.8195:  38%|[36m███▊      [0m| 10/26 [00:11<00:18,  1.14s/it]Epoch: 4/10. Loss: 0.8195:  42%|[36m████▏     [0m| 11/26 [00:11<00:15,  1.06s/it]Epoch: 4/10. Loss: 0.7885:  42%|[36m████▏     [0m| 11/26 [00:12<00:15,  1.06s/it]Epoch: 4/10. Loss: 0.7885:  46%|[36m████▌     [0m| 12/26 [00:12<00:14,  1.03s/it]Epoch: 4/10. Loss: 0.8740:  46%|[36m████▌     [0m| 12/26 [00:13<00:14,  1.03s/it]Epoch: 4/10. Loss: 0.8740:  50%|[36m█████     [0m| 13/26 [00:13<00:12,  1.01it/s]Epoch: 4/10. Loss: 0.9808:  50%|[36m█████     [0m| 13/26 [00:14<00:12,  1.01it/s]Epoch: 4/10. Loss: 0.9808:  54%|[36m█████▍    [0m| 14/26 [00:14<00:11,  1.01it/s]Epoch: 4/10. Loss: 0.8767:  54%|[36m█████▍    [0m| 14/26 [00:15<00:11,  1.01it/s]Epoch: 4/10. Loss: 0.8767:  58%|[36m█████▊    [0m| 15/26 [00:15<00:10,  1.01it/s]Epoch: 4/10. Loss: 0.9533:  58%|[36m█████▊    [0m| 15/26 [00:16<00:10,  1.01it/s]Epoch: 4/10. Loss: 0.9533:  62%|[36m██████▏   [0m| 16/26 [00:16<00:09,  1.01it/s]Epoch: 4/10. Loss: 0.9983:  62%|[36m██████▏   [0m| 16/26 [00:17<00:09,  1.01it/s]Epoch: 4/10. Loss: 0.9983:  65%|[36m██████▌   [0m| 17/26 [00:17<00:08,  1.02it/s]Epoch: 4/10. Loss: 0.8246:  65%|[36m██████▌   [0m| 17/26 [00:18<00:08,  1.02it/s]Epoch: 4/10. Loss: 0.8246:  69%|[36m██████▉   [0m| 18/26 [00:18<00:07,  1.02it/s]Epoch: 4/10. Loss: 0.9241:  69%|[36m██████▉   [0m| 18/26 [00:19<00:07,  1.02it/s]Epoch: 4/10. Loss: 0.9241:  73%|[36m███████▎  [0m| 19/26 [00:19<00:06,  1.01it/s]Epoch: 4/10. Loss: 0.8632:  73%|[36m███████▎  [0m| 19/26 [00:20<00:06,  1.01it/s]Epoch: 4/10. Loss: 0.8632:  77%|[36m███████▋  [0m| 20/26 [00:20<00:06,  1.01s/it]Epoch: 4/10. Loss: 0.8805:  77%|[36m███████▋  [0m| 20/26 [00:21<00:06,  1.01s/it]Epoch: 4/10. Loss: 0.8805:  81%|[36m████████  [0m| 21/26 [00:21<00:04,  1.02it/s]Epoch: 4/10. Loss: 0.9228:  81%|[36m████████  [0m| 21/26 [00:22<00:04,  1.02it/s]Epoch: 4/10. Loss: 0.9228:  85%|[36m████████▍ [0m| 22/26 [00:22<00:04,  1.12s/it]Epoch: 4/10. Loss: 0.8345:  85%|[36m████████▍ [0m| 22/26 [00:23<00:04,  1.12s/it]Epoch: 4/10. Loss: 0.8345:  88%|[36m████████▊ [0m| 23/26 [00:23<00:03,  1.05s/it]Epoch: 4/10. Loss: 0.9288:  88%|[36m████████▊ [0m| 23/26 [00:24<00:03,  1.05s/it]Epoch: 4/10. Loss: 0.9288:  92%|[36m█████████▏[0m| 24/26 [00:24<00:01,  1.02it/s]Epoch: 4/10. Loss: 0.8232:  92%|[36m█████████▏[0m| 24/26 [00:25<00:01,  1.02it/s]Epoch: 4/10. Loss: 0.8232:  96%|[36m█████████▌[0m| 25/26 [00:25<00:01,  1.04s/it]Epoch: 4/10. Loss: 0.7840:  96%|[36m█████████▌[0m| 25/26 [00:26<00:01,  1.04s/it]Epoch: 4/10. Loss: 0.7840: 100%|[36m██████████[0m| 26/26 [00:26<00:00,  1.10it/s]Epoch: 4/10. Loss: 0.7840: 100%|[36m██████████[0m| 26/26 [00:26<00:00,  1.00s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:05,  1.07it/s] 29%|[33m██▊       [0m| 2/7 [00:01<00:05,  1.01s/it] 43%|[33m████▎     [0m| 3/7 [00:02<00:03,  1.10it/s] 57%|[33m█████▋    [0m| 4/7 [00:04<00:03,  1.11s/it] 71%|[33m███████▏  [0m| 5/7 [00:04<00:01,  1.14it/s] 86%|[33m████████▌ [0m| 6/7 [00:05<00:00,  1.12it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.45it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.19it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 5/10. Loss: 0.8837:   0%|[36m          [0m| 0/26 [00:01<?, ?it/s]Epoch: 5/10. Loss: 0.8837:   4%|[36m▍         [0m| 1/26 [00:01<00:26,  1.06s/it]Epoch: 5/10. Loss: 0.9319:   4%|[36m▍         [0m| 1/26 [00:02<00:26,  1.06s/it]Epoch: 5/10. Loss: 0.9319:   8%|[36m▊         [0m| 2/26 [00:02<00:28,  1.17s/it]Epoch: 5/10. Loss: 0.8424:   8%|[36m▊         [0m| 2/26 [00:03<00:28,  1.17s/it]Epoch: 5/10. Loss: 0.8424:  12%|[36m█▏        [0m| 3/26 [00:03<00:24,  1.07s/it]Epoch: 5/10. Loss: 0.7988:  12%|[36m█▏        [0m| 3/26 [00:04<00:24,  1.07s/it]Epoch: 5/10. Loss: 0.7988:  15%|[36m█▌        [0m| 4/26 [00:04<00:24,  1.12s/it]Epoch: 5/10. Loss: 0.8400:  15%|[36m█▌        [0m| 4/26 [00:05<00:24,  1.12s/it]Epoch: 5/10. Loss: 0.8400:  19%|[36m█▉        [0m| 5/26 [00:05<00:21,  1.04s/it]Epoch: 5/10. Loss: 0.8395:  19%|[36m█▉        [0m| 5/26 [00:06<00:21,  1.04s/it]Epoch: 5/10. Loss: 0.8395:  23%|[36m██▎       [0m| 6/26 [00:06<00:24,  1.23s/it]Epoch: 5/10. Loss: 0.9608:  23%|[36m██▎       [0m| 6/26 [00:08<00:24,  1.23s/it]Epoch: 5/10. Loss: 0.9608:  27%|[36m██▋       [0m| 7/26 [00:08<00:23,  1.23s/it]Epoch: 5/10. Loss: 0.8280:  27%|[36m██▋       [0m| 7/26 [00:09<00:23,  1.23s/it]Epoch: 5/10. Loss: 0.8280:  31%|[36m███       [0m| 8/26 [00:09<00:20,  1.13s/it]Epoch: 5/10. Loss: 0.9164:  31%|[36m███       [0m| 8/26 [00:10<00:20,  1.13s/it]Epoch: 5/10. Loss: 0.9164:  35%|[36m███▍      [0m| 9/26 [00:10<00:18,  1.11s/it]Epoch: 5/10. Loss: 0.7499:  35%|[36m███▍      [0m| 9/26 [00:11<00:18,  1.11s/it]Epoch: 5/10. Loss: 0.7499:  38%|[36m███▊      [0m| 10/26 [00:11<00:16,  1.05s/it]Epoch: 5/10. Loss: 0.8377:  38%|[36m███▊      [0m| 10/26 [00:12<00:16,  1.05s/it]Epoch: 5/10. Loss: 0.8377:  42%|[36m████▏     [0m| 11/26 [00:12<00:15,  1.04s/it]Epoch: 5/10. Loss: 0.8839:  42%|[36m████▏     [0m| 11/26 [00:13<00:15,  1.04s/it]Epoch: 5/10. Loss: 0.8839:  46%|[36m████▌     [0m| 12/26 [00:13<00:16,  1.21s/it]Epoch: 5/10. Loss: 0.8290:  46%|[36m████▌     [0m| 12/26 [00:14<00:16,  1.21s/it]Epoch: 5/10. Loss: 0.8290:  50%|[36m█████     [0m| 13/26 [00:14<00:15,  1.20s/it]Epoch: 5/10. Loss: 0.8130:  50%|[36m█████     [0m| 13/26 [00:16<00:15,  1.20s/it]Epoch: 5/10. Loss: 0.8130:  54%|[36m█████▍    [0m| 14/26 [00:16<00:14,  1.22s/it]Epoch: 5/10. Loss: 0.9000:  54%|[36m█████▍    [0m| 14/26 [00:17<00:14,  1.22s/it]Epoch: 5/10. Loss: 0.9000:  58%|[36m█████▊    [0m| 15/26 [00:17<00:12,  1.15s/it]Epoch: 5/10. Loss: 0.8259:  58%|[36m█████▊    [0m| 15/26 [00:18<00:12,  1.15s/it]Epoch: 5/10. Loss: 0.8259:  62%|[36m██████▏   [0m| 16/26 [00:18<00:11,  1.11s/it]Epoch: 5/10. Loss: 0.8741:  62%|[36m██████▏   [0m| 16/26 [00:19<00:11,  1.11s/it]Epoch: 5/10. Loss: 0.8741:  65%|[36m██████▌   [0m| 17/26 [00:19<00:09,  1.08s/it]Epoch: 5/10. Loss: 0.8371:  65%|[36m██████▌   [0m| 17/26 [00:20<00:09,  1.08s/it]Epoch: 5/10. Loss: 0.8371:  69%|[36m██████▉   [0m| 18/26 [00:20<00:08,  1.09s/it]Epoch: 5/10. Loss: 0.8725:  69%|[36m██████▉   [0m| 18/26 [00:21<00:08,  1.09s/it]Epoch: 5/10. Loss: 0.8725:  73%|[36m███████▎  [0m| 19/26 [00:21<00:07,  1.08s/it]Epoch: 5/10. Loss: 0.7828:  73%|[36m███████▎  [0m| 19/26 [00:22<00:07,  1.08s/it]Epoch: 5/10. Loss: 0.7828:  77%|[36m███████▋  [0m| 20/26 [00:22<00:06,  1.02s/it]Epoch: 5/10. Loss: 0.8038:  77%|[36m███████▋  [0m| 20/26 [00:23<00:06,  1.02s/it]Epoch: 5/10. Loss: 0.8038:  81%|[36m████████  [0m| 21/26 [00:23<00:05,  1.01s/it]Epoch: 5/10. Loss: 0.8445:  81%|[36m████████  [0m| 21/26 [00:23<00:05,  1.01s/it]Epoch: 5/10. Loss: 0.8445:  85%|[36m████████▍ [0m| 22/26 [00:24<00:03,  1.05it/s]Epoch: 5/10. Loss: 0.7731:  85%|[36m████████▍ [0m| 22/26 [00:24<00:03,  1.05it/s]Epoch: 5/10. Loss: 0.7731:  88%|[36m████████▊ [0m| 23/26 [00:24<00:02,  1.08it/s]Epoch: 5/10. Loss: 0.8056:  88%|[36m████████▊ [0m| 23/26 [00:26<00:02,  1.08it/s]Epoch: 5/10. Loss: 0.8056:  92%|[36m█████████▏[0m| 24/26 [00:26<00:02,  1.14s/it]Epoch: 5/10. Loss: 0.8664:  92%|[36m█████████▏[0m| 24/26 [00:27<00:02,  1.14s/it]Epoch: 5/10. Loss: 0.8664:  96%|[36m█████████▌[0m| 25/26 [00:27<00:01,  1.06s/it]Epoch: 5/10. Loss: 0.9184:  96%|[36m█████████▌[0m| 25/26 [00:28<00:01,  1.06s/it]Epoch: 5/10. Loss: 0.9184: 100%|[36m██████████[0m| 26/26 [00:28<00:00,  1.02it/s]Epoch: 5/10. Loss: 0.9184: 100%|[36m██████████[0m| 26/26 [00:28<00:00,  1.08s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:05,  1.11it/s] 29%|[33m██▊       [0m| 2/7 [00:01<00:05,  1.01s/it] 43%|[33m████▎     [0m| 3/7 [00:02<00:03,  1.04it/s] 57%|[33m█████▋    [0m| 4/7 [00:04<00:03,  1.10s/it] 71%|[33m███████▏  [0m| 5/7 [00:04<00:01,  1.14it/s] 86%|[33m████████▌ [0m| 6/7 [00:05<00:00,  1.12it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.44it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.19it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 6/10. Loss: 0.8643:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 6/10. Loss: 0.8643:   4%|[36m▍         [0m| 1/26 [00:01<00:25,  1.02s/it]Epoch: 6/10. Loss: 0.7509:   4%|[36m▍         [0m| 1/26 [00:01<00:25,  1.02s/it]Epoch: 6/10. Loss: 0.7509:   8%|[36m▊         [0m| 2/26 [00:01<00:21,  1.13it/s]Epoch: 6/10. Loss: 0.8053:   8%|[36m▊         [0m| 2/26 [00:02<00:21,  1.13it/s]Epoch: 6/10. Loss: 0.8053:  12%|[36m█▏        [0m| 3/26 [00:02<00:23,  1.01s/it]Epoch: 6/10. Loss: 0.8480:  12%|[36m█▏        [0m| 3/26 [00:03<00:23,  1.01s/it]Epoch: 6/10. Loss: 0.8480:  15%|[36m█▌        [0m| 4/26 [00:03<00:22,  1.00s/it]Epoch: 6/10. Loss: 0.8250:  15%|[36m█▌        [0m| 4/26 [00:04<00:22,  1.00s/it]Epoch: 6/10. Loss: 0.8250:  19%|[36m█▉        [0m| 5/26 [00:04<00:21,  1.00s/it]Epoch: 6/10. Loss: 0.8280:  19%|[36m█▉        [0m| 5/26 [00:05<00:21,  1.00s/it]Epoch: 6/10. Loss: 0.8280:  23%|[36m██▎       [0m| 6/26 [00:06<00:20,  1.04s/it]Epoch: 6/10. Loss: 0.8577:  23%|[36m██▎       [0m| 6/26 [00:08<00:20,  1.04s/it]Epoch: 6/10. Loss: 0.8577:  27%|[36m██▋       [0m| 7/26 [00:08<00:28,  1.51s/it]Epoch: 6/10. Loss: 0.6983:  27%|[36m██▋       [0m| 7/26 [00:09<00:28,  1.51s/it]Epoch: 6/10. Loss: 0.6983:  31%|[36m███       [0m| 8/26 [00:09<00:25,  1.40s/it]Epoch: 6/10. Loss: 0.8379:  31%|[36m███       [0m| 8/26 [00:10<00:25,  1.40s/it]Epoch: 6/10. Loss: 0.8379:  35%|[36m███▍      [0m| 9/26 [00:10<00:20,  1.21s/it]Epoch: 6/10. Loss: 0.8572:  35%|[36m███▍      [0m| 9/26 [00:11<00:20,  1.21s/it]Epoch: 6/10. Loss: 0.8572:  38%|[36m███▊      [0m| 10/26 [00:11<00:18,  1.14s/it]Epoch: 6/10. Loss: 0.8826:  38%|[36m███▊      [0m| 10/26 [00:13<00:18,  1.14s/it]Epoch: 6/10. Loss: 0.8826:  42%|[36m████▏     [0m| 11/26 [00:13<00:23,  1.54s/it]Epoch: 6/10. Loss: 0.7045:  42%|[36m████▏     [0m| 11/26 [00:15<00:23,  1.54s/it]Epoch: 6/10. Loss: 0.7045:  46%|[36m████▌     [0m| 12/26 [00:15<00:23,  1.66s/it]Epoch: 6/10. Loss: 0.8058:  46%|[36m████▌     [0m| 12/26 [00:16<00:23,  1.66s/it]Epoch: 6/10. Loss: 0.8058:  50%|[36m█████     [0m| 13/26 [00:16<00:18,  1.44s/it]Epoch: 6/10. Loss: 0.8419:  50%|[36m█████     [0m| 13/26 [00:17<00:18,  1.44s/it]Epoch: 6/10. Loss: 0.8419:  54%|[36m█████▍    [0m| 14/26 [00:18<00:16,  1.37s/it]Epoch: 6/10. Loss: 0.8239:  54%|[36m█████▍    [0m| 14/26 [00:19<00:16,  1.37s/it]Epoch: 6/10. Loss: 0.8239:  58%|[36m█████▊    [0m| 15/26 [00:19<00:16,  1.47s/it]Epoch: 6/10. Loss: 0.7623:  58%|[36m█████▊    [0m| 15/26 [00:20<00:16,  1.47s/it]Epoch: 6/10. Loss: 0.7623:  62%|[36m██████▏   [0m| 16/26 [00:20<00:13,  1.33s/it]Epoch: 6/10. Loss: 0.8268:  62%|[36m██████▏   [0m| 16/26 [00:21<00:13,  1.33s/it]Epoch: 6/10. Loss: 0.8268:  65%|[36m██████▌   [0m| 17/26 [00:21<00:11,  1.25s/it]Epoch: 6/10. Loss: 0.7898:  65%|[36m██████▌   [0m| 17/26 [00:24<00:11,  1.25s/it]Epoch: 6/10. Loss: 0.7898:  69%|[36m██████▉   [0m| 18/26 [00:24<00:13,  1.74s/it]Epoch: 6/10. Loss: 0.8165:  69%|[36m██████▉   [0m| 18/26 [00:27<00:13,  1.74s/it]Epoch: 6/10. Loss: 0.8165:  73%|[36m███████▎  [0m| 19/26 [00:27<00:14,  2.12s/it]Epoch: 6/10. Loss: 0.7579:  73%|[36m███████▎  [0m| 19/26 [00:30<00:14,  2.12s/it]Epoch: 6/10. Loss: 0.7579:  77%|[36m███████▋  [0m| 20/26 [00:30<00:13,  2.33s/it]Epoch: 6/10. Loss: 0.8411:  77%|[36m███████▋  [0m| 20/26 [00:31<00:13,  2.33s/it]Epoch: 6/10. Loss: 0.8411:  81%|[36m████████  [0m| 21/26 [00:31<00:09,  1.95s/it]Epoch: 6/10. Loss: 0.7404:  81%|[36m████████  [0m| 21/26 [00:32<00:09,  1.95s/it]Epoch: 6/10. Loss: 0.7404:  85%|[36m████████▍ [0m| 22/26 [00:32<00:06,  1.63s/it]Epoch: 6/10. Loss: 0.7652:  85%|[36m████████▍ [0m| 22/26 [00:33<00:06,  1.63s/it]Epoch: 6/10. Loss: 0.7652:  88%|[36m████████▊ [0m| 23/26 [00:33<00:04,  1.46s/it]Epoch: 6/10. Loss: 0.9154:  88%|[36m████████▊ [0m| 23/26 [00:34<00:04,  1.46s/it]Epoch: 6/10. Loss: 0.9154:  92%|[36m█████████▏[0m| 24/26 [00:34<00:02,  1.29s/it]Epoch: 6/10. Loss: 0.8131:  92%|[36m█████████▏[0m| 24/26 [00:35<00:02,  1.29s/it]Epoch: 6/10. Loss: 0.8131:  96%|[36m█████████▌[0m| 25/26 [00:35<00:01,  1.16s/it]Epoch: 6/10. Loss: 0.7973:  96%|[36m█████████▌[0m| 25/26 [00:35<00:01,  1.16s/it]Epoch: 6/10. Loss: 0.7973: 100%|[36m██████████[0m| 26/26 [00:35<00:00,  1.02it/s]Epoch: 6/10. Loss: 0.7973: 100%|[36m██████████[0m| 26/26 [00:35<00:00,  1.38s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:05,  1.09it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:05,  1.04s/it] 43%|[33m████▎     [0m| 3/7 [00:02<00:03,  1.08it/s] 57%|[33m█████▋    [0m| 4/7 [00:04<00:03,  1.07s/it] 71%|[33m███████▏  [0m| 5/7 [00:04<00:01,  1.18it/s] 86%|[33m████████▌ [0m| 6/7 [00:05<00:00,  1.14it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.47it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.21it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 7/10. Loss: 0.9134:   0%|[36m          [0m| 0/26 [00:01<?, ?it/s]Epoch: 7/10. Loss: 0.9134:   4%|[36m▍         [0m| 1/26 [00:01<00:27,  1.11s/it]Epoch: 7/10. Loss: 0.7416:   4%|[36m▍         [0m| 1/26 [00:02<00:27,  1.11s/it]Epoch: 7/10. Loss: 0.7416:   8%|[36m▊         [0m| 2/26 [00:02<00:30,  1.26s/it]Epoch: 7/10. Loss: 0.7949:   8%|[36m▊         [0m| 2/26 [00:03<00:30,  1.26s/it]Epoch: 7/10. Loss: 0.7949:  12%|[36m█▏        [0m| 3/26 [00:03<00:26,  1.13s/it]Epoch: 7/10. Loss: 0.7634:  12%|[36m█▏        [0m| 3/26 [00:04<00:26,  1.13s/it]Epoch: 7/10. Loss: 0.7634:  15%|[36m█▌        [0m| 4/26 [00:04<00:23,  1.05s/it]Epoch: 7/10. Loss: 0.7764:  15%|[36m█▌        [0m| 4/26 [00:05<00:23,  1.05s/it]Epoch: 7/10. Loss: 0.7764:  19%|[36m█▉        [0m| 5/26 [00:05<00:21,  1.02s/it]Epoch: 7/10. Loss: 0.8204:  19%|[36m█▉        [0m| 5/26 [00:06<00:21,  1.02s/it]Epoch: 7/10. Loss: 0.8204:  23%|[36m██▎       [0m| 6/26 [00:06<00:20,  1.05s/it]Epoch: 7/10. Loss: 0.8679:  23%|[36m██▎       [0m| 6/26 [00:07<00:20,  1.05s/it]Epoch: 7/10. Loss: 0.8679:  27%|[36m██▋       [0m| 7/26 [00:07<00:19,  1.01s/it]Epoch: 7/10. Loss: 0.7555:  27%|[36m██▋       [0m| 7/26 [00:08<00:19,  1.01s/it]Epoch: 7/10. Loss: 0.7555:  31%|[36m███       [0m| 8/26 [00:08<00:17,  1.01it/s]Epoch: 7/10. Loss: 0.6406:  31%|[36m███       [0m| 8/26 [00:09<00:17,  1.01it/s]Epoch: 7/10. Loss: 0.6406:  35%|[36m███▍      [0m| 9/26 [00:09<00:16,  1.04it/s]Epoch: 7/10. Loss: 0.7972:  35%|[36m███▍      [0m| 9/26 [00:10<00:16,  1.04it/s]Epoch: 7/10. Loss: 0.7972:  38%|[36m███▊      [0m| 10/26 [00:10<00:14,  1.09it/s]Epoch: 7/10. Loss: 0.8442:  38%|[36m███▊      [0m| 10/26 [00:11<00:14,  1.09it/s]Epoch: 7/10. Loss: 0.8442:  42%|[36m████▏     [0m| 11/26 [00:11<00:15,  1.01s/it]Epoch: 7/10. Loss: 0.7906:  42%|[36m████▏     [0m| 11/26 [00:12<00:15,  1.01s/it]Epoch: 7/10. Loss: 0.7906:  46%|[36m████▌     [0m| 12/26 [00:12<00:13,  1.04it/s]Epoch: 7/10. Loss: 0.7635:  46%|[36m████▌     [0m| 12/26 [00:13<00:13,  1.04it/s]Epoch: 7/10. Loss: 0.7635:  50%|[36m█████     [0m| 13/26 [00:13<00:12,  1.02it/s]Epoch: 7/10. Loss: 0.7988:  50%|[36m█████     [0m| 13/26 [00:14<00:12,  1.02it/s]Epoch: 7/10. Loss: 0.7988:  54%|[36m█████▍    [0m| 14/26 [00:14<00:11,  1.01it/s]Epoch: 7/10. Loss: 0.7593:  54%|[36m█████▍    [0m| 14/26 [00:14<00:11,  1.01it/s]Epoch: 7/10. Loss: 0.7593:  58%|[36m█████▊    [0m| 15/26 [00:14<00:10,  1.06it/s]Epoch: 7/10. Loss: 0.6920:  58%|[36m█████▊    [0m| 15/26 [00:15<00:10,  1.06it/s]Epoch: 7/10. Loss: 0.6920:  62%|[36m██████▏   [0m| 16/26 [00:16<00:09,  1.03it/s]Epoch: 7/10. Loss: 0.6978:  62%|[36m██████▏   [0m| 16/26 [00:17<00:09,  1.03it/s]Epoch: 7/10. Loss: 0.6978:  65%|[36m██████▌   [0m| 17/26 [00:17<00:08,  1.01it/s]Epoch: 7/10. Loss: 0.8214:  65%|[36m██████▌   [0m| 17/26 [00:18<00:08,  1.01it/s]Epoch: 7/10. Loss: 0.8214:  69%|[36m██████▉   [0m| 18/26 [00:18<00:08,  1.00s/it]Epoch: 7/10. Loss: 0.7407:  69%|[36m██████▉   [0m| 18/26 [00:19<00:08,  1.00s/it]Epoch: 7/10. Loss: 0.7407:  73%|[36m███████▎  [0m| 19/26 [00:19<00:06,  1.00it/s]Epoch: 7/10. Loss: 0.8028:  73%|[36m███████▎  [0m| 19/26 [00:20<00:06,  1.00it/s]Epoch: 7/10. Loss: 0.8028:  77%|[36m███████▋  [0m| 20/26 [00:20<00:06,  1.04s/it]Epoch: 7/10. Loss: 0.8021:  77%|[36m███████▋  [0m| 20/26 [00:21<00:06,  1.04s/it]Epoch: 7/10. Loss: 0.8021:  81%|[36m████████  [0m| 21/26 [00:21<00:05,  1.00s/it]Epoch: 7/10. Loss: 0.8182:  81%|[36m████████  [0m| 21/26 [00:21<00:05,  1.00s/it]Epoch: 7/10. Loss: 0.8182:  85%|[36m████████▍ [0m| 22/26 [00:22<00:03,  1.03it/s]Epoch: 7/10. Loss: 0.7488:  85%|[36m████████▍ [0m| 22/26 [00:23<00:03,  1.03it/s]Epoch: 7/10. Loss: 0.7488:  88%|[36m████████▊ [0m| 23/26 [00:23<00:02,  1.01it/s]Epoch: 7/10. Loss: 0.8561:  88%|[36m████████▊ [0m| 23/26 [00:24<00:02,  1.01it/s]Epoch: 7/10. Loss: 0.8561:  92%|[36m█████████▏[0m| 24/26 [00:24<00:02,  1.00s/it]Epoch: 7/10. Loss: 0.8859:  92%|[36m█████████▏[0m| 24/26 [00:25<00:02,  1.00s/it]Epoch: 7/10. Loss: 0.8859:  96%|[36m█████████▌[0m| 25/26 [00:25<00:01,  1.13s/it]Epoch: 7/10. Loss: 0.7576:  96%|[36m█████████▌[0m| 25/26 [00:26<00:01,  1.13s/it]Epoch: 7/10. Loss: 0.7576: 100%|[36m██████████[0m| 26/26 [00:26<00:00,  1.01s/it]Epoch: 7/10. Loss: 0.7576: 100%|[36m██████████[0m| 26/26 [00:26<00:00,  1.01s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:01<00:06,  1.02s/it] 29%|[33m██▊       [0m| 2/7 [00:02<00:06,  1.37s/it] 43%|[33m████▎     [0m| 3/7 [00:03<00:04,  1.11s/it] 57%|[33m█████▋    [0m| 4/7 [00:04<00:03,  1.24s/it] 71%|[33m███████▏  [0m| 5/7 [00:05<00:01,  1.03it/s] 86%|[33m████████▌ [0m| 6/7 [00:06<00:00,  1.07it/s]100%|[33m██████████[0m| 7/7 [00:06<00:00,  1.42it/s]100%|[33m██████████[0m| 7/7 [00:06<00:00,  1.08it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 8/10. Loss: 0.8118:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 8/10. Loss: 0.8118:   4%|[36m▍         [0m| 1/26 [00:00<00:23,  1.06it/s]Epoch: 8/10. Loss: 0.8787:   4%|[36m▍         [0m| 1/26 [00:01<00:23,  1.06it/s]Epoch: 8/10. Loss: 0.8787:   8%|[36m▊         [0m| 2/26 [00:01<00:23,  1.02it/s]Epoch: 8/10. Loss: 0.9174:   8%|[36m▊         [0m| 2/26 [00:02<00:23,  1.02it/s]Epoch: 8/10. Loss: 0.9174:  12%|[36m█▏        [0m| 3/26 [00:02<00:22,  1.01it/s]Epoch: 8/10. Loss: 0.7718:  12%|[36m█▏        [0m| 3/26 [00:04<00:22,  1.01it/s]Epoch: 8/10. Loss: 0.7718:  15%|[36m█▌        [0m| 4/26 [00:04<00:29,  1.35s/it]Epoch: 8/10. Loss: 0.7324:  15%|[36m█▌        [0m| 4/26 [00:06<00:29,  1.35s/it]Epoch: 8/10. Loss: 0.7324:  19%|[36m█▉        [0m| 5/26 [00:06<00:27,  1.33s/it]Epoch: 8/10. Loss: 0.7425:  19%|[36m█▉        [0m| 5/26 [00:07<00:27,  1.33s/it]Epoch: 8/10. Loss: 0.7425:  23%|[36m██▎       [0m| 6/26 [00:07<00:25,  1.29s/it]Epoch: 8/10. Loss: 0.7299:  23%|[36m██▎       [0m| 6/26 [00:08<00:25,  1.29s/it]Epoch: 8/10. Loss: 0.7299:  27%|[36m██▋       [0m| 7/26 [00:08<00:21,  1.16s/it]Epoch: 8/10. Loss: 0.7780:  27%|[36m██▋       [0m| 7/26 [00:09<00:21,  1.16s/it]Epoch: 8/10. Loss: 0.7780:  31%|[36m███       [0m| 8/26 [00:09<00:19,  1.08s/it]Epoch: 8/10. Loss: 0.6870:  31%|[36m███       [0m| 8/26 [00:11<00:19,  1.08s/it]Epoch: 8/10. Loss: 0.6870:  35%|[36m███▍      [0m| 9/26 [00:11<00:27,  1.59s/it]Epoch: 8/10. Loss: 0.6819:  35%|[36m███▍      [0m| 9/26 [00:12<00:27,  1.59s/it]Epoch: 8/10. Loss: 0.6819:  38%|[36m███▊      [0m| 10/26 [00:12<00:22,  1.39s/it]Epoch: 8/10. Loss: 0.6393:  38%|[36m███▊      [0m| 10/26 [00:13<00:22,  1.39s/it]Epoch: 8/10. Loss: 0.6393:  42%|[36m████▏     [0m| 11/26 [00:13<00:18,  1.23s/it]Epoch: 8/10. Loss: 0.7163:  42%|[36m████▏     [0m| 11/26 [00:14<00:18,  1.23s/it]Epoch: 8/10. Loss: 0.7163:  46%|[36m████▌     [0m| 12/26 [00:14<00:16,  1.21s/it]Epoch: 8/10. Loss: 0.8486:  46%|[36m████▌     [0m| 12/26 [00:15<00:16,  1.21s/it]Epoch: 8/10. Loss: 0.8486:  50%|[36m█████     [0m| 13/26 [00:15<00:14,  1.13s/it]Epoch: 8/10. Loss: 0.7713:  50%|[36m█████     [0m| 13/26 [00:16<00:14,  1.13s/it]Epoch: 8/10. Loss: 0.7713:  54%|[36m█████▍    [0m| 14/26 [00:16<00:13,  1.12s/it]Epoch: 8/10. Loss: 0.7728:  54%|[36m█████▍    [0m| 14/26 [00:17<00:13,  1.12s/it]Epoch: 8/10. Loss: 0.7728:  58%|[36m█████▊    [0m| 15/26 [00:17<00:11,  1.09s/it]Epoch: 8/10. Loss: 0.9285:  58%|[36m█████▊    [0m| 15/26 [00:18<00:11,  1.09s/it]Epoch: 8/10. Loss: 0.9285:  62%|[36m██████▏   [0m| 16/26 [00:18<00:10,  1.01s/it]Epoch: 8/10. Loss: 0.8377:  62%|[36m██████▏   [0m| 16/26 [00:19<00:10,  1.01s/it]Epoch: 8/10. Loss: 0.8377:  65%|[36m██████▌   [0m| 17/26 [00:19<00:08,  1.01it/s]Epoch: 8/10. Loss: 0.7382:  65%|[36m██████▌   [0m| 17/26 [00:20<00:08,  1.01it/s]Epoch: 8/10. Loss: 0.7382:  69%|[36m██████▉   [0m| 18/26 [00:20<00:07,  1.02it/s]Epoch: 8/10. Loss: 0.8393:  69%|[36m██████▉   [0m| 18/26 [00:21<00:07,  1.02it/s]Epoch: 8/10. Loss: 0.8393:  73%|[36m███████▎  [0m| 19/26 [00:21<00:06,  1.03it/s]Epoch: 8/10. Loss: 0.7165:  73%|[36m███████▎  [0m| 19/26 [00:22<00:06,  1.03it/s]Epoch: 8/10. Loss: 0.7165:  77%|[36m███████▋  [0m| 20/26 [00:22<00:05,  1.02it/s]Epoch: 8/10. Loss: 0.8721:  77%|[36m███████▋  [0m| 20/26 [00:23<00:05,  1.02it/s]Epoch: 8/10. Loss: 0.8721:  81%|[36m████████  [0m| 21/26 [00:23<00:04,  1.04it/s]Epoch: 8/10. Loss: 0.7750:  81%|[36m████████  [0m| 21/26 [00:24<00:04,  1.04it/s]Epoch: 8/10. Loss: 0.7750:  85%|[36m████████▍ [0m| 22/26 [00:24<00:03,  1.02it/s]Epoch: 8/10. Loss: 0.7515:  85%|[36m████████▍ [0m| 22/26 [00:25<00:03,  1.02it/s]Epoch: 8/10. Loss: 0.7515:  88%|[36m████████▊ [0m| 23/26 [00:25<00:02,  1.03it/s]Epoch: 8/10. Loss: 0.8024:  88%|[36m████████▊ [0m| 23/26 [00:26<00:02,  1.03it/s]Epoch: 8/10. Loss: 0.8024:  92%|[36m█████████▏[0m| 24/26 [00:26<00:01,  1.04it/s]Epoch: 8/10. Loss: 0.7105:  92%|[36m█████████▏[0m| 24/26 [00:27<00:01,  1.04it/s]Epoch: 8/10. Loss: 0.7105:  96%|[36m█████████▌[0m| 25/26 [00:27<00:00,  1.06it/s]Epoch: 8/10. Loss: 0.7842:  96%|[36m█████████▌[0m| 25/26 [00:28<00:00,  1.06it/s]Epoch: 8/10. Loss: 0.7842: 100%|[36m██████████[0m| 26/26 [00:28<00:00,  1.10it/s]Epoch: 8/10. Loss: 0.7842: 100%|[36m██████████[0m| 26/26 [00:28<00:00,  1.08s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:05,  1.09it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:05,  1.09s/it] 43%|[33m████▎     [0m| 3/7 [00:02<00:03,  1.03it/s] 57%|[33m█████▋    [0m| 4/7 [00:04<00:03,  1.23s/it] 71%|[33m███████▏  [0m| 5/7 [00:05<00:01,  1.03it/s] 86%|[33m████████▌ [0m| 6/7 [00:05<00:00,  1.07it/s]100%|[33m██████████[0m| 7/7 [00:06<00:00,  1.41it/s]100%|[33m██████████[0m| 7/7 [00:06<00:00,  1.13it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 9/10. Loss: 0.6614:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 9/10. Loss: 0.6614:   4%|[36m▍         [0m| 1/26 [00:00<00:22,  1.09it/s]Epoch: 9/10. Loss: 0.6872:   4%|[36m▍         [0m| 1/26 [00:01<00:22,  1.09it/s]Epoch: 9/10. Loss: 0.6872:   8%|[36m▊         [0m| 2/26 [00:01<00:22,  1.06it/s]Epoch: 9/10. Loss: 0.7309:   8%|[36m▊         [0m| 2/26 [00:04<00:22,  1.06it/s]Epoch: 9/10. Loss: 0.7309:  12%|[36m█▏        [0m| 3/26 [00:04<00:41,  1.82s/it]Epoch: 9/10. Loss: 0.9427:  12%|[36m█▏        [0m| 3/26 [00:05<00:41,  1.82s/it]Epoch: 9/10. Loss: 0.9427:  15%|[36m█▌        [0m| 4/26 [00:05<00:32,  1.46s/it]Epoch: 9/10. Loss: 0.7234:  15%|[36m█▌        [0m| 4/26 [00:07<00:32,  1.46s/it]Epoch: 9/10. Loss: 0.7234:  19%|[36m█▉        [0m| 5/26 [00:07<00:31,  1.51s/it]Epoch: 9/10. Loss: 0.7458:  19%|[36m█▉        [0m| 5/26 [00:08<00:31,  1.51s/it]Epoch: 9/10. Loss: 0.7458:  23%|[36m██▎       [0m| 6/26 [00:08<00:26,  1.34s/it]Epoch: 9/10. Loss: 0.7648:  23%|[36m██▎       [0m| 6/26 [00:09<00:26,  1.34s/it]Epoch: 9/10. Loss: 0.7648:  27%|[36m██▋       [0m| 7/26 [00:09<00:26,  1.38s/it]Epoch: 9/10. Loss: 0.6986:  27%|[36m██▋       [0m| 7/26 [00:10<00:26,  1.38s/it]Epoch: 9/10. Loss: 0.6986:  31%|[36m███       [0m| 8/26 [00:10<00:22,  1.24s/it]Epoch: 9/10. Loss: 0.7129:  31%|[36m███       [0m| 8/26 [00:11<00:22,  1.24s/it]Epoch: 9/10. Loss: 0.7129:  35%|[36m███▍      [0m| 9/26 [00:11<00:18,  1.11s/it]Epoch: 9/10. Loss: 0.6884:  35%|[36m███▍      [0m| 9/26 [00:13<00:18,  1.11s/it]Epoch: 9/10. Loss: 0.6884:  38%|[36m███▊      [0m| 10/26 [00:13<00:20,  1.28s/it]Epoch: 9/10. Loss: 0.8086:  38%|[36m███▊      [0m| 10/26 [00:14<00:20,  1.28s/it]Epoch: 9/10. Loss: 0.8086:  42%|[36m████▏     [0m| 11/26 [00:14<00:20,  1.40s/it]Epoch: 9/10. Loss: 0.7978:  42%|[36m████▏     [0m| 11/26 [00:15<00:20,  1.40s/it]Epoch: 9/10. Loss: 0.7978:  46%|[36m████▌     [0m| 12/26 [00:15<00:18,  1.33s/it]Epoch: 9/10. Loss: 0.7618:  46%|[36m████▌     [0m| 12/26 [00:17<00:18,  1.33s/it]Epoch: 9/10. Loss: 0.7618:  50%|[36m█████     [0m| 13/26 [00:17<00:16,  1.26s/it]Epoch: 9/10. Loss: 0.6579:  50%|[36m█████     [0m| 13/26 [00:17<00:16,  1.26s/it]Epoch: 9/10. Loss: 0.6579:  54%|[36m█████▍    [0m| 14/26 [00:17<00:13,  1.14s/it]Epoch: 9/10. Loss: 0.8247:  54%|[36m█████▍    [0m| 14/26 [00:18<00:13,  1.14s/it]Epoch: 9/10. Loss: 0.8247:  58%|[36m█████▊    [0m| 15/26 [00:18<00:11,  1.05s/it]Epoch: 9/10. Loss: 0.6827:  58%|[36m█████▊    [0m| 15/26 [00:20<00:11,  1.05s/it]Epoch: 9/10. Loss: 0.6827:  62%|[36m██████▏   [0m| 16/26 [00:20<00:13,  1.36s/it]Epoch: 9/10. Loss: 0.6538:  62%|[36m██████▏   [0m| 16/26 [00:21<00:13,  1.36s/it]Epoch: 9/10. Loss: 0.6538:  65%|[36m██████▌   [0m| 17/26 [00:21<00:11,  1.26s/it]Epoch: 9/10. Loss: 0.8238:  65%|[36m██████▌   [0m| 17/26 [00:22<00:11,  1.26s/it]Epoch: 9/10. Loss: 0.8238:  69%|[36m██████▉   [0m| 18/26 [00:22<00:09,  1.17s/it]Epoch: 9/10. Loss: 0.7519:  69%|[36m██████▉   [0m| 18/26 [00:23<00:09,  1.17s/it]Epoch: 9/10. Loss: 0.7519:  73%|[36m███████▎  [0m| 19/26 [00:23<00:07,  1.12s/it]Epoch: 9/10. Loss: 0.7967:  73%|[36m███████▎  [0m| 19/26 [00:24<00:07,  1.12s/it]Epoch: 9/10. Loss: 0.7967:  77%|[36m███████▋  [0m| 20/26 [00:24<00:06,  1.09s/it]Epoch: 9/10. Loss: 0.8092:  77%|[36m███████▋  [0m| 20/26 [00:26<00:06,  1.09s/it]Epoch: 9/10. Loss: 0.8092:  81%|[36m████████  [0m| 21/26 [00:26<00:06,  1.33s/it]Epoch: 9/10. Loss: 0.7838:  81%|[36m████████  [0m| 21/26 [00:28<00:06,  1.33s/it]Epoch: 9/10. Loss: 0.7838:  85%|[36m████████▍ [0m| 22/26 [00:28<00:06,  1.53s/it]Epoch: 9/10. Loss: 0.7700:  85%|[36m████████▍ [0m| 22/26 [00:29<00:06,  1.53s/it]Epoch: 9/10. Loss: 0.7700:  88%|[36m████████▊ [0m| 23/26 [00:29<00:04,  1.42s/it]Epoch: 9/10. Loss: 0.7147:  88%|[36m████████▊ [0m| 23/26 [00:30<00:04,  1.42s/it]Epoch: 9/10. Loss: 0.7147:  92%|[36m█████████▏[0m| 24/26 [00:30<00:02,  1.24s/it]Epoch: 9/10. Loss: 0.7701:  92%|[36m█████████▏[0m| 24/26 [00:32<00:02,  1.24s/it]Epoch: 9/10. Loss: 0.7701:  96%|[36m█████████▌[0m| 25/26 [00:32<00:01,  1.36s/it]Epoch: 9/10. Loss: 0.7761:  96%|[36m█████████▌[0m| 25/26 [00:32<00:01,  1.36s/it]Epoch: 9/10. Loss: 0.7761: 100%|[36m██████████[0m| 26/26 [00:32<00:00,  1.14s/it]Epoch: 9/10. Loss: 0.7761: 100%|[36m██████████[0m| 26/26 [00:32<00:00,  1.27s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:04,  1.23it/s] 29%|[33m██▊       [0m| 2/7 [00:01<00:04,  1.09it/s] 43%|[33m████▎     [0m| 3/7 [00:02<00:03,  1.22it/s] 57%|[33m█████▋    [0m| 4/7 [00:03<00:03,  1.03s/it] 71%|[33m███████▏  [0m| 5/7 [00:04<00:01,  1.18it/s] 86%|[33m████████▌ [0m| 6/7 [00:05<00:00,  1.15it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.50it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.26it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 0/10. Loss: 1.1746:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 0/10. Loss: 1.1746:   4%|[36m▍         [0m| 1/26 [00:00<00:23,  1.05it/s]Epoch: 0/10. Loss: 17.2118:   4%|[36m▍         [0m| 1/26 [00:01<00:23,  1.05it/s]Epoch: 0/10. Loss: 17.2118:   8%|[36m▊         [0m| 2/26 [00:01<00:20,  1.16it/s]Epoch: 0/10. Loss: 2.8104:   8%|[36m▊         [0m| 2/26 [00:02<00:20,  1.16it/s] Epoch: 0/10. Loss: 2.8104:  12%|[36m█▏        [0m| 3/26 [00:02<00:20,  1.13it/s]Epoch: 0/10. Loss: 1.6861:  12%|[36m█▏        [0m| 3/26 [00:03<00:20,  1.13it/s]Epoch: 0/10. Loss: 1.6861:  15%|[36m█▌        [0m| 4/26 [00:03<00:18,  1.16it/s]Epoch: 0/10. Loss: 3.2377:  15%|[36m█▌        [0m| 4/26 [00:04<00:18,  1.16it/s]Epoch: 0/10. Loss: 3.2377:  19%|[36m█▉        [0m| 5/26 [00:04<00:19,  1.09it/s]Epoch: 0/10. Loss: 5.0043:  19%|[36m█▉        [0m| 5/26 [00:05<00:19,  1.09it/s]Epoch: 0/10. Loss: 5.0043:  23%|[36m██▎       [0m| 6/26 [00:05<00:18,  1.07it/s]Epoch: 0/10. Loss: 3.0905:  23%|[36m██▎       [0m| 6/26 [00:06<00:18,  1.07it/s]Epoch: 0/10. Loss: 3.0905:  27%|[36m██▋       [0m| 7/26 [00:06<00:17,  1.09it/s]Epoch: 0/10. Loss: 3.6465:  27%|[36m██▋       [0m| 7/26 [00:08<00:17,  1.09it/s]Epoch: 0/10. Loss: 3.6465:  31%|[36m███       [0m| 8/26 [00:08<00:24,  1.37s/it]Epoch: 0/10. Loss: 1.5611:  31%|[36m███       [0m| 8/26 [00:09<00:24,  1.37s/it]Epoch: 0/10. Loss: 1.5611:  35%|[36m███▍      [0m| 9/26 [00:09<00:20,  1.21s/it]Epoch: 0/10. Loss: 1.2322:  35%|[36m███▍      [0m| 9/26 [00:10<00:20,  1.21s/it]Epoch: 0/10. Loss: 1.2322:  38%|[36m███▊      [0m| 10/26 [00:10<00:19,  1.23s/it]Epoch: 0/10. Loss: 3.3917:  38%|[36m███▊      [0m| 10/26 [00:11<00:19,  1.23s/it]Epoch: 0/10. Loss: 3.3917:  42%|[36m████▏     [0m| 11/26 [00:11<00:18,  1.21s/it]Epoch: 0/10. Loss: 2.5220:  42%|[36m████▏     [0m| 11/26 [00:12<00:18,  1.21s/it]Epoch: 0/10. Loss: 2.5220:  46%|[36m████▌     [0m| 12/26 [00:12<00:15,  1.13s/it]Epoch: 0/10. Loss: 1.8799:  46%|[36m████▌     [0m| 12/26 [00:13<00:15,  1.13s/it]Epoch: 0/10. Loss: 1.8799:  50%|[36m█████     [0m| 13/26 [00:13<00:14,  1.08s/it]Epoch: 0/10. Loss: 1.9231:  50%|[36m█████     [0m| 13/26 [00:14<00:14,  1.08s/it]Epoch: 0/10. Loss: 1.9231:  54%|[36m█████▍    [0m| 14/26 [00:14<00:12,  1.08s/it]Epoch: 0/10. Loss: 2.0070:  54%|[36m█████▍    [0m| 14/26 [00:15<00:12,  1.08s/it]Epoch: 0/10. Loss: 2.0070:  58%|[36m█████▊    [0m| 15/26 [00:15<00:11,  1.02s/it]Epoch: 0/10. Loss: 1.3087:  58%|[36m█████▊    [0m| 15/26 [00:17<00:11,  1.02s/it]Epoch: 0/10. Loss: 1.3087:  62%|[36m██████▏   [0m| 16/26 [00:17<00:10,  1.08s/it]Epoch: 0/10. Loss: 1.1367:  62%|[36m██████▏   [0m| 16/26 [00:17<00:10,  1.08s/it]Epoch: 0/10. Loss: 1.1367:  65%|[36m██████▌   [0m| 17/26 [00:17<00:09,  1.03s/it]Epoch: 0/10. Loss: 1.3160:  65%|[36m██████▌   [0m| 17/26 [00:19<00:09,  1.03s/it]Epoch: 0/10. Loss: 1.3160:  69%|[36m██████▉   [0m| 18/26 [00:19<00:08,  1.11s/it]Epoch: 0/10. Loss: 1.1739:  69%|[36m██████▉   [0m| 18/26 [00:20<00:08,  1.11s/it]Epoch: 0/10. Loss: 1.1739:  73%|[36m███████▎  [0m| 19/26 [00:20<00:07,  1.06s/it]Epoch: 0/10. Loss: 1.3010:  73%|[36m███████▎  [0m| 19/26 [00:21<00:07,  1.06s/it]Epoch: 0/10. Loss: 1.3010:  77%|[36m███████▋  [0m| 20/26 [00:21<00:06,  1.02s/it]Epoch: 0/10. Loss: 1.1967:  77%|[36m███████▋  [0m| 20/26 [00:23<00:06,  1.02s/it]Epoch: 0/10. Loss: 1.1967:  81%|[36m████████  [0m| 21/26 [00:23<00:06,  1.39s/it]Epoch: 0/10. Loss: 1.1837:  81%|[36m████████  [0m| 21/26 [00:24<00:06,  1.39s/it]Epoch: 0/10. Loss: 1.1837:  85%|[36m████████▍ [0m| 22/26 [00:24<00:04,  1.23s/it]Epoch: 0/10. Loss: 1.1290:  85%|[36m████████▍ [0m| 22/26 [00:25<00:04,  1.23s/it]Epoch: 0/10. Loss: 1.1290:  88%|[36m████████▊ [0m| 23/26 [00:25<00:03,  1.23s/it]Epoch: 0/10. Loss: 1.0537:  88%|[36m████████▊ [0m| 23/26 [00:26<00:03,  1.23s/it]Epoch: 0/10. Loss: 1.0537:  92%|[36m█████████▏[0m| 24/26 [00:26<00:02,  1.14s/it]Epoch: 0/10. Loss: 0.9485:  92%|[36m█████████▏[0m| 24/26 [00:27<00:02,  1.14s/it]Epoch: 0/10. Loss: 0.9485:  96%|[36m█████████▌[0m| 25/26 [00:27<00:01,  1.11s/it]Epoch: 0/10. Loss: 1.0603:  96%|[36m█████████▌[0m| 25/26 [00:28<00:01,  1.11s/it]Epoch: 0/10. Loss: 1.0603: 100%|[36m██████████[0m| 26/26 [00:28<00:00,  1.08s/it]Epoch: 0/10. Loss: 1.0603: 100%|[36m██████████[0m| 26/26 [00:28<00:00,  1.10s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:01<00:07,  1.18s/it] 29%|[33m██▊       [0m| 2/7 [00:02<00:06,  1.37s/it] 43%|[33m████▎     [0m| 3/7 [00:03<00:04,  1.08s/it] 57%|[33m█████▋    [0m| 4/7 [00:04<00:03,  1.17s/it] 71%|[33m███████▏  [0m| 5/7 [00:05<00:01,  1.09it/s] 86%|[33m████████▌ [0m| 6/7 [00:06<00:00,  1.10it/s]100%|[33m██████████[0m| 7/7 [00:06<00:00,  1.27it/s]100%|[33m██████████[0m| 7/7 [00:06<00:00,  1.06it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 1/10. Loss: 1.2549:   0%|[36m          [0m| 0/26 [00:01<?, ?it/s]Epoch: 1/10. Loss: 1.2549:   4%|[36m▍         [0m| 1/26 [00:01<00:27,  1.10s/it]Epoch: 1/10. Loss: 1.0473:   4%|[36m▍         [0m| 1/26 [00:01<00:27,  1.10s/it]Epoch: 1/10. Loss: 1.0473:   8%|[36m▊         [0m| 2/26 [00:01<00:23,  1.04it/s]Epoch: 1/10. Loss: 1.0622:   8%|[36m▊         [0m| 2/26 [00:02<00:23,  1.04it/s]Epoch: 1/10. Loss: 1.0622:  12%|[36m█▏        [0m| 3/26 [00:02<00:21,  1.07it/s]Epoch: 1/10. Loss: 1.0778:  12%|[36m█▏        [0m| 3/26 [00:04<00:21,  1.07it/s]Epoch: 1/10. Loss: 1.0778:  15%|[36m█▌        [0m| 4/26 [00:04<00:27,  1.26s/it]Epoch: 1/10. Loss: 1.1647:  15%|[36m█▌        [0m| 4/26 [00:05<00:27,  1.26s/it]Epoch: 1/10. Loss: 1.1647:  19%|[36m█▉        [0m| 5/26 [00:05<00:23,  1.13s/it]Epoch: 1/10. Loss: 1.0473:  19%|[36m█▉        [0m| 5/26 [00:06<00:23,  1.13s/it]Epoch: 1/10. Loss: 1.0473:  23%|[36m██▎       [0m| 6/26 [00:06<00:20,  1.04s/it]Epoch: 1/10. Loss: 0.9870:  23%|[36m██▎       [0m| 6/26 [00:07<00:20,  1.04s/it]Epoch: 1/10. Loss: 0.9870:  27%|[36m██▋       [0m| 7/26 [00:07<00:20,  1.09s/it]Epoch: 1/10. Loss: 0.9445:  27%|[36m██▋       [0m| 7/26 [00:08<00:20,  1.09s/it]Epoch: 1/10. Loss: 0.9445:  31%|[36m███       [0m| 8/26 [00:08<00:18,  1.05s/it]Epoch: 1/10. Loss: 1.0166:  31%|[36m███       [0m| 8/26 [00:09<00:18,  1.05s/it]Epoch: 1/10. Loss: 1.0166:  35%|[36m███▍      [0m| 9/26 [00:09<00:16,  1.00it/s]Epoch: 1/10. Loss: 1.4044:  35%|[36m███▍      [0m| 9/26 [00:10<00:16,  1.00it/s]Epoch: 1/10. Loss: 1.4044:  38%|[36m███▊      [0m| 10/26 [00:10<00:15,  1.04it/s]Epoch: 1/10. Loss: 1.3104:  38%|[36m███▊      [0m| 10/26 [00:11<00:15,  1.04it/s]Epoch: 1/10. Loss: 1.3104:  42%|[36m████▏     [0m| 11/26 [00:11<00:13,  1.09it/s]Epoch: 1/10. Loss: 1.0896:  42%|[36m████▏     [0m| 11/26 [00:12<00:13,  1.09it/s]Epoch: 1/10. Loss: 1.0896:  46%|[36m████▌     [0m| 12/26 [00:12<00:12,  1.08it/s]Epoch: 1/10. Loss: 0.9936:  46%|[36m████▌     [0m| 12/26 [00:14<00:12,  1.08it/s]Epoch: 1/10. Loss: 0.9936:  50%|[36m█████     [0m| 13/26 [00:14<00:16,  1.24s/it]Epoch: 1/10. Loss: 1.0060:  50%|[36m█████     [0m| 13/26 [00:14<00:16,  1.24s/it]Epoch: 1/10. Loss: 1.0060:  54%|[36m█████▍    [0m| 14/26 [00:14<00:13,  1.13s/it]Epoch: 1/10. Loss: 1.0295:  54%|[36m█████▍    [0m| 14/26 [00:15<00:13,  1.13s/it]Epoch: 1/10. Loss: 1.0295:  58%|[36m█████▊    [0m| 15/26 [00:15<00:12,  1.09s/it]Epoch: 1/10. Loss: 0.9710:  58%|[36m█████▊    [0m| 15/26 [00:16<00:12,  1.09s/it]Epoch: 1/10. Loss: 0.9710:  62%|[36m██████▏   [0m| 16/26 [00:16<00:10,  1.08s/it]Epoch: 1/10. Loss: 0.9994:  62%|[36m██████▏   [0m| 16/26 [00:17<00:10,  1.08s/it]Epoch: 1/10. Loss: 0.9994:  65%|[36m██████▌   [0m| 17/26 [00:17<00:09,  1.03s/it]Epoch: 1/10. Loss: 1.0082:  65%|[36m██████▌   [0m| 17/26 [00:19<00:09,  1.03s/it]Epoch: 1/10. Loss: 1.0082:  69%|[36m██████▉   [0m| 18/26 [00:19<00:09,  1.15s/it]Epoch: 1/10. Loss: 0.9606:  69%|[36m██████▉   [0m| 18/26 [00:20<00:09,  1.15s/it]Epoch: 1/10. Loss: 0.9606:  73%|[36m███████▎  [0m| 19/26 [00:20<00:07,  1.11s/it]Epoch: 1/10. Loss: 1.0683:  73%|[36m███████▎  [0m| 19/26 [00:21<00:07,  1.11s/it]Epoch: 1/10. Loss: 1.0683:  77%|[36m███████▋  [0m| 20/26 [00:21<00:06,  1.03s/it]Epoch: 1/10. Loss: 1.0776:  77%|[36m███████▋  [0m| 20/26 [00:22<00:06,  1.03s/it]Epoch: 1/10. Loss: 1.0776:  81%|[36m████████  [0m| 21/26 [00:22<00:04,  1.01it/s]Epoch: 1/10. Loss: 1.0164:  81%|[36m████████  [0m| 21/26 [00:23<00:04,  1.01it/s]Epoch: 1/10. Loss: 1.0164:  85%|[36m████████▍ [0m| 22/26 [00:23<00:04,  1.07s/it]Epoch: 1/10. Loss: 0.9446:  85%|[36m████████▍ [0m| 22/26 [00:24<00:04,  1.07s/it]Epoch: 1/10. Loss: 0.9446:  88%|[36m████████▊ [0m| 23/26 [00:24<00:03,  1.13s/it]Epoch: 1/10. Loss: 0.9992:  88%|[36m████████▊ [0m| 23/26 [00:25<00:03,  1.13s/it]Epoch: 1/10. Loss: 0.9992:  92%|[36m█████████▏[0m| 24/26 [00:25<00:02,  1.04s/it]Epoch: 1/10. Loss: 0.9915:  92%|[36m█████████▏[0m| 24/26 [00:26<00:02,  1.04s/it]Epoch: 1/10. Loss: 0.9915:  96%|[36m█████████▌[0m| 25/26 [00:26<00:01,  1.02s/it]Epoch: 1/10. Loss: 1.0426:  96%|[36m█████████▌[0m| 25/26 [00:27<00:01,  1.02s/it]Epoch: 1/10. Loss: 1.0426: 100%|[36m██████████[0m| 26/26 [00:27<00:00,  1.09it/s]Epoch: 1/10. Loss: 1.0426: 100%|[36m██████████[0m| 26/26 [00:27<00:00,  1.04s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:05,  1.12it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:06,  1.24s/it] 43%|[33m████▎     [0m| 3/7 [00:03<00:04,  1.03s/it] 57%|[33m█████▋    [0m| 4/7 [00:04<00:03,  1.14s/it] 71%|[33m███████▏  [0m| 5/7 [00:04<00:01,  1.11it/s] 86%|[33m████████▌ [0m| 6/7 [00:05<00:00,  1.10it/s]100%|[33m██████████[0m| 7/7 [00:06<00:00,  1.37it/s]100%|[33m██████████[0m| 7/7 [00:06<00:00,  1.12it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 2/10. Loss: 1.0057:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 2/10. Loss: 1.0057:   4%|[36m▍         [0m| 1/26 [00:00<00:20,  1.20it/s]Epoch: 2/10. Loss: 1.0595:   4%|[36m▍         [0m| 1/26 [00:02<00:20,  1.20it/s]Epoch: 2/10. Loss: 1.0595:   8%|[36m▊         [0m| 2/26 [00:02<00:29,  1.24s/it]Epoch: 2/10. Loss: 1.0508:   8%|[36m▊         [0m| 2/26 [00:03<00:29,  1.24s/it]Epoch: 2/10. Loss: 1.0508:  12%|[36m█▏        [0m| 3/26 [00:03<00:24,  1.08s/it]Epoch: 2/10. Loss: 1.0285:  12%|[36m█▏        [0m| 3/26 [00:04<00:24,  1.08s/it]Epoch: 2/10. Loss: 1.0285:  15%|[36m█▌        [0m| 4/26 [00:04<00:22,  1.02s/it]Epoch: 2/10. Loss: 1.0862:  15%|[36m█▌        [0m| 4/26 [00:05<00:22,  1.02s/it]Epoch: 2/10. Loss: 1.0862:  19%|[36m█▉        [0m| 5/26 [00:05<00:20,  1.05it/s]Epoch: 2/10. Loss: 1.0333:  19%|[36m█▉        [0m| 5/26 [00:05<00:20,  1.05it/s]Epoch: 2/10. Loss: 1.0333:  23%|[36m██▎       [0m| 6/26 [00:05<00:18,  1.06it/s]Epoch: 2/10. Loss: 1.0429:  23%|[36m██▎       [0m| 6/26 [00:07<00:18,  1.06it/s]Epoch: 2/10. Loss: 1.0429:  27%|[36m██▋       [0m| 7/26 [00:07<00:21,  1.13s/it]Epoch: 2/10. Loss: 0.9239:  27%|[36m██▋       [0m| 7/26 [00:08<00:21,  1.13s/it]Epoch: 2/10. Loss: 0.9239:  31%|[36m███       [0m| 8/26 [00:08<00:19,  1.06s/it]Epoch: 2/10. Loss: 1.0434:  31%|[36m███       [0m| 8/26 [00:09<00:19,  1.06s/it]Epoch: 2/10. Loss: 1.0434:  35%|[36m███▍      [0m| 9/26 [00:09<00:18,  1.10s/it]Epoch: 2/10. Loss: 0.9844:  35%|[36m███▍      [0m| 9/26 [00:10<00:18,  1.10s/it]Epoch: 2/10. Loss: 0.9844:  38%|[36m███▊      [0m| 10/26 [00:10<00:17,  1.10s/it]Epoch: 2/10. Loss: 1.1239:  38%|[36m███▊      [0m| 10/26 [00:11<00:17,  1.10s/it]Epoch: 2/10. Loss: 1.1239:  42%|[36m████▏     [0m| 11/26 [00:11<00:15,  1.03s/it]Epoch: 2/10. Loss: 0.9365:  42%|[36m████▏     [0m| 11/26 [00:12<00:15,  1.03s/it]Epoch: 2/10. Loss: 0.9365:  46%|[36m████▌     [0m| 12/26 [00:12<00:13,  1.04it/s]Epoch: 2/10. Loss: 0.9959:  46%|[36m████▌     [0m| 12/26 [00:13<00:13,  1.04it/s]Epoch: 2/10. Loss: 0.9959:  50%|[36m█████     [0m| 13/26 [00:13<00:12,  1.03it/s]Epoch: 2/10. Loss: 0.9454:  50%|[36m█████     [0m| 13/26 [00:14<00:12,  1.03it/s]Epoch: 2/10. Loss: 0.9454:  54%|[36m█████▍    [0m| 14/26 [00:14<00:11,  1.04it/s]Epoch: 2/10. Loss: 0.9683:  54%|[36m█████▍    [0m| 14/26 [00:15<00:11,  1.04it/s]Epoch: 2/10. Loss: 0.9683:  58%|[36m█████▊    [0m| 15/26 [00:15<00:11,  1.02s/it]Epoch: 2/10. Loss: 0.9443:  58%|[36m█████▊    [0m| 15/26 [00:16<00:11,  1.02s/it]Epoch: 2/10. Loss: 0.9443:  62%|[36m██████▏   [0m| 16/26 [00:16<00:10,  1.01s/it]Epoch: 2/10. Loss: 1.0399:  62%|[36m██████▏   [0m| 16/26 [00:17<00:10,  1.01s/it]Epoch: 2/10. Loss: 1.0399:  65%|[36m██████▌   [0m| 17/26 [00:17<00:08,  1.05it/s]Epoch: 2/10. Loss: 0.9870:  65%|[36m██████▌   [0m| 17/26 [00:18<00:08,  1.05it/s]Epoch: 2/10. Loss: 0.9870:  69%|[36m██████▉   [0m| 18/26 [00:18<00:07,  1.06it/s]Epoch: 2/10. Loss: 0.9641:  69%|[36m██████▉   [0m| 18/26 [00:18<00:07,  1.06it/s]Epoch: 2/10. Loss: 0.9641:  73%|[36m███████▎  [0m| 19/26 [00:18<00:06,  1.10it/s]Epoch: 2/10. Loss: 1.0045:  73%|[36m███████▎  [0m| 19/26 [00:20<00:06,  1.10it/s]Epoch: 2/10. Loss: 1.0045:  77%|[36m███████▋  [0m| 20/26 [00:20<00:06,  1.02s/it]Epoch: 2/10. Loss: 0.8996:  77%|[36m███████▋  [0m| 20/26 [00:21<00:06,  1.02s/it]Epoch: 2/10. Loss: 0.8996:  81%|[36m████████  [0m| 21/26 [00:21<00:05,  1.03s/it]Epoch: 2/10. Loss: 0.9895:  81%|[36m████████  [0m| 21/26 [00:22<00:05,  1.03s/it]Epoch: 2/10. Loss: 0.9895:  85%|[36m████████▍ [0m| 22/26 [00:22<00:03,  1.00it/s]Epoch: 2/10. Loss: 0.9848:  85%|[36m████████▍ [0m| 22/26 [00:23<00:03,  1.00it/s]Epoch: 2/10. Loss: 0.9848:  88%|[36m████████▊ [0m| 23/26 [00:23<00:02,  1.04it/s]Epoch: 2/10. Loss: 0.9659:  88%|[36m████████▊ [0m| 23/26 [00:23<00:02,  1.04it/s]Epoch: 2/10. Loss: 0.9659:  92%|[36m█████████▏[0m| 24/26 [00:23<00:01,  1.07it/s]Epoch: 2/10. Loss: 1.0170:  92%|[36m█████████▏[0m| 24/26 [00:24<00:01,  1.07it/s]Epoch: 2/10. Loss: 1.0170:  96%|[36m█████████▌[0m| 25/26 [00:24<00:00,  1.07it/s]Epoch: 2/10. Loss: 0.9629:  96%|[36m█████████▌[0m| 25/26 [00:27<00:00,  1.07it/s]Epoch: 2/10. Loss: 0.9629: 100%|[36m██████████[0m| 26/26 [00:27<00:00,  1.32s/it]Epoch: 2/10. Loss: 0.9629: 100%|[36m██████████[0m| 26/26 [00:27<00:00,  1.04s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:01<00:07,  1.25s/it] 29%|[33m██▊       [0m| 2/7 [00:02<00:07,  1.45s/it] 43%|[33m████▎     [0m| 3/7 [00:03<00:04,  1.12s/it] 57%|[33m█████▋    [0m| 4/7 [00:05<00:04,  1.41s/it] 71%|[33m███████▏  [0m| 5/7 [00:05<00:02,  1.08s/it] 86%|[33m████████▌ [0m| 6/7 [00:06<00:01,  1.03s/it]100%|[33m██████████[0m| 7/7 [00:07<00:00,  1.25it/s]100%|[33m██████████[0m| 7/7 [00:07<00:00,  1.02s/it]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 3/10. Loss: 0.9149:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 3/10. Loss: 0.9149:   4%|[36m▍         [0m| 1/26 [00:00<00:24,  1.02it/s]Epoch: 3/10. Loss: 0.9296:   4%|[36m▍         [0m| 1/26 [00:02<00:24,  1.02it/s]Epoch: 3/10. Loss: 0.9296:   8%|[36m▊         [0m| 2/26 [00:02<00:24,  1.03s/it]Epoch: 3/10. Loss: 1.0114:   8%|[36m▊         [0m| 2/26 [00:02<00:24,  1.03s/it]Epoch: 3/10. Loss: 1.0114:  12%|[36m█▏        [0m| 3/26 [00:02<00:20,  1.10it/s]Epoch: 3/10. Loss: 1.0600:  12%|[36m█▏        [0m| 3/26 [00:03<00:20,  1.10it/s]Epoch: 3/10. Loss: 1.0600:  15%|[36m█▌        [0m| 4/26 [00:03<00:20,  1.09it/s]Epoch: 3/10. Loss: 0.9546:  15%|[36m█▌        [0m| 4/26 [00:04<00:20,  1.09it/s]Epoch: 3/10. Loss: 0.9546:  19%|[36m█▉        [0m| 5/26 [00:04<00:18,  1.11it/s]Epoch: 3/10. Loss: 0.9452:  19%|[36m█▉        [0m| 5/26 [00:05<00:18,  1.11it/s]Epoch: 3/10. Loss: 0.9452:  23%|[36m██▎       [0m| 6/26 [00:05<00:17,  1.13it/s]Epoch: 3/10. Loss: 1.0113:  23%|[36m██▎       [0m| 6/26 [00:07<00:17,  1.13it/s]Epoch: 3/10. Loss: 1.0113:  27%|[36m██▋       [0m| 7/26 [00:07<00:24,  1.27s/it]Epoch: 3/10. Loss: 1.0136:  27%|[36m██▋       [0m| 7/26 [00:08<00:24,  1.27s/it]Epoch: 3/10. Loss: 1.0136:  31%|[36m███       [0m| 8/26 [00:08<00:23,  1.32s/it]Epoch: 3/10. Loss: 0.9849:  31%|[36m███       [0m| 8/26 [00:10<00:23,  1.32s/it]Epoch: 3/10. Loss: 0.9849:  35%|[36m███▍      [0m| 9/26 [00:10<00:23,  1.36s/it]Epoch: 3/10. Loss: 0.9413:  35%|[36m███▍      [0m| 9/26 [00:11<00:23,  1.36s/it]Epoch: 3/10. Loss: 0.9413:  38%|[36m███▊      [0m| 10/26 [00:11<00:19,  1.19s/it]Epoch: 3/10. Loss: 1.0106:  38%|[36m███▊      [0m| 10/26 [00:12<00:19,  1.19s/it]Epoch: 3/10. Loss: 1.0106:  42%|[36m████▏     [0m| 11/26 [00:12<00:17,  1.14s/it]Epoch: 3/10. Loss: 0.9090:  42%|[36m████▏     [0m| 11/26 [00:13<00:17,  1.14s/it]Epoch: 3/10. Loss: 0.9090:  46%|[36m████▌     [0m| 12/26 [00:13<00:15,  1.10s/it]Epoch: 3/10. Loss: 1.0122:  46%|[36m████▌     [0m| 12/26 [00:14<00:15,  1.10s/it]Epoch: 3/10. Loss: 1.0122:  50%|[36m█████     [0m| 13/26 [00:14<00:14,  1.08s/it]Epoch: 3/10. Loss: 1.0146:  50%|[36m█████     [0m| 13/26 [00:15<00:14,  1.08s/it]Epoch: 3/10. Loss: 1.0146:  54%|[36m█████▍    [0m| 14/26 [00:15<00:12,  1.05s/it]Epoch: 3/10. Loss: 0.9745:  54%|[36m█████▍    [0m| 14/26 [00:16<00:12,  1.05s/it]Epoch: 3/10. Loss: 0.9745:  58%|[36m█████▊    [0m| 15/26 [00:16<00:11,  1.03s/it]Epoch: 3/10. Loss: 0.9728:  58%|[36m█████▊    [0m| 15/26 [00:17<00:11,  1.03s/it]Epoch: 3/10. Loss: 0.9728:  62%|[36m██████▏   [0m| 16/26 [00:17<00:09,  1.04it/s]Epoch: 3/10. Loss: 0.9973:  62%|[36m██████▏   [0m| 16/26 [00:18<00:09,  1.04it/s]Epoch: 3/10. Loss: 0.9973:  65%|[36m██████▌   [0m| 17/26 [00:18<00:08,  1.01it/s]Epoch: 3/10. Loss: 1.0005:  65%|[36m██████▌   [0m| 17/26 [00:21<00:08,  1.01it/s]Epoch: 3/10. Loss: 1.0005:  69%|[36m██████▉   [0m| 18/26 [00:21<00:12,  1.60s/it]Epoch: 3/10. Loss: 0.9158:  69%|[36m██████▉   [0m| 18/26 [00:22<00:12,  1.60s/it]Epoch: 3/10. Loss: 0.9158:  73%|[36m███████▎  [0m| 19/26 [00:22<00:10,  1.44s/it]Epoch: 3/10. Loss: 1.0391:  73%|[36m███████▎  [0m| 19/26 [00:23<00:10,  1.44s/it]Epoch: 3/10. Loss: 1.0391:  77%|[36m███████▋  [0m| 20/26 [00:23<00:08,  1.38s/it]Epoch: 3/10. Loss: 0.9661:  77%|[36m███████▋  [0m| 20/26 [00:24<00:08,  1.38s/it]Epoch: 3/10. Loss: 0.9661:  81%|[36m████████  [0m| 21/26 [00:24<00:05,  1.19s/it]Epoch: 3/10. Loss: 1.0157:  81%|[36m████████  [0m| 21/26 [00:25<00:05,  1.19s/it]Epoch: 3/10. Loss: 1.0157:  85%|[36m████████▍ [0m| 22/26 [00:25<00:04,  1.15s/it]Epoch: 3/10. Loss: 0.9617:  85%|[36m████████▍ [0m| 22/26 [00:26<00:04,  1.15s/it]Epoch: 3/10. Loss: 0.9617:  88%|[36m████████▊ [0m| 23/26 [00:26<00:03,  1.18s/it]Epoch: 3/10. Loss: 0.9949:  88%|[36m████████▊ [0m| 23/26 [00:27<00:03,  1.18s/it]Epoch: 3/10. Loss: 0.9949:  92%|[36m█████████▏[0m| 24/26 [00:27<00:02,  1.14s/it]Epoch: 3/10. Loss: 0.8966:  92%|[36m█████████▏[0m| 24/26 [00:28<00:02,  1.14s/it]Epoch: 3/10. Loss: 0.8966:  96%|[36m█████████▌[0m| 25/26 [00:28<00:01,  1.16s/it]Epoch: 3/10. Loss: 0.8727:  96%|[36m█████████▌[0m| 25/26 [00:29<00:01,  1.16s/it]Epoch: 3/10. Loss: 0.8727: 100%|[36m██████████[0m| 26/26 [00:29<00:00,  1.05s/it]Epoch: 3/10. Loss: 0.8727: 100%|[36m██████████[0m| 26/26 [00:29<00:00,  1.14s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:01<00:06,  1.10s/it] 29%|[33m██▊       [0m| 2/7 [00:02<00:06,  1.31s/it] 43%|[33m████▎     [0m| 3/7 [00:03<00:04,  1.06s/it] 57%|[33m█████▋    [0m| 4/7 [00:04<00:03,  1.17s/it] 71%|[33m███████▏  [0m| 5/7 [00:05<00:01,  1.00it/s] 86%|[33m████████▌ [0m| 6/7 [00:06<00:00,  1.04it/s]100%|[33m██████████[0m| 7/7 [00:07<00:00,  1.12s/it]100%|[33m██████████[0m| 7/7 [00:07<00:00,  1.10s/it]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 4/10. Loss: 1.0293:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 4/10. Loss: 1.0293:   4%|[36m▍         [0m| 1/26 [00:00<00:23,  1.06it/s]Epoch: 4/10. Loss: 0.9146:   4%|[36m▍         [0m| 1/26 [00:02<00:23,  1.06it/s]Epoch: 4/10. Loss: 0.9146:   8%|[36m▊         [0m| 2/26 [00:02<00:36,  1.51s/it]Epoch: 4/10. Loss: 0.9894:   8%|[36m▊         [0m| 2/26 [00:03<00:36,  1.51s/it]Epoch: 4/10. Loss: 0.9894:  12%|[36m█▏        [0m| 3/26 [00:03<00:30,  1.31s/it]Epoch: 4/10. Loss: 0.8987:  12%|[36m█▏        [0m| 3/26 [00:04<00:30,  1.31s/it]Epoch: 4/10. Loss: 0.8987:  15%|[36m█▌        [0m| 4/26 [00:04<00:26,  1.21s/it]Epoch: 4/10. Loss: 0.9063:  15%|[36m█▌        [0m| 4/26 [00:05<00:26,  1.21s/it]Epoch: 4/10. Loss: 0.9063:  19%|[36m█▉        [0m| 5/26 [00:05<00:22,  1.06s/it]Epoch: 4/10. Loss: 0.9925:  19%|[36m█▉        [0m| 5/26 [00:07<00:22,  1.06s/it]Epoch: 4/10. Loss: 0.9925:  23%|[36m██▎       [0m| 6/26 [00:07<00:23,  1.19s/it]Epoch: 4/10. Loss: 1.0787:  23%|[36m██▎       [0m| 6/26 [00:09<00:23,  1.19s/it]Epoch: 4/10. Loss: 1.0787:  27%|[36m██▋       [0m| 7/26 [00:09<00:27,  1.47s/it]Epoch: 4/10. Loss: 0.9034:  27%|[36m██▋       [0m| 7/26 [00:10<00:27,  1.47s/it]Epoch: 4/10. Loss: 0.9034:  31%|[36m███       [0m| 8/26 [00:10<00:22,  1.24s/it]Epoch: 4/10. Loss: 0.9290:  31%|[36m███       [0m| 8/26 [00:10<00:22,  1.24s/it]Epoch: 4/10. Loss: 0.9290:  35%|[36m███▍      [0m| 9/26 [00:10<00:19,  1.14s/it]Epoch: 4/10. Loss: 0.9119:  35%|[36m███▍      [0m| 9/26 [00:11<00:19,  1.14s/it]Epoch: 4/10. Loss: 0.9119:  38%|[36m███▊      [0m| 10/26 [00:11<00:16,  1.02s/it]Epoch: 4/10. Loss: 0.9287:  38%|[36m███▊      [0m| 10/26 [00:12<00:16,  1.02s/it]Epoch: 4/10. Loss: 0.9287:  42%|[36m████▏     [0m| 11/26 [00:12<00:14,  1.01it/s]Epoch: 4/10. Loss: 0.9924:  42%|[36m████▏     [0m| 11/26 [00:13<00:14,  1.01it/s]Epoch: 4/10. Loss: 0.9924:  46%|[36m████▌     [0m| 12/26 [00:13<00:13,  1.03it/s]Epoch: 4/10. Loss: 0.9715:  46%|[36m████▌     [0m| 12/26 [00:14<00:13,  1.03it/s]Epoch: 4/10. Loss: 0.9715:  50%|[36m█████     [0m| 13/26 [00:14<00:12,  1.07it/s]Epoch: 4/10. Loss: 0.9939:  50%|[36m█████     [0m| 13/26 [00:15<00:12,  1.07it/s]Epoch: 4/10. Loss: 0.9939:  54%|[36m█████▍    [0m| 14/26 [00:15<00:11,  1.08it/s]Epoch: 4/10. Loss: 0.9572:  54%|[36m█████▍    [0m| 14/26 [00:16<00:11,  1.08it/s]Epoch: 4/10. Loss: 0.9572:  58%|[36m█████▊    [0m| 15/26 [00:16<00:10,  1.06it/s]Epoch: 4/10. Loss: 0.9580:  58%|[36m█████▊    [0m| 15/26 [00:17<00:10,  1.06it/s]Epoch: 4/10. Loss: 0.9580:  62%|[36m██████▏   [0m| 16/26 [00:17<00:09,  1.08it/s]Epoch: 4/10. Loss: 0.9856:  62%|[36m██████▏   [0m| 16/26 [00:18<00:09,  1.08it/s]Epoch: 4/10. Loss: 0.9856:  65%|[36m██████▌   [0m| 17/26 [00:18<00:08,  1.06it/s]Epoch: 4/10. Loss: 0.9658:  65%|[36m██████▌   [0m| 17/26 [00:19<00:08,  1.06it/s]Epoch: 4/10. Loss: 0.9658:  69%|[36m██████▉   [0m| 18/26 [00:19<00:07,  1.05it/s]Epoch: 4/10. Loss: 0.9891:  69%|[36m██████▉   [0m| 18/26 [00:19<00:07,  1.05it/s]Epoch: 4/10. Loss: 0.9891:  73%|[36m███████▎  [0m| 19/26 [00:19<00:06,  1.09it/s]Epoch: 4/10. Loss: 1.1268:  73%|[36m███████▎  [0m| 19/26 [00:20<00:06,  1.09it/s]Epoch: 4/10. Loss: 1.1268:  77%|[36m███████▋  [0m| 20/26 [00:20<00:05,  1.05it/s]Epoch: 4/10. Loss: 1.1085:  77%|[36m███████▋  [0m| 20/26 [00:21<00:05,  1.05it/s]Epoch: 4/10. Loss: 1.1085:  81%|[36m████████  [0m| 21/26 [00:21<00:04,  1.07it/s]Epoch: 4/10. Loss: 0.9059:  81%|[36m████████  [0m| 21/26 [00:23<00:04,  1.07it/s]Epoch: 4/10. Loss: 0.9059:  85%|[36m████████▍ [0m| 22/26 [00:23<00:05,  1.29s/it]Epoch: 4/10. Loss: 1.0779:  85%|[36m████████▍ [0m| 22/26 [00:26<00:05,  1.29s/it]Epoch: 4/10. Loss: 1.0779:  88%|[36m████████▊ [0m| 23/26 [00:27<00:05,  1.81s/it]Epoch: 4/10. Loss: 0.9496:  88%|[36m████████▊ [0m| 23/26 [00:28<00:05,  1.81s/it]Epoch: 4/10. Loss: 0.9496:  92%|[36m█████████▏[0m| 24/26 [00:28<00:03,  1.64s/it]Epoch: 4/10. Loss: 0.9807:  92%|[36m█████████▏[0m| 24/26 [00:29<00:03,  1.64s/it]Epoch: 4/10. Loss: 0.9807:  96%|[36m█████████▌[0m| 25/26 [00:29<00:01,  1.46s/it]Epoch: 4/10. Loss: 0.8087:  96%|[36m█████████▌[0m| 25/26 [00:29<00:01,  1.46s/it]Epoch: 4/10. Loss: 0.8087: 100%|[36m██████████[0m| 26/26 [00:29<00:00,  1.21s/it]Epoch: 4/10. Loss: 0.8087: 100%|[36m██████████[0m| 26/26 [00:29<00:00,  1.15s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:04,  1.29it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:05,  1.16s/it] 43%|[33m████▎     [0m| 3/7 [00:02<00:03,  1.07it/s] 57%|[33m█████▋    [0m| 4/7 [00:04<00:03,  1.06s/it] 71%|[33m███████▏  [0m| 5/7 [00:04<00:01,  1.17it/s] 86%|[33m████████▌ [0m| 6/7 [00:05<00:00,  1.14it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.44it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.20it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 5/10. Loss: 1.1361:   0%|[36m          [0m| 0/26 [00:01<?, ?it/s]Epoch: 5/10. Loss: 1.1361:   4%|[36m▍         [0m| 1/26 [00:01<00:30,  1.21s/it]Epoch: 5/10. Loss: 0.8560:   4%|[36m▍         [0m| 1/26 [00:02<00:30,  1.21s/it]Epoch: 5/10. Loss: 0.8560:   8%|[36m▊         [0m| 2/26 [00:02<00:23,  1.02it/s]Epoch: 5/10. Loss: 1.0154:   8%|[36m▊         [0m| 2/26 [00:03<00:23,  1.02it/s]Epoch: 5/10. Loss: 1.0154:  12%|[36m█▏        [0m| 3/26 [00:03<00:30,  1.31s/it]Epoch: 5/10. Loss: 0.9613:  12%|[36m█▏        [0m| 3/26 [00:04<00:30,  1.31s/it]Epoch: 5/10. Loss: 0.9613:  15%|[36m█▌        [0m| 4/26 [00:04<00:24,  1.10s/it]Epoch: 5/10. Loss: 1.0721:  15%|[36m█▌        [0m| 4/26 [00:05<00:24,  1.10s/it]Epoch: 5/10. Loss: 1.0721:  19%|[36m█▉        [0m| 5/26 [00:05<00:22,  1.06s/it]Epoch: 5/10. Loss: 1.0641:  19%|[36m█▉        [0m| 5/26 [00:06<00:22,  1.06s/it]Epoch: 5/10. Loss: 1.0641:  23%|[36m██▎       [0m| 6/26 [00:06<00:22,  1.15s/it]Epoch: 5/10. Loss: 1.0429:  23%|[36m██▎       [0m| 6/26 [00:07<00:22,  1.15s/it]Epoch: 5/10. Loss: 1.0429:  27%|[36m██▋       [0m| 7/26 [00:07<00:21,  1.11s/it]Epoch: 5/10. Loss: 0.9559:  27%|[36m██▋       [0m| 7/26 [00:08<00:21,  1.11s/it]Epoch: 5/10. Loss: 0.9559:  31%|[36m███       [0m| 8/26 [00:08<00:18,  1.03s/it]Epoch: 5/10. Loss: 1.0442:  31%|[36m███       [0m| 8/26 [00:09<00:18,  1.03s/it]Epoch: 5/10. Loss: 1.0442:  35%|[36m███▍      [0m| 9/26 [00:09<00:16,  1.03it/s]Epoch: 5/10. Loss: 1.0364:  35%|[36m███▍      [0m| 9/26 [00:10<00:16,  1.03it/s]Epoch: 5/10. Loss: 1.0364:  38%|[36m███▊      [0m| 10/26 [00:10<00:15,  1.05it/s]Epoch: 5/10. Loss: 1.0825:  38%|[36m███▊      [0m| 10/26 [00:11<00:15,  1.05it/s]Epoch: 5/10. Loss: 1.0825:  42%|[36m████▏     [0m| 11/26 [00:11<00:14,  1.01it/s]Epoch: 5/10. Loss: 1.0173:  42%|[36m████▏     [0m| 11/26 [00:12<00:14,  1.01it/s]Epoch: 5/10. Loss: 1.0173:  46%|[36m████▌     [0m| 12/26 [00:12<00:13,  1.03it/s]Epoch: 5/10. Loss: 0.8725:  46%|[36m████▌     [0m| 12/26 [00:13<00:13,  1.03it/s]Epoch: 5/10. Loss: 0.8725:  50%|[36m█████     [0m| 13/26 [00:13<00:12,  1.07it/s]Epoch: 5/10. Loss: 0.9498:  50%|[36m█████     [0m| 13/26 [00:14<00:12,  1.07it/s]Epoch: 5/10. Loss: 0.9498:  54%|[36m█████▍    [0m| 14/26 [00:14<00:11,  1.08it/s]Epoch: 5/10. Loss: 0.9671:  54%|[36m█████▍    [0m| 14/26 [00:15<00:11,  1.08it/s]Epoch: 5/10. Loss: 0.9671:  58%|[36m█████▊    [0m| 15/26 [00:15<00:09,  1.10it/s]Epoch: 5/10. Loss: 0.9867:  58%|[36m█████▊    [0m| 15/26 [00:16<00:09,  1.10it/s]Epoch: 5/10. Loss: 0.9867:  62%|[36m██████▏   [0m| 16/26 [00:16<00:09,  1.08it/s]Epoch: 5/10. Loss: 1.0378:  62%|[36m██████▏   [0m| 16/26 [00:16<00:09,  1.08it/s]Epoch: 5/10. Loss: 1.0378:  65%|[36m██████▌   [0m| 17/26 [00:17<00:08,  1.07it/s]Epoch: 5/10. Loss: 0.9522:  65%|[36m██████▌   [0m| 17/26 [00:17<00:08,  1.07it/s]Epoch: 5/10. Loss: 0.9522:  69%|[36m██████▉   [0m| 18/26 [00:17<00:07,  1.10it/s]Epoch: 5/10. Loss: 0.9557:  69%|[36m██████▉   [0m| 18/26 [00:18<00:07,  1.10it/s]Epoch: 5/10. Loss: 0.9557:  73%|[36m███████▎  [0m| 19/26 [00:18<00:06,  1.06it/s]Epoch: 5/10. Loss: 0.9891:  73%|[36m███████▎  [0m| 19/26 [00:19<00:06,  1.06it/s]Epoch: 5/10. Loss: 0.9891:  77%|[36m███████▋  [0m| 20/26 [00:19<00:05,  1.01it/s]Epoch: 5/10. Loss: 0.8783:  77%|[36m███████▋  [0m| 20/26 [00:22<00:05,  1.01it/s]Epoch: 5/10. Loss: 0.8783:  81%|[36m████████  [0m| 21/26 [00:22<00:07,  1.57s/it]Epoch: 5/10. Loss: 0.8800:  81%|[36m████████  [0m| 21/26 [00:27<00:07,  1.57s/it]Epoch: 5/10. Loss: 0.8800:  85%|[36m████████▍ [0m| 22/26 [00:27<00:09,  2.38s/it]Epoch: 5/10. Loss: 0.9167:  85%|[36m████████▍ [0m| 22/26 [00:30<00:09,  2.38s/it]Epoch: 5/10. Loss: 0.9167:  88%|[36m████████▊ [0m| 23/26 [00:30<00:07,  2.57s/it]Epoch: 5/10. Loss: 0.9473:  88%|[36m████████▊ [0m| 23/26 [00:31<00:07,  2.57s/it]Epoch: 5/10. Loss: 0.9473:  92%|[36m█████████▏[0m| 24/26 [00:31<00:04,  2.22s/it]Epoch: 5/10. Loss: 0.8376:  92%|[36m█████████▏[0m| 24/26 [00:32<00:04,  2.22s/it]Epoch: 5/10. Loss: 0.8376:  96%|[36m█████████▌[0m| 25/26 [00:32<00:01,  1.94s/it]Epoch: 5/10. Loss: 0.9405:  96%|[36m█████████▌[0m| 25/26 [00:33<00:01,  1.94s/it]Epoch: 5/10. Loss: 0.9405: 100%|[36m██████████[0m| 26/26 [00:33<00:00,  1.53s/it]Epoch: 5/10. Loss: 0.9405: 100%|[36m██████████[0m| 26/26 [00:33<00:00,  1.29s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:04,  1.25it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:05,  1.15s/it] 43%|[33m████▎     [0m| 3/7 [00:02<00:03,  1.07it/s] 57%|[33m█████▋    [0m| 4/7 [00:04<00:03,  1.07s/it] 71%|[33m███████▏  [0m| 5/7 [00:04<00:01,  1.16it/s] 86%|[33m████████▌ [0m| 6/7 [00:05<00:00,  1.13it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.42it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.19it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 6/10. Loss: 0.9056:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 6/10. Loss: 0.9056:   4%|[36m▍         [0m| 1/26 [00:00<00:21,  1.18it/s]Epoch: 6/10. Loss: 1.0344:   4%|[36m▍         [0m| 1/26 [00:03<00:21,  1.18it/s]Epoch: 6/10. Loss: 1.0344:   8%|[36m▊         [0m| 2/26 [00:03<00:44,  1.85s/it]Epoch: 6/10. Loss: 0.9299:   8%|[36m▊         [0m| 2/26 [00:04<00:44,  1.85s/it]Epoch: 6/10. Loss: 0.9299:  12%|[36m█▏        [0m| 3/26 [00:04<00:36,  1.60s/it]Epoch: 6/10. Loss: 0.8815:  12%|[36m█▏        [0m| 3/26 [00:05<00:36,  1.60s/it]Epoch: 6/10. Loss: 0.8815:  15%|[36m█▌        [0m| 4/26 [00:05<00:28,  1.28s/it]Epoch: 6/10. Loss: 0.9702:  15%|[36m█▌        [0m| 4/26 [00:06<00:28,  1.28s/it]Epoch: 6/10. Loss: 0.9702:  19%|[36m█▉        [0m| 5/26 [00:06<00:25,  1.19s/it]Epoch: 6/10. Loss: 1.0074:  19%|[36m█▉        [0m| 5/26 [00:07<00:25,  1.19s/it]Epoch: 6/10. Loss: 1.0074:  23%|[36m██▎       [0m| 6/26 [00:07<00:23,  1.16s/it]Epoch: 6/10. Loss: 0.9712:  23%|[36m██▎       [0m| 6/26 [00:08<00:23,  1.16s/it]Epoch: 6/10. Loss: 0.9712:  27%|[36m██▋       [0m| 7/26 [00:08<00:20,  1.10s/it]Epoch: 6/10. Loss: 0.7885:  27%|[36m██▋       [0m| 7/26 [00:09<00:20,  1.10s/it]Epoch: 6/10. Loss: 0.7885:  31%|[36m███       [0m| 8/26 [00:09<00:19,  1.07s/it]Epoch: 6/10. Loss: 0.9602:  31%|[36m███       [0m| 8/26 [00:10<00:19,  1.07s/it]Epoch: 6/10. Loss: 0.9602:  35%|[36m███▍      [0m| 9/26 [00:10<00:17,  1.02s/it]Epoch: 6/10. Loss: 0.9949:  35%|[36m███▍      [0m| 9/26 [00:11<00:17,  1.02s/it]Epoch: 6/10. Loss: 0.9949:  38%|[36m███▊      [0m| 10/26 [00:11<00:16,  1.03s/it]Epoch: 6/10. Loss: 0.9860:  38%|[36m███▊      [0m| 10/26 [00:13<00:16,  1.03s/it]Epoch: 6/10. Loss: 0.9860:  42%|[36m████▏     [0m| 11/26 [00:13<00:20,  1.38s/it]Epoch: 6/10. Loss: 1.0850:  42%|[36m████▏     [0m| 11/26 [00:15<00:20,  1.38s/it]Epoch: 6/10. Loss: 1.0850:  46%|[36m████▌     [0m| 12/26 [00:15<00:19,  1.38s/it]Epoch: 6/10. Loss: 0.9421:  46%|[36m████▌     [0m| 12/26 [00:17<00:19,  1.38s/it]Epoch: 6/10. Loss: 0.9421:  50%|[36m█████     [0m| 13/26 [00:17<00:20,  1.56s/it]Epoch: 6/10. Loss: 1.0017:  50%|[36m█████     [0m| 13/26 [00:20<00:20,  1.56s/it]Epoch: 6/10. Loss: 1.0017:  54%|[36m█████▍    [0m| 14/26 [00:20<00:24,  2.01s/it]Epoch: 6/10. Loss: 0.9492:  54%|[36m█████▍    [0m| 14/26 [00:21<00:24,  2.01s/it]Epoch: 6/10. Loss: 0.9492:  58%|[36m█████▊    [0m| 15/26 [00:21<00:18,  1.67s/it]Epoch: 6/10. Loss: 0.8615:  58%|[36m█████▊    [0m| 15/26 [00:22<00:18,  1.67s/it]Epoch: 6/10. Loss: 0.8615:  62%|[36m██████▏   [0m| 16/26 [00:22<00:16,  1.65s/it]Epoch: 6/10. Loss: 0.9381:  62%|[36m██████▏   [0m| 16/26 [00:23<00:16,  1.65s/it]Epoch: 6/10. Loss: 0.9381:  65%|[36m██████▌   [0m| 17/26 [00:23<00:12,  1.41s/it]Epoch: 6/10. Loss: 0.9653:  65%|[36m██████▌   [0m| 17/26 [00:24<00:12,  1.41s/it]Epoch: 6/10. Loss: 0.9653:  69%|[36m██████▉   [0m| 18/26 [00:24<00:10,  1.26s/it]Epoch: 6/10. Loss: 0.9035:  69%|[36m██████▉   [0m| 18/26 [00:26<00:10,  1.26s/it]Epoch: 6/10. Loss: 0.9035:  73%|[36m███████▎  [0m| 19/26 [00:26<00:09,  1.38s/it]Epoch: 6/10. Loss: 0.8864:  73%|[36m███████▎  [0m| 19/26 [00:27<00:09,  1.38s/it]Epoch: 6/10. Loss: 0.8864:  77%|[36m███████▋  [0m| 20/26 [00:27<00:08,  1.42s/it]Epoch: 6/10. Loss: 0.9793:  77%|[36m███████▋  [0m| 20/26 [00:28<00:08,  1.42s/it]Epoch: 6/10. Loss: 0.9793:  81%|[36m████████  [0m| 21/26 [00:28<00:06,  1.37s/it]Epoch: 6/10. Loss: 0.9942:  81%|[36m████████  [0m| 21/26 [00:29<00:06,  1.37s/it]Epoch: 6/10. Loss: 0.9942:  85%|[36m████████▍ [0m| 22/26 [00:29<00:05,  1.28s/it]Epoch: 6/10. Loss: 0.8240:  85%|[36m████████▍ [0m| 22/26 [00:30<00:05,  1.28s/it]Epoch: 6/10. Loss: 0.8240:  88%|[36m████████▊ [0m| 23/26 [00:30<00:03,  1.18s/it]Epoch: 6/10. Loss: 0.8426:  88%|[36m████████▊ [0m| 23/26 [00:31<00:03,  1.18s/it]Epoch: 6/10. Loss: 0.8426:  92%|[36m█████████▏[0m| 24/26 [00:31<00:02,  1.08s/it]Epoch: 6/10. Loss: 0.9565:  92%|[36m█████████▏[0m| 24/26 [00:32<00:02,  1.08s/it]Epoch: 6/10. Loss: 0.9565:  96%|[36m█████████▌[0m| 25/26 [00:32<00:01,  1.03s/it]Epoch: 6/10. Loss: 0.9232:  96%|[36m█████████▌[0m| 25/26 [00:33<00:01,  1.03s/it]Epoch: 6/10. Loss: 0.9232: 100%|[36m██████████[0m| 26/26 [00:33<00:00,  1.03s/it]Epoch: 6/10. Loss: 0.9232: 100%|[36m██████████[0m| 26/26 [00:33<00:00,  1.29s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:05,  1.14it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:05,  1.18s/it] 43%|[33m████▎     [0m| 3/7 [00:03<00:03,  1.02it/s] 57%|[33m█████▋    [0m| 4/7 [00:05<00:04,  1.44s/it] 71%|[33m███████▏  [0m| 5/7 [00:05<00:02,  1.09s/it] 86%|[33m████████▌ [0m| 6/7 [00:06<00:01,  1.04s/it]100%|[33m██████████[0m| 7/7 [00:06<00:00,  1.24it/s]100%|[33m██████████[0m| 7/7 [00:06<00:00,  1.02it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 7/10. Loss: 0.9651:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 7/10. Loss: 0.9651:   4%|[36m▍         [0m| 1/26 [00:00<00:23,  1.07it/s]Epoch: 7/10. Loss: 0.9868:   4%|[36m▍         [0m| 1/26 [00:01<00:23,  1.07it/s]Epoch: 7/10. Loss: 0.9868:   8%|[36m▊         [0m| 2/26 [00:01<00:22,  1.08it/s]Epoch: 7/10. Loss: 0.9004:   8%|[36m▊         [0m| 2/26 [00:02<00:22,  1.08it/s]Epoch: 7/10. Loss: 0.9004:  12%|[36m█▏        [0m| 3/26 [00:02<00:19,  1.15it/s]Epoch: 7/10. Loss: 0.9028:  12%|[36m█▏        [0m| 3/26 [00:03<00:19,  1.15it/s]Epoch: 7/10. Loss: 0.9028:  15%|[36m█▌        [0m| 4/26 [00:03<00:19,  1.12it/s]Epoch: 7/10. Loss: 0.8579:  15%|[36m█▌        [0m| 4/26 [00:04<00:19,  1.12it/s]Epoch: 7/10. Loss: 0.8579:  19%|[36m█▉        [0m| 5/26 [00:04<00:19,  1.10it/s]Epoch: 7/10. Loss: 0.9198:  19%|[36m█▉        [0m| 5/26 [00:06<00:19,  1.10it/s]Epoch: 7/10. Loss: 0.9198:  23%|[36m██▎       [0m| 6/26 [00:06<00:22,  1.13s/it]Epoch: 7/10. Loss: 0.8969:  23%|[36m██▎       [0m| 6/26 [00:06<00:22,  1.13s/it]Epoch: 7/10. Loss: 0.8969:  27%|[36m██▋       [0m| 7/26 [00:06<00:19,  1.05s/it]Epoch: 7/10. Loss: 0.9639:  27%|[36m██▋       [0m| 7/26 [00:07<00:19,  1.05s/it]Epoch: 7/10. Loss: 0.9639:  31%|[36m███       [0m| 8/26 [00:07<00:17,  1.03it/s]Epoch: 7/10. Loss: 1.0351:  31%|[36m███       [0m| 8/26 [00:08<00:17,  1.03it/s]Epoch: 7/10. Loss: 1.0351:  35%|[36m███▍      [0m| 9/26 [00:08<00:15,  1.06it/s]Epoch: 7/10. Loss: 0.8329:  35%|[36m███▍      [0m| 9/26 [00:09<00:15,  1.06it/s]Epoch: 7/10. Loss: 0.8329:  38%|[36m███▊      [0m| 10/26 [00:09<00:16,  1.02s/it]Epoch: 7/10. Loss: 0.9108:  38%|[36m███▊      [0m| 10/26 [00:10<00:16,  1.02s/it]Epoch: 7/10. Loss: 0.9108:  42%|[36m████▏     [0m| 11/26 [00:10<00:15,  1.00s/it]Epoch: 7/10. Loss: 0.9423:  42%|[36m████▏     [0m| 11/26 [00:13<00:15,  1.00s/it]Epoch: 7/10. Loss: 0.9423:  46%|[36m████▌     [0m| 12/26 [00:13<00:22,  1.59s/it]Epoch: 7/10. Loss: 0.8939:  46%|[36m████▌     [0m| 12/26 [00:14<00:22,  1.59s/it]Epoch: 7/10. Loss: 0.8939:  50%|[36m█████     [0m| 13/26 [00:14<00:18,  1.42s/it]Epoch: 7/10. Loss: 0.8753:  50%|[36m█████     [0m| 13/26 [00:15<00:18,  1.42s/it]Epoch: 7/10. Loss: 0.8753:  54%|[36m█████▍    [0m| 14/26 [00:15<00:14,  1.19s/it]Epoch: 7/10. Loss: 0.9112:  54%|[36m█████▍    [0m| 14/26 [00:17<00:14,  1.19s/it]Epoch: 7/10. Loss: 0.9112:  58%|[36m█████▊    [0m| 15/26 [00:17<00:16,  1.49s/it]Epoch: 7/10. Loss: 0.9549:  58%|[36m█████▊    [0m| 15/26 [00:19<00:16,  1.49s/it]Epoch: 7/10. Loss: 0.9549:  62%|[36m██████▏   [0m| 16/26 [00:19<00:15,  1.58s/it]Epoch: 7/10. Loss: 1.0148:  62%|[36m██████▏   [0m| 16/26 [00:20<00:15,  1.58s/it]Epoch: 7/10. Loss: 1.0148:  65%|[36m██████▌   [0m| 17/26 [00:20<00:13,  1.46s/it]Epoch: 7/10. Loss: 0.9566:  65%|[36m██████▌   [0m| 17/26 [00:21<00:13,  1.46s/it]Epoch: 7/10. Loss: 0.9566:  69%|[36m██████▉   [0m| 18/26 [00:21<00:11,  1.41s/it]Epoch: 7/10. Loss: 0.9546:  69%|[36m██████▉   [0m| 18/26 [00:24<00:11,  1.41s/it]Epoch: 7/10. Loss: 0.9546:  73%|[36m███████▎  [0m| 19/26 [00:24<00:13,  1.87s/it]Epoch: 7/10. Loss: 1.0086:  73%|[36m███████▎  [0m| 19/26 [00:25<00:13,  1.87s/it]Epoch: 7/10. Loss: 1.0086:  77%|[36m███████▋  [0m| 20/26 [00:25<00:09,  1.64s/it]Epoch: 7/10. Loss: 0.9925:  77%|[36m███████▋  [0m| 20/26 [00:26<00:09,  1.64s/it]Epoch: 7/10. Loss: 0.9925:  81%|[36m████████  [0m| 21/26 [00:26<00:07,  1.44s/it]Epoch: 7/10. Loss: 0.9163:  81%|[36m████████  [0m| 21/26 [00:27<00:07,  1.44s/it]Epoch: 7/10. Loss: 0.9163:  85%|[36m████████▍ [0m| 22/26 [00:27<00:05,  1.28s/it]Epoch: 7/10. Loss: 0.8917:  85%|[36m████████▍ [0m| 22/26 [00:30<00:05,  1.28s/it]Epoch: 7/10. Loss: 0.8917:  88%|[36m████████▊ [0m| 23/26 [00:30<00:04,  1.58s/it]Epoch: 7/10. Loss: 0.8457:  88%|[36m████████▊ [0m| 23/26 [00:31<00:04,  1.58s/it]Epoch: 7/10. Loss: 0.8457:  92%|[36m█████████▏[0m| 24/26 [00:31<00:02,  1.41s/it]Epoch: 7/10. Loss: 0.9244:  92%|[36m█████████▏[0m| 24/26 [00:33<00:02,  1.41s/it]Epoch: 7/10. Loss: 0.9244:  96%|[36m█████████▌[0m| 25/26 [00:33<00:01,  1.61s/it]Epoch: 7/10. Loss: 0.9371:  96%|[36m█████████▌[0m| 25/26 [00:33<00:01,  1.61s/it]Epoch: 7/10. Loss: 0.9371: 100%|[36m██████████[0m| 26/26 [00:33<00:00,  1.34s/it]Epoch: 7/10. Loss: 0.9371: 100%|[36m██████████[0m| 26/26 [00:33<00:00,  1.30s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:01<00:10,  1.70s/it] 29%|[33m██▊       [0m| 2/7 [00:03<00:07,  1.51s/it] 43%|[33m████▎     [0m| 3/7 [00:04<00:05,  1.29s/it] 57%|[33m█████▋    [0m| 4/7 [00:05<00:03,  1.31s/it] 71%|[33m███████▏  [0m| 5/7 [00:06<00:02,  1.31s/it] 86%|[33m████████▌ [0m| 6/7 [00:07<00:01,  1.18s/it]100%|[33m██████████[0m| 7/7 [00:08<00:00,  1.10it/s]100%|[33m██████████[0m| 7/7 [00:08<00:00,  1.15s/it]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 8/10. Loss: 0.8369:   0%|[36m          [0m| 0/26 [00:01<?, ?it/s]Epoch: 8/10. Loss: 0.8369:   4%|[36m▍         [0m| 1/26 [00:01<00:26,  1.07s/it]Epoch: 8/10. Loss: 0.8529:   4%|[36m▍         [0m| 1/26 [00:02<00:26,  1.07s/it]Epoch: 8/10. Loss: 0.8529:   8%|[36m▊         [0m| 2/26 [00:02<00:36,  1.51s/it]Epoch: 8/10. Loss: 0.8668:   8%|[36m▊         [0m| 2/26 [00:03<00:36,  1.51s/it]Epoch: 8/10. Loss: 0.8668:  12%|[36m█▏        [0m| 3/26 [00:03<00:29,  1.27s/it]Epoch: 8/10. Loss: 0.8797:  12%|[36m█▏        [0m| 3/26 [00:05<00:29,  1.27s/it]Epoch: 8/10. Loss: 0.8797:  15%|[36m█▌        [0m| 4/26 [00:05<00:27,  1.25s/it]Epoch: 8/10. Loss: 0.9425:  15%|[36m█▌        [0m| 4/26 [00:05<00:27,  1.25s/it]Epoch: 8/10. Loss: 0.9425:  19%|[36m█▉        [0m| 5/26 [00:06<00:23,  1.13s/it]Epoch: 8/10. Loss: 0.8983:  19%|[36m█▉        [0m| 5/26 [00:06<00:23,  1.13s/it]Epoch: 8/10. Loss: 0.8983:  23%|[36m██▎       [0m| 6/26 [00:06<00:21,  1.06s/it]Epoch: 8/10. Loss: 0.8889:  23%|[36m██▎       [0m| 6/26 [00:07<00:21,  1.06s/it]Epoch: 8/10. Loss: 0.8889:  27%|[36m██▋       [0m| 7/26 [00:07<00:19,  1.03s/it]Epoch: 8/10. Loss: 0.9401:  27%|[36m██▋       [0m| 7/26 [00:09<00:19,  1.03s/it]Epoch: 8/10. Loss: 0.9401:  31%|[36m███       [0m| 8/26 [00:09<00:22,  1.26s/it]Epoch: 8/10. Loss: 0.8463:  31%|[36m███       [0m| 8/26 [00:10<00:22,  1.26s/it]Epoch: 8/10. Loss: 0.8463:  35%|[36m███▍      [0m| 9/26 [00:10<00:19,  1.13s/it]Epoch: 8/10. Loss: 0.8011:  35%|[36m███▍      [0m| 9/26 [00:11<00:19,  1.13s/it]Epoch: 8/10. Loss: 0.8011:  38%|[36m███▊      [0m| 10/26 [00:11<00:18,  1.13s/it]Epoch: 8/10. Loss: 0.9305:  38%|[36m███▊      [0m| 10/26 [00:13<00:18,  1.13s/it]Epoch: 8/10. Loss: 0.9305:  42%|[36m████▏     [0m| 11/26 [00:13<00:20,  1.38s/it]Epoch: 8/10. Loss: 0.8908:  42%|[36m████▏     [0m| 11/26 [00:15<00:20,  1.38s/it]Epoch: 8/10. Loss: 0.8908:  46%|[36m████▌     [0m| 12/26 [00:15<00:20,  1.46s/it]Epoch: 8/10. Loss: 0.9350:  46%|[36m████▌     [0m| 12/26 [00:16<00:20,  1.46s/it]Epoch: 8/10. Loss: 0.9350:  50%|[36m█████     [0m| 13/26 [00:16<00:20,  1.54s/it]Epoch: 8/10. Loss: 0.8160:  50%|[36m█████     [0m| 13/26 [00:18<00:20,  1.54s/it]Epoch: 8/10. Loss: 0.8160:  54%|[36m█████▍    [0m| 14/26 [00:18<00:16,  1.41s/it]Epoch: 8/10. Loss: 0.9447:  54%|[36m█████▍    [0m| 14/26 [00:19<00:16,  1.41s/it]Epoch: 8/10. Loss: 0.9447:  58%|[36m█████▊    [0m| 15/26 [00:19<00:14,  1.29s/it]Epoch: 8/10. Loss: 0.9166:  58%|[36m█████▊    [0m| 15/26 [00:19<00:14,  1.29s/it]Epoch: 8/10. Loss: 0.9166:  62%|[36m██████▏   [0m| 16/26 [00:19<00:11,  1.16s/it]Epoch: 8/10. Loss: 0.8544:  62%|[36m██████▏   [0m| 16/26 [00:20<00:11,  1.16s/it]Epoch: 8/10. Loss: 0.8544:  65%|[36m██████▌   [0m| 17/26 [00:20<00:10,  1.12s/it]Epoch: 8/10. Loss: 0.9021:  65%|[36m██████▌   [0m| 17/26 [00:21<00:10,  1.12s/it]Epoch: 8/10. Loss: 0.9021:  69%|[36m██████▉   [0m| 18/26 [00:21<00:08,  1.02s/it]Epoch: 8/10. Loss: 0.9238:  69%|[36m██████▉   [0m| 18/26 [00:22<00:08,  1.02s/it]Epoch: 8/10. Loss: 0.9238:  73%|[36m███████▎  [0m| 19/26 [00:22<00:06,  1.03it/s]Epoch: 8/10. Loss: 0.9233:  73%|[36m███████▎  [0m| 19/26 [00:23<00:06,  1.03it/s]Epoch: 8/10. Loss: 0.9233:  77%|[36m███████▋  [0m| 20/26 [00:23<00:05,  1.04it/s]Epoch: 8/10. Loss: 0.9060:  77%|[36m███████▋  [0m| 20/26 [00:24<00:05,  1.04it/s]Epoch: 8/10. Loss: 0.9060:  81%|[36m████████  [0m| 21/26 [00:24<00:05,  1.01s/it]Epoch: 8/10. Loss: 0.8767:  81%|[36m████████  [0m| 21/26 [00:25<00:05,  1.01s/it]Epoch: 8/10. Loss: 0.8767:  85%|[36m████████▍ [0m| 22/26 [00:25<00:03,  1.05it/s]Epoch: 8/10. Loss: 0.9483:  85%|[36m████████▍ [0m| 22/26 [00:26<00:03,  1.05it/s]Epoch: 8/10. Loss: 0.9483:  88%|[36m████████▊ [0m| 23/26 [00:26<00:03,  1.03s/it]Epoch: 8/10. Loss: 0.8651:  88%|[36m████████▊ [0m| 23/26 [00:27<00:03,  1.03s/it]Epoch: 8/10. Loss: 0.8651:  92%|[36m█████████▏[0m| 24/26 [00:27<00:01,  1.02it/s]Epoch: 8/10. Loss: 0.9403:  92%|[36m█████████▏[0m| 24/26 [00:28<00:01,  1.02it/s]Epoch: 8/10. Loss: 0.9403:  96%|[36m█████████▌[0m| 25/26 [00:28<00:00,  1.09it/s]Epoch: 8/10. Loss: 0.9429:  96%|[36m█████████▌[0m| 25/26 [00:28<00:00,  1.09it/s]Epoch: 8/10. Loss: 0.9429: 100%|[36m██████████[0m| 26/26 [00:28<00:00,  1.20it/s]Epoch: 8/10. Loss: 0.9429: 100%|[36m██████████[0m| 26/26 [00:28<00:00,  1.11s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:04,  1.23it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:05,  1.15s/it] 43%|[33m████▎     [0m| 3/7 [00:02<00:03,  1.07it/s] 57%|[33m█████▋    [0m| 4/7 [00:04<00:03,  1.19s/it] 71%|[33m███████▏  [0m| 5/7 [00:04<00:01,  1.08it/s] 86%|[33m████████▌ [0m| 6/7 [00:05<00:00,  1.06it/s]100%|[33m██████████[0m| 7/7 [00:06<00:00,  1.35it/s]100%|[33m██████████[0m| 7/7 [00:06<00:00,  1.12it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 9/10. Loss: 0.8329:   0%|[36m          [0m| 0/26 [00:02<?, ?it/s]Epoch: 9/10. Loss: 0.8329:   4%|[36m▍         [0m| 1/26 [00:02<00:54,  2.18s/it]Epoch: 9/10. Loss: 0.8707:   4%|[36m▍         [0m| 1/26 [00:03<00:54,  2.18s/it]Epoch: 9/10. Loss: 0.8707:   8%|[36m▊         [0m| 2/26 [00:03<00:35,  1.47s/it]Epoch: 9/10. Loss: 0.9090:   8%|[36m▊         [0m| 2/26 [00:04<00:35,  1.47s/it]Epoch: 9/10. Loss: 0.9090:  12%|[36m█▏        [0m| 3/26 [00:04<00:30,  1.33s/it]Epoch: 9/10. Loss: 0.8086:  12%|[36m█▏        [0m| 3/26 [00:05<00:30,  1.33s/it]Epoch: 9/10. Loss: 0.8086:  15%|[36m█▌        [0m| 4/26 [00:05<00:29,  1.34s/it]Epoch: 9/10. Loss: 0.8475:  15%|[36m█▌        [0m| 4/26 [00:06<00:29,  1.34s/it]Epoch: 9/10. Loss: 0.8475:  19%|[36m█▉        [0m| 5/26 [00:06<00:24,  1.18s/it]Epoch: 9/10. Loss: 0.8394:  19%|[36m█▉        [0m| 5/26 [00:07<00:24,  1.18s/it]Epoch: 9/10. Loss: 0.8394:  23%|[36m██▎       [0m| 6/26 [00:07<00:24,  1.23s/it]Epoch: 9/10. Loss: 0.7979:  23%|[36m██▎       [0m| 6/26 [00:10<00:24,  1.23s/it]Epoch: 9/10. Loss: 0.7979:  27%|[36m██▋       [0m| 7/26 [00:10<00:33,  1.76s/it]Epoch: 9/10. Loss: 0.9734:  27%|[36m██▋       [0m| 7/26 [00:11<00:33,  1.76s/it]Epoch: 9/10. Loss: 0.9734:  31%|[36m███       [0m| 8/26 [00:11<00:27,  1.50s/it]Epoch: 9/10. Loss: 0.8889:  31%|[36m███       [0m| 8/26 [00:12<00:27,  1.50s/it]Epoch: 9/10. Loss: 0.8889:  35%|[36m███▍      [0m| 9/26 [00:12<00:22,  1.34s/it]Epoch: 9/10. Loss: 0.8710:  35%|[36m███▍      [0m| 9/26 [00:13<00:22,  1.34s/it]Epoch: 9/10. Loss: 0.8710:  38%|[36m███▊      [0m| 10/26 [00:13<00:20,  1.26s/it]Epoch: 9/10. Loss: 0.9932:  38%|[36m███▊      [0m| 10/26 [00:14<00:20,  1.26s/it]Epoch: 9/10. Loss: 0.9932:  42%|[36m████▏     [0m| 11/26 [00:14<00:16,  1.12s/it]Epoch: 9/10. Loss: 0.9163:  42%|[36m████▏     [0m| 11/26 [00:15<00:16,  1.12s/it]Epoch: 9/10. Loss: 0.9163:  46%|[36m████▌     [0m| 12/26 [00:15<00:14,  1.01s/it]Epoch: 9/10. Loss: 0.9087:  46%|[36m████▌     [0m| 12/26 [00:16<00:14,  1.01s/it]Epoch: 9/10. Loss: 0.9087:  50%|[36m█████     [0m| 13/26 [00:16<00:12,  1.01it/s]Epoch: 9/10. Loss: 0.8524:  50%|[36m█████     [0m| 13/26 [00:17<00:12,  1.01it/s]Epoch: 9/10. Loss: 0.8524:  54%|[36m█████▍    [0m| 14/26 [00:17<00:11,  1.04it/s]Epoch: 9/10. Loss: 0.8941:  54%|[36m█████▍    [0m| 14/26 [00:18<00:11,  1.04it/s]Epoch: 9/10. Loss: 0.8941:  58%|[36m█████▊    [0m| 15/26 [00:18<00:10,  1.05it/s]Epoch: 9/10. Loss: 0.8586:  58%|[36m█████▊    [0m| 15/26 [00:19<00:10,  1.05it/s]Epoch: 9/10. Loss: 0.8586:  62%|[36m██████▏   [0m| 16/26 [00:19<00:09,  1.04it/s]Epoch: 9/10. Loss: 0.9327:  62%|[36m██████▏   [0m| 16/26 [00:20<00:09,  1.04it/s]Epoch: 9/10. Loss: 0.9327:  65%|[36m██████▌   [0m| 17/26 [00:20<00:08,  1.03it/s]Epoch: 9/10. Loss: 0.8009:  65%|[36m██████▌   [0m| 17/26 [00:21<00:08,  1.03it/s]Epoch: 9/10. Loss: 0.8009:  69%|[36m██████▉   [0m| 18/26 [00:21<00:08,  1.01s/it]Epoch: 9/10. Loss: 0.8134:  69%|[36m██████▉   [0m| 18/26 [00:22<00:08,  1.01s/it]Epoch: 9/10. Loss: 0.8134:  73%|[36m███████▎  [0m| 19/26 [00:22<00:07,  1.03s/it]Epoch: 9/10. Loss: 0.9766:  73%|[36m███████▎  [0m| 19/26 [00:23<00:07,  1.03s/it]Epoch: 9/10. Loss: 0.9766:  77%|[36m███████▋  [0m| 20/26 [00:23<00:06,  1.05s/it]Epoch: 9/10. Loss: 0.9502:  77%|[36m███████▋  [0m| 20/26 [00:24<00:06,  1.05s/it]Epoch: 9/10. Loss: 0.9502:  81%|[36m████████  [0m| 21/26 [00:24<00:04,  1.01it/s]Epoch: 9/10. Loss: 0.9032:  81%|[36m████████  [0m| 21/26 [00:25<00:04,  1.01it/s]Epoch: 9/10. Loss: 0.9032:  85%|[36m████████▍ [0m| 22/26 [00:25<00:03,  1.02it/s]Epoch: 9/10. Loss: 0.8730:  85%|[36m████████▍ [0m| 22/26 [00:25<00:03,  1.02it/s]Epoch: 9/10. Loss: 0.8730:  88%|[36m████████▊ [0m| 23/26 [00:26<00:02,  1.07it/s]Epoch: 9/10. Loss: 0.8890:  88%|[36m████████▊ [0m| 23/26 [00:26<00:02,  1.07it/s]Epoch: 9/10. Loss: 0.8890:  92%|[36m█████████▏[0m| 24/26 [00:26<00:01,  1.07it/s]Epoch: 9/10. Loss: 0.9044:  92%|[36m█████████▏[0m| 24/26 [00:27<00:01,  1.07it/s]Epoch: 9/10. Loss: 0.9044:  96%|[36m█████████▌[0m| 25/26 [00:27<00:00,  1.06it/s]Epoch: 9/10. Loss: 0.9244:  96%|[36m█████████▌[0m| 25/26 [00:28<00:00,  1.06it/s]Epoch: 9/10. Loss: 0.9244: 100%|[36m██████████[0m| 26/26 [00:28<00:00,  1.22it/s]Epoch: 9/10. Loss: 0.9244: 100%|[36m██████████[0m| 26/26 [00:28<00:00,  1.09s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:04,  1.22it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:05,  1.16s/it] 43%|[33m████▎     [0m| 3/7 [00:02<00:03,  1.05it/s] 57%|[33m█████▋    [0m| 4/7 [00:04<00:03,  1.08s/it] 71%|[33m███████▏  [0m| 5/7 [00:07<00:04,  2.02s/it] 86%|[33m████████▌ [0m| 6/7 [00:10<00:02,  2.09s/it]100%|[33m██████████[0m| 7/7 [00:12<00:00,  2.08s/it]100%|[33m██████████[0m| 7/7 [00:12<00:00,  1.74s/it]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 0/10. Loss: 1.0689:   0%|[36m          [0m| 0/26 [00:01<?, ?it/s]Epoch: 0/10. Loss: 1.0689:   4%|[36m▍         [0m| 1/26 [00:01<00:30,  1.21s/it]Epoch: 0/10. Loss: 4.6671:   4%|[36m▍         [0m| 1/26 [00:02<00:30,  1.21s/it]Epoch: 0/10. Loss: 4.6671:   8%|[36m▊         [0m| 2/26 [00:02<00:23,  1.02it/s]Epoch: 0/10. Loss: 2.3793:   8%|[36m▊         [0m| 2/26 [00:03<00:23,  1.02it/s]Epoch: 0/10. Loss: 2.3793:  12%|[36m█▏        [0m| 3/26 [00:03<00:23,  1.01s/it]Epoch: 0/10. Loss: 1.3273:  12%|[36m█▏        [0m| 3/26 [00:03<00:23,  1.01s/it]Epoch: 0/10. Loss: 1.3273:  15%|[36m█▌        [0m| 4/26 [00:03<00:19,  1.11it/s]Epoch: 0/10. Loss: 1.1959:  15%|[36m█▌        [0m| 4/26 [00:04<00:19,  1.11it/s]Epoch: 0/10. Loss: 1.1959:  19%|[36m█▉        [0m| 5/26 [00:04<00:19,  1.07it/s]Epoch: 0/10. Loss: 1.4069:  19%|[36m█▉        [0m| 5/26 [00:05<00:19,  1.07it/s]Epoch: 0/10. Loss: 1.4069:  23%|[36m██▎       [0m| 6/26 [00:05<00:19,  1.00it/s]Epoch: 0/10. Loss: 1.5077:  23%|[36m██▎       [0m| 6/26 [00:06<00:19,  1.00it/s]Epoch: 0/10. Loss: 1.5077:  27%|[36m██▋       [0m| 7/26 [00:06<00:17,  1.11it/s]Epoch: 0/10. Loss: 1.1340:  27%|[36m██▋       [0m| 7/26 [00:07<00:17,  1.11it/s]Epoch: 0/10. Loss: 1.1340:  31%|[36m███       [0m| 8/26 [00:07<00:15,  1.16it/s]Epoch: 0/10. Loss: 1.4588:  31%|[36m███       [0m| 8/26 [00:08<00:15,  1.16it/s]Epoch: 0/10. Loss: 1.4588:  35%|[36m███▍      [0m| 9/26 [00:08<00:14,  1.17it/s]Epoch: 0/10. Loss: 1.1186:  35%|[36m███▍      [0m| 9/26 [00:09<00:14,  1.17it/s]Epoch: 0/10. Loss: 1.1186:  38%|[36m███▊      [0m| 10/26 [00:09<00:14,  1.14it/s]Epoch: 0/10. Loss: 1.1469:  38%|[36m███▊      [0m| 10/26 [00:10<00:14,  1.14it/s]Epoch: 0/10. Loss: 1.1469:  42%|[36m████▏     [0m| 11/26 [00:10<00:14,  1.04it/s]Epoch: 0/10. Loss: 1.4392:  42%|[36m████▏     [0m| 11/26 [00:11<00:14,  1.04it/s]Epoch: 0/10. Loss: 1.4392:  46%|[36m████▌     [0m| 12/26 [00:11<00:15,  1.08s/it]Epoch: 0/10. Loss: 1.3546:  46%|[36m████▌     [0m| 12/26 [00:12<00:15,  1.08s/it]Epoch: 0/10. Loss: 1.3546:  50%|[36m█████     [0m| 13/26 [00:12<00:13,  1.02s/it]Epoch: 0/10. Loss: 1.0224:  50%|[36m█████     [0m| 13/26 [00:13<00:13,  1.02s/it]Epoch: 0/10. Loss: 1.0224:  54%|[36m█████▍    [0m| 14/26 [00:13<00:12,  1.06s/it]Epoch: 0/10. Loss: 1.0817:  54%|[36m█████▍    [0m| 14/26 [00:14<00:12,  1.06s/it]Epoch: 0/10. Loss: 1.0817:  58%|[36m█████▊    [0m| 15/26 [00:14<00:10,  1.03it/s]Epoch: 0/10. Loss: 1.0336:  58%|[36m█████▊    [0m| 15/26 [00:15<00:10,  1.03it/s]Epoch: 0/10. Loss: 1.0336:  62%|[36m██████▏   [0m| 16/26 [00:15<00:09,  1.02it/s]Epoch: 0/10. Loss: 1.2155:  62%|[36m██████▏   [0m| 16/26 [00:16<00:09,  1.02it/s]Epoch: 0/10. Loss: 1.2155:  65%|[36m██████▌   [0m| 17/26 [00:16<00:08,  1.05it/s]Epoch: 0/10. Loss: 0.9922:  65%|[36m██████▌   [0m| 17/26 [00:17<00:08,  1.05it/s]Epoch: 0/10. Loss: 0.9922:  69%|[36m██████▉   [0m| 18/26 [00:17<00:07,  1.07it/s]Epoch: 0/10. Loss: 1.5284:  69%|[36m██████▉   [0m| 18/26 [00:18<00:07,  1.07it/s]Epoch: 0/10. Loss: 1.5284:  73%|[36m███████▎  [0m| 19/26 [00:18<00:06,  1.08it/s]Epoch: 0/10. Loss: 1.2649:  73%|[36m███████▎  [0m| 19/26 [00:19<00:06,  1.08it/s]Epoch: 0/10. Loss: 1.2649:  77%|[36m███████▋  [0m| 20/26 [00:19<00:05,  1.04it/s]Epoch: 0/10. Loss: 0.9637:  77%|[36m███████▋  [0m| 20/26 [00:20<00:05,  1.04it/s]Epoch: 0/10. Loss: 0.9637:  81%|[36m████████  [0m| 21/26 [00:20<00:04,  1.03it/s]Epoch: 0/10. Loss: 0.9920:  81%|[36m████████  [0m| 21/26 [00:21<00:04,  1.03it/s]Epoch: 0/10. Loss: 0.9920:  85%|[36m████████▍ [0m| 22/26 [00:21<00:03,  1.06it/s]Epoch: 0/10. Loss: 1.0280:  85%|[36m████████▍ [0m| 22/26 [00:21<00:03,  1.06it/s]Epoch: 0/10. Loss: 1.0280:  88%|[36m████████▊ [0m| 23/26 [00:21<00:02,  1.09it/s]Epoch: 0/10. Loss: 1.0769:  88%|[36m████████▊ [0m| 23/26 [00:23<00:02,  1.09it/s]Epoch: 0/10. Loss: 1.0769:  92%|[36m█████████▏[0m| 24/26 [00:23<00:02,  1.25s/it]Epoch: 0/10. Loss: 1.0305:  92%|[36m█████████▏[0m| 24/26 [00:25<00:02,  1.25s/it]Epoch: 0/10. Loss: 1.0305:  96%|[36m█████████▌[0m| 25/26 [00:25<00:01,  1.34s/it]Epoch: 0/10. Loss: 1.1203:  96%|[36m█████████▌[0m| 25/26 [00:26<00:01,  1.34s/it]Epoch: 0/10. Loss: 1.1203: 100%|[36m██████████[0m| 26/26 [00:26<00:00,  1.16s/it]Epoch: 0/10. Loss: 1.1203: 100%|[36m██████████[0m| 26/26 [00:26<00:00,  1.01s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:04,  1.22it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:07,  1.48s/it] 43%|[33m████▎     [0m| 3/7 [00:03<00:04,  1.13s/it] 57%|[33m█████▋    [0m| 4/7 [00:04<00:03,  1.25s/it] 71%|[33m███████▏  [0m| 5/7 [00:05<00:01,  1.05it/s] 86%|[33m████████▌ [0m| 6/7 [00:06<00:00,  1.06it/s]100%|[33m██████████[0m| 7/7 [00:06<00:00,  1.38it/s]100%|[33m██████████[0m| 7/7 [00:06<00:00,  1.07it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 1/10. Loss: 1.1340:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 1/10. Loss: 1.1340:   4%|[36m▍         [0m| 1/26 [00:00<00:21,  1.17it/s]Epoch: 1/10. Loss: 0.9926:   4%|[36m▍         [0m| 1/26 [00:02<00:21,  1.17it/s]Epoch: 1/10. Loss: 0.9926:   8%|[36m▊         [0m| 2/26 [00:02<00:30,  1.25s/it]Epoch: 1/10. Loss: 1.1362:   8%|[36m▊         [0m| 2/26 [00:03<00:30,  1.25s/it]Epoch: 1/10. Loss: 1.1362:  12%|[36m█▏        [0m| 3/26 [00:03<00:25,  1.12s/it]Epoch: 1/10. Loss: 0.9690:  12%|[36m█▏        [0m| 3/26 [00:04<00:25,  1.12s/it]Epoch: 1/10. Loss: 0.9690:  15%|[36m█▌        [0m| 4/26 [00:04<00:23,  1.05s/it]Epoch: 1/10. Loss: 0.9542:  15%|[36m█▌        [0m| 4/26 [00:05<00:23,  1.05s/it]Epoch: 1/10. Loss: 0.9542:  19%|[36m█▉        [0m| 5/26 [00:05<00:26,  1.24s/it]Epoch: 1/10. Loss: 1.0983:  19%|[36m█▉        [0m| 5/26 [00:07<00:26,  1.24s/it]Epoch: 1/10. Loss: 1.0983:  23%|[36m██▎       [0m| 6/26 [00:07<00:26,  1.31s/it]Epoch: 1/10. Loss: 1.0656:  23%|[36m██▎       [0m| 6/26 [00:08<00:26,  1.31s/it]Epoch: 1/10. Loss: 1.0656:  27%|[36m██▋       [0m| 7/26 [00:08<00:22,  1.16s/it]Epoch: 1/10. Loss: 1.0992:  27%|[36m██▋       [0m| 7/26 [00:09<00:22,  1.16s/it]Epoch: 1/10. Loss: 1.0992:  31%|[36m███       [0m| 8/26 [00:09<00:19,  1.06s/it]Epoch: 1/10. Loss: 1.0410:  31%|[36m███       [0m| 8/26 [00:10<00:19,  1.06s/it]Epoch: 1/10. Loss: 1.0410:  35%|[36m███▍      [0m| 9/26 [00:10<00:18,  1.06s/it]Epoch: 1/10. Loss: 1.0417:  35%|[36m███▍      [0m| 9/26 [00:11<00:18,  1.06s/it]Epoch: 1/10. Loss: 1.0417:  38%|[36m███▊      [0m| 10/26 [00:11<00:18,  1.14s/it]Epoch: 1/10. Loss: 1.0284:  38%|[36m███▊      [0m| 10/26 [00:12<00:18,  1.14s/it]Epoch: 1/10. Loss: 1.0284:  42%|[36m████▏     [0m| 11/26 [00:12<00:17,  1.17s/it]Epoch: 1/10. Loss: 0.9750:  42%|[36m████▏     [0m| 11/26 [00:13<00:17,  1.17s/it]Epoch: 1/10. Loss: 0.9750:  46%|[36m████▌     [0m| 12/26 [00:13<00:15,  1.07s/it]Epoch: 1/10. Loss: 1.0008:  46%|[36m████▌     [0m| 12/26 [00:14<00:15,  1.07s/it]Epoch: 1/10. Loss: 1.0008:  50%|[36m█████     [0m| 13/26 [00:14<00:15,  1.21s/it]Epoch: 1/10. Loss: 1.0115:  50%|[36m█████     [0m| 13/26 [00:15<00:15,  1.21s/it]Epoch: 1/10. Loss: 1.0115:  54%|[36m█████▍    [0m| 14/26 [00:15<00:13,  1.11s/it]Epoch: 1/10. Loss: 1.0347:  54%|[36m█████▍    [0m| 14/26 [00:16<00:13,  1.11s/it]Epoch: 1/10. Loss: 1.0347:  58%|[36m█████▊    [0m| 15/26 [00:16<00:11,  1.06s/it]Epoch: 1/10. Loss: 0.9649:  58%|[36m█████▊    [0m| 15/26 [00:17<00:11,  1.06s/it]Epoch: 1/10. Loss: 0.9649:  62%|[36m██████▏   [0m| 16/26 [00:17<00:10,  1.03s/it]Epoch: 1/10. Loss: 0.9620:  62%|[36m██████▏   [0m| 16/26 [00:18<00:10,  1.03s/it]Epoch: 1/10. Loss: 0.9620:  65%|[36m██████▌   [0m| 17/26 [00:18<00:09,  1.06s/it]Epoch: 1/10. Loss: 1.0384:  65%|[36m██████▌   [0m| 17/26 [00:19<00:09,  1.06s/it]Epoch: 1/10. Loss: 1.0384:  69%|[36m██████▉   [0m| 18/26 [00:19<00:08,  1.04s/it]Epoch: 1/10. Loss: 1.0788:  69%|[36m██████▉   [0m| 18/26 [00:21<00:08,  1.04s/it]Epoch: 1/10. Loss: 1.0788:  73%|[36m███████▎  [0m| 19/26 [00:21<00:07,  1.13s/it]Epoch: 1/10. Loss: 1.0677:  73%|[36m███████▎  [0m| 19/26 [00:22<00:07,  1.13s/it]Epoch: 1/10. Loss: 1.0677:  77%|[36m███████▋  [0m| 20/26 [00:22<00:06,  1.13s/it]Epoch: 1/10. Loss: 0.9814:  77%|[36m███████▋  [0m| 20/26 [00:23<00:06,  1.13s/it]Epoch: 1/10. Loss: 0.9814:  81%|[36m████████  [0m| 21/26 [00:23<00:05,  1.01s/it]Epoch: 1/10. Loss: 1.0357:  81%|[36m████████  [0m| 21/26 [00:24<00:05,  1.01s/it]Epoch: 1/10. Loss: 1.0357:  85%|[36m████████▍ [0m| 22/26 [00:24<00:04,  1.00s/it]Epoch: 1/10. Loss: 1.0399:  85%|[36m████████▍ [0m| 22/26 [00:26<00:04,  1.00s/it]Epoch: 1/10. Loss: 1.0399:  88%|[36m████████▊ [0m| 23/26 [00:26<00:04,  1.34s/it]Epoch: 1/10. Loss: 0.9773:  88%|[36m████████▊ [0m| 23/26 [00:27<00:04,  1.34s/it]Epoch: 1/10. Loss: 0.9773:  92%|[36m█████████▏[0m| 24/26 [00:27<00:02,  1.29s/it]Epoch: 1/10. Loss: 0.9735:  92%|[36m█████████▏[0m| 24/26 [00:28<00:02,  1.29s/it]Epoch: 1/10. Loss: 0.9735:  96%|[36m█████████▌[0m| 25/26 [00:28<00:01,  1.17s/it]Epoch: 1/10. Loss: 0.9581:  96%|[36m█████████▌[0m| 25/26 [00:28<00:01,  1.17s/it]Epoch: 1/10. Loss: 0.9581: 100%|[36m██████████[0m| 26/26 [00:28<00:00,  1.01it/s]Epoch: 1/10. Loss: 0.9581: 100%|[36m██████████[0m| 26/26 [00:28<00:00,  1.11s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:05,  1.20it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:06,  1.20s/it] 43%|[33m████▎     [0m| 3/7 [00:03<00:04,  1.03s/it] 57%|[33m█████▋    [0m| 4/7 [00:04<00:03,  1.12s/it] 71%|[33m███████▏  [0m| 5/7 [00:04<00:01,  1.14it/s] 86%|[33m████████▌ [0m| 6/7 [00:05<00:00,  1.15it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.46it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.17it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 2/10. Loss: 1.0430:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 2/10. Loss: 1.0430:   4%|[36m▍         [0m| 1/26 [00:00<00:22,  1.11it/s]Epoch: 2/10. Loss: 0.9136:   4%|[36m▍         [0m| 1/26 [00:01<00:22,  1.11it/s]Epoch: 2/10. Loss: 0.9136:   8%|[36m▊         [0m| 2/26 [00:01<00:22,  1.05it/s]Epoch: 2/10. Loss: 0.9930:   8%|[36m▊         [0m| 2/26 [00:03<00:22,  1.05it/s]Epoch: 2/10. Loss: 0.9930:  12%|[36m█▏        [0m| 3/26 [00:03<00:25,  1.11s/it]Epoch: 2/10. Loss: 0.9723:  12%|[36m█▏        [0m| 3/26 [00:03<00:25,  1.11s/it]Epoch: 2/10. Loss: 0.9723:  15%|[36m█▌        [0m| 4/26 [00:03<00:21,  1.01it/s]Epoch: 2/10. Loss: 1.0873:  15%|[36m█▌        [0m| 4/26 [00:04<00:21,  1.01it/s]Epoch: 2/10. Loss: 1.0873:  19%|[36m█▉        [0m| 5/26 [00:04<00:20,  1.04it/s]Epoch: 2/10. Loss: 0.9950:  19%|[36m█▉        [0m| 5/26 [00:05<00:20,  1.04it/s]Epoch: 2/10. Loss: 0.9950:  23%|[36m██▎       [0m| 6/26 [00:05<00:19,  1.00it/s]Epoch: 2/10. Loss: 0.9820:  23%|[36m██▎       [0m| 6/26 [00:06<00:19,  1.00it/s]Epoch: 2/10. Loss: 0.9820:  27%|[36m██▋       [0m| 7/26 [00:06<00:18,  1.03it/s]Epoch: 2/10. Loss: 0.9683:  27%|[36m██▋       [0m| 7/26 [00:07<00:18,  1.03it/s]Epoch: 2/10. Loss: 0.9683:  31%|[36m███       [0m| 8/26 [00:08<00:18,  1.02s/it]Epoch: 2/10. Loss: 0.9793:  31%|[36m███       [0m| 8/26 [00:08<00:18,  1.02s/it]Epoch: 2/10. Loss: 0.9793:  35%|[36m███▍      [0m| 9/26 [00:08<00:17,  1.00s/it]Epoch: 2/10. Loss: 1.1010:  35%|[36m███▍      [0m| 9/26 [00:09<00:17,  1.00s/it]Epoch: 2/10. Loss: 1.1010:  38%|[36m███▊      [0m| 10/26 [00:09<00:14,  1.07it/s]Epoch: 2/10. Loss: 1.0303:  38%|[36m███▊      [0m| 10/26 [00:10<00:14,  1.07it/s]Epoch: 2/10. Loss: 1.0303:  42%|[36m████▏     [0m| 11/26 [00:10<00:14,  1.06it/s]Epoch: 2/10. Loss: 0.9107:  42%|[36m████▏     [0m| 11/26 [00:11<00:14,  1.06it/s]Epoch: 2/10. Loss: 0.9107:  46%|[36m████▌     [0m| 12/26 [00:11<00:12,  1.10it/s]Epoch: 2/10. Loss: 0.8883:  46%|[36m████▌     [0m| 12/26 [00:12<00:12,  1.10it/s]Epoch: 2/10. Loss: 0.8883:  50%|[36m█████     [0m| 13/26 [00:12<00:11,  1.12it/s]Epoch: 2/10. Loss: 1.0928:  50%|[36m█████     [0m| 13/26 [00:13<00:11,  1.12it/s]Epoch: 2/10. Loss: 1.0928:  54%|[36m█████▍    [0m| 14/26 [00:13<00:11,  1.07it/s]Epoch: 2/10. Loss: 0.9705:  54%|[36m█████▍    [0m| 14/26 [00:14<00:11,  1.07it/s]Epoch: 2/10. Loss: 0.9705:  58%|[36m█████▊    [0m| 15/26 [00:14<00:10,  1.07it/s]Epoch: 2/10. Loss: 0.9498:  58%|[36m█████▊    [0m| 15/26 [00:15<00:10,  1.07it/s]Epoch: 2/10. Loss: 0.9498:  62%|[36m██████▏   [0m| 16/26 [00:15<00:09,  1.07it/s]Epoch: 2/10. Loss: 0.9276:  62%|[36m██████▏   [0m| 16/26 [00:16<00:09,  1.07it/s]Epoch: 2/10. Loss: 0.9276:  65%|[36m██████▌   [0m| 17/26 [00:16<00:08,  1.12it/s]Epoch: 2/10. Loss: 0.9691:  65%|[36m██████▌   [0m| 17/26 [00:18<00:08,  1.12it/s]Epoch: 2/10. Loss: 0.9691:  69%|[36m██████▉   [0m| 18/26 [00:18<00:11,  1.43s/it]Epoch: 2/10. Loss: 1.0851:  69%|[36m██████▉   [0m| 18/26 [00:19<00:11,  1.43s/it]Epoch: 2/10. Loss: 1.0851:  73%|[36m███████▎  [0m| 19/26 [00:19<00:08,  1.27s/it]Epoch: 2/10. Loss: 0.9566:  73%|[36m███████▎  [0m| 19/26 [00:21<00:08,  1.27s/it]Epoch: 2/10. Loss: 0.9566:  77%|[36m███████▋  [0m| 20/26 [00:21<00:08,  1.42s/it]Epoch: 2/10. Loss: 0.9679:  77%|[36m███████▋  [0m| 20/26 [00:22<00:08,  1.42s/it]Epoch: 2/10. Loss: 0.9679:  81%|[36m████████  [0m| 21/26 [00:22<00:06,  1.21s/it]Epoch: 2/10. Loss: 0.9814:  81%|[36m████████  [0m| 21/26 [00:23<00:06,  1.21s/it]Epoch: 2/10. Loss: 0.9814:  85%|[36m████████▍ [0m| 22/26 [00:23<00:04,  1.10s/it]Epoch: 2/10. Loss: 0.9195:  85%|[36m████████▍ [0m| 22/26 [00:25<00:04,  1.10s/it]Epoch: 2/10. Loss: 0.9195:  88%|[36m████████▊ [0m| 23/26 [00:25<00:04,  1.58s/it]Epoch: 2/10. Loss: 0.9893:  88%|[36m████████▊ [0m| 23/26 [00:28<00:04,  1.58s/it]Epoch: 2/10. Loss: 0.9893:  92%|[36m█████████▏[0m| 24/26 [00:28<00:03,  1.88s/it]Epoch: 2/10. Loss: 0.9936:  92%|[36m█████████▏[0m| 24/26 [00:29<00:03,  1.88s/it]Epoch: 2/10. Loss: 0.9936:  96%|[36m█████████▌[0m| 25/26 [00:29<00:01,  1.62s/it]Epoch: 2/10. Loss: 1.0059:  96%|[36m█████████▌[0m| 25/26 [00:30<00:01,  1.62s/it]Epoch: 2/10. Loss: 1.0059: 100%|[36m██████████[0m| 26/26 [00:30<00:00,  1.36s/it]Epoch: 2/10. Loss: 1.0059: 100%|[36m██████████[0m| 26/26 [00:30<00:00,  1.16s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:05,  1.19it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:05,  1.19s/it] 43%|[33m████▎     [0m| 3/7 [00:02<00:03,  1.03it/s] 57%|[33m█████▋    [0m| 4/7 [00:05<00:05,  1.76s/it] 71%|[33m███████▏  [0m| 5/7 [00:06<00:02,  1.29s/it] 86%|[33m████████▌ [0m| 6/7 [00:07<00:01,  1.14s/it]100%|[33m██████████[0m| 7/7 [00:07<00:00,  1.16it/s]100%|[33m██████████[0m| 7/7 [00:07<00:00,  1.08s/it]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 3/10. Loss: 0.9340:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 3/10. Loss: 0.9340:   4%|[36m▍         [0m| 1/26 [00:00<00:22,  1.12it/s]Epoch: 3/10. Loss: 1.0312:   4%|[36m▍         [0m| 1/26 [00:01<00:22,  1.12it/s]Epoch: 3/10. Loss: 1.0312:   8%|[36m▊         [0m| 2/26 [00:01<00:20,  1.15it/s]Epoch: 3/10. Loss: 0.9873:   8%|[36m▊         [0m| 2/26 [00:02<00:20,  1.15it/s]Epoch: 3/10. Loss: 0.9873:  12%|[36m█▏        [0m| 3/26 [00:02<00:20,  1.11it/s]Epoch: 3/10. Loss: 0.9948:  12%|[36m█▏        [0m| 3/26 [00:03<00:20,  1.11it/s]Epoch: 3/10. Loss: 0.9948:  15%|[36m█▌        [0m| 4/26 [00:03<00:19,  1.13it/s]Epoch: 3/10. Loss: 0.9799:  15%|[36m█▌        [0m| 4/26 [00:04<00:19,  1.13it/s]Epoch: 3/10. Loss: 0.9799:  19%|[36m█▉        [0m| 5/26 [00:04<00:19,  1.08it/s]Epoch: 3/10. Loss: 0.8700:  19%|[36m█▉        [0m| 5/26 [00:05<00:19,  1.08it/s]Epoch: 3/10. Loss: 0.8700:  23%|[36m██▎       [0m| 6/26 [00:05<00:19,  1.03it/s]Epoch: 3/10. Loss: 1.0149:  23%|[36m██▎       [0m| 6/26 [00:06<00:19,  1.03it/s]Epoch: 3/10. Loss: 1.0149:  27%|[36m██▋       [0m| 7/26 [00:06<00:17,  1.06it/s]Epoch: 3/10. Loss: 0.8783:  27%|[36m██▋       [0m| 7/26 [00:07<00:17,  1.06it/s]Epoch: 3/10. Loss: 0.8783:  31%|[36m███       [0m| 8/26 [00:07<00:16,  1.11it/s]Epoch: 3/10. Loss: 0.9975:  31%|[36m███       [0m| 8/26 [00:08<00:16,  1.11it/s]Epoch: 3/10. Loss: 0.9975:  35%|[36m███▍      [0m| 9/26 [00:08<00:16,  1.03it/s]Epoch: 3/10. Loss: 1.0333:  35%|[36m███▍      [0m| 9/26 [00:09<00:16,  1.03it/s]Epoch: 3/10. Loss: 1.0333:  38%|[36m███▊      [0m| 10/26 [00:09<00:15,  1.06it/s]Epoch: 3/10. Loss: 0.8512:  38%|[36m███▊      [0m| 10/26 [00:10<00:15,  1.06it/s]Epoch: 3/10. Loss: 0.8512:  42%|[36m████▏     [0m| 11/26 [00:10<00:13,  1.10it/s]Epoch: 3/10. Loss: 0.9646:  42%|[36m████▏     [0m| 11/26 [00:11<00:13,  1.10it/s]Epoch: 3/10. Loss: 0.9646:  46%|[36m████▌     [0m| 12/26 [00:11<00:13,  1.04it/s]Epoch: 3/10. Loss: 0.9495:  46%|[36m████▌     [0m| 12/26 [00:12<00:13,  1.04it/s]Epoch: 3/10. Loss: 0.9495:  50%|[36m█████     [0m| 13/26 [00:12<00:12,  1.03it/s]Epoch: 3/10. Loss: 0.9410:  50%|[36m█████     [0m| 13/26 [00:13<00:12,  1.03it/s]Epoch: 3/10. Loss: 0.9410:  54%|[36m█████▍    [0m| 14/26 [00:13<00:11,  1.04it/s]Epoch: 3/10. Loss: 0.8776:  54%|[36m█████▍    [0m| 14/26 [00:14<00:11,  1.04it/s]Epoch: 3/10. Loss: 0.8776:  58%|[36m█████▊    [0m| 15/26 [00:14<00:10,  1.06it/s]Epoch: 3/10. Loss: 0.8790:  58%|[36m█████▊    [0m| 15/26 [00:14<00:10,  1.06it/s]Epoch: 3/10. Loss: 0.8790:  62%|[36m██████▏   [0m| 16/26 [00:14<00:08,  1.14it/s]Epoch: 3/10. Loss: 0.9088:  62%|[36m██████▏   [0m| 16/26 [00:15<00:08,  1.14it/s]Epoch: 3/10. Loss: 0.9088:  65%|[36m██████▌   [0m| 17/26 [00:15<00:08,  1.04it/s]Epoch: 3/10. Loss: 0.9097:  65%|[36m██████▌   [0m| 17/26 [00:16<00:08,  1.04it/s]Epoch: 3/10. Loss: 0.9097:  69%|[36m██████▉   [0m| 18/26 [00:16<00:07,  1.11it/s]Epoch: 3/10. Loss: 0.9086:  69%|[36m██████▉   [0m| 18/26 [00:17<00:07,  1.11it/s]Epoch: 3/10. Loss: 0.9086:  73%|[36m███████▎  [0m| 19/26 [00:17<00:06,  1.13it/s]Epoch: 3/10. Loss: 0.8788:  73%|[36m███████▎  [0m| 19/26 [00:18<00:06,  1.13it/s]Epoch: 3/10. Loss: 0.8788:  77%|[36m███████▋  [0m| 20/26 [00:18<00:05,  1.15it/s]Epoch: 3/10. Loss: 1.0667:  77%|[36m███████▋  [0m| 20/26 [00:19<00:05,  1.15it/s]Epoch: 3/10. Loss: 1.0667:  81%|[36m████████  [0m| 21/26 [00:19<00:04,  1.17it/s]Epoch: 3/10. Loss: 0.8645:  81%|[36m████████  [0m| 21/26 [00:20<00:04,  1.17it/s]Epoch: 3/10. Loss: 0.8645:  85%|[36m████████▍ [0m| 22/26 [00:20<00:03,  1.18it/s]Epoch: 3/10. Loss: 1.1475:  85%|[36m████████▍ [0m| 22/26 [00:22<00:03,  1.18it/s]Epoch: 3/10. Loss: 1.1475:  88%|[36m████████▊ [0m| 23/26 [00:22<00:04,  1.39s/it]Epoch: 3/10. Loss: 0.9282:  88%|[36m████████▊ [0m| 23/26 [00:23<00:04,  1.39s/it]Epoch: 3/10. Loss: 0.9282:  92%|[36m█████████▏[0m| 24/26 [00:23<00:02,  1.36s/it]Epoch: 3/10. Loss: 0.8647:  92%|[36m█████████▏[0m| 24/26 [00:24<00:02,  1.36s/it]Epoch: 3/10. Loss: 0.8647:  96%|[36m█████████▌[0m| 25/26 [00:24<00:01,  1.19s/it]Epoch: 3/10. Loss: 0.9427:  96%|[36m█████████▌[0m| 25/26 [00:27<00:01,  1.19s/it]Epoch: 3/10. Loss: 0.9427: 100%|[36m██████████[0m| 26/26 [00:27<00:00,  1.52s/it]Epoch: 3/10. Loss: 0.9427: 100%|[36m██████████[0m| 26/26 [00:27<00:00,  1.04s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:05,  1.15it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:06,  1.27s/it] 43%|[33m████▎     [0m| 3/7 [00:03<00:04,  1.01s/it] 57%|[33m█████▋    [0m| 4/7 [00:04<00:03,  1.12s/it] 71%|[33m███████▏  [0m| 5/7 [00:04<00:01,  1.13it/s] 86%|[33m████████▌ [0m| 6/7 [00:05<00:00,  1.14it/s]100%|[33m██████████[0m| 7/7 [00:06<00:00,  1.45it/s]100%|[33m██████████[0m| 7/7 [00:06<00:00,  1.16it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 4/10. Loss: 0.8717:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 4/10. Loss: 0.8717:   4%|[36m▍         [0m| 1/26 [00:00<00:22,  1.13it/s]Epoch: 4/10. Loss: 0.9116:   4%|[36m▍         [0m| 1/26 [00:03<00:22,  1.13it/s]Epoch: 4/10. Loss: 0.9116:   8%|[36m▊         [0m| 2/26 [00:03<00:47,  1.98s/it]Epoch: 4/10. Loss: 0.7221:   8%|[36m▊         [0m| 2/26 [00:04<00:47,  1.98s/it]Epoch: 4/10. Loss: 0.7221:  12%|[36m█▏        [0m| 3/26 [00:04<00:34,  1.49s/it]Epoch: 4/10. Loss: 0.8225:  12%|[36m█▏        [0m| 3/26 [00:05<00:34,  1.49s/it]Epoch: 4/10. Loss: 0.8225:  15%|[36m█▌        [0m| 4/26 [00:05<00:28,  1.29s/it]Epoch: 4/10. Loss: 1.0072:  15%|[36m█▌        [0m| 4/26 [00:06<00:28,  1.29s/it]Epoch: 4/10. Loss: 1.0072:  19%|[36m█▉        [0m| 5/26 [00:06<00:25,  1.20s/it]Epoch: 4/10. Loss: 0.8913:  19%|[36m█▉        [0m| 5/26 [00:07<00:25,  1.20s/it]Epoch: 4/10. Loss: 0.8913:  23%|[36m██▎       [0m| 6/26 [00:07<00:23,  1.17s/it]Epoch: 4/10. Loss: 1.0204:  23%|[36m██▎       [0m| 6/26 [00:08<00:23,  1.17s/it]Epoch: 4/10. Loss: 1.0204:  27%|[36m██▋       [0m| 7/26 [00:08<00:20,  1.09s/it]Epoch: 4/10. Loss: 0.9029:  27%|[36m██▋       [0m| 7/26 [00:09<00:20,  1.09s/it]Epoch: 4/10. Loss: 0.9029:  31%|[36m███       [0m| 8/26 [00:09<00:17,  1.02it/s]Epoch: 4/10. Loss: 0.9548:  31%|[36m███       [0m| 8/26 [00:10<00:17,  1.02it/s]Epoch: 4/10. Loss: 0.9548:  35%|[36m███▍      [0m| 9/26 [00:10<00:15,  1.07it/s]Epoch: 4/10. Loss: 0.8281:  35%|[36m███▍      [0m| 9/26 [00:11<00:15,  1.07it/s]Epoch: 4/10. Loss: 0.8281:  38%|[36m███▊      [0m| 10/26 [00:11<00:15,  1.06it/s]Epoch: 4/10. Loss: 0.8951:  38%|[36m███▊      [0m| 10/26 [00:12<00:15,  1.06it/s]Epoch: 4/10. Loss: 0.8951:  42%|[36m████▏     [0m| 11/26 [00:12<00:14,  1.07it/s]Epoch: 4/10. Loss: 0.9858:  42%|[36m████▏     [0m| 11/26 [00:13<00:14,  1.07it/s]Epoch: 4/10. Loss: 0.9858:  46%|[36m████▌     [0m| 12/26 [00:13<00:13,  1.07it/s]Epoch: 4/10. Loss: 0.9573:  46%|[36m████▌     [0m| 12/26 [00:13<00:13,  1.07it/s]Epoch: 4/10. Loss: 0.9573:  50%|[36m█████     [0m| 13/26 [00:13<00:12,  1.05it/s]Epoch: 4/10. Loss: 0.9341:  50%|[36m█████     [0m| 13/26 [00:14<00:12,  1.05it/s]Epoch: 4/10. Loss: 0.9341:  54%|[36m█████▍    [0m| 14/26 [00:15<00:11,  1.03it/s]Epoch: 4/10. Loss: 0.8344:  54%|[36m█████▍    [0m| 14/26 [00:15<00:11,  1.03it/s]Epoch: 4/10. Loss: 0.8344:  58%|[36m█████▊    [0m| 15/26 [00:15<00:09,  1.12it/s]Epoch: 4/10. Loss: 0.9107:  58%|[36m█████▊    [0m| 15/26 [00:16<00:09,  1.12it/s]Epoch: 4/10. Loss: 0.9107:  62%|[36m██████▏   [0m| 16/26 [00:16<00:09,  1.04it/s]Epoch: 4/10. Loss: 0.9043:  62%|[36m██████▏   [0m| 16/26 [00:17<00:09,  1.04it/s]Epoch: 4/10. Loss: 0.9043:  65%|[36m██████▌   [0m| 17/26 [00:17<00:08,  1.08it/s]Epoch: 4/10. Loss: 0.8663:  65%|[36m██████▌   [0m| 17/26 [00:18<00:08,  1.08it/s]Epoch: 4/10. Loss: 0.8663:  69%|[36m██████▉   [0m| 18/26 [00:18<00:07,  1.05it/s]Epoch: 4/10. Loss: 0.9784:  69%|[36m██████▉   [0m| 18/26 [00:19<00:07,  1.05it/s]Epoch: 4/10. Loss: 0.9784:  73%|[36m███████▎  [0m| 19/26 [00:19<00:06,  1.08it/s]Epoch: 4/10. Loss: 0.9654:  73%|[36m███████▎  [0m| 19/26 [00:20<00:06,  1.08it/s]Epoch: 4/10. Loss: 0.9654:  77%|[36m███████▋  [0m| 20/26 [00:20<00:05,  1.05it/s]Epoch: 4/10. Loss: 0.8350:  77%|[36m███████▋  [0m| 20/26 [00:21<00:05,  1.05it/s]Epoch: 4/10. Loss: 0.8350:  81%|[36m████████  [0m| 21/26 [00:21<00:04,  1.09it/s]Epoch: 4/10. Loss: 0.8918:  81%|[36m████████  [0m| 21/26 [00:22<00:04,  1.09it/s]Epoch: 4/10. Loss: 0.8918:  85%|[36m████████▍ [0m| 22/26 [00:22<00:03,  1.16it/s]Epoch: 4/10. Loss: 1.0017:  85%|[36m████████▍ [0m| 22/26 [00:22<00:03,  1.16it/s]Epoch: 4/10. Loss: 1.0017:  88%|[36m████████▊ [0m| 23/26 [00:22<00:02,  1.21it/s]Epoch: 4/10. Loss: 0.9152:  88%|[36m████████▊ [0m| 23/26 [00:23<00:02,  1.21it/s]Epoch: 4/10. Loss: 0.9152:  92%|[36m█████████▏[0m| 24/26 [00:23<00:01,  1.22it/s]Epoch: 4/10. Loss: 0.9957:  92%|[36m█████████▏[0m| 24/26 [00:24<00:01,  1.22it/s]Epoch: 4/10. Loss: 0.9957:  96%|[36m█████████▌[0m| 25/26 [00:24<00:00,  1.29it/s]Epoch: 4/10. Loss: 0.9790:  96%|[36m█████████▌[0m| 25/26 [00:25<00:00,  1.29it/s]Epoch: 4/10. Loss: 0.9790: 100%|[36m██████████[0m| 26/26 [00:25<00:00,  1.33it/s]Epoch: 4/10. Loss: 0.9790: 100%|[36m██████████[0m| 26/26 [00:25<00:00,  1.04it/s]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:05,  1.18it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:07,  1.53s/it] 43%|[33m████▎     [0m| 3/7 [00:03<00:04,  1.15s/it] 57%|[33m█████▋    [0m| 4/7 [00:06<00:05,  1.80s/it] 71%|[33m███████▏  [0m| 5/7 [00:08<00:03,  1.97s/it] 86%|[33m████████▌ [0m| 6/7 [00:09<00:01,  1.61s/it]100%|[33m██████████[0m| 7/7 [00:09<00:00,  1.18s/it]100%|[33m██████████[0m| 7/7 [00:09<00:00,  1.40s/it]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 5/10. Loss: 0.9552:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 5/10. Loss: 0.9552:   4%|[36m▍         [0m| 1/26 [00:00<00:20,  1.20it/s]Epoch: 5/10. Loss: 0.8925:   4%|[36m▍         [0m| 1/26 [00:01<00:20,  1.20it/s]Epoch: 5/10. Loss: 0.8925:   8%|[36m▊         [0m| 2/26 [00:01<00:19,  1.22it/s]Epoch: 5/10. Loss: 0.7565:   8%|[36m▊         [0m| 2/26 [00:02<00:19,  1.22it/s]Epoch: 5/10. Loss: 0.7565:  12%|[36m█▏        [0m| 3/26 [00:02<00:19,  1.17it/s]Epoch: 5/10. Loss: 0.9473:  12%|[36m█▏        [0m| 3/26 [00:03<00:19,  1.17it/s]Epoch: 5/10. Loss: 0.9473:  15%|[36m█▌        [0m| 4/26 [00:03<00:20,  1.09it/s]Epoch: 5/10. Loss: 0.9097:  15%|[36m█▌        [0m| 4/26 [00:04<00:20,  1.09it/s]Epoch: 5/10. Loss: 0.9097:  19%|[36m█▉        [0m| 5/26 [00:04<00:17,  1.20it/s]Epoch: 5/10. Loss: 0.8516:  19%|[36m█▉        [0m| 5/26 [00:04<00:17,  1.20it/s]Epoch: 5/10. Loss: 0.8516:  23%|[36m██▎       [0m| 6/26 [00:04<00:16,  1.24it/s]Epoch: 5/10. Loss: 0.8829:  23%|[36m██▎       [0m| 6/26 [00:06<00:16,  1.24it/s]Epoch: 5/10. Loss: 0.8829:  27%|[36m██▋       [0m| 7/26 [00:06<00:17,  1.07it/s]Epoch: 5/10. Loss: 0.9130:  27%|[36m██▋       [0m| 7/26 [00:07<00:17,  1.07it/s]Epoch: 5/10. Loss: 0.9130:  31%|[36m███       [0m| 8/26 [00:07<00:17,  1.02it/s]Epoch: 5/10. Loss: 0.8294:  31%|[36m███       [0m| 8/26 [00:08<00:17,  1.02it/s]Epoch: 5/10. Loss: 0.8294:  35%|[36m███▍      [0m| 9/26 [00:08<00:19,  1.17s/it]Epoch: 5/10. Loss: 0.8434:  35%|[36m███▍      [0m| 9/26 [00:09<00:19,  1.17s/it]Epoch: 5/10. Loss: 0.8434:  38%|[36m███▊      [0m| 10/26 [00:09<00:17,  1.10s/it]Epoch: 5/10. Loss: 0.9110:  38%|[36m███▊      [0m| 10/26 [00:11<00:17,  1.10s/it]Epoch: 5/10. Loss: 0.9110:  42%|[36m████▏     [0m| 11/26 [00:11<00:16,  1.13s/it]Epoch: 5/10. Loss: 0.8253:  42%|[36m████▏     [0m| 11/26 [00:12<00:16,  1.13s/it]Epoch: 5/10. Loss: 0.8253:  46%|[36m████▌     [0m| 12/26 [00:12<00:15,  1.11s/it]Epoch: 5/10. Loss: 0.8368:  46%|[36m████▌     [0m| 12/26 [00:12<00:15,  1.11s/it]Epoch: 5/10. Loss: 0.8368:  50%|[36m█████     [0m| 13/26 [00:12<00:13,  1.02s/it]Epoch: 5/10. Loss: 0.9057:  50%|[36m█████     [0m| 13/26 [00:13<00:13,  1.02s/it]Epoch: 5/10. Loss: 0.9057:  54%|[36m█████▍    [0m| 14/26 [00:13<00:11,  1.02it/s]Epoch: 5/10. Loss: 0.9535:  54%|[36m█████▍    [0m| 14/26 [00:14<00:11,  1.02it/s]Epoch: 5/10. Loss: 0.9535:  58%|[36m█████▊    [0m| 15/26 [00:14<00:10,  1.03it/s]Epoch: 5/10. Loss: 0.8747:  58%|[36m█████▊    [0m| 15/26 [00:15<00:10,  1.03it/s]Epoch: 5/10. Loss: 0.8747:  62%|[36m██████▏   [0m| 16/26 [00:15<00:09,  1.08it/s]Epoch: 5/10. Loss: 0.8209:  62%|[36m██████▏   [0m| 16/26 [00:16<00:09,  1.08it/s]Epoch: 5/10. Loss: 0.8209:  65%|[36m██████▌   [0m| 17/26 [00:16<00:08,  1.12it/s]Epoch: 5/10. Loss: 0.9184:  65%|[36m██████▌   [0m| 17/26 [00:17<00:08,  1.12it/s]Epoch: 5/10. Loss: 0.9184:  69%|[36m██████▉   [0m| 18/26 [00:17<00:06,  1.21it/s]Epoch: 5/10. Loss: 0.9368:  69%|[36m██████▉   [0m| 18/26 [00:17<00:06,  1.21it/s]Epoch: 5/10. Loss: 0.9368:  73%|[36m███████▎  [0m| 19/26 [00:17<00:05,  1.24it/s]Epoch: 5/10. Loss: 0.7864:  73%|[36m███████▎  [0m| 19/26 [00:18<00:05,  1.24it/s]Epoch: 5/10. Loss: 0.7864:  77%|[36m███████▋  [0m| 20/26 [00:18<00:05,  1.20it/s]Epoch: 5/10. Loss: 0.8003:  77%|[36m███████▋  [0m| 20/26 [00:19<00:05,  1.20it/s]Epoch: 5/10. Loss: 0.8003:  81%|[36m████████  [0m| 21/26 [00:19<00:04,  1.22it/s]Epoch: 5/10. Loss: 0.8689:  81%|[36m████████  [0m| 21/26 [00:20<00:04,  1.22it/s]Epoch: 5/10. Loss: 0.8689:  85%|[36m████████▍ [0m| 22/26 [00:20<00:03,  1.21it/s]Epoch: 5/10. Loss: 0.8638:  85%|[36m████████▍ [0m| 22/26 [00:21<00:03,  1.21it/s]Epoch: 5/10. Loss: 0.8638:  88%|[36m████████▊ [0m| 23/26 [00:21<00:02,  1.06it/s]Epoch: 5/10. Loss: 0.9596:  88%|[36m████████▊ [0m| 23/26 [00:22<00:02,  1.06it/s]Epoch: 5/10. Loss: 0.9596:  92%|[36m█████████▏[0m| 24/26 [00:22<00:01,  1.01it/s]Epoch: 5/10. Loss: 0.7315:  92%|[36m█████████▏[0m| 24/26 [00:23<00:01,  1.01it/s]Epoch: 5/10. Loss: 0.7315:  96%|[36m█████████▌[0m| 25/26 [00:23<00:00,  1.04it/s]Epoch: 5/10. Loss: 0.8356:  96%|[36m█████████▌[0m| 25/26 [00:24<00:00,  1.04it/s]Epoch: 5/10. Loss: 0.8356: 100%|[36m██████████[0m| 26/26 [00:24<00:00,  1.10it/s]Epoch: 5/10. Loss: 0.8356: 100%|[36m██████████[0m| 26/26 [00:24<00:00,  1.07it/s]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:02<00:14,  2.39s/it] 29%|[33m██▊       [0m| 2/7 [00:04<00:10,  2.12s/it] 43%|[33m████▎     [0m| 3/7 [00:05<00:07,  1.85s/it] 57%|[33m█████▋    [0m| 4/7 [00:07<00:05,  1.83s/it] 71%|[33m███████▏  [0m| 5/7 [00:08<00:02,  1.32s/it] 86%|[33m████████▌ [0m| 6/7 [00:08<00:01,  1.13s/it]100%|[33m██████████[0m| 7/7 [00:09<00:00,  1.18it/s]100%|[33m██████████[0m| 7/7 [00:09<00:00,  1.30s/it]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 6/10. Loss: 0.8804:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 6/10. Loss: 0.8804:   4%|[36m▍         [0m| 1/26 [00:00<00:20,  1.25it/s]Epoch: 6/10. Loss: 0.8630:   4%|[36m▍         [0m| 1/26 [00:01<00:20,  1.25it/s]Epoch: 6/10. Loss: 0.8630:   8%|[36m▊         [0m| 2/26 [00:01<00:18,  1.29it/s]Epoch: 6/10. Loss: 0.7954:   8%|[36m▊         [0m| 2/26 [00:02<00:18,  1.29it/s]Epoch: 6/10. Loss: 0.7954:  12%|[36m█▏        [0m| 3/26 [00:02<00:21,  1.06it/s]Epoch: 6/10. Loss: 0.9281:  12%|[36m█▏        [0m| 3/26 [00:03<00:21,  1.06it/s]Epoch: 6/10. Loss: 0.9281:  15%|[36m█▌        [0m| 4/26 [00:03<00:21,  1.04it/s]Epoch: 6/10. Loss: 0.8027:  15%|[36m█▌        [0m| 4/26 [00:04<00:21,  1.04it/s]Epoch: 6/10. Loss: 0.8027:  19%|[36m█▉        [0m| 5/26 [00:04<00:21,  1.00s/it]Epoch: 6/10. Loss: 0.9372:  19%|[36m█▉        [0m| 5/26 [00:05<00:21,  1.00s/it]Epoch: 6/10. Loss: 0.9372:  23%|[36m██▎       [0m| 6/26 [00:05<00:19,  1.03it/s]Epoch: 6/10. Loss: 0.8666:  23%|[36m██▎       [0m| 6/26 [00:06<00:19,  1.03it/s]Epoch: 6/10. Loss: 0.8666:  27%|[36m██▋       [0m| 7/26 [00:06<00:18,  1.05it/s]Epoch: 6/10. Loss: 0.8464:  27%|[36m██▋       [0m| 7/26 [00:08<00:18,  1.05it/s]Epoch: 6/10. Loss: 0.8464:  31%|[36m███       [0m| 8/26 [00:08<00:21,  1.18s/it]Epoch: 6/10. Loss: 0.9043:  31%|[36m███       [0m| 8/26 [00:09<00:21,  1.18s/it]Epoch: 6/10. Loss: 0.9043:  35%|[36m███▍      [0m| 9/26 [00:09<00:20,  1.18s/it]Epoch: 6/10. Loss: 0.8138:  35%|[36m███▍      [0m| 9/26 [00:10<00:20,  1.18s/it]Epoch: 6/10. Loss: 0.8138:  38%|[36m███▊      [0m| 10/26 [00:10<00:16,  1.05s/it]Epoch: 6/10. Loss: 0.8326:  38%|[36m███▊      [0m| 10/26 [00:11<00:16,  1.05s/it]Epoch: 6/10. Loss: 0.8326:  42%|[36m████▏     [0m| 11/26 [00:11<00:15,  1.02s/it]Epoch: 6/10. Loss: 0.8190:  42%|[36m████▏     [0m| 11/26 [00:11<00:15,  1.02s/it]Epoch: 6/10. Loss: 0.8190:  46%|[36m████▌     [0m| 12/26 [00:11<00:13,  1.06it/s]Epoch: 6/10. Loss: 0.8286:  46%|[36m████▌     [0m| 12/26 [00:12<00:13,  1.06it/s]Epoch: 6/10. Loss: 0.8286:  50%|[36m█████     [0m| 13/26 [00:12<00:12,  1.07it/s]Epoch: 6/10. Loss: 0.8993:  50%|[36m█████     [0m| 13/26 [00:13<00:12,  1.07it/s]Epoch: 6/10. Loss: 0.8993:  54%|[36m█████▍    [0m| 14/26 [00:13<00:10,  1.10it/s]Epoch: 6/10. Loss: 0.9336:  54%|[36m█████▍    [0m| 14/26 [00:14<00:10,  1.10it/s]Epoch: 6/10. Loss: 0.9336:  58%|[36m█████▊    [0m| 15/26 [00:14<00:10,  1.06it/s]Epoch: 6/10. Loss: 0.7529:  58%|[36m█████▊    [0m| 15/26 [00:15<00:10,  1.06it/s]Epoch: 6/10. Loss: 0.7529:  62%|[36m██████▏   [0m| 16/26 [00:15<00:09,  1.10it/s]Epoch: 6/10. Loss: 0.8415:  62%|[36m██████▏   [0m| 16/26 [00:16<00:09,  1.10it/s]Epoch: 6/10. Loss: 0.8415:  65%|[36m██████▌   [0m| 17/26 [00:16<00:07,  1.14it/s]Epoch: 6/10. Loss: 0.9685:  65%|[36m██████▌   [0m| 17/26 [00:17<00:07,  1.14it/s]Epoch: 6/10. Loss: 0.9685:  69%|[36m██████▉   [0m| 18/26 [00:17<00:06,  1.16it/s]Epoch: 6/10. Loss: 0.8013:  69%|[36m██████▉   [0m| 18/26 [00:19<00:06,  1.16it/s]Epoch: 6/10. Loss: 0.8013:  73%|[36m███████▎  [0m| 19/26 [00:19<00:08,  1.22s/it]Epoch: 6/10. Loss: 0.8859:  73%|[36m███████▎  [0m| 19/26 [00:20<00:08,  1.22s/it]Epoch: 6/10. Loss: 0.8859:  77%|[36m███████▋  [0m| 20/26 [00:20<00:06,  1.13s/it]Epoch: 6/10. Loss: 0.8561:  77%|[36m███████▋  [0m| 20/26 [00:20<00:06,  1.13s/it]Epoch: 6/10. Loss: 0.8561:  81%|[36m████████  [0m| 21/26 [00:20<00:05,  1.05s/it]Epoch: 6/10. Loss: 0.8797:  81%|[36m████████  [0m| 21/26 [00:21<00:05,  1.05s/it]Epoch: 6/10. Loss: 0.8797:  85%|[36m████████▍ [0m| 22/26 [00:21<00:03,  1.03it/s]Epoch: 6/10. Loss: 0.8485:  85%|[36m████████▍ [0m| 22/26 [00:22<00:03,  1.03it/s]Epoch: 6/10. Loss: 0.8485:  88%|[36m████████▊ [0m| 23/26 [00:22<00:02,  1.07it/s]Epoch: 6/10. Loss: 0.7917:  88%|[36m████████▊ [0m| 23/26 [00:23<00:02,  1.07it/s]Epoch: 6/10. Loss: 0.7917:  92%|[36m█████████▏[0m| 24/26 [00:23<00:01,  1.08it/s]Epoch: 6/10. Loss: 0.8127:  92%|[36m█████████▏[0m| 24/26 [00:24<00:01,  1.08it/s]Epoch: 6/10. Loss: 0.8127:  96%|[36m█████████▌[0m| 25/26 [00:24<00:00,  1.14it/s]Epoch: 6/10. Loss: 0.7696:  96%|[36m█████████▌[0m| 25/26 [00:24<00:00,  1.14it/s]Epoch: 6/10. Loss: 0.7696: 100%|[36m██████████[0m| 26/26 [00:24<00:00,  1.23it/s]Epoch: 6/10. Loss: 0.7696: 100%|[36m██████████[0m| 26/26 [00:24<00:00,  1.04it/s]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:05,  1.19it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:06,  1.20s/it] 43%|[33m████▎     [0m| 3/7 [00:03<00:03,  1.02it/s] 57%|[33m█████▋    [0m| 4/7 [00:04<00:03,  1.09s/it] 71%|[33m███████▏  [0m| 5/7 [00:04<00:01,  1.18it/s] 86%|[33m████████▌ [0m| 6/7 [00:05<00:00,  1.18it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.51it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.20it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 7/10. Loss: 0.9389:   0%|[36m          [0m| 0/26 [00:01<?, ?it/s]Epoch: 7/10. Loss: 0.9389:   4%|[36m▍         [0m| 1/26 [00:01<00:28,  1.14s/it]Epoch: 7/10. Loss: 0.7908:   4%|[36m▍         [0m| 1/26 [00:02<00:28,  1.14s/it]Epoch: 7/10. Loss: 0.7908:   8%|[36m▊         [0m| 2/26 [00:02<00:23,  1.01it/s]Epoch: 7/10. Loss: 0.7652:   8%|[36m▊         [0m| 2/26 [00:03<00:23,  1.01it/s]Epoch: 7/10. Loss: 0.7652:  12%|[36m█▏        [0m| 3/26 [00:03<00:24,  1.06s/it]Epoch: 7/10. Loss: 0.8411:  12%|[36m█▏        [0m| 3/26 [00:04<00:24,  1.06s/it]Epoch: 7/10. Loss: 0.8411:  15%|[36m█▌        [0m| 4/26 [00:04<00:21,  1.02it/s]Epoch: 7/10. Loss: 0.7986:  15%|[36m█▌        [0m| 4/26 [00:04<00:21,  1.02it/s]Epoch: 7/10. Loss: 0.7986:  19%|[36m█▉        [0m| 5/26 [00:04<00:19,  1.06it/s]Epoch: 7/10. Loss: 0.9113:  19%|[36m█▉        [0m| 5/26 [00:05<00:19,  1.06it/s]Epoch: 7/10. Loss: 0.9113:  23%|[36m██▎       [0m| 6/26 [00:05<00:18,  1.07it/s]Epoch: 7/10. Loss: 0.8284:  23%|[36m██▎       [0m| 6/26 [00:06<00:18,  1.07it/s]Epoch: 7/10. Loss: 0.8284:  27%|[36m██▋       [0m| 7/26 [00:06<00:17,  1.06it/s]Epoch: 7/10. Loss: 0.8475:  27%|[36m██▋       [0m| 7/26 [00:07<00:17,  1.06it/s]Epoch: 7/10. Loss: 0.8475:  31%|[36m███       [0m| 8/26 [00:07<00:17,  1.02it/s]Epoch: 7/10. Loss: 0.7654:  31%|[36m███       [0m| 8/26 [00:09<00:17,  1.02it/s]Epoch: 7/10. Loss: 0.7654:  35%|[36m███▍      [0m| 9/26 [00:09<00:18,  1.07s/it]Epoch: 7/10. Loss: 0.8338:  35%|[36m███▍      [0m| 9/26 [00:09<00:18,  1.07s/it]Epoch: 7/10. Loss: 0.8338:  38%|[36m███▊      [0m| 10/26 [00:09<00:16,  1.00s/it]Epoch: 7/10. Loss: 0.9293:  38%|[36m███▊      [0m| 10/26 [00:11<00:16,  1.00s/it]Epoch: 7/10. Loss: 0.9293:  42%|[36m████▏     [0m| 11/26 [00:11<00:15,  1.02s/it]Epoch: 7/10. Loss: 0.7641:  42%|[36m████▏     [0m| 11/26 [00:11<00:15,  1.02s/it]Epoch: 7/10. Loss: 0.7641:  46%|[36m████▌     [0m| 12/26 [00:11<00:13,  1.01it/s]Epoch: 7/10. Loss: 0.9233:  46%|[36m████▌     [0m| 12/26 [00:12<00:13,  1.01it/s]Epoch: 7/10. Loss: 0.9233:  50%|[36m█████     [0m| 13/26 [00:12<00:12,  1.06it/s]Epoch: 7/10. Loss: 0.9340:  50%|[36m█████     [0m| 13/26 [00:13<00:12,  1.06it/s]Epoch: 7/10. Loss: 0.9340:  54%|[36m█████▍    [0m| 14/26 [00:13<00:11,  1.08it/s]Epoch: 7/10. Loss: 0.8607:  54%|[36m█████▍    [0m| 14/26 [00:14<00:11,  1.08it/s]Epoch: 7/10. Loss: 0.8607:  58%|[36m█████▊    [0m| 15/26 [00:14<00:10,  1.09it/s]Epoch: 7/10. Loss: 0.7416:  58%|[36m█████▊    [0m| 15/26 [00:15<00:10,  1.09it/s]Epoch: 7/10. Loss: 0.7416:  62%|[36m██████▏   [0m| 16/26 [00:15<00:08,  1.13it/s]Epoch: 7/10. Loss: 0.8604:  62%|[36m██████▏   [0m| 16/26 [00:16<00:08,  1.13it/s]Epoch: 7/10. Loss: 0.8604:  65%|[36m██████▌   [0m| 17/26 [00:16<00:08,  1.08it/s]Epoch: 7/10. Loss: 0.9835:  65%|[36m██████▌   [0m| 17/26 [00:17<00:08,  1.08it/s]Epoch: 7/10. Loss: 0.9835:  69%|[36m██████▉   [0m| 18/26 [00:17<00:07,  1.10it/s]Epoch: 7/10. Loss: 1.0131:  69%|[36m██████▉   [0m| 18/26 [00:18<00:07,  1.10it/s]Epoch: 7/10. Loss: 1.0131:  73%|[36m███████▎  [0m| 19/26 [00:18<00:06,  1.11it/s]Epoch: 7/10. Loss: 0.9168:  73%|[36m███████▎  [0m| 19/26 [00:19<00:06,  1.11it/s]Epoch: 7/10. Loss: 0.9168:  77%|[36m███████▋  [0m| 20/26 [00:19<00:05,  1.09it/s]Epoch: 7/10. Loss: 0.8159:  77%|[36m███████▋  [0m| 20/26 [00:19<00:05,  1.09it/s]Epoch: 7/10. Loss: 0.8159:  81%|[36m████████  [0m| 21/26 [00:19<00:04,  1.17it/s]Epoch: 7/10. Loss: 0.8024:  81%|[36m████████  [0m| 21/26 [00:20<00:04,  1.17it/s]Epoch: 7/10. Loss: 0.8024:  85%|[36m████████▍ [0m| 22/26 [00:20<00:03,  1.14it/s]Epoch: 7/10. Loss: 0.8516:  85%|[36m████████▍ [0m| 22/26 [00:21<00:03,  1.14it/s]Epoch: 7/10. Loss: 0.8516:  88%|[36m████████▊ [0m| 23/26 [00:21<00:02,  1.11it/s]Epoch: 7/10. Loss: 0.9741:  88%|[36m████████▊ [0m| 23/26 [00:22<00:02,  1.11it/s]Epoch: 7/10. Loss: 0.9741:  92%|[36m█████████▏[0m| 24/26 [00:22<00:01,  1.10it/s]Epoch: 7/10. Loss: 0.8771:  92%|[36m█████████▏[0m| 24/26 [00:26<00:01,  1.10it/s]Epoch: 7/10. Loss: 0.8771:  96%|[36m█████████▌[0m| 25/26 [00:26<00:01,  1.72s/it]Epoch: 7/10. Loss: 0.7718:  96%|[36m█████████▌[0m| 25/26 [00:26<00:01,  1.72s/it]Epoch: 7/10. Loss: 0.7718: 100%|[36m██████████[0m| 26/26 [00:26<00:00,  1.42s/it]Epoch: 7/10. Loss: 0.7718: 100%|[36m██████████[0m| 26/26 [00:26<00:00,  1.04s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:04,  1.33it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:05,  1.09s/it] 43%|[33m████▎     [0m| 3/7 [00:02<00:03,  1.14it/s] 57%|[33m█████▋    [0m| 4/7 [00:03<00:02,  1.00it/s] 71%|[33m███████▏  [0m| 5/7 [00:04<00:01,  1.29it/s] 86%|[33m████████▌ [0m| 6/7 [00:05<00:00,  1.25it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.57it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.29it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 8/10. Loss: 0.8666:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 8/10. Loss: 0.8666:   4%|[36m▍         [0m| 1/26 [00:00<00:20,  1.23it/s]Epoch: 8/10. Loss: 0.7449:   4%|[36m▍         [0m| 1/26 [00:01<00:20,  1.23it/s]Epoch: 8/10. Loss: 0.7449:   8%|[36m▊         [0m| 2/26 [00:01<00:23,  1.03it/s]Epoch: 8/10. Loss: 0.8313:   8%|[36m▊         [0m| 2/26 [00:02<00:23,  1.03it/s]Epoch: 8/10. Loss: 0.8313:  12%|[36m█▏        [0m| 3/26 [00:02<00:22,  1.02it/s]Epoch: 8/10. Loss: 0.8351:  12%|[36m█▏        [0m| 3/26 [00:03<00:22,  1.02it/s]Epoch: 8/10. Loss: 0.8351:  15%|[36m█▌        [0m| 4/26 [00:03<00:21,  1.05it/s]Epoch: 8/10. Loss: 0.8917:  15%|[36m█▌        [0m| 4/26 [00:04<00:21,  1.05it/s]Epoch: 8/10. Loss: 0.8917:  19%|[36m█▉        [0m| 5/26 [00:04<00:19,  1.08it/s]Epoch: 8/10. Loss: 0.8093:  19%|[36m█▉        [0m| 5/26 [00:05<00:19,  1.08it/s]Epoch: 8/10. Loss: 0.8093:  23%|[36m██▎       [0m| 6/26 [00:05<00:18,  1.06it/s]Epoch: 8/10. Loss: 0.9172:  23%|[36m██▎       [0m| 6/26 [00:06<00:18,  1.06it/s]Epoch: 8/10. Loss: 0.9172:  27%|[36m██▋       [0m| 7/26 [00:06<00:17,  1.10it/s]Epoch: 8/10. Loss: 0.8732:  27%|[36m██▋       [0m| 7/26 [00:07<00:17,  1.10it/s]Epoch: 8/10. Loss: 0.8732:  31%|[36m███       [0m| 8/26 [00:07<00:18,  1.04s/it]Epoch: 8/10. Loss: 0.8673:  31%|[36m███       [0m| 8/26 [00:08<00:18,  1.04s/it]Epoch: 8/10. Loss: 0.8673:  35%|[36m███▍      [0m| 9/26 [00:08<00:17,  1.03s/it]Epoch: 8/10. Loss: 0.8928:  35%|[36m███▍      [0m| 9/26 [00:09<00:17,  1.03s/it]Epoch: 8/10. Loss: 0.8928:  38%|[36m███▊      [0m| 10/26 [00:09<00:16,  1.04s/it]Epoch: 8/10. Loss: 0.8749:  38%|[36m███▊      [0m| 10/26 [00:10<00:16,  1.04s/it]Epoch: 8/10. Loss: 0.8749:  42%|[36m████▏     [0m| 11/26 [00:10<00:15,  1.01s/it]Epoch: 8/10. Loss: 0.8509:  42%|[36m████▏     [0m| 11/26 [00:13<00:15,  1.01s/it]Epoch: 8/10. Loss: 0.8509:  46%|[36m████▌     [0m| 12/26 [00:13<00:20,  1.48s/it]Epoch: 8/10. Loss: 0.7948:  46%|[36m████▌     [0m| 12/26 [00:14<00:20,  1.48s/it]Epoch: 8/10. Loss: 0.7948:  50%|[36m█████     [0m| 13/26 [00:14<00:16,  1.30s/it]Epoch: 8/10. Loss: 0.7308:  50%|[36m█████     [0m| 13/26 [00:15<00:16,  1.30s/it]Epoch: 8/10. Loss: 0.7308:  54%|[36m█████▍    [0m| 14/26 [00:15<00:15,  1.31s/it]Epoch: 8/10. Loss: 0.7888:  54%|[36m█████▍    [0m| 14/26 [00:16<00:15,  1.31s/it]Epoch: 8/10. Loss: 0.7888:  58%|[36m█████▊    [0m| 15/26 [00:16<00:12,  1.17s/it]Epoch: 8/10. Loss: 0.8208:  58%|[36m█████▊    [0m| 15/26 [00:17<00:12,  1.17s/it]Epoch: 8/10. Loss: 0.8208:  62%|[36m██████▏   [0m| 16/26 [00:17<00:10,  1.08s/it]Epoch: 8/10. Loss: 0.8539:  62%|[36m██████▏   [0m| 16/26 [00:18<00:10,  1.08s/it]Epoch: 8/10. Loss: 0.8539:  65%|[36m██████▌   [0m| 17/26 [00:18<00:08,  1.04it/s]Epoch: 8/10. Loss: 0.8623:  65%|[36m██████▌   [0m| 17/26 [00:19<00:08,  1.04it/s]Epoch: 8/10. Loss: 0.8623:  69%|[36m██████▉   [0m| 18/26 [00:19<00:07,  1.03it/s]Epoch: 8/10. Loss: 0.8730:  69%|[36m██████▉   [0m| 18/26 [00:20<00:07,  1.03it/s]Epoch: 8/10. Loss: 0.8730:  73%|[36m███████▎  [0m| 19/26 [00:20<00:08,  1.15s/it]Epoch: 8/10. Loss: 0.7989:  73%|[36m███████▎  [0m| 19/26 [00:21<00:08,  1.15s/it]Epoch: 8/10. Loss: 0.7989:  77%|[36m███████▋  [0m| 20/26 [00:21<00:06,  1.07s/it]Epoch: 8/10. Loss: 0.8544:  77%|[36m███████▋  [0m| 20/26 [00:22<00:06,  1.07s/it]Epoch: 8/10. Loss: 0.8544:  81%|[36m████████  [0m| 21/26 [00:22<00:05,  1.06s/it]Epoch: 8/10. Loss: 0.8536:  81%|[36m████████  [0m| 21/26 [00:23<00:05,  1.06s/it]Epoch: 8/10. Loss: 0.8536:  85%|[36m████████▍ [0m| 22/26 [00:23<00:03,  1.02it/s]Epoch: 8/10. Loss: 0.8416:  85%|[36m████████▍ [0m| 22/26 [00:24<00:03,  1.02it/s]Epoch: 8/10. Loss: 0.8416:  88%|[36m████████▊ [0m| 23/26 [00:24<00:02,  1.04it/s]Epoch: 8/10. Loss: 0.7494:  88%|[36m████████▊ [0m| 23/26 [00:25<00:02,  1.04it/s]Epoch: 8/10. Loss: 0.7494:  92%|[36m█████████▏[0m| 24/26 [00:25<00:01,  1.06it/s]Epoch: 8/10. Loss: 0.8227:  92%|[36m█████████▏[0m| 24/26 [00:26<00:01,  1.06it/s]Epoch: 8/10. Loss: 0.8227:  96%|[36m█████████▌[0m| 25/26 [00:26<00:00,  1.05it/s]Epoch: 8/10. Loss: 1.1623:  96%|[36m█████████▌[0m| 25/26 [00:26<00:00,  1.05it/s]Epoch: 8/10. Loss: 1.1623: 100%|[36m██████████[0m| 26/26 [00:26<00:00,  1.16it/s]Epoch: 8/10. Loss: 1.1623: 100%|[36m██████████[0m| 26/26 [00:26<00:00,  1.03s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:04,  1.30it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:05,  1.17s/it] 43%|[33m████▎     [0m| 3/7 [00:02<00:03,  1.08it/s] 57%|[33m█████▋    [0m| 4/7 [00:04<00:03,  1.05s/it] 71%|[33m███████▏  [0m| 5/7 [00:04<00:01,  1.23it/s] 86%|[33m████████▌ [0m| 6/7 [00:05<00:00,  1.23it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.55it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.25it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 9/10. Loss: 0.8726:   0%|[36m          [0m| 0/26 [00:01<?, ?it/s]Epoch: 9/10. Loss: 0.8726:   4%|[36m▍         [0m| 1/26 [00:01<00:37,  1.51s/it]Epoch: 9/10. Loss: 0.8441:   4%|[36m▍         [0m| 1/26 [00:02<00:37,  1.51s/it]Epoch: 9/10. Loss: 0.8441:   8%|[36m▊         [0m| 2/26 [00:02<00:24,  1.04s/it]Epoch: 9/10. Loss: 1.0218:   8%|[36m▊         [0m| 2/26 [00:03<00:24,  1.04s/it]Epoch: 9/10. Loss: 1.0218:  12%|[36m█▏        [0m| 3/26 [00:03<00:23,  1.01s/it]Epoch: 9/10. Loss: 1.0273:  12%|[36m█▏        [0m| 3/26 [00:04<00:23,  1.01s/it]Epoch: 9/10. Loss: 1.0273:  15%|[36m█▌        [0m| 4/26 [00:04<00:23,  1.07s/it]Epoch: 9/10. Loss: 0.7249:  15%|[36m█▌        [0m| 4/26 [00:05<00:23,  1.07s/it]Epoch: 9/10. Loss: 0.7249:  19%|[36m█▉        [0m| 5/26 [00:05<00:20,  1.05it/s]Epoch: 9/10. Loss: 0.7463:  19%|[36m█▉        [0m| 5/26 [00:05<00:20,  1.05it/s]Epoch: 9/10. Loss: 0.7463:  23%|[36m██▎       [0m| 6/26 [00:05<00:18,  1.08it/s]Epoch: 9/10. Loss: 0.7906:  23%|[36m██▎       [0m| 6/26 [00:06<00:18,  1.08it/s]Epoch: 9/10. Loss: 0.7906:  27%|[36m██▋       [0m| 7/26 [00:06<00:18,  1.05it/s]Epoch: 9/10. Loss: 0.9307:  27%|[36m██▋       [0m| 7/26 [00:08<00:18,  1.05it/s]Epoch: 9/10. Loss: 0.9307:  31%|[36m███       [0m| 8/26 [00:08<00:17,  1.01it/s]Epoch: 9/10. Loss: 0.8493:  31%|[36m███       [0m| 8/26 [00:09<00:17,  1.01it/s]Epoch: 9/10. Loss: 0.8493:  35%|[36m███▍      [0m| 9/26 [00:09<00:17,  1.04s/it]Epoch: 9/10. Loss: 0.7877:  35%|[36m███▍      [0m| 9/26 [00:10<00:17,  1.04s/it]Epoch: 9/10. Loss: 0.7877:  38%|[36m███▊      [0m| 10/26 [00:10<00:16,  1.01s/it]Epoch: 9/10. Loss: 0.8189:  38%|[36m███▊      [0m| 10/26 [00:11<00:16,  1.01s/it]Epoch: 9/10. Loss: 0.8189:  42%|[36m████▏     [0m| 11/26 [00:11<00:15,  1.01s/it]Epoch: 9/10. Loss: 0.8096:  42%|[36m████▏     [0m| 11/26 [00:12<00:15,  1.01s/it]Epoch: 9/10. Loss: 0.8096:  46%|[36m████▌     [0m| 12/26 [00:12<00:13,  1.03it/s]Epoch: 9/10. Loss: 0.8215:  46%|[36m████▌     [0m| 12/26 [00:12<00:13,  1.03it/s]Epoch: 9/10. Loss: 0.8215:  50%|[36m█████     [0m| 13/26 [00:12<00:12,  1.06it/s]Epoch: 9/10. Loss: 0.8349:  50%|[36m█████     [0m| 13/26 [00:13<00:12,  1.06it/s]Epoch: 9/10. Loss: 0.8349:  54%|[36m█████▍    [0m| 14/26 [00:13<00:10,  1.11it/s]Epoch: 9/10. Loss: 0.7627:  54%|[36m█████▍    [0m| 14/26 [00:14<00:10,  1.11it/s]Epoch: 9/10. Loss: 0.7627:  58%|[36m█████▊    [0m| 15/26 [00:14<00:10,  1.08it/s]Epoch: 9/10. Loss: 0.8566:  58%|[36m█████▊    [0m| 15/26 [00:15<00:10,  1.08it/s]Epoch: 9/10. Loss: 0.8566:  62%|[36m██████▏   [0m| 16/26 [00:15<00:09,  1.01it/s]Epoch: 9/10. Loss: 0.8555:  62%|[36m██████▏   [0m| 16/26 [00:16<00:09,  1.01it/s]Epoch: 9/10. Loss: 0.8555:  65%|[36m██████▌   [0m| 17/26 [00:16<00:08,  1.08it/s]Epoch: 9/10. Loss: 0.8667:  65%|[36m██████▌   [0m| 17/26 [00:17<00:08,  1.08it/s]Epoch: 9/10. Loss: 0.8667:  69%|[36m██████▉   [0m| 18/26 [00:17<00:07,  1.10it/s]Epoch: 9/10. Loss: 0.7536:  69%|[36m██████▉   [0m| 18/26 [00:18<00:07,  1.10it/s]Epoch: 9/10. Loss: 0.7536:  73%|[36m███████▎  [0m| 19/26 [00:18<00:06,  1.08it/s]Epoch: 9/10. Loss: 0.7863:  73%|[36m███████▎  [0m| 19/26 [00:19<00:06,  1.08it/s]Epoch: 9/10. Loss: 0.7863:  77%|[36m███████▋  [0m| 20/26 [00:19<00:05,  1.03it/s]Epoch: 9/10. Loss: 0.8645:  77%|[36m███████▋  [0m| 20/26 [00:20<00:05,  1.03it/s]Epoch: 9/10. Loss: 0.8645:  81%|[36m████████  [0m| 21/26 [00:20<00:04,  1.05it/s]Epoch: 9/10. Loss: 0.7066:  81%|[36m████████  [0m| 21/26 [00:21<00:04,  1.05it/s]Epoch: 9/10. Loss: 0.7066:  85%|[36m████████▍ [0m| 22/26 [00:21<00:03,  1.07it/s]Epoch: 9/10. Loss: 0.9329:  85%|[36m████████▍ [0m| 22/26 [00:22<00:03,  1.07it/s]Epoch: 9/10. Loss: 0.9329:  88%|[36m████████▊ [0m| 23/26 [00:22<00:02,  1.10it/s]Epoch: 9/10. Loss: 0.7293:  88%|[36m████████▊ [0m| 23/26 [00:23<00:02,  1.10it/s]Epoch: 9/10. Loss: 0.7293:  92%|[36m█████████▏[0m| 24/26 [00:23<00:01,  1.13it/s]Epoch: 9/10. Loss: 0.8098:  92%|[36m█████████▏[0m| 24/26 [00:23<00:01,  1.13it/s]Epoch: 9/10. Loss: 0.8098:  96%|[36m█████████▌[0m| 25/26 [00:23<00:00,  1.12it/s]Epoch: 9/10. Loss: 0.8969:  96%|[36m█████████▌[0m| 25/26 [00:24<00:00,  1.12it/s]Epoch: 9/10. Loss: 0.8969: 100%|[36m██████████[0m| 26/26 [00:24<00:00,  1.32it/s]Epoch: 9/10. Loss: 0.8969: 100%|[36m██████████[0m| 26/26 [00:24<00:00,  1.07it/s]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:04,  1.24it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:05,  1.20s/it] 43%|[33m████▎     [0m| 3/7 [00:02<00:03,  1.04it/s] 57%|[33m█████▋    [0m| 4/7 [00:04<00:03,  1.07s/it] 71%|[33m███████▏  [0m| 5/7 [00:04<00:01,  1.21it/s] 86%|[33m████████▌ [0m| 6/7 [00:05<00:00,  1.20it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.52it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.22it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 0/10. Loss: 1.1125:   0%|[36m          [0m| 0/26 [00:01<?, ?it/s]Epoch: 0/10. Loss: 1.1125:   4%|[36m▍         [0m| 1/26 [00:01<00:29,  1.16s/it]Epoch: 0/10. Loss: 2.3270:   4%|[36m▍         [0m| 1/26 [00:02<00:29,  1.16s/it]Epoch: 0/10. Loss: 2.3270:   8%|[36m▊         [0m| 2/26 [00:02<00:30,  1.27s/it]Epoch: 0/10. Loss: 1.5530:   8%|[36m▊         [0m| 2/26 [00:05<00:30,  1.27s/it]Epoch: 0/10. Loss: 1.5530:  12%|[36m█▏        [0m| 3/26 [00:05<00:48,  2.12s/it]Epoch: 0/10. Loss: 1.5616:  12%|[36m█▏        [0m| 3/26 [00:07<00:48,  2.12s/it]Epoch: 0/10. Loss: 1.5616:  15%|[36m█▌        [0m| 4/26 [00:07<00:44,  2.04s/it]Epoch: 0/10. Loss: 1.0415:  15%|[36m█▌        [0m| 4/26 [00:08<00:44,  2.04s/it]Epoch: 0/10. Loss: 1.0415:  19%|[36m█▉        [0m| 5/26 [00:08<00:33,  1.62s/it]Epoch: 0/10. Loss: 1.0618:  19%|[36m█▉        [0m| 5/26 [00:10<00:33,  1.62s/it]Epoch: 0/10. Loss: 1.0618:  23%|[36m██▎       [0m| 6/26 [00:10<00:33,  1.67s/it]Epoch: 0/10. Loss: 1.0508:  23%|[36m██▎       [0m| 6/26 [00:11<00:33,  1.67s/it]Epoch: 0/10. Loss: 1.0508:  27%|[36m██▋       [0m| 7/26 [00:11<00:27,  1.45s/it]Epoch: 0/10. Loss: 1.1047:  27%|[36m██▋       [0m| 7/26 [00:13<00:27,  1.45s/it]Epoch: 0/10. Loss: 1.1047:  31%|[36m███       [0m| 8/26 [00:13<00:30,  1.68s/it]Epoch: 0/10. Loss: 1.5875:  31%|[36m███       [0m| 8/26 [00:14<00:30,  1.68s/it]Epoch: 0/10. Loss: 1.5875:  35%|[36m███▍      [0m| 9/26 [00:14<00:25,  1.49s/it]Epoch: 0/10. Loss: 1.3868:  35%|[36m███▍      [0m| 9/26 [00:15<00:25,  1.49s/it]Epoch: 0/10. Loss: 1.3868:  38%|[36m███▊      [0m| 10/26 [00:15<00:21,  1.31s/it]Epoch: 0/10. Loss: 1.4169:  38%|[36m███▊      [0m| 10/26 [00:16<00:21,  1.31s/it]Epoch: 0/10. Loss: 1.4169:  42%|[36m████▏     [0m| 11/26 [00:16<00:18,  1.26s/it]Epoch: 0/10. Loss: 1.0507:  42%|[36m████▏     [0m| 11/26 [00:17<00:18,  1.26s/it]Epoch: 0/10. Loss: 1.0507:  46%|[36m████▌     [0m| 12/26 [00:17<00:16,  1.19s/it]Epoch: 0/10. Loss: 1.1298:  46%|[36m████▌     [0m| 12/26 [00:18<00:16,  1.19s/it]Epoch: 0/10. Loss: 1.1298:  50%|[36m█████     [0m| 13/26 [00:18<00:14,  1.14s/it]Epoch: 0/10. Loss: 1.0712:  50%|[36m█████     [0m| 13/26 [00:19<00:14,  1.14s/it]Epoch: 0/10. Loss: 1.0712:  54%|[36m█████▍    [0m| 14/26 [00:19<00:13,  1.11s/it]Epoch: 0/10. Loss: 1.0651:  54%|[36m█████▍    [0m| 14/26 [00:20<00:13,  1.11s/it]Epoch: 0/10. Loss: 1.0651:  58%|[36m█████▊    [0m| 15/26 [00:20<00:12,  1.12s/it]Epoch: 0/10. Loss: 1.3473:  58%|[36m█████▊    [0m| 15/26 [00:21<00:12,  1.12s/it]Epoch: 0/10. Loss: 1.3473:  62%|[36m██████▏   [0m| 16/26 [00:21<00:10,  1.10s/it]Epoch: 0/10. Loss: 1.0560:  62%|[36m██████▏   [0m| 16/26 [00:22<00:10,  1.10s/it]Epoch: 0/10. Loss: 1.0560:  65%|[36m██████▌   [0m| 17/26 [00:22<00:09,  1.06s/it]Epoch: 0/10. Loss: 1.1227:  65%|[36m██████▌   [0m| 17/26 [00:23<00:09,  1.06s/it]Epoch: 0/10. Loss: 1.1227:  69%|[36m██████▉   [0m| 18/26 [00:23<00:08,  1.06s/it]Epoch: 0/10. Loss: 1.0386:  69%|[36m██████▉   [0m| 18/26 [00:24<00:08,  1.06s/it]Epoch: 0/10. Loss: 1.0386:  73%|[36m███████▎  [0m| 19/26 [00:24<00:07,  1.07s/it]Epoch: 0/10. Loss: 0.9359:  73%|[36m███████▎  [0m| 19/26 [00:25<00:07,  1.07s/it]Epoch: 0/10. Loss: 0.9359:  77%|[36m███████▋  [0m| 20/26 [00:25<00:06,  1.00s/it]Epoch: 0/10. Loss: 1.0664:  77%|[36m███████▋  [0m| 20/26 [00:26<00:06,  1.00s/it]Epoch: 0/10. Loss: 1.0664:  81%|[36m████████  [0m| 21/26 [00:26<00:04,  1.01it/s]Epoch: 0/10. Loss: 1.1284:  81%|[36m████████  [0m| 21/26 [00:27<00:04,  1.01it/s]Epoch: 0/10. Loss: 1.1284:  85%|[36m████████▍ [0m| 22/26 [00:27<00:03,  1.05it/s]Epoch: 0/10. Loss: 1.2366:  85%|[36m████████▍ [0m| 22/26 [00:28<00:03,  1.05it/s]Epoch: 0/10. Loss: 1.2366:  88%|[36m████████▊ [0m| 23/26 [00:28<00:02,  1.01it/s]Epoch: 0/10. Loss: 1.2078:  88%|[36m████████▊ [0m| 23/26 [00:29<00:02,  1.01it/s]Epoch: 0/10. Loss: 1.2078:  92%|[36m█████████▏[0m| 24/26 [00:29<00:01,  1.03it/s]Epoch: 0/10. Loss: 1.0064:  92%|[36m█████████▏[0m| 24/26 [00:30<00:01,  1.03it/s]Epoch: 0/10. Loss: 1.0064:  96%|[36m█████████▌[0m| 25/26 [00:30<00:01,  1.00s/it]Epoch: 0/10. Loss: 0.9860:  96%|[36m█████████▌[0m| 25/26 [00:31<00:01,  1.00s/it]Epoch: 0/10. Loss: 0.9860: 100%|[36m██████████[0m| 26/26 [00:31<00:00,  1.13it/s]Epoch: 0/10. Loss: 0.9860: 100%|[36m██████████[0m| 26/26 [00:31<00:00,  1.20s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:04,  1.20it/s] 29%|[33m██▊       [0m| 2/7 [00:04<00:11,  2.29s/it] 43%|[33m████▎     [0m| 3/7 [00:04<00:06,  1.57s/it] 57%|[33m█████▋    [0m| 4/7 [00:07<00:06,  2.04s/it] 71%|[33m███████▏  [0m| 5/7 [00:08<00:02,  1.47s/it] 86%|[33m████████▌ [0m| 6/7 [00:08<00:01,  1.27s/it]100%|[33m██████████[0m| 7/7 [00:10<00:00,  1.41s/it]100%|[33m██████████[0m| 7/7 [00:10<00:00,  1.52s/it]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 1/10. Loss: 1.0068:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 1/10. Loss: 1.0068:   4%|[36m▍         [0m| 1/26 [00:00<00:24,  1.02it/s]Epoch: 1/10. Loss: 1.0399:   4%|[36m▍         [0m| 1/26 [00:01<00:24,  1.02it/s]Epoch: 1/10. Loss: 1.0399:   8%|[36m▊         [0m| 2/26 [00:01<00:22,  1.05it/s]Epoch: 1/10. Loss: 1.1232:   8%|[36m▊         [0m| 2/26 [00:02<00:22,  1.05it/s]Epoch: 1/10. Loss: 1.1232:  12%|[36m█▏        [0m| 3/26 [00:02<00:22,  1.02it/s]Epoch: 1/10. Loss: 1.0360:  12%|[36m█▏        [0m| 3/26 [00:05<00:22,  1.02it/s]Epoch: 1/10. Loss: 1.0360:  15%|[36m█▌        [0m| 4/26 [00:05<00:37,  1.70s/it]Epoch: 1/10. Loss: 1.0265:  15%|[36m█▌        [0m| 4/26 [00:08<00:37,  1.70s/it]Epoch: 1/10. Loss: 1.0265:  19%|[36m█▉        [0m| 5/26 [00:08<00:43,  2.06s/it]Epoch: 1/10. Loss: 1.1174:  19%|[36m█▉        [0m| 5/26 [00:09<00:43,  2.06s/it]Epoch: 1/10. Loss: 1.1174:  23%|[36m██▎       [0m| 6/26 [00:09<00:33,  1.67s/it]Epoch: 1/10. Loss: 1.0053:  23%|[36m██▎       [0m| 6/26 [00:10<00:33,  1.67s/it]Epoch: 1/10. Loss: 1.0053:  27%|[36m██▋       [0m| 7/26 [00:10<00:26,  1.41s/it]Epoch: 1/10. Loss: 0.9939:  27%|[36m██▋       [0m| 7/26 [00:11<00:26,  1.41s/it]Epoch: 1/10. Loss: 0.9939:  31%|[36m███       [0m| 8/26 [00:11<00:23,  1.29s/it]Epoch: 1/10. Loss: 1.0074:  31%|[36m███       [0m| 8/26 [00:12<00:23,  1.29s/it]Epoch: 1/10. Loss: 1.0074:  35%|[36m███▍      [0m| 9/26 [00:12<00:19,  1.14s/it]Epoch: 1/10. Loss: 1.2547:  35%|[36m███▍      [0m| 9/26 [00:13<00:19,  1.14s/it]Epoch: 1/10. Loss: 1.2547:  38%|[36m███▊      [0m| 10/26 [00:14<00:22,  1.40s/it]Epoch: 1/10. Loss: 0.9997:  38%|[36m███▊      [0m| 10/26 [00:14<00:22,  1.40s/it]Epoch: 1/10. Loss: 0.9997:  42%|[36m████▏     [0m| 11/26 [00:14<00:18,  1.25s/it]Epoch: 1/10. Loss: 1.0081:  42%|[36m████▏     [0m| 11/26 [00:15<00:18,  1.25s/it]Epoch: 1/10. Loss: 1.0081:  46%|[36m████▌     [0m| 12/26 [00:15<00:16,  1.15s/it]Epoch: 1/10. Loss: 1.0172:  46%|[36m████▌     [0m| 12/26 [00:16<00:16,  1.15s/it]Epoch: 1/10. Loss: 1.0172:  50%|[36m█████     [0m| 13/26 [00:16<00:13,  1.07s/it]Epoch: 1/10. Loss: 1.0194:  50%|[36m█████     [0m| 13/26 [00:17<00:13,  1.07s/it]Epoch: 1/10. Loss: 1.0194:  54%|[36m█████▍    [0m| 14/26 [00:17<00:12,  1.00s/it]Epoch: 1/10. Loss: 1.1549:  54%|[36m█████▍    [0m| 14/26 [00:19<00:12,  1.00s/it]Epoch: 1/10. Loss: 1.1549:  58%|[36m█████▊    [0m| 15/26 [00:19<00:14,  1.30s/it]Epoch: 1/10. Loss: 1.0520:  58%|[36m█████▊    [0m| 15/26 [00:20<00:14,  1.30s/it]Epoch: 1/10. Loss: 1.0520:  62%|[36m██████▏   [0m| 16/26 [00:20<00:11,  1.19s/it]Epoch: 1/10. Loss: 1.0435:  62%|[36m██████▏   [0m| 16/26 [00:21<00:11,  1.19s/it]Epoch: 1/10. Loss: 1.0435:  65%|[36m██████▌   [0m| 17/26 [00:21<00:10,  1.12s/it]Epoch: 1/10. Loss: 1.0196:  65%|[36m██████▌   [0m| 17/26 [00:22<00:10,  1.12s/it]Epoch: 1/10. Loss: 1.0196:  69%|[36m██████▉   [0m| 18/26 [00:22<00:08,  1.07s/it]Epoch: 1/10. Loss: 0.9890:  69%|[36m██████▉   [0m| 18/26 [00:23<00:08,  1.07s/it]Epoch: 1/10. Loss: 0.9890:  73%|[36m███████▎  [0m| 19/26 [00:23<00:07,  1.05s/it]Epoch: 1/10. Loss: 1.0746:  73%|[36m███████▎  [0m| 19/26 [00:24<00:07,  1.05s/it]Epoch: 1/10. Loss: 1.0746:  77%|[36m███████▋  [0m| 20/26 [00:24<00:06,  1.07s/it]Epoch: 1/10. Loss: 1.2641:  77%|[36m███████▋  [0m| 20/26 [00:25<00:06,  1.07s/it]Epoch: 1/10. Loss: 1.2641:  81%|[36m████████  [0m| 21/26 [00:25<00:05,  1.08s/it]Epoch: 1/10. Loss: 1.0508:  81%|[36m████████  [0m| 21/26 [00:26<00:05,  1.08s/it]Epoch: 1/10. Loss: 1.0508:  85%|[36m████████▍ [0m| 22/26 [00:26<00:04,  1.03s/it]Epoch: 1/10. Loss: 0.9868:  85%|[36m████████▍ [0m| 22/26 [00:27<00:04,  1.03s/it]Epoch: 1/10. Loss: 0.9868:  88%|[36m████████▊ [0m| 23/26 [00:27<00:03,  1.10s/it]Epoch: 1/10. Loss: 1.2532:  88%|[36m████████▊ [0m| 23/26 [00:28<00:03,  1.10s/it]Epoch: 1/10. Loss: 1.2532:  92%|[36m█████████▏[0m| 24/26 [00:29<00:02,  1.13s/it]Epoch: 1/10. Loss: 1.0626:  92%|[36m█████████▏[0m| 24/26 [00:30<00:02,  1.13s/it]Epoch: 1/10. Loss: 1.0626:  96%|[36m█████████▌[0m| 25/26 [00:30<00:01,  1.21s/it]Epoch: 1/10. Loss: 1.0267:  96%|[36m█████████▌[0m| 25/26 [00:31<00:01,  1.21s/it]Epoch: 1/10. Loss: 1.0267: 100%|[36m██████████[0m| 26/26 [00:31<00:00,  1.04s/it]Epoch: 1/10. Loss: 1.0267: 100%|[36m██████████[0m| 26/26 [00:31<00:00,  1.19s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:01<00:07,  1.25s/it] 29%|[33m██▊       [0m| 2/7 [00:03<00:10,  2.02s/it] 43%|[33m████▎     [0m| 3/7 [00:04<00:05,  1.43s/it] 57%|[33m█████▋    [0m| 4/7 [00:06<00:04,  1.46s/it] 71%|[33m███████▏  [0m| 5/7 [00:06<00:02,  1.11s/it] 86%|[33m████████▌ [0m| 6/7 [00:07<00:01,  1.04s/it]100%|[33m██████████[0m| 7/7 [00:07<00:00,  1.24it/s]100%|[33m██████████[0m| 7/7 [00:07<00:00,  1.11s/it]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 2/10. Loss: 0.9903:   0%|[36m          [0m| 0/26 [00:01<?, ?it/s]Epoch: 2/10. Loss: 0.9903:   4%|[36m▍         [0m| 1/26 [00:01<00:27,  1.11s/it]Epoch: 2/10. Loss: 0.9702:   4%|[36m▍         [0m| 1/26 [00:01<00:27,  1.11s/it]Epoch: 2/10. Loss: 0.9702:   8%|[36m▊         [0m| 2/26 [00:02<00:23,  1.01it/s]Epoch: 2/10. Loss: 0.9718:   8%|[36m▊         [0m| 2/26 [00:02<00:23,  1.01it/s]Epoch: 2/10. Loss: 0.9718:  12%|[36m█▏        [0m| 3/26 [00:02<00:22,  1.02it/s]Epoch: 2/10. Loss: 0.9237:  12%|[36m█▏        [0m| 3/26 [00:03<00:22,  1.02it/s]Epoch: 2/10. Loss: 0.9237:  15%|[36m█▌        [0m| 4/26 [00:03<00:20,  1.06it/s]Epoch: 2/10. Loss: 1.0569:  15%|[36m█▌        [0m| 4/26 [00:04<00:20,  1.06it/s]Epoch: 2/10. Loss: 1.0569:  19%|[36m█▉        [0m| 5/26 [00:04<00:20,  1.01it/s]Epoch: 2/10. Loss: 1.1386:  19%|[36m█▉        [0m| 5/26 [00:05<00:20,  1.01it/s]Epoch: 2/10. Loss: 1.1386:  23%|[36m██▎       [0m| 6/26 [00:05<00:19,  1.05it/s]Epoch: 2/10. Loss: 1.0523:  23%|[36m██▎       [0m| 6/26 [00:06<00:19,  1.05it/s]Epoch: 2/10. Loss: 1.0523:  27%|[36m██▋       [0m| 7/26 [00:06<00:17,  1.09it/s]Epoch: 2/10. Loss: 1.0306:  27%|[36m██▋       [0m| 7/26 [00:07<00:17,  1.09it/s]Epoch: 2/10. Loss: 1.0306:  31%|[36m███       [0m| 8/26 [00:07<00:16,  1.09it/s]Epoch: 2/10. Loss: 1.1094:  31%|[36m███       [0m| 8/26 [00:10<00:16,  1.09it/s]Epoch: 2/10. Loss: 1.1094:  35%|[36m███▍      [0m| 9/26 [00:11<00:28,  1.70s/it]Epoch: 2/10. Loss: 1.1909:  35%|[36m███▍      [0m| 9/26 [00:11<00:28,  1.70s/it]Epoch: 2/10. Loss: 1.1909:  38%|[36m███▊      [0m| 10/26 [00:11<00:23,  1.46s/it]Epoch: 2/10. Loss: 1.0024:  38%|[36m███▊      [0m| 10/26 [00:12<00:23,  1.46s/it]Epoch: 2/10. Loss: 1.0024:  42%|[36m████▏     [0m| 11/26 [00:12<00:19,  1.32s/it]Epoch: 2/10. Loss: 0.9578:  42%|[36m████▏     [0m| 11/26 [00:14<00:19,  1.32s/it]Epoch: 2/10. Loss: 0.9578:  46%|[36m████▌     [0m| 12/26 [00:14<00:17,  1.27s/it]Epoch: 2/10. Loss: 1.0132:  46%|[36m████▌     [0m| 12/26 [00:15<00:17,  1.27s/it]Epoch: 2/10. Loss: 1.0132:  50%|[36m█████     [0m| 13/26 [00:15<00:15,  1.21s/it]Epoch: 2/10. Loss: 1.1552:  50%|[36m█████     [0m| 13/26 [00:16<00:15,  1.21s/it]Epoch: 2/10. Loss: 1.1552:  54%|[36m█████▍    [0m| 14/26 [00:16<00:14,  1.17s/it]Epoch: 2/10. Loss: 1.1051:  54%|[36m█████▍    [0m| 14/26 [00:17<00:14,  1.17s/it]Epoch: 2/10. Loss: 1.1051:  58%|[36m█████▊    [0m| 15/26 [00:17<00:12,  1.15s/it]Epoch: 2/10. Loss: 0.9761:  58%|[36m█████▊    [0m| 15/26 [00:18<00:12,  1.15s/it]Epoch: 2/10. Loss: 0.9761:  62%|[36m██████▏   [0m| 16/26 [00:18<00:11,  1.11s/it]Epoch: 2/10. Loss: 1.0375:  62%|[36m██████▏   [0m| 16/26 [00:19<00:11,  1.11s/it]Epoch: 2/10. Loss: 1.0375:  65%|[36m██████▌   [0m| 17/26 [00:19<00:09,  1.05s/it]Epoch: 2/10. Loss: 0.9939:  65%|[36m██████▌   [0m| 17/26 [00:20<00:09,  1.05s/it]Epoch: 2/10. Loss: 0.9939:  69%|[36m██████▉   [0m| 18/26 [00:20<00:08,  1.03s/it]Epoch: 2/10. Loss: 1.0780:  69%|[36m██████▉   [0m| 18/26 [00:21<00:08,  1.03s/it]Epoch: 2/10. Loss: 1.0780:  73%|[36m███████▎  [0m| 19/26 [00:21<00:07,  1.02s/it]Epoch: 2/10. Loss: 1.0233:  73%|[36m███████▎  [0m| 19/26 [00:22<00:07,  1.02s/it]Epoch: 2/10. Loss: 1.0233:  77%|[36m███████▋  [0m| 20/26 [00:22<00:06,  1.01s/it]Epoch: 2/10. Loss: 0.9895:  77%|[36m███████▋  [0m| 20/26 [00:23<00:06,  1.01s/it]Epoch: 2/10. Loss: 0.9895:  81%|[36m████████  [0m| 21/26 [00:23<00:05,  1.01s/it]Epoch: 2/10. Loss: 1.0110:  81%|[36m████████  [0m| 21/26 [00:24<00:05,  1.01s/it]Epoch: 2/10. Loss: 1.0110:  85%|[36m████████▍ [0m| 22/26 [00:24<00:03,  1.03it/s]Epoch: 2/10. Loss: 1.0316:  85%|[36m████████▍ [0m| 22/26 [00:25<00:03,  1.03it/s]Epoch: 2/10. Loss: 1.0316:  88%|[36m████████▊ [0m| 23/26 [00:25<00:03,  1.00s/it]Epoch: 2/10. Loss: 0.9901:  88%|[36m████████▊ [0m| 23/26 [00:26<00:03,  1.00s/it]Epoch: 2/10. Loss: 0.9901:  92%|[36m█████████▏[0m| 24/26 [00:26<00:01,  1.01it/s]Epoch: 2/10. Loss: 1.0856:  92%|[36m█████████▏[0m| 24/26 [00:27<00:01,  1.01it/s]Epoch: 2/10. Loss: 1.0856:  96%|[36m█████████▌[0m| 25/26 [00:27<00:01,  1.00s/it]Epoch: 2/10. Loss: 1.0484:  96%|[36m█████████▌[0m| 25/26 [00:27<00:01,  1.00s/it]Epoch: 2/10. Loss: 1.0484: 100%|[36m██████████[0m| 26/26 [00:27<00:00,  1.10it/s]Epoch: 2/10. Loss: 1.0484: 100%|[36m██████████[0m| 26/26 [00:27<00:00,  1.07s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:02<00:16,  2.77s/it] 29%|[33m██▊       [0m| 2/7 [00:08<00:22,  4.58s/it] 43%|[33m████▎     [0m| 3/7 [00:09<00:11,  2.91s/it] 57%|[33m█████▋    [0m| 4/7 [00:10<00:06,  2.28s/it] 71%|[33m███████▏  [0m| 5/7 [00:11<00:03,  1.61s/it] 86%|[33m████████▌ [0m| 6/7 [00:12<00:01,  1.46s/it]100%|[33m██████████[0m| 7/7 [00:12<00:00,  1.08s/it]100%|[33m██████████[0m| 7/7 [00:12<00:00,  1.82s/it]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 3/10. Loss: 0.9843:   0%|[36m          [0m| 0/26 [00:01<?, ?it/s]Epoch: 3/10. Loss: 0.9843:   4%|[36m▍         [0m| 1/26 [00:01<00:42,  1.69s/it]Epoch: 3/10. Loss: 0.9239:   4%|[36m▍         [0m| 1/26 [00:03<00:42,  1.69s/it]Epoch: 3/10. Loss: 0.9239:   8%|[36m▊         [0m| 2/26 [00:03<00:36,  1.54s/it]Epoch: 3/10. Loss: 1.0753:   8%|[36m▊         [0m| 2/26 [00:04<00:36,  1.54s/it]Epoch: 3/10. Loss: 1.0753:  12%|[36m█▏        [0m| 3/26 [00:04<00:30,  1.32s/it]Epoch: 3/10. Loss: 1.0543:  12%|[36m█▏        [0m| 3/26 [00:05<00:30,  1.32s/it]Epoch: 3/10. Loss: 1.0543:  15%|[36m█▌        [0m| 4/26 [00:05<00:26,  1.23s/it]Epoch: 3/10. Loss: 1.0106:  15%|[36m█▌        [0m| 4/26 [00:06<00:26,  1.23s/it]Epoch: 3/10. Loss: 1.0106:  19%|[36m█▉        [0m| 5/26 [00:06<00:26,  1.27s/it]Epoch: 3/10. Loss: 1.0495:  19%|[36m█▉        [0m| 5/26 [00:07<00:26,  1.27s/it]Epoch: 3/10. Loss: 1.0495:  23%|[36m██▎       [0m| 6/26 [00:07<00:22,  1.14s/it]Epoch: 3/10. Loss: 1.0533:  23%|[36m██▎       [0m| 6/26 [00:08<00:22,  1.14s/it]Epoch: 3/10. Loss: 1.0533:  27%|[36m██▋       [0m| 7/26 [00:08<00:21,  1.13s/it]Epoch: 3/10. Loss: 0.9541:  27%|[36m██▋       [0m| 7/26 [00:09<00:21,  1.13s/it]Epoch: 3/10. Loss: 0.9541:  31%|[36m███       [0m| 8/26 [00:09<00:19,  1.07s/it]Epoch: 3/10. Loss: 0.9566:  31%|[36m███       [0m| 8/26 [00:10<00:19,  1.07s/it]Epoch: 3/10. Loss: 0.9566:  35%|[36m███▍      [0m| 9/26 [00:10<00:17,  1.03s/it]Epoch: 3/10. Loss: 0.9742:  35%|[36m███▍      [0m| 9/26 [00:11<00:17,  1.03s/it]Epoch: 3/10. Loss: 0.9742:  38%|[36m███▊      [0m| 10/26 [00:11<00:18,  1.16s/it]Epoch: 3/10. Loss: 1.0452:  38%|[36m███▊      [0m| 10/26 [00:14<00:18,  1.16s/it]Epoch: 3/10. Loss: 1.0452:  42%|[36m████▏     [0m| 11/26 [00:14<00:22,  1.47s/it]Epoch: 3/10. Loss: 0.9926:  42%|[36m████▏     [0m| 11/26 [00:16<00:22,  1.47s/it]Epoch: 3/10. Loss: 0.9926:  46%|[36m████▌     [0m| 12/26 [00:16<00:24,  1.73s/it]Epoch: 3/10. Loss: 1.0207:  46%|[36m████▌     [0m| 12/26 [00:17<00:24,  1.73s/it]Epoch: 3/10. Loss: 1.0207:  50%|[36m█████     [0m| 13/26 [00:17<00:21,  1.62s/it]Epoch: 3/10. Loss: 1.0306:  50%|[36m█████     [0m| 13/26 [00:18<00:21,  1.62s/it]Epoch: 3/10. Loss: 1.0306:  54%|[36m█████▍    [0m| 14/26 [00:18<00:17,  1.46s/it]Epoch: 3/10. Loss: 0.9615:  54%|[36m█████▍    [0m| 14/26 [00:19<00:17,  1.46s/it]Epoch: 3/10. Loss: 0.9615:  58%|[36m█████▊    [0m| 15/26 [00:19<00:14,  1.31s/it]Epoch: 3/10. Loss: 0.9452:  58%|[36m█████▊    [0m| 15/26 [00:20<00:14,  1.31s/it]Epoch: 3/10. Loss: 0.9452:  62%|[36m██████▏   [0m| 16/26 [00:20<00:12,  1.22s/it]Epoch: 3/10. Loss: 0.9666:  62%|[36m██████▏   [0m| 16/26 [00:21<00:12,  1.22s/it]Epoch: 3/10. Loss: 0.9666:  65%|[36m██████▌   [0m| 17/26 [00:21<00:10,  1.13s/it]Epoch: 3/10. Loss: 1.1356:  65%|[36m██████▌   [0m| 17/26 [00:22<00:10,  1.13s/it]Epoch: 3/10. Loss: 1.1356:  69%|[36m██████▉   [0m| 18/26 [00:22<00:08,  1.07s/it]Epoch: 3/10. Loss: 0.9314:  69%|[36m██████▉   [0m| 18/26 [00:26<00:08,  1.07s/it]Epoch: 3/10. Loss: 0.9314:  73%|[36m███████▎  [0m| 19/26 [00:26<00:13,  1.92s/it]Epoch: 3/10. Loss: 0.9826:  73%|[36m███████▎  [0m| 19/26 [00:27<00:13,  1.92s/it]Epoch: 3/10. Loss: 0.9826:  77%|[36m███████▋  [0m| 20/26 [00:27<00:10,  1.68s/it]Epoch: 3/10. Loss: 1.0071:  77%|[36m███████▋  [0m| 20/26 [00:29<00:10,  1.68s/it]Epoch: 3/10. Loss: 1.0071:  81%|[36m████████  [0m| 21/26 [00:29<00:08,  1.63s/it]Epoch: 3/10. Loss: 1.0227:  81%|[36m████████  [0m| 21/26 [00:30<00:08,  1.63s/it]Epoch: 3/10. Loss: 1.0227:  85%|[36m████████▍ [0m| 22/26 [00:30<00:05,  1.44s/it]Epoch: 3/10. Loss: 0.9742:  85%|[36m████████▍ [0m| 22/26 [00:34<00:05,  1.44s/it]Epoch: 3/10. Loss: 0.9742:  88%|[36m████████▊ [0m| 23/26 [00:34<00:07,  2.43s/it]Epoch: 3/10. Loss: 1.0184:  88%|[36m████████▊ [0m| 23/26 [00:37<00:07,  2.43s/it]Epoch: 3/10. Loss: 1.0184:  92%|[36m█████████▏[0m| 24/26 [00:37<00:04,  2.45s/it]Epoch: 3/10. Loss: 0.9259:  92%|[36m█████████▏[0m| 24/26 [00:38<00:04,  2.45s/it]Epoch: 3/10. Loss: 0.9259:  96%|[36m█████████▌[0m| 25/26 [00:38<00:02,  2.02s/it]Epoch: 3/10. Loss: 1.0356:  96%|[36m█████████▌[0m| 25/26 [00:39<00:02,  2.02s/it]Epoch: 3/10. Loss: 1.0356: 100%|[36m██████████[0m| 26/26 [00:39<00:00,  1.75s/it]Epoch: 3/10. Loss: 1.0356: 100%|[36m██████████[0m| 26/26 [00:39<00:00,  1.52s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:05,  1.05it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:07,  1.53s/it] 43%|[33m████▎     [0m| 3/7 [00:03<00:04,  1.15s/it] 57%|[33m█████▋    [0m| 4/7 [00:05<00:04,  1.42s/it] 71%|[33m███████▏  [0m| 5/7 [00:06<00:02,  1.22s/it] 86%|[33m████████▌ [0m| 6/7 [00:07<00:01,  1.10s/it]100%|[33m██████████[0m| 7/7 [00:08<00:00,  1.07s/it]100%|[33m██████████[0m| 7/7 [00:08<00:00,  1.16s/it]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 4/10. Loss: 0.9699:   0%|[36m          [0m| 0/26 [00:01<?, ?it/s]Epoch: 4/10. Loss: 0.9699:   4%|[36m▍         [0m| 1/26 [00:01<00:28,  1.13s/it]Epoch: 4/10. Loss: 0.9657:   4%|[36m▍         [0m| 1/26 [00:02<00:28,  1.13s/it]Epoch: 4/10. Loss: 0.9657:   8%|[36m▊         [0m| 2/26 [00:02<00:25,  1.07s/it]Epoch: 4/10. Loss: 1.0978:   8%|[36m▊         [0m| 2/26 [00:04<00:25,  1.07s/it]Epoch: 4/10. Loss: 1.0978:  12%|[36m█▏        [0m| 3/26 [00:04<00:41,  1.79s/it]Epoch: 4/10. Loss: 1.0016:  12%|[36m█▏        [0m| 3/26 [00:06<00:41,  1.79s/it]Epoch: 4/10. Loss: 1.0016:  15%|[36m█▌        [0m| 4/26 [00:06<00:40,  1.85s/it]Epoch: 4/10. Loss: 0.9938:  15%|[36m█▌        [0m| 4/26 [00:07<00:40,  1.85s/it]Epoch: 4/10. Loss: 0.9938:  19%|[36m█▉        [0m| 5/26 [00:07<00:32,  1.55s/it]Epoch: 4/10. Loss: 1.0701:  19%|[36m█▉        [0m| 5/26 [00:08<00:32,  1.55s/it]Epoch: 4/10. Loss: 1.0701:  23%|[36m██▎       [0m| 6/26 [00:08<00:27,  1.35s/it]Epoch: 4/10. Loss: 0.9916:  23%|[36m██▎       [0m| 6/26 [00:09<00:27,  1.35s/it]Epoch: 4/10. Loss: 0.9916:  27%|[36m██▋       [0m| 7/26 [00:09<00:24,  1.28s/it]Epoch: 4/10. Loss: 0.9527:  27%|[36m██▋       [0m| 7/26 [00:10<00:24,  1.28s/it]Epoch: 4/10. Loss: 0.9527:  31%|[36m███       [0m| 8/26 [00:10<00:21,  1.21s/it]Epoch: 4/10. Loss: 1.0304:  31%|[36m███       [0m| 8/26 [00:12<00:21,  1.21s/it]Epoch: 4/10. Loss: 1.0304:  35%|[36m███▍      [0m| 9/26 [00:12<00:22,  1.35s/it]Epoch: 4/10. Loss: 0.9549:  35%|[36m███▍      [0m| 9/26 [00:13<00:22,  1.35s/it]Epoch: 4/10. Loss: 0.9549:  38%|[36m███▊      [0m| 10/26 [00:13<00:20,  1.26s/it]Epoch: 4/10. Loss: 0.9948:  38%|[36m███▊      [0m| 10/26 [00:14<00:20,  1.26s/it]Epoch: 4/10. Loss: 0.9948:  42%|[36m████▏     [0m| 11/26 [00:14<00:17,  1.17s/it]Epoch: 4/10. Loss: 0.9189:  42%|[36m████▏     [0m| 11/26 [00:15<00:17,  1.17s/it]Epoch: 4/10. Loss: 0.9189:  46%|[36m████▌     [0m| 12/26 [00:15<00:14,  1.06s/it]Epoch: 4/10. Loss: 0.9575:  46%|[36m████▌     [0m| 12/26 [00:16<00:14,  1.06s/it]Epoch: 4/10. Loss: 0.9575:  50%|[36m█████     [0m| 13/26 [00:16<00:13,  1.03s/it]Epoch: 4/10. Loss: 0.9689:  50%|[36m█████     [0m| 13/26 [00:17<00:13,  1.03s/it]Epoch: 4/10. Loss: 0.9689:  54%|[36m█████▍    [0m| 14/26 [00:17<00:11,  1.00it/s]Epoch: 4/10. Loss: 1.0646:  54%|[36m█████▍    [0m| 14/26 [00:18<00:11,  1.00it/s]Epoch: 4/10. Loss: 1.0646:  58%|[36m█████▊    [0m| 15/26 [00:18<00:11,  1.02s/it]Epoch: 4/10. Loss: 0.9205:  58%|[36m█████▊    [0m| 15/26 [00:19<00:11,  1.02s/it]Epoch: 4/10. Loss: 0.9205:  62%|[36m██████▏   [0m| 16/26 [00:19<00:09,  1.04it/s]Epoch: 4/10. Loss: 1.0272:  62%|[36m██████▏   [0m| 16/26 [00:20<00:09,  1.04it/s]Epoch: 4/10. Loss: 1.0272:  65%|[36m██████▌   [0m| 17/26 [00:20<00:09,  1.05s/it]Epoch: 4/10. Loss: 0.9911:  65%|[36m██████▌   [0m| 17/26 [00:21<00:09,  1.05s/it]Epoch: 4/10. Loss: 0.9911:  69%|[36m██████▉   [0m| 18/26 [00:21<00:08,  1.04s/it]Epoch: 4/10. Loss: 0.9891:  69%|[36m██████▉   [0m| 18/26 [00:22<00:08,  1.04s/it]Epoch: 4/10. Loss: 0.9891:  73%|[36m███████▎  [0m| 19/26 [00:22<00:07,  1.06s/it]Epoch: 4/10. Loss: 0.9453:  73%|[36m███████▎  [0m| 19/26 [00:23<00:07,  1.06s/it]Epoch: 4/10. Loss: 0.9453:  77%|[36m███████▋  [0m| 20/26 [00:23<00:05,  1.00it/s]Epoch: 4/10. Loss: 1.1101:  77%|[36m███████▋  [0m| 20/26 [00:24<00:05,  1.00it/s]Epoch: 4/10. Loss: 1.1101:  81%|[36m████████  [0m| 21/26 [00:24<00:04,  1.03it/s]Epoch: 4/10. Loss: 0.9469:  81%|[36m████████  [0m| 21/26 [00:25<00:04,  1.03it/s]Epoch: 4/10. Loss: 0.9469:  85%|[36m████████▍ [0m| 22/26 [00:25<00:03,  1.03it/s]Epoch: 4/10. Loss: 0.9581:  85%|[36m████████▍ [0m| 22/26 [00:26<00:03,  1.03it/s]Epoch: 4/10. Loss: 0.9581:  88%|[36m████████▊ [0m| 23/26 [00:26<00:02,  1.02it/s]Epoch: 4/10. Loss: 0.9905:  88%|[36m████████▊ [0m| 23/26 [00:27<00:02,  1.02it/s]Epoch: 4/10. Loss: 0.9905:  92%|[36m█████████▏[0m| 24/26 [00:27<00:01,  1.06it/s]Epoch: 4/10. Loss: 1.0444:  92%|[36m█████████▏[0m| 24/26 [00:28<00:01,  1.06it/s]Epoch: 4/10. Loss: 1.0444:  96%|[36m█████████▌[0m| 25/26 [00:28<00:00,  1.03it/s]Epoch: 4/10. Loss: 1.0409:  96%|[36m█████████▌[0m| 25/26 [00:28<00:00,  1.03it/s]Epoch: 4/10. Loss: 1.0409: 100%|[36m██████████[0m| 26/26 [00:28<00:00,  1.11it/s]Epoch: 4/10. Loss: 1.0409: 100%|[36m██████████[0m| 26/26 [00:28<00:00,  1.11s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:05,  1.12it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:06,  1.29s/it] 43%|[33m████▎     [0m| 3/7 [00:03<00:04,  1.03s/it] 57%|[33m█████▋    [0m| 4/7 [00:04<00:03,  1.14s/it] 71%|[33m███████▏  [0m| 5/7 [00:05<00:02,  1.13s/it] 86%|[33m████████▌ [0m| 6/7 [00:06<00:01,  1.07s/it]100%|[33m██████████[0m| 7/7 [00:06<00:00,  1.21it/s]100%|[33m██████████[0m| 7/7 [00:06<00:00,  1.02it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 5/10. Loss: 0.9619:   0%|[36m          [0m| 0/26 [00:01<?, ?it/s]Epoch: 5/10. Loss: 0.9619:   4%|[36m▍         [0m| 1/26 [00:01<00:41,  1.64s/it]Epoch: 5/10. Loss: 1.0106:   4%|[36m▍         [0m| 1/26 [00:02<00:41,  1.64s/it]Epoch: 5/10. Loss: 1.0106:   8%|[36m▊         [0m| 2/26 [00:02<00:29,  1.24s/it]Epoch: 5/10. Loss: 0.9780:   8%|[36m▊         [0m| 2/26 [00:03<00:29,  1.24s/it]Epoch: 5/10. Loss: 0.9780:  12%|[36m█▏        [0m| 3/26 [00:03<00:25,  1.10s/it]Epoch: 5/10. Loss: 0.9946:  12%|[36m█▏        [0m| 3/26 [00:04<00:25,  1.10s/it]Epoch: 5/10. Loss: 0.9946:  15%|[36m█▌        [0m| 4/26 [00:04<00:23,  1.08s/it]Epoch: 5/10. Loss: 1.0768:  15%|[36m█▌        [0m| 4/26 [00:05<00:23,  1.08s/it]Epoch: 5/10. Loss: 1.0768:  19%|[36m█▉        [0m| 5/26 [00:05<00:21,  1.03s/it]Epoch: 5/10. Loss: 0.9672:  19%|[36m█▉        [0m| 5/26 [00:07<00:21,  1.03s/it]Epoch: 5/10. Loss: 0.9672:  23%|[36m██▎       [0m| 6/26 [00:07<00:24,  1.24s/it]Epoch: 5/10. Loss: 0.9962:  23%|[36m██▎       [0m| 6/26 [00:09<00:24,  1.24s/it]Epoch: 5/10. Loss: 0.9962:  27%|[36m██▋       [0m| 7/26 [00:09<00:32,  1.73s/it]Epoch: 5/10. Loss: 0.9402:  27%|[36m██▋       [0m| 7/26 [00:11<00:32,  1.73s/it]Epoch: 5/10. Loss: 0.9402:  31%|[36m███       [0m| 8/26 [00:11<00:30,  1.71s/it]Epoch: 5/10. Loss: 0.9590:  31%|[36m███       [0m| 8/26 [00:12<00:30,  1.71s/it]Epoch: 5/10. Loss: 0.9590:  35%|[36m███▍      [0m| 9/26 [00:12<00:25,  1.48s/it]Epoch: 5/10. Loss: 0.8990:  35%|[36m███▍      [0m| 9/26 [00:16<00:25,  1.48s/it]Epoch: 5/10. Loss: 0.8990:  38%|[36m███▊      [0m| 10/26 [00:16<00:37,  2.34s/it]Epoch: 5/10. Loss: 1.0458:  38%|[36m███▊      [0m| 10/26 [00:17<00:37,  2.34s/it]Epoch: 5/10. Loss: 1.0458:  42%|[36m████▏     [0m| 11/26 [00:17<00:28,  1.93s/it]Epoch: 5/10. Loss: 0.9663:  42%|[36m████▏     [0m| 11/26 [00:18<00:28,  1.93s/it]Epoch: 5/10. Loss: 0.9663:  46%|[36m████▌     [0m| 12/26 [00:18<00:23,  1.65s/it]Epoch: 5/10. Loss: 1.1112:  46%|[36m████▌     [0m| 12/26 [00:19<00:23,  1.65s/it]Epoch: 5/10. Loss: 1.1112:  50%|[36m█████     [0m| 13/26 [00:19<00:18,  1.39s/it]Epoch: 5/10. Loss: 0.9287:  50%|[36m█████     [0m| 13/26 [00:20<00:18,  1.39s/it]Epoch: 5/10. Loss: 0.9287:  54%|[36m█████▍    [0m| 14/26 [00:20<00:15,  1.27s/it]Epoch: 5/10. Loss: 1.0470:  54%|[36m█████▍    [0m| 14/26 [00:21<00:15,  1.27s/it]Epoch: 5/10. Loss: 1.0470:  58%|[36m█████▊    [0m| 15/26 [00:21<00:13,  1.22s/it]Epoch: 5/10. Loss: 0.9965:  58%|[36m█████▊    [0m| 15/26 [00:22<00:13,  1.22s/it]Epoch: 5/10. Loss: 0.9965:  62%|[36m██████▏   [0m| 16/26 [00:22<00:11,  1.14s/it]Epoch: 5/10. Loss: 1.0610:  62%|[36m██████▏   [0m| 16/26 [00:23<00:11,  1.14s/it]Epoch: 5/10. Loss: 1.0610:  65%|[36m██████▌   [0m| 17/26 [00:23<00:09,  1.07s/it]Epoch: 5/10. Loss: 1.0800:  65%|[36m██████▌   [0m| 17/26 [00:24<00:09,  1.07s/it]Epoch: 5/10. Loss: 1.0800:  69%|[36m██████▉   [0m| 18/26 [00:24<00:08,  1.02s/it]Epoch: 5/10. Loss: 0.9503:  69%|[36m██████▉   [0m| 18/26 [00:25<00:08,  1.02s/it]Epoch: 5/10. Loss: 0.9503:  73%|[36m███████▎  [0m| 19/26 [00:25<00:07,  1.02s/it]Epoch: 5/10. Loss: 1.0353:  73%|[36m███████▎  [0m| 19/26 [00:26<00:07,  1.02s/it]Epoch: 5/10. Loss: 1.0353:  77%|[36m███████▋  [0m| 20/26 [00:26<00:06,  1.03s/it]Epoch: 5/10. Loss: 1.1028:  77%|[36m███████▋  [0m| 20/26 [00:27<00:06,  1.03s/it]Epoch: 5/10. Loss: 1.1028:  81%|[36m████████  [0m| 21/26 [00:27<00:04,  1.02it/s]Epoch: 5/10. Loss: 0.9986:  81%|[36m████████  [0m| 21/26 [00:28<00:04,  1.02it/s]Epoch: 5/10. Loss: 0.9986:  85%|[36m████████▍ [0m| 22/26 [00:28<00:04,  1.01s/it]Epoch: 5/10. Loss: 1.0303:  85%|[36m████████▍ [0m| 22/26 [00:29<00:04,  1.01s/it]Epoch: 5/10. Loss: 1.0303:  88%|[36m████████▊ [0m| 23/26 [00:29<00:02,  1.00it/s]Epoch: 5/10. Loss: 1.0705:  88%|[36m████████▊ [0m| 23/26 [00:30<00:02,  1.00it/s]Epoch: 5/10. Loss: 1.0705:  92%|[36m█████████▏[0m| 24/26 [00:30<00:02,  1.14s/it]Epoch: 5/10. Loss: 0.9526:  92%|[36m█████████▏[0m| 24/26 [00:31<00:02,  1.14s/it]Epoch: 5/10. Loss: 0.9526:  96%|[36m█████████▌[0m| 25/26 [00:31<00:01,  1.09s/it]Epoch: 5/10. Loss: 0.9790:  96%|[36m█████████▌[0m| 25/26 [00:32<00:01,  1.09s/it]Epoch: 5/10. Loss: 0.9790: 100%|[36m██████████[0m| 26/26 [00:32<00:00,  1.00it/s]Epoch: 5/10. Loss: 0.9790: 100%|[36m██████████[0m| 26/26 [00:32<00:00,  1.26s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:04,  1.28it/s] 29%|[33m██▊       [0m| 2/7 [00:03<00:08,  1.67s/it] 43%|[33m████▎     [0m| 3/7 [00:03<00:04,  1.23s/it] 57%|[33m█████▋    [0m| 4/7 [00:05<00:03,  1.25s/it] 71%|[33m███████▏  [0m| 5/7 [00:05<00:01,  1.03it/s] 86%|[33m████████▌ [0m| 6/7 [00:06<00:00,  1.06it/s]100%|[33m██████████[0m| 7/7 [00:06<00:00,  1.36it/s]100%|[33m██████████[0m| 7/7 [00:06<00:00,  1.04it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 6/10. Loss: 0.9978:   0%|[36m          [0m| 0/26 [00:01<?, ?it/s]Epoch: 6/10. Loss: 0.9978:   4%|[36m▍         [0m| 1/26 [00:01<00:41,  1.65s/it]Epoch: 6/10. Loss: 1.0269:   4%|[36m▍         [0m| 1/26 [00:02<00:41,  1.65s/it]Epoch: 6/10. Loss: 1.0269:   8%|[36m▊         [0m| 2/26 [00:02<00:28,  1.20s/it]Epoch: 6/10. Loss: 0.9862:   8%|[36m▊         [0m| 2/26 [00:03<00:28,  1.20s/it]Epoch: 6/10. Loss: 0.9862:  12%|[36m█▏        [0m| 3/26 [00:03<00:25,  1.10s/it]Epoch: 6/10. Loss: 0.9889:  12%|[36m█▏        [0m| 3/26 [00:04<00:25,  1.10s/it]Epoch: 6/10. Loss: 0.9889:  15%|[36m█▌        [0m| 4/26 [00:04<00:21,  1.01it/s]Epoch: 6/10. Loss: 1.0390:  15%|[36m█▌        [0m| 4/26 [00:05<00:21,  1.01it/s]Epoch: 6/10. Loss: 1.0390:  19%|[36m█▉        [0m| 5/26 [00:05<00:23,  1.13s/it]Epoch: 6/10. Loss: 0.9834:  19%|[36m█▉        [0m| 5/26 [00:06<00:23,  1.13s/it]Epoch: 6/10. Loss: 0.9834:  23%|[36m██▎       [0m| 6/26 [00:06<00:21,  1.05s/it]Epoch: 6/10. Loss: 0.9186:  23%|[36m██▎       [0m| 6/26 [00:07<00:21,  1.05s/it]Epoch: 6/10. Loss: 0.9186:  27%|[36m██▋       [0m| 7/26 [00:07<00:21,  1.12s/it]Epoch: 6/10. Loss: 1.0107:  27%|[36m██▋       [0m| 7/26 [00:11<00:21,  1.12s/it]Epoch: 6/10. Loss: 1.0107:  31%|[36m███       [0m| 8/26 [00:11<00:35,  1.97s/it]Epoch: 6/10. Loss: 0.9921:  31%|[36m███       [0m| 8/26 [00:12<00:35,  1.97s/it]Epoch: 6/10. Loss: 0.9921:  35%|[36m███▍      [0m| 9/26 [00:12<00:27,  1.62s/it]Epoch: 6/10. Loss: 1.0338:  35%|[36m███▍      [0m| 9/26 [00:13<00:27,  1.62s/it]Epoch: 6/10. Loss: 1.0338:  38%|[36m███▊      [0m| 10/26 [00:13<00:24,  1.51s/it]Epoch: 6/10. Loss: 1.0849:  38%|[36m███▊      [0m| 10/26 [00:14<00:24,  1.51s/it]Epoch: 6/10. Loss: 1.0849:  42%|[36m████▏     [0m| 11/26 [00:14<00:19,  1.32s/it]Epoch: 6/10. Loss: 0.9737:  42%|[36m████▏     [0m| 11/26 [00:15<00:19,  1.32s/it]Epoch: 6/10. Loss: 0.9737:  46%|[36m████▌     [0m| 12/26 [00:15<00:18,  1.32s/it]Epoch: 6/10. Loss: 0.9644:  46%|[36m████▌     [0m| 12/26 [00:17<00:18,  1.32s/it]Epoch: 6/10. Loss: 0.9644:  50%|[36m█████     [0m| 13/26 [00:17<00:16,  1.25s/it]Epoch: 6/10. Loss: 1.0023:  50%|[36m█████     [0m| 13/26 [00:18<00:16,  1.25s/it]Epoch: 6/10. Loss: 1.0023:  54%|[36m█████▍    [0m| 14/26 [00:18<00:14,  1.19s/it]Epoch: 6/10. Loss: 0.9973:  54%|[36m█████▍    [0m| 14/26 [00:19<00:14,  1.19s/it]Epoch: 6/10. Loss: 0.9973:  58%|[36m█████▊    [0m| 15/26 [00:19<00:12,  1.11s/it]Epoch: 6/10. Loss: 1.0296:  58%|[36m█████▊    [0m| 15/26 [00:20<00:12,  1.11s/it]Epoch: 6/10. Loss: 1.0296:  62%|[36m██████▏   [0m| 16/26 [00:20<00:12,  1.20s/it]Epoch: 6/10. Loss: 1.0250:  62%|[36m██████▏   [0m| 16/26 [00:23<00:12,  1.20s/it]Epoch: 6/10. Loss: 1.0250:  65%|[36m██████▌   [0m| 17/26 [00:23<00:15,  1.74s/it]Epoch: 6/10. Loss: 1.0137:  65%|[36m██████▌   [0m| 17/26 [00:24<00:15,  1.74s/it]Epoch: 6/10. Loss: 1.0137:  69%|[36m██████▉   [0m| 18/26 [00:24<00:12,  1.51s/it]Epoch: 6/10. Loss: 1.0324:  69%|[36m██████▉   [0m| 18/26 [00:25<00:12,  1.51s/it]Epoch: 6/10. Loss: 1.0324:  73%|[36m███████▎  [0m| 19/26 [00:25<00:09,  1.36s/it]Epoch: 6/10. Loss: 0.9889:  73%|[36m███████▎  [0m| 19/26 [00:26<00:09,  1.36s/it]Epoch: 6/10. Loss: 0.9889:  77%|[36m███████▋  [0m| 20/26 [00:26<00:07,  1.26s/it]Epoch: 6/10. Loss: 1.0369:  77%|[36m███████▋  [0m| 20/26 [00:27<00:07,  1.26s/it]Epoch: 6/10. Loss: 1.0369:  81%|[36m████████  [0m| 21/26 [00:27<00:05,  1.18s/it]Epoch: 6/10. Loss: 1.0293:  81%|[36m████████  [0m| 21/26 [00:28<00:05,  1.18s/it]Epoch: 6/10. Loss: 1.0293:  85%|[36m████████▍ [0m| 22/26 [00:28<00:04,  1.16s/it]Epoch: 6/10. Loss: 0.9984:  85%|[36m████████▍ [0m| 22/26 [00:30<00:04,  1.16s/it]Epoch: 6/10. Loss: 0.9984:  88%|[36m████████▊ [0m| 23/26 [00:30<00:04,  1.36s/it]Epoch: 6/10. Loss: 1.0232:  88%|[36m████████▊ [0m| 23/26 [00:31<00:04,  1.36s/it]Epoch: 6/10. Loss: 1.0232:  92%|[36m█████████▏[0m| 24/26 [00:31<00:02,  1.27s/it]Epoch: 6/10. Loss: 1.0245:  92%|[36m█████████▏[0m| 24/26 [00:32<00:02,  1.27s/it]Epoch: 6/10. Loss: 1.0245:  96%|[36m█████████▌[0m| 25/26 [00:32<00:01,  1.17s/it]Epoch: 6/10. Loss: 1.0393:  96%|[36m█████████▌[0m| 25/26 [00:32<00:01,  1.17s/it]Epoch: 6/10. Loss: 1.0393: 100%|[36m██████████[0m| 26/26 [00:33<00:00,  1.00s/it]Epoch: 6/10. Loss: 1.0393: 100%|[36m██████████[0m| 26/26 [00:33<00:00,  1.27s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:04,  1.21it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:07,  1.58s/it] 43%|[33m████▎     [0m| 3/7 [00:03<00:04,  1.19s/it] 57%|[33m█████▋    [0m| 4/7 [00:04<00:03,  1.23s/it] 71%|[33m███████▏  [0m| 5/7 [00:05<00:01,  1.04it/s] 86%|[33m████████▌ [0m| 6/7 [00:06<00:00,  1.06it/s]100%|[33m██████████[0m| 7/7 [00:06<00:00,  1.35it/s]100%|[33m██████████[0m| 7/7 [00:06<00:00,  1.05it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 7/10. Loss: 1.0422:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 7/10. Loss: 1.0422:   4%|[36m▍         [0m| 1/26 [00:00<00:21,  1.14it/s]Epoch: 7/10. Loss: 0.9804:   4%|[36m▍         [0m| 1/26 [00:02<00:21,  1.14it/s]Epoch: 7/10. Loss: 0.9804:   8%|[36m▊         [0m| 2/26 [00:02<00:32,  1.36s/it]Epoch: 7/10. Loss: 1.0278:   8%|[36m▊         [0m| 2/26 [00:03<00:32,  1.36s/it]Epoch: 7/10. Loss: 1.0278:  12%|[36m█▏        [0m| 3/26 [00:03<00:31,  1.37s/it]Epoch: 7/10. Loss: 1.0236:  12%|[36m█▏        [0m| 3/26 [00:04<00:31,  1.37s/it]Epoch: 7/10. Loss: 1.0236:  15%|[36m█▌        [0m| 4/26 [00:04<00:26,  1.19s/it]Epoch: 7/10. Loss: 1.0203:  15%|[36m█▌        [0m| 4/26 [00:08<00:26,  1.19s/it]Epoch: 7/10. Loss: 1.0203:  19%|[36m█▉        [0m| 5/26 [00:08<00:45,  2.17s/it]Epoch: 7/10. Loss: 0.9813:  19%|[36m█▉        [0m| 5/26 [00:10<00:45,  2.17s/it]Epoch: 7/10. Loss: 0.9813:  23%|[36m██▎       [0m| 6/26 [00:10<00:40,  2.02s/it]Epoch: 7/10. Loss: 1.0159:  23%|[36m██▎       [0m| 6/26 [00:11<00:40,  2.02s/it]Epoch: 7/10. Loss: 1.0159:  27%|[36m██▋       [0m| 7/26 [00:11<00:31,  1.65s/it]Epoch: 7/10. Loss: 1.0240:  27%|[36m██▋       [0m| 7/26 [00:14<00:31,  1.65s/it]Epoch: 7/10. Loss: 1.0240:  31%|[36m███       [0m| 8/26 [00:14<00:38,  2.12s/it]Epoch: 7/10. Loss: 0.9569:  31%|[36m███       [0m| 8/26 [00:15<00:38,  2.12s/it]Epoch: 7/10. Loss: 0.9569:  35%|[36m███▍      [0m| 9/26 [00:15<00:32,  1.90s/it]Epoch: 7/10. Loss: 0.9930:  35%|[36m███▍      [0m| 9/26 [00:17<00:32,  1.90s/it]Epoch: 7/10. Loss: 0.9930:  38%|[36m███▊      [0m| 10/26 [00:17<00:29,  1.85s/it]Epoch: 7/10. Loss: 1.0319:  38%|[36m███▊      [0m| 10/26 [00:18<00:29,  1.85s/it]Epoch: 7/10. Loss: 1.0319:  42%|[36m████▏     [0m| 11/26 [00:18<00:23,  1.54s/it]Epoch: 7/10. Loss: 1.0885:  42%|[36m████▏     [0m| 11/26 [00:19<00:23,  1.54s/it]Epoch: 7/10. Loss: 1.0885:  46%|[36m████▌     [0m| 12/26 [00:19<00:19,  1.39s/it]Epoch: 7/10. Loss: 1.0144:  46%|[36m████▌     [0m| 12/26 [00:20<00:19,  1.39s/it]Epoch: 7/10. Loss: 1.0144:  50%|[36m█████     [0m| 13/26 [00:20<00:16,  1.26s/it]Epoch: 7/10. Loss: 1.0545:  50%|[36m█████     [0m| 13/26 [00:21<00:16,  1.26s/it]Epoch: 7/10. Loss: 1.0545:  54%|[36m█████▍    [0m| 14/26 [00:21<00:14,  1.22s/it]Epoch: 7/10. Loss: 1.0032:  54%|[36m█████▍    [0m| 14/26 [00:22<00:14,  1.22s/it]Epoch: 7/10. Loss: 1.0032:  58%|[36m█████▊    [0m| 15/26 [00:22<00:12,  1.16s/it]Epoch: 7/10. Loss: 1.0013:  58%|[36m█████▊    [0m| 15/26 [00:23<00:12,  1.16s/it]Epoch: 7/10. Loss: 1.0013:  62%|[36m██████▏   [0m| 16/26 [00:23<00:11,  1.10s/it]Epoch: 7/10. Loss: 0.9354:  62%|[36m██████▏   [0m| 16/26 [00:24<00:11,  1.10s/it]Epoch: 7/10. Loss: 0.9354:  65%|[36m██████▌   [0m| 17/26 [00:24<00:09,  1.06s/it]Epoch: 7/10. Loss: 0.9294:  65%|[36m██████▌   [0m| 17/26 [00:25<00:09,  1.06s/it]Epoch: 7/10. Loss: 0.9294:  69%|[36m██████▉   [0m| 18/26 [00:25<00:08,  1.03s/it]Epoch: 7/10. Loss: 1.0058:  69%|[36m██████▉   [0m| 18/26 [00:26<00:08,  1.03s/it]Epoch: 7/10. Loss: 1.0058:  73%|[36m███████▎  [0m| 19/26 [00:26<00:06,  1.01it/s]Epoch: 7/10. Loss: 0.9980:  73%|[36m███████▎  [0m| 19/26 [00:27<00:06,  1.01it/s]Epoch: 7/10. Loss: 0.9980:  77%|[36m███████▋  [0m| 20/26 [00:27<00:06,  1.05s/it]Epoch: 7/10. Loss: 1.0183:  77%|[36m███████▋  [0m| 20/26 [00:28<00:06,  1.05s/it]Epoch: 7/10. Loss: 1.0183:  81%|[36m████████  [0m| 21/26 [00:28<00:05,  1.01s/it]Epoch: 7/10. Loss: 1.0999:  81%|[36m████████  [0m| 21/26 [00:29<00:05,  1.01s/it]Epoch: 7/10. Loss: 1.0999:  85%|[36m████████▍ [0m| 22/26 [00:29<00:04,  1.03s/it]Epoch: 7/10. Loss: 1.0106:  85%|[36m████████▍ [0m| 22/26 [00:30<00:04,  1.03s/it]Epoch: 7/10. Loss: 1.0106:  88%|[36m████████▊ [0m| 23/26 [00:30<00:02,  1.01it/s]Epoch: 7/10. Loss: 1.0444:  88%|[36m████████▊ [0m| 23/26 [00:31<00:02,  1.01it/s]Epoch: 7/10. Loss: 1.0444:  92%|[36m█████████▏[0m| 24/26 [00:31<00:01,  1.03it/s]Epoch: 7/10. Loss: 1.0266:  92%|[36m█████████▏[0m| 24/26 [00:32<00:01,  1.03it/s]Epoch: 7/10. Loss: 1.0266:  96%|[36m█████████▌[0m| 25/26 [00:32<00:01,  1.14s/it]Epoch: 7/10. Loss: 1.0721:  96%|[36m█████████▌[0m| 25/26 [00:34<00:01,  1.14s/it]Epoch: 7/10. Loss: 1.0721: 100%|[36m██████████[0m| 26/26 [00:34<00:00,  1.23s/it]Epoch: 7/10. Loss: 1.0721: 100%|[36m██████████[0m| 26/26 [00:34<00:00,  1.32s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:01<00:06,  1.05s/it] 29%|[33m██▊       [0m| 2/7 [00:04<00:12,  2.46s/it] 43%|[33m████▎     [0m| 3/7 [00:05<00:07,  1.79s/it] 57%|[33m█████▋    [0m| 4/7 [00:06<00:04,  1.59s/it] 71%|[33m███████▏  [0m| 5/7 [00:07<00:02,  1.19s/it] 86%|[33m████████▌ [0m| 6/7 [00:08<00:01,  1.12s/it]100%|[33m██████████[0m| 7/7 [00:08<00:00,  1.16it/s]100%|[33m██████████[0m| 7/7 [00:08<00:00,  1.22s/it]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 8/10. Loss: 0.9733:   0%|[36m          [0m| 0/26 [00:01<?, ?it/s]Epoch: 8/10. Loss: 0.9733:   4%|[36m▍         [0m| 1/26 [00:01<00:27,  1.09s/it]Epoch: 8/10. Loss: 1.0017:   4%|[36m▍         [0m| 1/26 [00:01<00:27,  1.09s/it]Epoch: 8/10. Loss: 1.0017:   8%|[36m▊         [0m| 2/26 [00:02<00:23,  1.01it/s]Epoch: 8/10. Loss: 1.0547:   8%|[36m▊         [0m| 2/26 [00:03<00:23,  1.01it/s]Epoch: 8/10. Loss: 1.0547:  12%|[36m█▏        [0m| 3/26 [00:03<00:23,  1.03s/it]Epoch: 8/10. Loss: 1.0969:  12%|[36m█▏        [0m| 3/26 [00:03<00:23,  1.03s/it]Epoch: 8/10. Loss: 1.0969:  15%|[36m█▌        [0m| 4/26 [00:03<00:20,  1.09it/s]Epoch: 8/10. Loss: 0.9744:  15%|[36m█▌        [0m| 4/26 [00:04<00:20,  1.09it/s]Epoch: 8/10. Loss: 0.9744:  19%|[36m█▉        [0m| 5/26 [00:04<00:19,  1.09it/s]Epoch: 8/10. Loss: 1.0177:  19%|[36m█▉        [0m| 5/26 [00:05<00:19,  1.09it/s]Epoch: 8/10. Loss: 1.0177:  23%|[36m██▎       [0m| 6/26 [00:05<00:18,  1.08it/s]Epoch: 8/10. Loss: 0.9749:  23%|[36m██▎       [0m| 6/26 [00:06<00:18,  1.08it/s]Epoch: 8/10. Loss: 0.9749:  27%|[36m██▋       [0m| 7/26 [00:06<00:17,  1.06it/s]Epoch: 8/10. Loss: 0.9937:  27%|[36m██▋       [0m| 7/26 [00:07<00:17,  1.06it/s]Epoch: 8/10. Loss: 0.9937:  31%|[36m███       [0m| 8/26 [00:07<00:17,  1.04it/s]Epoch: 8/10. Loss: 1.0052:  31%|[36m███       [0m| 8/26 [00:08<00:17,  1.04it/s]Epoch: 8/10. Loss: 1.0052:  35%|[36m███▍      [0m| 9/26 [00:08<00:17,  1.02s/it]Epoch: 8/10. Loss: 1.0180:  35%|[36m███▍      [0m| 9/26 [00:09<00:17,  1.02s/it]Epoch: 8/10. Loss: 1.0180:  38%|[36m███▊      [0m| 10/26 [00:10<00:17,  1.07s/it]Epoch: 8/10. Loss: 1.0105:  38%|[36m███▊      [0m| 10/26 [00:10<00:17,  1.07s/it]Epoch: 8/10. Loss: 1.0105:  42%|[36m████▏     [0m| 11/26 [00:10<00:15,  1.02s/it]Epoch: 8/10. Loss: 0.9667:  42%|[36m████▏     [0m| 11/26 [00:11<00:15,  1.02s/it]Epoch: 8/10. Loss: 0.9667:  46%|[36m████▌     [0m| 12/26 [00:11<00:14,  1.03s/it]Epoch: 8/10. Loss: 0.9822:  46%|[36m████▌     [0m| 12/26 [00:12<00:14,  1.03s/it]Epoch: 8/10. Loss: 0.9822:  50%|[36m█████     [0m| 13/26 [00:12<00:12,  1.01it/s]Epoch: 8/10. Loss: 1.0288:  50%|[36m█████     [0m| 13/26 [00:13<00:12,  1.01it/s]Epoch: 8/10. Loss: 1.0288:  54%|[36m█████▍    [0m| 14/26 [00:13<00:11,  1.06it/s]Epoch: 8/10. Loss: 0.9388:  54%|[36m█████▍    [0m| 14/26 [00:14<00:11,  1.06it/s]Epoch: 8/10. Loss: 0.9388:  58%|[36m█████▊    [0m| 15/26 [00:14<00:10,  1.09it/s]Epoch: 8/10. Loss: 0.9850:  58%|[36m█████▊    [0m| 15/26 [00:15<00:10,  1.09it/s]Epoch: 8/10. Loss: 0.9850:  62%|[36m██████▏   [0m| 16/26 [00:15<00:09,  1.05it/s]Epoch: 8/10. Loss: 1.0074:  62%|[36m██████▏   [0m| 16/26 [00:16<00:09,  1.05it/s]Epoch: 8/10. Loss: 1.0074:  65%|[36m██████▌   [0m| 17/26 [00:16<00:09,  1.01s/it]Epoch: 8/10. Loss: 0.9285:  65%|[36m██████▌   [0m| 17/26 [00:17<00:09,  1.01s/it]Epoch: 8/10. Loss: 0.9285:  69%|[36m██████▉   [0m| 18/26 [00:17<00:07,  1.04it/s]Epoch: 8/10. Loss: 0.9309:  69%|[36m██████▉   [0m| 18/26 [00:18<00:07,  1.04it/s]Epoch: 8/10. Loss: 0.9309:  73%|[36m███████▎  [0m| 19/26 [00:18<00:06,  1.08it/s]Epoch: 8/10. Loss: 1.0716:  73%|[36m███████▎  [0m| 19/26 [00:19<00:06,  1.08it/s]Epoch: 8/10. Loss: 1.0716:  77%|[36m███████▋  [0m| 20/26 [00:19<00:05,  1.06it/s]Epoch: 8/10. Loss: 0.9019:  77%|[36m███████▋  [0m| 20/26 [00:20<00:05,  1.06it/s]Epoch: 8/10. Loss: 0.9019:  81%|[36m████████  [0m| 21/26 [00:20<00:04,  1.03it/s]Epoch: 8/10. Loss: 0.9489:  81%|[36m████████  [0m| 21/26 [00:21<00:04,  1.03it/s]Epoch: 8/10. Loss: 0.9489:  85%|[36m████████▍ [0m| 22/26 [00:21<00:03,  1.06it/s]Epoch: 8/10. Loss: 0.9517:  85%|[36m████████▍ [0m| 22/26 [00:22<00:03,  1.06it/s]Epoch: 8/10. Loss: 0.9517:  88%|[36m████████▊ [0m| 23/26 [00:22<00:02,  1.03it/s]Epoch: 8/10. Loss: 0.9557:  88%|[36m████████▊ [0m| 23/26 [00:23<00:02,  1.03it/s]Epoch: 8/10. Loss: 0.9557:  92%|[36m█████████▏[0m| 24/26 [00:23<00:01,  1.01it/s]Epoch: 8/10. Loss: 0.9304:  92%|[36m█████████▏[0m| 24/26 [00:24<00:01,  1.01it/s]Epoch: 8/10. Loss: 0.9304:  96%|[36m█████████▌[0m| 25/26 [00:24<00:01,  1.16s/it]Epoch: 8/10. Loss: 1.0095:  96%|[36m█████████▌[0m| 25/26 [00:25<00:01,  1.16s/it]Epoch: 8/10. Loss: 1.0095: 100%|[36m██████████[0m| 26/26 [00:25<00:00,  1.01s/it]Epoch: 8/10. Loss: 1.0095: 100%|[36m██████████[0m| 26/26 [00:25<00:00,  1.02it/s]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:05,  1.11it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:06,  1.30s/it] 43%|[33m████▎     [0m| 3/7 [00:03<00:04,  1.04s/it] 57%|[33m█████▋    [0m| 4/7 [00:05<00:04,  1.43s/it] 71%|[33m███████▏  [0m| 5/7 [00:05<00:02,  1.09s/it] 86%|[33m████████▌ [0m| 6/7 [00:06<00:01,  1.04s/it]100%|[33m██████████[0m| 7/7 [00:06<00:00,  1.24it/s]100%|[33m██████████[0m| 7/7 [00:06<00:00,  1.00it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 9/10. Loss: 0.9588:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 9/10. Loss: 0.9588:   4%|[36m▍         [0m| 1/26 [00:00<00:24,  1.03it/s]Epoch: 9/10. Loss: 0.9180:   4%|[36m▍         [0m| 1/26 [00:01<00:24,  1.03it/s]Epoch: 9/10. Loss: 0.9180:   8%|[36m▊         [0m| 2/26 [00:01<00:21,  1.14it/s]Epoch: 9/10. Loss: 0.9952:   8%|[36m▊         [0m| 2/26 [00:02<00:21,  1.14it/s]Epoch: 9/10. Loss: 0.9952:  12%|[36m█▏        [0m| 3/26 [00:02<00:22,  1.01it/s]Epoch: 9/10. Loss: 0.9468:  12%|[36m█▏        [0m| 3/26 [00:03<00:22,  1.01it/s]Epoch: 9/10. Loss: 0.9468:  15%|[36m█▌        [0m| 4/26 [00:03<00:20,  1.05it/s]Epoch: 9/10. Loss: 0.9992:  15%|[36m█▌        [0m| 4/26 [00:04<00:20,  1.05it/s]Epoch: 9/10. Loss: 0.9992:  19%|[36m█▉        [0m| 5/26 [00:04<00:20,  1.00it/s]Epoch: 9/10. Loss: 0.9045:  19%|[36m█▉        [0m| 5/26 [00:05<00:20,  1.00it/s]Epoch: 9/10. Loss: 0.9045:  23%|[36m██▎       [0m| 6/26 [00:05<00:19,  1.00it/s]Epoch: 9/10. Loss: 0.9841:  23%|[36m██▎       [0m| 6/26 [00:06<00:19,  1.00it/s]Epoch: 9/10. Loss: 0.9841:  27%|[36m██▋       [0m| 7/26 [00:06<00:19,  1.03s/it]Epoch: 9/10. Loss: 0.9076:  27%|[36m██▋       [0m| 7/26 [00:07<00:19,  1.03s/it]Epoch: 9/10. Loss: 0.9076:  31%|[36m███       [0m| 8/26 [00:07<00:17,  1.03it/s]Epoch: 9/10. Loss: 1.0105:  31%|[36m███       [0m| 8/26 [00:08<00:17,  1.03it/s]Epoch: 9/10. Loss: 1.0105:  35%|[36m███▍      [0m| 9/26 [00:08<00:16,  1.04it/s]Epoch: 9/10. Loss: 0.9676:  35%|[36m███▍      [0m| 9/26 [00:09<00:16,  1.04it/s]Epoch: 9/10. Loss: 0.9676:  38%|[36m███▊      [0m| 10/26 [00:09<00:15,  1.03it/s]Epoch: 9/10. Loss: 0.9708:  38%|[36m███▊      [0m| 10/26 [00:10<00:15,  1.03it/s]Epoch: 9/10. Loss: 0.9708:  42%|[36m████▏     [0m| 11/26 [00:10<00:15,  1.00s/it]Epoch: 9/10. Loss: 0.9670:  42%|[36m████▏     [0m| 11/26 [00:11<00:15,  1.00s/it]Epoch: 9/10. Loss: 0.9670:  46%|[36m████▌     [0m| 12/26 [00:11<00:14,  1.02s/it]Epoch: 9/10. Loss: 0.9837:  46%|[36m████▌     [0m| 12/26 [00:13<00:14,  1.02s/it]Epoch: 9/10. Loss: 0.9837:  50%|[36m█████     [0m| 13/26 [00:13<00:14,  1.08s/it]Epoch: 9/10. Loss: 0.9719:  50%|[36m█████     [0m| 13/26 [00:14<00:14,  1.08s/it]Epoch: 9/10. Loss: 0.9719:  54%|[36m█████▍    [0m| 14/26 [00:14<00:13,  1.16s/it]Epoch: 9/10. Loss: 1.0290:  54%|[36m█████▍    [0m| 14/26 [00:15<00:13,  1.16s/it]Epoch: 9/10. Loss: 1.0290:  58%|[36m█████▊    [0m| 15/26 [00:15<00:12,  1.13s/it]Epoch: 9/10. Loss: 0.9529:  58%|[36m█████▊    [0m| 15/26 [00:16<00:12,  1.13s/it]Epoch: 9/10. Loss: 0.9529:  62%|[36m██████▏   [0m| 16/26 [00:16<00:10,  1.10s/it]Epoch: 9/10. Loss: 0.9807:  62%|[36m██████▏   [0m| 16/26 [00:17<00:10,  1.10s/it]Epoch: 9/10. Loss: 0.9807:  65%|[36m██████▌   [0m| 17/26 [00:17<00:09,  1.06s/it]Epoch: 9/10. Loss: 0.9139:  65%|[36m██████▌   [0m| 17/26 [00:18<00:09,  1.06s/it]Epoch: 9/10. Loss: 0.9139:  69%|[36m██████▉   [0m| 18/26 [00:18<00:08,  1.04s/it]Epoch: 9/10. Loss: 0.9442:  69%|[36m██████▉   [0m| 18/26 [00:19<00:08,  1.04s/it]Epoch: 9/10. Loss: 0.9442:  73%|[36m███████▎  [0m| 19/26 [00:19<00:07,  1.07s/it]Epoch: 9/10. Loss: 1.0243:  73%|[36m███████▎  [0m| 19/26 [00:20<00:07,  1.07s/it]Epoch: 9/10. Loss: 1.0243:  77%|[36m███████▋  [0m| 20/26 [00:20<00:06,  1.01s/it]Epoch: 9/10. Loss: 0.9581:  77%|[36m███████▋  [0m| 20/26 [00:21<00:06,  1.01s/it]Epoch: 9/10. Loss: 0.9581:  81%|[36m████████  [0m| 21/26 [00:21<00:05,  1.00s/it]Epoch: 9/10. Loss: 0.9526:  81%|[36m████████  [0m| 21/26 [00:22<00:05,  1.00s/it]Epoch: 9/10. Loss: 0.9526:  85%|[36m████████▍ [0m| 22/26 [00:22<00:03,  1.03it/s]Epoch: 9/10. Loss: 0.9579:  85%|[36m████████▍ [0m| 22/26 [00:23<00:03,  1.03it/s]Epoch: 9/10. Loss: 0.9579:  88%|[36m████████▊ [0m| 23/26 [00:23<00:02,  1.05it/s]Epoch: 9/10. Loss: 0.9845:  88%|[36m████████▊ [0m| 23/26 [00:24<00:02,  1.05it/s]Epoch: 9/10. Loss: 0.9845:  92%|[36m█████████▏[0m| 24/26 [00:24<00:01,  1.04it/s]Epoch: 9/10. Loss: 0.9979:  92%|[36m█████████▏[0m| 24/26 [00:25<00:01,  1.04it/s]Epoch: 9/10. Loss: 0.9979:  96%|[36m█████████▌[0m| 25/26 [00:25<00:00,  1.07it/s]Epoch: 9/10. Loss: 0.9690:  96%|[36m█████████▌[0m| 25/26 [00:25<00:00,  1.07it/s]Epoch: 9/10. Loss: 0.9690: 100%|[36m██████████[0m| 26/26 [00:25<00:00,  1.15it/s]Epoch: 9/10. Loss: 0.9690: 100%|[36m██████████[0m| 26/26 [00:25<00:00,  1.00it/s]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:04,  1.24it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:06,  1.21s/it] 43%|[33m████▎     [0m| 3/7 [00:03<00:04,  1.02s/it] 57%|[33m█████▋    [0m| 4/7 [00:04<00:03,  1.18s/it] 71%|[33m███████▏  [0m| 5/7 [00:05<00:01,  1.07it/s] 86%|[33m████████▌ [0m| 6/7 [00:05<00:00,  1.06it/s]100%|[33m██████████[0m| 7/7 [00:06<00:00,  1.23it/s]100%|[33m██████████[0m| 7/7 [00:06<00:00,  1.07it/s]
/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/models/inception.py:43: FutureWarning: The default weight initialization of inception_v3 will be changed in future releases of torchvision. If you wish to keep the old behavior (which leads to long initialization times due to scipy/scipy#11299), please set init_weights=True.
  warnings.warn(
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 0/10. Loss: 1.0872:   0%|[36m          [0m| 0/26 [00:01<?, ?it/s]Epoch: 0/10. Loss: 1.0872:   4%|[36m▍         [0m| 1/26 [00:01<00:28,  1.16s/it]Epoch: 0/10. Loss: 4.4986:   4%|[36m▍         [0m| 1/26 [00:02<00:28,  1.16s/it]Epoch: 0/10. Loss: 4.4986:   8%|[36m▊         [0m| 2/26 [00:02<00:24,  1.02s/it]Epoch: 0/10. Loss: 2.4016:   8%|[36m▊         [0m| 2/26 [00:03<00:24,  1.02s/it]Epoch: 0/10. Loss: 2.4016:  12%|[36m█▏        [0m| 3/26 [00:03<00:23,  1.04s/it]Epoch: 0/10. Loss: 1.5951:  12%|[36m█▏        [0m| 3/26 [00:04<00:23,  1.04s/it]Epoch: 0/10. Loss: 1.5951:  15%|[36m█▌        [0m| 4/26 [00:04<00:28,  1.30s/it]Epoch: 0/10. Loss: 1.1857:  15%|[36m█▌        [0m| 4/26 [00:05<00:28,  1.30s/it]Epoch: 0/10. Loss: 1.1857:  19%|[36m█▉        [0m| 5/26 [00:05<00:23,  1.12s/it]Epoch: 0/10. Loss: 1.1180:  19%|[36m█▉        [0m| 5/26 [00:06<00:23,  1.12s/it]Epoch: 0/10. Loss: 1.1180:  23%|[36m██▎       [0m| 6/26 [00:06<00:20,  1.03s/it]Epoch: 0/10. Loss: 1.1594:  23%|[36m██▎       [0m| 6/26 [00:08<00:20,  1.03s/it]Epoch: 0/10. Loss: 1.1594:  27%|[36m██▋       [0m| 7/26 [00:08<00:25,  1.34s/it]Epoch: 0/10. Loss: 1.5486:  27%|[36m██▋       [0m| 7/26 [00:09<00:25,  1.34s/it]Epoch: 0/10. Loss: 1.5486:  31%|[36m███       [0m| 8/26 [00:09<00:22,  1.26s/it]Epoch: 0/10. Loss: 1.6234:  31%|[36m███       [0m| 8/26 [00:10<00:22,  1.26s/it]Epoch: 0/10. Loss: 1.6234:  35%|[36m███▍      [0m| 9/26 [00:10<00:19,  1.14s/it]Epoch: 0/10. Loss: 1.0925:  35%|[36m███▍      [0m| 9/26 [00:11<00:19,  1.14s/it]Epoch: 0/10. Loss: 1.0925:  38%|[36m███▊      [0m| 10/26 [00:11<00:16,  1.06s/it]Epoch: 0/10. Loss: 1.2545:  38%|[36m███▊      [0m| 10/26 [00:12<00:16,  1.06s/it]Epoch: 0/10. Loss: 1.2545:  42%|[36m████▏     [0m| 11/26 [00:12<00:14,  1.01it/s]Epoch: 0/10. Loss: 1.1267:  42%|[36m████▏     [0m| 11/26 [00:13<00:14,  1.01it/s]Epoch: 0/10. Loss: 1.1267:  46%|[36m████▌     [0m| 12/26 [00:13<00:14,  1.01s/it]Epoch: 0/10. Loss: 1.3176:  46%|[36m████▌     [0m| 12/26 [00:14<00:14,  1.01s/it]Epoch: 0/10. Loss: 1.3176:  50%|[36m█████     [0m| 13/26 [00:14<00:12,  1.01it/s]Epoch: 0/10. Loss: 1.3346:  50%|[36m█████     [0m| 13/26 [00:15<00:12,  1.01it/s]Epoch: 0/10. Loss: 1.3346:  54%|[36m█████▍    [0m| 14/26 [00:15<00:12,  1.01s/it]Epoch: 0/10. Loss: 1.1464:  54%|[36m█████▍    [0m| 14/26 [00:16<00:12,  1.01s/it]Epoch: 0/10. Loss: 1.1464:  58%|[36m█████▊    [0m| 15/26 [00:16<00:10,  1.00it/s]Epoch: 0/10. Loss: 0.9993:  58%|[36m█████▊    [0m| 15/26 [00:17<00:10,  1.00it/s]Epoch: 0/10. Loss: 0.9993:  62%|[36m██████▏   [0m| 16/26 [00:17<00:09,  1.05it/s]Epoch: 0/10. Loss: 1.0357:  62%|[36m██████▏   [0m| 16/26 [00:18<00:09,  1.05it/s]Epoch: 0/10. Loss: 1.0357:  65%|[36m██████▌   [0m| 17/26 [00:18<00:08,  1.03it/s]Epoch: 0/10. Loss: 1.0731:  65%|[36m██████▌   [0m| 17/26 [00:19<00:08,  1.03it/s]Epoch: 0/10. Loss: 1.0731:  69%|[36m██████▉   [0m| 18/26 [00:19<00:08,  1.05s/it]Epoch: 0/10. Loss: 1.0224:  69%|[36m██████▉   [0m| 18/26 [00:20<00:08,  1.05s/it]Epoch: 0/10. Loss: 1.0224:  73%|[36m███████▎  [0m| 19/26 [00:20<00:07,  1.02s/it]Epoch: 0/10. Loss: 0.9660:  73%|[36m███████▎  [0m| 19/26 [00:22<00:07,  1.02s/it]Epoch: 0/10. Loss: 0.9660:  77%|[36m███████▋  [0m| 20/26 [00:22<00:07,  1.30s/it]Epoch: 0/10. Loss: 1.0254:  77%|[36m███████▋  [0m| 20/26 [00:24<00:07,  1.30s/it]Epoch: 0/10. Loss: 1.0254:  81%|[36m████████  [0m| 21/26 [00:24<00:08,  1.68s/it]Epoch: 0/10. Loss: 1.0769:  81%|[36m████████  [0m| 21/26 [00:25<00:08,  1.68s/it]Epoch: 0/10. Loss: 1.0769:  85%|[36m████████▍ [0m| 22/26 [00:25<00:05,  1.49s/it]Epoch: 0/10. Loss: 1.0826:  85%|[36m████████▍ [0m| 22/26 [00:26<00:05,  1.49s/it]Epoch: 0/10. Loss: 1.0826:  88%|[36m████████▊ [0m| 23/26 [00:26<00:03,  1.32s/it]Epoch: 0/10. Loss: 1.1004:  88%|[36m████████▊ [0m| 23/26 [00:27<00:03,  1.32s/it]Epoch: 0/10. Loss: 1.1004:  92%|[36m█████████▏[0m| 24/26 [00:27<00:02,  1.21s/it]Epoch: 0/10. Loss: 0.9865:  92%|[36m█████████▏[0m| 24/26 [00:29<00:02,  1.21s/it]Epoch: 0/10. Loss: 0.9865:  96%|[36m█████████▌[0m| 25/26 [00:29<00:01,  1.26s/it]Epoch: 0/10. Loss: 1.0478:  96%|[36m█████████▌[0m| 25/26 [00:31<00:01,  1.26s/it]Epoch: 0/10. Loss: 1.0478: 100%|[36m██████████[0m| 26/26 [00:31<00:00,  1.54s/it]Epoch: 0/10. Loss: 1.0478: 100%|[36m██████████[0m| 26/26 [00:31<00:00,  1.20s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:04,  1.25it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:05,  1.16s/it] 43%|[33m████▎     [0m| 3/7 [00:02<00:03,  1.05it/s] 57%|[33m█████▋    [0m| 4/7 [00:04<00:03,  1.10s/it] 71%|[33m███████▏  [0m| 5/7 [00:04<00:01,  1.15it/s] 86%|[33m████████▌ [0m| 6/7 [00:05<00:00,  1.15it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.46it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.19it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 1/10. Loss: 1.1414:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 1/10. Loss: 1.1414:   4%|[36m▍         [0m| 1/26 [00:00<00:23,  1.08it/s]Epoch: 1/10. Loss: 0.9926:   4%|[36m▍         [0m| 1/26 [00:01<00:23,  1.08it/s]Epoch: 1/10. Loss: 0.9926:   8%|[36m▊         [0m| 2/26 [00:01<00:19,  1.20it/s]Epoch: 1/10. Loss: 1.1220:   8%|[36m▊         [0m| 2/26 [00:02<00:19,  1.20it/s]Epoch: 1/10. Loss: 1.1220:  12%|[36m█▏        [0m| 3/26 [00:02<00:21,  1.09it/s]Epoch: 1/10. Loss: 1.1341:  12%|[36m█▏        [0m| 3/26 [00:03<00:21,  1.09it/s]Epoch: 1/10. Loss: 1.1341:  15%|[36m█▌        [0m| 4/26 [00:03<00:20,  1.09it/s]Epoch: 1/10. Loss: 1.0196:  15%|[36m█▌        [0m| 4/26 [00:04<00:20,  1.09it/s]Epoch: 1/10. Loss: 1.0196:  19%|[36m█▉        [0m| 5/26 [00:04<00:19,  1.07it/s]Epoch: 1/10. Loss: 1.0816:  19%|[36m█▉        [0m| 5/26 [00:05<00:19,  1.07it/s]Epoch: 1/10. Loss: 1.0816:  23%|[36m██▎       [0m| 6/26 [00:05<00:19,  1.02it/s]Epoch: 1/10. Loss: 1.0733:  23%|[36m██▎       [0m| 6/26 [00:06<00:19,  1.02it/s]Epoch: 1/10. Loss: 1.0733:  27%|[36m██▋       [0m| 7/26 [00:06<00:18,  1.02it/s]Epoch: 1/10. Loss: 1.1660:  27%|[36m██▋       [0m| 7/26 [00:07<00:18,  1.02it/s]Epoch: 1/10. Loss: 1.1660:  31%|[36m███       [0m| 8/26 [00:07<00:17,  1.00it/s]Epoch: 1/10. Loss: 1.0873:  31%|[36m███       [0m| 8/26 [00:08<00:17,  1.00it/s]Epoch: 1/10. Loss: 1.0873:  35%|[36m███▍      [0m| 9/26 [00:08<00:15,  1.09it/s]Epoch: 1/10. Loss: 1.0167:  35%|[36m███▍      [0m| 9/26 [00:11<00:15,  1.09it/s]Epoch: 1/10. Loss: 1.0167:  38%|[36m███▊      [0m| 10/26 [00:11<00:25,  1.56s/it]Epoch: 1/10. Loss: 1.1678:  38%|[36m███▊      [0m| 10/26 [00:13<00:25,  1.56s/it]Epoch: 1/10. Loss: 1.1678:  42%|[36m████▏     [0m| 11/26 [00:13<00:27,  1.82s/it]Epoch: 1/10. Loss: 0.9901:  42%|[36m████▏     [0m| 11/26 [00:14<00:27,  1.82s/it]Epoch: 1/10. Loss: 0.9901:  46%|[36m████▌     [0m| 12/26 [00:14<00:22,  1.59s/it]Epoch: 1/10. Loss: 1.0622:  46%|[36m████▌     [0m| 12/26 [00:16<00:22,  1.59s/it]Epoch: 1/10. Loss: 1.0622:  50%|[36m█████     [0m| 13/26 [00:16<00:19,  1.50s/it]Epoch: 1/10. Loss: 1.0529:  50%|[36m█████     [0m| 13/26 [00:17<00:19,  1.50s/it]Epoch: 1/10. Loss: 1.0529:  54%|[36m█████▍    [0m| 14/26 [00:17<00:15,  1.30s/it]Epoch: 1/10. Loss: 1.1474:  54%|[36m█████▍    [0m| 14/26 [00:18<00:15,  1.30s/it]Epoch: 1/10. Loss: 1.1474:  58%|[36m█████▊    [0m| 15/26 [00:18<00:13,  1.24s/it]Epoch: 1/10. Loss: 0.9967:  58%|[36m█████▊    [0m| 15/26 [00:19<00:13,  1.24s/it]Epoch: 1/10. Loss: 0.9967:  62%|[36m██████▏   [0m| 16/26 [00:19<00:13,  1.31s/it]Epoch: 1/10. Loss: 1.4070:  62%|[36m██████▏   [0m| 16/26 [00:20<00:13,  1.31s/it]Epoch: 1/10. Loss: 1.4070:  65%|[36m██████▌   [0m| 17/26 [00:20<00:10,  1.17s/it]Epoch: 1/10. Loss: 1.0034:  65%|[36m██████▌   [0m| 17/26 [00:21<00:10,  1.17s/it]Epoch: 1/10. Loss: 1.0034:  69%|[36m██████▉   [0m| 18/26 [00:21<00:08,  1.05s/it]Epoch: 1/10. Loss: 1.0153:  69%|[36m██████▉   [0m| 18/26 [00:22<00:08,  1.05s/it]Epoch: 1/10. Loss: 1.0153:  73%|[36m███████▎  [0m| 19/26 [00:22<00:07,  1.05s/it]Epoch: 1/10. Loss: 1.1337:  73%|[36m███████▎  [0m| 19/26 [00:23<00:07,  1.05s/it]Epoch: 1/10. Loss: 1.1337:  77%|[36m███████▋  [0m| 20/26 [00:23<00:05,  1.03it/s]Epoch: 1/10. Loss: 1.0163:  77%|[36m███████▋  [0m| 20/26 [00:23<00:05,  1.03it/s]Epoch: 1/10. Loss: 1.0163:  81%|[36m████████  [0m| 21/26 [00:23<00:04,  1.12it/s]Epoch: 1/10. Loss: 0.9823:  81%|[36m████████  [0m| 21/26 [00:24<00:04,  1.12it/s]Epoch: 1/10. Loss: 0.9823:  85%|[36m████████▍ [0m| 22/26 [00:24<00:03,  1.10it/s]Epoch: 1/10. Loss: 1.3427:  85%|[36m████████▍ [0m| 22/26 [00:25<00:03,  1.10it/s]Epoch: 1/10. Loss: 1.3427:  88%|[36m████████▊ [0m| 23/26 [00:25<00:02,  1.10it/s]Epoch: 1/10. Loss: 1.0982:  88%|[36m████████▊ [0m| 23/26 [00:26<00:02,  1.10it/s]Epoch: 1/10. Loss: 1.0982:  92%|[36m█████████▏[0m| 24/26 [00:26<00:01,  1.05it/s]Epoch: 1/10. Loss: 1.1817:  92%|[36m█████████▏[0m| 24/26 [00:27<00:01,  1.05it/s]Epoch: 1/10. Loss: 1.1817:  96%|[36m█████████▌[0m| 25/26 [00:27<00:00,  1.06it/s]Epoch: 1/10. Loss: 1.6178:  96%|[36m█████████▌[0m| 25/26 [00:28<00:00,  1.06it/s]Epoch: 1/10. Loss: 1.6178: 100%|[36m██████████[0m| 26/26 [00:28<00:00,  1.15it/s]Epoch: 1/10. Loss: 1.6178: 100%|[36m██████████[0m| 26/26 [00:28<00:00,  1.09s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:01<00:06,  1.07s/it] 29%|[33m██▊       [0m| 2/7 [00:02<00:06,  1.30s/it] 43%|[33m████▎     [0m| 3/7 [00:03<00:04,  1.03s/it] 57%|[33m█████▋    [0m| 4/7 [00:04<00:03,  1.14s/it] 71%|[33m███████▏  [0m| 5/7 [00:05<00:01,  1.12it/s] 86%|[33m████████▌ [0m| 6/7 [00:05<00:00,  1.13it/s]100%|[33m██████████[0m| 7/7 [00:06<00:00,  1.43it/s]100%|[33m██████████[0m| 7/7 [00:06<00:00,  1.13it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 2/10. Loss: 1.2741:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 2/10. Loss: 1.2741:   4%|[36m▍         [0m| 1/26 [00:00<00:20,  1.21it/s]Epoch: 2/10. Loss: 1.4867:   4%|[36m▍         [0m| 1/26 [00:01<00:20,  1.21it/s]Epoch: 2/10. Loss: 1.4867:   8%|[36m▊         [0m| 2/26 [00:01<00:21,  1.11it/s]Epoch: 2/10. Loss: 1.1895:   8%|[36m▊         [0m| 2/26 [00:02<00:21,  1.11it/s]Epoch: 2/10. Loss: 1.1895:  12%|[36m█▏        [0m| 3/26 [00:02<00:22,  1.01it/s]Epoch: 2/10. Loss: 0.9565:  12%|[36m█▏        [0m| 3/26 [00:03<00:22,  1.01it/s]Epoch: 2/10. Loss: 0.9565:  15%|[36m█▌        [0m| 4/26 [00:03<00:21,  1.04it/s]Epoch: 2/10. Loss: 1.2780:  15%|[36m█▌        [0m| 4/26 [00:04<00:21,  1.04it/s]Epoch: 2/10. Loss: 1.2780:  19%|[36m█▉        [0m| 5/26 [00:04<00:20,  1.02it/s]Epoch: 2/10. Loss: 1.1747:  19%|[36m█▉        [0m| 5/26 [00:06<00:20,  1.02it/s]Epoch: 2/10. Loss: 1.1747:  23%|[36m██▎       [0m| 6/26 [00:06<00:25,  1.29s/it]Epoch: 2/10. Loss: 1.5026:  23%|[36m██▎       [0m| 6/26 [00:07<00:25,  1.29s/it]Epoch: 2/10. Loss: 1.5026:  27%|[36m██▋       [0m| 7/26 [00:07<00:23,  1.26s/it]Epoch: 2/10. Loss: 1.1071:  27%|[36m██▋       [0m| 7/26 [00:08<00:23,  1.26s/it]Epoch: 2/10. Loss: 1.1071:  31%|[36m███       [0m| 8/26 [00:08<00:21,  1.18s/it]Epoch: 2/10. Loss: 1.1920:  31%|[36m███       [0m| 8/26 [00:09<00:21,  1.18s/it]Epoch: 2/10. Loss: 1.1920:  35%|[36m███▍      [0m| 9/26 [00:09<00:18,  1.09s/it]Epoch: 2/10. Loss: 1.0215:  35%|[36m███▍      [0m| 9/26 [00:11<00:18,  1.09s/it]Epoch: 2/10. Loss: 1.0215:  38%|[36m███▊      [0m| 10/26 [00:11<00:18,  1.18s/it]Epoch: 2/10. Loss: 1.2067:  38%|[36m███▊      [0m| 10/26 [00:12<00:18,  1.18s/it]Epoch: 2/10. Loss: 1.2067:  42%|[36m████▏     [0m| 11/26 [00:12<00:16,  1.09s/it]Epoch: 2/10. Loss: 1.0320:  42%|[36m████▏     [0m| 11/26 [00:16<00:16,  1.09s/it]Epoch: 2/10. Loss: 1.0320:  46%|[36m████▌     [0m| 12/26 [00:16<00:28,  2.01s/it]Epoch: 2/10. Loss: 1.0214:  46%|[36m████▌     [0m| 12/26 [00:17<00:28,  2.01s/it]Epoch: 2/10. Loss: 1.0214:  50%|[36m█████     [0m| 13/26 [00:17<00:23,  1.84s/it]Epoch: 2/10. Loss: 0.9926:  50%|[36m█████     [0m| 13/26 [00:18<00:23,  1.84s/it]Epoch: 2/10. Loss: 0.9926:  54%|[36m█████▍    [0m| 14/26 [00:18<00:18,  1.56s/it]Epoch: 2/10. Loss: 0.9948:  54%|[36m█████▍    [0m| 14/26 [00:19<00:18,  1.56s/it]Epoch: 2/10. Loss: 0.9948:  58%|[36m█████▊    [0m| 15/26 [00:19<00:15,  1.37s/it]Epoch: 2/10. Loss: 1.0702:  58%|[36m█████▊    [0m| 15/26 [00:20<00:15,  1.37s/it]Epoch: 2/10. Loss: 1.0702:  62%|[36m██████▏   [0m| 16/26 [00:20<00:11,  1.18s/it]Epoch: 2/10. Loss: 1.0561:  62%|[36m██████▏   [0m| 16/26 [00:21<00:11,  1.18s/it]Epoch: 2/10. Loss: 1.0561:  65%|[36m██████▌   [0m| 17/26 [00:21<00:09,  1.10s/it]Epoch: 2/10. Loss: 1.0868:  65%|[36m██████▌   [0m| 17/26 [00:23<00:09,  1.10s/it]Epoch: 2/10. Loss: 1.0868:  69%|[36m██████▉   [0m| 18/26 [00:23<00:13,  1.63s/it]Epoch: 2/10. Loss: 1.1525:  69%|[36m██████▉   [0m| 18/26 [00:26<00:13,  1.63s/it]Epoch: 2/10. Loss: 1.1525:  73%|[36m███████▎  [0m| 19/26 [00:26<00:12,  1.80s/it]Epoch: 2/10. Loss: 1.3066:  73%|[36m███████▎  [0m| 19/26 [00:26<00:12,  1.80s/it]Epoch: 2/10. Loss: 1.3066:  77%|[36m███████▋  [0m| 20/26 [00:26<00:08,  1.50s/it]Epoch: 2/10. Loss: 1.1035:  77%|[36m███████▋  [0m| 20/26 [00:28<00:08,  1.50s/it]Epoch: 2/10. Loss: 1.1035:  81%|[36m████████  [0m| 21/26 [00:28<00:07,  1.46s/it]Epoch: 2/10. Loss: 1.1951:  81%|[36m████████  [0m| 21/26 [00:30<00:07,  1.46s/it]Epoch: 2/10. Loss: 1.1951:  85%|[36m████████▍ [0m| 22/26 [00:30<00:06,  1.68s/it]Epoch: 2/10. Loss: 1.0826:  85%|[36m████████▍ [0m| 22/26 [00:31<00:06,  1.68s/it]Epoch: 2/10. Loss: 1.0826:  88%|[36m████████▊ [0m| 23/26 [00:31<00:04,  1.52s/it]Epoch: 2/10. Loss: 1.0003:  88%|[36m████████▊ [0m| 23/26 [00:32<00:04,  1.52s/it]Epoch: 2/10. Loss: 1.0003:  92%|[36m█████████▏[0m| 24/26 [00:32<00:02,  1.29s/it]Epoch: 2/10. Loss: 1.1646:  92%|[36m█████████▏[0m| 24/26 [00:33<00:02,  1.29s/it]Epoch: 2/10. Loss: 1.1646:  96%|[36m█████████▌[0m| 25/26 [00:33<00:01,  1.30s/it]Epoch: 2/10. Loss: 1.2637:  96%|[36m█████████▌[0m| 25/26 [00:35<00:01,  1.30s/it]Epoch: 2/10. Loss: 1.2637: 100%|[36m██████████[0m| 26/26 [00:35<00:00,  1.51s/it]Epoch: 2/10. Loss: 1.2637: 100%|[36m██████████[0m| 26/26 [00:35<00:00,  1.38s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:01<00:08,  1.42s/it] 29%|[33m██▊       [0m| 2/7 [00:02<00:07,  1.44s/it] 43%|[33m████▎     [0m| 3/7 [00:04<00:05,  1.46s/it] 57%|[33m█████▋    [0m| 4/7 [00:06<00:04,  1.60s/it] 71%|[33m███████▏  [0m| 5/7 [00:06<00:02,  1.19s/it] 86%|[33m████████▌ [0m| 6/7 [00:07<00:01,  1.09s/it]100%|[33m██████████[0m| 7/7 [00:07<00:00,  1.19it/s]100%|[33m██████████[0m| 7/7 [00:07<00:00,  1.12s/it]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 3/10. Loss: 0.9994:   0%|[36m          [0m| 0/26 [00:01<?, ?it/s]Epoch: 3/10. Loss: 0.9994:   4%|[36m▍         [0m| 1/26 [00:01<00:25,  1.03s/it]Epoch: 3/10. Loss: 1.1306:   4%|[36m▍         [0m| 1/26 [00:01<00:25,  1.03s/it]Epoch: 3/10. Loss: 1.1306:   8%|[36m▊         [0m| 2/26 [00:01<00:23,  1.01it/s]Epoch: 3/10. Loss: 1.1390:   8%|[36m▊         [0m| 2/26 [00:02<00:23,  1.01it/s]Epoch: 3/10. Loss: 1.1390:  12%|[36m█▏        [0m| 3/26 [00:02<00:20,  1.10it/s]Epoch: 3/10. Loss: 1.0199:  12%|[36m█▏        [0m| 3/26 [00:03<00:20,  1.10it/s]Epoch: 3/10. Loss: 1.0199:  15%|[36m█▌        [0m| 4/26 [00:03<00:21,  1.04it/s]Epoch: 3/10. Loss: 1.2211:  15%|[36m█▌        [0m| 4/26 [00:04<00:21,  1.04it/s]Epoch: 3/10. Loss: 1.2211:  19%|[36m█▉        [0m| 5/26 [00:04<00:20,  1.04it/s]Epoch: 3/10. Loss: 0.9986:  19%|[36m█▉        [0m| 5/26 [00:05<00:20,  1.04it/s]Epoch: 3/10. Loss: 0.9986:  23%|[36m██▎       [0m| 6/26 [00:05<00:18,  1.10it/s]Epoch: 3/10. Loss: 0.9318:  23%|[36m██▎       [0m| 6/26 [00:06<00:18,  1.10it/s]Epoch: 3/10. Loss: 0.9318:  27%|[36m██▋       [0m| 7/26 [00:06<00:17,  1.11it/s]Epoch: 3/10. Loss: 1.1308:  27%|[36m██▋       [0m| 7/26 [00:07<00:17,  1.11it/s]Epoch: 3/10. Loss: 1.1308:  31%|[36m███       [0m| 8/26 [00:07<00:15,  1.14it/s]Epoch: 3/10. Loss: 1.0309:  31%|[36m███       [0m| 8/26 [00:08<00:15,  1.14it/s]Epoch: 3/10. Loss: 1.0309:  35%|[36m███▍      [0m| 9/26 [00:08<00:15,  1.09it/s]Epoch: 3/10. Loss: 0.9782:  35%|[36m███▍      [0m| 9/26 [00:09<00:15,  1.09it/s]Epoch: 3/10. Loss: 0.9782:  38%|[36m███▊      [0m| 10/26 [00:09<00:15,  1.02it/s]Epoch: 3/10. Loss: 1.0616:  38%|[36m███▊      [0m| 10/26 [00:10<00:15,  1.02it/s]Epoch: 3/10. Loss: 1.0616:  42%|[36m████▏     [0m| 11/26 [00:10<00:15,  1.02s/it]Epoch: 3/10. Loss: 1.0515:  42%|[36m████▏     [0m| 11/26 [00:11<00:15,  1.02s/it]Epoch: 3/10. Loss: 1.0515:  46%|[36m████▌     [0m| 12/26 [00:11<00:13,  1.01it/s]Epoch: 3/10. Loss: 0.9923:  46%|[36m████▌     [0m| 12/26 [00:12<00:13,  1.01it/s]Epoch: 3/10. Loss: 0.9923:  50%|[36m█████     [0m| 13/26 [00:12<00:12,  1.06it/s]Epoch: 3/10. Loss: 1.0352:  50%|[36m█████     [0m| 13/26 [00:13<00:12,  1.06it/s]Epoch: 3/10. Loss: 1.0352:  54%|[36m█████▍    [0m| 14/26 [00:13<00:11,  1.06it/s]Epoch: 3/10. Loss: 1.1751:  54%|[36m█████▍    [0m| 14/26 [00:13<00:11,  1.06it/s]Epoch: 3/10. Loss: 1.1751:  58%|[36m█████▊    [0m| 15/26 [00:14<00:09,  1.13it/s]Epoch: 3/10. Loss: 0.9867:  58%|[36m█████▊    [0m| 15/26 [00:14<00:09,  1.13it/s]Epoch: 3/10. Loss: 0.9867:  62%|[36m██████▏   [0m| 16/26 [00:14<00:09,  1.09it/s]Epoch: 3/10. Loss: 1.1422:  62%|[36m██████▏   [0m| 16/26 [00:15<00:09,  1.09it/s]Epoch: 3/10. Loss: 1.1422:  65%|[36m██████▌   [0m| 17/26 [00:15<00:08,  1.11it/s]Epoch: 3/10. Loss: 1.0255:  65%|[36m██████▌   [0m| 17/26 [00:16<00:08,  1.11it/s]Epoch: 3/10. Loss: 1.0255:  69%|[36m██████▉   [0m| 18/26 [00:16<00:07,  1.08it/s]Epoch: 3/10. Loss: 0.9943:  69%|[36m██████▉   [0m| 18/26 [00:17<00:07,  1.08it/s]Epoch: 3/10. Loss: 0.9943:  73%|[36m███████▎  [0m| 19/26 [00:17<00:06,  1.13it/s]Epoch: 3/10. Loss: 1.0506:  73%|[36m███████▎  [0m| 19/26 [00:18<00:06,  1.13it/s]Epoch: 3/10. Loss: 1.0506:  77%|[36m███████▋  [0m| 20/26 [00:18<00:05,  1.04it/s]Epoch: 3/10. Loss: 1.0542:  77%|[36m███████▋  [0m| 20/26 [00:19<00:05,  1.04it/s]Epoch: 3/10. Loss: 1.0542:  81%|[36m████████  [0m| 21/26 [00:19<00:04,  1.13it/s]Epoch: 3/10. Loss: 1.2207:  81%|[36m████████  [0m| 21/26 [00:20<00:04,  1.13it/s]Epoch: 3/10. Loss: 1.2207:  85%|[36m████████▍ [0m| 22/26 [00:20<00:03,  1.07it/s]Epoch: 3/10. Loss: 1.0607:  85%|[36m████████▍ [0m| 22/26 [00:21<00:03,  1.07it/s]Epoch: 3/10. Loss: 1.0607:  88%|[36m████████▊ [0m| 23/26 [00:21<00:02,  1.07it/s]Epoch: 3/10. Loss: 0.9500:  88%|[36m████████▊ [0m| 23/26 [00:22<00:02,  1.07it/s]Epoch: 3/10. Loss: 0.9500:  92%|[36m█████████▏[0m| 24/26 [00:22<00:01,  1.12it/s]Epoch: 3/10. Loss: 0.9521:  92%|[36m█████████▏[0m| 24/26 [00:23<00:01,  1.12it/s]Epoch: 3/10. Loss: 0.9521:  96%|[36m█████████▌[0m| 25/26 [00:23<00:00,  1.13it/s]Epoch: 3/10. Loss: 1.2701:  96%|[36m█████████▌[0m| 25/26 [00:23<00:00,  1.13it/s]Epoch: 3/10. Loss: 1.2701: 100%|[36m██████████[0m| 26/26 [00:23<00:00,  1.21it/s]Epoch: 3/10. Loss: 1.2701: 100%|[36m██████████[0m| 26/26 [00:23<00:00,  1.09it/s]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:05,  1.13it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:06,  1.21s/it] 43%|[33m████▎     [0m| 3/7 [00:03<00:04,  1.00s/it] 57%|[33m█████▋    [0m| 4/7 [00:04<00:03,  1.13s/it] 71%|[33m███████▏  [0m| 5/7 [00:04<00:01,  1.11it/s] 86%|[33m████████▌ [0m| 6/7 [00:05<00:00,  1.08it/s]100%|[33m██████████[0m| 7/7 [00:06<00:00,  1.38it/s]100%|[33m██████████[0m| 7/7 [00:06<00:00,  1.13it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 4/10. Loss: 1.1119:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 4/10. Loss: 1.1119:   4%|[36m▍         [0m| 1/26 [00:00<00:22,  1.13it/s]Epoch: 4/10. Loss: 1.1068:   4%|[36m▍         [0m| 1/26 [00:02<00:22,  1.13it/s]Epoch: 4/10. Loss: 1.1068:   8%|[36m▊         [0m| 2/26 [00:02<00:26,  1.11s/it]Epoch: 4/10. Loss: 1.0800:   8%|[36m▊         [0m| 2/26 [00:03<00:26,  1.11s/it]Epoch: 4/10. Loss: 1.0800:  12%|[36m█▏        [0m| 3/26 [00:03<00:24,  1.08s/it]Epoch: 4/10. Loss: 1.1738:  12%|[36m█▏        [0m| 3/26 [00:04<00:24,  1.08s/it]Epoch: 4/10. Loss: 1.1738:  15%|[36m█▌        [0m| 4/26 [00:04<00:24,  1.10s/it]Epoch: 4/10. Loss: 1.1415:  15%|[36m█▌        [0m| 4/26 [00:05<00:24,  1.10s/it]Epoch: 4/10. Loss: 1.1415:  19%|[36m█▉        [0m| 5/26 [00:05<00:20,  1.01it/s]Epoch: 4/10. Loss: 0.9749:  19%|[36m█▉        [0m| 5/26 [00:06<00:20,  1.01it/s]Epoch: 4/10. Loss: 0.9749:  23%|[36m██▎       [0m| 6/26 [00:06<00:20,  1.00s/it]Epoch: 4/10. Loss: 1.2253:  23%|[36m██▎       [0m| 6/26 [00:07<00:20,  1.00s/it]Epoch: 4/10. Loss: 1.2253:  27%|[36m██▋       [0m| 7/26 [00:07<00:18,  1.02it/s]Epoch: 4/10. Loss: 0.9659:  27%|[36m██▋       [0m| 7/26 [00:08<00:18,  1.02it/s]Epoch: 4/10. Loss: 0.9659:  31%|[36m███       [0m| 8/26 [00:08<00:17,  1.01it/s]Epoch: 4/10. Loss: 0.9755:  31%|[36m███       [0m| 8/26 [00:09<00:17,  1.01it/s]Epoch: 4/10. Loss: 0.9755:  35%|[36m███▍      [0m| 9/26 [00:09<00:20,  1.21s/it]Epoch: 4/10. Loss: 0.9832:  35%|[36m███▍      [0m| 9/26 [00:10<00:20,  1.21s/it]Epoch: 4/10. Loss: 0.9832:  38%|[36m███▊      [0m| 10/26 [00:10<00:17,  1.11s/it]Epoch: 4/10. Loss: 1.1618:  38%|[36m███▊      [0m| 10/26 [00:11<00:17,  1.11s/it]Epoch: 4/10. Loss: 1.1618:  42%|[36m████▏     [0m| 11/26 [00:11<00:15,  1.00s/it]Epoch: 4/10. Loss: 1.3170:  42%|[36m████▏     [0m| 11/26 [00:12<00:15,  1.00s/it]Epoch: 4/10. Loss: 1.3170:  46%|[36m████▌     [0m| 12/26 [00:12<00:15,  1.12s/it]Epoch: 4/10. Loss: 0.9678:  46%|[36m████▌     [0m| 12/26 [00:13<00:15,  1.12s/it]Epoch: 4/10. Loss: 0.9678:  50%|[36m█████     [0m| 13/26 [00:13<00:13,  1.05s/it]Epoch: 4/10. Loss: 1.0358:  50%|[36m█████     [0m| 13/26 [00:14<00:13,  1.05s/it]Epoch: 4/10. Loss: 1.0358:  54%|[36m█████▍    [0m| 14/26 [00:14<00:11,  1.05it/s]Epoch: 4/10. Loss: 1.1583:  54%|[36m█████▍    [0m| 14/26 [00:15<00:11,  1.05it/s]Epoch: 4/10. Loss: 1.1583:  58%|[36m█████▊    [0m| 15/26 [00:15<00:10,  1.06it/s]Epoch: 4/10. Loss: 0.9846:  58%|[36m█████▊    [0m| 15/26 [00:16<00:10,  1.06it/s]Epoch: 4/10. Loss: 0.9846:  62%|[36m██████▏   [0m| 16/26 [00:16<00:09,  1.04it/s]Epoch: 4/10. Loss: 1.0284:  62%|[36m██████▏   [0m| 16/26 [00:17<00:09,  1.04it/s]Epoch: 4/10. Loss: 1.0284:  65%|[36m██████▌   [0m| 17/26 [00:17<00:08,  1.05it/s]Epoch: 4/10. Loss: 1.1222:  65%|[36m██████▌   [0m| 17/26 [00:18<00:08,  1.05it/s]Epoch: 4/10. Loss: 1.1222:  69%|[36m██████▉   [0m| 18/26 [00:18<00:08,  1.04s/it]Epoch: 4/10. Loss: 0.9732:  69%|[36m██████▉   [0m| 18/26 [00:19<00:08,  1.04s/it]Epoch: 4/10. Loss: 0.9732:  73%|[36m███████▎  [0m| 19/26 [00:19<00:06,  1.03it/s]Epoch: 4/10. Loss: 1.0850:  73%|[36m███████▎  [0m| 19/26 [00:20<00:06,  1.03it/s]Epoch: 4/10. Loss: 1.0850:  77%|[36m███████▋  [0m| 20/26 [00:20<00:05,  1.01it/s]Epoch: 4/10. Loss: 1.0394:  77%|[36m███████▋  [0m| 20/26 [00:21<00:05,  1.01it/s]Epoch: 4/10. Loss: 1.0394:  81%|[36m████████  [0m| 21/26 [00:21<00:04,  1.00it/s]Epoch: 4/10. Loss: 1.1560:  81%|[36m████████  [0m| 21/26 [00:22<00:04,  1.00it/s]Epoch: 4/10. Loss: 1.1560:  85%|[36m████████▍ [0m| 22/26 [00:22<00:03,  1.02it/s]Epoch: 4/10. Loss: 0.9698:  85%|[36m████████▍ [0m| 22/26 [00:23<00:03,  1.02it/s]Epoch: 4/10. Loss: 0.9698:  88%|[36m████████▊ [0m| 23/26 [00:23<00:02,  1.03it/s]Epoch: 4/10. Loss: 1.0853:  88%|[36m████████▊ [0m| 23/26 [00:24<00:02,  1.03it/s]Epoch: 4/10. Loss: 1.0853:  92%|[36m█████████▏[0m| 24/26 [00:24<00:02,  1.03s/it]Epoch: 4/10. Loss: 1.0277:  92%|[36m█████████▏[0m| 24/26 [00:25<00:02,  1.03s/it]Epoch: 4/10. Loss: 1.0277:  96%|[36m█████████▌[0m| 25/26 [00:25<00:01,  1.02s/it]Epoch: 4/10. Loss: 1.0197:  96%|[36m█████████▌[0m| 25/26 [00:26<00:01,  1.02s/it]Epoch: 4/10. Loss: 1.0197: 100%|[36m██████████[0m| 26/26 [00:26<00:00,  1.10it/s]Epoch: 4/10. Loss: 1.0197: 100%|[36m██████████[0m| 26/26 [00:26<00:00,  1.00s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:05,  1.18it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:06,  1.22s/it] 43%|[33m████▎     [0m| 3/7 [00:03<00:03,  1.00it/s] 57%|[33m█████▋    [0m| 4/7 [00:04<00:03,  1.10s/it] 71%|[33m███████▏  [0m| 5/7 [00:04<00:01,  1.14it/s] 86%|[33m████████▌ [0m| 6/7 [00:05<00:00,  1.12it/s]100%|[33m██████████[0m| 7/7 [00:06<00:00,  1.42it/s]100%|[33m██████████[0m| 7/7 [00:06<00:00,  1.16it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 5/10. Loss: 0.9704:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 5/10. Loss: 0.9704:   4%|[36m▍         [0m| 1/26 [00:00<00:22,  1.11it/s]Epoch: 5/10. Loss: 1.0434:   4%|[36m▍         [0m| 1/26 [00:01<00:22,  1.11it/s]Epoch: 5/10. Loss: 1.0434:   8%|[36m▊         [0m| 2/26 [00:01<00:20,  1.15it/s]Epoch: 5/10. Loss: 1.0023:   8%|[36m▊         [0m| 2/26 [00:02<00:20,  1.15it/s]Epoch: 5/10. Loss: 1.0023:  12%|[36m█▏        [0m| 3/26 [00:02<00:19,  1.20it/s]Epoch: 5/10. Loss: 0.9896:  12%|[36m█▏        [0m| 3/26 [00:03<00:19,  1.20it/s]Epoch: 5/10. Loss: 0.9896:  15%|[36m█▌        [0m| 4/26 [00:03<00:19,  1.13it/s]Epoch: 5/10. Loss: 1.0491:  15%|[36m█▌        [0m| 4/26 [00:04<00:19,  1.13it/s]Epoch: 5/10. Loss: 1.0491:  19%|[36m█▉        [0m| 5/26 [00:04<00:19,  1.09it/s]Epoch: 5/10. Loss: 1.0016:  19%|[36m█▉        [0m| 5/26 [00:05<00:19,  1.09it/s]Epoch: 5/10. Loss: 1.0016:  23%|[36m██▎       [0m| 6/26 [00:05<00:17,  1.12it/s]Epoch: 5/10. Loss: 0.9680:  23%|[36m██▎       [0m| 6/26 [00:06<00:17,  1.12it/s]Epoch: 5/10. Loss: 0.9680:  27%|[36m██▋       [0m| 7/26 [00:06<00:17,  1.10it/s]Epoch: 5/10. Loss: 1.0349:  27%|[36m██▋       [0m| 7/26 [00:06<00:17,  1.10it/s]Epoch: 5/10. Loss: 1.0349:  31%|[36m███       [0m| 8/26 [00:06<00:15,  1.19it/s]Epoch: 5/10. Loss: 1.0240:  31%|[36m███       [0m| 8/26 [00:07<00:15,  1.19it/s]Epoch: 5/10. Loss: 1.0240:  35%|[36m███▍      [0m| 9/26 [00:07<00:14,  1.15it/s]Epoch: 5/10. Loss: 0.9911:  35%|[36m███▍      [0m| 9/26 [00:10<00:14,  1.15it/s]Epoch: 5/10. Loss: 0.9911:  38%|[36m███▊      [0m| 10/26 [00:10<00:21,  1.34s/it]Epoch: 5/10. Loss: 1.0269:  38%|[36m███▊      [0m| 10/26 [00:11<00:21,  1.34s/it]Epoch: 5/10. Loss: 1.0269:  42%|[36m████▏     [0m| 11/26 [00:11<00:18,  1.26s/it]Epoch: 5/10. Loss: 0.9845:  42%|[36m████▏     [0m| 11/26 [00:12<00:18,  1.26s/it]Epoch: 5/10. Loss: 0.9845:  46%|[36m████▌     [0m| 12/26 [00:12<00:17,  1.25s/it]Epoch: 5/10. Loss: 1.2379:  46%|[36m████▌     [0m| 12/26 [00:14<00:17,  1.25s/it]Epoch: 5/10. Loss: 1.2379:  50%|[36m█████     [0m| 13/26 [00:14<00:20,  1.57s/it]Epoch: 5/10. Loss: 0.9425:  50%|[36m█████     [0m| 13/26 [00:15<00:20,  1.57s/it]Epoch: 5/10. Loss: 0.9425:  54%|[36m█████▍    [0m| 14/26 [00:15<00:16,  1.38s/it]Epoch: 5/10. Loss: 0.9622:  54%|[36m█████▍    [0m| 14/26 [00:16<00:16,  1.38s/it]Epoch: 5/10. Loss: 0.9622:  58%|[36m█████▊    [0m| 15/26 [00:16<00:13,  1.26s/it]Epoch: 5/10. Loss: 0.9894:  58%|[36m█████▊    [0m| 15/26 [00:18<00:13,  1.26s/it]Epoch: 5/10. Loss: 0.9894:  62%|[36m██████▏   [0m| 16/26 [00:18<00:13,  1.36s/it]Epoch: 5/10. Loss: 0.9941:  62%|[36m██████▏   [0m| 16/26 [00:21<00:13,  1.36s/it]Epoch: 5/10. Loss: 0.9941:  65%|[36m██████▌   [0m| 17/26 [00:21<00:17,  1.95s/it]Epoch: 5/10. Loss: 0.9038:  65%|[36m██████▌   [0m| 17/26 [00:23<00:17,  1.95s/it]Epoch: 5/10. Loss: 0.9038:  69%|[36m██████▉   [0m| 18/26 [00:23<00:15,  1.90s/it]Epoch: 5/10. Loss: 0.9170:  69%|[36m██████▉   [0m| 18/26 [00:25<00:15,  1.90s/it]Epoch: 5/10. Loss: 0.9170:  73%|[36m███████▎  [0m| 19/26 [00:25<00:13,  1.94s/it]Epoch: 5/10. Loss: 1.0158:  73%|[36m███████▎  [0m| 19/26 [00:26<00:13,  1.94s/it]Epoch: 5/10. Loss: 1.0158:  77%|[36m███████▋  [0m| 20/26 [00:26<00:09,  1.66s/it]Epoch: 5/10. Loss: 1.2804:  77%|[36m███████▋  [0m| 20/26 [00:27<00:09,  1.66s/it]Epoch: 5/10. Loss: 1.2804:  81%|[36m████████  [0m| 21/26 [00:27<00:07,  1.48s/it]Epoch: 5/10. Loss: 1.0961:  81%|[36m████████  [0m| 21/26 [00:28<00:07,  1.48s/it]Epoch: 5/10. Loss: 1.0961:  85%|[36m████████▍ [0m| 22/26 [00:28<00:05,  1.28s/it]Epoch: 5/10. Loss: 1.0547:  85%|[36m████████▍ [0m| 22/26 [00:29<00:05,  1.28s/it]Epoch: 5/10. Loss: 1.0547:  88%|[36m████████▊ [0m| 23/26 [00:29<00:03,  1.24s/it]Epoch: 5/10. Loss: 0.9953:  88%|[36m████████▊ [0m| 23/26 [00:30<00:03,  1.24s/it]Epoch: 5/10. Loss: 0.9953:  92%|[36m█████████▏[0m| 24/26 [00:30<00:02,  1.15s/it]Epoch: 5/10. Loss: 1.0221:  92%|[36m█████████▏[0m| 24/26 [00:31<00:02,  1.15s/it]Epoch: 5/10. Loss: 1.0221:  96%|[36m█████████▌[0m| 25/26 [00:31<00:01,  1.04s/it]Epoch: 5/10. Loss: 0.9442:  96%|[36m█████████▌[0m| 25/26 [00:31<00:01,  1.04s/it]Epoch: 5/10. Loss: 0.9442: 100%|[36m██████████[0m| 26/26 [00:31<00:00,  1.07it/s]Epoch: 5/10. Loss: 0.9442: 100%|[36m██████████[0m| 26/26 [00:31<00:00,  1.23s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:01<00:09,  1.51s/it] 29%|[33m██▊       [0m| 2/7 [00:02<00:07,  1.47s/it] 43%|[33m████▎     [0m| 3/7 [00:03<00:04,  1.13s/it] 57%|[33m█████▋    [0m| 4/7 [00:05<00:03,  1.26s/it] 71%|[33m███████▏  [0m| 5/7 [00:05<00:01,  1.02it/s] 86%|[33m████████▌ [0m| 6/7 [00:08<00:01,  1.51s/it]100%|[33m██████████[0m| 7/7 [00:08<00:00,  1.12s/it]100%|[33m██████████[0m| 7/7 [00:08<00:00,  1.21s/it]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 6/10. Loss: 1.0424:   0%|[36m          [0m| 0/26 [00:01<?, ?it/s]Epoch: 6/10. Loss: 1.0424:   4%|[36m▍         [0m| 1/26 [00:01<00:30,  1.23s/it]Epoch: 6/10. Loss: 0.9727:   4%|[36m▍         [0m| 1/26 [00:02<00:30,  1.23s/it]Epoch: 6/10. Loss: 0.9727:   8%|[36m▊         [0m| 2/26 [00:02<00:35,  1.46s/it]Epoch: 6/10. Loss: 0.9772:   8%|[36m▊         [0m| 2/26 [00:03<00:35,  1.46s/it]Epoch: 6/10. Loss: 0.9772:  12%|[36m█▏        [0m| 3/26 [00:03<00:27,  1.20s/it]Epoch: 6/10. Loss: 1.0157:  12%|[36m█▏        [0m| 3/26 [00:04<00:27,  1.20s/it]Epoch: 6/10. Loss: 1.0157:  15%|[36m█▌        [0m| 4/26 [00:04<00:23,  1.08s/it]Epoch: 6/10. Loss: 0.9606:  15%|[36m█▌        [0m| 4/26 [00:05<00:23,  1.08s/it]Epoch: 6/10. Loss: 0.9606:  19%|[36m█▉        [0m| 5/26 [00:05<00:21,  1.03s/it]Epoch: 6/10. Loss: 1.0033:  19%|[36m█▉        [0m| 5/26 [00:06<00:21,  1.03s/it]Epoch: 6/10. Loss: 1.0033:  23%|[36m██▎       [0m| 6/26 [00:06<00:21,  1.05s/it]Epoch: 6/10. Loss: 1.0096:  23%|[36m██▎       [0m| 6/26 [00:07<00:21,  1.05s/it]Epoch: 6/10. Loss: 1.0096:  27%|[36m██▋       [0m| 7/26 [00:07<00:18,  1.04it/s]Epoch: 6/10. Loss: 1.0264:  27%|[36m██▋       [0m| 7/26 [00:08<00:18,  1.04it/s]Epoch: 6/10. Loss: 1.0264:  31%|[36m███       [0m| 8/26 [00:08<00:17,  1.06it/s]Epoch: 6/10. Loss: 1.1070:  31%|[36m███       [0m| 8/26 [00:09<00:17,  1.06it/s]Epoch: 6/10. Loss: 1.1070:  35%|[36m███▍      [0m| 9/26 [00:09<00:16,  1.05it/s]Epoch: 6/10. Loss: 0.9766:  35%|[36m███▍      [0m| 9/26 [00:10<00:16,  1.05it/s]Epoch: 6/10. Loss: 0.9766:  38%|[36m███▊      [0m| 10/26 [00:10<00:15,  1.04it/s]Epoch: 6/10. Loss: 1.0196:  38%|[36m███▊      [0m| 10/26 [00:11<00:15,  1.04it/s]Epoch: 6/10. Loss: 1.0196:  42%|[36m████▏     [0m| 11/26 [00:11<00:14,  1.03it/s]Epoch: 6/10. Loss: 0.9870:  42%|[36m████▏     [0m| 11/26 [00:12<00:14,  1.03it/s]Epoch: 6/10. Loss: 0.9870:  46%|[36m████▌     [0m| 12/26 [00:12<00:13,  1.03it/s]Epoch: 6/10. Loss: 0.9482:  46%|[36m████▌     [0m| 12/26 [00:13<00:13,  1.03it/s]Epoch: 6/10. Loss: 0.9482:  50%|[36m█████     [0m| 13/26 [00:13<00:12,  1.07it/s]Epoch: 6/10. Loss: 0.9304:  50%|[36m█████     [0m| 13/26 [00:13<00:12,  1.07it/s]Epoch: 6/10. Loss: 0.9304:  54%|[36m█████▍    [0m| 14/26 [00:13<00:10,  1.14it/s]Epoch: 6/10. Loss: 1.0621:  54%|[36m█████▍    [0m| 14/26 [00:14<00:10,  1.14it/s]Epoch: 6/10. Loss: 1.0621:  58%|[36m█████▊    [0m| 15/26 [00:14<00:10,  1.08it/s]Epoch: 6/10. Loss: 0.9196:  58%|[36m█████▊    [0m| 15/26 [00:15<00:10,  1.08it/s]Epoch: 6/10. Loss: 0.9196:  62%|[36m██████▏   [0m| 16/26 [00:15<00:09,  1.10it/s]Epoch: 6/10. Loss: 1.0153:  62%|[36m██████▏   [0m| 16/26 [00:17<00:09,  1.10it/s]Epoch: 6/10. Loss: 1.0153:  65%|[36m██████▌   [0m| 17/26 [00:17<00:09,  1.08s/it]Epoch: 6/10. Loss: 0.9287:  65%|[36m██████▌   [0m| 17/26 [00:18<00:09,  1.08s/it]Epoch: 6/10. Loss: 0.9287:  69%|[36m██████▉   [0m| 18/26 [00:18<00:08,  1.06s/it]Epoch: 6/10. Loss: 1.2758:  69%|[36m██████▉   [0m| 18/26 [00:19<00:08,  1.06s/it]Epoch: 6/10. Loss: 1.2758:  73%|[36m███████▎  [0m| 19/26 [00:19<00:07,  1.02s/it]Epoch: 6/10. Loss: 1.2538:  73%|[36m███████▎  [0m| 19/26 [00:20<00:07,  1.02s/it]Epoch: 6/10. Loss: 1.2538:  77%|[36m███████▋  [0m| 20/26 [00:20<00:05,  1.01it/s]Epoch: 6/10. Loss: 1.4179:  77%|[36m███████▋  [0m| 20/26 [00:21<00:05,  1.01it/s]Epoch: 6/10. Loss: 1.4179:  81%|[36m████████  [0m| 21/26 [00:21<00:04,  1.02it/s]Epoch: 6/10. Loss: 1.2881:  81%|[36m████████  [0m| 21/26 [00:22<00:04,  1.02it/s]Epoch: 6/10. Loss: 1.2881:  85%|[36m████████▍ [0m| 22/26 [00:22<00:04,  1.07s/it]Epoch: 6/10. Loss: 0.9932:  85%|[36m████████▍ [0m| 22/26 [00:23<00:04,  1.07s/it]Epoch: 6/10. Loss: 0.9932:  88%|[36m████████▊ [0m| 23/26 [00:23<00:03,  1.05s/it]Epoch: 6/10. Loss: 1.0635:  88%|[36m████████▊ [0m| 23/26 [00:24<00:03,  1.05s/it]Epoch: 6/10. Loss: 1.0635:  92%|[36m█████████▏[0m| 24/26 [00:24<00:01,  1.01it/s]Epoch: 6/10. Loss: 1.0857:  92%|[36m█████████▏[0m| 24/26 [00:25<00:01,  1.01it/s]Epoch: 6/10. Loss: 1.0857:  96%|[36m█████████▌[0m| 25/26 [00:25<00:00,  1.03it/s]Epoch: 6/10. Loss: 0.9475:  96%|[36m█████████▌[0m| 25/26 [00:25<00:00,  1.03it/s]Epoch: 6/10. Loss: 0.9475: 100%|[36m██████████[0m| 26/26 [00:25<00:00,  1.13it/s]Epoch: 6/10. Loss: 0.9475: 100%|[36m██████████[0m| 26/26 [00:25<00:00,  1.01it/s]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:01<00:06,  1.16s/it] 29%|[33m██▊       [0m| 2/7 [00:02<00:06,  1.33s/it] 43%|[33m████▎     [0m| 3/7 [00:03<00:04,  1.05s/it] 57%|[33m█████▋    [0m| 4/7 [00:04<00:03,  1.14s/it] 71%|[33m███████▏  [0m| 5/7 [00:05<00:01,  1.10it/s] 86%|[33m████████▌ [0m| 6/7 [00:05<00:00,  1.11it/s]100%|[33m██████████[0m| 7/7 [00:06<00:00,  1.43it/s]100%|[33m██████████[0m| 7/7 [00:06<00:00,  1.11it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 7/10. Loss: 1.1086:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 7/10. Loss: 1.1086:   4%|[36m▍         [0m| 1/26 [00:00<00:20,  1.21it/s]Epoch: 7/10. Loss: 1.1380:   4%|[36m▍         [0m| 1/26 [00:01<00:20,  1.21it/s]Epoch: 7/10. Loss: 1.1380:   8%|[36m▊         [0m| 2/26 [00:01<00:20,  1.17it/s]Epoch: 7/10. Loss: 0.9640:   8%|[36m▊         [0m| 2/26 [00:02<00:20,  1.17it/s]Epoch: 7/10. Loss: 0.9640:  12%|[36m█▏        [0m| 3/26 [00:02<00:21,  1.07it/s]Epoch: 7/10. Loss: 1.1159:  12%|[36m█▏        [0m| 3/26 [00:03<00:21,  1.07it/s]Epoch: 7/10. Loss: 1.1159:  15%|[36m█▌        [0m| 4/26 [00:03<00:21,  1.02it/s]Epoch: 7/10. Loss: 0.9151:  15%|[36m█▌        [0m| 4/26 [00:05<00:21,  1.02it/s]Epoch: 7/10. Loss: 0.9151:  19%|[36m█▉        [0m| 5/26 [00:05<00:27,  1.29s/it]Epoch: 7/10. Loss: 0.9070:  19%|[36m█▉        [0m| 5/26 [00:06<00:27,  1.29s/it]Epoch: 7/10. Loss: 0.9070:  23%|[36m██▎       [0m| 6/26 [00:06<00:22,  1.14s/it]Epoch: 7/10. Loss: 0.9944:  23%|[36m██▎       [0m| 6/26 [00:07<00:22,  1.14s/it]Epoch: 7/10. Loss: 0.9944:  27%|[36m██▋       [0m| 7/26 [00:07<00:19,  1.05s/it]Epoch: 7/10. Loss: 0.9405:  27%|[36m██▋       [0m| 7/26 [00:08<00:19,  1.05s/it]Epoch: 7/10. Loss: 0.9405:  31%|[36m███       [0m| 8/26 [00:08<00:17,  1.04it/s]Epoch: 7/10. Loss: 1.2119:  31%|[36m███       [0m| 8/26 [00:09<00:17,  1.04it/s]Epoch: 7/10. Loss: 1.2119:  35%|[36m███▍      [0m| 9/26 [00:09<00:16,  1.04it/s]Epoch: 7/10. Loss: 1.0245:  35%|[36m███▍      [0m| 9/26 [00:10<00:16,  1.04it/s]Epoch: 7/10. Loss: 1.0245:  38%|[36m███▊      [0m| 10/26 [00:10<00:18,  1.17s/it]Epoch: 7/10. Loss: 1.0592:  38%|[36m███▊      [0m| 10/26 [00:11<00:18,  1.17s/it]Epoch: 7/10. Loss: 1.0592:  42%|[36m████▏     [0m| 11/26 [00:11<00:15,  1.04s/it]Epoch: 7/10. Loss: 1.0035:  42%|[36m████▏     [0m| 11/26 [00:12<00:15,  1.04s/it]Epoch: 7/10. Loss: 1.0035:  46%|[36m████▌     [0m| 12/26 [00:12<00:16,  1.15s/it]Epoch: 7/10. Loss: 1.0184:  46%|[36m████▌     [0m| 12/26 [00:13<00:16,  1.15s/it]Epoch: 7/10. Loss: 1.0184:  50%|[36m█████     [0m| 13/26 [00:13<00:13,  1.06s/it]Epoch: 7/10. Loss: 1.0485:  50%|[36m█████     [0m| 13/26 [00:14<00:13,  1.06s/it]Epoch: 7/10. Loss: 1.0485:  54%|[36m█████▍    [0m| 14/26 [00:14<00:12,  1.04s/it]Epoch: 7/10. Loss: 1.1424:  54%|[36m█████▍    [0m| 14/26 [00:15<00:12,  1.04s/it]Epoch: 7/10. Loss: 1.1424:  58%|[36m█████▊    [0m| 15/26 [00:15<00:10,  1.01it/s]Epoch: 7/10. Loss: 1.0556:  58%|[36m█████▊    [0m| 15/26 [00:16<00:10,  1.01it/s]Epoch: 7/10. Loss: 1.0556:  62%|[36m██████▏   [0m| 16/26 [00:16<00:10,  1.01s/it]Epoch: 7/10. Loss: 0.9910:  62%|[36m██████▏   [0m| 16/26 [00:17<00:10,  1.01s/it]Epoch: 7/10. Loss: 0.9910:  65%|[36m██████▌   [0m| 17/26 [00:17<00:08,  1.03it/s]Epoch: 7/10. Loss: 1.0068:  65%|[36m██████▌   [0m| 17/26 [00:18<00:08,  1.03it/s]Epoch: 7/10. Loss: 1.0068:  69%|[36m██████▉   [0m| 18/26 [00:18<00:08,  1.00s/it]Epoch: 7/10. Loss: 0.9620:  69%|[36m██████▉   [0m| 18/26 [00:19<00:08,  1.00s/it]Epoch: 7/10. Loss: 0.9620:  73%|[36m███████▎  [0m| 19/26 [00:19<00:06,  1.02it/s]Epoch: 7/10. Loss: 1.0133:  73%|[36m███████▎  [0m| 19/26 [00:20<00:06,  1.02it/s]Epoch: 7/10. Loss: 1.0133:  77%|[36m███████▋  [0m| 20/26 [00:20<00:05,  1.11it/s]Epoch: 7/10. Loss: 0.9308:  77%|[36m███████▋  [0m| 20/26 [00:21<00:05,  1.11it/s]Epoch: 7/10. Loss: 0.9308:  81%|[36m████████  [0m| 21/26 [00:21<00:04,  1.08it/s]Epoch: 7/10. Loss: 0.9766:  81%|[36m████████  [0m| 21/26 [00:22<00:04,  1.08it/s]Epoch: 7/10. Loss: 0.9766:  85%|[36m████████▍ [0m| 22/26 [00:22<00:03,  1.10it/s]Epoch: 7/10. Loss: 0.8999:  85%|[36m████████▍ [0m| 22/26 [00:23<00:03,  1.10it/s]Epoch: 7/10. Loss: 0.8999:  88%|[36m████████▊ [0m| 23/26 [00:23<00:02,  1.01it/s]Epoch: 7/10. Loss: 1.1481:  88%|[36m████████▊ [0m| 23/26 [00:23<00:02,  1.01it/s]Epoch: 7/10. Loss: 1.1481:  92%|[36m█████████▏[0m| 24/26 [00:23<00:01,  1.09it/s]Epoch: 7/10. Loss: 0.9422:  92%|[36m█████████▏[0m| 24/26 [00:24<00:01,  1.09it/s]Epoch: 7/10. Loss: 0.9422:  96%|[36m█████████▌[0m| 25/26 [00:24<00:00,  1.08it/s]Epoch: 7/10. Loss: 0.8922:  96%|[36m█████████▌[0m| 25/26 [00:25<00:00,  1.08it/s]Epoch: 7/10. Loss: 0.8922: 100%|[36m██████████[0m| 26/26 [00:25<00:00,  1.13it/s]Epoch: 7/10. Loss: 0.8922: 100%|[36m██████████[0m| 26/26 [00:25<00:00,  1.01it/s]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:05,  1.10it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:06,  1.25s/it] 43%|[33m████▎     [0m| 3/7 [00:03<00:04,  1.24s/it] 57%|[33m█████▋    [0m| 4/7 [00:04<00:03,  1.28s/it] 71%|[33m███████▏  [0m| 5/7 [00:05<00:01,  1.00it/s] 86%|[33m████████▌ [0m| 6/7 [00:06<00:00,  1.04it/s]100%|[33m██████████[0m| 7/7 [00:06<00:00,  1.34it/s]100%|[33m██████████[0m| 7/7 [00:06<00:00,  1.05it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 8/10. Loss: 1.0834:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 8/10. Loss: 1.0834:   4%|[36m▍         [0m| 1/26 [00:00<00:20,  1.23it/s]Epoch: 8/10. Loss: 0.9776:   4%|[36m▍         [0m| 1/26 [00:01<00:20,  1.23it/s]Epoch: 8/10. Loss: 0.9776:   8%|[36m▊         [0m| 2/26 [00:01<00:19,  1.20it/s]Epoch: 8/10. Loss: 0.9471:   8%|[36m▊         [0m| 2/26 [00:02<00:19,  1.20it/s]Epoch: 8/10. Loss: 0.9471:  12%|[36m█▏        [0m| 3/26 [00:02<00:21,  1.08it/s]Epoch: 8/10. Loss: 1.0502:  12%|[36m█▏        [0m| 3/26 [00:03<00:21,  1.08it/s]Epoch: 8/10. Loss: 1.0502:  15%|[36m█▌        [0m| 4/26 [00:03<00:19,  1.15it/s]Epoch: 8/10. Loss: 1.1355:  15%|[36m█▌        [0m| 4/26 [00:04<00:19,  1.15it/s]Epoch: 8/10. Loss: 1.1355:  19%|[36m█▉        [0m| 5/26 [00:04<00:19,  1.08it/s]Epoch: 8/10. Loss: 1.0452:  19%|[36m█▉        [0m| 5/26 [00:06<00:19,  1.08it/s]Epoch: 8/10. Loss: 1.0452:  23%|[36m██▎       [0m| 6/26 [00:06<00:23,  1.19s/it]Epoch: 8/10. Loss: 1.0326:  23%|[36m██▎       [0m| 6/26 [00:08<00:23,  1.19s/it]Epoch: 8/10. Loss: 1.0326:  27%|[36m██▋       [0m| 7/26 [00:08<00:26,  1.41s/it]Epoch: 8/10. Loss: 1.0382:  27%|[36m██▋       [0m| 7/26 [00:08<00:26,  1.41s/it]Epoch: 8/10. Loss: 1.0382:  31%|[36m███       [0m| 8/26 [00:08<00:21,  1.21s/it]Epoch: 8/10. Loss: 0.9536:  31%|[36m███       [0m| 8/26 [00:09<00:21,  1.21s/it]Epoch: 8/10. Loss: 0.9536:  35%|[36m███▍      [0m| 9/26 [00:09<00:20,  1.18s/it]Epoch: 8/10. Loss: 1.0503:  35%|[36m███▍      [0m| 9/26 [00:11<00:20,  1.18s/it]Epoch: 8/10. Loss: 1.0503:  38%|[36m███▊      [0m| 10/26 [00:11<00:18,  1.17s/it]Epoch: 8/10. Loss: 0.9282:  38%|[36m███▊      [0m| 10/26 [00:12<00:18,  1.17s/it]Epoch: 8/10. Loss: 0.9282:  42%|[36m████▏     [0m| 11/26 [00:12<00:16,  1.11s/it]Epoch: 8/10. Loss: 0.9661:  42%|[36m████▏     [0m| 11/26 [00:13<00:16,  1.11s/it]Epoch: 8/10. Loss: 0.9661:  46%|[36m████▌     [0m| 12/26 [00:13<00:18,  1.30s/it]Epoch: 8/10. Loss: 1.0851:  46%|[36m████▌     [0m| 12/26 [00:14<00:18,  1.30s/it]Epoch: 8/10. Loss: 1.0851:  50%|[36m█████     [0m| 13/26 [00:14<00:15,  1.19s/it]Epoch: 8/10. Loss: 1.0593:  50%|[36m█████     [0m| 13/26 [00:16<00:15,  1.19s/it]Epoch: 8/10. Loss: 1.0593:  54%|[36m█████▍    [0m| 14/26 [00:16<00:17,  1.42s/it]Epoch: 8/10. Loss: 1.1315:  54%|[36m█████▍    [0m| 14/26 [00:17<00:17,  1.42s/it]Epoch: 8/10. Loss: 1.1315:  58%|[36m█████▊    [0m| 15/26 [00:17<00:13,  1.23s/it]Epoch: 8/10. Loss: 1.0245:  58%|[36m█████▊    [0m| 15/26 [00:18<00:13,  1.23s/it]Epoch: 8/10. Loss: 1.0245:  62%|[36m██████▏   [0m| 16/26 [00:18<00:11,  1.12s/it]Epoch: 8/10. Loss: 0.9278:  62%|[36m██████▏   [0m| 16/26 [00:19<00:11,  1.12s/it]Epoch: 8/10. Loss: 0.9278:  65%|[36m██████▌   [0m| 17/26 [00:19<00:09,  1.04s/it]Epoch: 8/10. Loss: 0.9661:  65%|[36m██████▌   [0m| 17/26 [00:20<00:09,  1.04s/it]Epoch: 8/10. Loss: 0.9661:  69%|[36m██████▉   [0m| 18/26 [00:20<00:08,  1.05s/it]Epoch: 8/10. Loss: 1.0411:  69%|[36m██████▉   [0m| 18/26 [00:21<00:08,  1.05s/it]Epoch: 8/10. Loss: 1.0411:  73%|[36m███████▎  [0m| 19/26 [00:21<00:07,  1.03s/it]Epoch: 8/10. Loss: 0.9997:  73%|[36m███████▎  [0m| 19/26 [00:22<00:07,  1.03s/it]Epoch: 8/10. Loss: 0.9997:  77%|[36m███████▋  [0m| 20/26 [00:22<00:06,  1.01s/it]Epoch: 8/10. Loss: 0.9597:  77%|[36m███████▋  [0m| 20/26 [00:23<00:06,  1.01s/it]Epoch: 8/10. Loss: 0.9597:  81%|[36m████████  [0m| 21/26 [00:23<00:04,  1.01it/s]Epoch: 8/10. Loss: 1.0594:  81%|[36m████████  [0m| 21/26 [00:24<00:04,  1.01it/s]Epoch: 8/10. Loss: 1.0594:  85%|[36m████████▍ [0m| 22/26 [00:24<00:03,  1.05it/s]Epoch: 8/10. Loss: 0.9477:  85%|[36m████████▍ [0m| 22/26 [00:24<00:03,  1.05it/s]Epoch: 8/10. Loss: 0.9477:  88%|[36m████████▊ [0m| 23/26 [00:24<00:02,  1.10it/s]Epoch: 8/10. Loss: 1.0297:  88%|[36m████████▊ [0m| 23/26 [00:25<00:02,  1.10it/s]Epoch: 8/10. Loss: 1.0297:  92%|[36m█████████▏[0m| 24/26 [00:25<00:01,  1.04it/s]Epoch: 8/10. Loss: 1.0451:  92%|[36m█████████▏[0m| 24/26 [00:27<00:01,  1.04it/s]Epoch: 8/10. Loss: 1.0451:  96%|[36m█████████▌[0m| 25/26 [00:27<00:01,  1.05s/it]Epoch: 8/10. Loss: 0.9349:  96%|[36m█████████▌[0m| 25/26 [00:27<00:01,  1.05s/it]Epoch: 8/10. Loss: 0.9349: 100%|[36m██████████[0m| 26/26 [00:27<00:00,  1.05it/s]Epoch: 8/10. Loss: 0.9349: 100%|[36m██████████[0m| 26/26 [00:27<00:00,  1.07s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:05,  1.19it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:05,  1.15s/it] 43%|[33m████▎     [0m| 3/7 [00:02<00:03,  1.10it/s] 57%|[33m█████▋    [0m| 4/7 [00:03<00:03,  1.01s/it] 71%|[33m███████▏  [0m| 5/7 [00:04<00:01,  1.26it/s] 86%|[33m████████▌ [0m| 6/7 [00:05<00:00,  1.21it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.53it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.25it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 9/10. Loss: 1.0301:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 9/10. Loss: 1.0301:   4%|[36m▍         [0m| 1/26 [00:00<00:24,  1.04it/s]Epoch: 9/10. Loss: 1.0962:   4%|[36m▍         [0m| 1/26 [00:01<00:24,  1.04it/s]Epoch: 9/10. Loss: 1.0962:   8%|[36m▊         [0m| 2/26 [00:01<00:22,  1.06it/s]Epoch: 9/10. Loss: 1.0355:   8%|[36m▊         [0m| 2/26 [00:02<00:22,  1.06it/s]Epoch: 9/10. Loss: 1.0355:  12%|[36m█▏        [0m| 3/26 [00:02<00:22,  1.01it/s]Epoch: 9/10. Loss: 0.9308:  12%|[36m█▏        [0m| 3/26 [00:03<00:22,  1.01it/s]Epoch: 9/10. Loss: 0.9308:  15%|[36m█▌        [0m| 4/26 [00:03<00:21,  1.02it/s]Epoch: 9/10. Loss: 0.9405:  15%|[36m█▌        [0m| 4/26 [00:04<00:21,  1.02it/s]Epoch: 9/10. Loss: 0.9405:  19%|[36m█▉        [0m| 5/26 [00:04<00:19,  1.07it/s]Epoch: 9/10. Loss: 1.0132:  19%|[36m█▉        [0m| 5/26 [00:05<00:19,  1.07it/s]Epoch: 9/10. Loss: 1.0132:  23%|[36m██▎       [0m| 6/26 [00:05<00:18,  1.09it/s]Epoch: 9/10. Loss: 1.1484:  23%|[36m██▎       [0m| 6/26 [00:06<00:18,  1.09it/s]Epoch: 9/10. Loss: 1.1484:  27%|[36m██▋       [0m| 7/26 [00:06<00:17,  1.07it/s]Epoch: 9/10. Loss: 0.9228:  27%|[36m██▋       [0m| 7/26 [00:07<00:17,  1.07it/s]Epoch: 9/10. Loss: 0.9228:  31%|[36m███       [0m| 8/26 [00:07<00:16,  1.08it/s]Epoch: 9/10. Loss: 1.0074:  31%|[36m███       [0m| 8/26 [00:08<00:16,  1.08it/s]Epoch: 9/10. Loss: 1.0074:  35%|[36m███▍      [0m| 9/26 [00:08<00:16,  1.05it/s]Epoch: 9/10. Loss: 0.9730:  35%|[36m███▍      [0m| 9/26 [00:09<00:16,  1.05it/s]Epoch: 9/10. Loss: 0.9730:  38%|[36m███▊      [0m| 10/26 [00:09<00:16,  1.02s/it]Epoch: 9/10. Loss: 0.8708:  38%|[36m███▊      [0m| 10/26 [00:10<00:16,  1.02s/it]Epoch: 9/10. Loss: 0.8708:  42%|[36m████▏     [0m| 11/26 [00:10<00:15,  1.02s/it]Epoch: 9/10. Loss: 1.0686:  42%|[36m████▏     [0m| 11/26 [00:11<00:15,  1.02s/it]Epoch: 9/10. Loss: 1.0686:  46%|[36m████▌     [0m| 12/26 [00:11<00:14,  1.06s/it]Epoch: 9/10. Loss: 0.9691:  46%|[36m████▌     [0m| 12/26 [00:12<00:14,  1.06s/it]Epoch: 9/10. Loss: 0.9691:  50%|[36m█████     [0m| 13/26 [00:12<00:13,  1.05s/it]Epoch: 9/10. Loss: 1.0735:  50%|[36m█████     [0m| 13/26 [00:13<00:13,  1.05s/it]Epoch: 9/10. Loss: 1.0735:  54%|[36m█████▍    [0m| 14/26 [00:13<00:11,  1.01it/s]Epoch: 9/10. Loss: 0.9409:  54%|[36m█████▍    [0m| 14/26 [00:14<00:11,  1.01it/s]Epoch: 9/10. Loss: 0.9409:  58%|[36m█████▊    [0m| 15/26 [00:14<00:10,  1.00it/s]Epoch: 9/10. Loss: 1.0058:  58%|[36m█████▊    [0m| 15/26 [00:15<00:10,  1.00it/s]Epoch: 9/10. Loss: 1.0058:  62%|[36m██████▏   [0m| 16/26 [00:15<00:09,  1.06it/s]Epoch: 9/10. Loss: 1.1905:  62%|[36m██████▏   [0m| 16/26 [00:16<00:09,  1.06it/s]Epoch: 9/10. Loss: 1.1905:  65%|[36m██████▌   [0m| 17/26 [00:16<00:08,  1.06it/s]Epoch: 9/10. Loss: 1.0343:  65%|[36m██████▌   [0m| 17/26 [00:17<00:08,  1.06it/s]Epoch: 9/10. Loss: 1.0343:  69%|[36m██████▉   [0m| 18/26 [00:17<00:07,  1.06it/s]Epoch: 9/10. Loss: 0.9743:  69%|[36m██████▉   [0m| 18/26 [00:18<00:07,  1.06it/s]Epoch: 9/10. Loss: 0.9743:  73%|[36m███████▎  [0m| 19/26 [00:18<00:07,  1.11s/it]Epoch: 9/10. Loss: 0.9724:  73%|[36m███████▎  [0m| 19/26 [00:19<00:07,  1.11s/it]Epoch: 9/10. Loss: 0.9724:  77%|[36m███████▋  [0m| 20/26 [00:19<00:06,  1.05s/it]Epoch: 9/10. Loss: 0.9660:  77%|[36m███████▋  [0m| 20/26 [00:20<00:06,  1.05s/it]Epoch: 9/10. Loss: 0.9660:  81%|[36m████████  [0m| 21/26 [00:20<00:04,  1.01it/s]Epoch: 9/10. Loss: 0.9391:  81%|[36m████████  [0m| 21/26 [00:21<00:04,  1.01it/s]Epoch: 9/10. Loss: 0.9391:  85%|[36m████████▍ [0m| 22/26 [00:21<00:03,  1.01it/s]Epoch: 9/10. Loss: 1.2580:  85%|[36m████████▍ [0m| 22/26 [00:22<00:03,  1.01it/s]Epoch: 9/10. Loss: 1.2580:  88%|[36m████████▊ [0m| 23/26 [00:22<00:02,  1.01it/s]Epoch: 9/10. Loss: 0.9635:  88%|[36m████████▊ [0m| 23/26 [00:23<00:02,  1.01it/s]Epoch: 9/10. Loss: 0.9635:  92%|[36m█████████▏[0m| 24/26 [00:23<00:01,  1.04it/s]Epoch: 9/10. Loss: 0.9595:  92%|[36m█████████▏[0m| 24/26 [00:24<00:01,  1.04it/s]Epoch: 9/10. Loss: 0.9595:  96%|[36m█████████▌[0m| 25/26 [00:24<00:00,  1.04it/s]Epoch: 9/10. Loss: 1.0336:  96%|[36m█████████▌[0m| 25/26 [00:25<00:00,  1.04it/s]Epoch: 9/10. Loss: 1.0336: 100%|[36m██████████[0m| 26/26 [00:25<00:00,  1.18it/s]Epoch: 9/10. Loss: 1.0336: 100%|[36m██████████[0m| 26/26 [00:25<00:00,  1.03it/s]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:05,  1.04it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:06,  1.21s/it] 43%|[33m████▎     [0m| 3/7 [00:03<00:03,  1.04it/s] 57%|[33m█████▋    [0m| 4/7 [00:04<00:03,  1.05s/it] 71%|[33m███████▏  [0m| 5/7 [00:04<00:01,  1.20it/s] 86%|[33m████████▌ [0m| 6/7 [00:05<00:00,  1.17it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.48it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.20it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 0/10. Loss: 1.1741:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 0/10. Loss: 1.1741:   4%|[36m▍         [0m| 1/26 [00:00<00:21,  1.16it/s]Epoch: 0/10. Loss: 2.1333:   4%|[36m▍         [0m| 1/26 [00:01<00:21,  1.16it/s]Epoch: 0/10. Loss: 2.1333:   8%|[36m▊         [0m| 2/26 [00:01<00:21,  1.14it/s]Epoch: 0/10. Loss: 3.0748:   8%|[36m▊         [0m| 2/26 [00:02<00:21,  1.14it/s]Epoch: 0/10. Loss: 3.0748:  12%|[36m█▏        [0m| 3/26 [00:02<00:20,  1.11it/s]Epoch: 0/10. Loss: 4.2995:  12%|[36m█▏        [0m| 3/26 [00:03<00:20,  1.11it/s]Epoch: 0/10. Loss: 4.2995:  15%|[36m█▌        [0m| 4/26 [00:03<00:20,  1.06it/s]Epoch: 0/10. Loss: 2.6284:  15%|[36m█▌        [0m| 4/26 [00:04<00:20,  1.06it/s]Epoch: 0/10. Loss: 2.6284:  19%|[36m█▉        [0m| 5/26 [00:04<00:19,  1.05it/s]Epoch: 0/10. Loss: 1.7116:  19%|[36m█▉        [0m| 5/26 [00:05<00:19,  1.05it/s]Epoch: 0/10. Loss: 1.7116:  23%|[36m██▎       [0m| 6/26 [00:05<00:18,  1.08it/s]Epoch: 0/10. Loss: 1.1934:  23%|[36m██▎       [0m| 6/26 [00:06<00:18,  1.08it/s]Epoch: 0/10. Loss: 1.1934:  27%|[36m██▋       [0m| 7/26 [00:06<00:17,  1.10it/s]Epoch: 0/10. Loss: 1.2496:  27%|[36m██▋       [0m| 7/26 [00:07<00:17,  1.10it/s]Epoch: 0/10. Loss: 1.2496:  31%|[36m███       [0m| 8/26 [00:07<00:17,  1.06it/s]Epoch: 0/10. Loss: 1.4267:  31%|[36m███       [0m| 8/26 [00:08<00:17,  1.06it/s]Epoch: 0/10. Loss: 1.4267:  35%|[36m███▍      [0m| 9/26 [00:08<00:15,  1.07it/s]Epoch: 0/10. Loss: 1.5703:  35%|[36m███▍      [0m| 9/26 [00:09<00:15,  1.07it/s]Epoch: 0/10. Loss: 1.5703:  38%|[36m███▊      [0m| 10/26 [00:09<00:14,  1.08it/s]Epoch: 0/10. Loss: 1.3126:  38%|[36m███▊      [0m| 10/26 [00:10<00:14,  1.08it/s]Epoch: 0/10. Loss: 1.3126:  42%|[36m████▏     [0m| 11/26 [00:10<00:13,  1.11it/s]Epoch: 0/10. Loss: 1.2586:  42%|[36m████▏     [0m| 11/26 [00:11<00:13,  1.11it/s]Epoch: 0/10. Loss: 1.2586:  46%|[36m████▌     [0m| 12/26 [00:11<00:13,  1.05it/s]Epoch: 0/10. Loss: 1.0320:  46%|[36m████▌     [0m| 12/26 [00:12<00:13,  1.05it/s]Epoch: 0/10. Loss: 1.0320:  50%|[36m█████     [0m| 13/26 [00:12<00:12,  1.04it/s]Epoch: 0/10. Loss: 0.9872:  50%|[36m█████     [0m| 13/26 [00:13<00:12,  1.04it/s]Epoch: 0/10. Loss: 0.9872:  54%|[36m█████▍    [0m| 14/26 [00:13<00:11,  1.04it/s]Epoch: 0/10. Loss: 1.1961:  54%|[36m█████▍    [0m| 14/26 [00:14<00:11,  1.04it/s]Epoch: 0/10. Loss: 1.1961:  58%|[36m█████▊    [0m| 15/26 [00:14<00:10,  1.05it/s]Epoch: 0/10. Loss: 1.0439:  58%|[36m█████▊    [0m| 15/26 [00:14<00:10,  1.05it/s]Epoch: 0/10. Loss: 1.0439:  62%|[36m██████▏   [0m| 16/26 [00:14<00:09,  1.06it/s]Epoch: 0/10. Loss: 1.1979:  62%|[36m██████▏   [0m| 16/26 [00:15<00:09,  1.06it/s]Epoch: 0/10. Loss: 1.1979:  65%|[36m██████▌   [0m| 17/26 [00:15<00:08,  1.06it/s]Epoch: 0/10. Loss: 0.9959:  65%|[36m██████▌   [0m| 17/26 [00:16<00:08,  1.06it/s]Epoch: 0/10. Loss: 0.9959:  69%|[36m██████▉   [0m| 18/26 [00:16<00:07,  1.09it/s]Epoch: 0/10. Loss: 1.1721:  69%|[36m██████▉   [0m| 18/26 [00:17<00:07,  1.09it/s]Epoch: 0/10. Loss: 1.1721:  73%|[36m███████▎  [0m| 19/26 [00:17<00:06,  1.11it/s]Epoch: 0/10. Loss: 1.0469:  73%|[36m███████▎  [0m| 19/26 [00:19<00:06,  1.11it/s]Epoch: 0/10. Loss: 1.0469:  77%|[36m███████▋  [0m| 20/26 [00:19<00:07,  1.30s/it]Epoch: 0/10. Loss: 0.9986:  77%|[36m███████▋  [0m| 20/26 [00:20<00:07,  1.30s/it]Epoch: 0/10. Loss: 0.9986:  81%|[36m████████  [0m| 21/26 [00:20<00:05,  1.18s/it]Epoch: 0/10. Loss: 0.9539:  81%|[36m████████  [0m| 21/26 [00:23<00:05,  1.18s/it]Epoch: 0/10. Loss: 0.9539:  85%|[36m████████▍ [0m| 22/26 [00:23<00:06,  1.65s/it]Epoch: 0/10. Loss: 1.1037:  85%|[36m████████▍ [0m| 22/26 [00:25<00:06,  1.65s/it]Epoch: 0/10. Loss: 1.1037:  88%|[36m████████▊ [0m| 23/26 [00:25<00:04,  1.62s/it]Epoch: 0/10. Loss: 1.1493:  88%|[36m████████▊ [0m| 23/26 [00:26<00:04,  1.62s/it]Epoch: 0/10. Loss: 1.1493:  92%|[36m█████████▏[0m| 24/26 [00:26<00:02,  1.48s/it]Epoch: 0/10. Loss: 1.0698:  92%|[36m█████████▏[0m| 24/26 [00:27<00:02,  1.48s/it]Epoch: 0/10. Loss: 1.0698:  96%|[36m█████████▌[0m| 25/26 [00:27<00:01,  1.30s/it]Epoch: 0/10. Loss: 0.9609:  96%|[36m█████████▌[0m| 25/26 [00:27<00:01,  1.30s/it]Epoch: 0/10. Loss: 0.9609: 100%|[36m██████████[0m| 26/26 [00:27<00:00,  1.05s/it]Epoch: 0/10. Loss: 0.9609: 100%|[36m██████████[0m| 26/26 [00:27<00:00,  1.06s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:05,  1.19it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:06,  1.29s/it] 43%|[33m████▎     [0m| 3/7 [00:03<00:04,  1.02s/it] 57%|[33m█████▋    [0m| 4/7 [00:04<00:03,  1.10s/it] 71%|[33m███████▏  [0m| 5/7 [00:07<00:03,  1.95s/it] 86%|[33m████████▌ [0m| 6/7 [00:11<00:02,  2.52s/it]100%|[33m██████████[0m| 7/7 [00:11<00:00,  1.79s/it]100%|[33m██████████[0m| 7/7 [00:11<00:00,  1.68s/it]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 1/10. Loss: 0.9472:   0%|[36m          [0m| 0/26 [00:02<?, ?it/s]Epoch: 1/10. Loss: 0.9472:   4%|[36m▍         [0m| 1/26 [00:02<00:51,  2.08s/it]Epoch: 1/10. Loss: 1.0014:   4%|[36m▍         [0m| 1/26 [00:03<00:51,  2.08s/it]Epoch: 1/10. Loss: 1.0014:   8%|[36m▊         [0m| 2/26 [00:03<00:42,  1.76s/it]Epoch: 1/10. Loss: 0.9987:   8%|[36m▊         [0m| 2/26 [00:04<00:42,  1.76s/it]Epoch: 1/10. Loss: 0.9987:  12%|[36m█▏        [0m| 3/26 [00:04<00:30,  1.33s/it]Epoch: 1/10. Loss: 0.9756:  12%|[36m█▏        [0m| 3/26 [00:05<00:30,  1.33s/it]Epoch: 1/10. Loss: 0.9756:  15%|[36m█▌        [0m| 4/26 [00:05<00:24,  1.13s/it]Epoch: 1/10. Loss: 0.9642:  15%|[36m█▌        [0m| 4/26 [00:06<00:24,  1.13s/it]Epoch: 1/10. Loss: 0.9642:  19%|[36m█▉        [0m| 5/26 [00:06<00:21,  1.00s/it]Epoch: 1/10. Loss: 0.9779:  19%|[36m█▉        [0m| 5/26 [00:06<00:21,  1.00s/it]Epoch: 1/10. Loss: 0.9779:  23%|[36m██▎       [0m| 6/26 [00:06<00:19,  1.03it/s]Epoch: 1/10. Loss: 1.0506:  23%|[36m██▎       [0m| 6/26 [00:07<00:19,  1.03it/s]Epoch: 1/10. Loss: 1.0506:  27%|[36m██▋       [0m| 7/26 [00:07<00:18,  1.04it/s]Epoch: 1/10. Loss: 0.9426:  27%|[36m██▋       [0m| 7/26 [00:08<00:18,  1.04it/s]Epoch: 1/10. Loss: 0.9426:  31%|[36m███       [0m| 8/26 [00:08<00:17,  1.01it/s]Epoch: 1/10. Loss: 0.9552:  31%|[36m███       [0m| 8/26 [00:10<00:17,  1.01it/s]Epoch: 1/10. Loss: 0.9552:  35%|[36m███▍      [0m| 9/26 [00:10<00:19,  1.13s/it]Epoch: 1/10. Loss: 0.9609:  35%|[36m███▍      [0m| 9/26 [00:11<00:19,  1.13s/it]Epoch: 1/10. Loss: 0.9609:  38%|[36m███▊      [0m| 10/26 [00:11<00:17,  1.11s/it]Epoch: 1/10. Loss: 1.0688:  38%|[36m███▊      [0m| 10/26 [00:14<00:17,  1.11s/it]Epoch: 1/10. Loss: 1.0688:  42%|[36m████▏     [0m| 11/26 [00:14<00:26,  1.74s/it]Epoch: 1/10. Loss: 0.9185:  42%|[36m████▏     [0m| 11/26 [00:16<00:26,  1.74s/it]Epoch: 1/10. Loss: 0.9185:  46%|[36m████▌     [0m| 12/26 [00:16<00:23,  1.70s/it]Epoch: 1/10. Loss: 0.9986:  46%|[36m████▌     [0m| 12/26 [00:17<00:23,  1.70s/it]Epoch: 1/10. Loss: 0.9986:  50%|[36m█████     [0m| 13/26 [00:17<00:21,  1.65s/it]Epoch: 1/10. Loss: 1.0578:  50%|[36m█████     [0m| 13/26 [00:18<00:21,  1.65s/it]Epoch: 1/10. Loss: 1.0578:  54%|[36m█████▍    [0m| 14/26 [00:18<00:16,  1.38s/it]Epoch: 1/10. Loss: 1.0327:  54%|[36m█████▍    [0m| 14/26 [00:19<00:16,  1.38s/it]Epoch: 1/10. Loss: 1.0327:  58%|[36m█████▊    [0m| 15/26 [00:19<00:13,  1.22s/it]Epoch: 1/10. Loss: 1.0831:  58%|[36m█████▊    [0m| 15/26 [00:20<00:13,  1.22s/it]Epoch: 1/10. Loss: 1.0831:  62%|[36m██████▏   [0m| 16/26 [00:20<00:11,  1.13s/it]Epoch: 1/10. Loss: 0.9363:  62%|[36m██████▏   [0m| 16/26 [00:21<00:11,  1.13s/it]Epoch: 1/10. Loss: 0.9363:  65%|[36m██████▌   [0m| 17/26 [00:21<00:10,  1.11s/it]Epoch: 1/10. Loss: 0.9475:  65%|[36m██████▌   [0m| 17/26 [00:22<00:10,  1.11s/it]Epoch: 1/10. Loss: 0.9475:  69%|[36m██████▉   [0m| 18/26 [00:22<00:08,  1.04s/it]Epoch: 1/10. Loss: 0.9542:  69%|[36m██████▉   [0m| 18/26 [00:24<00:08,  1.04s/it]Epoch: 1/10. Loss: 0.9542:  73%|[36m███████▎  [0m| 19/26 [00:24<00:09,  1.36s/it]Epoch: 1/10. Loss: 0.9841:  73%|[36m███████▎  [0m| 19/26 [00:25<00:09,  1.36s/it]Epoch: 1/10. Loss: 0.9841:  77%|[36m███████▋  [0m| 20/26 [00:25<00:07,  1.23s/it]Epoch: 1/10. Loss: 0.9546:  77%|[36m███████▋  [0m| 20/26 [00:26<00:07,  1.23s/it]Epoch: 1/10. Loss: 0.9546:  81%|[36m████████  [0m| 21/26 [00:26<00:05,  1.14s/it]Epoch: 1/10. Loss: 1.0198:  81%|[36m████████  [0m| 21/26 [00:27<00:05,  1.14s/it]Epoch: 1/10. Loss: 1.0198:  85%|[36m████████▍ [0m| 22/26 [00:27<00:04,  1.12s/it]Epoch: 1/10. Loss: 0.8770:  85%|[36m████████▍ [0m| 22/26 [00:28<00:04,  1.12s/it]Epoch: 1/10. Loss: 0.8770:  88%|[36m████████▊ [0m| 23/26 [00:28<00:03,  1.12s/it]Epoch: 1/10. Loss: 0.9474:  88%|[36m████████▊ [0m| 23/26 [00:29<00:03,  1.12s/it]Epoch: 1/10. Loss: 0.9474:  92%|[36m█████████▏[0m| 24/26 [00:29<00:01,  1.00it/s]Epoch: 1/10. Loss: 0.9572:  92%|[36m█████████▏[0m| 24/26 [00:30<00:01,  1.00it/s]Epoch: 1/10. Loss: 0.9572:  96%|[36m█████████▌[0m| 25/26 [00:30<00:00,  1.00it/s]Epoch: 1/10. Loss: 0.9290:  96%|[36m█████████▌[0m| 25/26 [00:30<00:00,  1.00it/s]Epoch: 1/10. Loss: 0.9290: 100%|[36m██████████[0m| 26/26 [00:30<00:00,  1.17it/s]Epoch: 1/10. Loss: 0.9290: 100%|[36m██████████[0m| 26/26 [00:30<00:00,  1.18s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:04,  1.28it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:06,  1.32s/it] 43%|[33m████▎     [0m| 3/7 [00:03<00:04,  1.03s/it] 57%|[33m█████▋    [0m| 4/7 [00:04<00:03,  1.13s/it] 71%|[33m███████▏  [0m| 5/7 [00:04<00:01,  1.13it/s] 86%|[33m████████▌ [0m| 6/7 [00:05<00:00,  1.11it/s]100%|[33m██████████[0m| 7/7 [00:06<00:00,  1.41it/s]100%|[33m██████████[0m| 7/7 [00:06<00:00,  1.14it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 2/10. Loss: 0.9501:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 2/10. Loss: 0.9501:   4%|[36m▍         [0m| 1/26 [00:00<00:17,  1.41it/s]Epoch: 2/10. Loss: 0.8918:   4%|[36m▍         [0m| 1/26 [00:01<00:17,  1.41it/s]Epoch: 2/10. Loss: 0.8918:   8%|[36m▊         [0m| 2/26 [00:01<00:19,  1.23it/s]Epoch: 2/10. Loss: 1.1805:   8%|[36m▊         [0m| 2/26 [00:02<00:19,  1.23it/s]Epoch: 2/10. Loss: 1.1805:  12%|[36m█▏        [0m| 3/26 [00:02<00:18,  1.28it/s]Epoch: 2/10. Loss: 1.0082:  12%|[36m█▏        [0m| 3/26 [00:04<00:18,  1.28it/s]Epoch: 2/10. Loss: 1.0082:  15%|[36m█▌        [0m| 4/26 [00:04<00:33,  1.51s/it]Epoch: 2/10. Loss: 1.1002:  15%|[36m█▌        [0m| 4/26 [00:05<00:33,  1.51s/it]Epoch: 2/10. Loss: 1.1002:  19%|[36m█▉        [0m| 5/26 [00:05<00:27,  1.29s/it]Epoch: 2/10. Loss: 0.8921:  19%|[36m█▉        [0m| 5/26 [00:06<00:27,  1.29s/it]Epoch: 2/10. Loss: 0.8921:  23%|[36m██▎       [0m| 6/26 [00:06<00:24,  1.20s/it]Epoch: 2/10. Loss: 0.9037:  23%|[36m██▎       [0m| 6/26 [00:07<00:24,  1.20s/it]Epoch: 2/10. Loss: 0.9037:  27%|[36m██▋       [0m| 7/26 [00:07<00:20,  1.08s/it]Epoch: 2/10. Loss: 0.8475:  27%|[36m██▋       [0m| 7/26 [00:08<00:20,  1.08s/it]Epoch: 2/10. Loss: 0.8475:  31%|[36m███       [0m| 8/26 [00:08<00:17,  1.01it/s]Epoch: 2/10. Loss: 0.8851:  31%|[36m███       [0m| 8/26 [00:10<00:17,  1.01it/s]Epoch: 2/10. Loss: 0.8851:  35%|[36m███▍      [0m| 9/26 [00:10<00:20,  1.21s/it]Epoch: 2/10. Loss: 0.9239:  35%|[36m███▍      [0m| 9/26 [00:12<00:20,  1.21s/it]Epoch: 2/10. Loss: 0.9239:  38%|[36m███▊      [0m| 10/26 [00:12<00:25,  1.60s/it]Epoch: 2/10. Loss: 0.9237:  38%|[36m███▊      [0m| 10/26 [00:13<00:25,  1.60s/it]Epoch: 2/10. Loss: 0.9237:  42%|[36m████▏     [0m| 11/26 [00:13<00:22,  1.49s/it]Epoch: 2/10. Loss: 0.8944:  42%|[36m████▏     [0m| 11/26 [00:15<00:22,  1.49s/it]Epoch: 2/10. Loss: 0.8944:  46%|[36m████▌     [0m| 12/26 [00:15<00:22,  1.61s/it]Epoch: 2/10. Loss: 0.8139:  46%|[36m████▌     [0m| 12/26 [00:16<00:22,  1.61s/it]Epoch: 2/10. Loss: 0.8139:  50%|[36m█████     [0m| 13/26 [00:16<00:17,  1.37s/it]Epoch: 2/10. Loss: 0.9785:  50%|[36m█████     [0m| 13/26 [00:17<00:17,  1.37s/it]Epoch: 2/10. Loss: 0.9785:  54%|[36m█████▍    [0m| 14/26 [00:17<00:15,  1.32s/it]Epoch: 2/10. Loss: 1.0080:  54%|[36m█████▍    [0m| 14/26 [00:18<00:15,  1.32s/it]Epoch: 2/10. Loss: 1.0080:  58%|[36m█████▊    [0m| 15/26 [00:18<00:13,  1.24s/it]Epoch: 2/10. Loss: 0.7325:  58%|[36m█████▊    [0m| 15/26 [00:20<00:13,  1.24s/it]Epoch: 2/10. Loss: 0.7325:  62%|[36m██████▏   [0m| 16/26 [00:20<00:12,  1.23s/it]Epoch: 2/10. Loss: 0.8491:  62%|[36m██████▏   [0m| 16/26 [00:21<00:12,  1.23s/it]Epoch: 2/10. Loss: 0.8491:  65%|[36m██████▌   [0m| 17/26 [00:21<00:10,  1.15s/it]Epoch: 2/10. Loss: 0.8511:  65%|[36m██████▌   [0m| 17/26 [00:22<00:10,  1.15s/it]Epoch: 2/10. Loss: 0.8511:  69%|[36m██████▉   [0m| 18/26 [00:22<00:09,  1.13s/it]Epoch: 2/10. Loss: 0.9558:  69%|[36m██████▉   [0m| 18/26 [00:23<00:09,  1.13s/it]Epoch: 2/10. Loss: 0.9558:  73%|[36m███████▎  [0m| 19/26 [00:23<00:07,  1.11s/it]Epoch: 2/10. Loss: 0.8762:  73%|[36m███████▎  [0m| 19/26 [00:24<00:07,  1.11s/it]Epoch: 2/10. Loss: 0.8762:  77%|[36m███████▋  [0m| 20/26 [00:24<00:06,  1.05s/it]Epoch: 2/10. Loss: 0.9293:  77%|[36m███████▋  [0m| 20/26 [00:25<00:06,  1.05s/it]Epoch: 2/10. Loss: 0.9293:  81%|[36m████████  [0m| 21/26 [00:25<00:05,  1.01s/it]Epoch: 2/10. Loss: 1.0320:  81%|[36m████████  [0m| 21/26 [00:25<00:05,  1.01s/it]Epoch: 2/10. Loss: 1.0320:  85%|[36m████████▍ [0m| 22/26 [00:25<00:03,  1.05it/s]Epoch: 2/10. Loss: 0.9021:  85%|[36m████████▍ [0m| 22/26 [00:27<00:03,  1.05it/s]Epoch: 2/10. Loss: 0.9021:  88%|[36m████████▊ [0m| 23/26 [00:27<00:03,  1.10s/it]Epoch: 2/10. Loss: 0.8732:  88%|[36m████████▊ [0m| 23/26 [00:28<00:03,  1.10s/it]Epoch: 2/10. Loss: 0.8732:  92%|[36m█████████▏[0m| 24/26 [00:28<00:02,  1.02s/it]Epoch: 2/10. Loss: 0.9150:  92%|[36m█████████▏[0m| 24/26 [00:29<00:02,  1.02s/it]Epoch: 2/10. Loss: 0.9150:  96%|[36m█████████▌[0m| 25/26 [00:29<00:01,  1.01s/it]Epoch: 2/10. Loss: 0.8540:  96%|[36m█████████▌[0m| 25/26 [00:29<00:01,  1.01s/it]Epoch: 2/10. Loss: 0.8540: 100%|[36m██████████[0m| 26/26 [00:29<00:00,  1.09it/s]Epoch: 2/10. Loss: 0.8540: 100%|[36m██████████[0m| 26/26 [00:29<00:00,  1.15s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:04,  1.23it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:07,  1.41s/it] 43%|[33m████▎     [0m| 3/7 [00:03<00:04,  1.10s/it] 57%|[33m█████▋    [0m| 4/7 [00:04<00:03,  1.19s/it] 71%|[33m███████▏  [0m| 5/7 [00:05<00:01,  1.07it/s] 86%|[33m████████▌ [0m| 6/7 [00:06<00:00,  1.08it/s]100%|[33m██████████[0m| 7/7 [00:06<00:00,  1.36it/s]100%|[33m██████████[0m| 7/7 [00:06<00:00,  1.09it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 3/10. Loss: 0.7981:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 3/10. Loss: 0.7981:   4%|[36m▍         [0m| 1/26 [00:00<00:22,  1.11it/s]Epoch: 3/10. Loss: 0.9202:   4%|[36m▍         [0m| 1/26 [00:01<00:22,  1.11it/s]Epoch: 3/10. Loss: 0.9202:   8%|[36m▊         [0m| 2/26 [00:01<00:21,  1.12it/s]Epoch: 3/10. Loss: 0.8172:   8%|[36m▊         [0m| 2/26 [00:02<00:21,  1.12it/s]Epoch: 3/10. Loss: 0.8172:  12%|[36m█▏        [0m| 3/26 [00:02<00:20,  1.11it/s]Epoch: 3/10. Loss: 0.8297:  12%|[36m█▏        [0m| 3/26 [00:03<00:20,  1.11it/s]Epoch: 3/10. Loss: 0.8297:  15%|[36m█▌        [0m| 4/26 [00:03<00:19,  1.11it/s]Epoch: 3/10. Loss: 0.8411:  15%|[36m█▌        [0m| 4/26 [00:04<00:19,  1.11it/s]Epoch: 3/10. Loss: 0.8411:  19%|[36m█▉        [0m| 5/26 [00:04<00:17,  1.18it/s]Epoch: 3/10. Loss: 0.8992:  19%|[36m█▉        [0m| 5/26 [00:05<00:17,  1.18it/s]Epoch: 3/10. Loss: 0.8992:  23%|[36m██▎       [0m| 6/26 [00:05<00:18,  1.07it/s]Epoch: 3/10. Loss: 0.8659:  23%|[36m██▎       [0m| 6/26 [00:06<00:18,  1.07it/s]Epoch: 3/10. Loss: 0.8659:  27%|[36m██▋       [0m| 7/26 [00:06<00:16,  1.12it/s]Epoch: 3/10. Loss: 0.8765:  27%|[36m██▋       [0m| 7/26 [00:07<00:16,  1.12it/s]Epoch: 3/10. Loss: 0.8765:  31%|[36m███       [0m| 8/26 [00:07<00:15,  1.18it/s]Epoch: 3/10. Loss: 0.8974:  31%|[36m███       [0m| 8/26 [00:07<00:15,  1.18it/s]Epoch: 3/10. Loss: 0.8974:  35%|[36m███▍      [0m| 9/26 [00:07<00:14,  1.19it/s]Epoch: 3/10. Loss: 0.8864:  35%|[36m███▍      [0m| 9/26 [00:08<00:14,  1.19it/s]Epoch: 3/10. Loss: 0.8864:  38%|[36m███▊      [0m| 10/26 [00:08<00:14,  1.11it/s]Epoch: 3/10. Loss: 1.0201:  38%|[36m███▊      [0m| 10/26 [00:09<00:14,  1.11it/s]Epoch: 3/10. Loss: 1.0201:  42%|[36m████▏     [0m| 11/26 [00:09<00:13,  1.12it/s]Epoch: 3/10. Loss: 0.8071:  42%|[36m████▏     [0m| 11/26 [00:10<00:13,  1.12it/s]Epoch: 3/10. Loss: 0.8071:  46%|[36m████▌     [0m| 12/26 [00:10<00:13,  1.07it/s]Epoch: 3/10. Loss: 0.8892:  46%|[36m████▌     [0m| 12/26 [00:11<00:13,  1.07it/s]Epoch: 3/10. Loss: 0.8892:  50%|[36m█████     [0m| 13/26 [00:11<00:12,  1.04it/s]Epoch: 3/10. Loss: 0.8673:  50%|[36m█████     [0m| 13/26 [00:13<00:12,  1.04it/s]Epoch: 3/10. Loss: 0.8673:  54%|[36m█████▍    [0m| 14/26 [00:13<00:13,  1.14s/it]Epoch: 3/10. Loss: 0.9039:  54%|[36m█████▍    [0m| 14/26 [00:14<00:13,  1.14s/it]Epoch: 3/10. Loss: 0.9039:  58%|[36m█████▊    [0m| 15/26 [00:14<00:11,  1.09s/it]Epoch: 3/10. Loss: 1.0307:  58%|[36m█████▊    [0m| 15/26 [00:15<00:11,  1.09s/it]Epoch: 3/10. Loss: 1.0307:  62%|[36m██████▏   [0m| 16/26 [00:15<00:10,  1.01s/it]Epoch: 3/10. Loss: 0.7938:  62%|[36m██████▏   [0m| 16/26 [00:16<00:10,  1.01s/it]Epoch: 3/10. Loss: 0.7938:  65%|[36m██████▌   [0m| 17/26 [00:16<00:08,  1.01it/s]Epoch: 3/10. Loss: 0.9657:  65%|[36m██████▌   [0m| 17/26 [00:17<00:08,  1.01it/s]Epoch: 3/10. Loss: 0.9657:  69%|[36m██████▉   [0m| 18/26 [00:17<00:07,  1.03it/s]Epoch: 3/10. Loss: 0.8717:  69%|[36m██████▉   [0m| 18/26 [00:18<00:07,  1.03it/s]Epoch: 3/10. Loss: 0.8717:  73%|[36m███████▎  [0m| 19/26 [00:18<00:06,  1.00it/s]Epoch: 3/10. Loss: 0.9756:  73%|[36m███████▎  [0m| 19/26 [00:18<00:06,  1.00it/s]Epoch: 3/10. Loss: 0.9756:  77%|[36m███████▋  [0m| 20/26 [00:18<00:05,  1.07it/s]Epoch: 3/10. Loss: 0.8411:  77%|[36m███████▋  [0m| 20/26 [00:19<00:05,  1.07it/s]Epoch: 3/10. Loss: 0.8411:  81%|[36m████████  [0m| 21/26 [00:19<00:04,  1.10it/s]Epoch: 3/10. Loss: 0.8178:  81%|[36m████████  [0m| 21/26 [00:20<00:04,  1.10it/s]Epoch: 3/10. Loss: 0.8178:  85%|[36m████████▍ [0m| 22/26 [00:20<00:03,  1.09it/s]Epoch: 3/10. Loss: 0.8041:  85%|[36m████████▍ [0m| 22/26 [00:21<00:03,  1.09it/s]Epoch: 3/10. Loss: 0.8041:  88%|[36m████████▊ [0m| 23/26 [00:21<00:02,  1.10it/s]Epoch: 3/10. Loss: 0.8309:  88%|[36m████████▊ [0m| 23/26 [00:22<00:02,  1.10it/s]Epoch: 3/10. Loss: 0.8309:  92%|[36m█████████▏[0m| 24/26 [00:22<00:01,  1.08it/s]Epoch: 3/10. Loss: 0.7849:  92%|[36m█████████▏[0m| 24/26 [00:23<00:01,  1.08it/s]Epoch: 3/10. Loss: 0.7849:  96%|[36m█████████▌[0m| 25/26 [00:23<00:00,  1.04it/s]Epoch: 3/10. Loss: 0.9035:  96%|[36m█████████▌[0m| 25/26 [00:24<00:00,  1.04it/s]Epoch: 3/10. Loss: 0.9035: 100%|[36m██████████[0m| 26/26 [00:24<00:00,  1.14it/s]Epoch: 3/10. Loss: 0.9035: 100%|[36m██████████[0m| 26/26 [00:24<00:00,  1.07it/s]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:02<00:16,  2.71s/it] 29%|[33m██▊       [0m| 2/7 [00:04<00:12,  2.41s/it] 43%|[33m████▎     [0m| 3/7 [00:05<00:06,  1.60s/it] 57%|[33m█████▋    [0m| 4/7 [00:06<00:04,  1.43s/it] 71%|[33m███████▏  [0m| 5/7 [00:07<00:02,  1.05s/it] 86%|[33m████████▌ [0m| 6/7 [00:08<00:01,  1.16s/it]100%|[33m██████████[0m| 7/7 [00:08<00:00,  1.15it/s]100%|[33m██████████[0m| 7/7 [00:08<00:00,  1.25s/it]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 4/10. Loss: 0.6523:   0%|[36m          [0m| 0/26 [00:01<?, ?it/s]Epoch: 4/10. Loss: 0.6523:   4%|[36m▍         [0m| 1/26 [00:01<00:31,  1.25s/it]Epoch: 4/10. Loss: 0.8405:   4%|[36m▍         [0m| 1/26 [00:02<00:31,  1.25s/it]Epoch: 4/10. Loss: 0.8405:   8%|[36m▊         [0m| 2/26 [00:02<00:28,  1.20s/it]Epoch: 4/10. Loss: 0.8193:   8%|[36m▊         [0m| 2/26 [00:03<00:28,  1.20s/it]Epoch: 4/10. Loss: 0.8193:  12%|[36m█▏        [0m| 3/26 [00:03<00:24,  1.07s/it]Epoch: 4/10. Loss: 0.8487:  12%|[36m█▏        [0m| 3/26 [00:04<00:24,  1.07s/it]Epoch: 4/10. Loss: 0.8487:  15%|[36m█▌        [0m| 4/26 [00:04<00:25,  1.16s/it]Epoch: 4/10. Loss: 0.7672:  15%|[36m█▌        [0m| 4/26 [00:06<00:25,  1.16s/it]Epoch: 4/10. Loss: 0.7672:  19%|[36m█▉        [0m| 5/26 [00:06<00:29,  1.41s/it]Epoch: 4/10. Loss: 0.7606:  19%|[36m█▉        [0m| 5/26 [00:07<00:29,  1.41s/it]Epoch: 4/10. Loss: 0.7606:  23%|[36m██▎       [0m| 6/26 [00:07<00:24,  1.24s/it]Epoch: 4/10. Loss: 0.9416:  23%|[36m██▎       [0m| 6/26 [00:08<00:24,  1.24s/it]Epoch: 4/10. Loss: 0.9416:  27%|[36m██▋       [0m| 7/26 [00:08<00:21,  1.11s/it]Epoch: 4/10. Loss: 0.8849:  27%|[36m██▋       [0m| 7/26 [00:09<00:21,  1.11s/it]Epoch: 4/10. Loss: 0.8849:  31%|[36m███       [0m| 8/26 [00:09<00:18,  1.04s/it]Epoch: 4/10. Loss: 0.7949:  31%|[36m███       [0m| 8/26 [00:10<00:18,  1.04s/it]Epoch: 4/10. Loss: 0.7949:  35%|[36m███▍      [0m| 9/26 [00:10<00:17,  1.00s/it]Epoch: 4/10. Loss: 0.9438:  35%|[36m███▍      [0m| 9/26 [00:10<00:17,  1.00s/it]Epoch: 4/10. Loss: 0.9438:  38%|[36m███▊      [0m| 10/26 [00:11<00:15,  1.01it/s]Epoch: 4/10. Loss: 0.8999:  38%|[36m███▊      [0m| 10/26 [00:11<00:15,  1.01it/s]Epoch: 4/10. Loss: 0.8999:  42%|[36m████▏     [0m| 11/26 [00:11<00:14,  1.05it/s]Epoch: 4/10. Loss: 0.9880:  42%|[36m████▏     [0m| 11/26 [00:12<00:14,  1.05it/s]Epoch: 4/10. Loss: 0.9880:  46%|[36m████▌     [0m| 12/26 [00:12<00:12,  1.08it/s]Epoch: 4/10. Loss: 0.8820:  46%|[36m████▌     [0m| 12/26 [00:13<00:12,  1.08it/s]Epoch: 4/10. Loss: 0.8820:  50%|[36m█████     [0m| 13/26 [00:13<00:12,  1.08it/s]Epoch: 4/10. Loss: 0.8499:  50%|[36m█████     [0m| 13/26 [00:14<00:12,  1.08it/s]Epoch: 4/10. Loss: 0.8499:  54%|[36m█████▍    [0m| 14/26 [00:14<00:11,  1.07it/s]Epoch: 4/10. Loss: 0.8667:  54%|[36m█████▍    [0m| 14/26 [00:15<00:11,  1.07it/s]Epoch: 4/10. Loss: 0.8667:  58%|[36m█████▊    [0m| 15/26 [00:15<00:09,  1.15it/s]Epoch: 4/10. Loss: 0.8799:  58%|[36m█████▊    [0m| 15/26 [00:16<00:09,  1.15it/s]Epoch: 4/10. Loss: 0.8799:  62%|[36m██████▏   [0m| 16/26 [00:16<00:09,  1.00it/s]Epoch: 4/10. Loss: 0.8107:  62%|[36m██████▏   [0m| 16/26 [00:17<00:09,  1.00it/s]Epoch: 4/10. Loss: 0.8107:  65%|[36m██████▌   [0m| 17/26 [00:17<00:09,  1.02s/it]Epoch: 4/10. Loss: 0.8024:  65%|[36m██████▌   [0m| 17/26 [00:18<00:09,  1.02s/it]Epoch: 4/10. Loss: 0.8024:  69%|[36m██████▉   [0m| 18/26 [00:18<00:08,  1.00s/it]Epoch: 4/10. Loss: 1.0241:  69%|[36m██████▉   [0m| 18/26 [00:19<00:08,  1.00s/it]Epoch: 4/10. Loss: 1.0241:  73%|[36m███████▎  [0m| 19/26 [00:19<00:07,  1.09s/it]Epoch: 4/10. Loss: 0.8894:  73%|[36m███████▎  [0m| 19/26 [00:20<00:07,  1.09s/it]Epoch: 4/10. Loss: 0.8894:  77%|[36m███████▋  [0m| 20/26 [00:20<00:06,  1.01s/it]Epoch: 4/10. Loss: 1.0231:  77%|[36m███████▋  [0m| 20/26 [00:21<00:06,  1.01s/it]Epoch: 4/10. Loss: 1.0231:  81%|[36m████████  [0m| 21/26 [00:21<00:04,  1.06it/s]Epoch: 4/10. Loss: 0.7968:  81%|[36m████████  [0m| 21/26 [00:23<00:04,  1.06it/s]Epoch: 4/10. Loss: 0.7968:  85%|[36m████████▍ [0m| 22/26 [00:23<00:05,  1.26s/it]Epoch: 4/10. Loss: 0.8049:  85%|[36m████████▍ [0m| 22/26 [00:24<00:05,  1.26s/it]Epoch: 4/10. Loss: 0.8049:  88%|[36m████████▊ [0m| 23/26 [00:24<00:03,  1.11s/it]Epoch: 4/10. Loss: 0.7716:  88%|[36m████████▊ [0m| 23/26 [00:25<00:03,  1.11s/it]Epoch: 4/10. Loss: 0.7716:  92%|[36m█████████▏[0m| 24/26 [00:25<00:02,  1.09s/it]Epoch: 4/10. Loss: 1.0314:  92%|[36m█████████▏[0m| 24/26 [00:26<00:02,  1.09s/it]Epoch: 4/10. Loss: 1.0314:  96%|[36m█████████▌[0m| 25/26 [00:26<00:01,  1.10s/it]Epoch: 4/10. Loss: 0.8516:  96%|[36m█████████▌[0m| 25/26 [00:27<00:01,  1.10s/it]Epoch: 4/10. Loss: 0.8516: 100%|[36m██████████[0m| 26/26 [00:27<00:00,  1.04it/s]Epoch: 4/10. Loss: 0.8516: 100%|[36m██████████[0m| 26/26 [00:27<00:00,  1.04s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:04,  1.23it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:06,  1.27s/it] 43%|[33m████▎     [0m| 3/7 [00:03<00:03,  1.01it/s] 57%|[33m█████▋    [0m| 4/7 [00:04<00:03,  1.08s/it] 71%|[33m███████▏  [0m| 5/7 [00:05<00:02,  1.13s/it] 86%|[33m████████▌ [0m| 6/7 [00:06<00:01,  1.03s/it]100%|[33m██████████[0m| 7/7 [00:06<00:00,  1.27it/s]100%|[33m██████████[0m| 7/7 [00:06<00:00,  1.06it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 5/10. Loss: 0.8669:   0%|[36m          [0m| 0/26 [00:01<?, ?it/s]Epoch: 5/10. Loss: 0.8669:   4%|[36m▍         [0m| 1/26 [00:01<00:28,  1.12s/it]Epoch: 5/10. Loss: 0.9415:   4%|[36m▍         [0m| 1/26 [00:02<00:28,  1.12s/it]Epoch: 5/10. Loss: 0.9415:   8%|[36m▊         [0m| 2/26 [00:02<00:24,  1.03s/it]Epoch: 5/10. Loss: 0.8289:   8%|[36m▊         [0m| 2/26 [00:03<00:24,  1.03s/it]Epoch: 5/10. Loss: 0.8289:  12%|[36m█▏        [0m| 3/26 [00:03<00:23,  1.03s/it]Epoch: 5/10. Loss: 0.8001:  12%|[36m█▏        [0m| 3/26 [00:04<00:23,  1.03s/it]Epoch: 5/10. Loss: 0.8001:  15%|[36m█▌        [0m| 4/26 [00:04<00:22,  1.03s/it]Epoch: 5/10. Loss: 0.7019:  15%|[36m█▌        [0m| 4/26 [00:05<00:22,  1.03s/it]Epoch: 5/10. Loss: 0.7019:  19%|[36m█▉        [0m| 5/26 [00:05<00:21,  1.00s/it]Epoch: 5/10. Loss: 0.8680:  19%|[36m█▉        [0m| 5/26 [00:05<00:21,  1.00s/it]Epoch: 5/10. Loss: 0.8680:  23%|[36m██▎       [0m| 6/26 [00:05<00:18,  1.06it/s]Epoch: 5/10. Loss: 0.7177:  23%|[36m██▎       [0m| 6/26 [00:06<00:18,  1.06it/s]Epoch: 5/10. Loss: 0.7177:  27%|[36m██▋       [0m| 7/26 [00:06<00:17,  1.09it/s]Epoch: 5/10. Loss: 0.8178:  27%|[36m██▋       [0m| 7/26 [00:07<00:17,  1.09it/s]Epoch: 5/10. Loss: 0.8178:  31%|[36m███       [0m| 8/26 [00:07<00:16,  1.10it/s]Epoch: 5/10. Loss: 0.8086:  31%|[36m███       [0m| 8/26 [00:08<00:16,  1.10it/s]Epoch: 5/10. Loss: 0.8086:  35%|[36m███▍      [0m| 9/26 [00:08<00:14,  1.14it/s]Epoch: 5/10. Loss: 0.9064:  35%|[36m███▍      [0m| 9/26 [00:10<00:14,  1.14it/s]Epoch: 5/10. Loss: 0.9064:  38%|[36m███▊      [0m| 10/26 [00:10<00:21,  1.34s/it]Epoch: 5/10. Loss: 0.7901:  38%|[36m███▊      [0m| 10/26 [00:11<00:21,  1.34s/it]Epoch: 5/10. Loss: 0.7901:  42%|[36m████▏     [0m| 11/26 [00:11<00:18,  1.27s/it]Epoch: 5/10. Loss: 0.7061:  42%|[36m████▏     [0m| 11/26 [00:14<00:18,  1.27s/it]Epoch: 5/10. Loss: 0.7061:  46%|[36m████▌     [0m| 12/26 [00:14<00:21,  1.52s/it]Epoch: 5/10. Loss: 0.8043:  46%|[36m████▌     [0m| 12/26 [00:15<00:21,  1.52s/it]Epoch: 5/10. Loss: 0.8043:  50%|[36m█████     [0m| 13/26 [00:15<00:18,  1.46s/it]Epoch: 5/10. Loss: 0.9060:  50%|[36m█████     [0m| 13/26 [00:16<00:18,  1.46s/it]Epoch: 5/10. Loss: 0.9060:  54%|[36m█████▍    [0m| 14/26 [00:16<00:15,  1.30s/it]Epoch: 5/10. Loss: 0.7764:  54%|[36m█████▍    [0m| 14/26 [00:17<00:15,  1.30s/it]Epoch: 5/10. Loss: 0.7764:  58%|[36m█████▊    [0m| 15/26 [00:17<00:15,  1.38s/it]Epoch: 5/10. Loss: 0.8351:  58%|[36m█████▊    [0m| 15/26 [00:18<00:15,  1.38s/it]Epoch: 5/10. Loss: 0.8351:  62%|[36m██████▏   [0m| 16/26 [00:18<00:12,  1.21s/it]Epoch: 5/10. Loss: 0.8256:  62%|[36m██████▏   [0m| 16/26 [00:19<00:12,  1.21s/it]Epoch: 5/10. Loss: 0.8256:  65%|[36m██████▌   [0m| 17/26 [00:19<00:10,  1.15s/it]Epoch: 5/10. Loss: 0.6965:  65%|[36m██████▌   [0m| 17/26 [00:20<00:10,  1.15s/it]Epoch: 5/10. Loss: 0.6965:  69%|[36m██████▉   [0m| 18/26 [00:20<00:08,  1.06s/it]Epoch: 5/10. Loss: 0.6979:  69%|[36m██████▉   [0m| 18/26 [00:21<00:08,  1.06s/it]Epoch: 5/10. Loss: 0.6979:  73%|[36m███████▎  [0m| 19/26 [00:21<00:07,  1.14s/it]Epoch: 5/10. Loss: 0.8420:  73%|[36m███████▎  [0m| 19/26 [00:22<00:07,  1.14s/it]Epoch: 5/10. Loss: 0.8420:  77%|[36m███████▋  [0m| 20/26 [00:22<00:06,  1.07s/it]Epoch: 5/10. Loss: 0.6615:  77%|[36m███████▋  [0m| 20/26 [00:23<00:06,  1.07s/it]Epoch: 5/10. Loss: 0.6615:  81%|[36m████████  [0m| 21/26 [00:23<00:05,  1.02s/it]Epoch: 5/10. Loss: 0.8021:  81%|[36m████████  [0m| 21/26 [00:24<00:05,  1.02s/it]Epoch: 5/10. Loss: 0.8021:  85%|[36m████████▍ [0m| 22/26 [00:24<00:04,  1.00s/it]Epoch: 5/10. Loss: 0.8251:  85%|[36m████████▍ [0m| 22/26 [00:25<00:04,  1.00s/it]Epoch: 5/10. Loss: 0.8251:  88%|[36m████████▊ [0m| 23/26 [00:25<00:02,  1.05it/s]Epoch: 5/10. Loss: 0.7984:  88%|[36m████████▊ [0m| 23/26 [00:26<00:02,  1.05it/s]Epoch: 5/10. Loss: 0.7984:  92%|[36m█████████▏[0m| 24/26 [00:26<00:01,  1.11it/s]Epoch: 5/10. Loss: 0.6872:  92%|[36m█████████▏[0m| 24/26 [00:27<00:01,  1.11it/s]Epoch: 5/10. Loss: 0.6872:  96%|[36m█████████▌[0m| 25/26 [00:27<00:00,  1.07it/s]Epoch: 5/10. Loss: 0.7345:  96%|[36m█████████▌[0m| 25/26 [00:27<00:00,  1.07it/s]Epoch: 5/10. Loss: 0.7345: 100%|[36m██████████[0m| 26/26 [00:27<00:00,  1.20it/s]Epoch: 5/10. Loss: 0.7345: 100%|[36m██████████[0m| 26/26 [00:27<00:00,  1.07s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:04,  1.36it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:05,  1.08s/it] 43%|[33m████▎     [0m| 3/7 [00:02<00:03,  1.14it/s] 57%|[33m█████▋    [0m| 4/7 [00:03<00:03,  1.02s/it] 71%|[33m███████▏  [0m| 5/7 [00:04<00:01,  1.26it/s] 86%|[33m████████▌ [0m| 6/7 [00:05<00:00,  1.24it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.58it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.29it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 6/10. Loss: 0.6914:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 6/10. Loss: 0.6914:   4%|[36m▍         [0m| 1/26 [00:00<00:20,  1.19it/s]Epoch: 6/10. Loss: 0.6800:   4%|[36m▍         [0m| 1/26 [00:01<00:20,  1.19it/s]Epoch: 6/10. Loss: 0.6800:   8%|[36m▊         [0m| 2/26 [00:01<00:22,  1.07it/s]Epoch: 6/10. Loss: 0.7440:   8%|[36m▊         [0m| 2/26 [00:02<00:22,  1.07it/s]Epoch: 6/10. Loss: 0.7440:  12%|[36m█▏        [0m| 3/26 [00:02<00:23,  1.01s/it]Epoch: 6/10. Loss: 0.7452:  12%|[36m█▏        [0m| 3/26 [00:04<00:23,  1.01s/it]Epoch: 6/10. Loss: 0.7452:  15%|[36m█▌        [0m| 4/26 [00:04<00:25,  1.17s/it]Epoch: 6/10. Loss: 0.7147:  15%|[36m█▌        [0m| 4/26 [00:06<00:25,  1.17s/it]Epoch: 6/10. Loss: 0.7147:  19%|[36m█▉        [0m| 5/26 [00:06<00:31,  1.50s/it]Epoch: 6/10. Loss: 0.7935:  19%|[36m█▉        [0m| 5/26 [00:10<00:31,  1.50s/it]Epoch: 6/10. Loss: 0.7935:  23%|[36m██▎       [0m| 6/26 [00:10<00:45,  2.26s/it]Epoch: 6/10. Loss: 0.8787:  23%|[36m██▎       [0m| 6/26 [00:11<00:45,  2.26s/it]Epoch: 6/10. Loss: 0.8787:  27%|[36m██▋       [0m| 7/26 [00:11<00:37,  1.95s/it]Epoch: 6/10. Loss: 0.7816:  27%|[36m██▋       [0m| 7/26 [00:12<00:37,  1.95s/it]Epoch: 6/10. Loss: 0.7816:  31%|[36m███       [0m| 8/26 [00:12<00:28,  1.60s/it]Epoch: 6/10. Loss: 0.7940:  31%|[36m███       [0m| 8/26 [00:13<00:28,  1.60s/it]Epoch: 6/10. Loss: 0.7940:  35%|[36m███▍      [0m| 9/26 [00:13<00:24,  1.44s/it]Epoch: 6/10. Loss: 0.7542:  35%|[36m███▍      [0m| 9/26 [00:14<00:24,  1.44s/it]Epoch: 6/10. Loss: 0.7542:  38%|[36m███▊      [0m| 10/26 [00:14<00:20,  1.29s/it]Epoch: 6/10. Loss: 0.6991:  38%|[36m███▊      [0m| 10/26 [00:15<00:20,  1.29s/it]Epoch: 6/10. Loss: 0.6991:  42%|[36m████▏     [0m| 11/26 [00:15<00:17,  1.18s/it]Epoch: 6/10. Loss: 0.7928:  42%|[36m████▏     [0m| 11/26 [00:16<00:17,  1.18s/it]Epoch: 6/10. Loss: 0.7928:  46%|[36m████▌     [0m| 12/26 [00:16<00:16,  1.15s/it]Epoch: 6/10. Loss: 0.6940:  46%|[36m████▌     [0m| 12/26 [00:17<00:16,  1.15s/it]Epoch: 6/10. Loss: 0.6940:  50%|[36m█████     [0m| 13/26 [00:17<00:13,  1.06s/it]Epoch: 6/10. Loss: 0.7470:  50%|[36m█████     [0m| 13/26 [00:19<00:13,  1.06s/it]Epoch: 6/10. Loss: 0.7470:  54%|[36m█████▍    [0m| 14/26 [00:19<00:16,  1.37s/it]Epoch: 6/10. Loss: 0.7585:  54%|[36m█████▍    [0m| 14/26 [00:20<00:16,  1.37s/it]Epoch: 6/10. Loss: 0.7585:  58%|[36m█████▊    [0m| 15/26 [00:20<00:14,  1.28s/it]Epoch: 6/10. Loss: 0.7968:  58%|[36m█████▊    [0m| 15/26 [00:21<00:14,  1.28s/it]Epoch: 6/10. Loss: 0.7968:  62%|[36m██████▏   [0m| 16/26 [00:21<00:13,  1.37s/it]Epoch: 6/10. Loss: 0.7192:  62%|[36m██████▏   [0m| 16/26 [00:22<00:13,  1.37s/it]Epoch: 6/10. Loss: 0.7192:  65%|[36m██████▌   [0m| 17/26 [00:22<00:11,  1.25s/it]Epoch: 6/10. Loss: 0.6926:  65%|[36m██████▌   [0m| 17/26 [00:23<00:11,  1.25s/it]Epoch: 6/10. Loss: 0.6926:  69%|[36m██████▉   [0m| 18/26 [00:23<00:09,  1.14s/it]Epoch: 6/10. Loss: 0.7858:  69%|[36m██████▉   [0m| 18/26 [00:24<00:09,  1.14s/it]Epoch: 6/10. Loss: 0.7858:  73%|[36m███████▎  [0m| 19/26 [00:24<00:07,  1.10s/it]Epoch: 6/10. Loss: 0.7508:  73%|[36m███████▎  [0m| 19/26 [00:27<00:07,  1.10s/it]Epoch: 6/10. Loss: 0.7508:  77%|[36m███████▋  [0m| 20/26 [00:27<00:08,  1.47s/it]Epoch: 6/10. Loss: 0.7835:  77%|[36m███████▋  [0m| 20/26 [00:28<00:08,  1.47s/it]Epoch: 6/10. Loss: 0.7835:  81%|[36m████████  [0m| 21/26 [00:28<00:07,  1.41s/it]Epoch: 6/10. Loss: 0.6804:  81%|[36m████████  [0m| 21/26 [00:29<00:07,  1.41s/it]Epoch: 6/10. Loss: 0.6804:  85%|[36m████████▍ [0m| 22/26 [00:29<00:05,  1.26s/it]Epoch: 6/10. Loss: 0.8245:  85%|[36m████████▍ [0m| 22/26 [00:30<00:05,  1.26s/it]Epoch: 6/10. Loss: 0.8245:  88%|[36m████████▊ [0m| 23/26 [00:30<00:03,  1.15s/it]Epoch: 6/10. Loss: 0.7793:  88%|[36m████████▊ [0m| 23/26 [00:30<00:03,  1.15s/it]Epoch: 6/10. Loss: 0.7793:  92%|[36m█████████▏[0m| 24/26 [00:31<00:02,  1.03s/it]Epoch: 6/10. Loss: 0.8150:  92%|[36m█████████▏[0m| 24/26 [00:33<00:02,  1.03s/it]Epoch: 6/10. Loss: 0.8150:  96%|[36m█████████▌[0m| 25/26 [00:33<00:01,  1.36s/it]Epoch: 6/10. Loss: 0.8668:  96%|[36m█████████▌[0m| 25/26 [00:33<00:01,  1.36s/it]Epoch: 6/10. Loss: 0.8668: 100%|[36m██████████[0m| 26/26 [00:33<00:00,  1.13s/it]Epoch: 6/10. Loss: 0.8668: 100%|[36m██████████[0m| 26/26 [00:33<00:00,  1.30s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:04,  1.30it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:05,  1.14s/it] 43%|[33m████▎     [0m| 3/7 [00:02<00:03,  1.07it/s] 57%|[33m█████▋    [0m| 4/7 [00:04<00:03,  1.07s/it] 71%|[33m███████▏  [0m| 5/7 [00:04<00:01,  1.17it/s] 86%|[33m████████▌ [0m| 6/7 [00:05<00:00,  1.12it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.42it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.19it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 7/10. Loss: 0.7258:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 7/10. Loss: 0.7258:   4%|[36m▍         [0m| 1/26 [00:00<00:23,  1.08it/s]Epoch: 7/10. Loss: 0.6702:   4%|[36m▍         [0m| 1/26 [00:01<00:23,  1.08it/s]Epoch: 7/10. Loss: 0.6702:   8%|[36m▊         [0m| 2/26 [00:01<00:22,  1.06it/s]Epoch: 7/10. Loss: 0.6095:   8%|[36m▊         [0m| 2/26 [00:02<00:22,  1.06it/s]Epoch: 7/10. Loss: 0.6095:  12%|[36m█▏        [0m| 3/26 [00:02<00:20,  1.14it/s]Epoch: 7/10. Loss: 0.6423:  12%|[36m█▏        [0m| 3/26 [00:03<00:20,  1.14it/s]Epoch: 7/10. Loss: 0.6423:  15%|[36m█▌        [0m| 4/26 [00:03<00:18,  1.20it/s]Epoch: 7/10. Loss: 0.7414:  15%|[36m█▌        [0m| 4/26 [00:04<00:18,  1.20it/s]Epoch: 7/10. Loss: 0.7414:  19%|[36m█▉        [0m| 5/26 [00:04<00:20,  1.03it/s]Epoch: 7/10. Loss: 0.7506:  19%|[36m█▉        [0m| 5/26 [00:05<00:20,  1.03it/s]Epoch: 7/10. Loss: 0.7506:  23%|[36m██▎       [0m| 6/26 [00:05<00:20,  1.01s/it]Epoch: 7/10. Loss: 0.7256:  23%|[36m██▎       [0m| 6/26 [00:06<00:20,  1.01s/it]Epoch: 7/10. Loss: 0.7256:  27%|[36m██▋       [0m| 7/26 [00:06<00:18,  1.01it/s]Epoch: 7/10. Loss: 0.7253:  27%|[36m██▋       [0m| 7/26 [00:07<00:18,  1.01it/s]Epoch: 7/10. Loss: 0.7253:  31%|[36m███       [0m| 8/26 [00:07<00:17,  1.00it/s]Epoch: 7/10. Loss: 0.6266:  31%|[36m███       [0m| 8/26 [00:08<00:17,  1.00it/s]Epoch: 7/10. Loss: 0.6266:  35%|[36m███▍      [0m| 9/26 [00:08<00:15,  1.07it/s]Epoch: 7/10. Loss: 0.8522:  35%|[36m███▍      [0m| 9/26 [00:09<00:15,  1.07it/s]Epoch: 7/10. Loss: 0.8522:  38%|[36m███▊      [0m| 10/26 [00:09<00:16,  1.01s/it]Epoch: 7/10. Loss: 0.6873:  38%|[36m███▊      [0m| 10/26 [00:10<00:16,  1.01s/it]Epoch: 7/10. Loss: 0.6873:  42%|[36m████▏     [0m| 11/26 [00:10<00:14,  1.01it/s]Epoch: 7/10. Loss: 0.7291:  42%|[36m████▏     [0m| 11/26 [00:11<00:14,  1.01it/s]Epoch: 7/10. Loss: 0.7291:  46%|[36m████▌     [0m| 12/26 [00:11<00:12,  1.09it/s]Epoch: 7/10. Loss: 0.7303:  46%|[36m████▌     [0m| 12/26 [00:12<00:12,  1.09it/s]Epoch: 7/10. Loss: 0.7303:  50%|[36m█████     [0m| 13/26 [00:12<00:13,  1.05s/it]Epoch: 7/10. Loss: 0.6837:  50%|[36m█████     [0m| 13/26 [00:13<00:13,  1.05s/it]Epoch: 7/10. Loss: 0.6837:  54%|[36m█████▍    [0m| 14/26 [00:13<00:12,  1.01s/it]Epoch: 7/10. Loss: 0.8364:  54%|[36m█████▍    [0m| 14/26 [00:14<00:12,  1.01s/it]Epoch: 7/10. Loss: 0.8364:  58%|[36m█████▊    [0m| 15/26 [00:14<00:10,  1.03it/s]Epoch: 7/10. Loss: 0.5645:  58%|[36m█████▊    [0m| 15/26 [00:15<00:10,  1.03it/s]Epoch: 7/10. Loss: 0.5645:  62%|[36m██████▏   [0m| 16/26 [00:15<00:09,  1.08it/s]Epoch: 7/10. Loss: 0.8051:  62%|[36m██████▏   [0m| 16/26 [00:16<00:09,  1.08it/s]Epoch: 7/10. Loss: 0.8051:  65%|[36m██████▌   [0m| 17/26 [00:16<00:08,  1.07it/s]Epoch: 7/10. Loss: 0.6698:  65%|[36m██████▌   [0m| 17/26 [00:17<00:08,  1.07it/s]Epoch: 7/10. Loss: 0.6698:  69%|[36m██████▉   [0m| 18/26 [00:17<00:07,  1.11it/s]Epoch: 7/10. Loss: 0.6468:  69%|[36m██████▉   [0m| 18/26 [00:17<00:07,  1.11it/s]Epoch: 7/10. Loss: 0.6468:  73%|[36m███████▎  [0m| 19/26 [00:17<00:06,  1.13it/s]Epoch: 7/10. Loss: 0.8618:  73%|[36m███████▎  [0m| 19/26 [00:18<00:06,  1.13it/s]Epoch: 7/10. Loss: 0.8618:  77%|[36m███████▋  [0m| 20/26 [00:18<00:05,  1.16it/s]Epoch: 7/10. Loss: 0.7015:  77%|[36m███████▋  [0m| 20/26 [00:19<00:05,  1.16it/s]Epoch: 7/10. Loss: 0.7015:  81%|[36m████████  [0m| 21/26 [00:19<00:04,  1.11it/s]Epoch: 7/10. Loss: 0.6782:  81%|[36m████████  [0m| 21/26 [00:20<00:04,  1.11it/s]Epoch: 7/10. Loss: 0.6782:  85%|[36m████████▍ [0m| 22/26 [00:20<00:03,  1.08it/s]Epoch: 7/10. Loss: 0.7088:  85%|[36m████████▍ [0m| 22/26 [00:21<00:03,  1.08it/s]Epoch: 7/10. Loss: 0.7088:  88%|[36m████████▊ [0m| 23/26 [00:21<00:02,  1.06it/s]Epoch: 7/10. Loss: 0.7095:  88%|[36m████████▊ [0m| 23/26 [00:22<00:02,  1.06it/s]Epoch: 7/10. Loss: 0.7095:  92%|[36m█████████▏[0m| 24/26 [00:22<00:01,  1.04it/s]Epoch: 7/10. Loss: 0.6551:  92%|[36m█████████▏[0m| 24/26 [00:23<00:01,  1.04it/s]Epoch: 7/10. Loss: 0.6551:  96%|[36m█████████▌[0m| 25/26 [00:23<00:00,  1.05it/s]Epoch: 7/10. Loss: 0.6490:  96%|[36m█████████▌[0m| 25/26 [00:24<00:00,  1.05it/s]Epoch: 7/10. Loss: 0.6490: 100%|[36m██████████[0m| 26/26 [00:24<00:00,  1.20it/s]Epoch: 7/10. Loss: 0.6490: 100%|[36m██████████[0m| 26/26 [00:24<00:00,  1.07it/s]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:04,  1.23it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:05,  1.14s/it] 43%|[33m████▎     [0m| 3/7 [00:02<00:03,  1.06it/s] 57%|[33m█████▋    [0m| 4/7 [00:04<00:03,  1.07s/it] 71%|[33m███████▏  [0m| 5/7 [00:04<00:01,  1.18it/s] 86%|[33m████████▌ [0m| 6/7 [00:05<00:00,  1.16it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.47it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.21it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 8/10. Loss: 0.6963:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 8/10. Loss: 0.6963:   4%|[36m▍         [0m| 1/26 [00:00<00:21,  1.14it/s]Epoch: 8/10. Loss: 0.7540:   4%|[36m▍         [0m| 1/26 [00:01<00:21,  1.14it/s]Epoch: 8/10. Loss: 0.7540:   8%|[36m▊         [0m| 2/26 [00:01<00:21,  1.10it/s]Epoch: 8/10. Loss: 0.6596:   8%|[36m▊         [0m| 2/26 [00:02<00:21,  1.10it/s]Epoch: 8/10. Loss: 0.6596:  12%|[36m█▏        [0m| 3/26 [00:02<00:20,  1.12it/s]Epoch: 8/10. Loss: 0.6415:  12%|[36m█▏        [0m| 3/26 [00:03<00:20,  1.12it/s]Epoch: 8/10. Loss: 0.6415:  15%|[36m█▌        [0m| 4/26 [00:03<00:18,  1.17it/s]Epoch: 8/10. Loss: 0.7120:  15%|[36m█▌        [0m| 4/26 [00:04<00:18,  1.17it/s]Epoch: 8/10. Loss: 0.7120:  19%|[36m█▉        [0m| 5/26 [00:04<00:17,  1.20it/s]Epoch: 8/10. Loss: 0.7473:  19%|[36m█▉        [0m| 5/26 [00:05<00:17,  1.20it/s]Epoch: 8/10. Loss: 0.7473:  23%|[36m██▎       [0m| 6/26 [00:05<00:18,  1.08it/s]Epoch: 8/10. Loss: 0.8506:  23%|[36m██▎       [0m| 6/26 [00:06<00:18,  1.08it/s]Epoch: 8/10. Loss: 0.8506:  27%|[36m██▋       [0m| 7/26 [00:06<00:16,  1.12it/s]Epoch: 8/10. Loss: 0.8156:  27%|[36m██▋       [0m| 7/26 [00:06<00:16,  1.12it/s]Epoch: 8/10. Loss: 0.8156:  31%|[36m███       [0m| 8/26 [00:07<00:15,  1.16it/s]Epoch: 8/10. Loss: 0.6608:  31%|[36m███       [0m| 8/26 [00:07<00:15,  1.16it/s]Epoch: 8/10. Loss: 0.6608:  35%|[36m███▍      [0m| 9/26 [00:07<00:14,  1.21it/s]Epoch: 8/10. Loss: 0.6940:  35%|[36m███▍      [0m| 9/26 [00:08<00:14,  1.21it/s]Epoch: 8/10. Loss: 0.6940:  38%|[36m███▊      [0m| 10/26 [00:08<00:14,  1.12it/s]Epoch: 8/10. Loss: 0.7334:  38%|[36m███▊      [0m| 10/26 [00:09<00:14,  1.12it/s]Epoch: 8/10. Loss: 0.7334:  42%|[36m████▏     [0m| 11/26 [00:09<00:13,  1.08it/s]Epoch: 8/10. Loss: 0.7307:  42%|[36m████▏     [0m| 11/26 [00:10<00:13,  1.08it/s]Epoch: 8/10. Loss: 0.7307:  46%|[36m████▌     [0m| 12/26 [00:10<00:13,  1.06it/s]Epoch: 8/10. Loss: 0.7137:  46%|[36m████▌     [0m| 12/26 [00:12<00:13,  1.06it/s]Epoch: 8/10. Loss: 0.7137:  50%|[36m█████     [0m| 13/26 [00:12<00:15,  1.17s/it]Epoch: 8/10. Loss: 0.6693:  50%|[36m█████     [0m| 13/26 [00:13<00:15,  1.17s/it]Epoch: 8/10. Loss: 0.6693:  54%|[36m█████▍    [0m| 14/26 [00:13<00:12,  1.07s/it]Epoch: 8/10. Loss: 0.6551:  54%|[36m█████▍    [0m| 14/26 [00:14<00:12,  1.07s/it]Epoch: 8/10. Loss: 0.6551:  58%|[36m█████▊    [0m| 15/26 [00:14<00:11,  1.01s/it]Epoch: 8/10. Loss: 0.6721:  58%|[36m█████▊    [0m| 15/26 [00:15<00:11,  1.01s/it]Epoch: 8/10. Loss: 0.6721:  62%|[36m██████▏   [0m| 16/26 [00:15<00:10,  1.02s/it]Epoch: 8/10. Loss: 0.7371:  62%|[36m██████▏   [0m| 16/26 [00:16<00:10,  1.02s/it]Epoch: 8/10. Loss: 0.7371:  65%|[36m██████▌   [0m| 17/26 [00:16<00:08,  1.03it/s]Epoch: 8/10. Loss: 0.7624:  65%|[36m██████▌   [0m| 17/26 [00:16<00:08,  1.03it/s]Epoch: 8/10. Loss: 0.7624:  69%|[36m██████▉   [0m| 18/26 [00:16<00:07,  1.11it/s]Epoch: 8/10. Loss: 0.4979:  69%|[36m██████▉   [0m| 18/26 [00:17<00:07,  1.11it/s]Epoch: 8/10. Loss: 0.4979:  73%|[36m███████▎  [0m| 19/26 [00:17<00:06,  1.15it/s]Epoch: 8/10. Loss: 0.7261:  73%|[36m███████▎  [0m| 19/26 [00:18<00:06,  1.15it/s]Epoch: 8/10. Loss: 0.7261:  77%|[36m███████▋  [0m| 20/26 [00:18<00:05,  1.17it/s]Epoch: 8/10. Loss: 0.7682:  77%|[36m███████▋  [0m| 20/26 [00:19<00:05,  1.17it/s]Epoch: 8/10. Loss: 0.7682:  81%|[36m████████  [0m| 21/26 [00:19<00:04,  1.17it/s]Epoch: 8/10. Loss: 0.8797:  81%|[36m████████  [0m| 21/26 [00:20<00:04,  1.17it/s]Epoch: 8/10. Loss: 0.8797:  85%|[36m████████▍ [0m| 22/26 [00:20<00:03,  1.08it/s]Epoch: 8/10. Loss: 0.7132:  85%|[36m████████▍ [0m| 22/26 [00:21<00:03,  1.08it/s]Epoch: 8/10. Loss: 0.7132:  88%|[36m████████▊ [0m| 23/26 [00:21<00:02,  1.08it/s]Epoch: 8/10. Loss: 0.7995:  88%|[36m████████▊ [0m| 23/26 [00:22<00:02,  1.08it/s]Epoch: 8/10. Loss: 0.7995:  92%|[36m█████████▏[0m| 24/26 [00:22<00:01,  1.08it/s]Epoch: 8/10. Loss: 0.6128:  92%|[36m█████████▏[0m| 24/26 [00:23<00:01,  1.08it/s]Epoch: 8/10. Loss: 0.6128:  96%|[36m█████████▌[0m| 25/26 [00:23<00:00,  1.03it/s]Epoch: 8/10. Loss: 0.9243:  96%|[36m█████████▌[0m| 25/26 [00:23<00:00,  1.03it/s]Epoch: 8/10. Loss: 0.9243: 100%|[36m██████████[0m| 26/26 [00:23<00:00,  1.16it/s]Epoch: 8/10. Loss: 0.9243: 100%|[36m██████████[0m| 26/26 [00:23<00:00,  1.09it/s]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:04,  1.23it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:05,  1.15s/it] 43%|[33m████▎     [0m| 3/7 [00:02<00:03,  1.07it/s] 57%|[33m█████▋    [0m| 4/7 [00:04<00:03,  1.07s/it] 71%|[33m███████▏  [0m| 5/7 [00:05<00:02,  1.25s/it] 86%|[33m████████▌ [0m| 6/7 [00:06<00:01,  1.13s/it]100%|[33m██████████[0m| 7/7 [00:06<00:00,  1.17it/s]100%|[33m██████████[0m| 7/7 [00:06<00:00,  1.01it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 9/10. Loss: 0.6075:   0%|[36m          [0m| 0/26 [00:03<?, ?it/s]Epoch: 9/10. Loss: 0.6075:   4%|[36m▍         [0m| 1/26 [00:03<01:18,  3.12s/it]Epoch: 9/10. Loss: 0.7535:   4%|[36m▍         [0m| 1/26 [00:04<01:18,  3.12s/it]Epoch: 9/10. Loss: 0.7535:   8%|[36m▊         [0m| 2/26 [00:04<00:47,  1.98s/it]Epoch: 9/10. Loss: 0.7082:   8%|[36m▊         [0m| 2/26 [00:06<00:47,  1.98s/it]Epoch: 9/10. Loss: 0.7082:  12%|[36m█▏        [0m| 3/26 [00:06<00:49,  2.14s/it]Epoch: 9/10. Loss: 0.6745:  12%|[36m█▏        [0m| 3/26 [00:07<00:49,  2.14s/it]Epoch: 9/10. Loss: 0.6745:  15%|[36m█▌        [0m| 4/26 [00:07<00:36,  1.67s/it]Epoch: 9/10. Loss: 0.7563:  15%|[36m█▌        [0m| 4/26 [00:08<00:36,  1.67s/it]Epoch: 9/10. Loss: 0.7563:  19%|[36m█▉        [0m| 5/26 [00:08<00:28,  1.36s/it]Epoch: 9/10. Loss: 0.6887:  19%|[36m█▉        [0m| 5/26 [00:09<00:28,  1.36s/it]Epoch: 9/10. Loss: 0.6887:  23%|[36m██▎       [0m| 6/26 [00:09<00:22,  1.14s/it]Epoch: 9/10. Loss: 0.7184:  23%|[36m██▎       [0m| 6/26 [00:11<00:22,  1.14s/it]Epoch: 9/10. Loss: 0.7184:  27%|[36m██▋       [0m| 7/26 [00:11<00:26,  1.39s/it]Epoch: 9/10. Loss: 0.6942:  27%|[36m██▋       [0m| 7/26 [00:11<00:26,  1.39s/it]Epoch: 9/10. Loss: 0.6942:  31%|[36m███       [0m| 8/26 [00:11<00:21,  1.22s/it]Epoch: 9/10. Loss: 0.6718:  31%|[36m███       [0m| 8/26 [00:12<00:21,  1.22s/it]Epoch: 9/10. Loss: 0.6718:  35%|[36m███▍      [0m| 9/26 [00:12<00:19,  1.13s/it]Epoch: 9/10. Loss: 0.7463:  35%|[36m███▍      [0m| 9/26 [00:15<00:19,  1.13s/it]Epoch: 9/10. Loss: 0.7463:  38%|[36m███▊      [0m| 10/26 [00:15<00:24,  1.54s/it]Epoch: 9/10. Loss: 0.6149:  38%|[36m███▊      [0m| 10/26 [00:16<00:24,  1.54s/it]Epoch: 9/10. Loss: 0.6149:  42%|[36m████▏     [0m| 11/26 [00:16<00:20,  1.40s/it]Epoch: 9/10. Loss: 0.6578:  42%|[36m████▏     [0m| 11/26 [00:17<00:20,  1.40s/it]Epoch: 9/10. Loss: 0.6578:  46%|[36m████▌     [0m| 12/26 [00:17<00:17,  1.25s/it]Epoch: 9/10. Loss: 0.7162:  46%|[36m████▌     [0m| 12/26 [00:18<00:17,  1.25s/it]Epoch: 9/10. Loss: 0.7162:  50%|[36m█████     [0m| 13/26 [00:18<00:14,  1.11s/it]Epoch: 9/10. Loss: 0.6675:  50%|[36m█████     [0m| 13/26 [00:18<00:14,  1.11s/it]Epoch: 9/10. Loss: 0.6675:  54%|[36m█████▍    [0m| 14/26 [00:18<00:12,  1.03s/it]Epoch: 9/10. Loss: 0.6055:  54%|[36m█████▍    [0m| 14/26 [00:19<00:12,  1.03s/it]Epoch: 9/10. Loss: 0.6055:  58%|[36m█████▊    [0m| 15/26 [00:19<00:11,  1.04s/it]Epoch: 9/10. Loss: 0.7099:  58%|[36m█████▊    [0m| 15/26 [00:20<00:11,  1.04s/it]Epoch: 9/10. Loss: 0.7099:  62%|[36m██████▏   [0m| 16/26 [00:20<00:09,  1.00it/s]Epoch: 9/10. Loss: 0.6643:  62%|[36m██████▏   [0m| 16/26 [00:23<00:09,  1.00it/s]Epoch: 9/10. Loss: 0.6643:  65%|[36m██████▌   [0m| 17/26 [00:23<00:14,  1.62s/it]Epoch: 9/10. Loss: 0.6256:  65%|[36m██████▌   [0m| 17/26 [00:26<00:14,  1.62s/it]Epoch: 9/10. Loss: 0.6256:  69%|[36m██████▉   [0m| 18/26 [00:26<00:15,  1.97s/it]Epoch: 9/10. Loss: 0.7562:  69%|[36m██████▉   [0m| 18/26 [00:27<00:15,  1.97s/it]Epoch: 9/10. Loss: 0.7562:  73%|[36m███████▎  [0m| 19/26 [00:27<00:11,  1.63s/it]Epoch: 9/10. Loss: 0.8563:  73%|[36m███████▎  [0m| 19/26 [00:28<00:11,  1.63s/it]Epoch: 9/10. Loss: 0.8563:  77%|[36m███████▋  [0m| 20/26 [00:28<00:08,  1.34s/it]Epoch: 9/10. Loss: 0.8196:  77%|[36m███████▋  [0m| 20/26 [00:29<00:08,  1.34s/it]Epoch: 9/10. Loss: 0.8196:  81%|[36m████████  [0m| 21/26 [00:29<00:05,  1.20s/it]Epoch: 9/10. Loss: 0.7502:  81%|[36m████████  [0m| 21/26 [00:29<00:05,  1.20s/it]Epoch: 9/10. Loss: 0.7502:  85%|[36m████████▍ [0m| 22/26 [00:29<00:04,  1.12s/it]Epoch: 9/10. Loss: 0.7439:  85%|[36m████████▍ [0m| 22/26 [00:31<00:04,  1.12s/it]Epoch: 9/10. Loss: 0.7439:  88%|[36m████████▊ [0m| 23/26 [00:31<00:03,  1.22s/it]Epoch: 9/10. Loss: 0.7517:  88%|[36m████████▊ [0m| 23/26 [00:32<00:03,  1.22s/it]Epoch: 9/10. Loss: 0.7517:  92%|[36m█████████▏[0m| 24/26 [00:32<00:02,  1.16s/it]Epoch: 9/10. Loss: 0.7275:  92%|[36m█████████▏[0m| 24/26 [00:33<00:02,  1.16s/it]Epoch: 9/10. Loss: 0.7275:  96%|[36m█████████▌[0m| 25/26 [00:33<00:01,  1.05s/it]Epoch: 9/10. Loss: 0.8052:  96%|[36m█████████▌[0m| 25/26 [00:33<00:01,  1.05s/it]Epoch: 9/10. Loss: 0.8052: 100%|[36m██████████[0m| 26/26 [00:33<00:00,  1.08it/s]Epoch: 9/10. Loss: 0.8052: 100%|[36m██████████[0m| 26/26 [00:33<00:00,  1.30s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:01<00:09,  1.60s/it] 29%|[33m██▊       [0m| 2/7 [00:02<00:07,  1.48s/it] 43%|[33m████▎     [0m| 3/7 [00:03<00:04,  1.12s/it] 57%|[33m█████▋    [0m| 4/7 [00:05<00:03,  1.23s/it] 71%|[33m███████▏  [0m| 5/7 [00:05<00:01,  1.05it/s] 86%|[33m████████▌ [0m| 6/7 [00:06<00:00,  1.06it/s]100%|[33m██████████[0m| 7/7 [00:06<00:00,  1.36it/s]100%|[33m██████████[0m| 7/7 [00:06<00:00,  1.03it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 0/10. Loss: 1.0977:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 0/10. Loss: 1.0977:   4%|[36m▍         [0m| 1/26 [00:00<00:19,  1.25it/s]Epoch: 0/10. Loss: 1324826.8750:   4%|[36m▍         [0m| 1/26 [00:01<00:19,  1.25it/s]Epoch: 0/10. Loss: 1324826.8750:   8%|[36m▊         [0m| 2/26 [00:01<00:18,  1.32it/s]Epoch: 0/10. Loss: 1076.7483:   8%|[36m▊         [0m| 2/26 [00:02<00:18,  1.32it/s]   Epoch: 0/10. Loss: 1076.7483:  12%|[36m█▏        [0m| 3/26 [00:02<00:17,  1.34it/s]Epoch: 0/10. Loss: 43804.5859:  12%|[36m█▏        [0m| 3/26 [00:03<00:17,  1.34it/s]Epoch: 0/10. Loss: 43804.5859:  15%|[36m█▌        [0m| 4/26 [00:03<00:19,  1.12it/s]Epoch: 0/10. Loss: 8207.3184:  15%|[36m█▌        [0m| 4/26 [00:04<00:19,  1.12it/s] Epoch: 0/10. Loss: 8207.3184:  19%|[36m█▉        [0m| 5/26 [00:04<00:19,  1.09it/s]Epoch: 0/10. Loss: 190298.6875:  19%|[36m█▉        [0m| 5/26 [00:05<00:19,  1.09it/s]Epoch: 0/10. Loss: 190298.6875:  23%|[36m██▎       [0m| 6/26 [00:05<00:17,  1.14it/s]Epoch: 0/10. Loss: 3781.5806:  23%|[36m██▎       [0m| 6/26 [00:06<00:17,  1.14it/s]  Epoch: 0/10. Loss: 3781.5806:  27%|[36m██▋       [0m| 7/26 [00:06<00:16,  1.14it/s]Epoch: 0/10. Loss: 178.7138:  27%|[36m██▋       [0m| 7/26 [00:06<00:16,  1.14it/s] Epoch: 0/10. Loss: 178.7138:  31%|[36m███       [0m| 8/26 [00:06<00:16,  1.10it/s]Epoch: 0/10. Loss: 137.4813:  31%|[36m███       [0m| 8/26 [00:07<00:16,  1.10it/s]Epoch: 0/10. Loss: 137.4813:  35%|[36m███▍      [0m| 9/26 [00:07<00:14,  1.16it/s]Epoch: 0/10. Loss: 49.5383:  35%|[36m███▍      [0m| 9/26 [00:08<00:14,  1.16it/s] Epoch: 0/10. Loss: 49.5383:  38%|[36m███▊      [0m| 10/26 [00:08<00:14,  1.14it/s]Epoch: 0/10. Loss: 303.2295:  38%|[36m███▊      [0m| 10/26 [00:09<00:14,  1.14it/s]Epoch: 0/10. Loss: 303.2295:  42%|[36m████▏     [0m| 11/26 [00:09<00:13,  1.12it/s]Epoch: 0/10. Loss: 2789.6680:  42%|[36m████▏     [0m| 11/26 [00:10<00:13,  1.12it/s]Epoch: 0/10. Loss: 2789.6680:  46%|[36m████▌     [0m| 12/26 [00:10<00:12,  1.14it/s]Epoch: 0/10. Loss: 5.1088:  46%|[36m████▌     [0m| 12/26 [00:11<00:12,  1.14it/s]   Epoch: 0/10. Loss: 5.1088:  50%|[36m█████     [0m| 13/26 [00:11<00:12,  1.07it/s]Epoch: 0/10. Loss: 9.0122:  50%|[36m█████     [0m| 13/26 [00:12<00:12,  1.07it/s]Epoch: 0/10. Loss: 9.0122:  54%|[36m█████▍    [0m| 14/26 [00:12<00:10,  1.10it/s]Epoch: 0/10. Loss: 13.6377:  54%|[36m█████▍    [0m| 14/26 [00:13<00:10,  1.10it/s]Epoch: 0/10. Loss: 13.6377:  58%|[36m█████▊    [0m| 15/26 [00:13<00:09,  1.13it/s]Epoch: 0/10. Loss: 15.1824:  58%|[36m█████▊    [0m| 15/26 [00:17<00:09,  1.13it/s]Epoch: 0/10. Loss: 15.1824:  62%|[36m██████▏   [0m| 16/26 [00:17<00:17,  1.79s/it]Epoch: 0/10. Loss: 17.3414:  62%|[36m██████▏   [0m| 16/26 [00:18<00:17,  1.79s/it]Epoch: 0/10. Loss: 17.3414:  65%|[36m██████▌   [0m| 17/26 [00:18<00:15,  1.70s/it]Epoch: 0/10. Loss: 18.4590:  65%|[36m██████▌   [0m| 17/26 [00:19<00:15,  1.70s/it]Epoch: 0/10. Loss: 18.4590:  69%|[36m██████▉   [0m| 18/26 [00:19<00:11,  1.40s/it]Epoch: 0/10. Loss: 21.3309:  69%|[36m██████▉   [0m| 18/26 [00:19<00:11,  1.40s/it]Epoch: 0/10. Loss: 21.3309:  73%|[36m███████▎  [0m| 19/26 [00:19<00:08,  1.19s/it]Epoch: 0/10. Loss: 16.1850:  73%|[36m███████▎  [0m| 19/26 [00:21<00:08,  1.19s/it]Epoch: 0/10. Loss: 16.1850:  77%|[36m███████▋  [0m| 20/26 [00:21<00:08,  1.40s/it]Epoch: 0/10. Loss: 10.7224:  77%|[36m███████▋  [0m| 20/26 [00:22<00:08,  1.40s/it]Epoch: 0/10. Loss: 10.7224:  81%|[36m████████  [0m| 21/26 [00:22<00:06,  1.23s/it]Epoch: 0/10. Loss: 5.5073:  81%|[36m████████  [0m| 21/26 [00:23<00:06,  1.23s/it] Epoch: 0/10. Loss: 5.5073:  85%|[36m████████▍ [0m| 22/26 [00:23<00:04,  1.13s/it]Epoch: 0/10. Loss: 2.9254:  85%|[36m████████▍ [0m| 22/26 [00:24<00:04,  1.13s/it]Epoch: 0/10. Loss: 2.9254:  88%|[36m████████▊ [0m| 23/26 [00:24<00:03,  1.09s/it]Epoch: 0/10. Loss: 2.3687:  88%|[36m████████▊ [0m| 23/26 [00:25<00:03,  1.09s/it]Epoch: 0/10. Loss: 2.3687:  92%|[36m█████████▏[0m| 24/26 [00:25<00:02,  1.05s/it]Epoch: 0/10. Loss: 1.3920:  92%|[36m█████████▏[0m| 24/26 [00:26<00:02,  1.05s/it]Epoch: 0/10. Loss: 1.3920:  96%|[36m█████████▌[0m| 25/26 [00:26<00:00,  1.04it/s]Epoch: 0/10. Loss: 13.8813:  96%|[36m█████████▌[0m| 25/26 [00:26<00:00,  1.04it/s]Epoch: 0/10. Loss: 13.8813: 100%|[36m██████████[0m| 26/26 [00:26<00:00,  1.18it/s]Epoch: 0/10. Loss: 13.8813: 100%|[36m██████████[0m| 26/26 [00:26<00:00,  1.03s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:04,  1.26it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:05,  1.16s/it] 43%|[33m████▎     [0m| 3/7 [00:02<00:03,  1.06it/s] 57%|[33m█████▋    [0m| 4/7 [00:04<00:03,  1.03s/it] 71%|[33m███████▏  [0m| 5/7 [00:04<00:01,  1.27it/s] 86%|[33m████████▌ [0m| 6/7 [00:05<00:00,  1.28it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.63it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.28it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 1/10. Loss: 1.4983:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 1/10. Loss: 1.4983:   4%|[36m▍         [0m| 1/26 [00:00<00:20,  1.21it/s]Epoch: 1/10. Loss: 1.3054:   4%|[36m▍         [0m| 1/26 [00:01<00:20,  1.21it/s]Epoch: 1/10. Loss: 1.3054:   8%|[36m▊         [0m| 2/26 [00:01<00:22,  1.08it/s]Epoch: 1/10. Loss: 1.0669:   8%|[36m▊         [0m| 2/26 [00:02<00:22,  1.08it/s]Epoch: 1/10. Loss: 1.0669:  12%|[36m█▏        [0m| 3/26 [00:02<00:19,  1.21it/s]Epoch: 1/10. Loss: 1.0675:  12%|[36m█▏        [0m| 3/26 [00:03<00:19,  1.21it/s]Epoch: 1/10. Loss: 1.0675:  15%|[36m█▌        [0m| 4/26 [00:03<00:17,  1.27it/s]Epoch: 1/10. Loss: 1.0679:  15%|[36m█▌        [0m| 4/26 [00:04<00:17,  1.27it/s]Epoch: 1/10. Loss: 1.0679:  19%|[36m█▉        [0m| 5/26 [00:04<00:16,  1.25it/s]Epoch: 1/10. Loss: 0.9306:  19%|[36m█▉        [0m| 5/26 [00:05<00:16,  1.25it/s]Epoch: 1/10. Loss: 0.9306:  23%|[36m██▎       [0m| 6/26 [00:05<00:17,  1.16it/s]Epoch: 1/10. Loss: 1.1257:  23%|[36m██▎       [0m| 6/26 [00:06<00:17,  1.16it/s]Epoch: 1/10. Loss: 1.1257:  27%|[36m██▋       [0m| 7/26 [00:06<00:17,  1.08it/s]Epoch: 1/10. Loss: 1.2688:  27%|[36m██▋       [0m| 7/26 [00:06<00:17,  1.08it/s]Epoch: 1/10. Loss: 1.2688:  31%|[36m███       [0m| 8/26 [00:06<00:15,  1.13it/s]Epoch: 1/10. Loss: 1.1108:  31%|[36m███       [0m| 8/26 [00:07<00:15,  1.13it/s]Epoch: 1/10. Loss: 1.1108:  35%|[36m███▍      [0m| 9/26 [00:07<00:15,  1.09it/s]Epoch: 1/10. Loss: 1.1347:  35%|[36m███▍      [0m| 9/26 [00:08<00:15,  1.09it/s]Epoch: 1/10. Loss: 1.1347:  38%|[36m███▊      [0m| 10/26 [00:08<00:14,  1.12it/s]Epoch: 1/10. Loss: 1.0711:  38%|[36m███▊      [0m| 10/26 [00:09<00:14,  1.12it/s]Epoch: 1/10. Loss: 1.0711:  42%|[36m████▏     [0m| 11/26 [00:09<00:12,  1.16it/s]Epoch: 1/10. Loss: 1.0867:  42%|[36m████▏     [0m| 11/26 [00:10<00:12,  1.16it/s]Epoch: 1/10. Loss: 1.0867:  46%|[36m████▌     [0m| 12/26 [00:10<00:12,  1.15it/s]Epoch: 1/10. Loss: 1.1008:  46%|[36m████▌     [0m| 12/26 [00:11<00:12,  1.15it/s]Epoch: 1/10. Loss: 1.1008:  50%|[36m█████     [0m| 13/26 [00:11<00:11,  1.18it/s]Epoch: 1/10. Loss: 0.9528:  50%|[36m█████     [0m| 13/26 [00:12<00:11,  1.18it/s]Epoch: 1/10. Loss: 0.9528:  54%|[36m█████▍    [0m| 14/26 [00:12<00:11,  1.04it/s]Epoch: 1/10. Loss: 1.1147:  54%|[36m█████▍    [0m| 14/26 [00:13<00:11,  1.04it/s]Epoch: 1/10. Loss: 1.1147:  58%|[36m█████▊    [0m| 15/26 [00:13<00:10,  1.01it/s]Epoch: 1/10. Loss: 1.1591:  58%|[36m█████▊    [0m| 15/26 [00:14<00:10,  1.01it/s]Epoch: 1/10. Loss: 1.1591:  62%|[36m██████▏   [0m| 16/26 [00:14<00:09,  1.05it/s]Epoch: 1/10. Loss: 1.1880:  62%|[36m██████▏   [0m| 16/26 [00:15<00:09,  1.05it/s]Epoch: 1/10. Loss: 1.1880:  65%|[36m██████▌   [0m| 17/26 [00:15<00:08,  1.06it/s]Epoch: 1/10. Loss: 1.1112:  65%|[36m██████▌   [0m| 17/26 [00:16<00:08,  1.06it/s]Epoch: 1/10. Loss: 1.1112:  69%|[36m██████▉   [0m| 18/26 [00:16<00:07,  1.05it/s]Epoch: 1/10. Loss: 1.0998:  69%|[36m██████▉   [0m| 18/26 [00:17<00:07,  1.05it/s]Epoch: 1/10. Loss: 1.0998:  73%|[36m███████▎  [0m| 19/26 [00:17<00:06,  1.06it/s]Epoch: 1/10. Loss: 1.0596:  73%|[36m███████▎  [0m| 19/26 [00:18<00:06,  1.06it/s]Epoch: 1/10. Loss: 1.0596:  77%|[36m███████▋  [0m| 20/26 [00:18<00:05,  1.08it/s]Epoch: 1/10. Loss: 1.0448:  77%|[36m███████▋  [0m| 20/26 [00:18<00:05,  1.08it/s]Epoch: 1/10. Loss: 1.0448:  81%|[36m████████  [0m| 21/26 [00:18<00:04,  1.15it/s]Epoch: 1/10. Loss: 1.0687:  81%|[36m████████  [0m| 21/26 [00:19<00:04,  1.15it/s]Epoch: 1/10. Loss: 1.0687:  85%|[36m████████▍ [0m| 22/26 [00:19<00:03,  1.10it/s]Epoch: 1/10. Loss: 1.1242:  85%|[36m████████▍ [0m| 22/26 [00:20<00:03,  1.10it/s]Epoch: 1/10. Loss: 1.1242:  88%|[36m████████▊ [0m| 23/26 [00:20<00:02,  1.08it/s]Epoch: 1/10. Loss: 1.0473:  88%|[36m████████▊ [0m| 23/26 [00:21<00:02,  1.08it/s]Epoch: 1/10. Loss: 1.0473:  92%|[36m█████████▏[0m| 24/26 [00:21<00:01,  1.12it/s]Epoch: 1/10. Loss: 0.9803:  92%|[36m█████████▏[0m| 24/26 [00:22<00:01,  1.12it/s]Epoch: 1/10. Loss: 0.9803:  96%|[36m█████████▌[0m| 25/26 [00:22<00:00,  1.17it/s]Epoch: 1/10. Loss: 1.0631:  96%|[36m█████████▌[0m| 25/26 [00:24<00:00,  1.17it/s]Epoch: 1/10. Loss: 1.0631: 100%|[36m██████████[0m| 26/26 [00:24<00:00,  1.25s/it]Epoch: 1/10. Loss: 1.0631: 100%|[36m██████████[0m| 26/26 [00:24<00:00,  1.06it/s]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:04,  1.23it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:05,  1.16s/it] 43%|[33m████▎     [0m| 3/7 [00:02<00:03,  1.06it/s] 57%|[33m█████▋    [0m| 4/7 [00:04<00:03,  1.03s/it] 71%|[33m███████▏  [0m| 5/7 [00:04<00:01,  1.07it/s] 86%|[33m████████▌ [0m| 6/7 [00:05<00:00,  1.13it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.46it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.19it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 2/10. Loss: 1.0076:   0%|[36m          [0m| 0/26 [00:01<?, ?it/s]Epoch: 2/10. Loss: 1.0076:   4%|[36m▍         [0m| 1/26 [00:01<00:30,  1.20s/it]Epoch: 2/10. Loss: 0.9975:   4%|[36m▍         [0m| 1/26 [00:02<00:30,  1.20s/it]Epoch: 2/10. Loss: 0.9975:   8%|[36m▊         [0m| 2/26 [00:02<00:23,  1.02it/s]Epoch: 2/10. Loss: 2.1743:   8%|[36m▊         [0m| 2/26 [00:03<00:23,  1.02it/s]Epoch: 2/10. Loss: 2.1743:  12%|[36m█▏        [0m| 3/26 [00:03<00:26,  1.15s/it]Epoch: 2/10. Loss: 0.9918:  12%|[36m█▏        [0m| 3/26 [00:04<00:26,  1.15s/it]Epoch: 2/10. Loss: 0.9918:  15%|[36m█▌        [0m| 4/26 [00:04<00:23,  1.07s/it]Epoch: 2/10. Loss: 1.0195:  15%|[36m█▌        [0m| 4/26 [00:05<00:23,  1.07s/it]Epoch: 2/10. Loss: 1.0195:  19%|[36m█▉        [0m| 5/26 [00:05<00:21,  1.01s/it]Epoch: 2/10. Loss: 1.0737:  19%|[36m█▉        [0m| 5/26 [00:06<00:21,  1.01s/it]Epoch: 2/10. Loss: 1.0737:  23%|[36m██▎       [0m| 6/26 [00:06<00:24,  1.23s/it]Epoch: 2/10. Loss: 1.0640:  23%|[36m██▎       [0m| 6/26 [00:07<00:24,  1.23s/it]Epoch: 2/10. Loss: 1.0640:  27%|[36m██▋       [0m| 7/26 [00:07<00:22,  1.17s/it]Epoch: 2/10. Loss: 0.9906:  27%|[36m██▋       [0m| 7/26 [00:08<00:22,  1.17s/it]Epoch: 2/10. Loss: 0.9906:  31%|[36m███       [0m| 8/26 [00:08<00:19,  1.08s/it]Epoch: 2/10. Loss: 1.0393:  31%|[36m███       [0m| 8/26 [00:09<00:19,  1.08s/it]Epoch: 2/10. Loss: 1.0393:  35%|[36m███▍      [0m| 9/26 [00:09<00:16,  1.00it/s]Epoch: 2/10. Loss: 1.0278:  35%|[36m███▍      [0m| 9/26 [00:10<00:16,  1.00it/s]Epoch: 2/10. Loss: 1.0278:  38%|[36m███▊      [0m| 10/26 [00:10<00:15,  1.02it/s]Epoch: 2/10. Loss: 1.0872:  38%|[36m███▊      [0m| 10/26 [00:12<00:15,  1.02it/s]Epoch: 2/10. Loss: 1.0872:  42%|[36m████▏     [0m| 11/26 [00:12<00:18,  1.22s/it]Epoch: 2/10. Loss: 1.0214:  42%|[36m████▏     [0m| 11/26 [00:13<00:18,  1.22s/it]Epoch: 2/10. Loss: 1.0214:  46%|[36m████▌     [0m| 12/26 [00:13<00:15,  1.11s/it]Epoch: 2/10. Loss: 1.0301:  46%|[36m████▌     [0m| 12/26 [00:14<00:15,  1.11s/it]Epoch: 2/10. Loss: 1.0301:  50%|[36m█████     [0m| 13/26 [00:14<00:14,  1.08s/it]Epoch: 2/10. Loss: 1.0276:  50%|[36m█████     [0m| 13/26 [00:15<00:14,  1.08s/it]Epoch: 2/10. Loss: 1.0276:  54%|[36m█████▍    [0m| 14/26 [00:15<00:12,  1.00s/it]Epoch: 2/10. Loss: 0.9894:  54%|[36m█████▍    [0m| 14/26 [00:15<00:12,  1.00s/it]Epoch: 2/10. Loss: 0.9894:  58%|[36m█████▊    [0m| 15/26 [00:15<00:10,  1.05it/s]Epoch: 2/10. Loss: 1.0677:  58%|[36m█████▊    [0m| 15/26 [00:16<00:10,  1.05it/s]Epoch: 2/10. Loss: 1.0677:  62%|[36m██████▏   [0m| 16/26 [00:16<00:09,  1.10it/s]Epoch: 2/10. Loss: 1.0580:  62%|[36m██████▏   [0m| 16/26 [00:17<00:09,  1.10it/s]Epoch: 2/10. Loss: 1.0580:  65%|[36m██████▌   [0m| 17/26 [00:17<00:08,  1.05it/s]Epoch: 2/10. Loss: 1.0519:  65%|[36m██████▌   [0m| 17/26 [00:18<00:08,  1.05it/s]Epoch: 2/10. Loss: 1.0519:  69%|[36m██████▉   [0m| 18/26 [00:18<00:08,  1.02s/it]Epoch: 2/10. Loss: 1.0223:  69%|[36m██████▉   [0m| 18/26 [00:19<00:08,  1.02s/it]Epoch: 2/10. Loss: 1.0223:  73%|[36m███████▎  [0m| 19/26 [00:19<00:06,  1.02it/s]Epoch: 2/10. Loss: 0.9968:  73%|[36m███████▎  [0m| 19/26 [00:20<00:06,  1.02it/s]Epoch: 2/10. Loss: 0.9968:  77%|[36m███████▋  [0m| 20/26 [00:20<00:05,  1.12it/s]Epoch: 2/10. Loss: 1.0647:  77%|[36m███████▋  [0m| 20/26 [00:21<00:05,  1.12it/s]Epoch: 2/10. Loss: 1.0647:  81%|[36m████████  [0m| 21/26 [00:21<00:04,  1.19it/s]Epoch: 2/10. Loss: 1.0293:  81%|[36m████████  [0m| 21/26 [00:22<00:04,  1.19it/s]Epoch: 2/10. Loss: 1.0293:  85%|[36m████████▍ [0m| 22/26 [00:22<00:03,  1.16it/s]Epoch: 2/10. Loss: 1.0174:  85%|[36m████████▍ [0m| 22/26 [00:22<00:03,  1.16it/s]Epoch: 2/10. Loss: 1.0174:  88%|[36m████████▊ [0m| 23/26 [00:22<00:02,  1.20it/s]Epoch: 2/10. Loss: 1.0246:  88%|[36m████████▊ [0m| 23/26 [00:24<00:02,  1.20it/s]Epoch: 2/10. Loss: 1.0246:  92%|[36m█████████▏[0m| 24/26 [00:24<00:01,  1.08it/s]Epoch: 2/10. Loss: 1.0127:  92%|[36m█████████▏[0m| 24/26 [00:24<00:01,  1.08it/s]Epoch: 2/10. Loss: 1.0127:  96%|[36m█████████▌[0m| 25/26 [00:24<00:00,  1.12it/s]Epoch: 2/10. Loss: 0.9689:  96%|[36m█████████▌[0m| 25/26 [00:25<00:00,  1.12it/s]Epoch: 2/10. Loss: 0.9689: 100%|[36m██████████[0m| 26/26 [00:25<00:00,  1.22it/s]Epoch: 2/10. Loss: 0.9689: 100%|[36m██████████[0m| 26/26 [00:25<00:00,  1.02it/s]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:04,  1.39it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:05,  1.06s/it] 43%|[33m████▎     [0m| 3/7 [00:02<00:03,  1.18it/s] 57%|[33m█████▋    [0m| 4/7 [00:03<00:02,  1.05it/s] 71%|[33m███████▏  [0m| 5/7 [00:04<00:01,  1.35it/s] 86%|[33m████████▌ [0m| 6/7 [00:04<00:00,  1.30it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.65it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.35it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 3/10. Loss: 0.9971:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 3/10. Loss: 0.9971:   4%|[36m▍         [0m| 1/26 [00:00<00:17,  1.44it/s]Epoch: 3/10. Loss: 1.0522:   4%|[36m▍         [0m| 1/26 [00:01<00:17,  1.44it/s]Epoch: 3/10. Loss: 1.0522:   8%|[36m▊         [0m| 2/26 [00:01<00:22,  1.05it/s]Epoch: 3/10. Loss: 1.0018:   8%|[36m▊         [0m| 2/26 [00:03<00:22,  1.05it/s]Epoch: 3/10. Loss: 1.0018:  12%|[36m█▏        [0m| 3/26 [00:03<00:28,  1.22s/it]Epoch: 3/10. Loss: 1.0223:  12%|[36m█▏        [0m| 3/26 [00:04<00:28,  1.22s/it]Epoch: 3/10. Loss: 1.0223:  15%|[36m█▌        [0m| 4/26 [00:04<00:23,  1.08s/it]Epoch: 3/10. Loss: 1.0822:  15%|[36m█▌        [0m| 4/26 [00:05<00:23,  1.08s/it]Epoch: 3/10. Loss: 1.0822:  19%|[36m█▉        [0m| 5/26 [00:05<00:22,  1.05s/it]Epoch: 3/10. Loss: 1.0694:  19%|[36m█▉        [0m| 5/26 [00:06<00:22,  1.05s/it]Epoch: 3/10. Loss: 1.0694:  23%|[36m██▎       [0m| 6/26 [00:06<00:19,  1.04it/s]Epoch: 3/10. Loss: 1.0383:  23%|[36m██▎       [0m| 6/26 [00:07<00:19,  1.04it/s]Epoch: 3/10. Loss: 1.0383:  27%|[36m██▋       [0m| 7/26 [00:07<00:24,  1.27s/it]Epoch: 3/10. Loss: 1.0188:  27%|[36m██▋       [0m| 7/26 [00:08<00:24,  1.27s/it]Epoch: 3/10. Loss: 1.0188:  31%|[36m███       [0m| 8/26 [00:08<00:21,  1.18s/it]Epoch: 3/10. Loss: 1.0079:  31%|[36m███       [0m| 8/26 [00:09<00:21,  1.18s/it]Epoch: 3/10. Loss: 1.0079:  35%|[36m███▍      [0m| 9/26 [00:09<00:17,  1.03s/it]Epoch: 3/10. Loss: 1.0045:  35%|[36m███▍      [0m| 9/26 [00:10<00:17,  1.03s/it]Epoch: 3/10. Loss: 1.0045:  38%|[36m███▊      [0m| 10/26 [00:10<00:15,  1.05it/s]Epoch: 3/10. Loss: 1.0727:  38%|[36m███▊      [0m| 10/26 [00:11<00:15,  1.05it/s]Epoch: 3/10. Loss: 1.0727:  42%|[36m████▏     [0m| 11/26 [00:11<00:13,  1.10it/s]Epoch: 3/10. Loss: 0.9977:  42%|[36m████▏     [0m| 11/26 [00:12<00:13,  1.10it/s]Epoch: 3/10. Loss: 0.9977:  46%|[36m████▌     [0m| 12/26 [00:12<00:12,  1.10it/s]Epoch: 3/10. Loss: 1.0710:  46%|[36m████▌     [0m| 12/26 [00:12<00:12,  1.10it/s]Epoch: 3/10. Loss: 1.0710:  50%|[36m█████     [0m| 13/26 [00:12<00:11,  1.14it/s]Epoch: 3/10. Loss: 0.9737:  50%|[36m█████     [0m| 13/26 [00:14<00:11,  1.14it/s]Epoch: 3/10. Loss: 0.9737:  54%|[36m█████▍    [0m| 14/26 [00:14<00:12,  1.08s/it]Epoch: 3/10. Loss: 0.9943:  54%|[36m█████▍    [0m| 14/26 [00:15<00:12,  1.08s/it]Epoch: 3/10. Loss: 0.9943:  58%|[36m█████▊    [0m| 15/26 [00:15<00:11,  1.02s/it]Epoch: 3/10. Loss: 1.0484:  58%|[36m█████▊    [0m| 15/26 [00:16<00:11,  1.02s/it]Epoch: 3/10. Loss: 1.0484:  62%|[36m██████▏   [0m| 16/26 [00:16<00:10,  1.01s/it]Epoch: 3/10. Loss: 1.0415:  62%|[36m██████▏   [0m| 16/26 [00:17<00:10,  1.01s/it]Epoch: 3/10. Loss: 1.0415:  65%|[36m██████▌   [0m| 17/26 [00:17<00:08,  1.03it/s]Epoch: 3/10. Loss: 0.9835:  65%|[36m██████▌   [0m| 17/26 [00:18<00:08,  1.03it/s]Epoch: 3/10. Loss: 0.9835:  69%|[36m██████▉   [0m| 18/26 [00:18<00:08,  1.06s/it]Epoch: 3/10. Loss: 1.0373:  69%|[36m██████▉   [0m| 18/26 [00:19<00:08,  1.06s/it]Epoch: 3/10. Loss: 1.0373:  73%|[36m███████▎  [0m| 19/26 [00:19<00:07,  1.02s/it]Epoch: 3/10. Loss: 0.9775:  73%|[36m███████▎  [0m| 19/26 [00:22<00:07,  1.02s/it]Epoch: 3/10. Loss: 0.9775:  77%|[36m███████▋  [0m| 20/26 [00:22<00:09,  1.51s/it]Epoch: 3/10. Loss: 1.0441:  77%|[36m███████▋  [0m| 20/26 [00:22<00:09,  1.51s/it]Epoch: 3/10. Loss: 1.0441:  81%|[36m████████  [0m| 21/26 [00:22<00:06,  1.29s/it]Epoch: 3/10. Loss: 1.0195:  81%|[36m████████  [0m| 21/26 [00:23<00:06,  1.29s/it]Epoch: 3/10. Loss: 1.0195:  85%|[36m████████▍ [0m| 22/26 [00:23<00:04,  1.17s/it]Epoch: 3/10. Loss: 1.0154:  85%|[36m████████▍ [0m| 22/26 [00:24<00:04,  1.17s/it]Epoch: 3/10. Loss: 1.0154:  88%|[36m████████▊ [0m| 23/26 [00:24<00:03,  1.10s/it]Epoch: 3/10. Loss: 0.9581:  88%|[36m████████▊ [0m| 23/26 [00:25<00:03,  1.10s/it]Epoch: 3/10. Loss: 0.9581:  92%|[36m█████████▏[0m| 24/26 [00:25<00:02,  1.07s/it]Epoch: 3/10. Loss: 0.9925:  92%|[36m█████████▏[0m| 24/26 [00:26<00:02,  1.07s/it]Epoch: 3/10. Loss: 0.9925:  96%|[36m█████████▌[0m| 25/26 [00:26<00:01,  1.05s/it]Epoch: 3/10. Loss: 0.9762:  96%|[36m█████████▌[0m| 25/26 [00:28<00:01,  1.05s/it]Epoch: 3/10. Loss: 0.9762: 100%|[36m██████████[0m| 26/26 [00:28<00:00,  1.23s/it]Epoch: 3/10. Loss: 0.9762: 100%|[36m██████████[0m| 26/26 [00:28<00:00,  1.09s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:02<00:15,  2.59s/it] 29%|[33m██▊       [0m| 2/7 [00:03<00:09,  1.88s/it] 43%|[33m████▎     [0m| 3/7 [00:04<00:05,  1.31s/it] 57%|[33m█████▋    [0m| 4/7 [00:05<00:03,  1.24s/it] 71%|[33m███████▏  [0m| 5/7 [00:06<00:01,  1.07it/s] 86%|[33m████████▌ [0m| 6/7 [00:06<00:00,  1.12it/s]100%|[33m██████████[0m| 7/7 [00:07<00:00,  1.44it/s]100%|[33m██████████[0m| 7/7 [00:07<00:00,  1.03s/it]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 4/10. Loss: 1.0811:   0%|[36m          [0m| 0/26 [00:01<?, ?it/s]Epoch: 4/10. Loss: 1.0811:   4%|[36m▍         [0m| 1/26 [00:01<00:26,  1.07s/it]Epoch: 4/10. Loss: 1.0243:   4%|[36m▍         [0m| 1/26 [00:01<00:26,  1.07s/it]Epoch: 4/10. Loss: 1.0243:   8%|[36m▊         [0m| 2/26 [00:01<00:19,  1.22it/s]Epoch: 4/10. Loss: 0.9528:   8%|[36m▊         [0m| 2/26 [00:02<00:19,  1.22it/s]Epoch: 4/10. Loss: 0.9528:  12%|[36m█▏        [0m| 3/26 [00:02<00:20,  1.11it/s]Epoch: 4/10. Loss: 0.9885:  12%|[36m█▏        [0m| 3/26 [00:04<00:20,  1.11it/s]Epoch: 4/10. Loss: 0.9885:  15%|[36m█▌        [0m| 4/26 [00:04<00:24,  1.13s/it]Epoch: 4/10. Loss: 0.9730:  15%|[36m█▌        [0m| 4/26 [00:05<00:24,  1.13s/it]Epoch: 4/10. Loss: 0.9730:  19%|[36m█▉        [0m| 5/26 [00:05<00:22,  1.06s/it]Epoch: 4/10. Loss: 1.0206:  19%|[36m█▉        [0m| 5/26 [00:06<00:22,  1.06s/it]Epoch: 4/10. Loss: 1.0206:  23%|[36m██▎       [0m| 6/26 [00:06<00:23,  1.16s/it]Epoch: 4/10. Loss: 1.0397:  23%|[36m██▎       [0m| 6/26 [00:07<00:23,  1.16s/it]Epoch: 4/10. Loss: 1.0397:  27%|[36m██▋       [0m| 7/26 [00:07<00:20,  1.10s/it]Epoch: 4/10. Loss: 0.9464:  27%|[36m██▋       [0m| 7/26 [00:08<00:20,  1.10s/it]Epoch: 4/10. Loss: 0.9464:  31%|[36m███       [0m| 8/26 [00:08<00:18,  1.00s/it]Epoch: 4/10. Loss: 0.9866:  31%|[36m███       [0m| 8/26 [00:09<00:18,  1.00s/it]Epoch: 4/10. Loss: 0.9866:  35%|[36m███▍      [0m| 9/26 [00:09<00:16,  1.02it/s]Epoch: 4/10. Loss: 0.9683:  35%|[36m███▍      [0m| 9/26 [00:09<00:16,  1.02it/s]Epoch: 4/10. Loss: 0.9683:  38%|[36m███▊      [0m| 10/26 [00:09<00:14,  1.09it/s]Epoch: 4/10. Loss: 1.0001:  38%|[36m███▊      [0m| 10/26 [00:10<00:14,  1.09it/s]Epoch: 4/10. Loss: 1.0001:  42%|[36m████▏     [0m| 11/26 [00:10<00:14,  1.07it/s]Epoch: 4/10. Loss: 1.0520:  42%|[36m████▏     [0m| 11/26 [00:11<00:14,  1.07it/s]Epoch: 4/10. Loss: 1.0520:  46%|[36m████▌     [0m| 12/26 [00:11<00:13,  1.08it/s]Epoch: 4/10. Loss: 0.9698:  46%|[36m████▌     [0m| 12/26 [00:12<00:13,  1.08it/s]Epoch: 4/10. Loss: 0.9698:  50%|[36m█████     [0m| 13/26 [00:12<00:12,  1.06it/s]Epoch: 4/10. Loss: 1.8001:  50%|[36m█████     [0m| 13/26 [00:13<00:12,  1.06it/s]Epoch: 4/10. Loss: 1.8001:  54%|[36m█████▍    [0m| 14/26 [00:13<00:10,  1.13it/s]Epoch: 4/10. Loss: 1.0298:  54%|[36m█████▍    [0m| 14/26 [00:14<00:10,  1.13it/s]Epoch: 4/10. Loss: 1.0298:  58%|[36m█████▊    [0m| 15/26 [00:14<00:09,  1.14it/s]Epoch: 4/10. Loss: 0.9876:  58%|[36m█████▊    [0m| 15/26 [00:15<00:09,  1.14it/s]Epoch: 4/10. Loss: 0.9876:  62%|[36m██████▏   [0m| 16/26 [00:15<00:08,  1.19it/s]Epoch: 4/10. Loss: 1.0606:  62%|[36m██████▏   [0m| 16/26 [00:15<00:08,  1.19it/s]Epoch: 4/10. Loss: 1.0606:  65%|[36m██████▌   [0m| 17/26 [00:16<00:07,  1.20it/s]Epoch: 4/10. Loss: 1.0548:  65%|[36m██████▌   [0m| 17/26 [00:16<00:07,  1.20it/s]Epoch: 4/10. Loss: 1.0548:  69%|[36m██████▉   [0m| 18/26 [00:16<00:06,  1.22it/s]Epoch: 4/10. Loss: 1.0210:  69%|[36m██████▉   [0m| 18/26 [00:17<00:06,  1.22it/s]Epoch: 4/10. Loss: 1.0210:  73%|[36m███████▎  [0m| 19/26 [00:17<00:05,  1.17it/s]Epoch: 4/10. Loss: 1.0441:  73%|[36m███████▎  [0m| 19/26 [00:18<00:05,  1.17it/s]Epoch: 4/10. Loss: 1.0441:  77%|[36m███████▋  [0m| 20/26 [00:18<00:04,  1.23it/s]Epoch: 4/10. Loss: 0.9974:  77%|[36m███████▋  [0m| 20/26 [00:19<00:04,  1.23it/s]Epoch: 4/10. Loss: 0.9974:  81%|[36m████████  [0m| 21/26 [00:19<00:04,  1.16it/s]Epoch: 4/10. Loss: 1.0354:  81%|[36m████████  [0m| 21/26 [00:24<00:04,  1.16it/s]Epoch: 4/10. Loss: 1.0354:  85%|[36m████████▍ [0m| 22/26 [00:24<00:07,  2.00s/it]Epoch: 4/10. Loss: 0.9982:  85%|[36m████████▍ [0m| 22/26 [00:25<00:07,  2.00s/it]Epoch: 4/10. Loss: 0.9982:  88%|[36m████████▊ [0m| 23/26 [00:25<00:05,  1.68s/it]Epoch: 4/10. Loss: 1.1224:  88%|[36m████████▊ [0m| 23/26 [00:25<00:05,  1.68s/it]Epoch: 4/10. Loss: 1.1224:  92%|[36m█████████▏[0m| 24/26 [00:25<00:02,  1.41s/it]Epoch: 4/10. Loss: 1.0347:  92%|[36m█████████▏[0m| 24/26 [00:27<00:02,  1.41s/it]Epoch: 4/10. Loss: 1.0347:  96%|[36m█████████▌[0m| 25/26 [00:27<00:01,  1.52s/it]Epoch: 4/10. Loss: 1.0448:  96%|[36m█████████▌[0m| 25/26 [00:28<00:01,  1.52s/it]Epoch: 4/10. Loss: 1.0448: 100%|[36m██████████[0m| 26/26 [00:28<00:00,  1.20s/it]Epoch: 4/10. Loss: 1.0448: 100%|[36m██████████[0m| 26/26 [00:28<00:00,  1.08s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:05,  1.05it/s] 29%|[33m██▊       [0m| 2/7 [00:03<00:08,  1.62s/it] 43%|[33m████▎     [0m| 3/7 [00:03<00:04,  1.19s/it] 57%|[33m█████▋    [0m| 4/7 [00:05<00:04,  1.51s/it] 71%|[33m███████▏  [0m| 5/7 [00:06<00:02,  1.11s/it] 86%|[33m████████▌ [0m| 6/7 [00:06<00:01,  1.01s/it]100%|[33m██████████[0m| 7/7 [00:09<00:00,  1.36s/it]100%|[33m██████████[0m| 7/7 [00:09<00:00,  1.29s/it]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 5/10. Loss: 1.0316:   0%|[36m          [0m| 0/26 [00:02<?, ?it/s]Epoch: 5/10. Loss: 1.0316:   4%|[36m▍         [0m| 1/26 [00:02<01:11,  2.88s/it]Epoch: 5/10. Loss: 1.0397:   4%|[36m▍         [0m| 1/26 [00:03<01:11,  2.88s/it]Epoch: 5/10. Loss: 1.0397:   8%|[36m▊         [0m| 2/26 [00:03<00:39,  1.63s/it]Epoch: 5/10. Loss: 1.0116:   8%|[36m▊         [0m| 2/26 [00:04<00:39,  1.63s/it]Epoch: 5/10. Loss: 1.0116:  12%|[36m█▏        [0m| 3/26 [00:04<00:29,  1.29s/it]Epoch: 5/10. Loss: 0.9881:  12%|[36m█▏        [0m| 3/26 [00:05<00:29,  1.29s/it]Epoch: 5/10. Loss: 0.9881:  15%|[36m█▌        [0m| 4/26 [00:05<00:25,  1.17s/it]Epoch: 5/10. Loss: 1.0316:  15%|[36m█▌        [0m| 4/26 [00:06<00:25,  1.17s/it]Epoch: 5/10. Loss: 1.0316:  19%|[36m█▉        [0m| 5/26 [00:06<00:22,  1.09s/it]Epoch: 5/10. Loss: 1.0442:  19%|[36m█▉        [0m| 5/26 [00:07<00:22,  1.09s/it]Epoch: 5/10. Loss: 1.0442:  23%|[36m██▎       [0m| 6/26 [00:07<00:22,  1.11s/it]Epoch: 5/10. Loss: 1.0137:  23%|[36m██▎       [0m| 6/26 [00:08<00:22,  1.11s/it]Epoch: 5/10. Loss: 1.0137:  27%|[36m██▋       [0m| 7/26 [00:08<00:19,  1.00s/it]Epoch: 5/10. Loss: 1.0543:  27%|[36m██▋       [0m| 7/26 [00:09<00:19,  1.00s/it]Epoch: 5/10. Loss: 1.0543:  31%|[36m███       [0m| 8/26 [00:09<00:18,  1.02s/it]Epoch: 5/10. Loss: 1.0450:  31%|[36m███       [0m| 8/26 [00:11<00:18,  1.02s/it]Epoch: 5/10. Loss: 1.0450:  35%|[36m███▍      [0m| 9/26 [00:11<00:24,  1.44s/it]Epoch: 5/10. Loss: 1.0302:  35%|[36m███▍      [0m| 9/26 [00:12<00:24,  1.44s/it]Epoch: 5/10. Loss: 1.0302:  38%|[36m███▊      [0m| 10/26 [00:12<00:21,  1.35s/it]Epoch: 5/10. Loss: 1.0017:  38%|[36m███▊      [0m| 10/26 [00:13<00:21,  1.35s/it]Epoch: 5/10. Loss: 1.0017:  42%|[36m████▏     [0m| 11/26 [00:13<00:18,  1.25s/it]Epoch: 5/10. Loss: 0.9811:  42%|[36m████▏     [0m| 11/26 [00:14<00:18,  1.25s/it]Epoch: 5/10. Loss: 0.9811:  46%|[36m████▌     [0m| 12/26 [00:14<00:15,  1.14s/it]Epoch: 5/10. Loss: 1.0576:  46%|[36m████▌     [0m| 12/26 [00:15<00:15,  1.14s/it]Epoch: 5/10. Loss: 1.0576:  50%|[36m█████     [0m| 13/26 [00:15<00:13,  1.03s/it]Epoch: 5/10. Loss: 1.0111:  50%|[36m█████     [0m| 13/26 [00:16<00:13,  1.03s/it]Epoch: 5/10. Loss: 1.0111:  54%|[36m█████▍    [0m| 14/26 [00:16<00:11,  1.03it/s]Epoch: 5/10. Loss: 0.9928:  54%|[36m█████▍    [0m| 14/26 [00:17<00:11,  1.03it/s]Epoch: 5/10. Loss: 0.9928:  58%|[36m█████▊    [0m| 15/26 [00:17<00:09,  1.11it/s]Epoch: 5/10. Loss: 0.9930:  58%|[36m█████▊    [0m| 15/26 [00:18<00:09,  1.11it/s]Epoch: 5/10. Loss: 0.9930:  62%|[36m██████▏   [0m| 16/26 [00:18<00:09,  1.00it/s]Epoch: 5/10. Loss: 0.9568:  62%|[36m██████▏   [0m| 16/26 [00:19<00:09,  1.00it/s]Epoch: 5/10. Loss: 0.9568:  65%|[36m██████▌   [0m| 17/26 [00:19<00:08,  1.06it/s]Epoch: 5/10. Loss: 1.0240:  65%|[36m██████▌   [0m| 17/26 [00:20<00:08,  1.06it/s]Epoch: 5/10. Loss: 1.0240:  69%|[36m██████▉   [0m| 18/26 [00:20<00:07,  1.06it/s]Epoch: 5/10. Loss: 1.0114:  69%|[36m██████▉   [0m| 18/26 [00:22<00:07,  1.06it/s]Epoch: 5/10. Loss: 1.0114:  73%|[36m███████▎  [0m| 19/26 [00:22<00:08,  1.23s/it]Epoch: 5/10. Loss: 0.9801:  73%|[36m███████▎  [0m| 19/26 [00:23<00:08,  1.23s/it]Epoch: 5/10. Loss: 0.9801:  77%|[36m███████▋  [0m| 20/26 [00:23<00:06,  1.14s/it]Epoch: 5/10. Loss: 1.0107:  77%|[36m███████▋  [0m| 20/26 [00:23<00:06,  1.14s/it]Epoch: 5/10. Loss: 1.0107:  81%|[36m████████  [0m| 21/26 [00:23<00:05,  1.09s/it]Epoch: 5/10. Loss: 0.9722:  81%|[36m████████  [0m| 21/26 [00:24<00:05,  1.09s/it]Epoch: 5/10. Loss: 0.9722:  85%|[36m████████▍ [0m| 22/26 [00:24<00:04,  1.03s/it]Epoch: 5/10. Loss: 1.0150:  85%|[36m████████▍ [0m| 22/26 [00:26<00:04,  1.03s/it]Epoch: 5/10. Loss: 1.0150:  88%|[36m████████▊ [0m| 23/26 [00:26<00:03,  1.12s/it]Epoch: 5/10. Loss: 0.9969:  88%|[36m████████▊ [0m| 23/26 [00:26<00:03,  1.12s/it]Epoch: 5/10. Loss: 0.9969:  92%|[36m█████████▏[0m| 24/26 [00:26<00:02,  1.01s/it]Epoch: 5/10. Loss: 1.0915:  92%|[36m█████████▏[0m| 24/26 [00:27<00:02,  1.01s/it]Epoch: 5/10. Loss: 1.0915:  96%|[36m█████████▌[0m| 25/26 [00:27<00:01,  1.00s/it]Epoch: 5/10. Loss: 1.0136:  96%|[36m█████████▌[0m| 25/26 [00:28<00:01,  1.00s/it]Epoch: 5/10. Loss: 1.0136: 100%|[36m██████████[0m| 26/26 [00:28<00:00,  1.14it/s]Epoch: 5/10. Loss: 1.0136: 100%|[36m██████████[0m| 26/26 [00:28<00:00,  1.10s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:04,  1.30it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:05,  1.14s/it] 43%|[33m████▎     [0m| 3/7 [00:03<00:04,  1.15s/it] 57%|[33m█████▋    [0m| 4/7 [00:04<00:03,  1.16s/it] 71%|[33m███████▏  [0m| 5/7 [00:04<00:01,  1.13it/s] 86%|[33m████████▌ [0m| 6/7 [00:05<00:00,  1.15it/s]100%|[33m██████████[0m| 7/7 [00:06<00:00,  1.47it/s]100%|[33m██████████[0m| 7/7 [00:06<00:00,  1.16it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 6/10. Loss: 0.9959:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 6/10. Loss: 0.9959:   4%|[36m▍         [0m| 1/26 [00:00<00:23,  1.04it/s]Epoch: 6/10. Loss: 1.0171:   4%|[36m▍         [0m| 1/26 [00:01<00:23,  1.04it/s]Epoch: 6/10. Loss: 1.0171:   8%|[36m▊         [0m| 2/26 [00:01<00:21,  1.12it/s]Epoch: 6/10. Loss: 1.0291:   8%|[36m▊         [0m| 2/26 [00:02<00:21,  1.12it/s]Epoch: 6/10. Loss: 1.0291:  12%|[36m█▏        [0m| 3/26 [00:02<00:19,  1.18it/s]Epoch: 6/10. Loss: 0.9311:  12%|[36m█▏        [0m| 3/26 [00:03<00:19,  1.18it/s]Epoch: 6/10. Loss: 0.9311:  15%|[36m█▌        [0m| 4/26 [00:03<00:19,  1.16it/s]Epoch: 6/10. Loss: 1.0182:  15%|[36m█▌        [0m| 4/26 [00:04<00:19,  1.16it/s]Epoch: 6/10. Loss: 1.0182:  19%|[36m█▉        [0m| 5/26 [00:04<00:17,  1.23it/s]Epoch: 6/10. Loss: 1.9053:  19%|[36m█▉        [0m| 5/26 [00:05<00:17,  1.23it/s]Epoch: 6/10. Loss: 1.9053:  23%|[36m██▎       [0m| 6/26 [00:05<00:17,  1.14it/s]Epoch: 6/10. Loss: 1.0695:  23%|[36m██▎       [0m| 6/26 [00:06<00:17,  1.14it/s]Epoch: 6/10. Loss: 1.0695:  27%|[36m██▋       [0m| 7/26 [00:06<00:16,  1.18it/s]Epoch: 6/10. Loss: 0.9987:  27%|[36m██▋       [0m| 7/26 [00:06<00:16,  1.18it/s]Epoch: 6/10. Loss: 0.9987:  31%|[36m███       [0m| 8/26 [00:06<00:14,  1.27it/s]Epoch: 6/10. Loss: 1.0098:  31%|[36m███       [0m| 8/26 [00:07<00:14,  1.27it/s]Epoch: 6/10. Loss: 1.0098:  35%|[36m███▍      [0m| 9/26 [00:07<00:15,  1.11it/s]Epoch: 6/10. Loss: 1.0103:  35%|[36m███▍      [0m| 9/26 [00:09<00:15,  1.11it/s]Epoch: 6/10. Loss: 1.0103:  38%|[36m███▊      [0m| 10/26 [00:09<00:18,  1.18s/it]Epoch: 6/10. Loss: 1.0262:  38%|[36m███▊      [0m| 10/26 [00:10<00:18,  1.18s/it]Epoch: 6/10. Loss: 1.0262:  42%|[36m████▏     [0m| 11/26 [00:10<00:15,  1.02s/it]Epoch: 6/10. Loss: 1.0852:  42%|[36m████▏     [0m| 11/26 [00:11<00:15,  1.02s/it]Epoch: 6/10. Loss: 1.0852:  46%|[36m████▌     [0m| 12/26 [00:11<00:13,  1.05it/s]Epoch: 6/10. Loss: 1.0769:  46%|[36m████▌     [0m| 12/26 [00:11<00:13,  1.05it/s]Epoch: 6/10. Loss: 1.0769:  50%|[36m█████     [0m| 13/26 [00:11<00:11,  1.12it/s]Epoch: 6/10. Loss: 0.9722:  50%|[36m█████     [0m| 13/26 [00:12<00:11,  1.12it/s]Epoch: 6/10. Loss: 0.9722:  54%|[36m█████▍    [0m| 14/26 [00:12<00:10,  1.14it/s]Epoch: 6/10. Loss: 0.9867:  54%|[36m█████▍    [0m| 14/26 [00:14<00:10,  1.14it/s]Epoch: 6/10. Loss: 0.9867:  58%|[36m█████▊    [0m| 15/26 [00:14<00:12,  1.15s/it]Epoch: 6/10. Loss: 0.9919:  58%|[36m█████▊    [0m| 15/26 [00:15<00:12,  1.15s/it]Epoch: 6/10. Loss: 0.9919:  62%|[36m██████▏   [0m| 16/26 [00:15<00:10,  1.06s/it]Epoch: 6/10. Loss: 1.0123:  62%|[36m██████▏   [0m| 16/26 [00:16<00:10,  1.06s/it]Epoch: 6/10. Loss: 1.0123:  65%|[36m██████▌   [0m| 17/26 [00:16<00:09,  1.01s/it]Epoch: 6/10. Loss: 0.9812:  65%|[36m██████▌   [0m| 17/26 [00:17<00:09,  1.01s/it]Epoch: 6/10. Loss: 0.9812:  69%|[36m██████▉   [0m| 18/26 [00:17<00:08,  1.04s/it]Epoch: 6/10. Loss: 0.9762:  69%|[36m██████▉   [0m| 18/26 [00:18<00:08,  1.04s/it]Epoch: 6/10. Loss: 0.9762:  73%|[36m███████▎  [0m| 19/26 [00:18<00:07,  1.03s/it]Epoch: 6/10. Loss: 0.9564:  73%|[36m███████▎  [0m| 19/26 [00:19<00:07,  1.03s/it]Epoch: 6/10. Loss: 0.9564:  77%|[36m███████▋  [0m| 20/26 [00:19<00:05,  1.04it/s]Epoch: 6/10. Loss: 1.0215:  77%|[36m███████▋  [0m| 20/26 [00:20<00:05,  1.04it/s]Epoch: 6/10. Loss: 1.0215:  81%|[36m████████  [0m| 21/26 [00:20<00:05,  1.20s/it]Epoch: 6/10. Loss: 1.0045:  81%|[36m████████  [0m| 21/26 [00:21<00:05,  1.20s/it]Epoch: 6/10. Loss: 1.0045:  85%|[36m████████▍ [0m| 22/26 [00:21<00:04,  1.05s/it]Epoch: 6/10. Loss: 0.9434:  85%|[36m████████▍ [0m| 22/26 [00:22<00:04,  1.05s/it]Epoch: 6/10. Loss: 0.9434:  88%|[36m████████▊ [0m| 23/26 [00:22<00:03,  1.10s/it]Epoch: 6/10. Loss: 1.1194:  88%|[36m████████▊ [0m| 23/26 [00:25<00:03,  1.10s/it]Epoch: 6/10. Loss: 1.1194:  92%|[36m█████████▏[0m| 24/26 [00:25<00:03,  1.51s/it]Epoch: 6/10. Loss: 1.0433:  92%|[36m█████████▏[0m| 24/26 [00:26<00:03,  1.51s/it]Epoch: 6/10. Loss: 1.0433:  96%|[36m█████████▌[0m| 25/26 [00:26<00:01,  1.37s/it]Epoch: 6/10. Loss: 1.0431:  96%|[36m█████████▌[0m| 25/26 [00:27<00:01,  1.37s/it]Epoch: 6/10. Loss: 1.0431: 100%|[36m██████████[0m| 26/26 [00:27<00:00,  1.30s/it]Epoch: 6/10. Loss: 1.0431: 100%|[36m██████████[0m| 26/26 [00:27<00:00,  1.05s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:03<00:19,  3.22s/it] 29%|[33m██▊       [0m| 2/7 [00:05<00:13,  2.60s/it] 43%|[33m████▎     [0m| 3/7 [00:06<00:06,  1.72s/it] 57%|[33m█████▋    [0m| 4/7 [00:07<00:04,  1.53s/it] 71%|[33m███████▏  [0m| 5/7 [00:07<00:02,  1.12s/it] 86%|[33m████████▌ [0m| 6/7 [00:08<00:01,  1.03s/it]100%|[33m██████████[0m| 7/7 [00:08<00:00,  1.27it/s]100%|[33m██████████[0m| 7/7 [00:08<00:00,  1.26s/it]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 7/10. Loss: 0.9998:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 7/10. Loss: 0.9998:   4%|[36m▍         [0m| 1/26 [00:00<00:22,  1.09it/s]Epoch: 7/10. Loss: 0.9772:   4%|[36m▍         [0m| 1/26 [00:01<00:22,  1.09it/s]Epoch: 7/10. Loss: 0.9772:   8%|[36m▊         [0m| 2/26 [00:01<00:21,  1.12it/s]Epoch: 7/10. Loss: 1.0534:   8%|[36m▊         [0m| 2/26 [00:03<00:21,  1.12it/s]Epoch: 7/10. Loss: 1.0534:  12%|[36m█▏        [0m| 3/26 [00:03<00:31,  1.39s/it]Epoch: 7/10. Loss: 1.0168:  12%|[36m█▏        [0m| 3/26 [00:04<00:31,  1.39s/it]Epoch: 7/10. Loss: 1.0168:  15%|[36m█▌        [0m| 4/26 [00:04<00:24,  1.11s/it]Epoch: 7/10. Loss: 1.0104:  15%|[36m█▌        [0m| 4/26 [00:05<00:24,  1.11s/it]Epoch: 7/10. Loss: 1.0104:  19%|[36m█▉        [0m| 5/26 [00:05<00:21,  1.02s/it]Epoch: 7/10. Loss: 1.0581:  19%|[36m█▉        [0m| 5/26 [00:06<00:21,  1.02s/it]Epoch: 7/10. Loss: 1.0581:  23%|[36m██▎       [0m| 6/26 [00:06<00:19,  1.04it/s]Epoch: 7/10. Loss: 1.0415:  23%|[36m██▎       [0m| 6/26 [00:07<00:19,  1.04it/s]Epoch: 7/10. Loss: 1.0415:  27%|[36m██▋       [0m| 7/26 [00:07<00:17,  1.07it/s]Epoch: 7/10. Loss: 1.0291:  27%|[36m██▋       [0m| 7/26 [00:07<00:17,  1.07it/s]Epoch: 7/10. Loss: 1.0291:  31%|[36m███       [0m| 8/26 [00:07<00:16,  1.11it/s]Epoch: 7/10. Loss: 1.0533:  31%|[36m███       [0m| 8/26 [00:08<00:16,  1.11it/s]Epoch: 7/10. Loss: 1.0533:  35%|[36m███▍      [0m| 9/26 [00:08<00:15,  1.12it/s]Epoch: 7/10. Loss: 1.0095:  35%|[36m███▍      [0m| 9/26 [00:09<00:15,  1.12it/s]Epoch: 7/10. Loss: 1.0095:  38%|[36m███▊      [0m| 10/26 [00:09<00:15,  1.03it/s]Epoch: 7/10. Loss: 1.0220:  38%|[36m███▊      [0m| 10/26 [00:10<00:15,  1.03it/s]Epoch: 7/10. Loss: 1.0220:  42%|[36m████▏     [0m| 11/26 [00:10<00:14,  1.03it/s]Epoch: 7/10. Loss: 0.9836:  42%|[36m████▏     [0m| 11/26 [00:11<00:14,  1.03it/s]Epoch: 7/10. Loss: 0.9836:  46%|[36m████▌     [0m| 12/26 [00:11<00:13,  1.02it/s]Epoch: 7/10. Loss: 1.0189:  46%|[36m████▌     [0m| 12/26 [00:12<00:13,  1.02it/s]Epoch: 7/10. Loss: 1.0189:  50%|[36m█████     [0m| 13/26 [00:12<00:12,  1.04it/s]Epoch: 7/10. Loss: 0.9672:  50%|[36m█████     [0m| 13/26 [00:13<00:12,  1.04it/s]Epoch: 7/10. Loss: 0.9672:  54%|[36m█████▍    [0m| 14/26 [00:13<00:10,  1.10it/s]Epoch: 7/10. Loss: 1.0716:  54%|[36m█████▍    [0m| 14/26 [00:14<00:10,  1.10it/s]Epoch: 7/10. Loss: 1.0716:  58%|[36m█████▊    [0m| 15/26 [00:14<00:09,  1.13it/s]Epoch: 7/10. Loss: 0.9777:  58%|[36m█████▊    [0m| 15/26 [00:15<00:09,  1.13it/s]Epoch: 7/10. Loss: 0.9777:  62%|[36m██████▏   [0m| 16/26 [00:15<00:08,  1.16it/s]Epoch: 7/10. Loss: 0.9834:  62%|[36m██████▏   [0m| 16/26 [00:15<00:08,  1.16it/s]Epoch: 7/10. Loss: 0.9834:  65%|[36m██████▌   [0m| 17/26 [00:15<00:07,  1.20it/s]Epoch: 7/10. Loss: 1.0090:  65%|[36m██████▌   [0m| 17/26 [00:16<00:07,  1.20it/s]Epoch: 7/10. Loss: 1.0090:  69%|[36m██████▉   [0m| 18/26 [00:16<00:06,  1.15it/s]Epoch: 7/10. Loss: 1.0075:  69%|[36m██████▉   [0m| 18/26 [00:17<00:06,  1.15it/s]Epoch: 7/10. Loss: 1.0075:  73%|[36m███████▎  [0m| 19/26 [00:17<00:06,  1.10it/s]Epoch: 7/10. Loss: 1.0029:  73%|[36m███████▎  [0m| 19/26 [00:18<00:06,  1.10it/s]Epoch: 7/10. Loss: 1.0029:  77%|[36m███████▋  [0m| 20/26 [00:18<00:05,  1.15it/s]Epoch: 7/10. Loss: 1.0216:  77%|[36m███████▋  [0m| 20/26 [00:19<00:05,  1.15it/s]Epoch: 7/10. Loss: 1.0216:  81%|[36m████████  [0m| 21/26 [00:19<00:04,  1.14it/s]Epoch: 7/10. Loss: 0.9486:  81%|[36m████████  [0m| 21/26 [00:20<00:04,  1.14it/s]Epoch: 7/10. Loss: 0.9486:  85%|[36m████████▍ [0m| 22/26 [00:20<00:03,  1.21it/s]Epoch: 7/10. Loss: 0.9748:  85%|[36m████████▍ [0m| 22/26 [00:22<00:03,  1.21it/s]Epoch: 7/10. Loss: 0.9748:  88%|[36m████████▊ [0m| 23/26 [00:22<00:03,  1.11s/it]Epoch: 7/10. Loss: 1.0729:  88%|[36m████████▊ [0m| 23/26 [00:22<00:03,  1.11s/it]Epoch: 7/10. Loss: 1.0729:  92%|[36m█████████▏[0m| 24/26 [00:22<00:02,  1.04s/it]Epoch: 7/10. Loss: 1.1314:  92%|[36m█████████▏[0m| 24/26 [00:23<00:02,  1.04s/it]Epoch: 7/10. Loss: 1.1314:  96%|[36m█████████▌[0m| 25/26 [00:23<00:01,  1.03s/it]Epoch: 7/10. Loss: 0.9921:  96%|[36m█████████▌[0m| 25/26 [00:24<00:01,  1.03s/it]Epoch: 7/10. Loss: 0.9921: 100%|[36m██████████[0m| 26/26 [00:24<00:00,  1.10it/s]Epoch: 7/10. Loss: 0.9921: 100%|[36m██████████[0m| 26/26 [00:24<00:00,  1.06it/s]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:01<00:07,  1.22s/it] 29%|[33m██▊       [0m| 2/7 [00:03<00:08,  1.71s/it] 43%|[33m████▎     [0m| 3/7 [00:03<00:04,  1.21s/it] 57%|[33m█████▋    [0m| 4/7 [00:05<00:03,  1.23s/it] 71%|[33m███████▏  [0m| 5/7 [00:05<00:01,  1.04it/s] 86%|[33m████████▌ [0m| 6/7 [00:06<00:00,  1.09it/s]100%|[33m██████████[0m| 7/7 [00:06<00:00,  1.40it/s]100%|[33m██████████[0m| 7/7 [00:06<00:00,  1.04it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 8/10. Loss: 1.0188:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 8/10. Loss: 1.0188:   4%|[36m▍         [0m| 1/26 [00:00<00:22,  1.11it/s]Epoch: 8/10. Loss: 1.0569:   4%|[36m▍         [0m| 1/26 [00:01<00:22,  1.11it/s]Epoch: 8/10. Loss: 1.0569:   8%|[36m▊         [0m| 2/26 [00:01<00:22,  1.05it/s]Epoch: 8/10. Loss: 0.9355:   8%|[36m▊         [0m| 2/26 [00:02<00:22,  1.05it/s]Epoch: 8/10. Loss: 0.9355:  12%|[36m█▏        [0m| 3/26 [00:02<00:20,  1.10it/s]Epoch: 8/10. Loss: 1.0076:  12%|[36m█▏        [0m| 3/26 [00:03<00:20,  1.10it/s]Epoch: 8/10. Loss: 1.0076:  15%|[36m█▌        [0m| 4/26 [00:03<00:20,  1.05it/s]Epoch: 8/10. Loss: 0.9510:  15%|[36m█▌        [0m| 4/26 [00:04<00:20,  1.05it/s]Epoch: 8/10. Loss: 0.9510:  19%|[36m█▉        [0m| 5/26 [00:04<00:19,  1.06it/s]Epoch: 8/10. Loss: 1.0327:  19%|[36m█▉        [0m| 5/26 [00:05<00:19,  1.06it/s]Epoch: 8/10. Loss: 1.0327:  23%|[36m██▎       [0m| 6/26 [00:05<00:18,  1.09it/s]Epoch: 8/10. Loss: 1.0002:  23%|[36m██▎       [0m| 6/26 [00:06<00:18,  1.09it/s]Epoch: 8/10. Loss: 1.0002:  27%|[36m██▋       [0m| 7/26 [00:06<00:16,  1.18it/s]Epoch: 8/10. Loss: 1.0552:  27%|[36m██▋       [0m| 7/26 [00:07<00:16,  1.18it/s]Epoch: 8/10. Loss: 1.0552:  31%|[36m███       [0m| 8/26 [00:07<00:15,  1.13it/s]Epoch: 8/10. Loss: 1.0231:  31%|[36m███       [0m| 8/26 [00:08<00:15,  1.13it/s]Epoch: 8/10. Loss: 1.0231:  35%|[36m███▍      [0m| 9/26 [00:08<00:14,  1.17it/s]Epoch: 8/10. Loss: 1.0449:  35%|[36m███▍      [0m| 9/26 [00:08<00:14,  1.17it/s]Epoch: 8/10. Loss: 1.0449:  38%|[36m███▊      [0m| 10/26 [00:08<00:13,  1.16it/s]Epoch: 8/10. Loss: 1.0551:  38%|[36m███▊      [0m| 10/26 [00:10<00:13,  1.16it/s]Epoch: 8/10. Loss: 1.0551:  42%|[36m████▏     [0m| 11/26 [00:10<00:14,  1.00it/s]Epoch: 8/10. Loss: 0.9874:  42%|[36m████▏     [0m| 11/26 [00:11<00:14,  1.00it/s]Epoch: 8/10. Loss: 0.9874:  46%|[36m████▌     [0m| 12/26 [00:11<00:13,  1.01it/s]Epoch: 8/10. Loss: 1.0297:  46%|[36m████▌     [0m| 12/26 [00:11<00:13,  1.01it/s]Epoch: 8/10. Loss: 1.0297:  50%|[36m█████     [0m| 13/26 [00:11<00:11,  1.10it/s]Epoch: 8/10. Loss: 1.0070:  50%|[36m█████     [0m| 13/26 [00:12<00:11,  1.10it/s]Epoch: 8/10. Loss: 1.0070:  54%|[36m█████▍    [0m| 14/26 [00:12<00:10,  1.13it/s]Epoch: 8/10. Loss: 1.0260:  54%|[36m█████▍    [0m| 14/26 [00:13<00:10,  1.13it/s]Epoch: 8/10. Loss: 1.0260:  58%|[36m█████▊    [0m| 15/26 [00:13<00:10,  1.10it/s]Epoch: 8/10. Loss: 1.0068:  58%|[36m█████▊    [0m| 15/26 [00:14<00:10,  1.10it/s]Epoch: 8/10. Loss: 1.0068:  62%|[36m██████▏   [0m| 16/26 [00:14<00:08,  1.13it/s]Epoch: 8/10. Loss: 0.9853:  62%|[36m██████▏   [0m| 16/26 [00:15<00:08,  1.13it/s]Epoch: 8/10. Loss: 0.9853:  65%|[36m██████▌   [0m| 17/26 [00:15<00:07,  1.17it/s]Epoch: 8/10. Loss: 1.0107:  65%|[36m██████▌   [0m| 17/26 [00:16<00:07,  1.17it/s]Epoch: 8/10. Loss: 1.0107:  69%|[36m██████▉   [0m| 18/26 [00:16<00:07,  1.13it/s]Epoch: 8/10. Loss: 1.0724:  69%|[36m██████▉   [0m| 18/26 [00:17<00:07,  1.13it/s]Epoch: 8/10. Loss: 1.0724:  73%|[36m███████▎  [0m| 19/26 [00:17<00:05,  1.18it/s]Epoch: 8/10. Loss: 0.9691:  73%|[36m███████▎  [0m| 19/26 [00:17<00:05,  1.18it/s]Epoch: 8/10. Loss: 0.9691:  77%|[36m███████▋  [0m| 20/26 [00:17<00:05,  1.20it/s]Epoch: 8/10. Loss: 1.0304:  77%|[36m███████▋  [0m| 20/26 [00:18<00:05,  1.20it/s]Epoch: 8/10. Loss: 1.0304:  81%|[36m████████  [0m| 21/26 [00:18<00:04,  1.19it/s]Epoch: 8/10. Loss: 0.9924:  81%|[36m████████  [0m| 21/26 [00:19<00:04,  1.19it/s]Epoch: 8/10. Loss: 0.9924:  85%|[36m████████▍ [0m| 22/26 [00:19<00:03,  1.03it/s]Epoch: 8/10. Loss: 0.9955:  85%|[36m████████▍ [0m| 22/26 [00:21<00:03,  1.03it/s]Epoch: 8/10. Loss: 0.9955:  88%|[36m████████▊ [0m| 23/26 [00:21<00:03,  1.14s/it]Epoch: 8/10. Loss: 1.0056:  88%|[36m████████▊ [0m| 23/26 [00:22<00:03,  1.14s/it]Epoch: 8/10. Loss: 1.0056:  92%|[36m█████████▏[0m| 24/26 [00:22<00:02,  1.10s/it]Epoch: 8/10. Loss: 1.0779:  92%|[36m█████████▏[0m| 24/26 [00:24<00:02,  1.10s/it]Epoch: 8/10. Loss: 1.0779:  96%|[36m█████████▌[0m| 25/26 [00:24<00:01,  1.25s/it]Epoch: 8/10. Loss: 0.9713:  96%|[36m█████████▌[0m| 25/26 [00:24<00:01,  1.25s/it]Epoch: 8/10. Loss: 0.9713: 100%|[36m██████████[0m| 26/26 [00:24<00:00,  1.03s/it]Epoch: 8/10. Loss: 0.9713: 100%|[36m██████████[0m| 26/26 [00:24<00:00,  1.06it/s]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:04,  1.34it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:05,  1.09s/it] 43%|[33m████▎     [0m| 3/7 [00:02<00:03,  1.14it/s] 57%|[33m█████▋    [0m| 4/7 [00:03<00:02,  1.01it/s] 71%|[33m███████▏  [0m| 5/7 [00:04<00:01,  1.27it/s] 86%|[33m████████▌ [0m| 6/7 [00:05<00:00,  1.22it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.54it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.28it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 9/10. Loss: 1.0257:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 9/10. Loss: 1.0257:   4%|[36m▍         [0m| 1/26 [00:00<00:18,  1.32it/s]Epoch: 9/10. Loss: 0.9893:   4%|[36m▍         [0m| 1/26 [00:01<00:18,  1.32it/s]Epoch: 9/10. Loss: 0.9893:   8%|[36m▊         [0m| 2/26 [00:01<00:19,  1.24it/s]Epoch: 9/10. Loss: 1.0120:   8%|[36m▊         [0m| 2/26 [00:02<00:19,  1.24it/s]Epoch: 9/10. Loss: 1.0120:  12%|[36m█▏        [0m| 3/26 [00:02<00:19,  1.20it/s]Epoch: 9/10. Loss: 1.0192:  12%|[36m█▏        [0m| 3/26 [00:03<00:19,  1.20it/s]Epoch: 9/10. Loss: 1.0192:  15%|[36m█▌        [0m| 4/26 [00:03<00:18,  1.19it/s]Epoch: 9/10. Loss: 1.0358:  15%|[36m█▌        [0m| 4/26 [00:04<00:18,  1.19it/s]Epoch: 9/10. Loss: 1.0358:  19%|[36m█▉        [0m| 5/26 [00:04<00:17,  1.23it/s]Epoch: 9/10. Loss: 0.9997:  19%|[36m█▉        [0m| 5/26 [00:05<00:17,  1.23it/s]Epoch: 9/10. Loss: 0.9997:  23%|[36m██▎       [0m| 6/26 [00:05<00:17,  1.16it/s]Epoch: 9/10. Loss: 1.0134:  23%|[36m██▎       [0m| 6/26 [00:05<00:17,  1.16it/s]Epoch: 9/10. Loss: 1.0134:  27%|[36m██▋       [0m| 7/26 [00:05<00:16,  1.12it/s]Epoch: 9/10. Loss: 1.0094:  27%|[36m██▋       [0m| 7/26 [00:06<00:16,  1.12it/s]Epoch: 9/10. Loss: 1.0094:  31%|[36m███       [0m| 8/26 [00:06<00:16,  1.11it/s]Epoch: 9/10. Loss: 1.0143:  31%|[36m███       [0m| 8/26 [00:07<00:16,  1.11it/s]Epoch: 9/10. Loss: 1.0143:  35%|[36m███▍      [0m| 9/26 [00:07<00:15,  1.10it/s]Epoch: 9/10. Loss: 1.0534:  35%|[36m███▍      [0m| 9/26 [00:08<00:15,  1.10it/s]Epoch: 9/10. Loss: 1.0534:  38%|[36m███▊      [0m| 10/26 [00:08<00:14,  1.08it/s]Epoch: 9/10. Loss: 1.0433:  38%|[36m███▊      [0m| 10/26 [00:09<00:14,  1.08it/s]Epoch: 9/10. Loss: 1.0433:  42%|[36m████▏     [0m| 11/26 [00:09<00:14,  1.06it/s]Epoch: 9/10. Loss: 1.0010:  42%|[36m████▏     [0m| 11/26 [00:10<00:14,  1.06it/s]Epoch: 9/10. Loss: 1.0010:  46%|[36m████▌     [0m| 12/26 [00:10<00:12,  1.09it/s]Epoch: 9/10. Loss: 1.0263:  46%|[36m████▌     [0m| 12/26 [00:11<00:12,  1.09it/s]Epoch: 9/10. Loss: 1.0263:  50%|[36m█████     [0m| 13/26 [00:11<00:11,  1.11it/s]Epoch: 9/10. Loss: 1.0024:  50%|[36m█████     [0m| 13/26 [00:12<00:11,  1.11it/s]Epoch: 9/10. Loss: 1.0024:  54%|[36m█████▍    [0m| 14/26 [00:12<00:10,  1.13it/s]Epoch: 9/10. Loss: 1.0363:  54%|[36m█████▍    [0m| 14/26 [00:13<00:10,  1.13it/s]Epoch: 9/10. Loss: 1.0363:  58%|[36m█████▊    [0m| 15/26 [00:13<00:09,  1.13it/s]Epoch: 9/10. Loss: 0.9858:  58%|[36m█████▊    [0m| 15/26 [00:14<00:09,  1.13it/s]Epoch: 9/10. Loss: 0.9858:  62%|[36m██████▏   [0m| 16/26 [00:14<00:08,  1.11it/s]Epoch: 9/10. Loss: 0.9981:  62%|[36m██████▏   [0m| 16/26 [00:14<00:08,  1.11it/s]Epoch: 9/10. Loss: 0.9981:  65%|[36m██████▌   [0m| 17/26 [00:14<00:07,  1.14it/s]Epoch: 9/10. Loss: 0.9982:  65%|[36m██████▌   [0m| 17/26 [00:15<00:07,  1.14it/s]Epoch: 9/10. Loss: 0.9982:  69%|[36m██████▉   [0m| 18/26 [00:15<00:06,  1.16it/s]Epoch: 9/10. Loss: 1.0067:  69%|[36m██████▉   [0m| 18/26 [00:16<00:06,  1.16it/s]Epoch: 9/10. Loss: 1.0067:  73%|[36m███████▎  [0m| 19/26 [00:16<00:05,  1.18it/s]Epoch: 9/10. Loss: 0.9813:  73%|[36m███████▎  [0m| 19/26 [00:17<00:05,  1.18it/s]Epoch: 9/10. Loss: 0.9813:  77%|[36m███████▋  [0m| 20/26 [00:17<00:05,  1.12it/s]Epoch: 9/10. Loss: 1.0354:  77%|[36m███████▋  [0m| 20/26 [00:18<00:05,  1.12it/s]Epoch: 9/10. Loss: 1.0354:  81%|[36m████████  [0m| 21/26 [00:18<00:04,  1.13it/s]Epoch: 9/10. Loss: 1.0715:  81%|[36m████████  [0m| 21/26 [00:19<00:04,  1.13it/s]Epoch: 9/10. Loss: 1.0715:  85%|[36m████████▍ [0m| 22/26 [00:19<00:03,  1.15it/s]Epoch: 9/10. Loss: 0.9842:  85%|[36m████████▍ [0m| 22/26 [00:20<00:03,  1.15it/s]Epoch: 9/10. Loss: 0.9842:  88%|[36m████████▊ [0m| 23/26 [00:20<00:02,  1.18it/s]Epoch: 9/10. Loss: 0.9827:  88%|[36m████████▊ [0m| 23/26 [00:20<00:02,  1.18it/s]Epoch: 9/10. Loss: 0.9827:  92%|[36m█████████▏[0m| 24/26 [00:20<00:01,  1.23it/s]Epoch: 9/10. Loss: 1.0069:  92%|[36m█████████▏[0m| 24/26 [00:21<00:01,  1.23it/s]Epoch: 9/10. Loss: 1.0069:  96%|[36m█████████▌[0m| 25/26 [00:21<00:00,  1.22it/s]Epoch: 9/10. Loss: 1.0277:  96%|[36m█████████▌[0m| 25/26 [00:22<00:00,  1.22it/s]Epoch: 9/10. Loss: 1.0277: 100%|[36m██████████[0m| 26/26 [00:22<00:00,  1.22it/s]Epoch: 9/10. Loss: 1.0277: 100%|[36m██████████[0m| 26/26 [00:22<00:00,  1.16it/s]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:04,  1.25it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:05,  1.14s/it] 43%|[33m████▎     [0m| 3/7 [00:02<00:03,  1.09it/s] 57%|[33m█████▋    [0m| 4/7 [00:04<00:03,  1.02s/it] 71%|[33m███████▏  [0m| 5/7 [00:04<00:01,  1.23it/s] 86%|[33m████████▌ [0m| 6/7 [00:05<00:00,  1.20it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.52it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.25it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 0/10. Loss: 6.9976:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 0/10. Loss: 6.9976:   4%|[36m▍         [0m| 1/26 [00:00<00:23,  1.07it/s]Epoch: 0/10. Loss: 2.5121:   4%|[36m▍         [0m| 1/26 [00:01<00:23,  1.07it/s]Epoch: 0/10. Loss: 2.5121:   8%|[36m▊         [0m| 2/26 [00:01<00:24,  1.00s/it]Epoch: 0/10. Loss: 1.2326:   8%|[36m▊         [0m| 2/26 [00:02<00:24,  1.00s/it]Epoch: 0/10. Loss: 1.2326:  12%|[36m█▏        [0m| 3/26 [00:03<00:23,  1.01s/it]Epoch: 0/10. Loss: 1.3072:  12%|[36m█▏        [0m| 3/26 [00:03<00:23,  1.01s/it]Epoch: 0/10. Loss: 1.3072:  15%|[36m█▌        [0m| 4/26 [00:03<00:21,  1.01it/s]Epoch: 0/10. Loss: 1.1538:  15%|[36m█▌        [0m| 4/26 [00:04<00:21,  1.01it/s]Epoch: 0/10. Loss: 1.1538:  19%|[36m█▉        [0m| 5/26 [00:04<00:19,  1.06it/s]Epoch: 0/10. Loss: 1.0656:  19%|[36m█▉        [0m| 5/26 [00:05<00:19,  1.06it/s]Epoch: 0/10. Loss: 1.0656:  23%|[36m██▎       [0m| 6/26 [00:05<00:18,  1.06it/s]Epoch: 0/10. Loss: 1.0130:  23%|[36m██▎       [0m| 6/26 [00:06<00:18,  1.06it/s]Epoch: 0/10. Loss: 1.0130:  27%|[36m██▋       [0m| 7/26 [00:06<00:17,  1.06it/s]Epoch: 0/10. Loss: 1.1679:  27%|[36m██▋       [0m| 7/26 [00:07<00:17,  1.06it/s]Epoch: 0/10. Loss: 1.1679:  31%|[36m███       [0m| 8/26 [00:07<00:17,  1.04it/s]Epoch: 0/10. Loss: 1.0537:  31%|[36m███       [0m| 8/26 [00:08<00:17,  1.04it/s]Epoch: 0/10. Loss: 1.0537:  35%|[36m███▍      [0m| 9/26 [00:08<00:16,  1.01it/s]Epoch: 0/10. Loss: 0.9723:  35%|[36m███▍      [0m| 9/26 [00:09<00:16,  1.01it/s]Epoch: 0/10. Loss: 0.9723:  38%|[36m███▊      [0m| 10/26 [00:09<00:15,  1.05it/s]Epoch: 0/10. Loss: 1.1226:  38%|[36m███▊      [0m| 10/26 [00:10<00:15,  1.05it/s]Epoch: 0/10. Loss: 1.1226:  42%|[36m████▏     [0m| 11/26 [00:10<00:14,  1.03it/s]Epoch: 0/10. Loss: 1.0883:  42%|[36m████▏     [0m| 11/26 [00:11<00:14,  1.03it/s]Epoch: 0/10. Loss: 1.0883:  46%|[36m████▌     [0m| 12/26 [00:11<00:13,  1.03it/s]Epoch: 0/10. Loss: 1.0770:  46%|[36m████▌     [0m| 12/26 [00:12<00:13,  1.03it/s]Epoch: 0/10. Loss: 1.0770:  50%|[36m█████     [0m| 13/26 [00:12<00:13,  1.00s/it]Epoch: 0/10. Loss: 1.0666:  50%|[36m█████     [0m| 13/26 [00:13<00:13,  1.00s/it]Epoch: 0/10. Loss: 1.0666:  54%|[36m█████▍    [0m| 14/26 [00:13<00:11,  1.03it/s]Epoch: 0/10. Loss: 1.0053:  54%|[36m█████▍    [0m| 14/26 [00:14<00:11,  1.03it/s]Epoch: 0/10. Loss: 1.0053:  58%|[36m█████▊    [0m| 15/26 [00:14<00:10,  1.03it/s]Epoch: 0/10. Loss: 1.0652:  58%|[36m█████▊    [0m| 15/26 [00:15<00:10,  1.03it/s]Epoch: 0/10. Loss: 1.0652:  62%|[36m██████▏   [0m| 16/26 [00:15<00:09,  1.01it/s]Epoch: 0/10. Loss: 1.1959:  62%|[36m██████▏   [0m| 16/26 [00:16<00:09,  1.01it/s]Epoch: 0/10. Loss: 1.1959:  65%|[36m██████▌   [0m| 17/26 [00:16<00:09,  1.02s/it]Epoch: 0/10. Loss: 1.0356:  65%|[36m██████▌   [0m| 17/26 [00:17<00:09,  1.02s/it]Epoch: 0/10. Loss: 1.0356:  69%|[36m██████▉   [0m| 18/26 [00:17<00:07,  1.06it/s]Epoch: 0/10. Loss: 0.9877:  69%|[36m██████▉   [0m| 18/26 [00:18<00:07,  1.06it/s]Epoch: 0/10. Loss: 0.9877:  73%|[36m███████▎  [0m| 19/26 [00:18<00:06,  1.05it/s]Epoch: 0/10. Loss: 1.0901:  73%|[36m███████▎  [0m| 19/26 [00:19<00:06,  1.05it/s]Epoch: 0/10. Loss: 1.0901:  77%|[36m███████▋  [0m| 20/26 [00:19<00:05,  1.05it/s]Epoch: 0/10. Loss: 1.0733:  77%|[36m███████▋  [0m| 20/26 [00:20<00:05,  1.05it/s]Epoch: 0/10. Loss: 1.0733:  81%|[36m████████  [0m| 21/26 [00:20<00:04,  1.06it/s]Epoch: 0/10. Loss: 0.9947:  81%|[36m████████  [0m| 21/26 [00:21<00:04,  1.06it/s]Epoch: 0/10. Loss: 0.9947:  85%|[36m████████▍ [0m| 22/26 [00:21<00:03,  1.00it/s]Epoch: 0/10. Loss: 1.0072:  85%|[36m████████▍ [0m| 22/26 [00:22<00:03,  1.00it/s]Epoch: 0/10. Loss: 1.0072:  88%|[36m████████▊ [0m| 23/26 [00:22<00:02,  1.03it/s]Epoch: 0/10. Loss: 0.9547:  88%|[36m████████▊ [0m| 23/26 [00:23<00:02,  1.03it/s]Epoch: 0/10. Loss: 0.9547:  92%|[36m█████████▏[0m| 24/26 [00:23<00:01,  1.10it/s]Epoch: 0/10. Loss: 0.9484:  92%|[36m█████████▏[0m| 24/26 [00:24<00:01,  1.10it/s]Epoch: 0/10. Loss: 0.9484:  96%|[36m█████████▌[0m| 25/26 [00:24<00:00,  1.06it/s]Epoch: 0/10. Loss: 1.0184:  96%|[36m█████████▌[0m| 25/26 [00:24<00:00,  1.06it/s]Epoch: 0/10. Loss: 1.0184: 100%|[36m██████████[0m| 26/26 [00:25<00:00,  1.09it/s]Epoch: 0/10. Loss: 1.0184: 100%|[36m██████████[0m| 26/26 [00:25<00:00,  1.04it/s]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:05,  1.15it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:06,  1.21s/it] 43%|[33m████▎     [0m| 3/7 [00:03<00:04,  1.06s/it] 57%|[33m█████▋    [0m| 4/7 [00:04<00:03,  1.15s/it] 71%|[33m███████▏  [0m| 5/7 [00:04<00:01,  1.09it/s] 86%|[33m████████▌ [0m| 6/7 [00:06<00:01,  1.05s/it]100%|[33m██████████[0m| 7/7 [00:06<00:00,  1.23it/s]100%|[33m██████████[0m| 7/7 [00:06<00:00,  1.06it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 1/10. Loss: 1.0042:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 1/10. Loss: 1.0042:   4%|[36m▍         [0m| 1/26 [00:00<00:21,  1.14it/s]Epoch: 1/10. Loss: 1.0946:   4%|[36m▍         [0m| 1/26 [00:01<00:21,  1.14it/s]Epoch: 1/10. Loss: 1.0946:   8%|[36m▊         [0m| 2/26 [00:01<00:22,  1.06it/s]Epoch: 1/10. Loss: 0.9614:   8%|[36m▊         [0m| 2/26 [00:02<00:22,  1.06it/s]Epoch: 1/10. Loss: 0.9614:  12%|[36m█▏        [0m| 3/26 [00:02<00:22,  1.03it/s]Epoch: 1/10. Loss: 0.9009:  12%|[36m█▏        [0m| 3/26 [00:04<00:22,  1.03it/s]Epoch: 1/10. Loss: 0.9009:  15%|[36m█▌        [0m| 4/26 [00:04<00:24,  1.10s/it]Epoch: 1/10. Loss: 1.0207:  15%|[36m█▌        [0m| 4/26 [00:05<00:24,  1.10s/it]Epoch: 1/10. Loss: 1.0207:  19%|[36m█▉        [0m| 5/26 [00:05<00:21,  1.02s/it]Epoch: 1/10. Loss: 0.9279:  19%|[36m█▉        [0m| 5/26 [00:05<00:21,  1.02s/it]Epoch: 1/10. Loss: 0.9279:  23%|[36m██▎       [0m| 6/26 [00:05<00:19,  1.01it/s]Epoch: 1/10. Loss: 1.0105:  23%|[36m██▎       [0m| 6/26 [00:06<00:19,  1.01it/s]Epoch: 1/10. Loss: 1.0105:  27%|[36m██▋       [0m| 7/26 [00:06<00:18,  1.02it/s]Epoch: 1/10. Loss: 1.0014:  27%|[36m██▋       [0m| 7/26 [00:08<00:18,  1.02it/s]Epoch: 1/10. Loss: 1.0014:  31%|[36m███       [0m| 8/26 [00:08<00:19,  1.08s/it]Epoch: 1/10. Loss: 0.9510:  31%|[36m███       [0m| 8/26 [00:09<00:19,  1.08s/it]Epoch: 1/10. Loss: 0.9510:  35%|[36m███▍      [0m| 9/26 [00:09<00:17,  1.03s/it]Epoch: 1/10. Loss: 1.1215:  35%|[36m███▍      [0m| 9/26 [00:09<00:17,  1.03s/it]Epoch: 1/10. Loss: 1.1215:  38%|[36m███▊      [0m| 10/26 [00:10<00:15,  1.02it/s]Epoch: 1/10. Loss: 0.9679:  38%|[36m███▊      [0m| 10/26 [00:11<00:15,  1.02it/s]Epoch: 1/10. Loss: 0.9679:  42%|[36m████▏     [0m| 11/26 [00:11<00:15,  1.00s/it]Epoch: 1/10. Loss: 1.0635:  42%|[36m████▏     [0m| 11/26 [00:12<00:15,  1.00s/it]Epoch: 1/10. Loss: 1.0635:  46%|[36m████▌     [0m| 12/26 [00:12<00:13,  1.00it/s]Epoch: 1/10. Loss: 0.9955:  46%|[36m████▌     [0m| 12/26 [00:13<00:13,  1.00it/s]Epoch: 1/10. Loss: 0.9955:  50%|[36m█████     [0m| 13/26 [00:13<00:14,  1.10s/it]Epoch: 1/10. Loss: 0.9611:  50%|[36m█████     [0m| 13/26 [00:14<00:14,  1.10s/it]Epoch: 1/10. Loss: 0.9611:  54%|[36m█████▍    [0m| 14/26 [00:14<00:12,  1.05s/it]Epoch: 1/10. Loss: 1.0489:  54%|[36m█████▍    [0m| 14/26 [00:16<00:12,  1.05s/it]Epoch: 1/10. Loss: 1.0489:  58%|[36m█████▊    [0m| 15/26 [00:16<00:16,  1.47s/it]Epoch: 1/10. Loss: 0.9746:  58%|[36m█████▊    [0m| 15/26 [00:17<00:16,  1.47s/it]Epoch: 1/10. Loss: 0.9746:  62%|[36m██████▏   [0m| 16/26 [00:17<00:12,  1.24s/it]Epoch: 1/10. Loss: 0.9794:  62%|[36m██████▏   [0m| 16/26 [00:18<00:12,  1.24s/it]Epoch: 1/10. Loss: 0.9794:  65%|[36m██████▌   [0m| 17/26 [00:18<00:11,  1.27s/it]Epoch: 1/10. Loss: 0.9603:  65%|[36m██████▌   [0m| 17/26 [00:19<00:11,  1.27s/it]Epoch: 1/10. Loss: 0.9603:  69%|[36m██████▉   [0m| 18/26 [00:19<00:09,  1.15s/it]Epoch: 1/10. Loss: 0.9704:  69%|[36m██████▉   [0m| 18/26 [00:20<00:09,  1.15s/it]Epoch: 1/10. Loss: 0.9704:  73%|[36m███████▎  [0m| 19/26 [00:20<00:07,  1.08s/it]Epoch: 1/10. Loss: 0.9991:  73%|[36m███████▎  [0m| 19/26 [00:21<00:07,  1.08s/it]Epoch: 1/10. Loss: 0.9991:  77%|[36m███████▋  [0m| 20/26 [00:21<00:06,  1.08s/it]Epoch: 1/10. Loss: 0.8238:  77%|[36m███████▋  [0m| 20/26 [00:22<00:06,  1.08s/it]Epoch: 1/10. Loss: 0.8238:  81%|[36m████████  [0m| 21/26 [00:22<00:04,  1.03it/s]Epoch: 1/10. Loss: 1.0056:  81%|[36m████████  [0m| 21/26 [00:23<00:04,  1.03it/s]Epoch: 1/10. Loss: 1.0056:  85%|[36m████████▍ [0m| 22/26 [00:23<00:03,  1.06it/s]Epoch: 1/10. Loss: 1.0138:  85%|[36m████████▍ [0m| 22/26 [00:24<00:03,  1.06it/s]Epoch: 1/10. Loss: 1.0138:  88%|[36m████████▊ [0m| 23/26 [00:24<00:03,  1.00s/it]Epoch: 1/10. Loss: 0.9203:  88%|[36m████████▊ [0m| 23/26 [00:25<00:03,  1.00s/it]Epoch: 1/10. Loss: 0.9203:  92%|[36m█████████▏[0m| 24/26 [00:25<00:02,  1.01s/it]Epoch: 1/10. Loss: 0.9821:  92%|[36m█████████▏[0m| 24/26 [00:26<00:02,  1.01s/it]Epoch: 1/10. Loss: 0.9821:  96%|[36m█████████▌[0m| 25/26 [00:26<00:01,  1.06s/it]Epoch: 1/10. Loss: 0.9890:  96%|[36m█████████▌[0m| 25/26 [00:28<00:01,  1.06s/it]Epoch: 1/10. Loss: 0.9890: 100%|[36m██████████[0m| 26/26 [00:28<00:00,  1.26s/it]Epoch: 1/10. Loss: 0.9890: 100%|[36m██████████[0m| 26/26 [00:28<00:00,  1.09s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:02<00:17,  2.87s/it] 29%|[33m██▊       [0m| 2/7 [00:04<00:10,  2.05s/it] 43%|[33m████▎     [0m| 3/7 [00:05<00:05,  1.43s/it] 57%|[33m█████▋    [0m| 4/7 [00:06<00:04,  1.55s/it] 71%|[33m███████▏  [0m| 5/7 [00:07<00:02,  1.17s/it] 86%|[33m████████▌ [0m| 6/7 [00:08<00:01,  1.08s/it]100%|[33m██████████[0m| 7/7 [00:08<00:00,  1.20it/s]100%|[33m██████████[0m| 7/7 [00:08<00:00,  1.21s/it]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 2/10. Loss: 0.9547:   0%|[36m          [0m| 0/26 [00:02<?, ?it/s]Epoch: 2/10. Loss: 0.9547:   4%|[36m▍         [0m| 1/26 [00:02<01:00,  2.41s/it]Epoch: 2/10. Loss: 0.8945:   4%|[36m▍         [0m| 1/26 [00:03<01:00,  2.41s/it]Epoch: 2/10. Loss: 0.8945:   8%|[36m▊         [0m| 2/26 [00:03<00:36,  1.54s/it]Epoch: 2/10. Loss: 0.9538:   8%|[36m▊         [0m| 2/26 [00:04<00:36,  1.54s/it]Epoch: 2/10. Loss: 0.9538:  12%|[36m█▏        [0m| 3/26 [00:04<00:29,  1.27s/it]Epoch: 2/10. Loss: 0.8344:  12%|[36m█▏        [0m| 3/26 [00:05<00:29,  1.27s/it]Epoch: 2/10. Loss: 0.8344:  15%|[36m█▌        [0m| 4/26 [00:05<00:23,  1.07s/it]Epoch: 2/10. Loss: 1.0692:  15%|[36m█▌        [0m| 4/26 [00:05<00:23,  1.07s/it]Epoch: 2/10. Loss: 1.0692:  19%|[36m█▉        [0m| 5/26 [00:06<00:21,  1.03s/it]Epoch: 2/10. Loss: 1.0862:  19%|[36m█▉        [0m| 5/26 [00:06<00:21,  1.03s/it]Epoch: 2/10. Loss: 1.0862:  23%|[36m██▎       [0m| 6/26 [00:06<00:19,  1.01it/s]Epoch: 2/10. Loss: 0.9604:  23%|[36m██▎       [0m| 6/26 [00:07<00:19,  1.01it/s]Epoch: 2/10. Loss: 0.9604:  27%|[36m██▋       [0m| 7/26 [00:08<00:19,  1.02s/it]Epoch: 2/10. Loss: 1.0594:  27%|[36m██▋       [0m| 7/26 [00:08<00:19,  1.02s/it]Epoch: 2/10. Loss: 1.0594:  31%|[36m███       [0m| 8/26 [00:08<00:17,  1.03it/s]Epoch: 2/10. Loss: 1.0011:  31%|[36m███       [0m| 8/26 [00:09<00:17,  1.03it/s]Epoch: 2/10. Loss: 1.0011:  35%|[36m███▍      [0m| 9/26 [00:09<00:16,  1.04it/s]Epoch: 2/10. Loss: 1.1451:  35%|[36m███▍      [0m| 9/26 [00:11<00:16,  1.04it/s]Epoch: 2/10. Loss: 1.1451:  38%|[36m███▊      [0m| 10/26 [00:11<00:19,  1.21s/it]Epoch: 2/10. Loss: 1.0478:  38%|[36m███▊      [0m| 10/26 [00:12<00:19,  1.21s/it]Epoch: 2/10. Loss: 1.0478:  42%|[36m████▏     [0m| 11/26 [00:12<00:16,  1.10s/it]Epoch: 2/10. Loss: 1.0049:  42%|[36m████▏     [0m| 11/26 [00:13<00:16,  1.10s/it]Epoch: 2/10. Loss: 1.0049:  46%|[36m████▌     [0m| 12/26 [00:13<00:16,  1.19s/it]Epoch: 2/10. Loss: 0.9750:  46%|[36m████▌     [0m| 12/26 [00:15<00:16,  1.19s/it]Epoch: 2/10. Loss: 0.9750:  50%|[36m█████     [0m| 13/26 [00:15<00:16,  1.30s/it]Epoch: 2/10. Loss: 1.0850:  50%|[36m█████     [0m| 13/26 [00:16<00:16,  1.30s/it]Epoch: 2/10. Loss: 1.0850:  54%|[36m█████▍    [0m| 14/26 [00:16<00:14,  1.19s/it]Epoch: 2/10. Loss: 0.9326:  54%|[36m█████▍    [0m| 14/26 [00:17<00:14,  1.19s/it]Epoch: 2/10. Loss: 0.9326:  58%|[36m█████▊    [0m| 15/26 [00:17<00:14,  1.33s/it]Epoch: 2/10. Loss: 1.0213:  58%|[36m█████▊    [0m| 15/26 [00:18<00:14,  1.33s/it]Epoch: 2/10. Loss: 1.0213:  62%|[36m██████▏   [0m| 16/26 [00:19<00:12,  1.24s/it]Epoch: 2/10. Loss: 0.9947:  62%|[36m██████▏   [0m| 16/26 [00:19<00:12,  1.24s/it]Epoch: 2/10. Loss: 0.9947:  65%|[36m██████▌   [0m| 17/26 [00:19<00:10,  1.16s/it]Epoch: 2/10. Loss: 0.9534:  65%|[36m██████▌   [0m| 17/26 [00:20<00:10,  1.16s/it]Epoch: 2/10. Loss: 0.9534:  69%|[36m██████▉   [0m| 18/26 [00:20<00:08,  1.05s/it]Epoch: 2/10. Loss: 1.0148:  69%|[36m██████▉   [0m| 18/26 [00:21<00:08,  1.05s/it]Epoch: 2/10. Loss: 1.0148:  73%|[36m███████▎  [0m| 19/26 [00:21<00:07,  1.02s/it]Epoch: 2/10. Loss: 0.8540:  73%|[36m███████▎  [0m| 19/26 [00:22<00:07,  1.02s/it]Epoch: 2/10. Loss: 0.8540:  77%|[36m███████▋  [0m| 20/26 [00:22<00:06,  1.04s/it]Epoch: 2/10. Loss: 0.9560:  77%|[36m███████▋  [0m| 20/26 [00:23<00:06,  1.04s/it]Epoch: 2/10. Loss: 0.9560:  81%|[36m████████  [0m| 21/26 [00:23<00:05,  1.01s/it]Epoch: 2/10. Loss: 0.8829:  81%|[36m████████  [0m| 21/26 [00:25<00:05,  1.01s/it]Epoch: 2/10. Loss: 0.8829:  85%|[36m████████▍ [0m| 22/26 [00:25<00:04,  1.16s/it]Epoch: 2/10. Loss: 1.0596:  85%|[36m████████▍ [0m| 22/26 [00:26<00:04,  1.16s/it]Epoch: 2/10. Loss: 1.0596:  88%|[36m████████▊ [0m| 23/26 [00:26<00:03,  1.17s/it]Epoch: 2/10. Loss: 1.0278:  88%|[36m████████▊ [0m| 23/26 [00:27<00:03,  1.17s/it]Epoch: 2/10. Loss: 1.0278:  92%|[36m█████████▏[0m| 24/26 [00:27<00:02,  1.08s/it]Epoch: 2/10. Loss: 0.8538:  92%|[36m█████████▏[0m| 24/26 [00:29<00:02,  1.08s/it]Epoch: 2/10. Loss: 0.8538:  96%|[36m█████████▌[0m| 25/26 [00:29<00:01,  1.54s/it]Epoch: 2/10. Loss: 0.9384:  96%|[36m█████████▌[0m| 25/26 [00:30<00:01,  1.54s/it]Epoch: 2/10. Loss: 0.9384: 100%|[36m██████████[0m| 26/26 [00:30<00:00,  1.27s/it]Epoch: 2/10. Loss: 0.9384: 100%|[36m██████████[0m| 26/26 [00:30<00:00,  1.18s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:01<00:08,  1.46s/it] 29%|[33m██▊       [0m| 2/7 [00:03<00:07,  1.58s/it] 43%|[33m████▎     [0m| 3/7 [00:03<00:04,  1.18s/it] 57%|[33m█████▋    [0m| 4/7 [00:05<00:03,  1.23s/it] 71%|[33m███████▏  [0m| 5/7 [00:05<00:01,  1.04it/s] 86%|[33m████████▌ [0m| 6/7 [00:06<00:00,  1.05it/s]100%|[33m██████████[0m| 7/7 [00:06<00:00,  1.34it/s]100%|[33m██████████[0m| 7/7 [00:06<00:00,  1.02it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 3/10. Loss: 0.9581:   0%|[36m          [0m| 0/26 [00:01<?, ?it/s]Epoch: 3/10. Loss: 0.9581:   4%|[36m▍         [0m| 1/26 [00:01<00:28,  1.14s/it]Epoch: 3/10. Loss: 1.1026:   4%|[36m▍         [0m| 1/26 [00:03<00:28,  1.14s/it]Epoch: 3/10. Loss: 1.1026:   8%|[36m▊         [0m| 2/26 [00:03<00:50,  2.10s/it]Epoch: 3/10. Loss: 0.8341:   8%|[36m▊         [0m| 2/26 [00:05<00:50,  2.10s/it]Epoch: 3/10. Loss: 0.8341:  12%|[36m█▏        [0m| 3/26 [00:05<00:43,  1.90s/it]Epoch: 3/10. Loss: 1.0038:  12%|[36m█▏        [0m| 3/26 [00:06<00:43,  1.90s/it]Epoch: 3/10. Loss: 1.0038:  15%|[36m█▌        [0m| 4/26 [00:06<00:32,  1.49s/it]Epoch: 3/10. Loss: 0.9390:  15%|[36m█▌        [0m| 4/26 [00:07<00:32,  1.49s/it]Epoch: 3/10. Loss: 0.9390:  19%|[36m█▉        [0m| 5/26 [00:07<00:26,  1.28s/it]Epoch: 3/10. Loss: 0.8955:  19%|[36m█▉        [0m| 5/26 [00:08<00:26,  1.28s/it]Epoch: 3/10. Loss: 0.8955:  23%|[36m██▎       [0m| 6/26 [00:08<00:27,  1.39s/it]Epoch: 3/10. Loss: 0.9095:  23%|[36m██▎       [0m| 6/26 [00:09<00:27,  1.39s/it]Epoch: 3/10. Loss: 0.9095:  27%|[36m██▋       [0m| 7/26 [00:09<00:23,  1.23s/it]Epoch: 3/10. Loss: 1.0425:  27%|[36m██▋       [0m| 7/26 [00:10<00:23,  1.23s/it]Epoch: 3/10. Loss: 1.0425:  31%|[36m███       [0m| 8/26 [00:10<00:21,  1.21s/it]Epoch: 3/10. Loss: 1.1163:  31%|[36m███       [0m| 8/26 [00:11<00:21,  1.21s/it]Epoch: 3/10. Loss: 1.1163:  35%|[36m███▍      [0m| 9/26 [00:11<00:19,  1.14s/it]Epoch: 3/10. Loss: 0.9408:  35%|[36m███▍      [0m| 9/26 [00:12<00:19,  1.14s/it]Epoch: 3/10. Loss: 0.9408:  38%|[36m███▊      [0m| 10/26 [00:12<00:17,  1.07s/it]Epoch: 3/10. Loss: 1.0701:  38%|[36m███▊      [0m| 10/26 [00:13<00:17,  1.07s/it]Epoch: 3/10. Loss: 1.0701:  42%|[36m████▏     [0m| 11/26 [00:13<00:15,  1.02s/it]Epoch: 3/10. Loss: 0.8434:  42%|[36m████▏     [0m| 11/26 [00:14<00:15,  1.02s/it]Epoch: 3/10. Loss: 0.8434:  46%|[36m████▌     [0m| 12/26 [00:14<00:14,  1.01s/it]Epoch: 3/10. Loss: 0.9151:  46%|[36m████▌     [0m| 12/26 [00:15<00:14,  1.01s/it]Epoch: 3/10. Loss: 0.9151:  50%|[36m█████     [0m| 13/26 [00:15<00:13,  1.00s/it]Epoch: 3/10. Loss: 0.9722:  50%|[36m█████     [0m| 13/26 [00:16<00:13,  1.00s/it]Epoch: 3/10. Loss: 0.9722:  54%|[36m█████▍    [0m| 14/26 [00:16<00:11,  1.05it/s]Epoch: 3/10. Loss: 0.9590:  54%|[36m█████▍    [0m| 14/26 [00:17<00:11,  1.05it/s]Epoch: 3/10. Loss: 0.9590:  58%|[36m█████▊    [0m| 15/26 [00:17<00:10,  1.05it/s]Epoch: 3/10. Loss: 0.9687:  58%|[36m█████▊    [0m| 15/26 [00:18<00:10,  1.05it/s]Epoch: 3/10. Loss: 0.9687:  62%|[36m██████▏   [0m| 16/26 [00:18<00:09,  1.04it/s]Epoch: 3/10. Loss: 0.9001:  62%|[36m██████▏   [0m| 16/26 [00:19<00:09,  1.04it/s]Epoch: 3/10. Loss: 0.9001:  65%|[36m██████▌   [0m| 17/26 [00:19<00:08,  1.05it/s]Epoch: 3/10. Loss: 0.9439:  65%|[36m██████▌   [0m| 17/26 [00:20<00:08,  1.05it/s]Epoch: 3/10. Loss: 0.9439:  69%|[36m██████▉   [0m| 18/26 [00:20<00:07,  1.06it/s]Epoch: 3/10. Loss: 0.9133:  69%|[36m██████▉   [0m| 18/26 [00:21<00:07,  1.06it/s]Epoch: 3/10. Loss: 0.9133:  73%|[36m███████▎  [0m| 19/26 [00:21<00:06,  1.09it/s]Epoch: 3/10. Loss: 0.9291:  73%|[36m███████▎  [0m| 19/26 [00:22<00:06,  1.09it/s]Epoch: 3/10. Loss: 0.9291:  77%|[36m███████▋  [0m| 20/26 [00:22<00:05,  1.12it/s]Epoch: 3/10. Loss: 0.9288:  77%|[36m███████▋  [0m| 20/26 [00:23<00:05,  1.12it/s]Epoch: 3/10. Loss: 0.9288:  81%|[36m████████  [0m| 21/26 [00:23<00:04,  1.09it/s]Epoch: 3/10. Loss: 0.9223:  81%|[36m████████  [0m| 21/26 [00:24<00:04,  1.09it/s]Epoch: 3/10. Loss: 0.9223:  85%|[36m████████▍ [0m| 22/26 [00:24<00:03,  1.07it/s]Epoch: 3/10. Loss: 0.9428:  85%|[36m████████▍ [0m| 22/26 [00:24<00:03,  1.07it/s]Epoch: 3/10. Loss: 0.9428:  88%|[36m████████▊ [0m| 23/26 [00:25<00:02,  1.06it/s]Epoch: 3/10. Loss: 0.9146:  88%|[36m████████▊ [0m| 23/26 [00:25<00:02,  1.06it/s]Epoch: 3/10. Loss: 0.9146:  92%|[36m█████████▏[0m| 24/26 [00:25<00:01,  1.09it/s]Epoch: 3/10. Loss: 0.9429:  92%|[36m█████████▏[0m| 24/26 [00:26<00:01,  1.09it/s]Epoch: 3/10. Loss: 0.9429:  96%|[36m█████████▌[0m| 25/26 [00:26<00:00,  1.11it/s]Epoch: 3/10. Loss: 0.9927:  96%|[36m█████████▌[0m| 25/26 [00:27<00:00,  1.11it/s]Epoch: 3/10. Loss: 0.9927: 100%|[36m██████████[0m| 26/26 [00:27<00:00,  1.18it/s]Epoch: 3/10. Loss: 0.9927: 100%|[36m██████████[0m| 26/26 [00:27<00:00,  1.06s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:05,  1.10it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:06,  1.24s/it] 43%|[33m████▎     [0m| 3/7 [00:03<00:04,  1.01s/it] 57%|[33m█████▋    [0m| 4/7 [00:04<00:03,  1.11s/it] 71%|[33m███████▏  [0m| 5/7 [00:04<00:01,  1.12it/s] 86%|[33m████████▌ [0m| 6/7 [00:05<00:00,  1.12it/s]100%|[33m██████████[0m| 7/7 [00:06<00:00,  1.42it/s]100%|[33m██████████[0m| 7/7 [00:06<00:00,  1.15it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 4/10. Loss: 0.8980:   0%|[36m          [0m| 0/26 [00:01<?, ?it/s]Epoch: 4/10. Loss: 0.8980:   4%|[36m▍         [0m| 1/26 [00:01<00:32,  1.29s/it]Epoch: 4/10. Loss: 0.8636:   4%|[36m▍         [0m| 1/26 [00:02<00:32,  1.29s/it]Epoch: 4/10. Loss: 0.8636:   8%|[36m▊         [0m| 2/26 [00:02<00:24,  1.01s/it]Epoch: 4/10. Loss: 1.0272:   8%|[36m▊         [0m| 2/26 [00:04<00:24,  1.01s/it]Epoch: 4/10. Loss: 1.0272:  12%|[36m█▏        [0m| 3/26 [00:05<00:43,  1.89s/it]Epoch: 4/10. Loss: 0.8375:  12%|[36m█▏        [0m| 3/26 [00:06<00:43,  1.89s/it]Epoch: 4/10. Loss: 0.8375:  15%|[36m█▌        [0m| 4/26 [00:06<00:40,  1.83s/it]Epoch: 4/10. Loss: 0.9934:  15%|[36m█▌        [0m| 4/26 [00:07<00:40,  1.83s/it]Epoch: 4/10. Loss: 0.9934:  19%|[36m█▉        [0m| 5/26 [00:07<00:31,  1.49s/it]Epoch: 4/10. Loss: 0.9989:  19%|[36m█▉        [0m| 5/26 [00:08<00:31,  1.49s/it]Epoch: 4/10. Loss: 0.9989:  23%|[36m██▎       [0m| 6/26 [00:08<00:25,  1.27s/it]Epoch: 4/10. Loss: 0.9314:  23%|[36m██▎       [0m| 6/26 [00:09<00:25,  1.27s/it]Epoch: 4/10. Loss: 0.9314:  27%|[36m██▋       [0m| 7/26 [00:09<00:22,  1.20s/it]Epoch: 4/10. Loss: 0.8612:  27%|[36m██▋       [0m| 7/26 [00:10<00:22,  1.20s/it]Epoch: 4/10. Loss: 0.8612:  31%|[36m███       [0m| 8/26 [00:10<00:19,  1.07s/it]Epoch: 4/10. Loss: 0.9653:  31%|[36m███       [0m| 8/26 [00:11<00:19,  1.07s/it]Epoch: 4/10. Loss: 0.9653:  35%|[36m███▍      [0m| 9/26 [00:11<00:16,  1.01it/s]Epoch: 4/10. Loss: 0.8991:  35%|[36m███▍      [0m| 9/26 [00:11<00:16,  1.01it/s]Epoch: 4/10. Loss: 0.8991:  38%|[36m███▊      [0m| 10/26 [00:11<00:14,  1.11it/s]Epoch: 4/10. Loss: 0.8963:  38%|[36m███▊      [0m| 10/26 [00:12<00:14,  1.11it/s]Epoch: 4/10. Loss: 0.8963:  42%|[36m████▏     [0m| 11/26 [00:12<00:13,  1.08it/s]Epoch: 4/10. Loss: 0.8390:  42%|[36m████▏     [0m| 11/26 [00:13<00:13,  1.08it/s]Epoch: 4/10. Loss: 0.8390:  46%|[36m████▌     [0m| 12/26 [00:13<00:12,  1.10it/s]Epoch: 4/10. Loss: 0.9725:  46%|[36m████▌     [0m| 12/26 [00:14<00:12,  1.10it/s]Epoch: 4/10. Loss: 0.9725:  50%|[36m█████     [0m| 13/26 [00:14<00:11,  1.11it/s]Epoch: 4/10. Loss: 0.8742:  50%|[36m█████     [0m| 13/26 [00:15<00:11,  1.11it/s]Epoch: 4/10. Loss: 0.8742:  54%|[36m█████▍    [0m| 14/26 [00:15<00:11,  1.05it/s]Epoch: 4/10. Loss: 0.9308:  54%|[36m█████▍    [0m| 14/26 [00:16<00:11,  1.05it/s]Epoch: 4/10. Loss: 0.9308:  58%|[36m█████▊    [0m| 15/26 [00:16<00:10,  1.06it/s]Epoch: 4/10. Loss: 0.9694:  58%|[36m█████▊    [0m| 15/26 [00:17<00:10,  1.06it/s]Epoch: 4/10. Loss: 0.9694:  62%|[36m██████▏   [0m| 16/26 [00:17<00:09,  1.03it/s]Epoch: 4/10. Loss: 0.8938:  62%|[36m██████▏   [0m| 16/26 [00:18<00:09,  1.03it/s]Epoch: 4/10. Loss: 0.8938:  65%|[36m██████▌   [0m| 17/26 [00:18<00:08,  1.05it/s]Epoch: 4/10. Loss: 0.8440:  65%|[36m██████▌   [0m| 17/26 [00:19<00:08,  1.05it/s]Epoch: 4/10. Loss: 0.8440:  69%|[36m██████▉   [0m| 18/26 [00:19<00:08,  1.08s/it]Epoch: 4/10. Loss: 0.8426:  69%|[36m██████▉   [0m| 18/26 [00:20<00:08,  1.08s/it]Epoch: 4/10. Loss: 0.8426:  73%|[36m███████▎  [0m| 19/26 [00:20<00:07,  1.04s/it]Epoch: 4/10. Loss: 0.8630:  73%|[36m███████▎  [0m| 19/26 [00:21<00:07,  1.04s/it]Epoch: 4/10. Loss: 0.8630:  77%|[36m███████▋  [0m| 20/26 [00:21<00:06,  1.03s/it]Epoch: 4/10. Loss: 0.9084:  77%|[36m███████▋  [0m| 20/26 [00:22<00:06,  1.03s/it]Epoch: 4/10. Loss: 0.9084:  81%|[36m████████  [0m| 21/26 [00:22<00:04,  1.02it/s]Epoch: 4/10. Loss: 1.0215:  81%|[36m████████  [0m| 21/26 [00:23<00:04,  1.02it/s]Epoch: 4/10. Loss: 1.0215:  85%|[36m████████▍ [0m| 22/26 [00:23<00:03,  1.03it/s]Epoch: 4/10. Loss: 0.8310:  85%|[36m████████▍ [0m| 22/26 [00:24<00:03,  1.03it/s]Epoch: 4/10. Loss: 0.8310:  88%|[36m████████▊ [0m| 23/26 [00:24<00:02,  1.03it/s]Epoch: 4/10. Loss: 0.8770:  88%|[36m████████▊ [0m| 23/26 [00:25<00:02,  1.03it/s]Epoch: 4/10. Loss: 0.8770:  92%|[36m█████████▏[0m| 24/26 [00:25<00:01,  1.07it/s]Epoch: 4/10. Loss: 0.8881:  92%|[36m█████████▏[0m| 24/26 [00:26<00:01,  1.07it/s]Epoch: 4/10. Loss: 0.8881:  96%|[36m█████████▌[0m| 25/26 [00:26<00:00,  1.04it/s]Epoch: 4/10. Loss: 0.8558:  96%|[36m█████████▌[0m| 25/26 [00:27<00:00,  1.04it/s]Epoch: 4/10. Loss: 0.8558: 100%|[36m██████████[0m| 26/26 [00:27<00:00,  1.15it/s]Epoch: 4/10. Loss: 0.8558: 100%|[36m██████████[0m| 26/26 [00:27<00:00,  1.05s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:05,  1.16it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:05,  1.20s/it] 43%|[33m████▎     [0m| 3/7 [00:03<00:03,  1.01it/s] 57%|[33m█████▋    [0m| 4/7 [00:04<00:03,  1.07s/it] 71%|[33m███████▏  [0m| 5/7 [00:04<00:01,  1.20it/s] 86%|[33m████████▌ [0m| 6/7 [00:05<00:00,  1.21it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.54it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.22it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 5/10. Loss: 0.7908:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 5/10. Loss: 0.7908:   4%|[36m▍         [0m| 1/26 [00:00<00:24,  1.04it/s]Epoch: 5/10. Loss: 0.9620:   4%|[36m▍         [0m| 1/26 [00:01<00:24,  1.04it/s]Epoch: 5/10. Loss: 0.9620:   8%|[36m▊         [0m| 2/26 [00:01<00:23,  1.00it/s]Epoch: 5/10. Loss: 0.7719:   8%|[36m▊         [0m| 2/26 [00:02<00:23,  1.00it/s]Epoch: 5/10. Loss: 0.7719:  12%|[36m█▏        [0m| 3/26 [00:02<00:22,  1.01it/s]Epoch: 5/10. Loss: 0.7901:  12%|[36m█▏        [0m| 3/26 [00:03<00:22,  1.01it/s]Epoch: 5/10. Loss: 0.7901:  15%|[36m█▌        [0m| 4/26 [00:03<00:21,  1.03it/s]Epoch: 5/10. Loss: 0.8308:  15%|[36m█▌        [0m| 4/26 [00:04<00:21,  1.03it/s]Epoch: 5/10. Loss: 0.8308:  19%|[36m█▉        [0m| 5/26 [00:04<00:19,  1.06it/s]Epoch: 5/10. Loss: 0.9114:  19%|[36m█▉        [0m| 5/26 [00:06<00:19,  1.06it/s]Epoch: 5/10. Loss: 0.9114:  23%|[36m██▎       [0m| 6/26 [00:06<00:22,  1.15s/it]Epoch: 5/10. Loss: 0.9253:  23%|[36m██▎       [0m| 6/26 [00:07<00:22,  1.15s/it]Epoch: 5/10. Loss: 0.9253:  27%|[36m██▋       [0m| 7/26 [00:07<00:19,  1.05s/it]Epoch: 5/10. Loss: 0.9185:  27%|[36m██▋       [0m| 7/26 [00:08<00:19,  1.05s/it]Epoch: 5/10. Loss: 0.9185:  31%|[36m███       [0m| 8/26 [00:08<00:17,  1.01it/s]Epoch: 5/10. Loss: 0.9284:  31%|[36m███       [0m| 8/26 [00:09<00:17,  1.01it/s]Epoch: 5/10. Loss: 0.9284:  35%|[36m███▍      [0m| 9/26 [00:09<00:16,  1.00it/s]Epoch: 5/10. Loss: 0.9517:  35%|[36m███▍      [0m| 9/26 [00:10<00:16,  1.00it/s]Epoch: 5/10. Loss: 0.9517:  38%|[36m███▊      [0m| 10/26 [00:10<00:15,  1.01it/s]Epoch: 5/10. Loss: 0.9482:  38%|[36m███▊      [0m| 10/26 [00:10<00:15,  1.01it/s]Epoch: 5/10. Loss: 0.9482:  42%|[36m████▏     [0m| 11/26 [00:10<00:14,  1.04it/s]Epoch: 5/10. Loss: 0.8947:  42%|[36m████▏     [0m| 11/26 [00:11<00:14,  1.04it/s]Epoch: 5/10. Loss: 0.8947:  46%|[36m████▌     [0m| 12/26 [00:11<00:12,  1.10it/s]Epoch: 5/10. Loss: 0.9032:  46%|[36m████▌     [0m| 12/26 [00:12<00:12,  1.10it/s]Epoch: 5/10. Loss: 0.9032:  50%|[36m█████     [0m| 13/26 [00:12<00:11,  1.12it/s]Epoch: 5/10. Loss: 0.8224:  50%|[36m█████     [0m| 13/26 [00:13<00:11,  1.12it/s]Epoch: 5/10. Loss: 0.8224:  54%|[36m█████▍    [0m| 14/26 [00:13<00:10,  1.11it/s]Epoch: 5/10. Loss: 0.9005:  54%|[36m█████▍    [0m| 14/26 [00:14<00:10,  1.11it/s]Epoch: 5/10. Loss: 0.9005:  58%|[36m█████▊    [0m| 15/26 [00:14<00:10,  1.06it/s]Epoch: 5/10. Loss: 0.8914:  58%|[36m█████▊    [0m| 15/26 [00:15<00:10,  1.06it/s]Epoch: 5/10. Loss: 0.8914:  62%|[36m██████▏   [0m| 16/26 [00:15<00:09,  1.01it/s]Epoch: 5/10. Loss: 0.9472:  62%|[36m██████▏   [0m| 16/26 [00:16<00:09,  1.01it/s]Epoch: 5/10. Loss: 0.9472:  65%|[36m██████▌   [0m| 17/26 [00:16<00:08,  1.06it/s]Epoch: 5/10. Loss: 0.9249:  65%|[36m██████▌   [0m| 17/26 [00:17<00:08,  1.06it/s]Epoch: 5/10. Loss: 0.9249:  69%|[36m██████▉   [0m| 18/26 [00:17<00:07,  1.06it/s]Epoch: 5/10. Loss: 0.7977:  69%|[36m██████▉   [0m| 18/26 [00:18<00:07,  1.06it/s]Epoch: 5/10. Loss: 0.7977:  73%|[36m███████▎  [0m| 19/26 [00:18<00:06,  1.09it/s]Epoch: 5/10. Loss: 0.9375:  73%|[36m███████▎  [0m| 19/26 [00:19<00:06,  1.09it/s]Epoch: 5/10. Loss: 0.9375:  77%|[36m███████▋  [0m| 20/26 [00:19<00:05,  1.07it/s]Epoch: 5/10. Loss: 0.9053:  77%|[36m███████▋  [0m| 20/26 [00:20<00:05,  1.07it/s]Epoch: 5/10. Loss: 0.9053:  81%|[36m████████  [0m| 21/26 [00:20<00:05,  1.03s/it]Epoch: 5/10. Loss: 0.8597:  81%|[36m████████  [0m| 21/26 [00:21<00:05,  1.03s/it]Epoch: 5/10. Loss: 0.8597:  85%|[36m████████▍ [0m| 22/26 [00:21<00:04,  1.03s/it]Epoch: 5/10. Loss: 0.8878:  85%|[36m████████▍ [0m| 22/26 [00:22<00:04,  1.03s/it]Epoch: 5/10. Loss: 0.8878:  88%|[36m████████▊ [0m| 23/26 [00:22<00:03,  1.01s/it]Epoch: 5/10. Loss: 0.9368:  88%|[36m████████▊ [0m| 23/26 [00:23<00:03,  1.01s/it]Epoch: 5/10. Loss: 0.9368:  92%|[36m█████████▏[0m| 24/26 [00:23<00:01,  1.04it/s]Epoch: 5/10. Loss: 0.8955:  92%|[36m█████████▏[0m| 24/26 [00:24<00:01,  1.04it/s]Epoch: 5/10. Loss: 0.8955:  96%|[36m█████████▌[0m| 25/26 [00:24<00:00,  1.03it/s]Epoch: 5/10. Loss: 0.9612:  96%|[36m█████████▌[0m| 25/26 [00:24<00:00,  1.03it/s]Epoch: 5/10. Loss: 0.9612: 100%|[36m██████████[0m| 26/26 [00:25<00:00,  1.13it/s]Epoch: 5/10. Loss: 0.9612: 100%|[36m██████████[0m| 26/26 [00:25<00:00,  1.04it/s]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:05,  1.14it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:06,  1.22s/it] 43%|[33m████▎     [0m| 3/7 [00:03<00:04,  1.00s/it] 57%|[33m█████▋    [0m| 4/7 [00:04<00:03,  1.16s/it] 71%|[33m███████▏  [0m| 5/7 [00:04<00:01,  1.12it/s] 86%|[33m████████▌ [0m| 6/7 [00:05<00:00,  1.13it/s]100%|[33m██████████[0m| 7/7 [00:06<00:00,  1.45it/s]100%|[33m██████████[0m| 7/7 [00:06<00:00,  1.15it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 6/10. Loss: 0.8341:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 6/10. Loss: 0.8341:   4%|[36m▍         [0m| 1/26 [00:00<00:20,  1.24it/s]Epoch: 6/10. Loss: 0.8128:   4%|[36m▍         [0m| 1/26 [00:01<00:20,  1.24it/s]Epoch: 6/10. Loss: 0.8128:   8%|[36m▊         [0m| 2/26 [00:01<00:22,  1.08it/s]Epoch: 6/10. Loss: 0.8263:   8%|[36m▊         [0m| 2/26 [00:02<00:22,  1.08it/s]Epoch: 6/10. Loss: 0.8263:  12%|[36m█▏        [0m| 3/26 [00:02<00:22,  1.04it/s]Epoch: 6/10. Loss: 0.9155:  12%|[36m█▏        [0m| 3/26 [00:03<00:22,  1.04it/s]Epoch: 6/10. Loss: 0.9155:  15%|[36m█▌        [0m| 4/26 [00:03<00:20,  1.08it/s]Epoch: 6/10. Loss: 0.9689:  15%|[36m█▌        [0m| 4/26 [00:04<00:20,  1.08it/s]Epoch: 6/10. Loss: 0.9689:  19%|[36m█▉        [0m| 5/26 [00:04<00:19,  1.07it/s]Epoch: 6/10. Loss: 0.7805:  19%|[36m█▉        [0m| 5/26 [00:06<00:19,  1.07it/s]Epoch: 6/10. Loss: 0.7805:  23%|[36m██▎       [0m| 6/26 [00:06<00:22,  1.11s/it]Epoch: 6/10. Loss: 0.9017:  23%|[36m██▎       [0m| 6/26 [00:07<00:22,  1.11s/it]Epoch: 6/10. Loss: 0.9017:  27%|[36m██▋       [0m| 7/26 [00:07<00:20,  1.06s/it]Epoch: 6/10. Loss: 0.9292:  27%|[36m██▋       [0m| 7/26 [00:07<00:20,  1.06s/it]Epoch: 6/10. Loss: 0.9292:  31%|[36m███       [0m| 8/26 [00:07<00:18,  1.01s/it]Epoch: 6/10. Loss: 0.9058:  31%|[36m███       [0m| 8/26 [00:08<00:18,  1.01s/it]Epoch: 6/10. Loss: 0.9058:  35%|[36m███▍      [0m| 9/26 [00:08<00:16,  1.06it/s]Epoch: 6/10. Loss: 0.7887:  35%|[36m███▍      [0m| 9/26 [00:09<00:16,  1.06it/s]Epoch: 6/10. Loss: 0.7887:  38%|[36m███▊      [0m| 10/26 [00:09<00:15,  1.04it/s]Epoch: 6/10. Loss: 0.8764:  38%|[36m███▊      [0m| 10/26 [00:10<00:15,  1.04it/s]Epoch: 6/10. Loss: 0.8764:  42%|[36m████▏     [0m| 11/26 [00:10<00:14,  1.05it/s]Epoch: 6/10. Loss: 0.7974:  42%|[36m████▏     [0m| 11/26 [00:11<00:14,  1.05it/s]Epoch: 6/10. Loss: 0.7974:  46%|[36m████▌     [0m| 12/26 [00:11<00:13,  1.05it/s]Epoch: 6/10. Loss: 0.9405:  46%|[36m████▌     [0m| 12/26 [00:12<00:13,  1.05it/s]Epoch: 6/10. Loss: 0.9405:  50%|[36m█████     [0m| 13/26 [00:12<00:12,  1.02it/s]Epoch: 6/10. Loss: 0.8863:  50%|[36m█████     [0m| 13/26 [00:13<00:12,  1.02it/s]Epoch: 6/10. Loss: 0.8863:  54%|[36m█████▍    [0m| 14/26 [00:13<00:11,  1.01it/s]Epoch: 6/10. Loss: 0.8004:  54%|[36m█████▍    [0m| 14/26 [00:14<00:11,  1.01it/s]Epoch: 6/10. Loss: 0.8004:  58%|[36m█████▊    [0m| 15/26 [00:14<00:10,  1.05it/s]Epoch: 6/10. Loss: 0.8529:  58%|[36m█████▊    [0m| 15/26 [00:15<00:10,  1.05it/s]Epoch: 6/10. Loss: 0.8529:  62%|[36m██████▏   [0m| 16/26 [00:15<00:09,  1.07it/s]Epoch: 6/10. Loss: 0.9650:  62%|[36m██████▏   [0m| 16/26 [00:16<00:09,  1.07it/s]Epoch: 6/10. Loss: 0.9650:  65%|[36m██████▌   [0m| 17/26 [00:16<00:08,  1.03it/s]Epoch: 6/10. Loss: 0.8803:  65%|[36m██████▌   [0m| 17/26 [00:17<00:08,  1.03it/s]Epoch: 6/10. Loss: 0.8803:  69%|[36m██████▉   [0m| 18/26 [00:17<00:07,  1.04it/s]Epoch: 6/10. Loss: 0.8897:  69%|[36m██████▉   [0m| 18/26 [00:18<00:07,  1.04it/s]Epoch: 6/10. Loss: 0.8897:  73%|[36m███████▎  [0m| 19/26 [00:18<00:06,  1.03it/s]Epoch: 6/10. Loss: 0.8388:  73%|[36m███████▎  [0m| 19/26 [00:19<00:06,  1.03it/s]Epoch: 6/10. Loss: 0.8388:  77%|[36m███████▋  [0m| 20/26 [00:19<00:05,  1.01it/s]Epoch: 6/10. Loss: 0.8972:  77%|[36m███████▋  [0m| 20/26 [00:20<00:05,  1.01it/s]Epoch: 6/10. Loss: 0.8972:  81%|[36m████████  [0m| 21/26 [00:20<00:05,  1.02s/it]Epoch: 6/10. Loss: 0.9342:  81%|[36m████████  [0m| 21/26 [00:22<00:05,  1.02s/it]Epoch: 6/10. Loss: 0.9342:  85%|[36m████████▍ [0m| 22/26 [00:22<00:04,  1.16s/it]Epoch: 6/10. Loss: 0.7987:  85%|[36m████████▍ [0m| 22/26 [00:22<00:04,  1.16s/it]Epoch: 6/10. Loss: 0.7987:  88%|[36m████████▊ [0m| 23/26 [00:22<00:03,  1.06s/it]Epoch: 6/10. Loss: 0.7864:  88%|[36m████████▊ [0m| 23/26 [00:23<00:03,  1.06s/it]Epoch: 6/10. Loss: 0.7864:  92%|[36m█████████▏[0m| 24/26 [00:23<00:02,  1.03s/it]Epoch: 6/10. Loss: 0.8927:  92%|[36m█████████▏[0m| 24/26 [00:24<00:02,  1.03s/it]Epoch: 6/10. Loss: 0.8927:  96%|[36m█████████▌[0m| 25/26 [00:24<00:01,  1.00s/it]Epoch: 6/10. Loss: 0.9032:  96%|[36m█████████▌[0m| 25/26 [00:25<00:01,  1.00s/it]Epoch: 6/10. Loss: 0.9032: 100%|[36m██████████[0m| 26/26 [00:25<00:00,  1.12it/s]Epoch: 6/10. Loss: 0.9032: 100%|[36m██████████[0m| 26/26 [00:25<00:00,  1.02it/s]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:04,  1.29it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:05,  1.11s/it] 43%|[33m████▎     [0m| 3/7 [00:02<00:03,  1.11it/s] 57%|[33m█████▋    [0m| 4/7 [00:03<00:03,  1.02s/it] 71%|[33m███████▏  [0m| 5/7 [00:04<00:01,  1.23it/s] 86%|[33m████████▌ [0m| 6/7 [00:05<00:00,  1.20it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.52it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.25it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 7/10. Loss: 0.8753:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 7/10. Loss: 0.8753:   4%|[36m▍         [0m| 1/26 [00:00<00:21,  1.14it/s]Epoch: 7/10. Loss: 0.7910:   4%|[36m▍         [0m| 1/26 [00:01<00:21,  1.14it/s]Epoch: 7/10. Loss: 0.7910:   8%|[36m▊         [0m| 2/26 [00:01<00:23,  1.03it/s]Epoch: 7/10. Loss: 0.8271:   8%|[36m▊         [0m| 2/26 [00:02<00:23,  1.03it/s]Epoch: 7/10. Loss: 0.8271:  12%|[36m█▏        [0m| 3/26 [00:02<00:21,  1.07it/s]Epoch: 7/10. Loss: 0.8841:  12%|[36m█▏        [0m| 3/26 [00:03<00:21,  1.07it/s]Epoch: 7/10. Loss: 0.8841:  15%|[36m█▌        [0m| 4/26 [00:03<00:20,  1.06it/s]Epoch: 7/10. Loss: 0.8627:  15%|[36m█▌        [0m| 4/26 [00:04<00:20,  1.06it/s]Epoch: 7/10. Loss: 0.8627:  19%|[36m█▉        [0m| 5/26 [00:04<00:19,  1.08it/s]Epoch: 7/10. Loss: 0.8191:  19%|[36m█▉        [0m| 5/26 [00:05<00:19,  1.08it/s]Epoch: 7/10. Loss: 0.8191:  23%|[36m██▎       [0m| 6/26 [00:05<00:18,  1.10it/s]Epoch: 7/10. Loss: 0.8148:  23%|[36m██▎       [0m| 6/26 [00:06<00:18,  1.10it/s]Epoch: 7/10. Loss: 0.8148:  27%|[36m██▋       [0m| 7/26 [00:06<00:18,  1.04it/s]Epoch: 7/10. Loss: 0.9390:  27%|[36m██▋       [0m| 7/26 [00:07<00:18,  1.04it/s]Epoch: 7/10. Loss: 0.9390:  31%|[36m███       [0m| 8/26 [00:07<00:16,  1.09it/s]Epoch: 7/10. Loss: 0.8265:  31%|[36m███       [0m| 8/26 [00:08<00:16,  1.09it/s]Epoch: 7/10. Loss: 0.8265:  35%|[36m███▍      [0m| 9/26 [00:08<00:15,  1.07it/s]Epoch: 7/10. Loss: 0.8776:  35%|[36m███▍      [0m| 9/26 [00:09<00:15,  1.07it/s]Epoch: 7/10. Loss: 0.8776:  38%|[36m███▊      [0m| 10/26 [00:09<00:14,  1.08it/s]Epoch: 7/10. Loss: 0.8685:  38%|[36m███▊      [0m| 10/26 [00:10<00:14,  1.08it/s]Epoch: 7/10. Loss: 0.8685:  42%|[36m████▏     [0m| 11/26 [00:10<00:14,  1.05it/s]Epoch: 7/10. Loss: 0.9447:  42%|[36m████▏     [0m| 11/26 [00:11<00:14,  1.05it/s]Epoch: 7/10. Loss: 0.9447:  46%|[36m████▌     [0m| 12/26 [00:11<00:13,  1.02it/s]Epoch: 7/10. Loss: 0.9435:  46%|[36m████▌     [0m| 12/26 [00:12<00:13,  1.02it/s]Epoch: 7/10. Loss: 0.9435:  50%|[36m█████     [0m| 13/26 [00:12<00:12,  1.02it/s]Epoch: 7/10. Loss: 0.9272:  50%|[36m█████     [0m| 13/26 [00:13<00:12,  1.02it/s]Epoch: 7/10. Loss: 0.9272:  54%|[36m█████▍    [0m| 14/26 [00:13<00:11,  1.01it/s]Epoch: 7/10. Loss: 0.7645:  54%|[36m█████▍    [0m| 14/26 [00:14<00:11,  1.01it/s]Epoch: 7/10. Loss: 0.7645:  58%|[36m█████▊    [0m| 15/26 [00:14<00:10,  1.03it/s]Epoch: 7/10. Loss: 0.8191:  58%|[36m█████▊    [0m| 15/26 [00:15<00:10,  1.03it/s]Epoch: 7/10. Loss: 0.8191:  62%|[36m██████▏   [0m| 16/26 [00:15<00:09,  1.04it/s]Epoch: 7/10. Loss: 0.8726:  62%|[36m██████▏   [0m| 16/26 [00:16<00:09,  1.04it/s]Epoch: 7/10. Loss: 0.8726:  65%|[36m██████▌   [0m| 17/26 [00:16<00:08,  1.02it/s]Epoch: 7/10. Loss: 0.9382:  65%|[36m██████▌   [0m| 17/26 [00:17<00:08,  1.02it/s]Epoch: 7/10. Loss: 0.9382:  69%|[36m██████▉   [0m| 18/26 [00:17<00:07,  1.04it/s]Epoch: 7/10. Loss: 0.9423:  69%|[36m██████▉   [0m| 18/26 [00:17<00:07,  1.04it/s]Epoch: 7/10. Loss: 0.9423:  73%|[36m███████▎  [0m| 19/26 [00:17<00:06,  1.09it/s]Epoch: 7/10. Loss: 0.8417:  73%|[36m███████▎  [0m| 19/26 [00:18<00:06,  1.09it/s]Epoch: 7/10. Loss: 0.8417:  77%|[36m███████▋  [0m| 20/26 [00:18<00:05,  1.09it/s]Epoch: 7/10. Loss: 0.8624:  77%|[36m███████▋  [0m| 20/26 [00:19<00:05,  1.09it/s]Epoch: 7/10. Loss: 0.8624:  81%|[36m████████  [0m| 21/26 [00:19<00:04,  1.09it/s]Epoch: 7/10. Loss: 0.7803:  81%|[36m████████  [0m| 21/26 [00:20<00:04,  1.09it/s]Epoch: 7/10. Loss: 0.7803:  85%|[36m████████▍ [0m| 22/26 [00:20<00:03,  1.09it/s]Epoch: 7/10. Loss: 0.8383:  85%|[36m████████▍ [0m| 22/26 [00:21<00:03,  1.09it/s]Epoch: 7/10. Loss: 0.8383:  88%|[36m████████▊ [0m| 23/26 [00:21<00:02,  1.12it/s]Epoch: 7/10. Loss: 0.9159:  88%|[36m████████▊ [0m| 23/26 [00:22<00:02,  1.12it/s]Epoch: 7/10. Loss: 0.9159:  92%|[36m█████████▏[0m| 24/26 [00:22<00:01,  1.10it/s]Epoch: 7/10. Loss: 0.8637:  92%|[36m█████████▏[0m| 24/26 [00:23<00:01,  1.10it/s]Epoch: 7/10. Loss: 0.8637:  96%|[36m█████████▌[0m| 25/26 [00:23<00:00,  1.09it/s]Epoch: 7/10. Loss: 0.9439:  96%|[36m█████████▌[0m| 25/26 [00:24<00:00,  1.09it/s]Epoch: 7/10. Loss: 0.9439: 100%|[36m██████████[0m| 26/26 [00:24<00:00,  1.16it/s]Epoch: 7/10. Loss: 0.9439: 100%|[36m██████████[0m| 26/26 [00:24<00:00,  1.07it/s]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:04,  1.24it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:05,  1.13s/it] 43%|[33m████▎     [0m| 3/7 [00:02<00:03,  1.08it/s] 57%|[33m█████▋    [0m| 4/7 [00:04<00:03,  1.04s/it] 71%|[33m███████▏  [0m| 5/7 [00:04<00:01,  1.20it/s] 86%|[33m████████▌ [0m| 6/7 [00:05<00:00,  1.17it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.49it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.22it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 8/10. Loss: 0.7713:   0%|[36m          [0m| 0/26 [00:01<?, ?it/s]Epoch: 8/10. Loss: 0.7713:   4%|[36m▍         [0m| 1/26 [00:01<00:27,  1.09s/it]Epoch: 8/10. Loss: 0.8075:   4%|[36m▍         [0m| 1/26 [00:01<00:27,  1.09s/it]Epoch: 8/10. Loss: 0.8075:   8%|[36m▊         [0m| 2/26 [00:01<00:23,  1.03it/s]Epoch: 8/10. Loss: 0.7379:   8%|[36m▊         [0m| 2/26 [00:02<00:23,  1.03it/s]Epoch: 8/10. Loss: 0.7379:  12%|[36m█▏        [0m| 3/26 [00:02<00:21,  1.09it/s]Epoch: 8/10. Loss: 0.7728:  12%|[36m█▏        [0m| 3/26 [00:03<00:21,  1.09it/s]Epoch: 8/10. Loss: 0.7728:  15%|[36m█▌        [0m| 4/26 [00:03<00:21,  1.02it/s]Epoch: 8/10. Loss: 0.8152:  15%|[36m█▌        [0m| 4/26 [00:04<00:21,  1.02it/s]Epoch: 8/10. Loss: 0.8152:  19%|[36m█▉        [0m| 5/26 [00:04<00:20,  1.02it/s]Epoch: 8/10. Loss: 0.9725:  19%|[36m█▉        [0m| 5/26 [00:05<00:20,  1.02it/s]Epoch: 8/10. Loss: 0.9725:  23%|[36m██▎       [0m| 6/26 [00:05<00:19,  1.02it/s]Epoch: 8/10. Loss: 0.8343:  23%|[36m██▎       [0m| 6/26 [00:06<00:19,  1.02it/s]Epoch: 8/10. Loss: 0.8343:  27%|[36m██▋       [0m| 7/26 [00:06<00:18,  1.04it/s]Epoch: 8/10. Loss: 0.8780:  27%|[36m██▋       [0m| 7/26 [00:07<00:18,  1.04it/s]Epoch: 8/10. Loss: 0.8780:  31%|[36m███       [0m| 8/26 [00:07<00:18,  1.00s/it]Epoch: 8/10. Loss: 0.8122:  31%|[36m███       [0m| 8/26 [00:08<00:18,  1.00s/it]Epoch: 8/10. Loss: 0.8122:  35%|[36m███▍      [0m| 9/26 [00:08<00:16,  1.00it/s]Epoch: 8/10. Loss: 0.8469:  35%|[36m███▍      [0m| 9/26 [00:09<00:16,  1.00it/s]Epoch: 8/10. Loss: 0.8469:  38%|[36m███▊      [0m| 10/26 [00:09<00:15,  1.00it/s]Epoch: 8/10. Loss: 0.8646:  38%|[36m███▊      [0m| 10/26 [00:10<00:15,  1.00it/s]Epoch: 8/10. Loss: 0.8646:  42%|[36m████▏     [0m| 11/26 [00:10<00:14,  1.06it/s]Epoch: 8/10. Loss: 0.7916:  42%|[36m████▏     [0m| 11/26 [00:11<00:14,  1.06it/s]Epoch: 8/10. Loss: 0.7916:  46%|[36m████▌     [0m| 12/26 [00:11<00:12,  1.08it/s]Epoch: 8/10. Loss: 0.8501:  46%|[36m████▌     [0m| 12/26 [00:12<00:12,  1.08it/s]Epoch: 8/10. Loss: 0.8501:  50%|[36m█████     [0m| 13/26 [00:12<00:12,  1.07it/s]Epoch: 8/10. Loss: 0.9003:  50%|[36m█████     [0m| 13/26 [00:13<00:12,  1.07it/s]Epoch: 8/10. Loss: 0.9003:  54%|[36m█████▍    [0m| 14/26 [00:13<00:11,  1.07it/s]Epoch: 8/10. Loss: 0.7675:  54%|[36m█████▍    [0m| 14/26 [00:14<00:11,  1.07it/s]Epoch: 8/10. Loss: 0.7675:  58%|[36m█████▊    [0m| 15/26 [00:14<00:09,  1.10it/s]Epoch: 8/10. Loss: 0.7862:  58%|[36m█████▊    [0m| 15/26 [00:15<00:09,  1.10it/s]Epoch: 8/10. Loss: 0.7862:  62%|[36m██████▏   [0m| 16/26 [00:15<00:09,  1.06it/s]Epoch: 8/10. Loss: 0.8899:  62%|[36m██████▏   [0m| 16/26 [00:16<00:09,  1.06it/s]Epoch: 8/10. Loss: 0.8899:  65%|[36m██████▌   [0m| 17/26 [00:16<00:08,  1.07it/s]Epoch: 8/10. Loss: 0.8364:  65%|[36m██████▌   [0m| 17/26 [00:17<00:08,  1.07it/s]Epoch: 8/10. Loss: 0.8364:  69%|[36m██████▉   [0m| 18/26 [00:17<00:07,  1.04it/s]Epoch: 8/10. Loss: 0.8645:  69%|[36m██████▉   [0m| 18/26 [00:18<00:07,  1.04it/s]Epoch: 8/10. Loss: 0.8645:  73%|[36m███████▎  [0m| 19/26 [00:18<00:06,  1.01it/s]Epoch: 8/10. Loss: 0.8012:  73%|[36m███████▎  [0m| 19/26 [00:19<00:06,  1.01it/s]Epoch: 8/10. Loss: 0.8012:  77%|[36m███████▋  [0m| 20/26 [00:19<00:05,  1.08it/s]Epoch: 8/10. Loss: 0.7644:  77%|[36m███████▋  [0m| 20/26 [00:20<00:05,  1.08it/s]Epoch: 8/10. Loss: 0.7644:  81%|[36m████████  [0m| 21/26 [00:20<00:04,  1.04it/s]Epoch: 8/10. Loss: 0.8876:  81%|[36m████████  [0m| 21/26 [00:21<00:04,  1.04it/s]Epoch: 8/10. Loss: 0.8876:  85%|[36m████████▍ [0m| 22/26 [00:21<00:03,  1.03it/s]Epoch: 8/10. Loss: 0.9066:  85%|[36m████████▍ [0m| 22/26 [00:21<00:03,  1.03it/s]Epoch: 8/10. Loss: 0.9066:  88%|[36m████████▊ [0m| 23/26 [00:21<00:02,  1.08it/s]Epoch: 8/10. Loss: 0.8037:  88%|[36m████████▊ [0m| 23/26 [00:22<00:02,  1.08it/s]Epoch: 8/10. Loss: 0.8037:  92%|[36m█████████▏[0m| 24/26 [00:22<00:01,  1.07it/s]Epoch: 8/10. Loss: 0.8633:  92%|[36m█████████▏[0m| 24/26 [00:23<00:01,  1.07it/s]Epoch: 8/10. Loss: 0.8633:  96%|[36m█████████▌[0m| 25/26 [00:23<00:00,  1.05it/s]Epoch: 8/10. Loss: 0.8568:  96%|[36m█████████▌[0m| 25/26 [00:24<00:00,  1.05it/s]Epoch: 8/10. Loss: 0.8568: 100%|[36m██████████[0m| 26/26 [00:24<00:00,  1.18it/s]Epoch: 8/10. Loss: 0.8568: 100%|[36m██████████[0m| 26/26 [00:24<00:00,  1.06it/s]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:04,  1.25it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:05,  1.14s/it] 43%|[33m████▎     [0m| 3/7 [00:02<00:03,  1.09it/s] 57%|[33m█████▋    [0m| 4/7 [00:04<00:03,  1.05s/it] 71%|[33m███████▏  [0m| 5/7 [00:04<00:01,  1.20it/s] 86%|[33m████████▌ [0m| 6/7 [00:05<00:00,  1.17it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.48it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.22it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 9/10. Loss: 0.7540:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 9/10. Loss: 0.7540:   4%|[36m▍         [0m| 1/26 [00:00<00:23,  1.07it/s]Epoch: 9/10. Loss: 0.8100:   4%|[36m▍         [0m| 1/26 [00:01<00:23,  1.07it/s]Epoch: 9/10. Loss: 0.8100:   8%|[36m▊         [0m| 2/26 [00:01<00:20,  1.19it/s]Epoch: 9/10. Loss: 0.8719:   8%|[36m▊         [0m| 2/26 [00:02<00:20,  1.19it/s]Epoch: 9/10. Loss: 0.8719:  12%|[36m█▏        [0m| 3/26 [00:02<00:19,  1.17it/s]Epoch: 9/10. Loss: 0.8104:  12%|[36m█▏        [0m| 3/26 [00:03<00:19,  1.17it/s]Epoch: 9/10. Loss: 0.8104:  15%|[36m█▌        [0m| 4/26 [00:03<00:19,  1.11it/s]Epoch: 9/10. Loss: 0.8312:  15%|[36m█▌        [0m| 4/26 [00:04<00:19,  1.11it/s]Epoch: 9/10. Loss: 0.8312:  19%|[36m█▉        [0m| 5/26 [00:04<00:19,  1.06it/s]Epoch: 9/10. Loss: 0.7608:  19%|[36m█▉        [0m| 5/26 [00:05<00:19,  1.06it/s]Epoch: 9/10. Loss: 0.7608:  23%|[36m██▎       [0m| 6/26 [00:05<00:20,  1.02s/it]Epoch: 9/10. Loss: 0.8561:  23%|[36m██▎       [0m| 6/26 [00:06<00:20,  1.02s/it]Epoch: 9/10. Loss: 0.8561:  27%|[36m██▋       [0m| 7/26 [00:06<00:19,  1.00s/it]Epoch: 9/10. Loss: 0.8328:  27%|[36m██▋       [0m| 7/26 [00:07<00:19,  1.00s/it]Epoch: 9/10. Loss: 0.8328:  31%|[36m███       [0m| 8/26 [00:07<00:17,  1.02it/s]Epoch: 9/10. Loss: 0.9682:  31%|[36m███       [0m| 8/26 [00:08<00:17,  1.02it/s]Epoch: 9/10. Loss: 0.9682:  35%|[36m███▍      [0m| 9/26 [00:08<00:16,  1.03it/s]Epoch: 9/10. Loss: 0.8048:  35%|[36m███▍      [0m| 9/26 [00:09<00:16,  1.03it/s]Epoch: 9/10. Loss: 0.8048:  38%|[36m███▊      [0m| 10/26 [00:09<00:16,  1.00s/it]Epoch: 9/10. Loss: 0.8069:  38%|[36m███▊      [0m| 10/26 [00:10<00:16,  1.00s/it]Epoch: 9/10. Loss: 0.8069:  42%|[36m████▏     [0m| 11/26 [00:10<00:13,  1.09it/s]Epoch: 9/10. Loss: 0.8716:  42%|[36m████▏     [0m| 11/26 [00:11<00:13,  1.09it/s]Epoch: 9/10. Loss: 0.8716:  46%|[36m████▌     [0m| 12/26 [00:11<00:13,  1.07it/s]Epoch: 9/10. Loss: 0.8281:  46%|[36m████▌     [0m| 12/26 [00:12<00:13,  1.07it/s]Epoch: 9/10. Loss: 0.8281:  50%|[36m█████     [0m| 13/26 [00:12<00:11,  1.10it/s]Epoch: 9/10. Loss: 0.8137:  50%|[36m█████     [0m| 13/26 [00:13<00:11,  1.10it/s]Epoch: 9/10. Loss: 0.8137:  54%|[36m█████▍    [0m| 14/26 [00:13<00:11,  1.06it/s]Epoch: 9/10. Loss: 0.7486:  54%|[36m█████▍    [0m| 14/26 [00:14<00:11,  1.06it/s]Epoch: 9/10. Loss: 0.7486:  58%|[36m█████▊    [0m| 15/26 [00:14<00:10,  1.06it/s]Epoch: 9/10. Loss: 0.9604:  58%|[36m█████▊    [0m| 15/26 [00:15<00:10,  1.06it/s]Epoch: 9/10. Loss: 0.9604:  62%|[36m██████▏   [0m| 16/26 [00:15<00:09,  1.05it/s]Epoch: 9/10. Loss: 0.8180:  62%|[36m██████▏   [0m| 16/26 [00:16<00:09,  1.05it/s]Epoch: 9/10. Loss: 0.8180:  65%|[36m██████▌   [0m| 17/26 [00:16<00:08,  1.02it/s]Epoch: 9/10. Loss: 0.8223:  65%|[36m██████▌   [0m| 17/26 [00:17<00:08,  1.02it/s]Epoch: 9/10. Loss: 0.8223:  69%|[36m██████▉   [0m| 18/26 [00:17<00:07,  1.07it/s]Epoch: 9/10. Loss: 0.7517:  69%|[36m██████▉   [0m| 18/26 [00:17<00:07,  1.07it/s]Epoch: 9/10. Loss: 0.7517:  73%|[36m███████▎  [0m| 19/26 [00:17<00:06,  1.09it/s]Epoch: 9/10. Loss: 0.7910:  73%|[36m███████▎  [0m| 19/26 [00:19<00:06,  1.09it/s]Epoch: 9/10. Loss: 0.7910:  77%|[36m███████▋  [0m| 20/26 [00:19<00:05,  1.01it/s]Epoch: 9/10. Loss: 0.7684:  77%|[36m███████▋  [0m| 20/26 [00:19<00:05,  1.01it/s]Epoch: 9/10. Loss: 0.7684:  81%|[36m████████  [0m| 21/26 [00:19<00:04,  1.09it/s]Epoch: 9/10. Loss: 0.8704:  81%|[36m████████  [0m| 21/26 [00:21<00:04,  1.09it/s]Epoch: 9/10. Loss: 0.8704:  85%|[36m████████▍ [0m| 22/26 [00:21<00:04,  1.22s/it]Epoch: 9/10. Loss: 0.9012:  85%|[36m████████▍ [0m| 22/26 [00:22<00:04,  1.22s/it]Epoch: 9/10. Loss: 0.9012:  88%|[36m████████▊ [0m| 23/26 [00:22<00:03,  1.12s/it]Epoch: 9/10. Loss: 0.8278:  88%|[36m████████▊ [0m| 23/26 [00:23<00:03,  1.12s/it]Epoch: 9/10. Loss: 0.8278:  92%|[36m█████████▏[0m| 24/26 [00:23<00:02,  1.10s/it]Epoch: 9/10. Loss: 0.7640:  92%|[36m█████████▏[0m| 24/26 [00:24<00:02,  1.10s/it]Epoch: 9/10. Loss: 0.7640:  96%|[36m█████████▌[0m| 25/26 [00:24<00:01,  1.07s/it]Epoch: 9/10. Loss: 0.8242:  96%|[36m█████████▌[0m| 25/26 [00:25<00:01,  1.07s/it]Epoch: 9/10. Loss: 0.8242: 100%|[36m██████████[0m| 26/26 [00:25<00:00,  1.01it/s]Epoch: 9/10. Loss: 0.8242: 100%|[36m██████████[0m| 26/26 [00:25<00:00,  1.02it/s]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:04,  1.24it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:05,  1.15s/it] 43%|[33m████▎     [0m| 3/7 [00:02<00:03,  1.07it/s] 57%|[33m█████▋    [0m| 4/7 [00:04<00:03,  1.06s/it] 71%|[33m███████▏  [0m| 5/7 [00:04<00:01,  1.18it/s] 86%|[33m████████▌ [0m| 6/7 [00:05<00:00,  1.14it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.44it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.20it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 0/10. Loss: 1.0935:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 0/10. Loss: 1.0935:   4%|[36m▍         [0m| 1/26 [00:00<00:21,  1.16it/s]Epoch: 0/10. Loss: 3.7595:   4%|[36m▍         [0m| 1/26 [00:01<00:21,  1.16it/s]Epoch: 0/10. Loss: 3.7595:   8%|[36m▊         [0m| 2/26 [00:01<00:20,  1.19it/s]Epoch: 0/10. Loss: 4.0569:   8%|[36m▊         [0m| 2/26 [00:02<00:20,  1.19it/s]Epoch: 0/10. Loss: 4.0569:  12%|[36m█▏        [0m| 3/26 [00:02<00:21,  1.07it/s]Epoch: 0/10. Loss: 3.4925:  12%|[36m█▏        [0m| 3/26 [00:03<00:21,  1.07it/s]Epoch: 0/10. Loss: 3.4925:  15%|[36m█▌        [0m| 4/26 [00:03<00:18,  1.20it/s]Epoch: 0/10. Loss: 1.4768:  15%|[36m█▌        [0m| 4/26 [00:04<00:18,  1.20it/s]Epoch: 0/10. Loss: 1.4768:  19%|[36m█▉        [0m| 5/26 [00:04<00:17,  1.21it/s]Epoch: 0/10. Loss: 1.7593:  19%|[36m█▉        [0m| 5/26 [00:05<00:17,  1.21it/s]Epoch: 0/10. Loss: 1.7593:  23%|[36m██▎       [0m| 6/26 [00:05<00:16,  1.20it/s]Epoch: 0/10. Loss: 2.2651:  23%|[36m██▎       [0m| 6/26 [00:05<00:16,  1.20it/s]Epoch: 0/10. Loss: 2.2651:  27%|[36m██▋       [0m| 7/26 [00:05<00:15,  1.24it/s]Epoch: 0/10. Loss: 1.6390:  27%|[36m██▋       [0m| 7/26 [00:06<00:15,  1.24it/s]Epoch: 0/10. Loss: 1.6390:  31%|[36m███       [0m| 8/26 [00:06<00:14,  1.23it/s]Epoch: 0/10. Loss: 1.0695:  31%|[36m███       [0m| 8/26 [00:07<00:14,  1.23it/s]Epoch: 0/10. Loss: 1.0695:  35%|[36m███▍      [0m| 9/26 [00:07<00:13,  1.22it/s]Epoch: 0/10. Loss: 1.2642:  35%|[36m███▍      [0m| 9/26 [00:08<00:13,  1.22it/s]Epoch: 0/10. Loss: 1.2642:  38%|[36m███▊      [0m| 10/26 [00:08<00:13,  1.19it/s]Epoch: 0/10. Loss: 1.2060:  38%|[36m███▊      [0m| 10/26 [00:09<00:13,  1.19it/s]Epoch: 0/10. Loss: 1.2060:  42%|[36m████▏     [0m| 11/26 [00:09<00:13,  1.14it/s]Epoch: 0/10. Loss: 1.0697:  42%|[36m████▏     [0m| 11/26 [00:10<00:13,  1.14it/s]Epoch: 0/10. Loss: 1.0697:  46%|[36m████▌     [0m| 12/26 [00:10<00:11,  1.17it/s]Epoch: 0/10. Loss: 1.0234:  46%|[36m████▌     [0m| 12/26 [00:10<00:11,  1.17it/s]Epoch: 0/10. Loss: 1.0234:  50%|[36m█████     [0m| 13/26 [00:10<00:10,  1.21it/s]Epoch: 0/10. Loss: 1.0213:  50%|[36m█████     [0m| 13/26 [00:11<00:10,  1.21it/s]Epoch: 0/10. Loss: 1.0213:  54%|[36m█████▍    [0m| 14/26 [00:11<00:09,  1.21it/s]Epoch: 0/10. Loss: 1.0958:  54%|[36m█████▍    [0m| 14/26 [00:12<00:09,  1.21it/s]Epoch: 0/10. Loss: 1.0958:  58%|[36m█████▊    [0m| 15/26 [00:12<00:09,  1.21it/s]Epoch: 0/10. Loss: 1.1670:  58%|[36m█████▊    [0m| 15/26 [00:13<00:09,  1.21it/s]Epoch: 0/10. Loss: 1.1670:  62%|[36m██████▏   [0m| 16/26 [00:13<00:09,  1.04it/s]Epoch: 0/10. Loss: 1.2616:  62%|[36m██████▏   [0m| 16/26 [00:14<00:09,  1.04it/s]Epoch: 0/10. Loss: 1.2616:  65%|[36m██████▌   [0m| 17/26 [00:14<00:08,  1.05it/s]Epoch: 0/10. Loss: 0.9956:  65%|[36m██████▌   [0m| 17/26 [00:15<00:08,  1.05it/s]Epoch: 0/10. Loss: 0.9956:  69%|[36m██████▉   [0m| 18/26 [00:15<00:07,  1.03it/s]Epoch: 0/10. Loss: 1.1975:  69%|[36m██████▉   [0m| 18/26 [00:16<00:07,  1.03it/s]Epoch: 0/10. Loss: 1.1975:  73%|[36m███████▎  [0m| 19/26 [00:16<00:06,  1.05it/s]Epoch: 0/10. Loss: 1.2030:  73%|[36m███████▎  [0m| 19/26 [00:17<00:06,  1.05it/s]Epoch: 0/10. Loss: 1.2030:  77%|[36m███████▋  [0m| 20/26 [00:17<00:05,  1.10it/s]Epoch: 0/10. Loss: 1.0168:  77%|[36m███████▋  [0m| 20/26 [00:18<00:05,  1.10it/s]Epoch: 0/10. Loss: 1.0168:  81%|[36m████████  [0m| 21/26 [00:18<00:04,  1.08it/s]Epoch: 0/10. Loss: 1.1931:  81%|[36m████████  [0m| 21/26 [00:19<00:04,  1.08it/s]Epoch: 0/10. Loss: 1.1931:  85%|[36m████████▍ [0m| 22/26 [00:19<00:03,  1.09it/s]Epoch: 0/10. Loss: 1.1489:  85%|[36m████████▍ [0m| 22/26 [00:20<00:03,  1.09it/s]Epoch: 0/10. Loss: 1.1489:  88%|[36m████████▊ [0m| 23/26 [00:20<00:02,  1.02it/s]Epoch: 0/10. Loss: 1.0694:  88%|[36m████████▊ [0m| 23/26 [00:21<00:02,  1.02it/s]Epoch: 0/10. Loss: 1.0694:  92%|[36m█████████▏[0m| 24/26 [00:21<00:01,  1.02it/s]Epoch: 0/10. Loss: 1.0814:  92%|[36m█████████▏[0m| 24/26 [00:22<00:01,  1.02it/s]Epoch: 0/10. Loss: 1.0814:  96%|[36m█████████▌[0m| 25/26 [00:22<00:00,  1.01it/s]Epoch: 0/10. Loss: 1.1311:  96%|[36m█████████▌[0m| 25/26 [00:23<00:00,  1.01it/s]Epoch: 0/10. Loss: 1.1311: 100%|[36m██████████[0m| 26/26 [00:23<00:00,  1.13it/s]Epoch: 0/10. Loss: 1.1311: 100%|[36m██████████[0m| 26/26 [00:23<00:00,  1.12it/s]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:04,  1.31it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:07,  1.44s/it] 43%|[33m████▎     [0m| 3/7 [00:03<00:04,  1.08s/it] 57%|[33m█████▋    [0m| 4/7 [00:04<00:03,  1.12s/it] 71%|[33m███████▏  [0m| 5/7 [00:04<00:01,  1.15it/s] 86%|[33m████████▌ [0m| 6/7 [00:05<00:00,  1.14it/s]100%|[33m██████████[0m| 7/7 [00:06<00:00,  1.46it/s]100%|[33m██████████[0m| 7/7 [00:06<00:00,  1.14it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 1/10. Loss: 1.0148:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 1/10. Loss: 1.0148:   4%|[36m▍         [0m| 1/26 [00:00<00:22,  1.10it/s]Epoch: 1/10. Loss: 1.0676:   4%|[36m▍         [0m| 1/26 [00:01<00:22,  1.10it/s]Epoch: 1/10. Loss: 1.0676:   8%|[36m▊         [0m| 2/26 [00:01<00:22,  1.08it/s]Epoch: 1/10. Loss: 1.0508:   8%|[36m▊         [0m| 2/26 [00:02<00:22,  1.08it/s]Epoch: 1/10. Loss: 1.0508:  12%|[36m█▏        [0m| 3/26 [00:02<00:22,  1.04it/s]Epoch: 1/10. Loss: 0.9805:  12%|[36m█▏        [0m| 3/26 [00:03<00:22,  1.04it/s]Epoch: 1/10. Loss: 0.9805:  15%|[36m█▌        [0m| 4/26 [00:03<00:20,  1.07it/s]Epoch: 1/10. Loss: 1.1005:  15%|[36m█▌        [0m| 4/26 [00:04<00:20,  1.07it/s]Epoch: 1/10. Loss: 1.1005:  19%|[36m█▉        [0m| 5/26 [00:04<00:17,  1.20it/s]Epoch: 1/10. Loss: 1.0081:  19%|[36m█▉        [0m| 5/26 [00:05<00:17,  1.20it/s]Epoch: 1/10. Loss: 1.0081:  23%|[36m██▎       [0m| 6/26 [00:05<00:17,  1.14it/s]Epoch: 1/10. Loss: 1.0653:  23%|[36m██▎       [0m| 6/26 [00:07<00:17,  1.14it/s]Epoch: 1/10. Loss: 1.0653:  27%|[36m██▋       [0m| 7/26 [00:07<00:25,  1.33s/it]Epoch: 1/10. Loss: 1.0820:  27%|[36m██▋       [0m| 7/26 [00:08<00:25,  1.33s/it]Epoch: 1/10. Loss: 1.0820:  31%|[36m███       [0m| 8/26 [00:08<00:23,  1.28s/it]Epoch: 1/10. Loss: 1.0288:  31%|[36m███       [0m| 8/26 [00:09<00:23,  1.28s/it]Epoch: 1/10. Loss: 1.0288:  35%|[36m███▍      [0m| 9/26 [00:09<00:19,  1.14s/it]Epoch: 1/10. Loss: 1.0459:  35%|[36m███▍      [0m| 9/26 [00:10<00:19,  1.14s/it]Epoch: 1/10. Loss: 1.0459:  38%|[36m███▊      [0m| 10/26 [00:10<00:16,  1.05s/it]Epoch: 1/10. Loss: 0.9779:  38%|[36m███▊      [0m| 10/26 [00:11<00:16,  1.05s/it]Epoch: 1/10. Loss: 0.9779:  42%|[36m████▏     [0m| 11/26 [00:11<00:15,  1.01s/it]Epoch: 1/10. Loss: 1.0653:  42%|[36m████▏     [0m| 11/26 [00:12<00:15,  1.01s/it]Epoch: 1/10. Loss: 1.0653:  46%|[36m████▌     [0m| 12/26 [00:12<00:14,  1.01s/it]Epoch: 1/10. Loss: 1.1088:  46%|[36m████▌     [0m| 12/26 [00:13<00:14,  1.01s/it]Epoch: 1/10. Loss: 1.1088:  50%|[36m█████     [0m| 13/26 [00:13<00:12,  1.02it/s]Epoch: 1/10. Loss: 1.0282:  50%|[36m█████     [0m| 13/26 [00:14<00:12,  1.02it/s]Epoch: 1/10. Loss: 1.0282:  54%|[36m█████▍    [0m| 14/26 [00:14<00:12,  1.01s/it]Epoch: 1/10. Loss: 1.0234:  54%|[36m█████▍    [0m| 14/26 [00:15<00:12,  1.01s/it]Epoch: 1/10. Loss: 1.0234:  58%|[36m█████▊    [0m| 15/26 [00:15<00:10,  1.08it/s]Epoch: 1/10. Loss: 1.1040:  58%|[36m█████▊    [0m| 15/26 [00:16<00:10,  1.08it/s]Epoch: 1/10. Loss: 1.1040:  62%|[36m██████▏   [0m| 16/26 [00:16<00:09,  1.07it/s]Epoch: 1/10. Loss: 1.0465:  62%|[36m██████▏   [0m| 16/26 [00:16<00:09,  1.07it/s]Epoch: 1/10. Loss: 1.0465:  65%|[36m██████▌   [0m| 17/26 [00:16<00:08,  1.12it/s]Epoch: 1/10. Loss: 0.9714:  65%|[36m██████▌   [0m| 17/26 [00:17<00:08,  1.12it/s]Epoch: 1/10. Loss: 0.9714:  69%|[36m██████▉   [0m| 18/26 [00:17<00:07,  1.11it/s]Epoch: 1/10. Loss: 1.1285:  69%|[36m██████▉   [0m| 18/26 [00:18<00:07,  1.11it/s]Epoch: 1/10. Loss: 1.1285:  73%|[36m███████▎  [0m| 19/26 [00:18<00:06,  1.13it/s]Epoch: 1/10. Loss: 1.0023:  73%|[36m███████▎  [0m| 19/26 [00:19<00:06,  1.13it/s]Epoch: 1/10. Loss: 1.0023:  77%|[36m███████▋  [0m| 20/26 [00:19<00:05,  1.08it/s]Epoch: 1/10. Loss: 1.0167:  77%|[36m███████▋  [0m| 20/26 [00:20<00:05,  1.08it/s]Epoch: 1/10. Loss: 1.0167:  81%|[36m████████  [0m| 21/26 [00:20<00:04,  1.09it/s]Epoch: 1/10. Loss: 0.9605:  81%|[36m████████  [0m| 21/26 [00:21<00:04,  1.09it/s]Epoch: 1/10. Loss: 0.9605:  85%|[36m████████▍ [0m| 22/26 [00:21<00:03,  1.10it/s]Epoch: 1/10. Loss: 0.9163:  85%|[36m████████▍ [0m| 22/26 [00:22<00:03,  1.10it/s]Epoch: 1/10. Loss: 0.9163:  88%|[36m████████▊ [0m| 23/26 [00:22<00:02,  1.17it/s]Epoch: 1/10. Loss: 1.0249:  88%|[36m████████▊ [0m| 23/26 [00:23<00:02,  1.17it/s]Epoch: 1/10. Loss: 1.0249:  92%|[36m█████████▏[0m| 24/26 [00:23<00:01,  1.17it/s]Epoch: 1/10. Loss: 1.0614:  92%|[36m█████████▏[0m| 24/26 [00:23<00:01,  1.17it/s]Epoch: 1/10. Loss: 1.0614:  96%|[36m█████████▌[0m| 25/26 [00:23<00:00,  1.16it/s]Epoch: 1/10. Loss: 0.9135:  96%|[36m█████████▌[0m| 25/26 [00:24<00:00,  1.16it/s]Epoch: 1/10. Loss: 0.9135: 100%|[36m██████████[0m| 26/26 [00:24<00:00,  1.25it/s]Epoch: 1/10. Loss: 0.9135: 100%|[36m██████████[0m| 26/26 [00:24<00:00,  1.06it/s]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:04,  1.31it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:05,  1.11s/it] 43%|[33m████▎     [0m| 3/7 [00:02<00:03,  1.10it/s] 57%|[33m█████▋    [0m| 4/7 [00:03<00:03,  1.03s/it] 71%|[33m███████▏  [0m| 5/7 [00:04<00:01,  1.22it/s] 86%|[33m████████▌ [0m| 6/7 [00:05<00:00,  1.19it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.51it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.25it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 2/10. Loss: 1.0206:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 2/10. Loss: 1.0206:   4%|[36m▍         [0m| 1/26 [00:00<00:18,  1.36it/s]Epoch: 2/10. Loss: 1.1244:   4%|[36m▍         [0m| 1/26 [00:01<00:18,  1.36it/s]Epoch: 2/10. Loss: 1.1244:   8%|[36m▊         [0m| 2/26 [00:01<00:18,  1.30it/s]Epoch: 2/10. Loss: 0.9669:   8%|[36m▊         [0m| 2/26 [00:02<00:18,  1.30it/s]Epoch: 2/10. Loss: 0.9669:  12%|[36m█▏        [0m| 3/26 [00:02<00:17,  1.32it/s]Epoch: 2/10. Loss: 1.0232:  12%|[36m█▏        [0m| 3/26 [00:03<00:17,  1.32it/s]Epoch: 2/10. Loss: 1.0232:  15%|[36m█▌        [0m| 4/26 [00:03<00:18,  1.17it/s]Epoch: 2/10. Loss: 0.9798:  15%|[36m█▌        [0m| 4/26 [00:03<00:18,  1.17it/s]Epoch: 2/10. Loss: 0.9798:  19%|[36m█▉        [0m| 5/26 [00:03<00:16,  1.24it/s]Epoch: 2/10. Loss: 1.0096:  19%|[36m█▉        [0m| 5/26 [00:04<00:16,  1.24it/s]Epoch: 2/10. Loss: 1.0096:  23%|[36m██▎       [0m| 6/26 [00:04<00:17,  1.16it/s]Epoch: 2/10. Loss: 1.0072:  23%|[36m██▎       [0m| 6/26 [00:06<00:17,  1.16it/s]Epoch: 2/10. Loss: 1.0072:  27%|[36m██▋       [0m| 7/26 [00:06<00:17,  1.07it/s]Epoch: 2/10. Loss: 0.9507:  27%|[36m██▋       [0m| 7/26 [00:06<00:17,  1.07it/s]Epoch: 2/10. Loss: 0.9507:  31%|[36m███       [0m| 8/26 [00:06<00:16,  1.09it/s]Epoch: 2/10. Loss: 1.0089:  31%|[36m███       [0m| 8/26 [00:07<00:16,  1.09it/s]Epoch: 2/10. Loss: 1.0089:  35%|[36m███▍      [0m| 9/26 [00:07<00:14,  1.14it/s]Epoch: 2/10. Loss: 0.9399:  35%|[36m███▍      [0m| 9/26 [00:08<00:14,  1.14it/s]Epoch: 2/10. Loss: 0.9399:  38%|[36m███▊      [0m| 10/26 [00:08<00:13,  1.17it/s]Epoch: 2/10. Loss: 1.1242:  38%|[36m███▊      [0m| 10/26 [00:09<00:13,  1.17it/s]Epoch: 2/10. Loss: 1.1242:  42%|[36m████▏     [0m| 11/26 [00:09<00:13,  1.14it/s]Epoch: 2/10. Loss: 1.0164:  42%|[36m████▏     [0m| 11/26 [00:10<00:13,  1.14it/s]Epoch: 2/10. Loss: 1.0164:  46%|[36m████▌     [0m| 12/26 [00:10<00:11,  1.18it/s]Epoch: 2/10. Loss: 0.9874:  46%|[36m████▌     [0m| 12/26 [00:11<00:11,  1.18it/s]Epoch: 2/10. Loss: 0.9874:  50%|[36m█████     [0m| 13/26 [00:11<00:11,  1.14it/s]Epoch: 2/10. Loss: 0.9366:  50%|[36m█████     [0m| 13/26 [00:12<00:11,  1.14it/s]Epoch: 2/10. Loss: 0.9366:  54%|[36m█████▍    [0m| 14/26 [00:12<00:10,  1.15it/s]Epoch: 2/10. Loss: 0.9135:  54%|[36m█████▍    [0m| 14/26 [00:13<00:10,  1.15it/s]Epoch: 2/10. Loss: 0.9135:  58%|[36m█████▊    [0m| 15/26 [00:13<00:10,  1.09it/s]Epoch: 2/10. Loss: 0.9830:  58%|[36m█████▊    [0m| 15/26 [00:13<00:10,  1.09it/s]Epoch: 2/10. Loss: 0.9830:  62%|[36m██████▏   [0m| 16/26 [00:13<00:09,  1.11it/s]Epoch: 2/10. Loss: 1.1158:  62%|[36m██████▏   [0m| 16/26 [00:14<00:09,  1.11it/s]Epoch: 2/10. Loss: 1.1158:  65%|[36m██████▌   [0m| 17/26 [00:14<00:07,  1.14it/s]Epoch: 2/10. Loss: 1.0122:  65%|[36m██████▌   [0m| 17/26 [00:15<00:07,  1.14it/s]Epoch: 2/10. Loss: 1.0122:  69%|[36m██████▉   [0m| 18/26 [00:15<00:07,  1.05it/s]Epoch: 2/10. Loss: 1.0040:  69%|[36m██████▉   [0m| 18/26 [00:16<00:07,  1.05it/s]Epoch: 2/10. Loss: 1.0040:  73%|[36m███████▎  [0m| 19/26 [00:16<00:06,  1.08it/s]Epoch: 2/10. Loss: 0.9768:  73%|[36m███████▎  [0m| 19/26 [00:17<00:06,  1.08it/s]Epoch: 2/10. Loss: 0.9768:  77%|[36m███████▋  [0m| 20/26 [00:17<00:05,  1.06it/s]Epoch: 2/10. Loss: 0.9276:  77%|[36m███████▋  [0m| 20/26 [00:18<00:05,  1.06it/s]Epoch: 2/10. Loss: 0.9276:  81%|[36m████████  [0m| 21/26 [00:18<00:04,  1.10it/s]Epoch: 2/10. Loss: 0.9443:  81%|[36m████████  [0m| 21/26 [00:19<00:04,  1.10it/s]Epoch: 2/10. Loss: 0.9443:  85%|[36m████████▍ [0m| 22/26 [00:19<00:03,  1.12it/s]Epoch: 2/10. Loss: 0.8720:  85%|[36m████████▍ [0m| 22/26 [00:20<00:03,  1.12it/s]Epoch: 2/10. Loss: 0.8720:  88%|[36m████████▊ [0m| 23/26 [00:20<00:02,  1.09it/s]Epoch: 2/10. Loss: 0.9593:  88%|[36m████████▊ [0m| 23/26 [00:21<00:02,  1.09it/s]Epoch: 2/10. Loss: 0.9593:  92%|[36m█████████▏[0m| 24/26 [00:21<00:01,  1.16it/s]Epoch: 2/10. Loss: 1.0712:  92%|[36m█████████▏[0m| 24/26 [00:21<00:01,  1.16it/s]Epoch: 2/10. Loss: 1.0712:  96%|[36m█████████▌[0m| 25/26 [00:21<00:00,  1.16it/s]Epoch: 2/10. Loss: 1.2396:  96%|[36m█████████▌[0m| 25/26 [00:22<00:00,  1.16it/s]Epoch: 2/10. Loss: 1.2396: 100%|[36m██████████[0m| 26/26 [00:22<00:00,  1.28it/s]Epoch: 2/10. Loss: 1.2396: 100%|[36m██████████[0m| 26/26 [00:22<00:00,  1.15it/s]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:04,  1.25it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:05,  1.15s/it] 43%|[33m████▎     [0m| 3/7 [00:02<00:03,  1.07it/s] 57%|[33m█████▋    [0m| 4/7 [00:04<00:03,  1.05s/it] 71%|[33m███████▏  [0m| 5/7 [00:04<00:01,  1.21it/s] 86%|[33m████████▌ [0m| 6/7 [00:05<00:00,  1.18it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.50it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.23it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 3/10. Loss: 1.0439:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 3/10. Loss: 1.0439:   4%|[36m▍         [0m| 1/26 [00:00<00:22,  1.09it/s]Epoch: 3/10. Loss: 0.9879:   4%|[36m▍         [0m| 1/26 [00:01<00:22,  1.09it/s]Epoch: 3/10. Loss: 0.9879:   8%|[36m▊         [0m| 2/26 [00:01<00:21,  1.11it/s]Epoch: 3/10. Loss: 1.0240:   8%|[36m▊         [0m| 2/26 [00:02<00:21,  1.11it/s]Epoch: 3/10. Loss: 1.0240:  12%|[36m█▏        [0m| 3/26 [00:02<00:21,  1.08it/s]Epoch: 3/10. Loss: 1.0123:  12%|[36m█▏        [0m| 3/26 [00:03<00:21,  1.08it/s]Epoch: 3/10. Loss: 1.0123:  15%|[36m█▌        [0m| 4/26 [00:03<00:19,  1.12it/s]Epoch: 3/10. Loss: 1.0305:  15%|[36m█▌        [0m| 4/26 [00:04<00:19,  1.12it/s]Epoch: 3/10. Loss: 1.0305:  19%|[36m█▉        [0m| 5/26 [00:04<00:18,  1.15it/s]Epoch: 3/10. Loss: 1.0558:  19%|[36m█▉        [0m| 5/26 [00:05<00:18,  1.15it/s]Epoch: 3/10. Loss: 1.0558:  23%|[36m██▎       [0m| 6/26 [00:05<00:19,  1.03it/s]Epoch: 3/10. Loss: 0.9515:  23%|[36m██▎       [0m| 6/26 [00:06<00:19,  1.03it/s]Epoch: 3/10. Loss: 0.9515:  27%|[36m██▋       [0m| 7/26 [00:06<00:18,  1.03it/s]Epoch: 3/10. Loss: 0.8860:  27%|[36m██▋       [0m| 7/26 [00:07<00:18,  1.03it/s]Epoch: 3/10. Loss: 0.8860:  31%|[36m███       [0m| 8/26 [00:07<00:16,  1.08it/s]Epoch: 3/10. Loss: 0.9108:  31%|[36m███       [0m| 8/26 [00:08<00:16,  1.08it/s]Epoch: 3/10. Loss: 0.9108:  35%|[36m███▍      [0m| 9/26 [00:08<00:15,  1.11it/s]Epoch: 3/10. Loss: 1.0283:  35%|[36m███▍      [0m| 9/26 [00:09<00:15,  1.11it/s]Epoch: 3/10. Loss: 1.0283:  38%|[36m███▊      [0m| 10/26 [00:09<00:15,  1.06it/s]Epoch: 3/10. Loss: 1.0683:  38%|[36m███▊      [0m| 10/26 [00:10<00:15,  1.06it/s]Epoch: 3/10. Loss: 1.0683:  42%|[36m████▏     [0m| 11/26 [00:10<00:14,  1.02it/s]Epoch: 3/10. Loss: 1.0087:  42%|[36m████▏     [0m| 11/26 [00:11<00:14,  1.02it/s]Epoch: 3/10. Loss: 1.0087:  46%|[36m████▌     [0m| 12/26 [00:11<00:12,  1.11it/s]Epoch: 3/10. Loss: 0.8599:  46%|[36m████▌     [0m| 12/26 [00:11<00:12,  1.11it/s]Epoch: 3/10. Loss: 0.8599:  50%|[36m█████     [0m| 13/26 [00:11<00:11,  1.17it/s]Epoch: 3/10. Loss: 0.9702:  50%|[36m█████     [0m| 13/26 [00:12<00:11,  1.17it/s]Epoch: 3/10. Loss: 0.9702:  54%|[36m█████▍    [0m| 14/26 [00:12<00:09,  1.22it/s]Epoch: 3/10. Loss: 1.0568:  54%|[36m█████▍    [0m| 14/26 [00:13<00:09,  1.22it/s]Epoch: 3/10. Loss: 1.0568:  58%|[36m█████▊    [0m| 15/26 [00:13<00:09,  1.21it/s]Epoch: 3/10. Loss: 0.8484:  58%|[36m█████▊    [0m| 15/26 [00:14<00:09,  1.21it/s]Epoch: 3/10. Loss: 0.8484:  62%|[36m██████▏   [0m| 16/26 [00:14<00:09,  1.10it/s]Epoch: 3/10. Loss: 0.9424:  62%|[36m██████▏   [0m| 16/26 [00:15<00:09,  1.10it/s]Epoch: 3/10. Loss: 0.9424:  65%|[36m██████▌   [0m| 17/26 [00:15<00:08,  1.07it/s]Epoch: 3/10. Loss: 0.9109:  65%|[36m██████▌   [0m| 17/26 [00:16<00:08,  1.07it/s]Epoch: 3/10. Loss: 0.9109:  69%|[36m██████▉   [0m| 18/26 [00:16<00:07,  1.13it/s]Epoch: 3/10. Loss: 0.9112:  69%|[36m██████▉   [0m| 18/26 [00:16<00:07,  1.13it/s]Epoch: 3/10. Loss: 0.9112:  73%|[36m███████▎  [0m| 19/26 [00:16<00:05,  1.19it/s]Epoch: 3/10. Loss: 0.9448:  73%|[36m███████▎  [0m| 19/26 [00:17<00:05,  1.19it/s]Epoch: 3/10. Loss: 0.9448:  77%|[36m███████▋  [0m| 20/26 [00:18<00:05,  1.11it/s]Epoch: 3/10. Loss: 0.8485:  77%|[36m███████▋  [0m| 20/26 [00:18<00:05,  1.11it/s]Epoch: 3/10. Loss: 0.8485:  81%|[36m████████  [0m| 21/26 [00:18<00:04,  1.16it/s]Epoch: 3/10. Loss: 1.0279:  81%|[36m████████  [0m| 21/26 [00:19<00:04,  1.16it/s]Epoch: 3/10. Loss: 1.0279:  85%|[36m████████▍ [0m| 22/26 [00:19<00:03,  1.21it/s]Epoch: 3/10. Loss: 0.9353:  85%|[36m████████▍ [0m| 22/26 [00:20<00:03,  1.21it/s]Epoch: 3/10. Loss: 0.9353:  88%|[36m████████▊ [0m| 23/26 [00:20<00:02,  1.07it/s]Epoch: 3/10. Loss: 1.0059:  88%|[36m████████▊ [0m| 23/26 [00:21<00:02,  1.07it/s]Epoch: 3/10. Loss: 1.0059:  92%|[36m█████████▏[0m| 24/26 [00:21<00:01,  1.10it/s]Epoch: 3/10. Loss: 0.8736:  92%|[36m█████████▏[0m| 24/26 [00:22<00:01,  1.10it/s]Epoch: 3/10. Loss: 0.8736:  96%|[36m█████████▌[0m| 25/26 [00:22<00:00,  1.12it/s]Epoch: 3/10. Loss: 0.9662:  96%|[36m█████████▌[0m| 25/26 [00:22<00:00,  1.12it/s]Epoch: 3/10. Loss: 0.9662: 100%|[36m██████████[0m| 26/26 [00:23<00:00,  1.25it/s]Epoch: 3/10. Loss: 0.9662: 100%|[36m██████████[0m| 26/26 [00:23<00:00,  1.13it/s]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:04,  1.25it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:05,  1.15s/it] 43%|[33m████▎     [0m| 3/7 [00:02<00:03,  1.06it/s] 57%|[33m█████▋    [0m| 4/7 [00:04<00:03,  1.06s/it] 71%|[33m███████▏  [0m| 5/7 [00:04<00:01,  1.19it/s] 86%|[33m████████▌ [0m| 6/7 [00:05<00:00,  1.17it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.49it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.22it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 4/10. Loss: 0.8805:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 4/10. Loss: 0.8805:   4%|[36m▍         [0m| 1/26 [00:00<00:21,  1.14it/s]Epoch: 4/10. Loss: 0.8458:   4%|[36m▍         [0m| 1/26 [00:01<00:21,  1.14it/s]Epoch: 4/10. Loss: 0.8458:   8%|[36m▊         [0m| 2/26 [00:01<00:21,  1.10it/s]Epoch: 4/10. Loss: 0.9681:   8%|[36m▊         [0m| 2/26 [00:02<00:21,  1.10it/s]Epoch: 4/10. Loss: 0.9681:  12%|[36m█▏        [0m| 3/26 [00:02<00:19,  1.16it/s]Epoch: 4/10. Loss: 0.8928:  12%|[36m█▏        [0m| 3/26 [00:03<00:19,  1.16it/s]Epoch: 4/10. Loss: 0.8928:  15%|[36m█▌        [0m| 4/26 [00:03<00:19,  1.10it/s]Epoch: 4/10. Loss: 0.9857:  15%|[36m█▌        [0m| 4/26 [00:04<00:19,  1.10it/s]Epoch: 4/10. Loss: 0.9857:  19%|[36m█▉        [0m| 5/26 [00:04<00:19,  1.10it/s]Epoch: 4/10. Loss: 0.9998:  19%|[36m█▉        [0m| 5/26 [00:05<00:19,  1.10it/s]Epoch: 4/10. Loss: 0.9998:  23%|[36m██▎       [0m| 6/26 [00:05<00:18,  1.07it/s]Epoch: 4/10. Loss: 0.9859:  23%|[36m██▎       [0m| 6/26 [00:06<00:18,  1.07it/s]Epoch: 4/10. Loss: 0.9859:  27%|[36m██▋       [0m| 7/26 [00:06<00:16,  1.13it/s]Epoch: 4/10. Loss: 1.0344:  27%|[36m██▋       [0m| 7/26 [00:07<00:16,  1.13it/s]Epoch: 4/10. Loss: 1.0344:  31%|[36m███       [0m| 8/26 [00:07<00:16,  1.11it/s]Epoch: 4/10. Loss: 0.9506:  31%|[36m███       [0m| 8/26 [00:08<00:16,  1.11it/s]Epoch: 4/10. Loss: 0.9506:  35%|[36m███▍      [0m| 9/26 [00:08<00:15,  1.06it/s]Epoch: 4/10. Loss: 0.8750:  35%|[36m███▍      [0m| 9/26 [00:09<00:15,  1.06it/s]Epoch: 4/10. Loss: 0.8750:  38%|[36m███▊      [0m| 10/26 [00:09<00:14,  1.07it/s]Epoch: 4/10. Loss: 0.9522:  38%|[36m███▊      [0m| 10/26 [00:10<00:14,  1.07it/s]Epoch: 4/10. Loss: 0.9522:  42%|[36m████▏     [0m| 11/26 [00:10<00:13,  1.09it/s]Epoch: 4/10. Loss: 0.9993:  42%|[36m████▏     [0m| 11/26 [00:10<00:13,  1.09it/s]Epoch: 4/10. Loss: 0.9993:  46%|[36m████▌     [0m| 12/26 [00:10<00:12,  1.12it/s]Epoch: 4/10. Loss: 0.8774:  46%|[36m████▌     [0m| 12/26 [00:11<00:12,  1.12it/s]Epoch: 4/10. Loss: 0.8774:  50%|[36m█████     [0m| 13/26 [00:11<00:11,  1.15it/s]Epoch: 4/10. Loss: 0.9255:  50%|[36m█████     [0m| 13/26 [00:12<00:11,  1.15it/s]Epoch: 4/10. Loss: 0.9255:  54%|[36m█████▍    [0m| 14/26 [00:12<00:10,  1.16it/s]Epoch: 4/10. Loss: 0.9524:  54%|[36m█████▍    [0m| 14/26 [00:13<00:10,  1.16it/s]Epoch: 4/10. Loss: 0.9524:  58%|[36m█████▊    [0m| 15/26 [00:13<00:09,  1.14it/s]Epoch: 4/10. Loss: 0.8928:  58%|[36m█████▊    [0m| 15/26 [00:14<00:09,  1.14it/s]Epoch: 4/10. Loss: 0.8928:  62%|[36m██████▏   [0m| 16/26 [00:14<00:09,  1.09it/s]Epoch: 4/10. Loss: 1.0097:  62%|[36m██████▏   [0m| 16/26 [00:15<00:09,  1.09it/s]Epoch: 4/10. Loss: 1.0097:  65%|[36m██████▌   [0m| 17/26 [00:15<00:08,  1.08it/s]Epoch: 4/10. Loss: 0.8687:  65%|[36m██████▌   [0m| 17/26 [00:16<00:08,  1.08it/s]Epoch: 4/10. Loss: 0.8687:  69%|[36m██████▉   [0m| 18/26 [00:16<00:07,  1.09it/s]Epoch: 4/10. Loss: 0.9905:  69%|[36m██████▉   [0m| 18/26 [00:17<00:07,  1.09it/s]Epoch: 4/10. Loss: 0.9905:  73%|[36m███████▎  [0m| 19/26 [00:17<00:06,  1.13it/s]Epoch: 4/10. Loss: 0.8786:  73%|[36m███████▎  [0m| 19/26 [00:17<00:06,  1.13it/s]Epoch: 4/10. Loss: 0.8786:  77%|[36m███████▋  [0m| 20/26 [00:17<00:05,  1.14it/s]Epoch: 4/10. Loss: 0.8715:  77%|[36m███████▋  [0m| 20/26 [00:18<00:05,  1.14it/s]Epoch: 4/10. Loss: 0.8715:  81%|[36m████████  [0m| 21/26 [00:18<00:04,  1.16it/s]Epoch: 4/10. Loss: 0.8655:  81%|[36m████████  [0m| 21/26 [00:19<00:04,  1.16it/s]Epoch: 4/10. Loss: 0.8655:  85%|[36m████████▍ [0m| 22/26 [00:19<00:03,  1.12it/s]Epoch: 4/10. Loss: 0.9580:  85%|[36m████████▍ [0m| 22/26 [00:20<00:03,  1.12it/s]Epoch: 4/10. Loss: 0.9580:  88%|[36m████████▊ [0m| 23/26 [00:20<00:02,  1.16it/s]Epoch: 4/10. Loss: 1.0460:  88%|[36m████████▊ [0m| 23/26 [00:21<00:02,  1.16it/s]Epoch: 4/10. Loss: 1.0460:  92%|[36m█████████▏[0m| 24/26 [00:21<00:01,  1.15it/s]Epoch: 4/10. Loss: 0.9540:  92%|[36m█████████▏[0m| 24/26 [00:22<00:01,  1.15it/s]Epoch: 4/10. Loss: 0.9540:  96%|[36m█████████▌[0m| 25/26 [00:22<00:00,  1.12it/s]Epoch: 4/10. Loss: 0.9520:  96%|[36m█████████▌[0m| 25/26 [00:22<00:00,  1.12it/s]Epoch: 4/10. Loss: 0.9520: 100%|[36m██████████[0m| 26/26 [00:22<00:00,  1.24it/s]Epoch: 4/10. Loss: 0.9520: 100%|[36m██████████[0m| 26/26 [00:22<00:00,  1.13it/s]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:04,  1.36it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:05,  1.08s/it] 43%|[33m████▎     [0m| 3/7 [00:02<00:03,  1.16it/s] 57%|[33m█████▋    [0m| 4/7 [00:03<00:02,  1.03it/s] 71%|[33m███████▏  [0m| 5/7 [00:04<00:01,  1.33it/s] 86%|[33m████████▌ [0m| 6/7 [00:04<00:00,  1.30it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.62it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.33it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 5/10. Loss: 1.0318:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 5/10. Loss: 1.0318:   4%|[36m▍         [0m| 1/26 [00:00<00:20,  1.24it/s]Epoch: 5/10. Loss: 0.9518:   4%|[36m▍         [0m| 1/26 [00:01<00:20,  1.24it/s]Epoch: 5/10. Loss: 0.9518:   8%|[36m▊         [0m| 2/26 [00:01<00:20,  1.16it/s]Epoch: 5/10. Loss: 1.0207:   8%|[36m▊         [0m| 2/26 [00:02<00:20,  1.16it/s]Epoch: 5/10. Loss: 1.0207:  12%|[36m█▏        [0m| 3/26 [00:02<00:19,  1.17it/s]Epoch: 5/10. Loss: 0.9816:  12%|[36m█▏        [0m| 3/26 [00:03<00:19,  1.17it/s]Epoch: 5/10. Loss: 0.9816:  15%|[36m█▌        [0m| 4/26 [00:03<00:18,  1.18it/s]Epoch: 5/10. Loss: 0.9421:  15%|[36m█▌        [0m| 4/26 [00:04<00:18,  1.18it/s]Epoch: 5/10. Loss: 0.9421:  19%|[36m█▉        [0m| 5/26 [00:04<00:18,  1.14it/s]Epoch: 5/10. Loss: 0.9181:  19%|[36m█▉        [0m| 5/26 [00:05<00:18,  1.14it/s]Epoch: 5/10. Loss: 0.9181:  23%|[36m██▎       [0m| 6/26 [00:05<00:17,  1.12it/s]Epoch: 5/10. Loss: 0.8504:  23%|[36m██▎       [0m| 6/26 [00:06<00:17,  1.12it/s]Epoch: 5/10. Loss: 0.8504:  27%|[36m██▋       [0m| 7/26 [00:06<00:16,  1.15it/s]Epoch: 5/10. Loss: 0.8286:  27%|[36m██▋       [0m| 7/26 [00:06<00:16,  1.15it/s]Epoch: 5/10. Loss: 0.8286:  31%|[36m███       [0m| 8/26 [00:06<00:15,  1.16it/s]Epoch: 5/10. Loss: 0.8906:  31%|[36m███       [0m| 8/26 [00:07<00:15,  1.16it/s]Epoch: 5/10. Loss: 0.8906:  35%|[36m███▍      [0m| 9/26 [00:07<00:15,  1.11it/s]Epoch: 5/10. Loss: 0.9470:  35%|[36m███▍      [0m| 9/26 [00:08<00:15,  1.11it/s]Epoch: 5/10. Loss: 0.9470:  38%|[36m███▊      [0m| 10/26 [00:08<00:14,  1.14it/s]Epoch: 5/10. Loss: 1.0006:  38%|[36m███▊      [0m| 10/26 [00:09<00:14,  1.14it/s]Epoch: 5/10. Loss: 1.0006:  42%|[36m████▏     [0m| 11/26 [00:09<00:13,  1.12it/s]Epoch: 5/10. Loss: 1.1073:  42%|[36m████▏     [0m| 11/26 [00:10<00:13,  1.12it/s]Epoch: 5/10. Loss: 1.1073:  46%|[36m████▌     [0m| 12/26 [00:10<00:12,  1.09it/s]Epoch: 5/10. Loss: 0.9471:  46%|[36m████▌     [0m| 12/26 [00:11<00:12,  1.09it/s]Epoch: 5/10. Loss: 0.9471:  50%|[36m█████     [0m| 13/26 [00:11<00:11,  1.15it/s]Epoch: 5/10. Loss: 0.9769:  50%|[36m█████     [0m| 13/26 [00:12<00:11,  1.15it/s]Epoch: 5/10. Loss: 0.9769:  54%|[36m█████▍    [0m| 14/26 [00:12<00:09,  1.20it/s]Epoch: 5/10. Loss: 0.8480:  54%|[36m█████▍    [0m| 14/26 [00:12<00:09,  1.20it/s]Epoch: 5/10. Loss: 0.8480:  58%|[36m█████▊    [0m| 15/26 [00:13<00:09,  1.19it/s]Epoch: 5/10. Loss: 0.9912:  58%|[36m█████▊    [0m| 15/26 [00:13<00:09,  1.19it/s]Epoch: 5/10. Loss: 0.9912:  62%|[36m██████▏   [0m| 16/26 [00:13<00:08,  1.13it/s]Epoch: 5/10. Loss: 0.8639:  62%|[36m██████▏   [0m| 16/26 [00:14<00:08,  1.13it/s]Epoch: 5/10. Loss: 0.8639:  65%|[36m██████▌   [0m| 17/26 [00:14<00:07,  1.16it/s]Epoch: 5/10. Loss: 0.9928:  65%|[36m██████▌   [0m| 17/26 [00:15<00:07,  1.16it/s]Epoch: 5/10. Loss: 0.9928:  69%|[36m██████▉   [0m| 18/26 [00:15<00:07,  1.09it/s]Epoch: 5/10. Loss: 0.9969:  69%|[36m██████▉   [0m| 18/26 [00:16<00:07,  1.09it/s]Epoch: 5/10. Loss: 0.9969:  73%|[36m███████▎  [0m| 19/26 [00:16<00:06,  1.13it/s]Epoch: 5/10. Loss: 0.9562:  73%|[36m███████▎  [0m| 19/26 [00:17<00:06,  1.13it/s]Epoch: 5/10. Loss: 0.9562:  77%|[36m███████▋  [0m| 20/26 [00:17<00:05,  1.15it/s]Epoch: 5/10. Loss: 0.8422:  77%|[36m███████▋  [0m| 20/26 [00:18<00:05,  1.15it/s]Epoch: 5/10. Loss: 0.8422:  81%|[36m████████  [0m| 21/26 [00:18<00:04,  1.06it/s]Epoch: 5/10. Loss: 1.0116:  81%|[36m████████  [0m| 21/26 [00:19<00:04,  1.06it/s]Epoch: 5/10. Loss: 1.0116:  85%|[36m████████▍ [0m| 22/26 [00:19<00:03,  1.06it/s]Epoch: 5/10. Loss: 0.9516:  85%|[36m████████▍ [0m| 22/26 [00:20<00:03,  1.06it/s]Epoch: 5/10. Loss: 0.9516:  88%|[36m████████▊ [0m| 23/26 [00:20<00:02,  1.08it/s]Epoch: 5/10. Loss: 0.8973:  88%|[36m████████▊ [0m| 23/26 [00:21<00:02,  1.08it/s]Epoch: 5/10. Loss: 0.8973:  92%|[36m█████████▏[0m| 24/26 [00:21<00:01,  1.05it/s]Epoch: 5/10. Loss: 0.9466:  92%|[36m█████████▏[0m| 24/26 [00:22<00:01,  1.05it/s]Epoch: 5/10. Loss: 0.9466:  96%|[36m█████████▌[0m| 25/26 [00:22<00:00,  1.10it/s]Epoch: 5/10. Loss: 0.8639:  96%|[36m█████████▌[0m| 25/26 [00:22<00:00,  1.10it/s]Epoch: 5/10. Loss: 0.8639: 100%|[36m██████████[0m| 26/26 [00:22<00:00,  1.20it/s]Epoch: 5/10. Loss: 0.8639: 100%|[36m██████████[0m| 26/26 [00:22<00:00,  1.13it/s]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:04,  1.33it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:05,  1.10s/it] 43%|[33m████▎     [0m| 3/7 [00:02<00:03,  1.13it/s] 57%|[33m█████▋    [0m| 4/7 [00:03<00:02,  1.00it/s] 71%|[33m███████▏  [0m| 5/7 [00:04<00:01,  1.29it/s] 86%|[33m████████▌ [0m| 6/7 [00:05<00:00,  1.26it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.58it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.30it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 6/10. Loss: 0.9661:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 6/10. Loss: 0.9661:   4%|[36m▍         [0m| 1/26 [00:00<00:21,  1.19it/s]Epoch: 6/10. Loss: 0.9816:   4%|[36m▍         [0m| 1/26 [00:01<00:21,  1.19it/s]Epoch: 6/10. Loss: 0.9816:   8%|[36m▊         [0m| 2/26 [00:01<00:18,  1.30it/s]Epoch: 6/10. Loss: 0.8602:   8%|[36m▊         [0m| 2/26 [00:02<00:18,  1.30it/s]Epoch: 6/10. Loss: 0.8602:  12%|[36m█▏        [0m| 3/26 [00:02<00:21,  1.06it/s]Epoch: 6/10. Loss: 0.8833:  12%|[36m█▏        [0m| 3/26 [00:03<00:21,  1.06it/s]Epoch: 6/10. Loss: 0.8833:  15%|[36m█▌        [0m| 4/26 [00:03<00:20,  1.08it/s]Epoch: 6/10. Loss: 0.9076:  15%|[36m█▌        [0m| 4/26 [00:04<00:20,  1.08it/s]Epoch: 6/10. Loss: 0.9076:  19%|[36m█▉        [0m| 5/26 [00:04<00:20,  1.04it/s]Epoch: 6/10. Loss: 0.8565:  19%|[36m█▉        [0m| 5/26 [00:05<00:20,  1.04it/s]Epoch: 6/10. Loss: 0.8565:  23%|[36m██▎       [0m| 6/26 [00:05<00:18,  1.08it/s]Epoch: 6/10. Loss: 0.9105:  23%|[36m██▎       [0m| 6/26 [00:06<00:18,  1.08it/s]Epoch: 6/10. Loss: 0.9105:  27%|[36m██▋       [0m| 7/26 [00:06<00:16,  1.16it/s]Epoch: 6/10. Loss: 1.0620:  27%|[36m██▋       [0m| 7/26 [00:07<00:16,  1.16it/s]Epoch: 6/10. Loss: 1.0620:  31%|[36m███       [0m| 8/26 [00:07<00:15,  1.18it/s]Epoch: 6/10. Loss: 0.9069:  31%|[36m███       [0m| 8/26 [00:07<00:15,  1.18it/s]Epoch: 6/10. Loss: 0.9069:  35%|[36m███▍      [0m| 9/26 [00:07<00:14,  1.17it/s]Epoch: 6/10. Loss: 0.9511:  35%|[36m███▍      [0m| 9/26 [00:08<00:14,  1.17it/s]Epoch: 6/10. Loss: 0.9511:  38%|[36m███▊      [0m| 10/26 [00:08<00:13,  1.17it/s]Epoch: 6/10. Loss: 0.9308:  38%|[36m███▊      [0m| 10/26 [00:09<00:13,  1.17it/s]Epoch: 6/10. Loss: 0.9308:  42%|[36m████▏     [0m| 11/26 [00:09<00:13,  1.15it/s]Epoch: 6/10. Loss: 0.7996:  42%|[36m████▏     [0m| 11/26 [00:10<00:13,  1.15it/s]Epoch: 6/10. Loss: 0.7996:  46%|[36m████▌     [0m| 12/26 [00:10<00:12,  1.14it/s]Epoch: 6/10. Loss: 0.9279:  46%|[36m████▌     [0m| 12/26 [00:11<00:12,  1.14it/s]Epoch: 6/10. Loss: 0.9279:  50%|[36m█████     [0m| 13/26 [00:11<00:12,  1.08it/s]Epoch: 6/10. Loss: 0.8340:  50%|[36m█████     [0m| 13/26 [00:12<00:12,  1.08it/s]Epoch: 6/10. Loss: 0.8340:  54%|[36m█████▍    [0m| 14/26 [00:12<00:10,  1.09it/s]Epoch: 6/10. Loss: 0.8968:  54%|[36m█████▍    [0m| 14/26 [00:13<00:10,  1.09it/s]Epoch: 6/10. Loss: 0.8968:  58%|[36m█████▊    [0m| 15/26 [00:13<00:10,  1.09it/s]Epoch: 6/10. Loss: 1.0537:  58%|[36m█████▊    [0m| 15/26 [00:14<00:10,  1.09it/s]Epoch: 6/10. Loss: 1.0537:  62%|[36m██████▏   [0m| 16/26 [00:14<00:08,  1.12it/s]Epoch: 6/10. Loss: 0.8971:  62%|[36m██████▏   [0m| 16/26 [00:15<00:08,  1.12it/s]Epoch: 6/10. Loss: 0.8971:  65%|[36m██████▌   [0m| 17/26 [00:15<00:07,  1.15it/s]Epoch: 6/10. Loss: 0.9970:  65%|[36m██████▌   [0m| 17/26 [00:16<00:07,  1.15it/s]Epoch: 6/10. Loss: 0.9970:  69%|[36m██████▉   [0m| 18/26 [00:16<00:07,  1.09it/s]Epoch: 6/10. Loss: 0.8508:  69%|[36m██████▉   [0m| 18/26 [00:17<00:07,  1.09it/s]Epoch: 6/10. Loss: 0.8508:  73%|[36m███████▎  [0m| 19/26 [00:17<00:06,  1.05it/s]Epoch: 6/10. Loss: 0.9310:  73%|[36m███████▎  [0m| 19/26 [00:18<00:06,  1.05it/s]Epoch: 6/10. Loss: 0.9310:  77%|[36m███████▋  [0m| 20/26 [00:18<00:05,  1.05it/s]Epoch: 6/10. Loss: 0.8554:  77%|[36m███████▋  [0m| 20/26 [00:18<00:05,  1.05it/s]Epoch: 6/10. Loss: 0.8554:  81%|[36m████████  [0m| 21/26 [00:18<00:04,  1.06it/s]Epoch: 6/10. Loss: 0.8432:  81%|[36m████████  [0m| 21/26 [00:19<00:04,  1.06it/s]Epoch: 6/10. Loss: 0.8432:  85%|[36m████████▍ [0m| 22/26 [00:19<00:03,  1.14it/s]Epoch: 6/10. Loss: 0.8500:  85%|[36m████████▍ [0m| 22/26 [00:20<00:03,  1.14it/s]Epoch: 6/10. Loss: 0.8500:  88%|[36m████████▊ [0m| 23/26 [00:20<00:02,  1.18it/s]Epoch: 6/10. Loss: 0.7409:  88%|[36m████████▊ [0m| 23/26 [00:21<00:02,  1.18it/s]Epoch: 6/10. Loss: 0.7409:  92%|[36m█████████▏[0m| 24/26 [00:21<00:01,  1.17it/s]Epoch: 6/10. Loss: 0.9469:  92%|[36m█████████▏[0m| 24/26 [00:24<00:01,  1.17it/s]Epoch: 6/10. Loss: 0.9469:  96%|[36m█████████▌[0m| 25/26 [00:24<00:01,  1.45s/it]Epoch: 6/10. Loss: 1.0051:  96%|[36m█████████▌[0m| 25/26 [00:24<00:01,  1.45s/it]Epoch: 6/10. Loss: 1.0051: 100%|[36m██████████[0m| 26/26 [00:24<00:00,  1.20s/it]Epoch: 6/10. Loss: 1.0051: 100%|[36m██████████[0m| 26/26 [00:24<00:00,  1.05it/s]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:04,  1.29it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:05,  1.11s/it] 43%|[33m████▎     [0m| 3/7 [00:02<00:03,  1.13it/s] 57%|[33m█████▋    [0m| 4/7 [00:03<00:02,  1.01it/s] 71%|[33m███████▏  [0m| 5/7 [00:04<00:01,  1.31it/s] 86%|[33m████████▌ [0m| 6/7 [00:05<00:00,  1.30it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.65it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.32it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 7/10. Loss: 0.9398:   0%|[36m          [0m| 0/26 [00:01<?, ?it/s]Epoch: 7/10. Loss: 0.9398:   4%|[36m▍         [0m| 1/26 [00:01<00:25,  1.01s/it]Epoch: 7/10. Loss: 0.8834:   4%|[36m▍         [0m| 1/26 [00:01<00:25,  1.01s/it]Epoch: 7/10. Loss: 0.8834:   8%|[36m▊         [0m| 2/26 [00:01<00:21,  1.09it/s]Epoch: 7/10. Loss: 0.8648:   8%|[36m▊         [0m| 2/26 [00:02<00:21,  1.09it/s]Epoch: 7/10. Loss: 0.8648:  12%|[36m█▏        [0m| 3/26 [00:02<00:20,  1.12it/s]Epoch: 7/10. Loss: 0.7981:  12%|[36m█▏        [0m| 3/26 [00:03<00:20,  1.12it/s]Epoch: 7/10. Loss: 0.7981:  15%|[36m█▌        [0m| 4/26 [00:03<00:20,  1.08it/s]Epoch: 7/10. Loss: 0.9433:  15%|[36m█▌        [0m| 4/26 [00:04<00:20,  1.08it/s]Epoch: 7/10. Loss: 0.9433:  19%|[36m█▉        [0m| 5/26 [00:04<00:17,  1.18it/s]Epoch: 7/10. Loss: 0.9147:  19%|[36m█▉        [0m| 5/26 [00:05<00:17,  1.18it/s]Epoch: 7/10. Loss: 0.9147:  23%|[36m██▎       [0m| 6/26 [00:05<00:16,  1.19it/s]Epoch: 7/10. Loss: 1.0016:  23%|[36m██▎       [0m| 6/26 [00:06<00:16,  1.19it/s]Epoch: 7/10. Loss: 1.0016:  27%|[36m██▋       [0m| 7/26 [00:06<00:16,  1.18it/s]Epoch: 7/10. Loss: 0.8291:  27%|[36m██▋       [0m| 7/26 [00:06<00:16,  1.18it/s]Epoch: 7/10. Loss: 0.8291:  31%|[36m███       [0m| 8/26 [00:06<00:15,  1.20it/s]Epoch: 7/10. Loss: 0.8724:  31%|[36m███       [0m| 8/26 [00:07<00:15,  1.20it/s]Epoch: 7/10. Loss: 0.8724:  35%|[36m███▍      [0m| 9/26 [00:07<00:15,  1.11it/s]Epoch: 7/10. Loss: 0.9025:  35%|[36m███▍      [0m| 9/26 [00:08<00:15,  1.11it/s]Epoch: 7/10. Loss: 0.9025:  38%|[36m███▊      [0m| 10/26 [00:08<00:14,  1.09it/s]Epoch: 7/10. Loss: 0.8031:  38%|[36m███▊      [0m| 10/26 [00:09<00:14,  1.09it/s]Epoch: 7/10. Loss: 0.8031:  42%|[36m████▏     [0m| 11/26 [00:09<00:13,  1.12it/s]Epoch: 7/10. Loss: 0.8287:  42%|[36m████▏     [0m| 11/26 [00:10<00:13,  1.12it/s]Epoch: 7/10. Loss: 0.8287:  46%|[36m████▌     [0m| 12/26 [00:10<00:12,  1.11it/s]Epoch: 7/10. Loss: 1.0617:  46%|[36m████▌     [0m| 12/26 [00:11<00:12,  1.11it/s]Epoch: 7/10. Loss: 1.0617:  50%|[36m█████     [0m| 13/26 [00:11<00:11,  1.09it/s]Epoch: 7/10. Loss: 0.8147:  50%|[36m█████     [0m| 13/26 [00:12<00:11,  1.09it/s]Epoch: 7/10. Loss: 0.8147:  54%|[36m█████▍    [0m| 14/26 [00:12<00:10,  1.14it/s]Epoch: 7/10. Loss: 0.8276:  54%|[36m█████▍    [0m| 14/26 [00:13<00:10,  1.14it/s]Epoch: 7/10. Loss: 0.8276:  58%|[36m█████▊    [0m| 15/26 [00:13<00:09,  1.15it/s]Epoch: 7/10. Loss: 0.8912:  58%|[36m█████▊    [0m| 15/26 [00:14<00:09,  1.15it/s]Epoch: 7/10. Loss: 0.8912:  62%|[36m██████▏   [0m| 16/26 [00:14<00:09,  1.08it/s]Epoch: 7/10. Loss: 0.8527:  62%|[36m██████▏   [0m| 16/26 [00:15<00:09,  1.08it/s]Epoch: 7/10. Loss: 0.8527:  65%|[36m██████▌   [0m| 17/26 [00:15<00:08,  1.07it/s]Epoch: 7/10. Loss: 0.9981:  65%|[36m██████▌   [0m| 17/26 [00:16<00:08,  1.07it/s]Epoch: 7/10. Loss: 0.9981:  69%|[36m██████▉   [0m| 18/26 [00:16<00:07,  1.07it/s]Epoch: 7/10. Loss: 0.8954:  69%|[36m██████▉   [0m| 18/26 [00:16<00:07,  1.07it/s]Epoch: 7/10. Loss: 0.8954:  73%|[36m███████▎  [0m| 19/26 [00:16<00:06,  1.13it/s]Epoch: 7/10. Loss: 0.9395:  73%|[36m███████▎  [0m| 19/26 [00:17<00:06,  1.13it/s]Epoch: 7/10. Loss: 0.9395:  77%|[36m███████▋  [0m| 20/26 [00:17<00:05,  1.09it/s]Epoch: 7/10. Loss: 0.9794:  77%|[36m███████▋  [0m| 20/26 [00:19<00:05,  1.09it/s]Epoch: 7/10. Loss: 0.9794:  81%|[36m████████  [0m| 21/26 [00:19<00:04,  1.04it/s]Epoch: 7/10. Loss: 0.8704:  81%|[36m████████  [0m| 21/26 [00:19<00:04,  1.04it/s]Epoch: 7/10. Loss: 0.8704:  85%|[36m████████▍ [0m| 22/26 [00:19<00:03,  1.04it/s]Epoch: 7/10. Loss: 0.8150:  85%|[36m████████▍ [0m| 22/26 [00:20<00:03,  1.04it/s]Epoch: 7/10. Loss: 0.8150:  88%|[36m████████▊ [0m| 23/26 [00:20<00:02,  1.10it/s]Epoch: 7/10. Loss: 0.9578:  88%|[36m████████▊ [0m| 23/26 [00:21<00:02,  1.10it/s]Epoch: 7/10. Loss: 0.9578:  92%|[36m█████████▏[0m| 24/26 [00:21<00:01,  1.11it/s]Epoch: 7/10. Loss: 0.7374:  92%|[36m█████████▏[0m| 24/26 [00:22<00:01,  1.11it/s]Epoch: 7/10. Loss: 0.7374:  96%|[36m█████████▌[0m| 25/26 [00:22<00:00,  1.09it/s]Epoch: 7/10. Loss: 0.8606:  96%|[36m█████████▌[0m| 25/26 [00:23<00:00,  1.09it/s]Epoch: 7/10. Loss: 0.8606: 100%|[36m██████████[0m| 26/26 [00:23<00:00,  1.24it/s]Epoch: 7/10. Loss: 0.8606: 100%|[36m██████████[0m| 26/26 [00:23<00:00,  1.12it/s]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:04,  1.28it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:05,  1.13s/it] 43%|[33m████▎     [0m| 3/7 [00:02<00:03,  1.10it/s] 57%|[33m█████▋    [0m| 4/7 [00:03<00:03,  1.01s/it] 71%|[33m███████▏  [0m| 5/7 [00:04<00:01,  1.27it/s] 86%|[33m████████▌ [0m| 6/7 [00:05<00:00,  1.26it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.59it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.28it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 8/10. Loss: 0.8443:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 8/10. Loss: 0.8443:   4%|[36m▍         [0m| 1/26 [00:00<00:23,  1.05it/s]Epoch: 8/10. Loss: 0.9281:   4%|[36m▍         [0m| 1/26 [00:01<00:23,  1.05it/s]Epoch: 8/10. Loss: 0.9281:   8%|[36m▊         [0m| 2/26 [00:01<00:20,  1.17it/s]Epoch: 8/10. Loss: 0.8262:   8%|[36m▊         [0m| 2/26 [00:02<00:20,  1.17it/s]Epoch: 8/10. Loss: 0.8262:  12%|[36m█▏        [0m| 3/26 [00:02<00:21,  1.07it/s]Epoch: 8/10. Loss: 0.9296:  12%|[36m█▏        [0m| 3/26 [00:03<00:21,  1.07it/s]Epoch: 8/10. Loss: 0.9296:  15%|[36m█▌        [0m| 4/26 [00:03<00:21,  1.04it/s]Epoch: 8/10. Loss: 0.8216:  15%|[36m█▌        [0m| 4/26 [00:04<00:21,  1.04it/s]Epoch: 8/10. Loss: 0.8216:  19%|[36m█▉        [0m| 5/26 [00:04<00:21,  1.02s/it]Epoch: 8/10. Loss: 0.8780:  19%|[36m█▉        [0m| 5/26 [00:05<00:21,  1.02s/it]Epoch: 8/10. Loss: 0.8780:  23%|[36m██▎       [0m| 6/26 [00:05<00:19,  1.03it/s]Epoch: 8/10. Loss: 0.8488:  23%|[36m██▎       [0m| 6/26 [00:06<00:19,  1.03it/s]Epoch: 8/10. Loss: 0.8488:  27%|[36m██▋       [0m| 7/26 [00:06<00:18,  1.03it/s]Epoch: 8/10. Loss: 0.8711:  27%|[36m██▋       [0m| 7/26 [00:07<00:18,  1.03it/s]Epoch: 8/10. Loss: 0.8711:  31%|[36m███       [0m| 8/26 [00:07<00:16,  1.10it/s]Epoch: 8/10. Loss: 0.8662:  31%|[36m███       [0m| 8/26 [00:08<00:16,  1.10it/s]Epoch: 8/10. Loss: 0.8662:  35%|[36m███▍      [0m| 9/26 [00:08<00:14,  1.15it/s]Epoch: 8/10. Loss: 0.8511:  35%|[36m███▍      [0m| 9/26 [00:09<00:14,  1.15it/s]Epoch: 8/10. Loss: 0.8511:  38%|[36m███▊      [0m| 10/26 [00:09<00:13,  1.17it/s]Epoch: 8/10. Loss: 0.8013:  38%|[36m███▊      [0m| 10/26 [00:09<00:13,  1.17it/s]Epoch: 8/10. Loss: 0.8013:  42%|[36m████▏     [0m| 11/26 [00:09<00:12,  1.18it/s]Epoch: 8/10. Loss: 0.8678:  42%|[36m████▏     [0m| 11/26 [00:10<00:12,  1.18it/s]Epoch: 8/10. Loss: 0.8678:  46%|[36m████▌     [0m| 12/26 [00:10<00:11,  1.22it/s]Epoch: 8/10. Loss: 0.9006:  46%|[36m████▌     [0m| 12/26 [00:11<00:11,  1.22it/s]Epoch: 8/10. Loss: 0.9006:  50%|[36m█████     [0m| 13/26 [00:11<00:11,  1.17it/s]Epoch: 8/10. Loss: 0.7126:  50%|[36m█████     [0m| 13/26 [00:12<00:11,  1.17it/s]Epoch: 8/10. Loss: 0.7126:  54%|[36m█████▍    [0m| 14/26 [00:12<00:10,  1.12it/s]Epoch: 8/10. Loss: 0.9107:  54%|[36m█████▍    [0m| 14/26 [00:13<00:10,  1.12it/s]Epoch: 8/10. Loss: 0.9107:  58%|[36m█████▊    [0m| 15/26 [00:13<00:10,  1.07it/s]Epoch: 8/10. Loss: 0.9155:  58%|[36m█████▊    [0m| 15/26 [00:14<00:10,  1.07it/s]Epoch: 8/10. Loss: 0.9155:  62%|[36m██████▏   [0m| 16/26 [00:14<00:09,  1.09it/s]Epoch: 8/10. Loss: 0.9925:  62%|[36m██████▏   [0m| 16/26 [00:15<00:09,  1.09it/s]Epoch: 8/10. Loss: 0.9925:  65%|[36m██████▌   [0m| 17/26 [00:15<00:08,  1.10it/s]Epoch: 8/10. Loss: 0.8427:  65%|[36m██████▌   [0m| 17/26 [00:16<00:08,  1.10it/s]Epoch: 8/10. Loss: 0.8427:  69%|[36m██████▉   [0m| 18/26 [00:16<00:07,  1.09it/s]Epoch: 8/10. Loss: 0.9668:  69%|[36m██████▉   [0m| 18/26 [00:17<00:07,  1.09it/s]Epoch: 8/10. Loss: 0.9668:  73%|[36m███████▎  [0m| 19/26 [00:17<00:06,  1.07it/s]Epoch: 8/10. Loss: 0.9586:  73%|[36m███████▎  [0m| 19/26 [00:18<00:06,  1.07it/s]Epoch: 8/10. Loss: 0.9586:  77%|[36m███████▋  [0m| 20/26 [00:18<00:05,  1.03it/s]Epoch: 8/10. Loss: 0.8741:  77%|[36m███████▋  [0m| 20/26 [00:19<00:05,  1.03it/s]Epoch: 8/10. Loss: 0.8741:  81%|[36m████████  [0m| 21/26 [00:19<00:04,  1.10it/s]Epoch: 8/10. Loss: 0.9044:  81%|[36m████████  [0m| 21/26 [00:19<00:04,  1.10it/s]Epoch: 8/10. Loss: 0.9044:  85%|[36m████████▍ [0m| 22/26 [00:19<00:03,  1.13it/s]Epoch: 8/10. Loss: 0.8890:  85%|[36m████████▍ [0m| 22/26 [00:20<00:03,  1.13it/s]Epoch: 8/10. Loss: 0.8890:  88%|[36m████████▊ [0m| 23/26 [00:20<00:02,  1.13it/s]Epoch: 8/10. Loss: 0.8650:  88%|[36m████████▊ [0m| 23/26 [00:21<00:02,  1.13it/s]Epoch: 8/10. Loss: 0.8650:  92%|[36m█████████▏[0m| 24/26 [00:21<00:01,  1.18it/s]Epoch: 8/10. Loss: 0.8730:  92%|[36m█████████▏[0m| 24/26 [00:22<00:01,  1.18it/s]Epoch: 8/10. Loss: 0.8730:  96%|[36m█████████▌[0m| 25/26 [00:22<00:00,  1.11it/s]Epoch: 8/10. Loss: 0.8876:  96%|[36m█████████▌[0m| 25/26 [00:23<00:00,  1.11it/s]Epoch: 8/10. Loss: 0.8876: 100%|[36m██████████[0m| 26/26 [00:23<00:00,  1.22it/s]Epoch: 8/10. Loss: 0.8876: 100%|[36m██████████[0m| 26/26 [00:23<00:00,  1.12it/s]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:04,  1.24it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:05,  1.14s/it] 43%|[33m████▎     [0m| 3/7 [00:02<00:03,  1.01it/s] 57%|[33m█████▋    [0m| 4/7 [00:04<00:03,  1.07s/it] 71%|[33m███████▏  [0m| 5/7 [00:04<00:01,  1.23it/s] 86%|[33m████████▌ [0m| 6/7 [00:05<00:00,  1.24it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.59it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.25it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 9/10. Loss: 0.9528:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 9/10. Loss: 0.9528:   4%|[36m▍         [0m| 1/26 [00:00<00:20,  1.24it/s]Epoch: 9/10. Loss: 0.8481:   4%|[36m▍         [0m| 1/26 [00:01<00:20,  1.24it/s]Epoch: 9/10. Loss: 0.8481:   8%|[36m▊         [0m| 2/26 [00:01<00:20,  1.16it/s]Epoch: 9/10. Loss: 0.9112:   8%|[36m▊         [0m| 2/26 [00:02<00:20,  1.16it/s]Epoch: 9/10. Loss: 0.9112:  12%|[36m█▏        [0m| 3/26 [00:02<00:21,  1.05it/s]Epoch: 9/10. Loss: 0.7990:  12%|[36m█▏        [0m| 3/26 [00:03<00:21,  1.05it/s]Epoch: 9/10. Loss: 0.7990:  15%|[36m█▌        [0m| 4/26 [00:03<00:21,  1.01it/s]Epoch: 9/10. Loss: 0.8287:  15%|[36m█▌        [0m| 4/26 [00:04<00:21,  1.01it/s]Epoch: 9/10. Loss: 0.8287:  19%|[36m█▉        [0m| 5/26 [00:04<00:20,  1.05it/s]Epoch: 9/10. Loss: 0.8852:  19%|[36m█▉        [0m| 5/26 [00:05<00:20,  1.05it/s]Epoch: 9/10. Loss: 0.8852:  23%|[36m██▎       [0m| 6/26 [00:05<00:17,  1.12it/s]Epoch: 9/10. Loss: 0.7355:  23%|[36m██▎       [0m| 6/26 [00:06<00:17,  1.12it/s]Epoch: 9/10. Loss: 0.7355:  27%|[36m██▋       [0m| 7/26 [00:06<00:16,  1.13it/s]Epoch: 9/10. Loss: 0.7945:  27%|[36m██▋       [0m| 7/26 [00:07<00:16,  1.13it/s]Epoch: 9/10. Loss: 0.7945:  31%|[36m███       [0m| 8/26 [00:07<00:16,  1.09it/s]Epoch: 9/10. Loss: 0.9442:  31%|[36m███       [0m| 8/26 [00:08<00:16,  1.09it/s]Epoch: 9/10. Loss: 0.9442:  35%|[36m███▍      [0m| 9/26 [00:08<00:15,  1.12it/s]Epoch: 9/10. Loss: 0.8391:  35%|[36m███▍      [0m| 9/26 [00:09<00:15,  1.12it/s]Epoch: 9/10. Loss: 0.8391:  38%|[36m███▊      [0m| 10/26 [00:09<00:14,  1.12it/s]Epoch: 9/10. Loss: 0.8677:  38%|[36m███▊      [0m| 10/26 [00:09<00:14,  1.12it/s]Epoch: 9/10. Loss: 0.8677:  42%|[36m████▏     [0m| 11/26 [00:09<00:13,  1.13it/s]Epoch: 9/10. Loss: 0.8950:  42%|[36m████▏     [0m| 11/26 [00:10<00:13,  1.13it/s]Epoch: 9/10. Loss: 0.8950:  46%|[36m████▌     [0m| 12/26 [00:10<00:12,  1.09it/s]Epoch: 9/10. Loss: 0.9173:  46%|[36m████▌     [0m| 12/26 [00:11<00:12,  1.09it/s]Epoch: 9/10. Loss: 0.9173:  50%|[36m█████     [0m| 13/26 [00:11<00:12,  1.04it/s]Epoch: 9/10. Loss: 0.8317:  50%|[36m█████     [0m| 13/26 [00:12<00:12,  1.04it/s]Epoch: 9/10. Loss: 0.8317:  54%|[36m█████▍    [0m| 14/26 [00:12<00:10,  1.11it/s]Epoch: 9/10. Loss: 0.8608:  54%|[36m█████▍    [0m| 14/26 [00:13<00:10,  1.11it/s]Epoch: 9/10. Loss: 0.8608:  58%|[36m█████▊    [0m| 15/26 [00:13<00:09,  1.13it/s]Epoch: 9/10. Loss: 0.8112:  58%|[36m█████▊    [0m| 15/26 [00:14<00:09,  1.13it/s]Epoch: 9/10. Loss: 0.8112:  62%|[36m██████▏   [0m| 16/26 [00:14<00:08,  1.11it/s]Epoch: 9/10. Loss: 0.7588:  62%|[36m██████▏   [0m| 16/26 [00:15<00:08,  1.11it/s]Epoch: 9/10. Loss: 0.7588:  65%|[36m██████▌   [0m| 17/26 [00:15<00:08,  1.11it/s]Epoch: 9/10. Loss: 1.0867:  65%|[36m██████▌   [0m| 17/26 [00:16<00:08,  1.11it/s]Epoch: 9/10. Loss: 1.0867:  69%|[36m██████▉   [0m| 18/26 [00:16<00:06,  1.17it/s]Epoch: 9/10. Loss: 0.9048:  69%|[36m██████▉   [0m| 18/26 [00:17<00:06,  1.17it/s]Epoch: 9/10. Loss: 0.9048:  73%|[36m███████▎  [0m| 19/26 [00:17<00:06,  1.16it/s]Epoch: 9/10. Loss: 0.8911:  73%|[36m███████▎  [0m| 19/26 [00:17<00:06,  1.16it/s]Epoch: 9/10. Loss: 0.8911:  77%|[36m███████▋  [0m| 20/26 [00:17<00:04,  1.27it/s]Epoch: 9/10. Loss: 0.8214:  77%|[36m███████▋  [0m| 20/26 [00:18<00:04,  1.27it/s]Epoch: 9/10. Loss: 0.8214:  81%|[36m████████  [0m| 21/26 [00:18<00:04,  1.21it/s]Epoch: 9/10. Loss: 0.8554:  81%|[36m████████  [0m| 21/26 [00:19<00:04,  1.21it/s]Epoch: 9/10. Loss: 0.8554:  85%|[36m████████▍ [0m| 22/26 [00:19<00:03,  1.22it/s]Epoch: 9/10. Loss: 0.8332:  85%|[36m████████▍ [0m| 22/26 [00:20<00:03,  1.22it/s]Epoch: 9/10. Loss: 0.8332:  88%|[36m████████▊ [0m| 23/26 [00:20<00:02,  1.22it/s]Epoch: 9/10. Loss: 0.8309:  88%|[36m████████▊ [0m| 23/26 [00:21<00:02,  1.22it/s]Epoch: 9/10. Loss: 0.8309:  92%|[36m█████████▏[0m| 24/26 [00:21<00:01,  1.18it/s]Epoch: 9/10. Loss: 0.8723:  92%|[36m█████████▏[0m| 24/26 [00:22<00:01,  1.18it/s]Epoch: 9/10. Loss: 0.8723:  96%|[36m█████████▌[0m| 25/26 [00:22<00:00,  1.10it/s]Epoch: 9/10. Loss: 0.8833:  96%|[36m█████████▌[0m| 25/26 [00:22<00:00,  1.10it/s]Epoch: 9/10. Loss: 0.8833: 100%|[36m██████████[0m| 26/26 [00:22<00:00,  1.21it/s]Epoch: 9/10. Loss: 0.8833: 100%|[36m██████████[0m| 26/26 [00:22<00:00,  1.14it/s]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:04,  1.22it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:05,  1.19s/it] 43%|[33m████▎     [0m| 3/7 [00:02<00:03,  1.05it/s] 57%|[33m█████▋    [0m| 4/7 [00:04<00:03,  1.05s/it] 71%|[33m███████▏  [0m| 5/7 [00:04<00:01,  1.23it/s] 86%|[33m████████▌ [0m| 6/7 [00:05<00:00,  1.23it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.57it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.25it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 0/10. Loss: 1.3995:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 0/10. Loss: 1.3995:   4%|[36m▍         [0m| 1/26 [00:00<00:21,  1.16it/s]Epoch: 0/10. Loss: 8.0616:   4%|[36m▍         [0m| 1/26 [00:01<00:21,  1.16it/s]Epoch: 0/10. Loss: 8.0616:   8%|[36m▊         [0m| 2/26 [00:01<00:23,  1.04it/s]Epoch: 0/10. Loss: 6.3390:   8%|[36m▊         [0m| 2/26 [00:02<00:23,  1.04it/s]Epoch: 0/10. Loss: 6.3390:  12%|[36m█▏        [0m| 3/26 [00:02<00:22,  1.03it/s]Epoch: 0/10. Loss: 7.0050:  12%|[36m█▏        [0m| 3/26 [00:03<00:22,  1.03it/s]Epoch: 0/10. Loss: 7.0050:  15%|[36m█▌        [0m| 4/26 [00:03<00:20,  1.09it/s]Epoch: 0/10. Loss: 5.6028:  15%|[36m█▌        [0m| 4/26 [00:04<00:20,  1.09it/s]Epoch: 0/10. Loss: 5.6028:  19%|[36m█▉        [0m| 5/26 [00:04<00:18,  1.14it/s]Epoch: 0/10. Loss: 1.4276:  19%|[36m█▉        [0m| 5/26 [00:05<00:18,  1.14it/s]Epoch: 0/10. Loss: 1.4276:  23%|[36m██▎       [0m| 6/26 [00:05<00:19,  1.03it/s]Epoch: 0/10. Loss: 3.7917:  23%|[36m██▎       [0m| 6/26 [00:06<00:19,  1.03it/s]Epoch: 0/10. Loss: 3.7917:  27%|[36m██▋       [0m| 7/26 [00:06<00:18,  1.05it/s]Epoch: 0/10. Loss: 3.0488:  27%|[36m██▋       [0m| 7/26 [00:07<00:18,  1.05it/s]Epoch: 0/10. Loss: 3.0488:  31%|[36m███       [0m| 8/26 [00:07<00:16,  1.08it/s]Epoch: 0/10. Loss: 2.1599:  31%|[36m███       [0m| 8/26 [00:08<00:16,  1.08it/s]Epoch: 0/10. Loss: 2.1599:  35%|[36m███▍      [0m| 9/26 [00:08<00:15,  1.06it/s]Epoch: 0/10. Loss: 2.1881:  35%|[36m███▍      [0m| 9/26 [00:09<00:15,  1.06it/s]Epoch: 0/10. Loss: 2.1881:  38%|[36m███▊      [0m| 10/26 [00:09<00:15,  1.06it/s]Epoch: 0/10. Loss: 1.6169:  38%|[36m███▊      [0m| 10/26 [00:10<00:15,  1.06it/s]Epoch: 0/10. Loss: 1.6169:  42%|[36m████▏     [0m| 11/26 [00:10<00:13,  1.10it/s]Epoch: 0/10. Loss: 1.2531:  42%|[36m████▏     [0m| 11/26 [00:11<00:13,  1.10it/s]Epoch: 0/10. Loss: 1.2531:  46%|[36m████▌     [0m| 12/26 [00:11<00:12,  1.10it/s]Epoch: 0/10. Loss: 1.3698:  46%|[36m████▌     [0m| 12/26 [00:12<00:12,  1.10it/s]Epoch: 0/10. Loss: 1.3698:  50%|[36m█████     [0m| 13/26 [00:12<00:11,  1.09it/s]Epoch: 0/10. Loss: 1.5491:  50%|[36m█████     [0m| 13/26 [00:12<00:11,  1.09it/s]Epoch: 0/10. Loss: 1.5491:  54%|[36m█████▍    [0m| 14/26 [00:12<00:10,  1.10it/s]Epoch: 0/10. Loss: 1.0829:  54%|[36m█████▍    [0m| 14/26 [00:13<00:10,  1.10it/s]Epoch: 0/10. Loss: 1.0829:  58%|[36m█████▊    [0m| 15/26 [00:13<00:09,  1.11it/s]Epoch: 0/10. Loss: 1.0438:  58%|[36m█████▊    [0m| 15/26 [00:14<00:09,  1.11it/s]Epoch: 0/10. Loss: 1.0438:  62%|[36m██████▏   [0m| 16/26 [00:14<00:08,  1.15it/s]Epoch: 0/10. Loss: 1.1412:  62%|[36m██████▏   [0m| 16/26 [00:15<00:08,  1.15it/s]Epoch: 0/10. Loss: 1.1412:  65%|[36m██████▌   [0m| 17/26 [00:15<00:07,  1.13it/s]Epoch: 0/10. Loss: 1.1239:  65%|[36m██████▌   [0m| 17/26 [00:16<00:07,  1.13it/s]Epoch: 0/10. Loss: 1.1239:  69%|[36m██████▉   [0m| 18/26 [00:16<00:06,  1.16it/s]Epoch: 0/10. Loss: 1.0280:  69%|[36m██████▉   [0m| 18/26 [00:17<00:06,  1.16it/s]Epoch: 0/10. Loss: 1.0280:  73%|[36m███████▎  [0m| 19/26 [00:17<00:06,  1.14it/s]Epoch: 0/10. Loss: 1.0639:  73%|[36m███████▎  [0m| 19/26 [00:18<00:06,  1.14it/s]Epoch: 0/10. Loss: 1.0639:  77%|[36m███████▋  [0m| 20/26 [00:18<00:05,  1.04it/s]Epoch: 0/10. Loss: 1.0313:  77%|[36m███████▋  [0m| 20/26 [00:19<00:05,  1.04it/s]Epoch: 0/10. Loss: 1.0313:  81%|[36m████████  [0m| 21/26 [00:19<00:04,  1.04it/s]Epoch: 0/10. Loss: 1.0983:  81%|[36m████████  [0m| 21/26 [00:20<00:04,  1.04it/s]Epoch: 0/10. Loss: 1.0983:  85%|[36m████████▍ [0m| 22/26 [00:20<00:03,  1.06it/s]Epoch: 0/10. Loss: 1.1067:  85%|[36m████████▍ [0m| 22/26 [00:21<00:03,  1.06it/s]Epoch: 0/10. Loss: 1.1067:  88%|[36m████████▊ [0m| 23/26 [00:21<00:02,  1.05it/s]Epoch: 0/10. Loss: 1.1026:  88%|[36m████████▊ [0m| 23/26 [00:22<00:02,  1.05it/s]Epoch: 0/10. Loss: 1.1026:  92%|[36m█████████▏[0m| 24/26 [00:22<00:01,  1.01it/s]Epoch: 0/10. Loss: 1.0316:  92%|[36m█████████▏[0m| 24/26 [00:23<00:01,  1.01it/s]Epoch: 0/10. Loss: 1.0316:  96%|[36m█████████▌[0m| 25/26 [00:23<00:00,  1.02it/s]Epoch: 0/10. Loss: 1.0829:  96%|[36m█████████▌[0m| 25/26 [00:23<00:00,  1.02it/s]Epoch: 0/10. Loss: 1.0829: 100%|[36m██████████[0m| 26/26 [00:23<00:00,  1.14it/s]Epoch: 0/10. Loss: 1.0829: 100%|[36m██████████[0m| 26/26 [00:23<00:00,  1.09it/s]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:05,  1.18it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:05,  1.19s/it] 43%|[33m████▎     [0m| 3/7 [00:03<00:03,  1.02it/s] 57%|[33m█████▋    [0m| 4/7 [00:04<00:03,  1.08s/it] 71%|[33m███████▏  [0m| 5/7 [00:04<00:01,  1.18it/s] 86%|[33m████████▌ [0m| 6/7 [00:05<00:00,  1.17it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.49it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.20it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 1/10. Loss: 1.0746:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 1/10. Loss: 1.0746:   4%|[36m▍         [0m| 1/26 [00:00<00:24,  1.02it/s]Epoch: 1/10. Loss: 0.9802:   4%|[36m▍         [0m| 1/26 [00:01<00:24,  1.02it/s]Epoch: 1/10. Loss: 0.9802:   8%|[36m▊         [0m| 2/26 [00:01<00:21,  1.11it/s]Epoch: 1/10. Loss: 1.0290:   8%|[36m▊         [0m| 2/26 [00:02<00:21,  1.11it/s]Epoch: 1/10. Loss: 1.0290:  12%|[36m█▏        [0m| 3/26 [00:02<00:20,  1.11it/s]Epoch: 1/10. Loss: 1.0759:  12%|[36m█▏        [0m| 3/26 [00:03<00:20,  1.11it/s]Epoch: 1/10. Loss: 1.0759:  15%|[36m█▌        [0m| 4/26 [00:03<00:18,  1.17it/s]Epoch: 1/10. Loss: 1.0293:  15%|[36m█▌        [0m| 4/26 [00:04<00:18,  1.17it/s]Epoch: 1/10. Loss: 1.0293:  19%|[36m█▉        [0m| 5/26 [00:04<00:18,  1.14it/s]Epoch: 1/10. Loss: 0.9911:  19%|[36m█▉        [0m| 5/26 [00:05<00:18,  1.14it/s]Epoch: 1/10. Loss: 0.9911:  23%|[36m██▎       [0m| 6/26 [00:05<00:17,  1.15it/s]Epoch: 1/10. Loss: 1.0049:  23%|[36m██▎       [0m| 6/26 [00:06<00:17,  1.15it/s]Epoch: 1/10. Loss: 1.0049:  27%|[36m██▋       [0m| 7/26 [00:06<00:17,  1.12it/s]Epoch: 1/10. Loss: 0.9669:  27%|[36m██▋       [0m| 7/26 [00:07<00:17,  1.12it/s]Epoch: 1/10. Loss: 0.9669:  31%|[36m███       [0m| 8/26 [00:07<00:17,  1.06it/s]Epoch: 1/10. Loss: 0.9791:  31%|[36m███       [0m| 8/26 [00:08<00:17,  1.06it/s]Epoch: 1/10. Loss: 0.9791:  35%|[36m███▍      [0m| 9/26 [00:08<00:16,  1.05it/s]Epoch: 1/10. Loss: 1.0474:  35%|[36m███▍      [0m| 9/26 [00:09<00:16,  1.05it/s]Epoch: 1/10. Loss: 1.0474:  38%|[36m███▊      [0m| 10/26 [00:09<00:14,  1.08it/s]Epoch: 1/10. Loss: 1.0375:  38%|[36m███▊      [0m| 10/26 [00:10<00:14,  1.08it/s]Epoch: 1/10. Loss: 1.0375:  42%|[36m████▏     [0m| 11/26 [00:10<00:14,  1.06it/s]Epoch: 1/10. Loss: 0.9643:  42%|[36m████▏     [0m| 11/26 [00:10<00:14,  1.06it/s]Epoch: 1/10. Loss: 0.9643:  46%|[36m████▌     [0m| 12/26 [00:10<00:12,  1.11it/s]Epoch: 1/10. Loss: 1.1390:  46%|[36m████▌     [0m| 12/26 [00:11<00:12,  1.11it/s]Epoch: 1/10. Loss: 1.1390:  50%|[36m█████     [0m| 13/26 [00:11<00:12,  1.07it/s]Epoch: 1/10. Loss: 1.0955:  50%|[36m█████     [0m| 13/26 [00:12<00:12,  1.07it/s]Epoch: 1/10. Loss: 1.0955:  54%|[36m█████▍    [0m| 14/26 [00:12<00:10,  1.10it/s]Epoch: 1/10. Loss: 0.9744:  54%|[36m█████▍    [0m| 14/26 [00:13<00:10,  1.10it/s]Epoch: 1/10. Loss: 0.9744:  58%|[36m█████▊    [0m| 15/26 [00:13<00:09,  1.10it/s]Epoch: 1/10. Loss: 1.0353:  58%|[36m█████▊    [0m| 15/26 [00:14<00:09,  1.10it/s]Epoch: 1/10. Loss: 1.0353:  62%|[36m██████▏   [0m| 16/26 [00:14<00:09,  1.08it/s]Epoch: 1/10. Loss: 1.0148:  62%|[36m██████▏   [0m| 16/26 [00:15<00:09,  1.08it/s]Epoch: 1/10. Loss: 1.0148:  65%|[36m██████▌   [0m| 17/26 [00:15<00:08,  1.11it/s]Epoch: 1/10. Loss: 0.9973:  65%|[36m██████▌   [0m| 17/26 [00:16<00:08,  1.11it/s]Epoch: 1/10. Loss: 0.9973:  69%|[36m██████▉   [0m| 18/26 [00:16<00:07,  1.10it/s]Epoch: 1/10. Loss: 1.0252:  69%|[36m██████▉   [0m| 18/26 [00:17<00:07,  1.10it/s]Epoch: 1/10. Loss: 1.0252:  73%|[36m███████▎  [0m| 19/26 [00:17<00:06,  1.08it/s]Epoch: 1/10. Loss: 0.9404:  73%|[36m███████▎  [0m| 19/26 [00:18<00:06,  1.08it/s]Epoch: 1/10. Loss: 0.9404:  77%|[36m███████▋  [0m| 20/26 [00:18<00:05,  1.06it/s]Epoch: 1/10. Loss: 1.0441:  77%|[36m███████▋  [0m| 20/26 [00:19<00:05,  1.06it/s]Epoch: 1/10. Loss: 1.0441:  81%|[36m████████  [0m| 21/26 [00:19<00:04,  1.08it/s]Epoch: 1/10. Loss: 1.0759:  81%|[36m████████  [0m| 21/26 [00:20<00:04,  1.08it/s]Epoch: 1/10. Loss: 1.0759:  85%|[36m████████▍ [0m| 22/26 [00:20<00:03,  1.08it/s]Epoch: 1/10. Loss: 1.0178:  85%|[36m████████▍ [0m| 22/26 [00:21<00:03,  1.08it/s]Epoch: 1/10. Loss: 1.0178:  88%|[36m████████▊ [0m| 23/26 [00:21<00:02,  1.03it/s]Epoch: 1/10. Loss: 0.9382:  88%|[36m████████▊ [0m| 23/26 [00:21<00:02,  1.03it/s]Epoch: 1/10. Loss: 0.9382:  92%|[36m█████████▏[0m| 24/26 [00:22<00:01,  1.10it/s]Epoch: 1/10. Loss: 0.8847:  92%|[36m█████████▏[0m| 24/26 [00:22<00:01,  1.10it/s]Epoch: 1/10. Loss: 0.8847:  96%|[36m█████████▌[0m| 25/26 [00:22<00:00,  1.15it/s]Epoch: 1/10. Loss: 0.9280:  96%|[36m█████████▌[0m| 25/26 [00:23<00:00,  1.15it/s]Epoch: 1/10. Loss: 0.9280: 100%|[36m██████████[0m| 26/26 [00:23<00:00,  1.20it/s]Epoch: 1/10. Loss: 0.9280: 100%|[36m██████████[0m| 26/26 [00:23<00:00,  1.10it/s]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:05,  1.20it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:05,  1.18s/it] 43%|[33m████▎     [0m| 3/7 [00:02<00:03,  1.03it/s] 57%|[33m█████▋    [0m| 4/7 [00:04<00:03,  1.08s/it] 71%|[33m███████▏  [0m| 5/7 [00:04<00:01,  1.17it/s] 86%|[33m████████▌ [0m| 6/7 [00:05<00:00,  1.16it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.48it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.19it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 2/10. Loss: 0.9538:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 2/10. Loss: 0.9538:   4%|[36m▍         [0m| 1/26 [00:00<00:23,  1.06it/s]Epoch: 2/10. Loss: 0.9384:   4%|[36m▍         [0m| 1/26 [00:01<00:23,  1.06it/s]Epoch: 2/10. Loss: 0.9384:   8%|[36m▊         [0m| 2/26 [00:01<00:22,  1.07it/s]Epoch: 2/10. Loss: 1.1423:   8%|[36m▊         [0m| 2/26 [00:02<00:22,  1.07it/s]Epoch: 2/10. Loss: 1.1423:  12%|[36m█▏        [0m| 3/26 [00:02<00:21,  1.06it/s]Epoch: 2/10. Loss: 1.0328:  12%|[36m█▏        [0m| 3/26 [00:03<00:21,  1.06it/s]Epoch: 2/10. Loss: 1.0328:  15%|[36m█▌        [0m| 4/26 [00:03<00:20,  1.08it/s]Epoch: 2/10. Loss: 0.9709:  15%|[36m█▌        [0m| 4/26 [00:04<00:20,  1.08it/s]Epoch: 2/10. Loss: 0.9709:  19%|[36m█▉        [0m| 5/26 [00:04<00:19,  1.06it/s]Epoch: 2/10. Loss: 1.0592:  19%|[36m█▉        [0m| 5/26 [00:05<00:19,  1.06it/s]Epoch: 2/10. Loss: 1.0592:  23%|[36m██▎       [0m| 6/26 [00:05<00:18,  1.07it/s]Epoch: 2/10. Loss: 1.0025:  23%|[36m██▎       [0m| 6/26 [00:06<00:18,  1.07it/s]Epoch: 2/10. Loss: 1.0025:  27%|[36m██▋       [0m| 7/26 [00:06<00:17,  1.10it/s]Epoch: 2/10. Loss: 0.9794:  27%|[36m██▋       [0m| 7/26 [00:07<00:17,  1.10it/s]Epoch: 2/10. Loss: 0.9794:  31%|[36m███       [0m| 8/26 [00:07<00:16,  1.08it/s]Epoch: 2/10. Loss: 1.0605:  31%|[36m███       [0m| 8/26 [00:08<00:16,  1.08it/s]Epoch: 2/10. Loss: 1.0605:  35%|[36m███▍      [0m| 9/26 [00:08<00:14,  1.15it/s]Epoch: 2/10. Loss: 1.0231:  35%|[36m███▍      [0m| 9/26 [00:09<00:14,  1.15it/s]Epoch: 2/10. Loss: 1.0231:  38%|[36m███▊      [0m| 10/26 [00:09<00:14,  1.10it/s]Epoch: 2/10. Loss: 1.0042:  38%|[36m███▊      [0m| 10/26 [00:10<00:14,  1.10it/s]Epoch: 2/10. Loss: 1.0042:  42%|[36m████▏     [0m| 11/26 [00:10<00:13,  1.09it/s]Epoch: 2/10. Loss: 0.9916:  42%|[36m████▏     [0m| 11/26 [00:11<00:13,  1.09it/s]Epoch: 2/10. Loss: 0.9916:  46%|[36m████▌     [0m| 12/26 [00:11<00:13,  1.03it/s]Epoch: 2/10. Loss: 0.9649:  46%|[36m████▌     [0m| 12/26 [00:12<00:13,  1.03it/s]Epoch: 2/10. Loss: 0.9649:  50%|[36m█████     [0m| 13/26 [00:12<00:12,  1.07it/s]Epoch: 2/10. Loss: 0.9936:  50%|[36m█████     [0m| 13/26 [00:13<00:12,  1.07it/s]Epoch: 2/10. Loss: 0.9936:  54%|[36m█████▍    [0m| 14/26 [00:13<00:11,  1.06it/s]Epoch: 2/10. Loss: 0.9777:  54%|[36m█████▍    [0m| 14/26 [00:13<00:11,  1.06it/s]Epoch: 2/10. Loss: 0.9777:  58%|[36m█████▊    [0m| 15/26 [00:13<00:10,  1.09it/s]Epoch: 2/10. Loss: 0.9646:  58%|[36m█████▊    [0m| 15/26 [00:14<00:10,  1.09it/s]Epoch: 2/10. Loss: 0.9646:  62%|[36m██████▏   [0m| 16/26 [00:14<00:09,  1.05it/s]Epoch: 2/10. Loss: 1.0000:  62%|[36m██████▏   [0m| 16/26 [00:15<00:09,  1.05it/s]Epoch: 2/10. Loss: 1.0000:  65%|[36m██████▌   [0m| 17/26 [00:15<00:08,  1.02it/s]Epoch: 2/10. Loss: 1.0618:  65%|[36m██████▌   [0m| 17/26 [00:16<00:08,  1.02it/s]Epoch: 2/10. Loss: 1.0618:  69%|[36m██████▉   [0m| 18/26 [00:16<00:07,  1.08it/s]Epoch: 2/10. Loss: 0.9710:  69%|[36m██████▉   [0m| 18/26 [00:17<00:07,  1.08it/s]Epoch: 2/10. Loss: 0.9710:  73%|[36m███████▎  [0m| 19/26 [00:17<00:06,  1.03it/s]Epoch: 2/10. Loss: 0.9800:  73%|[36m███████▎  [0m| 19/26 [00:18<00:06,  1.03it/s]Epoch: 2/10. Loss: 0.9800:  77%|[36m███████▋  [0m| 20/26 [00:18<00:05,  1.01it/s]Epoch: 2/10. Loss: 0.8943:  77%|[36m███████▋  [0m| 20/26 [00:19<00:05,  1.01it/s]Epoch: 2/10. Loss: 0.8943:  81%|[36m████████  [0m| 21/26 [00:19<00:04,  1.05it/s]Epoch: 2/10. Loss: 0.9381:  81%|[36m████████  [0m| 21/26 [00:20<00:04,  1.05it/s]Epoch: 2/10. Loss: 0.9381:  85%|[36m████████▍ [0m| 22/26 [00:20<00:03,  1.08it/s]Epoch: 2/10. Loss: 0.9835:  85%|[36m████████▍ [0m| 22/26 [00:21<00:03,  1.08it/s]Epoch: 2/10. Loss: 0.9835:  88%|[36m████████▊ [0m| 23/26 [00:21<00:02,  1.10it/s]Epoch: 2/10. Loss: 0.9527:  88%|[36m████████▊ [0m| 23/26 [00:22<00:02,  1.10it/s]Epoch: 2/10. Loss: 0.9527:  92%|[36m█████████▏[0m| 24/26 [00:22<00:01,  1.16it/s]Epoch: 2/10. Loss: 0.9020:  92%|[36m█████████▏[0m| 24/26 [00:23<00:01,  1.16it/s]Epoch: 2/10. Loss: 0.9020:  96%|[36m█████████▌[0m| 25/26 [00:23<00:00,  1.15it/s]Epoch: 2/10. Loss: 0.9926:  96%|[36m█████████▌[0m| 25/26 [00:23<00:00,  1.15it/s]Epoch: 2/10. Loss: 0.9926: 100%|[36m██████████[0m| 26/26 [00:23<00:00,  1.29it/s]Epoch: 2/10. Loss: 0.9926: 100%|[36m██████████[0m| 26/26 [00:23<00:00,  1.10it/s]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:04,  1.20it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:05,  1.19s/it] 43%|[33m████▎     [0m| 3/7 [00:02<00:03,  1.03it/s] 57%|[33m█████▋    [0m| 4/7 [00:04<00:03,  1.18s/it] 71%|[33m███████▏  [0m| 5/7 [00:04<00:01,  1.09it/s] 86%|[33m████████▌ [0m| 6/7 [00:05<00:00,  1.10it/s]100%|[33m██████████[0m| 7/7 [00:06<00:00,  1.42it/s]100%|[33m██████████[0m| 7/7 [00:06<00:00,  1.14it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 3/10. Loss: 0.9253:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 3/10. Loss: 0.9253:   4%|[36m▍         [0m| 1/26 [00:00<00:18,  1.35it/s]Epoch: 3/10. Loss: 0.9222:   4%|[36m▍         [0m| 1/26 [00:01<00:18,  1.35it/s]Epoch: 3/10. Loss: 0.9222:   8%|[36m▊         [0m| 2/26 [00:01<00:17,  1.38it/s]Epoch: 3/10. Loss: 1.0380:   8%|[36m▊         [0m| 2/26 [00:02<00:17,  1.38it/s]Epoch: 3/10. Loss: 1.0380:  12%|[36m█▏        [0m| 3/26 [00:02<00:18,  1.23it/s]Epoch: 3/10. Loss: 0.9843:  12%|[36m█▏        [0m| 3/26 [00:03<00:18,  1.23it/s]Epoch: 3/10. Loss: 0.9843:  15%|[36m█▌        [0m| 4/26 [00:03<00:18,  1.21it/s]Epoch: 3/10. Loss: 1.0198:  15%|[36m█▌        [0m| 4/26 [00:04<00:18,  1.21it/s]Epoch: 3/10. Loss: 1.0198:  19%|[36m█▉        [0m| 5/26 [00:04<00:18,  1.14it/s]Epoch: 3/10. Loss: 1.0442:  19%|[36m█▉        [0m| 5/26 [00:05<00:18,  1.14it/s]Epoch: 3/10. Loss: 1.0442:  23%|[36m██▎       [0m| 6/26 [00:05<00:17,  1.15it/s]Epoch: 3/10. Loss: 1.0667:  23%|[36m██▎       [0m| 6/26 [00:06<00:17,  1.15it/s]Epoch: 3/10. Loss: 1.0667:  27%|[36m██▋       [0m| 7/26 [00:06<00:17,  1.09it/s]Epoch: 3/10. Loss: 0.9767:  27%|[36m██▋       [0m| 7/26 [00:07<00:17,  1.09it/s]Epoch: 3/10. Loss: 0.9767:  31%|[36m███       [0m| 8/26 [00:07<00:17,  1.04it/s]Epoch: 3/10. Loss: 0.9788:  31%|[36m███       [0m| 8/26 [00:08<00:17,  1.04it/s]Epoch: 3/10. Loss: 0.9788:  35%|[36m███▍      [0m| 9/26 [00:08<00:16,  1.04it/s]Epoch: 3/10. Loss: 1.0329:  35%|[36m███▍      [0m| 9/26 [00:08<00:16,  1.04it/s]Epoch: 3/10. Loss: 1.0329:  38%|[36m███▊      [0m| 10/26 [00:08<00:15,  1.06it/s]Epoch: 3/10. Loss: 0.9938:  38%|[36m███▊      [0m| 10/26 [00:09<00:15,  1.06it/s]Epoch: 3/10. Loss: 0.9938:  42%|[36m████▏     [0m| 11/26 [00:09<00:14,  1.04it/s]Epoch: 3/10. Loss: 0.9666:  42%|[36m████▏     [0m| 11/26 [00:10<00:14,  1.04it/s]Epoch: 3/10. Loss: 0.9666:  46%|[36m████▌     [0m| 12/26 [00:10<00:13,  1.04it/s]Epoch: 3/10. Loss: 1.0012:  46%|[36m████▌     [0m| 12/26 [00:11<00:13,  1.04it/s]Epoch: 3/10. Loss: 1.0012:  50%|[36m█████     [0m| 13/26 [00:11<00:12,  1.03it/s]Epoch: 3/10. Loss: 0.9747:  50%|[36m█████     [0m| 13/26 [00:12<00:12,  1.03it/s]Epoch: 3/10. Loss: 0.9747:  54%|[36m█████▍    [0m| 14/26 [00:13<00:11,  1.00it/s]Epoch: 3/10. Loss: 0.9106:  54%|[36m█████▍    [0m| 14/26 [00:13<00:11,  1.00it/s]Epoch: 3/10. Loss: 0.9106:  58%|[36m█████▊    [0m| 15/26 [00:13<00:09,  1.11it/s]Epoch: 3/10. Loss: 1.0002:  58%|[36m█████▊    [0m| 15/26 [00:14<00:09,  1.11it/s]Epoch: 3/10. Loss: 1.0002:  62%|[36m██████▏   [0m| 16/26 [00:14<00:08,  1.14it/s]Epoch: 3/10. Loss: 0.9323:  62%|[36m██████▏   [0m| 16/26 [00:15<00:08,  1.14it/s]Epoch: 3/10. Loss: 0.9323:  65%|[36m██████▌   [0m| 17/26 [00:15<00:07,  1.15it/s]Epoch: 3/10. Loss: 0.9636:  65%|[36m██████▌   [0m| 17/26 [00:16<00:07,  1.15it/s]Epoch: 3/10. Loss: 0.9636:  69%|[36m██████▉   [0m| 18/26 [00:16<00:06,  1.19it/s]Epoch: 3/10. Loss: 0.9945:  69%|[36m██████▉   [0m| 18/26 [00:17<00:06,  1.19it/s]Epoch: 3/10. Loss: 0.9945:  73%|[36m███████▎  [0m| 19/26 [00:17<00:06,  1.15it/s]Epoch: 3/10. Loss: 0.9089:  73%|[36m███████▎  [0m| 19/26 [00:17<00:06,  1.15it/s]Epoch: 3/10. Loss: 0.9089:  77%|[36m███████▋  [0m| 20/26 [00:18<00:05,  1.12it/s]Epoch: 3/10. Loss: 0.9711:  77%|[36m███████▋  [0m| 20/26 [00:18<00:05,  1.12it/s]Epoch: 3/10. Loss: 0.9711:  81%|[36m████████  [0m| 21/26 [00:18<00:04,  1.15it/s]Epoch: 3/10. Loss: 1.0063:  81%|[36m████████  [0m| 21/26 [00:19<00:04,  1.15it/s]Epoch: 3/10. Loss: 1.0063:  85%|[36m████████▍ [0m| 22/26 [00:19<00:03,  1.11it/s]Epoch: 3/10. Loss: 0.9192:  85%|[36m████████▍ [0m| 22/26 [00:20<00:03,  1.11it/s]Epoch: 3/10. Loss: 0.9192:  88%|[36m████████▊ [0m| 23/26 [00:20<00:02,  1.06it/s]Epoch: 3/10. Loss: 1.0404:  88%|[36m████████▊ [0m| 23/26 [00:21<00:02,  1.06it/s]Epoch: 3/10. Loss: 1.0404:  92%|[36m█████████▏[0m| 24/26 [00:21<00:01,  1.02it/s]Epoch: 3/10. Loss: 1.0173:  92%|[36m█████████▏[0m| 24/26 [00:22<00:01,  1.02it/s]Epoch: 3/10. Loss: 1.0173:  96%|[36m█████████▌[0m| 25/26 [00:22<00:00,  1.03it/s]Epoch: 3/10. Loss: 0.9060:  96%|[36m█████████▌[0m| 25/26 [00:23<00:00,  1.03it/s]Epoch: 3/10. Loss: 0.9060: 100%|[36m██████████[0m| 26/26 [00:23<00:00,  1.17it/s]Epoch: 3/10. Loss: 0.9060: 100%|[36m██████████[0m| 26/26 [00:23<00:00,  1.11it/s]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:05,  1.18it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:05,  1.20s/it] 43%|[33m████▎     [0m| 3/7 [00:03<00:03,  1.01it/s] 57%|[33m█████▋    [0m| 4/7 [00:04<00:03,  1.10s/it] 71%|[33m███████▏  [0m| 5/7 [00:04<00:01,  1.15it/s] 86%|[33m████████▌ [0m| 6/7 [00:05<00:00,  1.13it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.44it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.17it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 4/10. Loss: 0.9593:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 4/10. Loss: 0.9593:   4%|[36m▍         [0m| 1/26 [00:00<00:23,  1.07it/s]Epoch: 4/10. Loss: 0.9760:   4%|[36m▍         [0m| 1/26 [00:01<00:23,  1.07it/s]Epoch: 4/10. Loss: 0.9760:   8%|[36m▊         [0m| 2/26 [00:01<00:21,  1.12it/s]Epoch: 4/10. Loss: 0.9756:   8%|[36m▊         [0m| 2/26 [00:02<00:21,  1.12it/s]Epoch: 4/10. Loss: 0.9756:  12%|[36m█▏        [0m| 3/26 [00:02<00:20,  1.14it/s]Epoch: 4/10. Loss: 0.9542:  12%|[36m█▏        [0m| 3/26 [00:03<00:20,  1.14it/s]Epoch: 4/10. Loss: 0.9542:  15%|[36m█▌        [0m| 4/26 [00:03<00:19,  1.13it/s]Epoch: 4/10. Loss: 0.9528:  15%|[36m█▌        [0m| 4/26 [00:04<00:19,  1.13it/s]Epoch: 4/10. Loss: 0.9528:  19%|[36m█▉        [0m| 5/26 [00:04<00:19,  1.09it/s]Epoch: 4/10. Loss: 1.0504:  19%|[36m█▉        [0m| 5/26 [00:05<00:19,  1.09it/s]Epoch: 4/10. Loss: 1.0504:  23%|[36m██▎       [0m| 6/26 [00:05<00:19,  1.04it/s]Epoch: 4/10. Loss: 1.0361:  23%|[36m██▎       [0m| 6/26 [00:06<00:19,  1.04it/s]Epoch: 4/10. Loss: 1.0361:  27%|[36m██▋       [0m| 7/26 [00:06<00:19,  1.01s/it]Epoch: 4/10. Loss: 1.0010:  27%|[36m██▋       [0m| 7/26 [00:07<00:19,  1.01s/it]Epoch: 4/10. Loss: 1.0010:  31%|[36m███       [0m| 8/26 [00:07<00:17,  1.00it/s]Epoch: 4/10. Loss: 0.9115:  31%|[36m███       [0m| 8/26 [00:08<00:17,  1.00it/s]Epoch: 4/10. Loss: 0.9115:  35%|[36m███▍      [0m| 9/26 [00:08<00:15,  1.12it/s]Epoch: 4/10. Loss: 1.0042:  35%|[36m███▍      [0m| 9/26 [00:09<00:15,  1.12it/s]Epoch: 4/10. Loss: 1.0042:  38%|[36m███▊      [0m| 10/26 [00:09<00:15,  1.03it/s]Epoch: 4/10. Loss: 1.0221:  38%|[36m███▊      [0m| 10/26 [00:10<00:15,  1.03it/s]Epoch: 4/10. Loss: 1.0221:  42%|[36m████▏     [0m| 11/26 [00:10<00:14,  1.02it/s]Epoch: 4/10. Loss: 0.9705:  42%|[36m████▏     [0m| 11/26 [00:11<00:14,  1.02it/s]Epoch: 4/10. Loss: 0.9705:  46%|[36m████▌     [0m| 12/26 [00:11<00:13,  1.02it/s]Epoch: 4/10. Loss: 1.0358:  46%|[36m████▌     [0m| 12/26 [00:12<00:13,  1.02it/s]Epoch: 4/10. Loss: 1.0358:  50%|[36m█████     [0m| 13/26 [00:12<00:12,  1.02it/s]Epoch: 4/10. Loss: 0.9577:  50%|[36m█████     [0m| 13/26 [00:13<00:12,  1.02it/s]Epoch: 4/10. Loss: 0.9577:  54%|[36m█████▍    [0m| 14/26 [00:13<00:11,  1.03it/s]Epoch: 4/10. Loss: 1.0192:  54%|[36m█████▍    [0m| 14/26 [00:14<00:11,  1.03it/s]Epoch: 4/10. Loss: 1.0192:  58%|[36m█████▊    [0m| 15/26 [00:14<00:10,  1.01it/s]Epoch: 4/10. Loss: 0.9327:  58%|[36m█████▊    [0m| 15/26 [00:15<00:10,  1.01it/s]Epoch: 4/10. Loss: 0.9327:  62%|[36m██████▏   [0m| 16/26 [00:15<00:09,  1.03it/s]Epoch: 4/10. Loss: 0.9723:  62%|[36m██████▏   [0m| 16/26 [00:16<00:09,  1.03it/s]Epoch: 4/10. Loss: 0.9723:  65%|[36m██████▌   [0m| 17/26 [00:16<00:08,  1.05it/s]Epoch: 4/10. Loss: 1.0177:  65%|[36m██████▌   [0m| 17/26 [00:16<00:08,  1.05it/s]Epoch: 4/10. Loss: 1.0177:  69%|[36m██████▉   [0m| 18/26 [00:16<00:07,  1.12it/s]Epoch: 4/10. Loss: 0.8713:  69%|[36m██████▉   [0m| 18/26 [00:18<00:07,  1.12it/s]Epoch: 4/10. Loss: 0.8713:  73%|[36m███████▎  [0m| 19/26 [00:18<00:06,  1.06it/s]Epoch: 4/10. Loss: 0.8941:  73%|[36m███████▎  [0m| 19/26 [00:18<00:06,  1.06it/s]Epoch: 4/10. Loss: 0.8941:  77%|[36m███████▋  [0m| 20/26 [00:18<00:05,  1.09it/s]Epoch: 4/10. Loss: 0.9357:  77%|[36m███████▋  [0m| 20/26 [00:19<00:05,  1.09it/s]Epoch: 4/10. Loss: 0.9357:  81%|[36m████████  [0m| 21/26 [00:19<00:04,  1.12it/s]Epoch: 4/10. Loss: 0.8607:  81%|[36m████████  [0m| 21/26 [00:20<00:04,  1.12it/s]Epoch: 4/10. Loss: 0.8607:  85%|[36m████████▍ [0m| 22/26 [00:20<00:03,  1.19it/s]Epoch: 4/10. Loss: 0.9289:  85%|[36m████████▍ [0m| 22/26 [00:21<00:03,  1.19it/s]Epoch: 4/10. Loss: 0.9289:  88%|[36m████████▊ [0m| 23/26 [00:21<00:02,  1.21it/s]Epoch: 4/10. Loss: 0.9375:  88%|[36m████████▊ [0m| 23/26 [00:22<00:02,  1.21it/s]Epoch: 4/10. Loss: 0.9375:  92%|[36m█████████▏[0m| 24/26 [00:22<00:01,  1.17it/s]Epoch: 4/10. Loss: 0.9985:  92%|[36m█████████▏[0m| 24/26 [00:23<00:01,  1.17it/s]Epoch: 4/10. Loss: 0.9985:  96%|[36m█████████▌[0m| 25/26 [00:23<00:00,  1.11it/s]Epoch: 4/10. Loss: 0.9273:  96%|[36m█████████▌[0m| 25/26 [00:23<00:00,  1.11it/s]Epoch: 4/10. Loss: 0.9273: 100%|[36m██████████[0m| 26/26 [00:23<00:00,  1.25it/s]Epoch: 4/10. Loss: 0.9273: 100%|[36m██████████[0m| 26/26 [00:23<00:00,  1.10it/s]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:05,  1.17it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:05,  1.20s/it] 43%|[33m████▎     [0m| 3/7 [00:03<00:03,  1.01it/s] 57%|[33m█████▋    [0m| 4/7 [00:04<00:03,  1.09s/it] 71%|[33m███████▏  [0m| 5/7 [00:04<00:01,  1.14it/s] 86%|[33m████████▌ [0m| 6/7 [00:05<00:00,  1.14it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.44it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.17it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 5/10. Loss: 0.9158:   0%|[36m          [0m| 0/26 [00:01<?, ?it/s]Epoch: 5/10. Loss: 0.9158:   4%|[36m▍         [0m| 1/26 [00:01<00:26,  1.08s/it]Epoch: 5/10. Loss: 0.9772:   4%|[36m▍         [0m| 1/26 [00:02<00:26,  1.08s/it]Epoch: 5/10. Loss: 0.9772:   8%|[36m▊         [0m| 2/26 [00:02<00:25,  1.07s/it]Epoch: 5/10. Loss: 1.0864:   8%|[36m▊         [0m| 2/26 [00:02<00:25,  1.07s/it]Epoch: 5/10. Loss: 1.0864:  12%|[36m█▏        [0m| 3/26 [00:02<00:22,  1.03it/s]Epoch: 5/10. Loss: 0.9652:  12%|[36m█▏        [0m| 3/26 [00:03<00:22,  1.03it/s]Epoch: 5/10. Loss: 0.9652:  15%|[36m█▌        [0m| 4/26 [00:03<00:21,  1.02it/s]Epoch: 5/10. Loss: 0.9552:  15%|[36m█▌        [0m| 4/26 [00:05<00:21,  1.02it/s]Epoch: 5/10. Loss: 0.9552:  19%|[36m█▉        [0m| 5/26 [00:05<00:21,  1.02s/it]Epoch: 5/10. Loss: 1.0172:  19%|[36m█▉        [0m| 5/26 [00:05<00:21,  1.02s/it]Epoch: 5/10. Loss: 1.0172:  23%|[36m██▎       [0m| 6/26 [00:05<00:19,  1.05it/s]Epoch: 5/10. Loss: 0.9988:  23%|[36m██▎       [0m| 6/26 [00:06<00:19,  1.05it/s]Epoch: 5/10. Loss: 0.9988:  27%|[36m██▋       [0m| 7/26 [00:06<00:17,  1.07it/s]Epoch: 5/10. Loss: 0.9447:  27%|[36m██▋       [0m| 7/26 [00:07<00:17,  1.07it/s]Epoch: 5/10. Loss: 0.9447:  31%|[36m███       [0m| 8/26 [00:07<00:16,  1.08it/s]Epoch: 5/10. Loss: 0.9273:  31%|[36m███       [0m| 8/26 [00:08<00:16,  1.08it/s]Epoch: 5/10. Loss: 0.9273:  35%|[36m███▍      [0m| 9/26 [00:08<00:15,  1.09it/s]Epoch: 5/10. Loss: 0.8963:  35%|[36m███▍      [0m| 9/26 [00:09<00:15,  1.09it/s]Epoch: 5/10. Loss: 0.8963:  38%|[36m███▊      [0m| 10/26 [00:09<00:15,  1.05it/s]Epoch: 5/10. Loss: 0.9339:  38%|[36m███▊      [0m| 10/26 [00:10<00:15,  1.05it/s]Epoch: 5/10. Loss: 0.9339:  42%|[36m████▏     [0m| 11/26 [00:10<00:13,  1.09it/s]Epoch: 5/10. Loss: 0.8697:  42%|[36m████▏     [0m| 11/26 [00:11<00:13,  1.09it/s]Epoch: 5/10. Loss: 0.8697:  46%|[36m████▌     [0m| 12/26 [00:11<00:12,  1.10it/s]Epoch: 5/10. Loss: 0.8891:  46%|[36m████▌     [0m| 12/26 [00:12<00:12,  1.10it/s]Epoch: 5/10. Loss: 0.8891:  50%|[36m█████     [0m| 13/26 [00:12<00:11,  1.10it/s]Epoch: 5/10. Loss: 1.0591:  50%|[36m█████     [0m| 13/26 [00:13<00:11,  1.10it/s]Epoch: 5/10. Loss: 1.0591:  54%|[36m█████▍    [0m| 14/26 [00:13<00:10,  1.16it/s]Epoch: 5/10. Loss: 0.8789:  54%|[36m█████▍    [0m| 14/26 [00:13<00:10,  1.16it/s]Epoch: 5/10. Loss: 0.8789:  58%|[36m█████▊    [0m| 15/26 [00:13<00:09,  1.15it/s]Epoch: 5/10. Loss: 0.9862:  58%|[36m█████▊    [0m| 15/26 [00:14<00:09,  1.15it/s]Epoch: 5/10. Loss: 0.9862:  62%|[36m██████▏   [0m| 16/26 [00:14<00:08,  1.14it/s]Epoch: 5/10. Loss: 0.9239:  62%|[36m██████▏   [0m| 16/26 [00:15<00:08,  1.14it/s]Epoch: 5/10. Loss: 0.9239:  65%|[36m██████▌   [0m| 17/26 [00:15<00:07,  1.15it/s]Epoch: 5/10. Loss: 1.0652:  65%|[36m██████▌   [0m| 17/26 [00:16<00:07,  1.15it/s]Epoch: 5/10. Loss: 1.0652:  69%|[36m██████▉   [0m| 18/26 [00:16<00:07,  1.09it/s]Epoch: 5/10. Loss: 0.9704:  69%|[36m██████▉   [0m| 18/26 [00:17<00:07,  1.09it/s]Epoch: 5/10. Loss: 0.9704:  73%|[36m███████▎  [0m| 19/26 [00:17<00:06,  1.10it/s]Epoch: 5/10. Loss: 1.0261:  73%|[36m███████▎  [0m| 19/26 [00:18<00:06,  1.10it/s]Epoch: 5/10. Loss: 1.0261:  77%|[36m███████▋  [0m| 20/26 [00:18<00:05,  1.12it/s]Epoch: 5/10. Loss: 0.9197:  77%|[36m███████▋  [0m| 20/26 [00:19<00:05,  1.12it/s]Epoch: 5/10. Loss: 0.9197:  81%|[36m████████  [0m| 21/26 [00:19<00:04,  1.02it/s]Epoch: 5/10. Loss: 0.9973:  81%|[36m████████  [0m| 21/26 [00:20<00:04,  1.02it/s]Epoch: 5/10. Loss: 0.9973:  85%|[36m████████▍ [0m| 22/26 [00:20<00:03,  1.04it/s]Epoch: 5/10. Loss: 0.9676:  85%|[36m████████▍ [0m| 22/26 [00:21<00:03,  1.04it/s]Epoch: 5/10. Loss: 0.9676:  88%|[36m████████▊ [0m| 23/26 [00:21<00:02,  1.03it/s]Epoch: 5/10. Loss: 1.0557:  88%|[36m████████▊ [0m| 23/26 [00:22<00:02,  1.03it/s]Epoch: 5/10. Loss: 1.0557:  92%|[36m█████████▏[0m| 24/26 [00:22<00:01,  1.06it/s]Epoch: 5/10. Loss: 0.9748:  92%|[36m█████████▏[0m| 24/26 [00:23<00:01,  1.06it/s]Epoch: 5/10. Loss: 0.9748:  96%|[36m█████████▌[0m| 25/26 [00:23<00:00,  1.06it/s]Epoch: 5/10. Loss: 0.9783:  96%|[36m█████████▌[0m| 25/26 [00:23<00:00,  1.06it/s]Epoch: 5/10. Loss: 0.9783: 100%|[36m██████████[0m| 26/26 [00:23<00:00,  1.18it/s]Epoch: 5/10. Loss: 0.9783: 100%|[36m██████████[0m| 26/26 [00:23<00:00,  1.08it/s]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:05,  1.17it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:05,  1.20s/it] 43%|[33m████▎     [0m| 3/7 [00:03<00:04,  1.17s/it] 57%|[33m█████▋    [0m| 4/7 [00:05<00:04,  1.39s/it] 71%|[33m███████▏  [0m| 5/7 [00:05<00:02,  1.06s/it] 86%|[33m████████▌ [0m| 6/7 [00:06<00:01,  1.01s/it]100%|[33m██████████[0m| 7/7 [00:06<00:00,  1.27it/s]100%|[33m██████████[0m| 7/7 [00:06<00:00,  1.02it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 6/10. Loss: 0.9351:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 6/10. Loss: 0.9351:   4%|[36m▍         [0m| 1/26 [00:00<00:22,  1.13it/s]Epoch: 6/10. Loss: 0.9488:   4%|[36m▍         [0m| 1/26 [00:01<00:22,  1.13it/s]Epoch: 6/10. Loss: 0.9488:   8%|[36m▊         [0m| 2/26 [00:01<00:20,  1.18it/s]Epoch: 6/10. Loss: 1.0059:   8%|[36m▊         [0m| 2/26 [00:02<00:20,  1.18it/s]Epoch: 6/10. Loss: 1.0059:  12%|[36m█▏        [0m| 3/26 [00:02<00:20,  1.13it/s]Epoch: 6/10. Loss: 0.9965:  12%|[36m█▏        [0m| 3/26 [00:03<00:20,  1.13it/s]Epoch: 6/10. Loss: 0.9965:  15%|[36m█▌        [0m| 4/26 [00:03<00:19,  1.13it/s]Epoch: 6/10. Loss: 1.0475:  15%|[36m█▌        [0m| 4/26 [00:04<00:19,  1.13it/s]Epoch: 6/10. Loss: 1.0475:  19%|[36m█▉        [0m| 5/26 [00:04<00:19,  1.08it/s]Epoch: 6/10. Loss: 0.9246:  19%|[36m█▉        [0m| 5/26 [00:05<00:19,  1.08it/s]Epoch: 6/10. Loss: 0.9246:  23%|[36m██▎       [0m| 6/26 [00:05<00:18,  1.06it/s]Epoch: 6/10. Loss: 0.8976:  23%|[36m██▎       [0m| 6/26 [00:06<00:18,  1.06it/s]Epoch: 6/10. Loss: 0.8976:  27%|[36m██▋       [0m| 7/26 [00:06<00:17,  1.11it/s]Epoch: 6/10. Loss: 1.0112:  27%|[36m██▋       [0m| 7/26 [00:07<00:17,  1.11it/s]Epoch: 6/10. Loss: 1.0112:  31%|[36m███       [0m| 8/26 [00:07<00:17,  1.06it/s]Epoch: 6/10. Loss: 0.9519:  31%|[36m███       [0m| 8/26 [00:08<00:17,  1.06it/s]Epoch: 6/10. Loss: 0.9519:  35%|[36m███▍      [0m| 9/26 [00:08<00:15,  1.07it/s]Epoch: 6/10. Loss: 1.0061:  35%|[36m███▍      [0m| 9/26 [00:09<00:15,  1.07it/s]Epoch: 6/10. Loss: 1.0061:  38%|[36m███▊      [0m| 10/26 [00:09<00:14,  1.12it/s]Epoch: 6/10. Loss: 0.9193:  38%|[36m███▊      [0m| 10/26 [00:10<00:14,  1.12it/s]Epoch: 6/10. Loss: 0.9193:  42%|[36m████▏     [0m| 11/26 [00:10<00:13,  1.08it/s]Epoch: 6/10. Loss: 0.9316:  42%|[36m████▏     [0m| 11/26 [00:10<00:13,  1.08it/s]Epoch: 6/10. Loss: 0.9316:  46%|[36m████▌     [0m| 12/26 [00:11<00:12,  1.08it/s]Epoch: 6/10. Loss: 1.0622:  46%|[36m████▌     [0m| 12/26 [00:12<00:12,  1.08it/s]Epoch: 6/10. Loss: 1.0622:  50%|[36m█████     [0m| 13/26 [00:12<00:13,  1.01s/it]Epoch: 6/10. Loss: 0.9584:  50%|[36m█████     [0m| 13/26 [00:13<00:13,  1.01s/it]Epoch: 6/10. Loss: 0.9584:  54%|[36m█████▍    [0m| 14/26 [00:13<00:12,  1.01s/it]Epoch: 6/10. Loss: 1.0262:  54%|[36m█████▍    [0m| 14/26 [00:14<00:12,  1.01s/it]Epoch: 6/10. Loss: 1.0262:  58%|[36m█████▊    [0m| 15/26 [00:14<00:11,  1.04s/it]Epoch: 6/10. Loss: 1.0036:  58%|[36m█████▊    [0m| 15/26 [00:15<00:11,  1.04s/it]Epoch: 6/10. Loss: 1.0036:  62%|[36m██████▏   [0m| 16/26 [00:15<00:10,  1.03s/it]Epoch: 6/10. Loss: 0.9812:  62%|[36m██████▏   [0m| 16/26 [00:16<00:10,  1.03s/it]Epoch: 6/10. Loss: 0.9812:  65%|[36m██████▌   [0m| 17/26 [00:16<00:09,  1.01s/it]Epoch: 6/10. Loss: 0.9843:  65%|[36m██████▌   [0m| 17/26 [00:17<00:09,  1.01s/it]Epoch: 6/10. Loss: 0.9843:  69%|[36m██████▉   [0m| 18/26 [00:17<00:07,  1.08it/s]Epoch: 6/10. Loss: 0.9551:  69%|[36m██████▉   [0m| 18/26 [00:17<00:07,  1.08it/s]Epoch: 6/10. Loss: 0.9551:  73%|[36m███████▎  [0m| 19/26 [00:17<00:06,  1.10it/s]Epoch: 6/10. Loss: 0.9422:  73%|[36m███████▎  [0m| 19/26 [00:18<00:06,  1.10it/s]Epoch: 6/10. Loss: 0.9422:  77%|[36m███████▋  [0m| 20/26 [00:18<00:05,  1.10it/s]Epoch: 6/10. Loss: 0.9418:  77%|[36m███████▋  [0m| 20/26 [00:19<00:05,  1.10it/s]Epoch: 6/10. Loss: 0.9418:  81%|[36m████████  [0m| 21/26 [00:19<00:04,  1.09it/s]Epoch: 6/10. Loss: 0.9227:  81%|[36m████████  [0m| 21/26 [00:20<00:04,  1.09it/s]Epoch: 6/10. Loss: 0.9227:  85%|[36m████████▍ [0m| 22/26 [00:20<00:03,  1.12it/s]Epoch: 6/10. Loss: 0.9346:  85%|[36m████████▍ [0m| 22/26 [00:21<00:03,  1.12it/s]Epoch: 6/10. Loss: 0.9346:  88%|[36m████████▊ [0m| 23/26 [00:21<00:02,  1.10it/s]Epoch: 6/10. Loss: 1.0302:  88%|[36m████████▊ [0m| 23/26 [00:22<00:02,  1.10it/s]Epoch: 6/10. Loss: 1.0302:  92%|[36m█████████▏[0m| 24/26 [00:22<00:01,  1.11it/s]Epoch: 6/10. Loss: 0.8530:  92%|[36m█████████▏[0m| 24/26 [00:23<00:01,  1.11it/s]Epoch: 6/10. Loss: 0.8530:  96%|[36m█████████▌[0m| 25/26 [00:23<00:00,  1.09it/s]Epoch: 6/10. Loss: 0.9112:  96%|[36m█████████▌[0m| 25/26 [00:24<00:00,  1.09it/s]Epoch: 6/10. Loss: 0.9112: 100%|[36m██████████[0m| 26/26 [00:24<00:00,  1.19it/s]Epoch: 6/10. Loss: 0.9112: 100%|[36m██████████[0m| 26/26 [00:24<00:00,  1.08it/s]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:05,  1.14it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:06,  1.24s/it] 43%|[33m████▎     [0m| 3/7 [00:03<00:04,  1.02s/it] 57%|[33m█████▋    [0m| 4/7 [00:04<00:03,  1.13s/it] 71%|[33m███████▏  [0m| 5/7 [00:04<00:01,  1.14it/s] 86%|[33m████████▌ [0m| 6/7 [00:05<00:00,  1.16it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.49it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.17it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 7/10. Loss: 0.9391:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 7/10. Loss: 0.9391:   4%|[36m▍         [0m| 1/26 [00:00<00:22,  1.10it/s]Epoch: 7/10. Loss: 0.9007:   4%|[36m▍         [0m| 1/26 [00:01<00:22,  1.10it/s]Epoch: 7/10. Loss: 0.9007:   8%|[36m▊         [0m| 2/26 [00:01<00:22,  1.08it/s]Epoch: 7/10. Loss: 0.9421:   8%|[36m▊         [0m| 2/26 [00:02<00:22,  1.08it/s]Epoch: 7/10. Loss: 0.9421:  12%|[36m█▏        [0m| 3/26 [00:02<00:21,  1.06it/s]Epoch: 7/10. Loss: 0.9090:  12%|[36m█▏        [0m| 3/26 [00:03<00:21,  1.06it/s]Epoch: 7/10. Loss: 0.9090:  15%|[36m█▌        [0m| 4/26 [00:03<00:21,  1.01it/s]Epoch: 7/10. Loss: 0.8495:  15%|[36m█▌        [0m| 4/26 [00:04<00:21,  1.01it/s]Epoch: 7/10. Loss: 0.8495:  19%|[36m█▉        [0m| 5/26 [00:04<00:20,  1.04it/s]Epoch: 7/10. Loss: 0.9999:  19%|[36m█▉        [0m| 5/26 [00:05<00:20,  1.04it/s]Epoch: 7/10. Loss: 0.9999:  23%|[36m██▎       [0m| 6/26 [00:05<00:19,  1.04it/s]Epoch: 7/10. Loss: 1.0288:  23%|[36m██▎       [0m| 6/26 [00:06<00:19,  1.04it/s]Epoch: 7/10. Loss: 1.0288:  27%|[36m██▋       [0m| 7/26 [00:06<00:17,  1.06it/s]Epoch: 7/10. Loss: 0.9099:  27%|[36m██▋       [0m| 7/26 [00:07<00:17,  1.06it/s]Epoch: 7/10. Loss: 0.9099:  31%|[36m███       [0m| 8/26 [00:07<00:18,  1.02s/it]Epoch: 7/10. Loss: 0.9580:  31%|[36m███       [0m| 8/26 [00:08<00:18,  1.02s/it]Epoch: 7/10. Loss: 0.9580:  35%|[36m███▍      [0m| 9/26 [00:08<00:16,  1.02it/s]Epoch: 7/10. Loss: 0.9182:  35%|[36m███▍      [0m| 9/26 [00:09<00:16,  1.02it/s]Epoch: 7/10. Loss: 0.9182:  38%|[36m███▊      [0m| 10/26 [00:09<00:15,  1.04it/s]Epoch: 7/10. Loss: 0.9388:  38%|[36m███▊      [0m| 10/26 [00:10<00:15,  1.04it/s]Epoch: 7/10. Loss: 0.9388:  42%|[36m████▏     [0m| 11/26 [00:10<00:14,  1.03it/s]Epoch: 7/10. Loss: 0.9033:  42%|[36m████▏     [0m| 11/26 [00:11<00:14,  1.03it/s]Epoch: 7/10. Loss: 0.9033:  46%|[36m████▌     [0m| 12/26 [00:11<00:13,  1.04it/s]Epoch: 7/10. Loss: 0.9733:  46%|[36m████▌     [0m| 12/26 [00:12<00:13,  1.04it/s]Epoch: 7/10. Loss: 0.9733:  50%|[36m█████     [0m| 13/26 [00:12<00:12,  1.03it/s]Epoch: 7/10. Loss: 0.9720:  50%|[36m█████     [0m| 13/26 [00:13<00:12,  1.03it/s]Epoch: 7/10. Loss: 0.9720:  54%|[36m█████▍    [0m| 14/26 [00:13<00:11,  1.00it/s]Epoch: 7/10. Loss: 0.8827:  54%|[36m█████▍    [0m| 14/26 [00:14<00:11,  1.00it/s]Epoch: 7/10. Loss: 0.8827:  58%|[36m█████▊    [0m| 15/26 [00:14<00:11,  1.02s/it]Epoch: 7/10. Loss: 0.9992:  58%|[36m█████▊    [0m| 15/26 [00:15<00:11,  1.02s/it]Epoch: 7/10. Loss: 0.9992:  62%|[36m██████▏   [0m| 16/26 [00:15<00:10,  1.01s/it]Epoch: 7/10. Loss: 0.9162:  62%|[36m██████▏   [0m| 16/26 [00:16<00:10,  1.01s/it]Epoch: 7/10. Loss: 0.9162:  65%|[36m██████▌   [0m| 17/26 [00:16<00:08,  1.00it/s]Epoch: 7/10. Loss: 0.9627:  65%|[36m██████▌   [0m| 17/26 [00:17<00:08,  1.00it/s]Epoch: 7/10. Loss: 0.9627:  69%|[36m██████▉   [0m| 18/26 [00:17<00:07,  1.04it/s]Epoch: 7/10. Loss: 0.9075:  69%|[36m██████▉   [0m| 18/26 [00:18<00:07,  1.04it/s]Epoch: 7/10. Loss: 0.9075:  73%|[36m███████▎  [0m| 19/26 [00:18<00:06,  1.09it/s]Epoch: 7/10. Loss: 0.9196:  73%|[36m███████▎  [0m| 19/26 [00:19<00:06,  1.09it/s]Epoch: 7/10. Loss: 0.9196:  77%|[36m███████▋  [0m| 20/26 [00:19<00:05,  1.12it/s]Epoch: 7/10. Loss: 0.9429:  77%|[36m███████▋  [0m| 20/26 [00:20<00:05,  1.12it/s]Epoch: 7/10. Loss: 0.9429:  81%|[36m████████  [0m| 21/26 [00:20<00:04,  1.08it/s]Epoch: 7/10. Loss: 0.9095:  81%|[36m████████  [0m| 21/26 [00:21<00:04,  1.08it/s]Epoch: 7/10. Loss: 0.9095:  85%|[36m████████▍ [0m| 22/26 [00:21<00:03,  1.11it/s]Epoch: 7/10. Loss: 0.8811:  85%|[36m████████▍ [0m| 22/26 [00:24<00:03,  1.11it/s]Epoch: 7/10. Loss: 0.8811:  88%|[36m████████▊ [0m| 23/26 [00:24<00:05,  1.82s/it]Epoch: 7/10. Loss: 0.8820:  88%|[36m████████▊ [0m| 23/26 [00:25<00:05,  1.82s/it]Epoch: 7/10. Loss: 0.8820:  92%|[36m█████████▏[0m| 24/26 [00:25<00:03,  1.52s/it]Epoch: 7/10. Loss: 0.9186:  92%|[36m█████████▏[0m| 24/26 [00:26<00:03,  1.52s/it]Epoch: 7/10. Loss: 0.9186:  96%|[36m█████████▌[0m| 25/26 [00:26<00:01,  1.31s/it]Epoch: 7/10. Loss: 0.9687:  96%|[36m█████████▌[0m| 25/26 [00:27<00:01,  1.31s/it]Epoch: 7/10. Loss: 0.9687: 100%|[36m██████████[0m| 26/26 [00:27<00:00,  1.10s/it]Epoch: 7/10. Loss: 0.9687: 100%|[36m██████████[0m| 26/26 [00:27<00:00,  1.05s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:05,  1.17it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:06,  1.20s/it] 43%|[33m████▎     [0m| 3/7 [00:03<00:03,  1.00it/s] 57%|[33m█████▋    [0m| 4/7 [00:04<00:03,  1.10s/it] 71%|[33m███████▏  [0m| 5/7 [00:04<00:01,  1.17it/s] 86%|[33m████████▌ [0m| 6/7 [00:05<00:00,  1.17it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.50it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.19it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 8/10. Loss: 0.8786:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 8/10. Loss: 0.8786:   4%|[36m▍         [0m| 1/26 [00:00<00:24,  1.02it/s]Epoch: 8/10. Loss: 0.8441:   4%|[36m▍         [0m| 1/26 [00:01<00:24,  1.02it/s]Epoch: 8/10. Loss: 0.8441:   8%|[36m▊         [0m| 2/26 [00:01<00:21,  1.11it/s]Epoch: 8/10. Loss: 0.9604:   8%|[36m▊         [0m| 2/26 [00:02<00:21,  1.11it/s]Epoch: 8/10. Loss: 0.9604:  12%|[36m█▏        [0m| 3/26 [00:02<00:21,  1.05it/s]Epoch: 8/10. Loss: 0.9801:  12%|[36m█▏        [0m| 3/26 [00:03<00:21,  1.05it/s]Epoch: 8/10. Loss: 0.9801:  15%|[36m█▌        [0m| 4/26 [00:03<00:21,  1.02it/s]Epoch: 8/10. Loss: 0.9117:  15%|[36m█▌        [0m| 4/26 [00:04<00:21,  1.02it/s]Epoch: 8/10. Loss: 0.9117:  19%|[36m█▉        [0m| 5/26 [00:04<00:21,  1.03s/it]Epoch: 8/10. Loss: 0.9223:  19%|[36m█▉        [0m| 5/26 [00:07<00:21,  1.03s/it]Epoch: 8/10. Loss: 0.9223:  23%|[36m██▎       [0m| 6/26 [00:07<00:30,  1.53s/it]Epoch: 8/10. Loss: 0.8977:  23%|[36m██▎       [0m| 6/26 [00:09<00:30,  1.53s/it]Epoch: 8/10. Loss: 0.8977:  27%|[36m██▋       [0m| 7/26 [00:09<00:30,  1.60s/it]Epoch: 8/10. Loss: 0.8581:  27%|[36m██▋       [0m| 7/26 [00:10<00:30,  1.60s/it]Epoch: 8/10. Loss: 0.8581:  31%|[36m███       [0m| 8/26 [00:10<00:24,  1.36s/it]Epoch: 8/10. Loss: 0.8595:  31%|[36m███       [0m| 8/26 [00:10<00:24,  1.36s/it]Epoch: 8/10. Loss: 0.8595:  35%|[36m███▍      [0m| 9/26 [00:10<00:20,  1.21s/it]Epoch: 8/10. Loss: 0.8118:  35%|[36m███▍      [0m| 9/26 [00:11<00:20,  1.21s/it]Epoch: 8/10. Loss: 0.8118:  38%|[36m███▊      [0m| 10/26 [00:11<00:17,  1.10s/it]Epoch: 8/10. Loss: 0.9244:  38%|[36m███▊      [0m| 10/26 [00:13<00:17,  1.10s/it]Epoch: 8/10. Loss: 0.9244:  42%|[36m████▏     [0m| 11/26 [00:13<00:17,  1.15s/it]Epoch: 8/10. Loss: 0.9220:  42%|[36m████▏     [0m| 11/26 [00:13<00:17,  1.15s/it]Epoch: 8/10. Loss: 0.9220:  46%|[36m████▌     [0m| 12/26 [00:13<00:14,  1.07s/it]Epoch: 8/10. Loss: 1.0052:  46%|[36m████▌     [0m| 12/26 [00:14<00:14,  1.07s/it]Epoch: 8/10. Loss: 1.0052:  50%|[36m█████     [0m| 13/26 [00:14<00:12,  1.02it/s]Epoch: 8/10. Loss: 0.8970:  50%|[36m█████     [0m| 13/26 [00:15<00:12,  1.02it/s]Epoch: 8/10. Loss: 0.8970:  54%|[36m█████▍    [0m| 14/26 [00:15<00:11,  1.02it/s]Epoch: 8/10. Loss: 1.0054:  54%|[36m█████▍    [0m| 14/26 [00:16<00:11,  1.02it/s]Epoch: 8/10. Loss: 1.0054:  58%|[36m█████▊    [0m| 15/26 [00:16<00:10,  1.05it/s]Epoch: 8/10. Loss: 0.9579:  58%|[36m█████▊    [0m| 15/26 [00:17<00:10,  1.05it/s]Epoch: 8/10. Loss: 0.9579:  62%|[36m██████▏   [0m| 16/26 [00:17<00:09,  1.10it/s]Epoch: 8/10. Loss: 0.8985:  62%|[36m██████▏   [0m| 16/26 [00:18<00:09,  1.10it/s]Epoch: 8/10. Loss: 0.8985:  65%|[36m██████▌   [0m| 17/26 [00:18<00:08,  1.11it/s]Epoch: 8/10. Loss: 0.8977:  65%|[36m██████▌   [0m| 17/26 [00:19<00:08,  1.11it/s]Epoch: 8/10. Loss: 0.8977:  69%|[36m██████▉   [0m| 18/26 [00:19<00:07,  1.14it/s]Epoch: 8/10. Loss: 0.9571:  69%|[36m██████▉   [0m| 18/26 [00:19<00:07,  1.14it/s]Epoch: 8/10. Loss: 0.9571:  73%|[36m███████▎  [0m| 19/26 [00:20<00:06,  1.14it/s]Epoch: 8/10. Loss: 0.9527:  73%|[36m███████▎  [0m| 19/26 [00:20<00:06,  1.14it/s]Epoch: 8/10. Loss: 0.9527:  77%|[36m███████▋  [0m| 20/26 [00:20<00:05,  1.14it/s]Epoch: 8/10. Loss: 1.0855:  77%|[36m███████▋  [0m| 20/26 [00:21<00:05,  1.14it/s]Epoch: 8/10. Loss: 1.0855:  81%|[36m████████  [0m| 21/26 [00:21<00:04,  1.13it/s]Epoch: 8/10. Loss: 1.0078:  81%|[36m████████  [0m| 21/26 [00:22<00:04,  1.13it/s]Epoch: 8/10. Loss: 1.0078:  85%|[36m████████▍ [0m| 22/26 [00:22<00:03,  1.12it/s]Epoch: 8/10. Loss: 0.9163:  85%|[36m████████▍ [0m| 22/26 [00:23<00:03,  1.12it/s]Epoch: 8/10. Loss: 0.9163:  88%|[36m████████▊ [0m| 23/26 [00:23<00:02,  1.10it/s]Epoch: 8/10. Loss: 0.8775:  88%|[36m████████▊ [0m| 23/26 [00:24<00:02,  1.10it/s]Epoch: 8/10. Loss: 0.8775:  92%|[36m█████████▏[0m| 24/26 [00:24<00:01,  1.13it/s]Epoch: 8/10. Loss: 0.8552:  92%|[36m█████████▏[0m| 24/26 [00:25<00:01,  1.13it/s]Epoch: 8/10. Loss: 0.8552:  96%|[36m█████████▌[0m| 25/26 [00:25<00:00,  1.11it/s]Epoch: 8/10. Loss: 0.8814:  96%|[36m█████████▌[0m| 25/26 [00:25<00:00,  1.11it/s]Epoch: 8/10. Loss: 0.8814: 100%|[36m██████████[0m| 26/26 [00:25<00:00,  1.25it/s]Epoch: 8/10. Loss: 0.8814: 100%|[36m██████████[0m| 26/26 [00:25<00:00,  1.00it/s]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:04,  1.31it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:05,  1.12s/it] 43%|[33m████▎     [0m| 3/7 [00:02<00:03,  1.11it/s] 57%|[33m█████▋    [0m| 4/7 [00:03<00:03,  1.01s/it] 71%|[33m███████▏  [0m| 5/7 [00:04<00:01,  1.27it/s] 86%|[33m████████▌ [0m| 6/7 [00:05<00:00,  1.25it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.59it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.29it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 9/10. Loss: 0.9274:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 9/10. Loss: 0.9274:   4%|[36m▍         [0m| 1/26 [00:00<00:18,  1.37it/s]Epoch: 9/10. Loss: 0.8796:   4%|[36m▍         [0m| 1/26 [00:01<00:18,  1.37it/s]Epoch: 9/10. Loss: 0.8796:   8%|[36m▊         [0m| 2/26 [00:01<00:18,  1.28it/s]Epoch: 9/10. Loss: 0.8356:   8%|[36m▊         [0m| 2/26 [00:02<00:18,  1.28it/s]Epoch: 9/10. Loss: 0.8356:  12%|[36m█▏        [0m| 3/26 [00:02<00:18,  1.24it/s]Epoch: 9/10. Loss: 0.9446:  12%|[36m█▏        [0m| 3/26 [00:03<00:18,  1.24it/s]Epoch: 9/10. Loss: 0.9446:  15%|[36m█▌        [0m| 4/26 [00:03<00:19,  1.12it/s]Epoch: 9/10. Loss: 0.9658:  15%|[36m█▌        [0m| 4/26 [00:04<00:19,  1.12it/s]Epoch: 9/10. Loss: 0.9658:  19%|[36m█▉        [0m| 5/26 [00:04<00:19,  1.09it/s]Epoch: 9/10. Loss: 0.8296:  19%|[36m█▉        [0m| 5/26 [00:05<00:19,  1.09it/s]Epoch: 9/10. Loss: 0.8296:  23%|[36m██▎       [0m| 6/26 [00:05<00:19,  1.04it/s]Epoch: 9/10. Loss: 0.8596:  23%|[36m██▎       [0m| 6/26 [00:06<00:19,  1.04it/s]Epoch: 9/10. Loss: 0.8596:  27%|[36m██▋       [0m| 7/26 [00:06<00:17,  1.07it/s]Epoch: 9/10. Loss: 0.8642:  27%|[36m██▋       [0m| 7/26 [00:08<00:17,  1.07it/s]Epoch: 9/10. Loss: 0.8642:  31%|[36m███       [0m| 8/26 [00:08<00:24,  1.38s/it]Epoch: 9/10. Loss: 0.9106:  31%|[36m███       [0m| 8/26 [00:09<00:24,  1.38s/it]Epoch: 9/10. Loss: 0.9106:  35%|[36m███▍      [0m| 9/26 [00:09<00:21,  1.25s/it]Epoch: 9/10. Loss: 0.8407:  35%|[36m███▍      [0m| 9/26 [00:10<00:21,  1.25s/it]Epoch: 9/10. Loss: 0.8407:  38%|[36m███▊      [0m| 10/26 [00:10<00:19,  1.22s/it]Epoch: 9/10. Loss: 0.9489:  38%|[36m███▊      [0m| 10/26 [00:14<00:19,  1.22s/it]Epoch: 9/10. Loss: 0.9489:  42%|[36m████▏     [0m| 11/26 [00:14<00:28,  1.92s/it]Epoch: 9/10. Loss: 0.9185:  42%|[36m████▏     [0m| 11/26 [00:15<00:28,  1.92s/it]Epoch: 9/10. Loss: 0.9185:  46%|[36m████▌     [0m| 12/26 [00:15<00:22,  1.62s/it]Epoch: 9/10. Loss: 0.9291:  46%|[36m████▌     [0m| 12/26 [00:16<00:22,  1.62s/it]Epoch: 9/10. Loss: 0.9291:  50%|[36m█████     [0m| 13/26 [00:16<00:18,  1.46s/it]Epoch: 9/10. Loss: 1.0084:  50%|[36m█████     [0m| 13/26 [00:17<00:18,  1.46s/it]Epoch: 9/10. Loss: 1.0084:  54%|[36m█████▍    [0m| 14/26 [00:17<00:16,  1.38s/it]Epoch: 9/10. Loss: 0.9215:  54%|[36m█████▍    [0m| 14/26 [00:18<00:16,  1.38s/it]Epoch: 9/10. Loss: 0.9215:  58%|[36m█████▊    [0m| 15/26 [00:18<00:13,  1.27s/it]Epoch: 9/10. Loss: 0.8362:  58%|[36m█████▊    [0m| 15/26 [00:19<00:13,  1.27s/it]Epoch: 9/10. Loss: 0.8362:  62%|[36m██████▏   [0m| 16/26 [00:19<00:12,  1.22s/it]Epoch: 9/10. Loss: 0.9029:  62%|[36m██████▏   [0m| 16/26 [00:20<00:12,  1.22s/it]Epoch: 9/10. Loss: 0.9029:  65%|[36m██████▌   [0m| 17/26 [00:20<00:10,  1.14s/it]Epoch: 9/10. Loss: 0.8683:  65%|[36m██████▌   [0m| 17/26 [00:21<00:10,  1.14s/it]Epoch: 9/10. Loss: 0.8683:  69%|[36m██████▉   [0m| 18/26 [00:21<00:08,  1.07s/it]Epoch: 9/10. Loss: 0.9554:  69%|[36m██████▉   [0m| 18/26 [00:22<00:08,  1.07s/it]Epoch: 9/10. Loss: 0.9554:  73%|[36m███████▎  [0m| 19/26 [00:22<00:07,  1.08s/it]Epoch: 9/10. Loss: 0.8457:  73%|[36m███████▎  [0m| 19/26 [00:23<00:07,  1.08s/it]Epoch: 9/10. Loss: 0.8457:  77%|[36m███████▋  [0m| 20/26 [00:23<00:06,  1.04s/it]Epoch: 9/10. Loss: 0.8726:  77%|[36m███████▋  [0m| 20/26 [00:24<00:06,  1.04s/it]Epoch: 9/10. Loss: 0.8726:  81%|[36m████████  [0m| 21/26 [00:24<00:04,  1.02it/s]Epoch: 9/10. Loss: 0.9001:  81%|[36m████████  [0m| 21/26 [00:25<00:04,  1.02it/s]Epoch: 9/10. Loss: 0.9001:  85%|[36m████████▍ [0m| 22/26 [00:25<00:03,  1.07it/s]Epoch: 9/10. Loss: 1.0211:  85%|[36m████████▍ [0m| 22/26 [00:26<00:03,  1.07it/s]Epoch: 9/10. Loss: 1.0211:  88%|[36m████████▊ [0m| 23/26 [00:26<00:02,  1.09it/s]Epoch: 9/10. Loss: 0.9582:  88%|[36m████████▊ [0m| 23/26 [00:26<00:02,  1.09it/s]Epoch: 9/10. Loss: 0.9582:  92%|[36m█████████▏[0m| 24/26 [00:26<00:01,  1.09it/s]Epoch: 9/10. Loss: 0.9596:  92%|[36m█████████▏[0m| 24/26 [00:28<00:01,  1.09it/s]Epoch: 9/10. Loss: 0.9596:  96%|[36m█████████▌[0m| 25/26 [00:28<00:01,  1.02s/it]Epoch: 9/10. Loss: 0.8287:  96%|[36m█████████▌[0m| 25/26 [00:28<00:01,  1.02s/it]Epoch: 9/10. Loss: 0.8287: 100%|[36m██████████[0m| 26/26 [00:28<00:00,  1.06it/s]Epoch: 9/10. Loss: 0.8287: 100%|[36m██████████[0m| 26/26 [00:28<00:00,  1.11s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:04,  1.27it/s] 29%|[33m██▊       [0m| 2/7 [00:04<00:13,  2.77s/it] 43%|[33m████▎     [0m| 3/7 [00:05<00:07,  1.96s/it] 57%|[33m█████▋    [0m| 4/7 [00:07<00:04,  1.67s/it] 71%|[33m███████▏  [0m| 5/7 [00:11<00:05,  2.63s/it] 86%|[33m████████▌ [0m| 6/7 [00:12<00:02,  2.02s/it]100%|[33m██████████[0m| 7/7 [00:12<00:00,  1.46s/it]100%|[33m██████████[0m| 7/7 [00:12<00:00,  1.81s/it]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 0/10. Loss: 1.4204:   0%|[36m          [0m| 0/26 [00:02<?, ?it/s]Epoch: 0/10. Loss: 1.4204:   4%|[36m▍         [0m| 1/26 [00:02<01:07,  2.71s/it]Epoch: 0/10. Loss: 3.1849:   4%|[36m▍         [0m| 1/26 [00:05<01:07,  2.71s/it]Epoch: 0/10. Loss: 3.1849:   8%|[36m▊         [0m| 2/26 [00:05<01:02,  2.60s/it]Epoch: 0/10. Loss: 1.9844:   8%|[36m▊         [0m| 2/26 [00:06<01:02,  2.60s/it]Epoch: 0/10. Loss: 1.9844:  12%|[36m█▏        [0m| 3/26 [00:06<00:42,  1.85s/it]Epoch: 0/10. Loss: 2.1481:  12%|[36m█▏        [0m| 3/26 [00:07<00:42,  1.85s/it]Epoch: 0/10. Loss: 2.1481:  15%|[36m█▌        [0m| 4/26 [00:07<00:33,  1.52s/it]Epoch: 0/10. Loss: 1.2857:  15%|[36m█▌        [0m| 4/26 [00:08<00:33,  1.52s/it]Epoch: 0/10. Loss: 1.2857:  19%|[36m█▉        [0m| 5/26 [00:08<00:27,  1.30s/it]Epoch: 0/10. Loss: 0.9983:  19%|[36m█▉        [0m| 5/26 [00:09<00:27,  1.30s/it]Epoch: 0/10. Loss: 0.9983:  23%|[36m██▎       [0m| 6/26 [00:09<00:24,  1.21s/it]Epoch: 0/10. Loss: 0.9726:  23%|[36m██▎       [0m| 6/26 [00:10<00:24,  1.21s/it]Epoch: 0/10. Loss: 0.9726:  27%|[36m██▋       [0m| 7/26 [00:10<00:21,  1.13s/it]Epoch: 0/10. Loss: 3.4018:  27%|[36m██▋       [0m| 7/26 [00:10<00:21,  1.13s/it]Epoch: 0/10. Loss: 3.4018:  31%|[36m███       [0m| 8/26 [00:10<00:18,  1.03s/it]Epoch: 0/10. Loss: 3.2274:  31%|[36m███       [0m| 8/26 [00:11<00:18,  1.03s/it]Epoch: 0/10. Loss: 3.2274:  35%|[36m███▍      [0m| 9/26 [00:11<00:16,  1.04it/s]Epoch: 0/10. Loss: 2.4405:  35%|[36m███▍      [0m| 9/26 [00:12<00:16,  1.04it/s]Epoch: 0/10. Loss: 2.4405:  38%|[36m███▊      [0m| 10/26 [00:12<00:15,  1.01it/s]Epoch: 0/10. Loss: 1.2931:  38%|[36m███▊      [0m| 10/26 [00:13<00:15,  1.01it/s]Epoch: 0/10. Loss: 1.2931:  42%|[36m████▏     [0m| 11/26 [00:13<00:14,  1.06it/s]Epoch: 0/10. Loss: 1.0416:  42%|[36m████▏     [0m| 11/26 [00:14<00:14,  1.06it/s]Epoch: 0/10. Loss: 1.0416:  46%|[36m████▌     [0m| 12/26 [00:14<00:12,  1.08it/s]Epoch: 0/10. Loss: 1.1715:  46%|[36m████▌     [0m| 12/26 [00:15<00:12,  1.08it/s]Epoch: 0/10. Loss: 1.1715:  50%|[36m█████     [0m| 13/26 [00:15<00:11,  1.16it/s]Epoch: 0/10. Loss: 1.1942:  50%|[36m█████     [0m| 13/26 [00:15<00:11,  1.16it/s]Epoch: 0/10. Loss: 1.1942:  54%|[36m█████▍    [0m| 14/26 [00:16<00:10,  1.20it/s]Epoch: 0/10. Loss: 1.1999:  54%|[36m█████▍    [0m| 14/26 [00:16<00:10,  1.20it/s]Epoch: 0/10. Loss: 1.1999:  58%|[36m█████▊    [0m| 15/26 [00:16<00:09,  1.14it/s]Epoch: 0/10. Loss: 1.1529:  58%|[36m█████▊    [0m| 15/26 [00:17<00:09,  1.14it/s]Epoch: 0/10. Loss: 1.1529:  62%|[36m██████▏   [0m| 16/26 [00:17<00:08,  1.14it/s]Epoch: 0/10. Loss: 1.0322:  62%|[36m██████▏   [0m| 16/26 [00:18<00:08,  1.14it/s]Epoch: 0/10. Loss: 1.0322:  65%|[36m██████▌   [0m| 17/26 [00:18<00:08,  1.09it/s]Epoch: 0/10. Loss: 1.1477:  65%|[36m██████▌   [0m| 17/26 [00:19<00:08,  1.09it/s]Epoch: 0/10. Loss: 1.1477:  69%|[36m██████▉   [0m| 18/26 [00:19<00:07,  1.07it/s]Epoch: 0/10. Loss: 1.1039:  69%|[36m██████▉   [0m| 18/26 [00:20<00:07,  1.07it/s]Epoch: 0/10. Loss: 1.1039:  73%|[36m███████▎  [0m| 19/26 [00:20<00:06,  1.13it/s]Epoch: 0/10. Loss: 1.2480:  73%|[36m███████▎  [0m| 19/26 [00:21<00:06,  1.13it/s]Epoch: 0/10. Loss: 1.2480:  77%|[36m███████▋  [0m| 20/26 [00:21<00:05,  1.10it/s]Epoch: 0/10. Loss: 0.9721:  77%|[36m███████▋  [0m| 20/26 [00:22<00:05,  1.10it/s]Epoch: 0/10. Loss: 0.9721:  81%|[36m████████  [0m| 21/26 [00:22<00:04,  1.08it/s]Epoch: 0/10. Loss: 1.1158:  81%|[36m████████  [0m| 21/26 [00:25<00:04,  1.08it/s]Epoch: 0/10. Loss: 1.1158:  85%|[36m████████▍ [0m| 22/26 [00:25<00:05,  1.43s/it]Epoch: 0/10. Loss: 1.0100:  85%|[36m████████▍ [0m| 22/26 [00:26<00:05,  1.43s/it]Epoch: 0/10. Loss: 1.0100:  88%|[36m████████▊ [0m| 23/26 [00:26<00:03,  1.28s/it]Epoch: 0/10. Loss: 1.0618:  88%|[36m████████▊ [0m| 23/26 [00:28<00:03,  1.28s/it]Epoch: 0/10. Loss: 1.0618:  92%|[36m█████████▏[0m| 24/26 [00:28<00:03,  1.54s/it]Epoch: 0/10. Loss: 1.1643:  92%|[36m█████████▏[0m| 24/26 [00:29<00:03,  1.54s/it]Epoch: 0/10. Loss: 1.1643:  96%|[36m█████████▌[0m| 25/26 [00:29<00:01,  1.37s/it]Epoch: 0/10. Loss: 1.1106:  96%|[36m█████████▌[0m| 25/26 [00:29<00:01,  1.37s/it]Epoch: 0/10. Loss: 1.1106: 100%|[36m██████████[0m| 26/26 [00:29<00:00,  1.15s/it]Epoch: 0/10. Loss: 1.1106: 100%|[36m██████████[0m| 26/26 [00:29<00:00,  1.15s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:05,  1.19it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:05,  1.16s/it] 43%|[33m████▎     [0m| 3/7 [00:02<00:03,  1.06it/s] 57%|[33m█████▋    [0m| 4/7 [00:06<00:05,  1.83s/it] 71%|[33m███████▏  [0m| 5/7 [00:08<00:03,  1.99s/it] 86%|[33m████████▌ [0m| 6/7 [00:09<00:01,  1.59s/it]100%|[33m██████████[0m| 7/7 [00:10<00:00,  1.66s/it]100%|[33m██████████[0m| 7/7 [00:11<00:00,  1.57s/it]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 1/10. Loss: 1.0629:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 1/10. Loss: 1.0629:   4%|[36m▍         [0m| 1/26 [00:00<00:23,  1.06it/s]Epoch: 1/10. Loss: 1.0320:   4%|[36m▍         [0m| 1/26 [00:01<00:23,  1.06it/s]Epoch: 1/10. Loss: 1.0320:   8%|[36m▊         [0m| 2/26 [00:01<00:21,  1.11it/s]Epoch: 1/10. Loss: 0.9632:   8%|[36m▊         [0m| 2/26 [00:02<00:21,  1.11it/s]Epoch: 1/10. Loss: 0.9632:  12%|[36m█▏        [0m| 3/26 [00:02<00:19,  1.18it/s]Epoch: 1/10. Loss: 0.9776:  12%|[36m█▏        [0m| 3/26 [00:03<00:19,  1.18it/s]Epoch: 1/10. Loss: 0.9776:  15%|[36m█▌        [0m| 4/26 [00:03<00:20,  1.10it/s]Epoch: 1/10. Loss: 0.9869:  15%|[36m█▌        [0m| 4/26 [00:06<00:20,  1.10it/s]Epoch: 1/10. Loss: 0.9869:  19%|[36m█▉        [0m| 5/26 [00:06<00:34,  1.64s/it]Epoch: 1/10. Loss: 0.9809:  19%|[36m█▉        [0m| 5/26 [00:09<00:34,  1.64s/it]Epoch: 1/10. Loss: 0.9809:  23%|[36m██▎       [0m| 6/26 [00:09<00:40,  2.01s/it]Epoch: 1/10. Loss: 1.0298:  23%|[36m██▎       [0m| 6/26 [00:10<00:40,  2.01s/it]Epoch: 1/10. Loss: 1.0298:  27%|[36m██▋       [0m| 7/26 [00:10<00:31,  1.66s/it]Epoch: 1/10. Loss: 1.1214:  27%|[36m██▋       [0m| 7/26 [00:11<00:31,  1.66s/it]Epoch: 1/10. Loss: 1.1214:  31%|[36m███       [0m| 8/26 [00:11<00:28,  1.60s/it]Epoch: 1/10. Loss: 0.9600:  31%|[36m███       [0m| 8/26 [00:13<00:28,  1.60s/it]Epoch: 1/10. Loss: 0.9600:  35%|[36m███▍      [0m| 9/26 [00:13<00:31,  1.82s/it]Epoch: 1/10. Loss: 1.0210:  35%|[36m███▍      [0m| 9/26 [00:16<00:31,  1.82s/it]Epoch: 1/10. Loss: 1.0210:  38%|[36m███▊      [0m| 10/26 [00:16<00:32,  2.04s/it]Epoch: 1/10. Loss: 1.0188:  38%|[36m███▊      [0m| 10/26 [00:17<00:32,  2.04s/it]Epoch: 1/10. Loss: 1.0188:  42%|[36m████▏     [0m| 11/26 [00:17<00:26,  1.75s/it]Epoch: 1/10. Loss: 0.9506:  42%|[36m████▏     [0m| 11/26 [00:18<00:26,  1.75s/it]Epoch: 1/10. Loss: 0.9506:  46%|[36m████▌     [0m| 12/26 [00:18<00:20,  1.50s/it]Epoch: 1/10. Loss: 1.1195:  46%|[36m████▌     [0m| 12/26 [00:19<00:20,  1.50s/it]Epoch: 1/10. Loss: 1.1195:  50%|[36m█████     [0m| 13/26 [00:19<00:18,  1.43s/it]Epoch: 1/10. Loss: 0.9416:  50%|[36m█████     [0m| 13/26 [00:20<00:18,  1.43s/it]Epoch: 1/10. Loss: 0.9416:  54%|[36m█████▍    [0m| 14/26 [00:20<00:15,  1.28s/it]Epoch: 1/10. Loss: 0.9173:  54%|[36m█████▍    [0m| 14/26 [00:21<00:15,  1.28s/it]Epoch: 1/10. Loss: 0.9173:  58%|[36m█████▊    [0m| 15/26 [00:21<00:12,  1.15s/it]Epoch: 1/10. Loss: 0.9530:  58%|[36m█████▊    [0m| 15/26 [00:22<00:12,  1.15s/it]Epoch: 1/10. Loss: 0.9530:  62%|[36m██████▏   [0m| 16/26 [00:22<00:11,  1.11s/it]Epoch: 1/10. Loss: 0.9131:  62%|[36m██████▏   [0m| 16/26 [00:23<00:11,  1.11s/it]Epoch: 1/10. Loss: 0.9131:  65%|[36m██████▌   [0m| 17/26 [00:23<00:09,  1.02s/it]Epoch: 1/10. Loss: 1.0631:  65%|[36m██████▌   [0m| 17/26 [00:24<00:09,  1.02s/it]Epoch: 1/10. Loss: 1.0631:  69%|[36m██████▉   [0m| 18/26 [00:24<00:07,  1.03it/s]Epoch: 1/10. Loss: 0.9316:  69%|[36m██████▉   [0m| 18/26 [00:25<00:07,  1.03it/s]Epoch: 1/10. Loss: 0.9316:  73%|[36m███████▎  [0m| 19/26 [00:25<00:06,  1.05it/s]Epoch: 1/10. Loss: 0.9152:  73%|[36m███████▎  [0m| 19/26 [00:26<00:06,  1.05it/s]Epoch: 1/10. Loss: 0.9152:  77%|[36m███████▋  [0m| 20/26 [00:26<00:05,  1.07it/s]Epoch: 1/10. Loss: 0.9375:  77%|[36m███████▋  [0m| 20/26 [00:27<00:05,  1.07it/s]Epoch: 1/10. Loss: 0.9375:  81%|[36m████████  [0m| 21/26 [00:27<00:04,  1.04it/s]Epoch: 1/10. Loss: 0.9321:  81%|[36m████████  [0m| 21/26 [00:27<00:04,  1.04it/s]Epoch: 1/10. Loss: 0.9321:  85%|[36m████████▍ [0m| 22/26 [00:27<00:03,  1.07it/s]Epoch: 1/10. Loss: 0.9485:  85%|[36m████████▍ [0m| 22/26 [00:28<00:03,  1.07it/s]Epoch: 1/10. Loss: 0.9485:  88%|[36m████████▊ [0m| 23/26 [00:28<00:02,  1.08it/s]Epoch: 1/10. Loss: 1.0003:  88%|[36m████████▊ [0m| 23/26 [00:29<00:02,  1.08it/s]Epoch: 1/10. Loss: 1.0003:  92%|[36m█████████▏[0m| 24/26 [00:29<00:01,  1.06it/s]Epoch: 1/10. Loss: 0.9660:  92%|[36m█████████▏[0m| 24/26 [00:30<00:01,  1.06it/s]Epoch: 1/10. Loss: 0.9660:  96%|[36m█████████▌[0m| 25/26 [00:30<00:00,  1.08it/s]Epoch: 1/10. Loss: 0.9895:  96%|[36m█████████▌[0m| 25/26 [00:31<00:00,  1.08it/s]Epoch: 1/10. Loss: 0.9895: 100%|[36m██████████[0m| 26/26 [00:31<00:00,  1.20it/s]Epoch: 1/10. Loss: 0.9895: 100%|[36m██████████[0m| 26/26 [00:31<00:00,  1.21s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:04,  1.28it/s] 29%|[33m██▊       [0m| 2/7 [00:03<00:10,  2.09s/it] 43%|[33m████▎     [0m| 3/7 [00:05<00:07,  1.85s/it] 57%|[33m█████▋    [0m| 4/7 [00:06<00:04,  1.66s/it] 71%|[33m███████▏  [0m| 5/7 [00:07<00:02,  1.21s/it] 86%|[33m████████▌ [0m| 6/7 [00:07<00:01,  1.08s/it]100%|[33m██████████[0m| 7/7 [00:08<00:00,  1.09it/s]100%|[33m██████████[0m| 7/7 [00:08<00:00,  1.22s/it]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 2/10. Loss: 0.9471:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 2/10. Loss: 0.9471:   4%|[36m▍         [0m| 1/26 [00:00<00:21,  1.15it/s]Epoch: 2/10. Loss: 0.9114:   4%|[36m▍         [0m| 1/26 [00:01<00:21,  1.15it/s]Epoch: 2/10. Loss: 0.9114:   8%|[36m▊         [0m| 2/26 [00:01<00:21,  1.11it/s]Epoch: 2/10. Loss: 0.9365:   8%|[36m▊         [0m| 2/26 [00:02<00:21,  1.11it/s]Epoch: 2/10. Loss: 0.9365:  12%|[36m█▏        [0m| 3/26 [00:02<00:21,  1.05it/s]Epoch: 2/10. Loss: 0.9334:  12%|[36m█▏        [0m| 3/26 [00:03<00:21,  1.05it/s]Epoch: 2/10. Loss: 0.9334:  15%|[36m█▌        [0m| 4/26 [00:03<00:21,  1.02it/s]Epoch: 2/10. Loss: 0.9467:  15%|[36m█▌        [0m| 4/26 [00:04<00:21,  1.02it/s]Epoch: 2/10. Loss: 0.9467:  19%|[36m█▉        [0m| 5/26 [00:04<00:19,  1.06it/s]Epoch: 2/10. Loss: 0.8966:  19%|[36m█▉        [0m| 5/26 [00:05<00:19,  1.06it/s]Epoch: 2/10. Loss: 0.8966:  23%|[36m██▎       [0m| 6/26 [00:05<00:18,  1.07it/s]Epoch: 2/10. Loss: 0.8926:  23%|[36m██▎       [0m| 6/26 [00:06<00:18,  1.07it/s]Epoch: 2/10. Loss: 0.8926:  27%|[36m██▋       [0m| 7/26 [00:06<00:19,  1.05s/it]Epoch: 2/10. Loss: 1.0054:  27%|[36m██▋       [0m| 7/26 [00:07<00:19,  1.05s/it]Epoch: 2/10. Loss: 1.0054:  31%|[36m███       [0m| 8/26 [00:07<00:17,  1.04it/s]Epoch: 2/10. Loss: 0.8850:  31%|[36m███       [0m| 8/26 [00:08<00:17,  1.04it/s]Epoch: 2/10. Loss: 0.8850:  35%|[36m███▍      [0m| 9/26 [00:09<00:18,  1.08s/it]Epoch: 2/10. Loss: 0.9486:  35%|[36m███▍      [0m| 9/26 [00:09<00:18,  1.08s/it]Epoch: 2/10. Loss: 0.9486:  38%|[36m███▊      [0m| 10/26 [00:09<00:15,  1.03it/s]Epoch: 2/10. Loss: 0.9274:  38%|[36m███▊      [0m| 10/26 [00:10<00:15,  1.03it/s]Epoch: 2/10. Loss: 0.9274:  42%|[36m████▏     [0m| 11/26 [00:10<00:14,  1.05it/s]Epoch: 2/10. Loss: 0.9471:  42%|[36m████▏     [0m| 11/26 [00:11<00:14,  1.05it/s]Epoch: 2/10. Loss: 0.9471:  46%|[36m████▌     [0m| 12/26 [00:11<00:13,  1.03it/s]Epoch: 2/10. Loss: 0.7934:  46%|[36m████▌     [0m| 12/26 [00:12<00:13,  1.03it/s]Epoch: 2/10. Loss: 0.7934:  50%|[36m█████     [0m| 13/26 [00:12<00:13,  1.07s/it]Epoch: 2/10. Loss: 0.8916:  50%|[36m█████     [0m| 13/26 [00:13<00:13,  1.07s/it]Epoch: 2/10. Loss: 0.8916:  54%|[36m█████▍    [0m| 14/26 [00:13<00:12,  1.04s/it]Epoch: 2/10. Loss: 0.9258:  54%|[36m█████▍    [0m| 14/26 [00:14<00:12,  1.04s/it]Epoch: 2/10. Loss: 0.9258:  58%|[36m█████▊    [0m| 15/26 [00:14<00:10,  1.00it/s]Epoch: 2/10. Loss: 0.9135:  58%|[36m█████▊    [0m| 15/26 [00:16<00:10,  1.00it/s]Epoch: 2/10. Loss: 0.9135:  62%|[36m██████▏   [0m| 16/26 [00:16<00:10,  1.06s/it]Epoch: 2/10. Loss: 1.0053:  62%|[36m██████▏   [0m| 16/26 [00:16<00:10,  1.06s/it]Epoch: 2/10. Loss: 1.0053:  65%|[36m██████▌   [0m| 17/26 [00:16<00:08,  1.02it/s]Epoch: 2/10. Loss: 0.9199:  65%|[36m██████▌   [0m| 17/26 [00:17<00:08,  1.02it/s]Epoch: 2/10. Loss: 0.9199:  69%|[36m██████▉   [0m| 18/26 [00:17<00:07,  1.09it/s]Epoch: 2/10. Loss: 0.8706:  69%|[36m██████▉   [0m| 18/26 [00:18<00:07,  1.09it/s]Epoch: 2/10. Loss: 0.8706:  73%|[36m███████▎  [0m| 19/26 [00:18<00:06,  1.12it/s]Epoch: 2/10. Loss: 1.0197:  73%|[36m███████▎  [0m| 19/26 [00:19<00:06,  1.12it/s]Epoch: 2/10. Loss: 1.0197:  77%|[36m███████▋  [0m| 20/26 [00:19<00:05,  1.12it/s]Epoch: 2/10. Loss: 0.9154:  77%|[36m███████▋  [0m| 20/26 [00:20<00:05,  1.12it/s]Epoch: 2/10. Loss: 0.9154:  81%|[36m████████  [0m| 21/26 [00:20<00:04,  1.14it/s]Epoch: 2/10. Loss: 0.8702:  81%|[36m████████  [0m| 21/26 [00:20<00:04,  1.14it/s]Epoch: 2/10. Loss: 0.8702:  85%|[36m████████▍ [0m| 22/26 [00:21<00:03,  1.16it/s]Epoch: 2/10. Loss: 0.8467:  85%|[36m████████▍ [0m| 22/26 [00:21<00:03,  1.16it/s]Epoch: 2/10. Loss: 0.8467:  88%|[36m████████▊ [0m| 23/26 [00:21<00:02,  1.13it/s]Epoch: 2/10. Loss: 0.8606:  88%|[36m████████▊ [0m| 23/26 [00:22<00:02,  1.13it/s]Epoch: 2/10. Loss: 0.8606:  92%|[36m█████████▏[0m| 24/26 [00:22<00:01,  1.19it/s]Epoch: 2/10. Loss: 0.9001:  92%|[36m█████████▏[0m| 24/26 [00:23<00:01,  1.19it/s]Epoch: 2/10. Loss: 0.9001:  96%|[36m█████████▌[0m| 25/26 [00:23<00:00,  1.23it/s]Epoch: 2/10. Loss: 0.9115:  96%|[36m█████████▌[0m| 25/26 [00:23<00:00,  1.23it/s]Epoch: 2/10. Loss: 0.9115: 100%|[36m██████████[0m| 26/26 [00:23<00:00,  1.42it/s]Epoch: 2/10. Loss: 0.9115: 100%|[36m██████████[0m| 26/26 [00:23<00:00,  1.09it/s]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:01<00:06,  1.13s/it] 29%|[33m██▊       [0m| 2/7 [00:02<00:06,  1.31s/it] 43%|[33m████▎     [0m| 3/7 [00:03<00:04,  1.01s/it] 57%|[33m█████▋    [0m| 4/7 [00:04<00:03,  1.09s/it] 71%|[33m███████▏  [0m| 5/7 [00:04<00:01,  1.17it/s] 86%|[33m████████▌ [0m| 6/7 [00:05<00:00,  1.14it/s]100%|[33m██████████[0m| 7/7 [00:06<00:00,  1.45it/s]100%|[33m██████████[0m| 7/7 [00:06<00:00,  1.15it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 3/10. Loss: 0.8764:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 3/10. Loss: 0.8764:   4%|[36m▍         [0m| 1/26 [00:00<00:20,  1.23it/s]Epoch: 3/10. Loss: 0.8009:   4%|[36m▍         [0m| 1/26 [00:01<00:20,  1.23it/s]Epoch: 3/10. Loss: 0.8009:   8%|[36m▊         [0m| 2/26 [00:01<00:20,  1.19it/s]Epoch: 3/10. Loss: 0.9046:   8%|[36m▊         [0m| 2/26 [00:02<00:20,  1.19it/s]Epoch: 3/10. Loss: 0.9046:  12%|[36m█▏        [0m| 3/26 [00:02<00:19,  1.16it/s]Epoch: 3/10. Loss: 0.8124:  12%|[36m█▏        [0m| 3/26 [00:03<00:19,  1.16it/s]Epoch: 3/10. Loss: 0.8124:  15%|[36m█▌        [0m| 4/26 [00:03<00:19,  1.13it/s]Epoch: 3/10. Loss: 0.9447:  15%|[36m█▌        [0m| 4/26 [00:04<00:19,  1.13it/s]Epoch: 3/10. Loss: 0.9447:  19%|[36m█▉        [0m| 5/26 [00:04<00:20,  1.04it/s]Epoch: 3/10. Loss: 0.8858:  19%|[36m█▉        [0m| 5/26 [00:05<00:20,  1.04it/s]Epoch: 3/10. Loss: 0.8858:  23%|[36m██▎       [0m| 6/26 [00:05<00:21,  1.06s/it]Epoch: 3/10. Loss: 0.9018:  23%|[36m██▎       [0m| 6/26 [00:06<00:21,  1.06s/it]Epoch: 3/10. Loss: 0.9018:  27%|[36m██▋       [0m| 7/26 [00:06<00:18,  1.05it/s]Epoch: 3/10. Loss: 0.8388:  27%|[36m██▋       [0m| 7/26 [00:07<00:18,  1.05it/s]Epoch: 3/10. Loss: 0.8388:  31%|[36m███       [0m| 8/26 [00:07<00:17,  1.02it/s]Epoch: 3/10. Loss: 0.9050:  31%|[36m███       [0m| 8/26 [00:08<00:17,  1.02it/s]Epoch: 3/10. Loss: 0.9050:  35%|[36m███▍      [0m| 9/26 [00:08<00:15,  1.08it/s]Epoch: 3/10. Loss: 0.8405:  35%|[36m███▍      [0m| 9/26 [00:09<00:15,  1.08it/s]Epoch: 3/10. Loss: 0.8405:  38%|[36m███▊      [0m| 10/26 [00:09<00:13,  1.15it/s]Epoch: 3/10. Loss: 0.8549:  38%|[36m███▊      [0m| 10/26 [00:09<00:13,  1.15it/s]Epoch: 3/10. Loss: 0.8549:  42%|[36m████▏     [0m| 11/26 [00:10<00:13,  1.15it/s]Epoch: 3/10. Loss: 0.8118:  42%|[36m████▏     [0m| 11/26 [00:12<00:13,  1.15it/s]Epoch: 3/10. Loss: 0.8118:  46%|[36m████▌     [0m| 12/26 [00:12<00:18,  1.30s/it]Epoch: 3/10. Loss: 0.8788:  46%|[36m████▌     [0m| 12/26 [00:13<00:18,  1.30s/it]Epoch: 3/10. Loss: 0.8788:  50%|[36m█████     [0m| 13/26 [00:13<00:15,  1.22s/it]Epoch: 3/10. Loss: 0.8439:  50%|[36m█████     [0m| 13/26 [00:14<00:15,  1.22s/it]Epoch: 3/10. Loss: 0.8439:  54%|[36m█████▍    [0m| 14/26 [00:14<00:13,  1.11s/it]Epoch: 3/10. Loss: 0.8836:  54%|[36m█████▍    [0m| 14/26 [00:15<00:13,  1.11s/it]Epoch: 3/10. Loss: 0.8836:  58%|[36m█████▊    [0m| 15/26 [00:15<00:11,  1.02s/it]Epoch: 3/10. Loss: 0.8127:  58%|[36m█████▊    [0m| 15/26 [00:15<00:11,  1.02s/it]Epoch: 3/10. Loss: 0.8127:  62%|[36m██████▏   [0m| 16/26 [00:15<00:10,  1.01s/it]Epoch: 3/10. Loss: 0.8821:  62%|[36m██████▏   [0m| 16/26 [00:16<00:10,  1.01s/it]Epoch: 3/10. Loss: 0.8821:  65%|[36m██████▌   [0m| 17/26 [00:16<00:08,  1.05it/s]Epoch: 3/10. Loss: 0.8478:  65%|[36m██████▌   [0m| 17/26 [00:17<00:08,  1.05it/s]Epoch: 3/10. Loss: 0.8478:  69%|[36m██████▉   [0m| 18/26 [00:17<00:07,  1.08it/s]Epoch: 3/10. Loss: 0.8890:  69%|[36m██████▉   [0m| 18/26 [00:18<00:07,  1.08it/s]Epoch: 3/10. Loss: 0.8890:  73%|[36m███████▎  [0m| 19/26 [00:18<00:06,  1.07it/s]Epoch: 3/10. Loss: 0.8705:  73%|[36m███████▎  [0m| 19/26 [00:19<00:06,  1.07it/s]Epoch: 3/10. Loss: 0.8705:  77%|[36m███████▋  [0m| 20/26 [00:19<00:06,  1.01s/it]Epoch: 3/10. Loss: 0.8218:  77%|[36m███████▋  [0m| 20/26 [00:20<00:06,  1.01s/it]Epoch: 3/10. Loss: 0.8218:  81%|[36m████████  [0m| 21/26 [00:20<00:04,  1.02it/s]Epoch: 3/10. Loss: 0.8315:  81%|[36m████████  [0m| 21/26 [00:21<00:04,  1.02it/s]Epoch: 3/10. Loss: 0.8315:  85%|[36m████████▍ [0m| 22/26 [00:21<00:03,  1.03it/s]Epoch: 3/10. Loss: 0.8411:  85%|[36m████████▍ [0m| 22/26 [00:22<00:03,  1.03it/s]Epoch: 3/10. Loss: 0.8411:  88%|[36m████████▊ [0m| 23/26 [00:22<00:02,  1.07it/s]Epoch: 3/10. Loss: 0.8579:  88%|[36m████████▊ [0m| 23/26 [00:23<00:02,  1.07it/s]Epoch: 3/10. Loss: 0.8579:  92%|[36m█████████▏[0m| 24/26 [00:23<00:01,  1.10it/s]Epoch: 3/10. Loss: 0.8723:  92%|[36m█████████▏[0m| 24/26 [00:24<00:01,  1.10it/s]Epoch: 3/10. Loss: 0.8723:  96%|[36m█████████▌[0m| 25/26 [00:24<00:00,  1.10it/s]Epoch: 3/10. Loss: 0.8347:  96%|[36m█████████▌[0m| 25/26 [00:24<00:00,  1.10it/s]Epoch: 3/10. Loss: 0.8347: 100%|[36m██████████[0m| 26/26 [00:25<00:00,  1.17it/s]Epoch: 3/10. Loss: 0.8347: 100%|[36m██████████[0m| 26/26 [00:25<00:00,  1.04it/s]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:04,  1.27it/s] 29%|[33m██▊       [0m| 2/7 [00:03<00:10,  2.19s/it] 43%|[33m████▎     [0m| 3/7 [00:05<00:07,  1.77s/it] 57%|[33m█████▋    [0m| 4/7 [00:07<00:06,  2.05s/it] 71%|[33m███████▏  [0m| 5/7 [00:08<00:02,  1.47s/it] 86%|[33m████████▌ [0m| 6/7 [00:09<00:01,  1.44s/it]100%|[33m██████████[0m| 7/7 [00:09<00:00,  1.07s/it]100%|[33m██████████[0m| 7/7 [00:09<00:00,  1.40s/it]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 4/10. Loss: 0.8306:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 4/10. Loss: 0.8306:   4%|[36m▍         [0m| 1/26 [00:00<00:20,  1.21it/s]Epoch: 4/10. Loss: 0.7958:   4%|[36m▍         [0m| 1/26 [00:01<00:20,  1.21it/s]Epoch: 4/10. Loss: 0.7958:   8%|[36m▊         [0m| 2/26 [00:01<00:20,  1.16it/s]Epoch: 4/10. Loss: 0.8065:   8%|[36m▊         [0m| 2/26 [00:02<00:20,  1.16it/s]Epoch: 4/10. Loss: 0.8065:  12%|[36m█▏        [0m| 3/26 [00:02<00:21,  1.09it/s]Epoch: 4/10. Loss: 0.7060:  12%|[36m█▏        [0m| 3/26 [00:03<00:21,  1.09it/s]Epoch: 4/10. Loss: 0.7060:  15%|[36m█▌        [0m| 4/26 [00:03<00:20,  1.10it/s]Epoch: 4/10. Loss: 0.8333:  15%|[36m█▌        [0m| 4/26 [00:04<00:20,  1.10it/s]Epoch: 4/10. Loss: 0.8333:  19%|[36m█▉        [0m| 5/26 [00:04<00:18,  1.16it/s]Epoch: 4/10. Loss: 0.8050:  19%|[36m█▉        [0m| 5/26 [00:05<00:18,  1.16it/s]Epoch: 4/10. Loss: 0.8050:  23%|[36m██▎       [0m| 6/26 [00:05<00:17,  1.15it/s]Epoch: 4/10. Loss: 0.8182:  23%|[36m██▎       [0m| 6/26 [00:06<00:17,  1.15it/s]Epoch: 4/10. Loss: 0.8182:  27%|[36m██▋       [0m| 7/26 [00:06<00:16,  1.19it/s]Epoch: 4/10. Loss: 0.8380:  27%|[36m██▋       [0m| 7/26 [00:06<00:16,  1.19it/s]Epoch: 4/10. Loss: 0.8380:  31%|[36m███       [0m| 8/26 [00:06<00:15,  1.15it/s]Epoch: 4/10. Loss: 0.9142:  31%|[36m███       [0m| 8/26 [00:07<00:15,  1.15it/s]Epoch: 4/10. Loss: 0.9142:  35%|[36m███▍      [0m| 9/26 [00:07<00:15,  1.09it/s]Epoch: 4/10. Loss: 0.8871:  35%|[36m███▍      [0m| 9/26 [00:08<00:15,  1.09it/s]Epoch: 4/10. Loss: 0.8871:  38%|[36m███▊      [0m| 10/26 [00:08<00:14,  1.10it/s]Epoch: 4/10. Loss: 0.7830:  38%|[36m███▊      [0m| 10/26 [00:09<00:14,  1.10it/s]Epoch: 4/10. Loss: 0.7830:  42%|[36m████▏     [0m| 11/26 [00:09<00:13,  1.10it/s]Epoch: 4/10. Loss: 0.8258:  42%|[36m████▏     [0m| 11/26 [00:10<00:13,  1.10it/s]Epoch: 4/10. Loss: 0.8258:  46%|[36m████▌     [0m| 12/26 [00:10<00:12,  1.09it/s]Epoch: 4/10. Loss: 0.8531:  46%|[36m████▌     [0m| 12/26 [00:11<00:12,  1.09it/s]Epoch: 4/10. Loss: 0.8531:  50%|[36m█████     [0m| 13/26 [00:11<00:11,  1.12it/s]Epoch: 4/10. Loss: 0.9182:  50%|[36m█████     [0m| 13/26 [00:12<00:11,  1.12it/s]Epoch: 4/10. Loss: 0.9182:  54%|[36m█████▍    [0m| 14/26 [00:12<00:10,  1.13it/s]Epoch: 4/10. Loss: 0.8875:  54%|[36m█████▍    [0m| 14/26 [00:13<00:10,  1.13it/s]Epoch: 4/10. Loss: 0.8875:  58%|[36m█████▊    [0m| 15/26 [00:13<00:09,  1.16it/s]Epoch: 4/10. Loss: 0.7421:  58%|[36m█████▊    [0m| 15/26 [00:14<00:09,  1.16it/s]Epoch: 4/10. Loss: 0.7421:  62%|[36m██████▏   [0m| 16/26 [00:14<00:09,  1.10it/s]Epoch: 4/10. Loss: 0.8178:  62%|[36m██████▏   [0m| 16/26 [00:15<00:09,  1.10it/s]Epoch: 4/10. Loss: 0.8178:  65%|[36m██████▌   [0m| 17/26 [00:15<00:08,  1.07it/s]Epoch: 4/10. Loss: 0.8996:  65%|[36m██████▌   [0m| 17/26 [00:16<00:08,  1.07it/s]Epoch: 4/10. Loss: 0.8996:  69%|[36m██████▉   [0m| 18/26 [00:16<00:07,  1.09it/s]Epoch: 4/10. Loss: 0.7711:  69%|[36m██████▉   [0m| 18/26 [00:17<00:07,  1.09it/s]Epoch: 4/10. Loss: 0.7711:  73%|[36m███████▎  [0m| 19/26 [00:17<00:06,  1.07it/s]Epoch: 4/10. Loss: 0.8779:  73%|[36m███████▎  [0m| 19/26 [00:18<00:06,  1.07it/s]Epoch: 4/10. Loss: 0.8779:  77%|[36m███████▋  [0m| 20/26 [00:18<00:07,  1.19s/it]Epoch: 4/10. Loss: 0.8948:  77%|[36m███████▋  [0m| 20/26 [00:19<00:07,  1.19s/it]Epoch: 4/10. Loss: 0.8948:  81%|[36m████████  [0m| 21/26 [00:19<00:05,  1.10s/it]Epoch: 4/10. Loss: 0.7221:  81%|[36m████████  [0m| 21/26 [00:20<00:05,  1.10s/it]Epoch: 4/10. Loss: 0.7221:  85%|[36m████████▍ [0m| 22/26 [00:20<00:04,  1.11s/it]Epoch: 4/10. Loss: 0.7602:  85%|[36m████████▍ [0m| 22/26 [00:21<00:04,  1.11s/it]Epoch: 4/10. Loss: 0.7602:  88%|[36m████████▊ [0m| 23/26 [00:21<00:03,  1.01s/it]Epoch: 4/10. Loss: 0.7632:  88%|[36m████████▊ [0m| 23/26 [00:22<00:03,  1.01s/it]Epoch: 4/10. Loss: 0.7632:  92%|[36m█████████▏[0m| 24/26 [00:22<00:02,  1.03s/it]Epoch: 4/10. Loss: 0.8042:  92%|[36m█████████▏[0m| 24/26 [00:23<00:02,  1.03s/it]Epoch: 4/10. Loss: 0.8042:  96%|[36m█████████▌[0m| 25/26 [00:23<00:00,  1.03it/s]Epoch: 4/10. Loss: 0.6761:  96%|[36m█████████▌[0m| 25/26 [00:24<00:00,  1.03it/s]Epoch: 4/10. Loss: 0.6761: 100%|[36m██████████[0m| 26/26 [00:24<00:00,  1.17it/s]Epoch: 4/10. Loss: 0.6761: 100%|[36m██████████[0m| 26/26 [00:24<00:00,  1.07it/s]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:04,  1.24it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:06,  1.25s/it] 43%|[33m████▎     [0m| 3/7 [00:03<00:03,  1.01it/s] 57%|[33m█████▋    [0m| 4/7 [00:04<00:03,  1.09s/it] 71%|[33m███████▏  [0m| 5/7 [00:04<00:01,  1.17it/s] 86%|[33m████████▌ [0m| 6/7 [00:05<00:00,  1.15it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.47it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.18it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 5/10. Loss: 0.8932:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 5/10. Loss: 0.8932:   4%|[36m▍         [0m| 1/26 [00:00<00:23,  1.08it/s]Epoch: 5/10. Loss: 0.8065:   4%|[36m▍         [0m| 1/26 [00:01<00:23,  1.08it/s]Epoch: 5/10. Loss: 0.8065:   8%|[36m▊         [0m| 2/26 [00:01<00:21,  1.12it/s]Epoch: 5/10. Loss: 0.7367:   8%|[36m▊         [0m| 2/26 [00:02<00:21,  1.12it/s]Epoch: 5/10. Loss: 0.7367:  12%|[36m█▏        [0m| 3/26 [00:02<00:19,  1.17it/s]Epoch: 5/10. Loss: 0.7132:  12%|[36m█▏        [0m| 3/26 [00:03<00:19,  1.17it/s]Epoch: 5/10. Loss: 0.7132:  15%|[36m█▌        [0m| 4/26 [00:03<00:19,  1.14it/s]Epoch: 5/10. Loss: 0.8374:  15%|[36m█▌        [0m| 4/26 [00:04<00:19,  1.14it/s]Epoch: 5/10. Loss: 0.8374:  19%|[36m█▉        [0m| 5/26 [00:04<00:20,  1.04it/s]Epoch: 5/10. Loss: 0.7976:  19%|[36m█▉        [0m| 5/26 [00:05<00:20,  1.04it/s]Epoch: 5/10. Loss: 0.7976:  23%|[36m██▎       [0m| 6/26 [00:05<00:17,  1.11it/s]Epoch: 5/10. Loss: 0.7168:  23%|[36m██▎       [0m| 6/26 [00:06<00:17,  1.11it/s]Epoch: 5/10. Loss: 0.7168:  27%|[36m██▋       [0m| 7/26 [00:06<00:16,  1.15it/s]Epoch: 5/10. Loss: 0.7324:  27%|[36m██▋       [0m| 7/26 [00:06<00:16,  1.15it/s]Epoch: 5/10. Loss: 0.7324:  31%|[36m███       [0m| 8/26 [00:06<00:15,  1.19it/s]Epoch: 5/10. Loss: 0.6901:  31%|[36m███       [0m| 8/26 [00:07<00:15,  1.19it/s]Epoch: 5/10. Loss: 0.6901:  35%|[36m███▍      [0m| 9/26 [00:07<00:14,  1.15it/s]Epoch: 5/10. Loss: 0.8944:  35%|[36m███▍      [0m| 9/26 [00:08<00:14,  1.15it/s]Epoch: 5/10. Loss: 0.8944:  38%|[36m███▊      [0m| 10/26 [00:08<00:13,  1.15it/s]Epoch: 5/10. Loss: 0.6853:  38%|[36m███▊      [0m| 10/26 [00:09<00:13,  1.15it/s]Epoch: 5/10. Loss: 0.6853:  42%|[36m████▏     [0m| 11/26 [00:09<00:13,  1.10it/s]Epoch: 5/10. Loss: 0.8338:  42%|[36m████▏     [0m| 11/26 [00:10<00:13,  1.10it/s]Epoch: 5/10. Loss: 0.8338:  46%|[36m████▌     [0m| 12/26 [00:10<00:11,  1.20it/s]Epoch: 5/10. Loss: 0.7449:  46%|[36m████▌     [0m| 12/26 [00:11<00:11,  1.20it/s]Epoch: 5/10. Loss: 0.7449:  50%|[36m█████     [0m| 13/26 [00:11<00:11,  1.16it/s]Epoch: 5/10. Loss: 0.7336:  50%|[36m█████     [0m| 13/26 [00:12<00:11,  1.16it/s]Epoch: 5/10. Loss: 0.7336:  54%|[36m█████▍    [0m| 14/26 [00:12<00:10,  1.17it/s]Epoch: 5/10. Loss: 0.7200:  54%|[36m█████▍    [0m| 14/26 [00:13<00:10,  1.17it/s]Epoch: 5/10. Loss: 0.7200:  58%|[36m█████▊    [0m| 15/26 [00:13<00:09,  1.19it/s]Epoch: 5/10. Loss: 0.7717:  58%|[36m█████▊    [0m| 15/26 [00:13<00:09,  1.19it/s]Epoch: 5/10. Loss: 0.7717:  62%|[36m██████▏   [0m| 16/26 [00:13<00:08,  1.25it/s]Epoch: 5/10. Loss: 0.8797:  62%|[36m██████▏   [0m| 16/26 [00:14<00:08,  1.25it/s]Epoch: 5/10. Loss: 0.8797:  65%|[36m██████▌   [0m| 17/26 [00:14<00:07,  1.23it/s]Epoch: 5/10. Loss: 0.8565:  65%|[36m██████▌   [0m| 17/26 [00:15<00:07,  1.23it/s]Epoch: 5/10. Loss: 0.8565:  69%|[36m██████▉   [0m| 18/26 [00:15<00:06,  1.17it/s]Epoch: 5/10. Loss: 0.6862:  69%|[36m██████▉   [0m| 18/26 [00:16<00:06,  1.17it/s]Epoch: 5/10. Loss: 0.6862:  73%|[36m███████▎  [0m| 19/26 [00:16<00:06,  1.08it/s]Epoch: 5/10. Loss: 0.7617:  73%|[36m███████▎  [0m| 19/26 [00:17<00:06,  1.08it/s]Epoch: 5/10. Loss: 0.7617:  77%|[36m███████▋  [0m| 20/26 [00:17<00:05,  1.19it/s]Epoch: 5/10. Loss: 0.7917:  77%|[36m███████▋  [0m| 20/26 [00:18<00:05,  1.19it/s]Epoch: 5/10. Loss: 0.7917:  81%|[36m████████  [0m| 21/26 [00:18<00:04,  1.11it/s]Epoch: 5/10. Loss: 0.8031:  81%|[36m████████  [0m| 21/26 [00:19<00:04,  1.11it/s]Epoch: 5/10. Loss: 0.8031:  85%|[36m████████▍ [0m| 22/26 [00:19<00:03,  1.13it/s]Epoch: 5/10. Loss: 0.7893:  85%|[36m████████▍ [0m| 22/26 [00:20<00:03,  1.13it/s]Epoch: 5/10. Loss: 0.7893:  88%|[36m████████▊ [0m| 23/26 [00:20<00:02,  1.10it/s]Epoch: 5/10. Loss: 0.8484:  88%|[36m████████▊ [0m| 23/26 [00:21<00:02,  1.10it/s]Epoch: 5/10. Loss: 0.8484:  92%|[36m█████████▏[0m| 24/26 [00:21<00:01,  1.08it/s]Epoch: 5/10. Loss: 0.7972:  92%|[36m█████████▏[0m| 24/26 [00:21<00:01,  1.08it/s]Epoch: 5/10. Loss: 0.7972:  96%|[36m█████████▌[0m| 25/26 [00:21<00:00,  1.09it/s]Epoch: 5/10. Loss: 0.7002:  96%|[36m█████████▌[0m| 25/26 [00:22<00:00,  1.09it/s]Epoch: 5/10. Loss: 0.7002: 100%|[36m██████████[0m| 26/26 [00:22<00:00,  1.21it/s]Epoch: 5/10. Loss: 0.7002: 100%|[36m██████████[0m| 26/26 [00:22<00:00,  1.15it/s]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:04,  1.21it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:05,  1.18s/it] 43%|[33m████▎     [0m| 3/7 [00:02<00:03,  1.03it/s] 57%|[33m█████▋    [0m| 4/7 [00:04<00:03,  1.08s/it] 71%|[33m███████▏  [0m| 5/7 [00:04<00:01,  1.18it/s] 86%|[33m████████▌ [0m| 6/7 [00:05<00:00,  1.17it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.48it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.20it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 6/10. Loss: 0.7982:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 6/10. Loss: 0.7982:   4%|[36m▍         [0m| 1/26 [00:00<00:22,  1.10it/s]Epoch: 6/10. Loss: 0.6991:   4%|[36m▍         [0m| 1/26 [00:01<00:22,  1.10it/s]Epoch: 6/10. Loss: 0.6991:   8%|[36m▊         [0m| 2/26 [00:01<00:21,  1.11it/s]Epoch: 6/10. Loss: 0.8453:   8%|[36m▊         [0m| 2/26 [00:02<00:21,  1.11it/s]Epoch: 6/10. Loss: 0.8453:  12%|[36m█▏        [0m| 3/26 [00:02<00:20,  1.13it/s]Epoch: 6/10. Loss: 0.9212:  12%|[36m█▏        [0m| 3/26 [00:04<00:20,  1.13it/s]Epoch: 6/10. Loss: 0.9212:  15%|[36m█▌        [0m| 4/26 [00:04<00:29,  1.33s/it]Epoch: 6/10. Loss: 0.7662:  15%|[36m█▌        [0m| 4/26 [00:05<00:29,  1.33s/it]Epoch: 6/10. Loss: 0.7662:  19%|[36m█▉        [0m| 5/26 [00:05<00:24,  1.19s/it]Epoch: 6/10. Loss: 0.8117:  19%|[36m█▉        [0m| 5/26 [00:06<00:24,  1.19s/it]Epoch: 6/10. Loss: 0.8117:  23%|[36m██▎       [0m| 6/26 [00:06<00:21,  1.10s/it]Epoch: 6/10. Loss: 0.7321:  23%|[36m██▎       [0m| 6/26 [00:07<00:21,  1.10s/it]Epoch: 6/10. Loss: 0.7321:  27%|[36m██▋       [0m| 7/26 [00:07<00:21,  1.12s/it]Epoch: 6/10. Loss: 0.8926:  27%|[36m██▋       [0m| 7/26 [00:08<00:21,  1.12s/it]Epoch: 6/10. Loss: 0.8926:  31%|[36m███       [0m| 8/26 [00:08<00:18,  1.05s/it]Epoch: 6/10. Loss: 0.8626:  31%|[36m███       [0m| 8/26 [00:09<00:18,  1.05s/it]Epoch: 6/10. Loss: 0.8626:  35%|[36m███▍      [0m| 9/26 [00:09<00:17,  1.01s/it]Epoch: 6/10. Loss: 0.7850:  35%|[36m███▍      [0m| 9/26 [00:10<00:17,  1.01s/it]Epoch: 6/10. Loss: 0.7850:  38%|[36m███▊      [0m| 10/26 [00:10<00:15,  1.04it/s]Epoch: 6/10. Loss: 0.6932:  38%|[36m███▊      [0m| 10/26 [00:11<00:15,  1.04it/s]Epoch: 6/10. Loss: 0.6932:  42%|[36m████▏     [0m| 11/26 [00:11<00:14,  1.04it/s]Epoch: 6/10. Loss: 0.7864:  42%|[36m████▏     [0m| 11/26 [00:12<00:14,  1.04it/s]Epoch: 6/10. Loss: 0.7864:  46%|[36m████▌     [0m| 12/26 [00:12<00:12,  1.12it/s]Epoch: 6/10. Loss: 0.7769:  46%|[36m████▌     [0m| 12/26 [00:13<00:12,  1.12it/s]Epoch: 6/10. Loss: 0.7769:  50%|[36m█████     [0m| 13/26 [00:13<00:13,  1.07s/it]Epoch: 6/10. Loss: 0.7552:  50%|[36m█████     [0m| 13/26 [00:14<00:13,  1.07s/it]Epoch: 6/10. Loss: 0.7552:  54%|[36m█████▍    [0m| 14/26 [00:14<00:12,  1.04s/it]Epoch: 6/10. Loss: 0.8662:  54%|[36m█████▍    [0m| 14/26 [00:15<00:12,  1.04s/it]Epoch: 6/10. Loss: 0.8662:  58%|[36m█████▊    [0m| 15/26 [00:15<00:12,  1.10s/it]Epoch: 6/10. Loss: 0.7491:  58%|[36m█████▊    [0m| 15/26 [00:18<00:12,  1.10s/it]Epoch: 6/10. Loss: 0.7491:  62%|[36m██████▏   [0m| 16/26 [00:18<00:14,  1.45s/it]Epoch: 6/10. Loss: 0.8200:  62%|[36m██████▏   [0m| 16/26 [00:18<00:14,  1.45s/it]Epoch: 6/10. Loss: 0.8200:  65%|[36m██████▌   [0m| 17/26 [00:18<00:11,  1.27s/it]Epoch: 6/10. Loss: 0.7646:  65%|[36m██████▌   [0m| 17/26 [00:19<00:11,  1.27s/it]Epoch: 6/10. Loss: 0.7646:  69%|[36m██████▉   [0m| 18/26 [00:19<00:09,  1.18s/it]Epoch: 6/10. Loss: 0.6263:  69%|[36m██████▉   [0m| 18/26 [00:20<00:09,  1.18s/it]Epoch: 6/10. Loss: 0.6263:  73%|[36m███████▎  [0m| 19/26 [00:20<00:07,  1.06s/it]Epoch: 6/10. Loss: 0.7609:  73%|[36m███████▎  [0m| 19/26 [00:21<00:07,  1.06s/it]Epoch: 6/10. Loss: 0.7609:  77%|[36m███████▋  [0m| 20/26 [00:21<00:06,  1.02s/it]Epoch: 6/10. Loss: 0.7423:  77%|[36m███████▋  [0m| 20/26 [00:22<00:06,  1.02s/it]Epoch: 6/10. Loss: 0.7423:  81%|[36m████████  [0m| 21/26 [00:22<00:04,  1.06it/s]Epoch: 6/10. Loss: 0.8376:  81%|[36m████████  [0m| 21/26 [00:23<00:04,  1.06it/s]Epoch: 6/10. Loss: 0.8376:  85%|[36m████████▍ [0m| 22/26 [00:23<00:03,  1.14it/s]Epoch: 6/10. Loss: 0.6873:  85%|[36m████████▍ [0m| 22/26 [00:24<00:03,  1.14it/s]Epoch: 6/10. Loss: 0.6873:  88%|[36m████████▊ [0m| 23/26 [00:24<00:02,  1.07it/s]Epoch: 6/10. Loss: 0.7566:  88%|[36m████████▊ [0m| 23/26 [00:27<00:02,  1.07it/s]Epoch: 6/10. Loss: 0.7566:  92%|[36m█████████▏[0m| 24/26 [00:27<00:03,  1.54s/it]Epoch: 6/10. Loss: 0.7863:  92%|[36m█████████▏[0m| 24/26 [00:27<00:03,  1.54s/it]Epoch: 6/10. Loss: 0.7863:  96%|[36m█████████▌[0m| 25/26 [00:27<00:01,  1.35s/it]Epoch: 6/10. Loss: 0.8627:  96%|[36m█████████▌[0m| 25/26 [00:28<00:01,  1.35s/it]Epoch: 6/10. Loss: 0.8627: 100%|[36m██████████[0m| 26/26 [00:28<00:00,  1.12s/it]Epoch: 6/10. Loss: 0.8627: 100%|[36m██████████[0m| 26/26 [00:28<00:00,  1.10s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:01<00:07,  1.28s/it] 29%|[33m██▊       [0m| 2/7 [00:02<00:06,  1.38s/it] 43%|[33m████▎     [0m| 3/7 [00:03<00:04,  1.07s/it] 57%|[33m█████▋    [0m| 4/7 [00:04<00:03,  1.13s/it] 71%|[33m███████▏  [0m| 5/7 [00:05<00:01,  1.13it/s] 86%|[33m████████▌ [0m| 6/7 [00:06<00:00,  1.02it/s]100%|[33m██████████[0m| 7/7 [00:06<00:00,  1.32it/s]100%|[33m██████████[0m| 7/7 [00:06<00:00,  1.06it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 7/10. Loss: 0.6738:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 7/10. Loss: 0.6738:   4%|[36m▍         [0m| 1/26 [00:00<00:24,  1.00it/s]Epoch: 7/10. Loss: 0.6563:   4%|[36m▍         [0m| 1/26 [00:01<00:24,  1.00it/s]Epoch: 7/10. Loss: 0.6563:   8%|[36m▊         [0m| 2/26 [00:01<00:21,  1.14it/s]Epoch: 7/10. Loss: 0.8791:   8%|[36m▊         [0m| 2/26 [00:02<00:21,  1.14it/s]Epoch: 7/10. Loss: 0.8791:  12%|[36m█▏        [0m| 3/26 [00:02<00:22,  1.02it/s]Epoch: 7/10. Loss: 0.6908:  12%|[36m█▏        [0m| 3/26 [00:04<00:22,  1.02it/s]Epoch: 7/10. Loss: 0.6908:  15%|[36m█▌        [0m| 4/26 [00:04<00:24,  1.11s/it]Epoch: 7/10. Loss: 0.7657:  15%|[36m█▌        [0m| 4/26 [00:05<00:24,  1.11s/it]Epoch: 7/10. Loss: 0.7657:  19%|[36m█▉        [0m| 5/26 [00:05<00:21,  1.05s/it]Epoch: 7/10. Loss: 0.6846:  19%|[36m█▉        [0m| 5/26 [00:05<00:21,  1.05s/it]Epoch: 7/10. Loss: 0.6846:  23%|[36m██▎       [0m| 6/26 [00:05<00:19,  1.03it/s]Epoch: 7/10. Loss: 0.7389:  23%|[36m██▎       [0m| 6/26 [00:06<00:19,  1.03it/s]Epoch: 7/10. Loss: 0.7389:  27%|[36m██▋       [0m| 7/26 [00:06<00:17,  1.06it/s]Epoch: 7/10. Loss: 0.7234:  27%|[36m██▋       [0m| 7/26 [00:07<00:17,  1.06it/s]Epoch: 7/10. Loss: 0.7234:  31%|[36m███       [0m| 8/26 [00:07<00:15,  1.13it/s]Epoch: 7/10. Loss: 0.8626:  31%|[36m███       [0m| 8/26 [00:08<00:15,  1.13it/s]Epoch: 7/10. Loss: 0.8626:  35%|[36m███▍      [0m| 9/26 [00:08<00:15,  1.10it/s]Epoch: 7/10. Loss: 0.6400:  35%|[36m███▍      [0m| 9/26 [00:09<00:15,  1.10it/s]Epoch: 7/10. Loss: 0.6400:  38%|[36m███▊      [0m| 10/26 [00:09<00:14,  1.11it/s]Epoch: 7/10. Loss: 0.7154:  38%|[36m███▊      [0m| 10/26 [00:10<00:14,  1.11it/s]Epoch: 7/10. Loss: 0.7154:  42%|[36m████▏     [0m| 11/26 [00:10<00:14,  1.05it/s]Epoch: 7/10. Loss: 0.8356:  42%|[36m████▏     [0m| 11/26 [00:11<00:14,  1.05it/s]Epoch: 7/10. Loss: 0.8356:  46%|[36m████▌     [0m| 12/26 [00:11<00:13,  1.07it/s]Epoch: 7/10. Loss: 0.6991:  46%|[36m████▌     [0m| 12/26 [00:12<00:13,  1.07it/s]Epoch: 7/10. Loss: 0.6991:  50%|[36m█████     [0m| 13/26 [00:12<00:12,  1.06it/s]Epoch: 7/10. Loss: 0.9036:  50%|[36m█████     [0m| 13/26 [00:13<00:12,  1.06it/s]Epoch: 7/10. Loss: 0.9036:  54%|[36m█████▍    [0m| 14/26 [00:13<00:11,  1.08it/s]Epoch: 7/10. Loss: 0.6239:  54%|[36m█████▍    [0m| 14/26 [00:14<00:11,  1.08it/s]Epoch: 7/10. Loss: 0.6239:  58%|[36m█████▊    [0m| 15/26 [00:14<00:10,  1.07it/s]Epoch: 7/10. Loss: 0.8069:  58%|[36m█████▊    [0m| 15/26 [00:15<00:10,  1.07it/s]Epoch: 7/10. Loss: 0.8069:  62%|[36m██████▏   [0m| 16/26 [00:15<00:09,  1.08it/s]Epoch: 7/10. Loss: 0.7949:  62%|[36m██████▏   [0m| 16/26 [00:16<00:09,  1.08it/s]Epoch: 7/10. Loss: 0.7949:  65%|[36m██████▌   [0m| 17/26 [00:16<00:08,  1.07it/s]Epoch: 7/10. Loss: 0.7389:  65%|[36m██████▌   [0m| 17/26 [00:16<00:08,  1.07it/s]Epoch: 7/10. Loss: 0.7389:  69%|[36m██████▉   [0m| 18/26 [00:16<00:07,  1.09it/s]Epoch: 7/10. Loss: 0.8006:  69%|[36m██████▉   [0m| 18/26 [00:17<00:07,  1.09it/s]Epoch: 7/10. Loss: 0.8006:  73%|[36m███████▎  [0m| 19/26 [00:17<00:06,  1.11it/s]Epoch: 7/10. Loss: 0.7815:  73%|[36m███████▎  [0m| 19/26 [00:20<00:06,  1.11it/s]Epoch: 7/10. Loss: 0.7815:  77%|[36m███████▋  [0m| 20/26 [00:20<00:07,  1.33s/it]Epoch: 7/10. Loss: 0.7249:  77%|[36m███████▋  [0m| 20/26 [00:21<00:07,  1.33s/it]Epoch: 7/10. Loss: 0.7249:  81%|[36m████████  [0m| 21/26 [00:21<00:07,  1.40s/it]Epoch: 7/10. Loss: 0.6377:  81%|[36m████████  [0m| 21/26 [00:22<00:07,  1.40s/it]Epoch: 7/10. Loss: 0.6377:  85%|[36m████████▍ [0m| 22/26 [00:22<00:04,  1.21s/it]Epoch: 7/10. Loss: 0.7782:  85%|[36m████████▍ [0m| 22/26 [00:25<00:04,  1.21s/it]Epoch: 7/10. Loss: 0.7782:  88%|[36m████████▊ [0m| 23/26 [00:25<00:04,  1.64s/it]Epoch: 7/10. Loss: 0.9943:  88%|[36m████████▊ [0m| 23/26 [00:26<00:04,  1.64s/it]Epoch: 7/10. Loss: 0.9943:  92%|[36m█████████▏[0m| 24/26 [00:26<00:02,  1.46s/it]Epoch: 7/10. Loss: 0.7367:  92%|[36m█████████▏[0m| 24/26 [00:27<00:02,  1.46s/it]Epoch: 7/10. Loss: 0.7367:  96%|[36m█████████▌[0m| 25/26 [00:27<00:01,  1.31s/it]Epoch: 7/10. Loss: 0.7411:  96%|[36m█████████▌[0m| 25/26 [00:28<00:01,  1.31s/it]Epoch: 7/10. Loss: 0.7411: 100%|[36m██████████[0m| 26/26 [00:28<00:00,  1.29s/it]Epoch: 7/10. Loss: 0.7411: 100%|[36m██████████[0m| 26/26 [00:28<00:00,  1.09s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:04,  1.22it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:05,  1.19s/it] 43%|[33m████▎     [0m| 3/7 [00:02<00:03,  1.04it/s] 57%|[33m█████▋    [0m| 4/7 [00:04<00:03,  1.07s/it] 71%|[33m███████▏  [0m| 5/7 [00:05<00:02,  1.28s/it] 86%|[33m████████▌ [0m| 6/7 [00:06<00:01,  1.14s/it]100%|[33m██████████[0m| 7/7 [00:07<00:00,  1.15it/s]100%|[33m██████████[0m| 7/7 [00:07<00:00,  1.00s/it]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 8/10. Loss: 0.7095:   0%|[36m          [0m| 0/26 [00:01<?, ?it/s]Epoch: 8/10. Loss: 0.7095:   4%|[36m▍         [0m| 1/26 [00:01<00:28,  1.14s/it]Epoch: 8/10. Loss: 0.6685:   4%|[36m▍         [0m| 1/26 [00:02<00:28,  1.14s/it]Epoch: 8/10. Loss: 0.6685:   8%|[36m▊         [0m| 2/26 [00:02<00:24,  1.01s/it]Epoch: 8/10. Loss: 0.6810:   8%|[36m▊         [0m| 2/26 [00:02<00:24,  1.01s/it]Epoch: 8/10. Loss: 0.6810:  12%|[36m█▏        [0m| 3/26 [00:02<00:21,  1.07it/s]Epoch: 8/10. Loss: 0.9063:  12%|[36m█▏        [0m| 3/26 [00:03<00:21,  1.07it/s]Epoch: 8/10. Loss: 0.9063:  15%|[36m█▌        [0m| 4/26 [00:03<00:19,  1.13it/s]Epoch: 8/10. Loss: 0.7808:  15%|[36m█▌        [0m| 4/26 [00:04<00:19,  1.13it/s]Epoch: 8/10. Loss: 0.7808:  19%|[36m█▉        [0m| 5/26 [00:04<00:19,  1.09it/s]Epoch: 8/10. Loss: 0.6975:  19%|[36m█▉        [0m| 5/26 [00:05<00:19,  1.09it/s]Epoch: 8/10. Loss: 0.6975:  23%|[36m██▎       [0m| 6/26 [00:05<00:18,  1.07it/s]Epoch: 8/10. Loss: 0.7458:  23%|[36m██▎       [0m| 6/26 [00:06<00:18,  1.07it/s]Epoch: 8/10. Loss: 0.7458:  27%|[36m██▋       [0m| 7/26 [00:06<00:16,  1.14it/s]Epoch: 8/10. Loss: 0.6606:  27%|[36m██▋       [0m| 7/26 [00:07<00:16,  1.14it/s]Epoch: 8/10. Loss: 0.6606:  31%|[36m███       [0m| 8/26 [00:07<00:15,  1.16it/s]Epoch: 8/10. Loss: 0.7736:  31%|[36m███       [0m| 8/26 [00:08<00:15,  1.16it/s]Epoch: 8/10. Loss: 0.7736:  35%|[36m███▍      [0m| 9/26 [00:08<00:14,  1.18it/s]Epoch: 8/10. Loss: 0.6865:  35%|[36m███▍      [0m| 9/26 [00:08<00:14,  1.18it/s]Epoch: 8/10. Loss: 0.6865:  38%|[36m███▊      [0m| 10/26 [00:08<00:13,  1.22it/s]Epoch: 8/10. Loss: 0.7312:  38%|[36m███▊      [0m| 10/26 [00:12<00:13,  1.22it/s]Epoch: 8/10. Loss: 0.7312:  42%|[36m████▏     [0m| 11/26 [00:12<00:24,  1.61s/it]Epoch: 8/10. Loss: 0.6623:  42%|[36m████▏     [0m| 11/26 [00:13<00:24,  1.61s/it]Epoch: 8/10. Loss: 0.6623:  46%|[36m████▌     [0m| 12/26 [00:13<00:21,  1.50s/it]Epoch: 8/10. Loss: 0.7421:  46%|[36m████▌     [0m| 12/26 [00:14<00:21,  1.50s/it]Epoch: 8/10. Loss: 0.7421:  50%|[36m█████     [0m| 13/26 [00:14<00:17,  1.34s/it]Epoch: 8/10. Loss: 0.7160:  50%|[36m█████     [0m| 13/26 [00:15<00:17,  1.34s/it]Epoch: 8/10. Loss: 0.7160:  54%|[36m█████▍    [0m| 14/26 [00:15<00:15,  1.29s/it]Epoch: 8/10. Loss: 0.5704:  54%|[36m█████▍    [0m| 14/26 [00:16<00:15,  1.29s/it]Epoch: 8/10. Loss: 0.5704:  58%|[36m█████▊    [0m| 15/26 [00:16<00:12,  1.16s/it]Epoch: 8/10. Loss: 0.6328:  58%|[36m█████▊    [0m| 15/26 [00:18<00:12,  1.16s/it]Epoch: 8/10. Loss: 0.6328:  62%|[36m██████▏   [0m| 16/26 [00:18<00:15,  1.52s/it]Epoch: 8/10. Loss: 0.6962:  62%|[36m██████▏   [0m| 16/26 [00:21<00:15,  1.52s/it]Epoch: 8/10. Loss: 0.6962:  65%|[36m██████▌   [0m| 17/26 [00:21<00:16,  1.80s/it]Epoch: 8/10. Loss: 0.8550:  65%|[36m██████▌   [0m| 17/26 [00:22<00:16,  1.80s/it]Epoch: 8/10. Loss: 0.8550:  69%|[36m██████▉   [0m| 18/26 [00:22<00:12,  1.53s/it]Epoch: 8/10. Loss: 0.7234:  69%|[36m██████▉   [0m| 18/26 [00:23<00:12,  1.53s/it]Epoch: 8/10. Loss: 0.7234:  73%|[36m███████▎  [0m| 19/26 [00:23<00:09,  1.37s/it]Epoch: 8/10. Loss: 0.7384:  73%|[36m███████▎  [0m| 19/26 [00:23<00:09,  1.37s/it]Epoch: 8/10. Loss: 0.7384:  77%|[36m███████▋  [0m| 20/26 [00:23<00:07,  1.19s/it]Epoch: 8/10. Loss: 0.6142:  77%|[36m███████▋  [0m| 20/26 [00:25<00:07,  1.19s/it]Epoch: 8/10. Loss: 0.6142:  81%|[36m████████  [0m| 21/26 [00:25<00:06,  1.26s/it]Epoch: 8/10. Loss: 0.8349:  81%|[36m████████  [0m| 21/26 [00:26<00:06,  1.26s/it]Epoch: 8/10. Loss: 0.8349:  85%|[36m████████▍ [0m| 22/26 [00:26<00:04,  1.19s/it]Epoch: 8/10. Loss: 0.7275:  85%|[36m████████▍ [0m| 22/26 [00:27<00:04,  1.19s/it]Epoch: 8/10. Loss: 0.7275:  88%|[36m████████▊ [0m| 23/26 [00:27<00:03,  1.18s/it]Epoch: 8/10. Loss: 0.6696:  88%|[36m████████▊ [0m| 23/26 [00:28<00:03,  1.18s/it]Epoch: 8/10. Loss: 0.6696:  92%|[36m█████████▏[0m| 24/26 [00:28<00:02,  1.10s/it]Epoch: 8/10. Loss: 0.8663:  92%|[36m█████████▏[0m| 24/26 [00:29<00:02,  1.10s/it]Epoch: 8/10. Loss: 0.8663:  96%|[36m█████████▌[0m| 25/26 [00:29<00:01,  1.01s/it]Epoch: 8/10. Loss: 0.6392:  96%|[36m█████████▌[0m| 25/26 [00:30<00:01,  1.01s/it]Epoch: 8/10. Loss: 0.6392: 100%|[36m██████████[0m| 26/26 [00:30<00:00,  1.06it/s]Epoch: 8/10. Loss: 0.6392: 100%|[36m██████████[0m| 26/26 [00:30<00:00,  1.16s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:04,  1.22it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:05,  1.17s/it] 43%|[33m████▎     [0m| 3/7 [00:02<00:03,  1.05it/s] 57%|[33m█████▋    [0m| 4/7 [00:06<00:05,  1.98s/it] 71%|[33m███████▏  [0m| 5/7 [00:08<00:04,  2.16s/it] 86%|[33m████████▌ [0m| 6/7 [00:09<00:01,  1.74s/it]100%|[33m██████████[0m| 7/7 [00:10<00:00,  1.27s/it]100%|[33m██████████[0m| 7/7 [00:10<00:00,  1.46s/it]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 9/10. Loss: 0.6932:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 9/10. Loss: 0.6932:   4%|[36m▍         [0m| 1/26 [00:00<00:24,  1.01it/s]Epoch: 9/10. Loss: 0.6396:   4%|[36m▍         [0m| 1/26 [00:01<00:24,  1.01it/s]Epoch: 9/10. Loss: 0.6396:   8%|[36m▊         [0m| 2/26 [00:01<00:23,  1.03it/s]Epoch: 9/10. Loss: 0.8146:   8%|[36m▊         [0m| 2/26 [00:02<00:23,  1.03it/s]Epoch: 9/10. Loss: 0.8146:  12%|[36m█▏        [0m| 3/26 [00:02<00:21,  1.06it/s]Epoch: 9/10. Loss: 0.6078:  12%|[36m█▏        [0m| 3/26 [00:03<00:21,  1.06it/s]Epoch: 9/10. Loss: 0.6078:  15%|[36m█▌        [0m| 4/26 [00:03<00:20,  1.08it/s]Epoch: 9/10. Loss: 0.6331:  15%|[36m█▌        [0m| 4/26 [00:04<00:20,  1.08it/s]Epoch: 9/10. Loss: 0.6331:  19%|[36m█▉        [0m| 5/26 [00:04<00:18,  1.15it/s]Epoch: 9/10. Loss: 0.6900:  19%|[36m█▉        [0m| 5/26 [00:05<00:18,  1.15it/s]Epoch: 9/10. Loss: 0.6900:  23%|[36m██▎       [0m| 6/26 [00:05<00:17,  1.16it/s]Epoch: 9/10. Loss: 0.6557:  23%|[36m██▎       [0m| 6/26 [00:06<00:17,  1.16it/s]Epoch: 9/10. Loss: 0.6557:  27%|[36m██▋       [0m| 7/26 [00:06<00:15,  1.20it/s]Epoch: 9/10. Loss: 0.7499:  27%|[36m██▋       [0m| 7/26 [00:06<00:15,  1.20it/s]Epoch: 9/10. Loss: 0.7499:  31%|[36m███       [0m| 8/26 [00:06<00:15,  1.20it/s]Epoch: 9/10. Loss: 0.6012:  31%|[36m███       [0m| 8/26 [00:08<00:15,  1.20it/s]Epoch: 9/10. Loss: 0.6012:  35%|[36m███▍      [0m| 9/26 [00:08<00:15,  1.10it/s]Epoch: 9/10. Loss: 0.5647:  35%|[36m███▍      [0m| 9/26 [00:08<00:15,  1.10it/s]Epoch: 9/10. Loss: 0.5647:  38%|[36m███▊      [0m| 10/26 [00:08<00:13,  1.15it/s]Epoch: 9/10. Loss: 0.7447:  38%|[36m███▊      [0m| 10/26 [00:09<00:13,  1.15it/s]Epoch: 9/10. Loss: 0.7447:  42%|[36m████▏     [0m| 11/26 [00:09<00:13,  1.15it/s]Epoch: 9/10. Loss: 0.6940:  42%|[36m████▏     [0m| 11/26 [00:10<00:13,  1.15it/s]Epoch: 9/10. Loss: 0.6940:  46%|[36m████▌     [0m| 12/26 [00:10<00:12,  1.16it/s]Epoch: 9/10. Loss: 0.7290:  46%|[36m████▌     [0m| 12/26 [00:11<00:12,  1.16it/s]Epoch: 9/10. Loss: 0.7290:  50%|[36m█████     [0m| 13/26 [00:11<00:10,  1.19it/s]Epoch: 9/10. Loss: 0.7289:  50%|[36m█████     [0m| 13/26 [00:12<00:10,  1.19it/s]Epoch: 9/10. Loss: 0.7289:  54%|[36m█████▍    [0m| 14/26 [00:12<00:10,  1.16it/s]Epoch: 9/10. Loss: 0.6379:  54%|[36m█████▍    [0m| 14/26 [00:13<00:10,  1.16it/s]Epoch: 9/10. Loss: 0.6379:  58%|[36m█████▊    [0m| 15/26 [00:13<00:09,  1.19it/s]Epoch: 9/10. Loss: 0.6399:  58%|[36m█████▊    [0m| 15/26 [00:14<00:09,  1.19it/s]Epoch: 9/10. Loss: 0.6399:  62%|[36m██████▏   [0m| 16/26 [00:14<00:08,  1.13it/s]Epoch: 9/10. Loss: 0.6370:  62%|[36m██████▏   [0m| 16/26 [00:14<00:08,  1.13it/s]Epoch: 9/10. Loss: 0.6370:  65%|[36m██████▌   [0m| 17/26 [00:14<00:08,  1.11it/s]Epoch: 9/10. Loss: 0.6682:  65%|[36m██████▌   [0m| 17/26 [00:15<00:08,  1.11it/s]Epoch: 9/10. Loss: 0.6682:  69%|[36m██████▉   [0m| 18/26 [00:15<00:06,  1.21it/s]Epoch: 9/10. Loss: 0.6879:  69%|[36m██████▉   [0m| 18/26 [00:16<00:06,  1.21it/s]Epoch: 9/10. Loss: 0.6879:  73%|[36m███████▎  [0m| 19/26 [00:16<00:06,  1.15it/s]Epoch: 9/10. Loss: 0.6073:  73%|[36m███████▎  [0m| 19/26 [00:17<00:06,  1.15it/s]Epoch: 9/10. Loss: 0.6073:  77%|[36m███████▋  [0m| 20/26 [00:17<00:05,  1.19it/s]Epoch: 9/10. Loss: 0.5058:  77%|[36m███████▋  [0m| 20/26 [00:18<00:05,  1.19it/s]Epoch: 9/10. Loss: 0.5058:  81%|[36m████████  [0m| 21/26 [00:18<00:04,  1.14it/s]Epoch: 9/10. Loss: 0.6544:  81%|[36m████████  [0m| 21/26 [00:19<00:04,  1.14it/s]Epoch: 9/10. Loss: 0.6544:  85%|[36m████████▍ [0m| 22/26 [00:19<00:03,  1.13it/s]Epoch: 9/10. Loss: 0.6377:  85%|[36m████████▍ [0m| 22/26 [00:20<00:03,  1.13it/s]Epoch: 9/10. Loss: 0.6377:  88%|[36m████████▊ [0m| 23/26 [00:20<00:02,  1.12it/s]Epoch: 9/10. Loss: 0.7844:  88%|[36m████████▊ [0m| 23/26 [00:20<00:02,  1.12it/s]Epoch: 9/10. Loss: 0.7844:  92%|[36m█████████▏[0m| 24/26 [00:21<00:01,  1.13it/s]Epoch: 9/10. Loss: 0.6821:  92%|[36m█████████▏[0m| 24/26 [00:21<00:01,  1.13it/s]Epoch: 9/10. Loss: 0.6821:  96%|[36m█████████▌[0m| 25/26 [00:21<00:00,  1.16it/s]Epoch: 9/10. Loss: 0.5646:  96%|[36m█████████▌[0m| 25/26 [00:22<00:00,  1.16it/s]Epoch: 9/10. Loss: 0.5646: 100%|[36m██████████[0m| 26/26 [00:22<00:00,  1.29it/s]Epoch: 9/10. Loss: 0.5646: 100%|[36m██████████[0m| 26/26 [00:22<00:00,  1.16it/s]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:04,  1.22it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:05,  1.17s/it] 43%|[33m████▎     [0m| 3/7 [00:02<00:03,  1.04it/s] 57%|[33m█████▋    [0m| 4/7 [00:04<00:03,  1.08s/it] 71%|[33m███████▏  [0m| 5/7 [00:04<00:01,  1.16it/s] 86%|[33m████████▌ [0m| 6/7 [00:05<00:00,  1.15it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.44it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.18it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 0/10. Loss: 1.2703:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 0/10. Loss: 1.2703:   4%|[36m▍         [0m| 1/26 [00:00<00:23,  1.05it/s]Epoch: 0/10. Loss: 3.5136:   4%|[36m▍         [0m| 1/26 [00:02<00:23,  1.05it/s]Epoch: 0/10. Loss: 3.5136:   8%|[36m▊         [0m| 2/26 [00:02<00:28,  1.20s/it]Epoch: 0/10. Loss: 3.5813:   8%|[36m▊         [0m| 2/26 [00:03<00:28,  1.20s/it]Epoch: 0/10. Loss: 3.5813:  12%|[36m█▏        [0m| 3/26 [00:03<00:27,  1.18s/it]Epoch: 0/10. Loss: 1.9909:  12%|[36m█▏        [0m| 3/26 [00:04<00:27,  1.18s/it]Epoch: 0/10. Loss: 1.9909:  15%|[36m█▌        [0m| 4/26 [00:04<00:24,  1.11s/it]Epoch: 0/10. Loss: 2.2962:  15%|[36m█▌        [0m| 4/26 [00:05<00:24,  1.11s/it]Epoch: 0/10. Loss: 2.2962:  19%|[36m█▉        [0m| 5/26 [00:05<00:22,  1.07s/it]Epoch: 0/10. Loss: 1.1749:  19%|[36m█▉        [0m| 5/26 [00:07<00:22,  1.07s/it]Epoch: 0/10. Loss: 1.1749:  23%|[36m██▎       [0m| 6/26 [00:07<00:28,  1.42s/it]Epoch: 0/10. Loss: 1.1976:  23%|[36m██▎       [0m| 6/26 [00:08<00:28,  1.42s/it]Epoch: 0/10. Loss: 1.1976:  27%|[36m██▋       [0m| 7/26 [00:08<00:24,  1.31s/it]Epoch: 0/10. Loss: 1.0093:  27%|[36m██▋       [0m| 7/26 [00:09<00:24,  1.31s/it]Epoch: 0/10. Loss: 1.0093:  31%|[36m███       [0m| 8/26 [00:09<00:21,  1.18s/it]Epoch: 0/10. Loss: 1.3712:  31%|[36m███       [0m| 8/26 [00:10<00:21,  1.18s/it]Epoch: 0/10. Loss: 1.3712:  35%|[36m███▍      [0m| 9/26 [00:10<00:18,  1.12s/it]Epoch: 0/10. Loss: 1.0632:  35%|[36m███▍      [0m| 9/26 [00:11<00:18,  1.12s/it]Epoch: 0/10. Loss: 1.0632:  38%|[36m███▊      [0m| 10/26 [00:11<00:16,  1.02s/it]Epoch: 0/10. Loss: 1.0447:  38%|[36m███▊      [0m| 10/26 [00:12<00:16,  1.02s/it]Epoch: 0/10. Loss: 1.0447:  42%|[36m████▏     [0m| 11/26 [00:12<00:15,  1.02s/it]Epoch: 0/10. Loss: 1.3157:  42%|[36m████▏     [0m| 11/26 [00:13<00:15,  1.02s/it]Epoch: 0/10. Loss: 1.3157:  46%|[36m████▌     [0m| 12/26 [00:13<00:15,  1.08s/it]Epoch: 0/10. Loss: 1.1285:  46%|[36m████▌     [0m| 12/26 [00:14<00:15,  1.08s/it]Epoch: 0/10. Loss: 1.1285:  50%|[36m█████     [0m| 13/26 [00:14<00:13,  1.03s/it]Epoch: 0/10. Loss: 0.9336:  50%|[36m█████     [0m| 13/26 [00:15<00:13,  1.03s/it]Epoch: 0/10. Loss: 0.9336:  54%|[36m█████▍    [0m| 14/26 [00:15<00:12,  1.07s/it]Epoch: 0/10. Loss: 1.0934:  54%|[36m█████▍    [0m| 14/26 [00:16<00:12,  1.07s/it]Epoch: 0/10. Loss: 1.0934:  58%|[36m█████▊    [0m| 15/26 [00:16<00:11,  1.05s/it]Epoch: 0/10. Loss: 1.0918:  58%|[36m█████▊    [0m| 15/26 [00:17<00:11,  1.05s/it]Epoch: 0/10. Loss: 1.0918:  62%|[36m██████▏   [0m| 16/26 [00:17<00:09,  1.02it/s]Epoch: 0/10. Loss: 1.1505:  62%|[36m██████▏   [0m| 16/26 [00:18<00:09,  1.02it/s]Epoch: 0/10. Loss: 1.1505:  65%|[36m██████▌   [0m| 17/26 [00:18<00:09,  1.03s/it]Epoch: 0/10. Loss: 0.9662:  65%|[36m██████▌   [0m| 17/26 [00:19<00:09,  1.03s/it]Epoch: 0/10. Loss: 0.9662:  69%|[36m██████▉   [0m| 18/26 [00:19<00:07,  1.04it/s]Epoch: 0/10. Loss: 0.9035:  69%|[36m██████▉   [0m| 18/26 [00:20<00:07,  1.04it/s]Epoch: 0/10. Loss: 0.9035:  73%|[36m███████▎  [0m| 19/26 [00:20<00:07,  1.03s/it]Epoch: 0/10. Loss: 0.9596:  73%|[36m███████▎  [0m| 19/26 [00:21<00:07,  1.03s/it]Epoch: 0/10. Loss: 0.9596:  77%|[36m███████▋  [0m| 20/26 [00:21<00:05,  1.01it/s]Epoch: 0/10. Loss: 1.1275:  77%|[36m███████▋  [0m| 20/26 [00:22<00:05,  1.01it/s]Epoch: 0/10. Loss: 1.1275:  81%|[36m████████  [0m| 21/26 [00:22<00:05,  1.02s/it]Epoch: 0/10. Loss: 1.0342:  81%|[36m████████  [0m| 21/26 [00:23<00:05,  1.02s/it]Epoch: 0/10. Loss: 1.0342:  85%|[36m████████▍ [0m| 22/26 [00:23<00:03,  1.04it/s]Epoch: 0/10. Loss: 1.0893:  85%|[36m████████▍ [0m| 22/26 [00:25<00:03,  1.04it/s]Epoch: 0/10. Loss: 1.0893:  88%|[36m████████▊ [0m| 23/26 [00:25<00:04,  1.44s/it]Epoch: 0/10. Loss: 1.0346:  88%|[36m████████▊ [0m| 23/26 [00:27<00:04,  1.44s/it]Epoch: 0/10. Loss: 1.0346:  92%|[36m█████████▏[0m| 24/26 [00:27<00:02,  1.40s/it]Epoch: 0/10. Loss: 1.0585:  92%|[36m█████████▏[0m| 24/26 [00:28<00:02,  1.40s/it]Epoch: 0/10. Loss: 1.0585:  96%|[36m█████████▌[0m| 25/26 [00:28<00:01,  1.23s/it]Epoch: 0/10. Loss: 1.0494:  96%|[36m█████████▌[0m| 25/26 [00:28<00:01,  1.23s/it]Epoch: 0/10. Loss: 1.0494: 100%|[36m██████████[0m| 26/26 [00:28<00:00,  1.03s/it]Epoch: 0/10. Loss: 1.0494: 100%|[36m██████████[0m| 26/26 [00:28<00:00,  1.10s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:01<00:07,  1.21s/it] 29%|[33m██▊       [0m| 2/7 [00:02<00:06,  1.36s/it] 43%|[33m████▎     [0m| 3/7 [00:03<00:04,  1.08s/it] 57%|[33m█████▋    [0m| 4/7 [00:04<00:03,  1.14s/it] 71%|[33m███████▏  [0m| 5/7 [00:05<00:01,  1.15it/s] 86%|[33m████████▌ [0m| 6/7 [00:05<00:00,  1.18it/s]100%|[33m██████████[0m| 7/7 [00:06<00:00,  1.52it/s]100%|[33m██████████[0m| 7/7 [00:06<00:00,  1.14it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 1/10. Loss: 0.9600:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 1/10. Loss: 0.9600:   4%|[36m▍         [0m| 1/26 [00:01<00:25,  1.03s/it]Epoch: 1/10. Loss: 1.0261:   4%|[36m▍         [0m| 1/26 [00:01<00:25,  1.03s/it]Epoch: 1/10. Loss: 1.0261:   8%|[36m▊         [0m| 2/26 [00:01<00:20,  1.15it/s]Epoch: 1/10. Loss: 0.9744:   8%|[36m▊         [0m| 2/26 [00:02<00:20,  1.15it/s]Epoch: 1/10. Loss: 0.9744:  12%|[36m█▏        [0m| 3/26 [00:02<00:23,  1.02s/it]Epoch: 1/10. Loss: 1.0654:  12%|[36m█▏        [0m| 3/26 [00:03<00:23,  1.02s/it]Epoch: 1/10. Loss: 1.0654:  15%|[36m█▌        [0m| 4/26 [00:03<00:21,  1.01it/s]Epoch: 1/10. Loss: 1.3840:  15%|[36m█▌        [0m| 4/26 [00:05<00:21,  1.01it/s]Epoch: 1/10. Loss: 1.3840:  19%|[36m█▉        [0m| 5/26 [00:05<00:23,  1.10s/it]Epoch: 1/10. Loss: 1.0658:  19%|[36m█▉        [0m| 5/26 [00:06<00:23,  1.10s/it]Epoch: 1/10. Loss: 1.0658:  23%|[36m██▎       [0m| 6/26 [00:06<00:20,  1.05s/it]Epoch: 1/10. Loss: 1.1030:  23%|[36m██▎       [0m| 6/26 [00:07<00:20,  1.05s/it]Epoch: 1/10. Loss: 1.1030:  27%|[36m██▋       [0m| 7/26 [00:07<00:19,  1.00s/it]Epoch: 1/10. Loss: 1.3105:  27%|[36m██▋       [0m| 7/26 [00:08<00:19,  1.00s/it]Epoch: 1/10. Loss: 1.3105:  31%|[36m███       [0m| 8/26 [00:08<00:18,  1.01s/it]Epoch: 1/10. Loss: 1.0798:  31%|[36m███       [0m| 8/26 [00:08<00:18,  1.01s/it]Epoch: 1/10. Loss: 1.0798:  35%|[36m███▍      [0m| 9/26 [00:08<00:16,  1.03it/s]Epoch: 1/10. Loss: 1.0074:  35%|[36m███▍      [0m| 9/26 [00:09<00:16,  1.03it/s]Epoch: 1/10. Loss: 1.0074:  38%|[36m███▊      [0m| 10/26 [00:09<00:15,  1.04it/s]Epoch: 1/10. Loss: 1.0583:  38%|[36m███▊      [0m| 10/26 [00:10<00:15,  1.04it/s]Epoch: 1/10. Loss: 1.0583:  42%|[36m████▏     [0m| 11/26 [00:11<00:14,  1.00it/s]Epoch: 1/10. Loss: 1.0190:  42%|[36m████▏     [0m| 11/26 [00:11<00:14,  1.00it/s]Epoch: 1/10. Loss: 1.0190:  46%|[36m████▌     [0m| 12/26 [00:11<00:13,  1.01it/s]Epoch: 1/10. Loss: 0.9947:  46%|[36m████▌     [0m| 12/26 [00:12<00:13,  1.01it/s]Epoch: 1/10. Loss: 0.9947:  50%|[36m█████     [0m| 13/26 [00:13<00:13,  1.00s/it]Epoch: 1/10. Loss: 0.9815:  50%|[36m█████     [0m| 13/26 [00:14<00:13,  1.00s/it]Epoch: 1/10. Loss: 0.9815:  54%|[36m█████▍    [0m| 14/26 [00:14<00:12,  1.01s/it]Epoch: 1/10. Loss: 1.0117:  54%|[36m█████▍    [0m| 14/26 [00:15<00:12,  1.01s/it]Epoch: 1/10. Loss: 1.0117:  58%|[36m█████▊    [0m| 15/26 [00:15<00:11,  1.02s/it]Epoch: 1/10. Loss: 1.0325:  58%|[36m█████▊    [0m| 15/26 [00:15<00:11,  1.02s/it]Epoch: 1/10. Loss: 1.0325:  62%|[36m██████▏   [0m| 16/26 [00:15<00:09,  1.02it/s]Epoch: 1/10. Loss: 1.0261:  62%|[36m██████▏   [0m| 16/26 [00:16<00:09,  1.02it/s]Epoch: 1/10. Loss: 1.0261:  65%|[36m██████▌   [0m| 17/26 [00:17<00:08,  1.00it/s]Epoch: 1/10. Loss: 1.0535:  65%|[36m██████▌   [0m| 17/26 [00:17<00:08,  1.00it/s]Epoch: 1/10. Loss: 1.0535:  69%|[36m██████▉   [0m| 18/26 [00:17<00:07,  1.03it/s]Epoch: 1/10. Loss: 1.1040:  69%|[36m██████▉   [0m| 18/26 [00:18<00:07,  1.03it/s]Epoch: 1/10. Loss: 1.1040:  73%|[36m███████▎  [0m| 19/26 [00:18<00:06,  1.01it/s]Epoch: 1/10. Loss: 0.9856:  73%|[36m███████▎  [0m| 19/26 [00:20<00:06,  1.01it/s]Epoch: 1/10. Loss: 0.9856:  77%|[36m███████▋  [0m| 20/26 [00:20<00:06,  1.06s/it]Epoch: 1/10. Loss: 1.0077:  77%|[36m███████▋  [0m| 20/26 [00:20<00:06,  1.06s/it]Epoch: 1/10. Loss: 1.0077:  81%|[36m████████  [0m| 21/26 [00:21<00:04,  1.01it/s]Epoch: 1/10. Loss: 1.0641:  81%|[36m████████  [0m| 21/26 [00:22<00:04,  1.01it/s]Epoch: 1/10. Loss: 1.0641:  85%|[36m████████▍ [0m| 22/26 [00:22<00:04,  1.12s/it]Epoch: 1/10. Loss: 1.0332:  85%|[36m████████▍ [0m| 22/26 [00:23<00:04,  1.12s/it]Epoch: 1/10. Loss: 1.0332:  88%|[36m████████▊ [0m| 23/26 [00:23<00:03,  1.07s/it]Epoch: 1/10. Loss: 0.9460:  88%|[36m████████▊ [0m| 23/26 [00:24<00:03,  1.07s/it]Epoch: 1/10. Loss: 0.9460:  92%|[36m█████████▏[0m| 24/26 [00:24<00:02,  1.06s/it]Epoch: 1/10. Loss: 1.0415:  92%|[36m█████████▏[0m| 24/26 [00:27<00:02,  1.06s/it]Epoch: 1/10. Loss: 1.0415:  96%|[36m█████████▌[0m| 25/26 [00:27<00:01,  1.74s/it]Epoch: 1/10. Loss: 1.0160:  96%|[36m█████████▌[0m| 25/26 [00:28<00:01,  1.74s/it]Epoch: 1/10. Loss: 1.0160: 100%|[36m██████████[0m| 26/26 [00:28<00:00,  1.42s/it]Epoch: 1/10. Loss: 1.0160: 100%|[36m██████████[0m| 26/26 [00:28<00:00,  1.09s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:05,  1.03it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:06,  1.33s/it] 43%|[33m████▎     [0m| 3/7 [00:03<00:04,  1.06s/it] 57%|[33m█████▋    [0m| 4/7 [00:04<00:03,  1.13s/it] 71%|[33m███████▏  [0m| 5/7 [00:04<00:01,  1.13it/s] 86%|[33m████████▌ [0m| 6/7 [00:05<00:00,  1.08it/s]100%|[33m██████████[0m| 7/7 [00:06<00:00,  1.39it/s]100%|[33m██████████[0m| 7/7 [00:06<00:00,  1.11it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 2/10. Loss: 1.0770:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 2/10. Loss: 1.0770:   4%|[36m▍         [0m| 1/26 [00:00<00:23,  1.05it/s]Epoch: 2/10. Loss: 1.0103:   4%|[36m▍         [0m| 1/26 [00:01<00:23,  1.05it/s]Epoch: 2/10. Loss: 1.0103:   8%|[36m▊         [0m| 2/26 [00:01<00:22,  1.06it/s]Epoch: 2/10. Loss: 1.0303:   8%|[36m▊         [0m| 2/26 [00:02<00:22,  1.06it/s]Epoch: 2/10. Loss: 1.0303:  12%|[36m█▏        [0m| 3/26 [00:02<00:22,  1.01it/s]Epoch: 2/10. Loss: 0.9760:  12%|[36m█▏        [0m| 3/26 [00:04<00:22,  1.01it/s]Epoch: 2/10. Loss: 0.9760:  15%|[36m█▌        [0m| 4/26 [00:04<00:22,  1.03s/it]Epoch: 2/10. Loss: 1.0461:  15%|[36m█▌        [0m| 4/26 [00:04<00:22,  1.03s/it]Epoch: 2/10. Loss: 1.0461:  19%|[36m█▉        [0m| 5/26 [00:04<00:20,  1.01it/s]Epoch: 2/10. Loss: 0.9343:  19%|[36m█▉        [0m| 5/26 [00:05<00:20,  1.01it/s]Epoch: 2/10. Loss: 0.9343:  23%|[36m██▎       [0m| 6/26 [00:06<00:20,  1.02s/it]Epoch: 2/10. Loss: 0.9750:  23%|[36m██▎       [0m| 6/26 [00:06<00:20,  1.02s/it]Epoch: 2/10. Loss: 0.9750:  27%|[36m██▋       [0m| 7/26 [00:06<00:18,  1.03it/s]Epoch: 2/10. Loss: 1.0313:  27%|[36m██▋       [0m| 7/26 [00:07<00:18,  1.03it/s]Epoch: 2/10. Loss: 1.0313:  31%|[36m███       [0m| 8/26 [00:07<00:17,  1.04it/s]Epoch: 2/10. Loss: 0.9136:  31%|[36m███       [0m| 8/26 [00:09<00:17,  1.04it/s]Epoch: 2/10. Loss: 0.9136:  35%|[36m███▍      [0m| 9/26 [00:09<00:18,  1.09s/it]Epoch: 2/10. Loss: 0.9206:  35%|[36m███▍      [0m| 9/26 [00:09<00:18,  1.09s/it]Epoch: 2/10. Loss: 0.9206:  38%|[36m███▊      [0m| 10/26 [00:10<00:16,  1.00s/it]Epoch: 2/10. Loss: 0.9718:  38%|[36m███▊      [0m| 10/26 [00:10<00:16,  1.00s/it]Epoch: 2/10. Loss: 0.9718:  42%|[36m████▏     [0m| 11/26 [00:10<00:14,  1.04it/s]Epoch: 2/10. Loss: 0.9842:  42%|[36m████▏     [0m| 11/26 [00:11<00:14,  1.04it/s]Epoch: 2/10. Loss: 0.9842:  46%|[36m████▌     [0m| 12/26 [00:11<00:13,  1.07it/s]Epoch: 2/10. Loss: 0.9795:  46%|[36m████▌     [0m| 12/26 [00:12<00:13,  1.07it/s]Epoch: 2/10. Loss: 0.9795:  50%|[36m█████     [0m| 13/26 [00:12<00:12,  1.04it/s]Epoch: 2/10. Loss: 0.9814:  50%|[36m█████     [0m| 13/26 [00:15<00:12,  1.04it/s]Epoch: 2/10. Loss: 0.9814:  54%|[36m█████▍    [0m| 14/26 [00:15<00:16,  1.41s/it]Epoch: 2/10. Loss: 0.9676:  54%|[36m█████▍    [0m| 14/26 [00:16<00:16,  1.41s/it]Epoch: 2/10. Loss: 0.9676:  58%|[36m█████▊    [0m| 15/26 [00:16<00:13,  1.24s/it]Epoch: 2/10. Loss: 1.0520:  58%|[36m█████▊    [0m| 15/26 [00:17<00:13,  1.24s/it]Epoch: 2/10. Loss: 1.0520:  62%|[36m██████▏   [0m| 16/26 [00:17<00:11,  1.20s/it]Epoch: 2/10. Loss: 0.9698:  62%|[36m██████▏   [0m| 16/26 [00:18<00:11,  1.20s/it]Epoch: 2/10. Loss: 0.9698:  65%|[36m██████▌   [0m| 17/26 [00:18<00:09,  1.10s/it]Epoch: 2/10. Loss: 1.1086:  65%|[36m██████▌   [0m| 17/26 [00:18<00:09,  1.10s/it]Epoch: 2/10. Loss: 1.1086:  69%|[36m██████▉   [0m| 18/26 [00:18<00:08,  1.04s/it]Epoch: 2/10. Loss: 0.9385:  69%|[36m██████▉   [0m| 18/26 [00:20<00:08,  1.04s/it]Epoch: 2/10. Loss: 0.9385:  73%|[36m███████▎  [0m| 19/26 [00:20<00:07,  1.05s/it]Epoch: 2/10. Loss: 0.9708:  73%|[36m███████▎  [0m| 19/26 [00:20<00:07,  1.05s/it]Epoch: 2/10. Loss: 0.9708:  77%|[36m███████▋  [0m| 20/26 [00:20<00:06,  1.02s/it]Epoch: 2/10. Loss: 0.9729:  77%|[36m███████▋  [0m| 20/26 [00:21<00:06,  1.02s/it]Epoch: 2/10. Loss: 0.9729:  81%|[36m████████  [0m| 21/26 [00:21<00:04,  1.02it/s]Epoch: 2/10. Loss: 0.9517:  81%|[36m████████  [0m| 21/26 [00:24<00:04,  1.02it/s]Epoch: 2/10. Loss: 0.9517:  85%|[36m████████▍ [0m| 22/26 [00:24<00:05,  1.35s/it]Epoch: 2/10. Loss: 1.0128:  85%|[36m████████▍ [0m| 22/26 [00:24<00:05,  1.35s/it]Epoch: 2/10. Loss: 1.0128:  88%|[36m████████▊ [0m| 23/26 [00:24<00:03,  1.20s/it]Epoch: 2/10. Loss: 0.9952:  88%|[36m████████▊ [0m| 23/26 [00:25<00:03,  1.20s/it]Epoch: 2/10. Loss: 0.9952:  92%|[36m█████████▏[0m| 24/26 [00:25<00:02,  1.08s/it]Epoch: 2/10. Loss: 0.9889:  92%|[36m█████████▏[0m| 24/26 [00:26<00:02,  1.08s/it]Epoch: 2/10. Loss: 0.9889:  96%|[36m█████████▌[0m| 25/26 [00:26<00:01,  1.04s/it]Epoch: 2/10. Loss: 1.0423:  96%|[36m█████████▌[0m| 25/26 [00:27<00:01,  1.04s/it]Epoch: 2/10. Loss: 1.0423: 100%|[36m██████████[0m| 26/26 [00:27<00:00,  1.09it/s]Epoch: 2/10. Loss: 1.0423: 100%|[36m██████████[0m| 26/26 [00:27<00:00,  1.05s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:04,  1.31it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:05,  1.20s/it] 43%|[33m████▎     [0m| 3/7 [00:03<00:05,  1.30s/it] 57%|[33m█████▋    [0m| 4/7 [00:04<00:03,  1.28s/it] 71%|[33m███████▏  [0m| 5/7 [00:05<00:01,  1.03it/s] 86%|[33m████████▌ [0m| 6/7 [00:06<00:00,  1.08it/s]100%|[33m██████████[0m| 7/7 [00:06<00:00,  1.39it/s]100%|[33m██████████[0m| 7/7 [00:06<00:00,  1.08it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 3/10. Loss: 0.9998:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 3/10. Loss: 0.9998:   4%|[36m▍         [0m| 1/26 [00:00<00:20,  1.21it/s]Epoch: 3/10. Loss: 1.0010:   4%|[36m▍         [0m| 1/26 [00:01<00:20,  1.21it/s]Epoch: 3/10. Loss: 1.0010:   8%|[36m▊         [0m| 2/26 [00:01<00:21,  1.13it/s]Epoch: 3/10. Loss: 1.0360:   8%|[36m▊         [0m| 2/26 [00:02<00:21,  1.13it/s]Epoch: 3/10. Loss: 1.0360:  12%|[36m█▏        [0m| 3/26 [00:02<00:21,  1.05it/s]Epoch: 3/10. Loss: 0.9310:  12%|[36m█▏        [0m| 3/26 [00:03<00:21,  1.05it/s]Epoch: 3/10. Loss: 0.9310:  15%|[36m█▌        [0m| 4/26 [00:03<00:20,  1.10it/s]Epoch: 3/10. Loss: 1.1293:  15%|[36m█▌        [0m| 4/26 [00:04<00:20,  1.10it/s]Epoch: 3/10. Loss: 1.1293:  19%|[36m█▉        [0m| 5/26 [00:04<00:19,  1.10it/s]Epoch: 3/10. Loss: 0.9783:  19%|[36m█▉        [0m| 5/26 [00:05<00:19,  1.10it/s]Epoch: 3/10. Loss: 0.9783:  23%|[36m██▎       [0m| 6/26 [00:05<00:19,  1.04it/s]Epoch: 3/10. Loss: 0.9943:  23%|[36m██▎       [0m| 6/26 [00:06<00:19,  1.04it/s]Epoch: 3/10. Loss: 0.9943:  27%|[36m██▋       [0m| 7/26 [00:06<00:19,  1.01s/it]Epoch: 3/10. Loss: 0.8942:  27%|[36m██▋       [0m| 7/26 [00:07<00:19,  1.01s/it]Epoch: 3/10. Loss: 0.8942:  31%|[36m███       [0m| 8/26 [00:07<00:17,  1.01it/s]Epoch: 3/10. Loss: 1.0261:  31%|[36m███       [0m| 8/26 [00:08<00:17,  1.01it/s]Epoch: 3/10. Loss: 1.0261:  35%|[36m███▍      [0m| 9/26 [00:08<00:15,  1.08it/s]Epoch: 3/10. Loss: 0.9209:  35%|[36m███▍      [0m| 9/26 [00:09<00:15,  1.08it/s]Epoch: 3/10. Loss: 0.9209:  38%|[36m███▊      [0m| 10/26 [00:09<00:14,  1.10it/s]Epoch: 3/10. Loss: 0.9624:  38%|[36m███▊      [0m| 10/26 [00:10<00:14,  1.10it/s]Epoch: 3/10. Loss: 0.9624:  42%|[36m████▏     [0m| 11/26 [00:10<00:14,  1.07it/s]Epoch: 3/10. Loss: 0.9683:  42%|[36m████▏     [0m| 11/26 [00:11<00:14,  1.07it/s]Epoch: 3/10. Loss: 0.9683:  46%|[36m████▌     [0m| 12/26 [00:11<00:12,  1.12it/s]Epoch: 3/10. Loss: 1.0569:  46%|[36m████▌     [0m| 12/26 [00:11<00:12,  1.12it/s]Epoch: 3/10. Loss: 1.0569:  50%|[36m█████     [0m| 13/26 [00:11<00:11,  1.16it/s]Epoch: 3/10. Loss: 0.9667:  50%|[36m█████     [0m| 13/26 [00:12<00:11,  1.16it/s]Epoch: 3/10. Loss: 0.9667:  54%|[36m█████▍    [0m| 14/26 [00:12<00:11,  1.09it/s]Epoch: 3/10. Loss: 0.9431:  54%|[36m█████▍    [0m| 14/26 [00:13<00:11,  1.09it/s]Epoch: 3/10. Loss: 0.9431:  58%|[36m█████▊    [0m| 15/26 [00:13<00:10,  1.08it/s]Epoch: 3/10. Loss: 0.9272:  58%|[36m█████▊    [0m| 15/26 [00:14<00:10,  1.08it/s]Epoch: 3/10. Loss: 0.9272:  62%|[36m██████▏   [0m| 16/26 [00:14<00:09,  1.06it/s]Epoch: 3/10. Loss: 1.0229:  62%|[36m██████▏   [0m| 16/26 [00:15<00:09,  1.06it/s]Epoch: 3/10. Loss: 1.0229:  65%|[36m██████▌   [0m| 17/26 [00:15<00:08,  1.06it/s]Epoch: 3/10. Loss: 0.9582:  65%|[36m██████▌   [0m| 17/26 [00:16<00:08,  1.06it/s]Epoch: 3/10. Loss: 0.9582:  69%|[36m██████▉   [0m| 18/26 [00:16<00:07,  1.09it/s]Epoch: 3/10. Loss: 0.9765:  69%|[36m██████▉   [0m| 18/26 [00:17<00:07,  1.09it/s]Epoch: 3/10. Loss: 0.9765:  73%|[36m███████▎  [0m| 19/26 [00:17<00:06,  1.06it/s]Epoch: 3/10. Loss: 0.9297:  73%|[36m███████▎  [0m| 19/26 [00:18<00:06,  1.06it/s]Epoch: 3/10. Loss: 0.9297:  77%|[36m███████▋  [0m| 20/26 [00:18<00:05,  1.07it/s]Epoch: 3/10. Loss: 0.9612:  77%|[36m███████▋  [0m| 20/26 [00:19<00:05,  1.07it/s]Epoch: 3/10. Loss: 0.9612:  81%|[36m████████  [0m| 21/26 [00:19<00:04,  1.11it/s]Epoch: 3/10. Loss: 0.9647:  81%|[36m████████  [0m| 21/26 [00:20<00:04,  1.11it/s]Epoch: 3/10. Loss: 0.9647:  85%|[36m████████▍ [0m| 22/26 [00:20<00:03,  1.11it/s]Epoch: 3/10. Loss: 1.0238:  85%|[36m████████▍ [0m| 22/26 [00:21<00:03,  1.11it/s]Epoch: 3/10. Loss: 1.0238:  88%|[36m████████▊ [0m| 23/26 [00:21<00:02,  1.07it/s]Epoch: 3/10. Loss: 0.9328:  88%|[36m████████▊ [0m| 23/26 [00:22<00:02,  1.07it/s]Epoch: 3/10. Loss: 0.9328:  92%|[36m█████████▏[0m| 24/26 [00:22<00:01,  1.03it/s]Epoch: 3/10. Loss: 0.9832:  92%|[36m█████████▏[0m| 24/26 [00:23<00:01,  1.03it/s]Epoch: 3/10. Loss: 0.9832:  96%|[36m█████████▌[0m| 25/26 [00:23<00:00,  1.01it/s]Epoch: 3/10. Loss: 1.0067:  96%|[36m█████████▌[0m| 25/26 [00:24<00:00,  1.01it/s]Epoch: 3/10. Loss: 1.0067: 100%|[36m██████████[0m| 26/26 [00:24<00:00,  1.14it/s]Epoch: 3/10. Loss: 1.0067: 100%|[36m██████████[0m| 26/26 [00:24<00:00,  1.08it/s]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:04,  1.25it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:07,  1.47s/it] 43%|[33m████▎     [0m| 3/7 [00:03<00:04,  1.14s/it] 57%|[33m█████▋    [0m| 4/7 [00:04<00:03,  1.19s/it] 71%|[33m███████▏  [0m| 5/7 [00:05<00:01,  1.10it/s] 86%|[33m████████▌ [0m| 6/7 [00:06<00:00,  1.12it/s]100%|[33m██████████[0m| 7/7 [00:06<00:00,  1.43it/s]100%|[33m██████████[0m| 7/7 [00:06<00:00,  1.11it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 4/10. Loss: 0.9595:   0%|[36m          [0m| 0/26 [00:01<?, ?it/s]Epoch: 4/10. Loss: 0.9595:   4%|[36m▍         [0m| 1/26 [00:01<00:39,  1.58s/it]Epoch: 4/10. Loss: 0.9220:   4%|[36m▍         [0m| 1/26 [00:02<00:39,  1.58s/it]Epoch: 4/10. Loss: 0.9220:   8%|[36m▊         [0m| 2/26 [00:02<00:30,  1.25s/it]Epoch: 4/10. Loss: 1.0030:   8%|[36m▊         [0m| 2/26 [00:03<00:30,  1.25s/it]Epoch: 4/10. Loss: 1.0030:  12%|[36m█▏        [0m| 3/26 [00:03<00:27,  1.18s/it]Epoch: 4/10. Loss: 0.9763:  12%|[36m█▏        [0m| 3/26 [00:04<00:27,  1.18s/it]Epoch: 4/10. Loss: 0.9763:  15%|[36m█▌        [0m| 4/26 [00:04<00:25,  1.15s/it]Epoch: 4/10. Loss: 0.9766:  15%|[36m█▌        [0m| 4/26 [00:05<00:25,  1.15s/it]Epoch: 4/10. Loss: 0.9766:  19%|[36m█▉        [0m| 5/26 [00:05<00:23,  1.10s/it]Epoch: 4/10. Loss: 0.9536:  19%|[36m█▉        [0m| 5/26 [00:06<00:23,  1.10s/it]Epoch: 4/10. Loss: 0.9536:  23%|[36m██▎       [0m| 6/26 [00:06<00:21,  1.09s/it]Epoch: 4/10. Loss: 0.9447:  23%|[36m██▎       [0m| 6/26 [00:07<00:21,  1.09s/it]Epoch: 4/10. Loss: 0.9447:  27%|[36m██▋       [0m| 7/26 [00:07<00:20,  1.08s/it]Epoch: 4/10. Loss: 0.9707:  27%|[36m██▋       [0m| 7/26 [00:09<00:20,  1.08s/it]Epoch: 4/10. Loss: 0.9707:  31%|[36m███       [0m| 8/26 [00:09<00:19,  1.10s/it]Epoch: 4/10. Loss: 0.9330:  31%|[36m███       [0m| 8/26 [00:09<00:19,  1.10s/it]Epoch: 4/10. Loss: 0.9330:  35%|[36m███▍      [0m| 9/26 [00:09<00:17,  1.03s/it]Epoch: 4/10. Loss: 0.9561:  35%|[36m███▍      [0m| 9/26 [00:10<00:17,  1.03s/it]Epoch: 4/10. Loss: 0.9561:  38%|[36m███▊      [0m| 10/26 [00:10<00:16,  1.03s/it]Epoch: 4/10. Loss: 0.9448:  38%|[36m███▊      [0m| 10/26 [00:11<00:16,  1.03s/it]Epoch: 4/10. Loss: 0.9448:  42%|[36m████▏     [0m| 11/26 [00:11<00:14,  1.04it/s]Epoch: 4/10. Loss: 1.0964:  42%|[36m████▏     [0m| 11/26 [00:12<00:14,  1.04it/s]Epoch: 4/10. Loss: 1.0964:  46%|[36m████▌     [0m| 12/26 [00:12<00:13,  1.05it/s]Epoch: 4/10. Loss: 0.8819:  46%|[36m████▌     [0m| 12/26 [00:13<00:13,  1.05it/s]Epoch: 4/10. Loss: 0.8819:  50%|[36m█████     [0m| 13/26 [00:13<00:12,  1.06it/s]Epoch: 4/10. Loss: 1.0037:  50%|[36m█████     [0m| 13/26 [00:14<00:12,  1.06it/s]Epoch: 4/10. Loss: 1.0037:  54%|[36m█████▍    [0m| 14/26 [00:14<00:10,  1.11it/s]Epoch: 4/10. Loss: 0.9720:  54%|[36m█████▍    [0m| 14/26 [00:15<00:10,  1.11it/s]Epoch: 4/10. Loss: 0.9720:  58%|[36m█████▊    [0m| 15/26 [00:15<00:10,  1.09it/s]Epoch: 4/10. Loss: 0.9650:  58%|[36m█████▊    [0m| 15/26 [00:16<00:10,  1.09it/s]Epoch: 4/10. Loss: 0.9650:  62%|[36m██████▏   [0m| 16/26 [00:16<00:09,  1.05it/s]Epoch: 4/10. Loss: 0.9802:  62%|[36m██████▏   [0m| 16/26 [00:17<00:09,  1.05it/s]Epoch: 4/10. Loss: 0.9802:  65%|[36m██████▌   [0m| 17/26 [00:17<00:08,  1.05it/s]Epoch: 4/10. Loss: 0.8954:  65%|[36m██████▌   [0m| 17/26 [00:18<00:08,  1.05it/s]Epoch: 4/10. Loss: 0.8954:  69%|[36m██████▉   [0m| 18/26 [00:18<00:07,  1.05it/s]Epoch: 4/10. Loss: 1.0118:  69%|[36m██████▉   [0m| 18/26 [00:19<00:07,  1.05it/s]Epoch: 4/10. Loss: 1.0118:  73%|[36m███████▎  [0m| 19/26 [00:19<00:06,  1.12it/s]Epoch: 4/10. Loss: 0.8770:  73%|[36m███████▎  [0m| 19/26 [00:19<00:06,  1.12it/s]Epoch: 4/10. Loss: 0.8770:  77%|[36m███████▋  [0m| 20/26 [00:20<00:05,  1.12it/s]Epoch: 4/10. Loss: 0.9114:  77%|[36m███████▋  [0m| 20/26 [00:20<00:05,  1.12it/s]Epoch: 4/10. Loss: 0.9114:  81%|[36m████████  [0m| 21/26 [00:20<00:04,  1.11it/s]Epoch: 4/10. Loss: 0.9039:  81%|[36m████████  [0m| 21/26 [00:21<00:04,  1.11it/s]Epoch: 4/10. Loss: 0.9039:  85%|[36m████████▍ [0m| 22/26 [00:21<00:03,  1.14it/s]Epoch: 4/10. Loss: 0.8435:  85%|[36m████████▍ [0m| 22/26 [00:22<00:03,  1.14it/s]Epoch: 4/10. Loss: 0.8435:  88%|[36m████████▊ [0m| 23/26 [00:22<00:02,  1.17it/s]Epoch: 4/10. Loss: 0.8971:  88%|[36m████████▊ [0m| 23/26 [00:23<00:02,  1.17it/s]Epoch: 4/10. Loss: 0.8971:  92%|[36m█████████▏[0m| 24/26 [00:23<00:01,  1.11it/s]Epoch: 4/10. Loss: 0.9471:  92%|[36m█████████▏[0m| 24/26 [00:24<00:01,  1.11it/s]Epoch: 4/10. Loss: 0.9471:  96%|[36m█████████▌[0m| 25/26 [00:24<00:00,  1.13it/s]Epoch: 4/10. Loss: 0.9543:  96%|[36m█████████▌[0m| 25/26 [00:25<00:00,  1.13it/s]Epoch: 4/10. Loss: 0.9543: 100%|[36m██████████[0m| 26/26 [00:25<00:00,  1.22it/s]Epoch: 4/10. Loss: 0.9543: 100%|[36m██████████[0m| 26/26 [00:25<00:00,  1.04it/s]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:04,  1.24it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:05,  1.18s/it] 43%|[33m████▎     [0m| 3/7 [00:02<00:03,  1.02it/s] 57%|[33m█████▋    [0m| 4/7 [00:04<00:03,  1.10s/it] 71%|[33m███████▏  [0m| 5/7 [00:04<00:01,  1.16it/s] 86%|[33m████████▌ [0m| 6/7 [00:07<00:01,  1.42s/it]100%|[33m██████████[0m| 7/7 [00:07<00:00,  1.13s/it]100%|[33m██████████[0m| 7/7 [00:07<00:00,  1.11s/it]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 5/10. Loss: 0.8948:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 5/10. Loss: 0.8948:   4%|[36m▍         [0m| 1/26 [00:00<00:24,  1.03it/s]Epoch: 5/10. Loss: 0.9229:   4%|[36m▍         [0m| 1/26 [00:01<00:24,  1.03it/s]Epoch: 5/10. Loss: 0.9229:   8%|[36m▊         [0m| 2/26 [00:01<00:22,  1.09it/s]Epoch: 5/10. Loss: 0.9168:   8%|[36m▊         [0m| 2/26 [00:02<00:22,  1.09it/s]Epoch: 5/10. Loss: 0.9168:  12%|[36m█▏        [0m| 3/26 [00:02<00:22,  1.04it/s]Epoch: 5/10. Loss: 0.9041:  12%|[36m█▏        [0m| 3/26 [00:03<00:22,  1.04it/s]Epoch: 5/10. Loss: 0.9041:  15%|[36m█▌        [0m| 4/26 [00:03<00:20,  1.06it/s]Epoch: 5/10. Loss: 0.9575:  15%|[36m█▌        [0m| 4/26 [00:04<00:20,  1.06it/s]Epoch: 5/10. Loss: 0.9575:  19%|[36m█▉        [0m| 5/26 [00:04<00:20,  1.03it/s]Epoch: 5/10. Loss: 0.9064:  19%|[36m█▉        [0m| 5/26 [00:05<00:20,  1.03it/s]Epoch: 5/10. Loss: 0.9064:  23%|[36m██▎       [0m| 6/26 [00:05<00:18,  1.06it/s]Epoch: 5/10. Loss: 0.7968:  23%|[36m██▎       [0m| 6/26 [00:07<00:18,  1.06it/s]Epoch: 5/10. Loss: 0.7968:  27%|[36m██▋       [0m| 7/26 [00:07<00:20,  1.08s/it]Epoch: 5/10. Loss: 0.9720:  27%|[36m██▋       [0m| 7/26 [00:07<00:20,  1.08s/it]Epoch: 5/10. Loss: 0.9720:  31%|[36m███       [0m| 8/26 [00:07<00:17,  1.01it/s]Epoch: 5/10. Loss: 0.8875:  31%|[36m███       [0m| 8/26 [00:08<00:17,  1.01it/s]Epoch: 5/10. Loss: 0.8875:  35%|[36m███▍      [0m| 9/26 [00:08<00:15,  1.07it/s]Epoch: 5/10. Loss: 0.8572:  35%|[36m███▍      [0m| 9/26 [00:09<00:15,  1.07it/s]Epoch: 5/10. Loss: 0.8572:  38%|[36m███▊      [0m| 10/26 [00:09<00:16,  1.01s/it]Epoch: 5/10. Loss: 0.8938:  38%|[36m███▊      [0m| 10/26 [00:10<00:16,  1.01s/it]Epoch: 5/10. Loss: 0.8938:  42%|[36m████▏     [0m| 11/26 [00:10<00:13,  1.08it/s]Epoch: 5/10. Loss: 0.8916:  42%|[36m████▏     [0m| 11/26 [00:11<00:13,  1.08it/s]Epoch: 5/10. Loss: 0.8916:  46%|[36m████▌     [0m| 12/26 [00:11<00:12,  1.08it/s]Epoch: 5/10. Loss: 0.9514:  46%|[36m████▌     [0m| 12/26 [00:12<00:12,  1.08it/s]Epoch: 5/10. Loss: 0.9514:  50%|[36m█████     [0m| 13/26 [00:12<00:11,  1.10it/s]Epoch: 5/10. Loss: 0.9340:  50%|[36m█████     [0m| 13/26 [00:13<00:11,  1.10it/s]Epoch: 5/10. Loss: 0.9340:  54%|[36m█████▍    [0m| 14/26 [00:13<00:11,  1.03it/s]Epoch: 5/10. Loss: 0.8271:  54%|[36m█████▍    [0m| 14/26 [00:14<00:11,  1.03it/s]Epoch: 5/10. Loss: 0.8271:  58%|[36m█████▊    [0m| 15/26 [00:14<00:10,  1.01it/s]Epoch: 5/10. Loss: 0.9385:  58%|[36m█████▊    [0m| 15/26 [00:16<00:10,  1.01it/s]Epoch: 5/10. Loss: 0.9385:  62%|[36m██████▏   [0m| 16/26 [00:16<00:14,  1.43s/it]Epoch: 5/10. Loss: 0.9131:  62%|[36m██████▏   [0m| 16/26 [00:18<00:14,  1.43s/it]Epoch: 5/10. Loss: 0.9131:  65%|[36m██████▌   [0m| 17/26 [00:18<00:12,  1.38s/it]Epoch: 5/10. Loss: 0.9181:  65%|[36m██████▌   [0m| 17/26 [00:19<00:12,  1.38s/it]Epoch: 5/10. Loss: 0.9181:  69%|[36m██████▉   [0m| 18/26 [00:19<00:10,  1.32s/it]Epoch: 5/10. Loss: 0.7571:  69%|[36m██████▉   [0m| 18/26 [00:20<00:10,  1.32s/it]Epoch: 5/10. Loss: 0.7571:  73%|[36m███████▎  [0m| 19/26 [00:20<00:08,  1.20s/it]Epoch: 5/10. Loss: 0.8921:  73%|[36m███████▎  [0m| 19/26 [00:21<00:08,  1.20s/it]Epoch: 5/10. Loss: 0.8921:  77%|[36m███████▋  [0m| 20/26 [00:21<00:06,  1.14s/it]Epoch: 5/10. Loss: 0.9322:  77%|[36m███████▋  [0m| 20/26 [00:22<00:06,  1.14s/it]Epoch: 5/10. Loss: 0.9322:  81%|[36m████████  [0m| 21/26 [00:22<00:05,  1.09s/it]Epoch: 5/10. Loss: 0.8248:  81%|[36m████████  [0m| 21/26 [00:25<00:05,  1.09s/it]Epoch: 5/10. Loss: 0.8248:  85%|[36m████████▍ [0m| 22/26 [00:25<00:06,  1.73s/it]Epoch: 5/10. Loss: 0.9233:  85%|[36m████████▍ [0m| 22/26 [00:26<00:06,  1.73s/it]Epoch: 5/10. Loss: 0.9233:  88%|[36m████████▊ [0m| 23/26 [00:26<00:04,  1.48s/it]Epoch: 5/10. Loss: 0.7848:  88%|[36m████████▊ [0m| 23/26 [00:28<00:04,  1.48s/it]Epoch: 5/10. Loss: 0.7848:  92%|[36m█████████▏[0m| 24/26 [00:28<00:03,  1.78s/it]Epoch: 5/10. Loss: 0.8544:  92%|[36m█████████▏[0m| 24/26 [00:30<00:03,  1.78s/it]Epoch: 5/10. Loss: 0.8544:  96%|[36m█████████▌[0m| 25/26 [00:30<00:01,  1.85s/it]Epoch: 5/10. Loss: 0.7278:  96%|[36m█████████▌[0m| 25/26 [00:31<00:01,  1.85s/it]Epoch: 5/10. Loss: 0.7278: 100%|[36m██████████[0m| 26/26 [00:31<00:00,  1.46s/it]Epoch: 5/10. Loss: 0.7278: 100%|[36m██████████[0m| 26/26 [00:31<00:00,  1.21s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:01<00:07,  1.24s/it] 29%|[33m██▊       [0m| 2/7 [00:02<00:07,  1.54s/it] 43%|[33m████▎     [0m| 3/7 [00:03<00:04,  1.17s/it] 57%|[33m█████▋    [0m| 4/7 [00:05<00:03,  1.21s/it] 71%|[33m███████▏  [0m| 5/7 [00:05<00:01,  1.07it/s] 86%|[33m████████▌ [0m| 6/7 [00:06<00:01,  1.12s/it]100%|[33m██████████[0m| 7/7 [00:07<00:00,  1.17it/s]100%|[33m██████████[0m| 7/7 [00:07<00:00,  1.03s/it]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 6/10. Loss: 0.8092:   0%|[36m          [0m| 0/26 [00:01<?, ?it/s]Epoch: 6/10. Loss: 0.8092:   4%|[36m▍         [0m| 1/26 [00:01<00:25,  1.04s/it]Epoch: 6/10. Loss: 0.8659:   4%|[36m▍         [0m| 1/26 [00:02<00:25,  1.04s/it]Epoch: 6/10. Loss: 0.8659:   8%|[36m▊         [0m| 2/26 [00:02<00:30,  1.25s/it]Epoch: 6/10. Loss: 0.8296:   8%|[36m▊         [0m| 2/26 [00:03<00:30,  1.25s/it]Epoch: 6/10. Loss: 0.8296:  12%|[36m█▏        [0m| 3/26 [00:03<00:27,  1.19s/it]Epoch: 6/10. Loss: 0.7849:  12%|[36m█▏        [0m| 3/26 [00:04<00:27,  1.19s/it]Epoch: 6/10. Loss: 0.7849:  15%|[36m█▌        [0m| 4/26 [00:04<00:23,  1.06s/it]Epoch: 6/10. Loss: 0.8532:  15%|[36m█▌        [0m| 4/26 [00:05<00:23,  1.06s/it]Epoch: 6/10. Loss: 0.8532:  19%|[36m█▉        [0m| 5/26 [00:05<00:19,  1.06it/s]Epoch: 6/10. Loss: 0.7695:  19%|[36m█▉        [0m| 5/26 [00:06<00:19,  1.06it/s]Epoch: 6/10. Loss: 0.7695:  23%|[36m██▎       [0m| 6/26 [00:06<00:18,  1.07it/s]Epoch: 6/10. Loss: 0.8935:  23%|[36m██▎       [0m| 6/26 [00:07<00:18,  1.07it/s]Epoch: 6/10. Loss: 0.8935:  27%|[36m██▋       [0m| 7/26 [00:07<00:19,  1.05s/it]Epoch: 6/10. Loss: 0.8267:  27%|[36m██▋       [0m| 7/26 [00:08<00:19,  1.05s/it]Epoch: 6/10. Loss: 0.8267:  31%|[36m███       [0m| 8/26 [00:08<00:17,  1.01it/s]Epoch: 6/10. Loss: 0.9170:  31%|[36m███       [0m| 8/26 [00:09<00:17,  1.01it/s]Epoch: 6/10. Loss: 0.9170:  35%|[36m███▍      [0m| 9/26 [00:09<00:16,  1.04it/s]Epoch: 6/10. Loss: 0.8176:  35%|[36m███▍      [0m| 9/26 [00:10<00:16,  1.04it/s]Epoch: 6/10. Loss: 0.8176:  38%|[36m███▊      [0m| 10/26 [00:10<00:15,  1.05it/s]Epoch: 6/10. Loss: 0.8363:  38%|[36m███▊      [0m| 10/26 [00:10<00:15,  1.05it/s]Epoch: 6/10. Loss: 0.8363:  42%|[36m████▏     [0m| 11/26 [00:10<00:13,  1.08it/s]Epoch: 6/10. Loss: 0.8625:  42%|[36m████▏     [0m| 11/26 [00:11<00:13,  1.08it/s]Epoch: 6/10. Loss: 0.8625:  46%|[36m████▌     [0m| 12/26 [00:11<00:12,  1.08it/s]Epoch: 6/10. Loss: 0.8000:  46%|[36m████▌     [0m| 12/26 [00:12<00:12,  1.08it/s]Epoch: 6/10. Loss: 0.8000:  50%|[36m█████     [0m| 13/26 [00:12<00:12,  1.06it/s]Epoch: 6/10. Loss: 0.7902:  50%|[36m█████     [0m| 13/26 [00:13<00:12,  1.06it/s]Epoch: 6/10. Loss: 0.7902:  54%|[36m█████▍    [0m| 14/26 [00:13<00:11,  1.08it/s]Epoch: 6/10. Loss: 0.8288:  54%|[36m█████▍    [0m| 14/26 [00:14<00:11,  1.08it/s]Epoch: 6/10. Loss: 0.8288:  58%|[36m█████▊    [0m| 15/26 [00:14<00:10,  1.09it/s]Epoch: 6/10. Loss: 0.9316:  58%|[36m█████▊    [0m| 15/26 [00:15<00:10,  1.09it/s]Epoch: 6/10. Loss: 0.9316:  62%|[36m██████▏   [0m| 16/26 [00:15<00:09,  1.06it/s]Epoch: 6/10. Loss: 0.8196:  62%|[36m██████▏   [0m| 16/26 [00:16<00:09,  1.06it/s]Epoch: 6/10. Loss: 0.8196:  65%|[36m██████▌   [0m| 17/26 [00:16<00:08,  1.05it/s]Epoch: 6/10. Loss: 0.8055:  65%|[36m██████▌   [0m| 17/26 [00:17<00:08,  1.05it/s]Epoch: 6/10. Loss: 0.8055:  69%|[36m██████▉   [0m| 18/26 [00:17<00:07,  1.08it/s]Epoch: 6/10. Loss: 0.8240:  69%|[36m██████▉   [0m| 18/26 [00:18<00:07,  1.08it/s]Epoch: 6/10. Loss: 0.8240:  73%|[36m███████▎  [0m| 19/26 [00:18<00:06,  1.09it/s]Epoch: 6/10. Loss: 0.8555:  73%|[36m███████▎  [0m| 19/26 [00:19<00:06,  1.09it/s]Epoch: 6/10. Loss: 0.8555:  77%|[36m███████▋  [0m| 20/26 [00:19<00:06,  1.02s/it]Epoch: 6/10. Loss: 0.8069:  77%|[36m███████▋  [0m| 20/26 [00:20<00:06,  1.02s/it]Epoch: 6/10. Loss: 0.8069:  81%|[36m████████  [0m| 21/26 [00:20<00:04,  1.02it/s]Epoch: 6/10. Loss: 0.8419:  81%|[36m████████  [0m| 21/26 [00:21<00:04,  1.02it/s]Epoch: 6/10. Loss: 0.8419:  85%|[36m████████▍ [0m| 22/26 [00:21<00:03,  1.04it/s]Epoch: 6/10. Loss: 0.8536:  85%|[36m████████▍ [0m| 22/26 [00:22<00:03,  1.04it/s]Epoch: 6/10. Loss: 0.8536:  88%|[36m████████▊ [0m| 23/26 [00:22<00:02,  1.06it/s]Epoch: 6/10. Loss: 0.7971:  88%|[36m████████▊ [0m| 23/26 [00:23<00:02,  1.06it/s]Epoch: 6/10. Loss: 0.7971:  92%|[36m█████████▏[0m| 24/26 [00:23<00:01,  1.10it/s]Epoch: 6/10. Loss: 0.7995:  92%|[36m█████████▏[0m| 24/26 [00:23<00:01,  1.10it/s]Epoch: 6/10. Loss: 0.7995:  96%|[36m█████████▌[0m| 25/26 [00:23<00:00,  1.13it/s]Epoch: 6/10. Loss: 0.6990:  96%|[36m█████████▌[0m| 25/26 [00:24<00:00,  1.13it/s]Epoch: 6/10. Loss: 0.6990: 100%|[36m██████████[0m| 26/26 [00:24<00:00,  1.12it/s]Epoch: 6/10. Loss: 0.6990: 100%|[36m██████████[0m| 26/26 [00:24<00:00,  1.04it/s]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:05,  1.19it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:06,  1.20s/it] 43%|[33m████▎     [0m| 3/7 [00:03<00:03,  1.01it/s] 57%|[33m█████▋    [0m| 4/7 [00:04<00:03,  1.11s/it] 71%|[33m███████▏  [0m| 5/7 [00:04<00:01,  1.14it/s] 86%|[33m████████▌ [0m| 6/7 [00:05<00:00,  1.10it/s]100%|[33m██████████[0m| 7/7 [00:06<00:00,  1.40it/s]100%|[33m██████████[0m| 7/7 [00:06<00:00,  1.15it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 7/10. Loss: 0.9525:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 7/10. Loss: 0.9525:   4%|[36m▍         [0m| 1/26 [00:00<00:20,  1.22it/s]Epoch: 7/10. Loss: 0.9500:   4%|[36m▍         [0m| 1/26 [00:02<00:20,  1.22it/s]Epoch: 7/10. Loss: 0.9500:   8%|[36m▊         [0m| 2/26 [00:02<00:27,  1.16s/it]Epoch: 7/10. Loss: 0.8798:   8%|[36m▊         [0m| 2/26 [00:03<00:27,  1.16s/it]Epoch: 7/10. Loss: 0.8798:  12%|[36m█▏        [0m| 3/26 [00:03<00:26,  1.14s/it]Epoch: 7/10. Loss: 0.7874:  12%|[36m█▏        [0m| 3/26 [00:04<00:26,  1.14s/it]Epoch: 7/10. Loss: 0.7874:  15%|[36m█▌        [0m| 4/26 [00:04<00:22,  1.02s/it]Epoch: 7/10. Loss: 0.9190:  15%|[36m█▌        [0m| 4/26 [00:05<00:22,  1.02s/it]Epoch: 7/10. Loss: 0.9190:  19%|[36m█▉        [0m| 5/26 [00:05<00:20,  1.01it/s]Epoch: 7/10. Loss: 0.8535:  19%|[36m█▉        [0m| 5/26 [00:05<00:20,  1.01it/s]Epoch: 7/10. Loss: 0.8535:  23%|[36m██▎       [0m| 6/26 [00:05<00:18,  1.05it/s]Epoch: 7/10. Loss: 0.8219:  23%|[36m██▎       [0m| 6/26 [00:07<00:18,  1.05it/s]Epoch: 7/10. Loss: 0.8219:  27%|[36m██▋       [0m| 7/26 [00:07<00:18,  1.01it/s]Epoch: 7/10. Loss: 0.8904:  27%|[36m██▋       [0m| 7/26 [00:08<00:18,  1.01it/s]Epoch: 7/10. Loss: 0.8904:  31%|[36m███       [0m| 8/26 [00:08<00:17,  1.01it/s]Epoch: 7/10. Loss: 0.7802:  31%|[36m███       [0m| 8/26 [00:08<00:17,  1.01it/s]Epoch: 7/10. Loss: 0.7802:  35%|[36m███▍      [0m| 9/26 [00:08<00:15,  1.07it/s]Epoch: 7/10. Loss: 0.8478:  35%|[36m███▍      [0m| 9/26 [00:09<00:15,  1.07it/s]Epoch: 7/10. Loss: 0.8478:  38%|[36m███▊      [0m| 10/26 [00:09<00:15,  1.06it/s]Epoch: 7/10. Loss: 0.9123:  38%|[36m███▊      [0m| 10/26 [00:12<00:15,  1.06it/s]Epoch: 7/10. Loss: 0.9123:  42%|[36m████▏     [0m| 11/26 [00:12<00:21,  1.44s/it]Epoch: 7/10. Loss: 0.8081:  42%|[36m████▏     [0m| 11/26 [00:14<00:21,  1.44s/it]Epoch: 7/10. Loss: 0.8081:  46%|[36m████▌     [0m| 12/26 [00:14<00:24,  1.72s/it]Epoch: 7/10. Loss: 0.9037:  46%|[36m████▌     [0m| 12/26 [00:16<00:24,  1.72s/it]Epoch: 7/10. Loss: 0.9037:  50%|[36m█████     [0m| 13/26 [00:16<00:21,  1.62s/it]Epoch: 7/10. Loss: 0.8364:  50%|[36m█████     [0m| 13/26 [00:16<00:21,  1.62s/it]Epoch: 7/10. Loss: 0.8364:  54%|[36m█████▍    [0m| 14/26 [00:17<00:16,  1.40s/it]Epoch: 7/10. Loss: 0.8849:  54%|[36m█████▍    [0m| 14/26 [00:18<00:16,  1.40s/it]Epoch: 7/10. Loss: 0.8849:  58%|[36m█████▊    [0m| 15/26 [00:18<00:14,  1.30s/it]Epoch: 7/10. Loss: 0.8024:  58%|[36m█████▊    [0m| 15/26 [00:19<00:14,  1.30s/it]Epoch: 7/10. Loss: 0.8024:  62%|[36m██████▏   [0m| 16/26 [00:19<00:12,  1.25s/it]Epoch: 7/10. Loss: 0.8101:  62%|[36m██████▏   [0m| 16/26 [00:19<00:12,  1.25s/it]Epoch: 7/10. Loss: 0.8101:  65%|[36m██████▌   [0m| 17/26 [00:19<00:09,  1.10s/it]Epoch: 7/10. Loss: 0.9303:  65%|[36m██████▌   [0m| 17/26 [00:20<00:09,  1.10s/it]Epoch: 7/10. Loss: 0.9303:  69%|[36m██████▉   [0m| 18/26 [00:20<00:08,  1.04s/it]Epoch: 7/10. Loss: 0.8551:  69%|[36m██████▉   [0m| 18/26 [00:21<00:08,  1.04s/it]Epoch: 7/10. Loss: 0.8551:  73%|[36m███████▎  [0m| 19/26 [00:21<00:07,  1.02s/it]Epoch: 7/10. Loss: 0.8830:  73%|[36m███████▎  [0m| 19/26 [00:22<00:07,  1.02s/it]Epoch: 7/10. Loss: 0.8830:  77%|[36m███████▋  [0m| 20/26 [00:22<00:06,  1.06s/it]Epoch: 7/10. Loss: 0.7474:  77%|[36m███████▋  [0m| 20/26 [00:23<00:06,  1.06s/it]Epoch: 7/10. Loss: 0.7474:  81%|[36m████████  [0m| 21/26 [00:23<00:05,  1.01s/it]Epoch: 7/10. Loss: 0.9318:  81%|[36m████████  [0m| 21/26 [00:24<00:05,  1.01s/it]Epoch: 7/10. Loss: 0.9318:  85%|[36m████████▍ [0m| 22/26 [00:24<00:04,  1.03s/it]Epoch: 7/10. Loss: 0.9849:  85%|[36m████████▍ [0m| 22/26 [00:25<00:04,  1.03s/it]Epoch: 7/10. Loss: 0.9849:  88%|[36m████████▊ [0m| 23/26 [00:25<00:03,  1.03s/it]Epoch: 7/10. Loss: 0.7931:  88%|[36m████████▊ [0m| 23/26 [00:26<00:03,  1.03s/it]Epoch: 7/10. Loss: 0.7931:  92%|[36m█████████▏[0m| 24/26 [00:26<00:01,  1.02it/s]Epoch: 7/10. Loss: 0.8602:  92%|[36m█████████▏[0m| 24/26 [00:27<00:01,  1.02it/s]Epoch: 7/10. Loss: 0.8602:  96%|[36m█████████▌[0m| 25/26 [00:27<00:00,  1.05it/s]Epoch: 7/10. Loss: 0.8847:  96%|[36m█████████▌[0m| 25/26 [00:28<00:00,  1.05it/s]Epoch: 7/10. Loss: 0.8847: 100%|[36m██████████[0m| 26/26 [00:28<00:00,  1.16it/s]Epoch: 7/10. Loss: 0.8847: 100%|[36m██████████[0m| 26/26 [00:28<00:00,  1.09s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:05,  1.19it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:05,  1.19s/it] 43%|[33m████▎     [0m| 3/7 [00:03<00:03,  1.01it/s] 57%|[33m█████▋    [0m| 4/7 [00:04<00:03,  1.13s/it] 71%|[33m███████▏  [0m| 5/7 [00:04<00:01,  1.13it/s] 86%|[33m████████▌ [0m| 6/7 [00:05<00:00,  1.12it/s]100%|[33m██████████[0m| 7/7 [00:06<00:00,  1.41it/s]100%|[33m██████████[0m| 7/7 [00:06<00:00,  1.15it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 8/10. Loss: 0.8487:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 8/10. Loss: 0.8487:   4%|[36m▍         [0m| 1/26 [00:00<00:22,  1.11it/s]Epoch: 8/10. Loss: 0.7575:   4%|[36m▍         [0m| 1/26 [00:03<00:22,  1.11it/s]Epoch: 8/10. Loss: 0.7575:   8%|[36m▊         [0m| 2/26 [00:03<00:43,  1.81s/it]Epoch: 8/10. Loss: 0.8636:   8%|[36m▊         [0m| 2/26 [00:04<00:43,  1.81s/it]Epoch: 8/10. Loss: 0.8636:  12%|[36m█▏        [0m| 3/26 [00:04<00:38,  1.65s/it]Epoch: 8/10. Loss: 0.8971:  12%|[36m█▏        [0m| 3/26 [00:05<00:38,  1.65s/it]Epoch: 8/10. Loss: 0.8971:  15%|[36m█▌        [0m| 4/26 [00:05<00:29,  1.33s/it]Epoch: 8/10. Loss: 0.8358:  15%|[36m█▌        [0m| 4/26 [00:06<00:29,  1.33s/it]Epoch: 8/10. Loss: 0.8358:  19%|[36m█▉        [0m| 5/26 [00:06<00:25,  1.20s/it]Epoch: 8/10. Loss: 0.7659:  19%|[36m█▉        [0m| 5/26 [00:07<00:25,  1.20s/it]Epoch: 8/10. Loss: 0.7659:  23%|[36m██▎       [0m| 6/26 [00:07<00:22,  1.14s/it]Epoch: 8/10. Loss: 0.8363:  23%|[36m██▎       [0m| 6/26 [00:08<00:22,  1.14s/it]Epoch: 8/10. Loss: 0.8363:  27%|[36m██▋       [0m| 7/26 [00:08<00:20,  1.09s/it]Epoch: 8/10. Loss: 0.7662:  27%|[36m██▋       [0m| 7/26 [00:09<00:20,  1.09s/it]Epoch: 8/10. Loss: 0.7662:  31%|[36m███       [0m| 8/26 [00:09<00:20,  1.16s/it]Epoch: 8/10. Loss: 0.7800:  31%|[36m███       [0m| 8/26 [00:10<00:20,  1.16s/it]Epoch: 8/10. Loss: 0.7800:  35%|[36m███▍      [0m| 9/26 [00:10<00:17,  1.04s/it]Epoch: 8/10. Loss: 0.7151:  35%|[36m███▍      [0m| 9/26 [00:11<00:17,  1.04s/it]Epoch: 8/10. Loss: 0.7151:  38%|[36m███▊      [0m| 10/26 [00:11<00:16,  1.02s/it]Epoch: 8/10. Loss: 0.8644:  38%|[36m███▊      [0m| 10/26 [00:12<00:16,  1.02s/it]Epoch: 8/10. Loss: 0.8644:  42%|[36m████▏     [0m| 11/26 [00:12<00:14,  1.05it/s]Epoch: 8/10. Loss: 1.0154:  42%|[36m████▏     [0m| 11/26 [00:13<00:14,  1.05it/s]Epoch: 8/10. Loss: 1.0154:  46%|[36m████▌     [0m| 12/26 [00:13<00:13,  1.07it/s]Epoch: 8/10. Loss: 0.9188:  46%|[36m████▌     [0m| 12/26 [00:14<00:13,  1.07it/s]Epoch: 8/10. Loss: 0.9188:  50%|[36m█████     [0m| 13/26 [00:14<00:11,  1.09it/s]Epoch: 8/10. Loss: 0.7998:  50%|[36m█████     [0m| 13/26 [00:15<00:11,  1.09it/s]Epoch: 8/10. Loss: 0.7998:  54%|[36m█████▍    [0m| 14/26 [00:15<00:11,  1.07it/s]Epoch: 8/10. Loss: 0.8690:  54%|[36m█████▍    [0m| 14/26 [00:16<00:11,  1.07it/s]Epoch: 8/10. Loss: 0.8690:  58%|[36m█████▊    [0m| 15/26 [00:16<00:10,  1.05it/s]Epoch: 8/10. Loss: 0.8554:  58%|[36m█████▊    [0m| 15/26 [00:17<00:10,  1.05it/s]Epoch: 8/10. Loss: 0.8554:  62%|[36m██████▏   [0m| 16/26 [00:17<00:09,  1.03it/s]Epoch: 8/10. Loss: 0.8625:  62%|[36m██████▏   [0m| 16/26 [00:18<00:09,  1.03it/s]Epoch: 8/10. Loss: 0.8625:  65%|[36m██████▌   [0m| 17/26 [00:18<00:09,  1.02s/it]Epoch: 8/10. Loss: 0.7966:  65%|[36m██████▌   [0m| 17/26 [00:19<00:09,  1.02s/it]Epoch: 8/10. Loss: 0.7966:  69%|[36m██████▉   [0m| 18/26 [00:19<00:07,  1.03it/s]Epoch: 8/10. Loss: 0.8506:  69%|[36m██████▉   [0m| 18/26 [00:20<00:07,  1.03it/s]Epoch: 8/10. Loss: 0.8506:  73%|[36m███████▎  [0m| 19/26 [00:20<00:06,  1.06it/s]Epoch: 8/10. Loss: 0.9245:  73%|[36m███████▎  [0m| 19/26 [00:21<00:06,  1.06it/s]Epoch: 8/10. Loss: 0.9245:  77%|[36m███████▋  [0m| 20/26 [00:21<00:05,  1.06it/s]Epoch: 8/10. Loss: 0.7968:  77%|[36m███████▋  [0m| 20/26 [00:21<00:05,  1.06it/s]Epoch: 8/10. Loss: 0.7968:  81%|[36m████████  [0m| 21/26 [00:21<00:04,  1.09it/s]Epoch: 8/10. Loss: 0.8245:  81%|[36m████████  [0m| 21/26 [00:22<00:04,  1.09it/s]Epoch: 8/10. Loss: 0.8245:  85%|[36m████████▍ [0m| 22/26 [00:22<00:03,  1.10it/s]Epoch: 8/10. Loss: 0.8668:  85%|[36m████████▍ [0m| 22/26 [00:23<00:03,  1.10it/s]Epoch: 8/10. Loss: 0.8668:  88%|[36m████████▊ [0m| 23/26 [00:23<00:02,  1.12it/s]Epoch: 8/10. Loss: 0.8152:  88%|[36m████████▊ [0m| 23/26 [00:24<00:02,  1.12it/s]Epoch: 8/10. Loss: 0.8152:  92%|[36m█████████▏[0m| 24/26 [00:24<00:01,  1.10it/s]Epoch: 8/10. Loss: 0.8755:  92%|[36m█████████▏[0m| 24/26 [00:25<00:01,  1.10it/s]Epoch: 8/10. Loss: 0.8755:  96%|[36m█████████▌[0m| 25/26 [00:25<00:00,  1.06it/s]Epoch: 8/10. Loss: 0.8169:  96%|[36m█████████▌[0m| 25/26 [00:26<00:00,  1.06it/s]Epoch: 8/10. Loss: 0.8169: 100%|[36m██████████[0m| 26/26 [00:26<00:00,  1.02s/it]Epoch: 8/10. Loss: 0.8169: 100%|[36m██████████[0m| 26/26 [00:26<00:00,  1.03s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:01<00:07,  1.31s/it] 29%|[33m██▊       [0m| 2/7 [00:02<00:06,  1.39s/it] 43%|[33m████▎     [0m| 3/7 [00:03<00:04,  1.09s/it] 57%|[33m█████▋    [0m| 4/7 [00:05<00:03,  1.29s/it] 71%|[33m███████▏  [0m| 5/7 [00:05<00:01,  1.01it/s] 86%|[33m████████▌ [0m| 6/7 [00:07<00:01,  1.47s/it]100%|[33m██████████[0m| 7/7 [00:08<00:00,  1.28s/it]100%|[33m██████████[0m| 7/7 [00:08<00:00,  1.26s/it]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 9/10. Loss: 0.7666:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 9/10. Loss: 0.7666:   4%|[36m▍         [0m| 1/26 [00:00<00:23,  1.07it/s]Epoch: 9/10. Loss: 0.8675:   4%|[36m▍         [0m| 1/26 [00:02<00:23,  1.07it/s]Epoch: 9/10. Loss: 0.8675:   8%|[36m▊         [0m| 2/26 [00:02<00:24,  1.04s/it]Epoch: 9/10. Loss: 0.6294:   8%|[36m▊         [0m| 2/26 [00:03<00:24,  1.04s/it]Epoch: 9/10. Loss: 0.6294:  12%|[36m█▏        [0m| 3/26 [00:03<00:25,  1.10s/it]Epoch: 9/10. Loss: 0.7063:  12%|[36m█▏        [0m| 3/26 [00:04<00:25,  1.10s/it]Epoch: 9/10. Loss: 0.7063:  15%|[36m█▌        [0m| 4/26 [00:04<00:22,  1.02s/it]Epoch: 9/10. Loss: 0.8356:  15%|[36m█▌        [0m| 4/26 [00:05<00:22,  1.02s/it]Epoch: 9/10. Loss: 0.8356:  19%|[36m█▉        [0m| 5/26 [00:05<00:20,  1.00it/s]Epoch: 9/10. Loss: 0.8443:  19%|[36m█▉        [0m| 5/26 [00:05<00:20,  1.00it/s]Epoch: 9/10. Loss: 0.8443:  23%|[36m██▎       [0m| 6/26 [00:05<00:18,  1.06it/s]Epoch: 9/10. Loss: 0.8263:  23%|[36m██▎       [0m| 6/26 [00:06<00:18,  1.06it/s]Epoch: 9/10. Loss: 0.8263:  27%|[36m██▋       [0m| 7/26 [00:06<00:17,  1.09it/s]Epoch: 9/10. Loss: 0.7378:  27%|[36m██▋       [0m| 7/26 [00:09<00:17,  1.09it/s]Epoch: 9/10. Loss: 0.7378:  31%|[36m███       [0m| 8/26 [00:09<00:25,  1.39s/it]Epoch: 9/10. Loss: 0.7654:  31%|[36m███       [0m| 8/26 [00:10<00:25,  1.39s/it]Epoch: 9/10. Loss: 0.7654:  35%|[36m███▍      [0m| 9/26 [00:10<00:22,  1.34s/it]Epoch: 9/10. Loss: 0.8099:  35%|[36m███▍      [0m| 9/26 [00:11<00:22,  1.34s/it]Epoch: 9/10. Loss: 0.8099:  38%|[36m███▊      [0m| 10/26 [00:11<00:19,  1.23s/it]Epoch: 9/10. Loss: 0.8360:  38%|[36m███▊      [0m| 10/26 [00:12<00:19,  1.23s/it]Epoch: 9/10. Loss: 0.8360:  42%|[36m████▏     [0m| 11/26 [00:12<00:17,  1.14s/it]Epoch: 9/10. Loss: 0.7668:  42%|[36m████▏     [0m| 11/26 [00:13<00:17,  1.14s/it]Epoch: 9/10. Loss: 0.7668:  46%|[36m████▌     [0m| 12/26 [00:13<00:14,  1.07s/it]Epoch: 9/10. Loss: 0.7998:  46%|[36m████▌     [0m| 12/26 [00:14<00:14,  1.07s/it]Epoch: 9/10. Loss: 0.7998:  50%|[36m█████     [0m| 13/26 [00:14<00:15,  1.17s/it]Epoch: 9/10. Loss: 0.8035:  50%|[36m█████     [0m| 13/26 [00:15<00:15,  1.17s/it]Epoch: 9/10. Loss: 0.8035:  54%|[36m█████▍    [0m| 14/26 [00:15<00:12,  1.07s/it]Epoch: 9/10. Loss: 0.8773:  54%|[36m█████▍    [0m| 14/26 [00:16<00:12,  1.07s/it]Epoch: 9/10. Loss: 0.8773:  58%|[36m█████▊    [0m| 15/26 [00:16<00:12,  1.18s/it]Epoch: 9/10. Loss: 0.8307:  58%|[36m█████▊    [0m| 15/26 [00:18<00:12,  1.18s/it]Epoch: 9/10. Loss: 0.8307:  62%|[36m██████▏   [0m| 16/26 [00:18<00:12,  1.29s/it]Epoch: 9/10. Loss: 0.7233:  62%|[36m██████▏   [0m| 16/26 [00:19<00:12,  1.29s/it]Epoch: 9/10. Loss: 0.7233:  65%|[36m██████▌   [0m| 17/26 [00:19<00:10,  1.16s/it]Epoch: 9/10. Loss: 0.7133:  65%|[36m██████▌   [0m| 17/26 [00:20<00:10,  1.16s/it]Epoch: 9/10. Loss: 0.7133:  69%|[36m██████▉   [0m| 18/26 [00:20<00:08,  1.09s/it]Epoch: 9/10. Loss: 0.6783:  69%|[36m██████▉   [0m| 18/26 [00:21<00:08,  1.09s/it]Epoch: 9/10. Loss: 0.6783:  73%|[36m███████▎  [0m| 19/26 [00:21<00:07,  1.06s/it]Epoch: 9/10. Loss: 0.7503:  73%|[36m███████▎  [0m| 19/26 [00:22<00:07,  1.06s/it]Epoch: 9/10. Loss: 0.7503:  77%|[36m███████▋  [0m| 20/26 [00:22<00:06,  1.00s/it]Epoch: 9/10. Loss: 0.6318:  77%|[36m███████▋  [0m| 20/26 [00:22<00:06,  1.00s/it]Epoch: 9/10. Loss: 0.6318:  81%|[36m████████  [0m| 21/26 [00:22<00:04,  1.03it/s]Epoch: 9/10. Loss: 0.7747:  81%|[36m████████  [0m| 21/26 [00:23<00:04,  1.03it/s]Epoch: 9/10. Loss: 0.7747:  85%|[36m████████▍ [0m| 22/26 [00:23<00:03,  1.08it/s]Epoch: 9/10. Loss: 0.7999:  85%|[36m████████▍ [0m| 22/26 [00:24<00:03,  1.08it/s]Epoch: 9/10. Loss: 0.7999:  88%|[36m████████▊ [0m| 23/26 [00:24<00:02,  1.04it/s]Epoch: 9/10. Loss: 0.7226:  88%|[36m████████▊ [0m| 23/26 [00:25<00:02,  1.04it/s]Epoch: 9/10. Loss: 0.7226:  92%|[36m█████████▏[0m| 24/26 [00:25<00:01,  1.01it/s]Epoch: 9/10. Loss: 0.8533:  92%|[36m█████████▏[0m| 24/26 [00:26<00:01,  1.01it/s]Epoch: 9/10. Loss: 0.8533:  96%|[36m█████████▌[0m| 25/26 [00:26<00:00,  1.04it/s]Epoch: 9/10. Loss: 0.9005:  96%|[36m█████████▌[0m| 25/26 [00:27<00:00,  1.04it/s]Epoch: 9/10. Loss: 0.9005: 100%|[36m██████████[0m| 26/26 [00:27<00:00,  1.14it/s]Epoch: 9/10. Loss: 0.9005: 100%|[36m██████████[0m| 26/26 [00:27<00:00,  1.06s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:04,  1.29it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:05,  1.12s/it] 43%|[33m████▎     [0m| 3/7 [00:02<00:03,  1.12it/s] 57%|[33m█████▋    [0m| 4/7 [00:03<00:03,  1.00s/it] 71%|[33m███████▏  [0m| 5/7 [00:04<00:01,  1.28it/s] 86%|[33m████████▌ [0m| 6/7 [00:05<00:00,  1.23it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.54it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.27it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 0/10. Loss: 1.0580:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 0/10. Loss: 1.0580:   4%|[36m▍         [0m| 1/26 [00:00<00:19,  1.27it/s]Epoch: 0/10. Loss: 15.3222:   4%|[36m▍         [0m| 1/26 [00:01<00:19,  1.27it/s]Epoch: 0/10. Loss: 15.3222:   8%|[36m▊         [0m| 2/26 [00:01<00:19,  1.23it/s]Epoch: 0/10. Loss: 6.6713:   8%|[36m▊         [0m| 2/26 [00:02<00:19,  1.23it/s] Epoch: 0/10. Loss: 6.6713:  12%|[36m█▏        [0m| 3/26 [00:02<00:19,  1.15it/s]Epoch: 0/10. Loss: 2.2262:  12%|[36m█▏        [0m| 3/26 [00:03<00:19,  1.15it/s]Epoch: 0/10. Loss: 2.2262:  15%|[36m█▌        [0m| 4/26 [00:03<00:19,  1.12it/s]Epoch: 0/10. Loss: 2.1142:  15%|[36m█▌        [0m| 4/26 [00:04<00:19,  1.12it/s]Epoch: 0/10. Loss: 2.1142:  19%|[36m█▉        [0m| 5/26 [00:04<00:18,  1.15it/s]Epoch: 0/10. Loss: 3.2251:  19%|[36m█▉        [0m| 5/26 [00:05<00:18,  1.15it/s]Epoch: 0/10. Loss: 3.2251:  23%|[36m██▎       [0m| 6/26 [00:05<00:18,  1.07it/s]Epoch: 0/10. Loss: 1.8673:  23%|[36m██▎       [0m| 6/26 [00:06<00:18,  1.07it/s]Epoch: 0/10. Loss: 1.8673:  27%|[36m██▋       [0m| 7/26 [00:06<00:17,  1.11it/s]Epoch: 0/10. Loss: 1.2485:  27%|[36m██▋       [0m| 7/26 [00:07<00:17,  1.11it/s]Epoch: 0/10. Loss: 1.2485:  31%|[36m███       [0m| 8/26 [00:07<00:15,  1.14it/s]Epoch: 0/10. Loss: 1.7274:  31%|[36m███       [0m| 8/26 [00:07<00:15,  1.14it/s]Epoch: 0/10. Loss: 1.7274:  35%|[36m███▍      [0m| 9/26 [00:07<00:14,  1.21it/s]Epoch: 0/10. Loss: 1.6545:  35%|[36m███▍      [0m| 9/26 [00:08<00:14,  1.21it/s]Epoch: 0/10. Loss: 1.6545:  38%|[36m███▊      [0m| 10/26 [00:08<00:13,  1.15it/s]Epoch: 0/10. Loss: 1.0833:  38%|[36m███▊      [0m| 10/26 [00:09<00:13,  1.15it/s]Epoch: 0/10. Loss: 1.0833:  42%|[36m████▏     [0m| 11/26 [00:09<00:13,  1.15it/s]Epoch: 0/10. Loss: 1.0682:  42%|[36m████▏     [0m| 11/26 [00:10<00:13,  1.15it/s]Epoch: 0/10. Loss: 1.0682:  46%|[36m████▌     [0m| 12/26 [00:10<00:12,  1.15it/s]Epoch: 0/10. Loss: 1.3656:  46%|[36m████▌     [0m| 12/26 [00:11<00:12,  1.15it/s]Epoch: 0/10. Loss: 1.3656:  50%|[36m█████     [0m| 13/26 [00:11<00:12,  1.07it/s]Epoch: 0/10. Loss: 1.0492:  50%|[36m█████     [0m| 13/26 [00:12<00:12,  1.07it/s]Epoch: 0/10. Loss: 1.0492:  54%|[36m█████▍    [0m| 14/26 [00:12<00:10,  1.13it/s]Epoch: 0/10. Loss: 2.3068:  54%|[36m█████▍    [0m| 14/26 [00:13<00:10,  1.13it/s]Epoch: 0/10. Loss: 2.3068:  58%|[36m█████▊    [0m| 15/26 [00:13<00:10,  1.08it/s]Epoch: 0/10. Loss: 1.4579:  58%|[36m█████▊    [0m| 15/26 [00:14<00:10,  1.08it/s]Epoch: 0/10. Loss: 1.4579:  62%|[36m██████▏   [0m| 16/26 [00:14<00:09,  1.08it/s]Epoch: 0/10. Loss: 1.4442:  62%|[36m██████▏   [0m| 16/26 [00:15<00:09,  1.08it/s]Epoch: 0/10. Loss: 1.4442:  65%|[36m██████▌   [0m| 17/26 [00:15<00:08,  1.12it/s]Epoch: 0/10. Loss: 1.0300:  65%|[36m██████▌   [0m| 17/26 [00:16<00:08,  1.12it/s]Epoch: 0/10. Loss: 1.0300:  69%|[36m██████▉   [0m| 18/26 [00:16<00:07,  1.06it/s]Epoch: 0/10. Loss: 1.1423:  69%|[36m██████▉   [0m| 18/26 [00:16<00:07,  1.06it/s]Epoch: 0/10. Loss: 1.1423:  73%|[36m███████▎  [0m| 19/26 [00:16<00:06,  1.10it/s]Epoch: 0/10. Loss: 0.9315:  73%|[36m███████▎  [0m| 19/26 [00:17<00:06,  1.10it/s]Epoch: 0/10. Loss: 0.9315:  77%|[36m███████▋  [0m| 20/26 [00:17<00:05,  1.10it/s]Epoch: 0/10. Loss: 1.1918:  77%|[36m███████▋  [0m| 20/26 [00:19<00:05,  1.10it/s]Epoch: 0/10. Loss: 1.1918:  81%|[36m████████  [0m| 21/26 [00:19<00:05,  1.12s/it]Epoch: 0/10. Loss: 1.0778:  81%|[36m████████  [0m| 21/26 [00:20<00:05,  1.12s/it]Epoch: 0/10. Loss: 1.0778:  85%|[36m████████▍ [0m| 22/26 [00:20<00:04,  1.13s/it]Epoch: 0/10. Loss: 1.7639:  85%|[36m████████▍ [0m| 22/26 [00:22<00:04,  1.13s/it]Epoch: 0/10. Loss: 1.7639:  88%|[36m████████▊ [0m| 23/26 [00:22<00:03,  1.29s/it]Epoch: 0/10. Loss: 2.1670:  88%|[36m████████▊ [0m| 23/26 [00:23<00:03,  1.29s/it]Epoch: 0/10. Loss: 2.1670:  92%|[36m█████████▏[0m| 24/26 [00:23<00:02,  1.17s/it]Epoch: 0/10. Loss: 1.2101:  92%|[36m█████████▏[0m| 24/26 [00:24<00:02,  1.17s/it]Epoch: 0/10. Loss: 1.2101:  96%|[36m█████████▌[0m| 25/26 [00:24<00:01,  1.20s/it]Epoch: 0/10. Loss: 1.0160:  96%|[36m█████████▌[0m| 25/26 [00:25<00:01,  1.20s/it]Epoch: 0/10. Loss: 1.0160: 100%|[36m██████████[0m| 26/26 [00:25<00:00,  1.01s/it]Epoch: 0/10. Loss: 1.0160: 100%|[36m██████████[0m| 26/26 [00:25<00:00,  1.04it/s]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:05,  1.08it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:05,  1.10s/it] 43%|[33m████▎     [0m| 3/7 [00:02<00:03,  1.02it/s] 57%|[33m█████▋    [0m| 4/7 [00:04<00:03,  1.15s/it] 71%|[33m███████▏  [0m| 5/7 [00:04<00:01,  1.12it/s] 86%|[33m████████▌ [0m| 6/7 [00:05<00:00,  1.16it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.50it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.18it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 1/10. Loss: 1.0674:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 1/10. Loss: 1.0674:   4%|[36m▍         [0m| 1/26 [00:00<00:24,  1.02it/s]Epoch: 1/10. Loss: 1.0594:   4%|[36m▍         [0m| 1/26 [00:01<00:24,  1.02it/s]Epoch: 1/10. Loss: 1.0594:   8%|[36m▊         [0m| 2/26 [00:01<00:20,  1.20it/s]Epoch: 1/10. Loss: 1.1085:   8%|[36m▊         [0m| 2/26 [00:02<00:20,  1.20it/s]Epoch: 1/10. Loss: 1.1085:  12%|[36m█▏        [0m| 3/26 [00:02<00:21,  1.08it/s]Epoch: 1/10. Loss: 1.0684:  12%|[36m█▏        [0m| 3/26 [00:03<00:21,  1.08it/s]Epoch: 1/10. Loss: 1.0684:  15%|[36m█▌        [0m| 4/26 [00:03<00:22,  1.04s/it]Epoch: 1/10. Loss: 1.4337:  15%|[36m█▌        [0m| 4/26 [00:04<00:22,  1.04s/it]Epoch: 1/10. Loss: 1.4337:  19%|[36m█▉        [0m| 5/26 [00:04<00:20,  1.03it/s]Epoch: 1/10. Loss: 1.0557:  19%|[36m█▉        [0m| 5/26 [00:05<00:20,  1.03it/s]Epoch: 1/10. Loss: 1.0557:  23%|[36m██▎       [0m| 6/26 [00:05<00:17,  1.13it/s]Epoch: 1/10. Loss: 1.3250:  23%|[36m██▎       [0m| 6/26 [00:06<00:17,  1.13it/s]Epoch: 1/10. Loss: 1.3250:  27%|[36m██▋       [0m| 7/26 [00:06<00:17,  1.10it/s]Epoch: 1/10. Loss: 1.0545:  27%|[36m██▋       [0m| 7/26 [00:07<00:17,  1.10it/s]Epoch: 1/10. Loss: 1.0545:  31%|[36m███       [0m| 8/26 [00:07<00:16,  1.12it/s]Epoch: 1/10. Loss: 1.0114:  31%|[36m███       [0m| 8/26 [00:08<00:16,  1.12it/s]Epoch: 1/10. Loss: 1.0114:  35%|[36m███▍      [0m| 9/26 [00:08<00:14,  1.15it/s]Epoch: 1/10. Loss: 1.0905:  35%|[36m███▍      [0m| 9/26 [00:09<00:14,  1.15it/s]Epoch: 1/10. Loss: 1.0905:  38%|[36m███▊      [0m| 10/26 [00:09<00:14,  1.09it/s]Epoch: 1/10. Loss: 0.9714:  38%|[36m███▊      [0m| 10/26 [00:10<00:14,  1.09it/s]Epoch: 1/10. Loss: 0.9714:  42%|[36m████▏     [0m| 11/26 [00:10<00:14,  1.03it/s]Epoch: 1/10. Loss: 1.1051:  42%|[36m████▏     [0m| 11/26 [00:11<00:14,  1.03it/s]Epoch: 1/10. Loss: 1.1051:  46%|[36m████▌     [0m| 12/26 [00:11<00:13,  1.04it/s]Epoch: 1/10. Loss: 1.0959:  46%|[36m████▌     [0m| 12/26 [00:12<00:13,  1.04it/s]Epoch: 1/10. Loss: 1.0959:  50%|[36m█████     [0m| 13/26 [00:12<00:13,  1.07s/it]Epoch: 1/10. Loss: 0.9912:  50%|[36m█████     [0m| 13/26 [00:13<00:13,  1.07s/it]Epoch: 1/10. Loss: 0.9912:  54%|[36m█████▍    [0m| 14/26 [00:13<00:12,  1.03s/it]Epoch: 1/10. Loss: 0.9809:  54%|[36m█████▍    [0m| 14/26 [00:14<00:12,  1.03s/it]Epoch: 1/10. Loss: 0.9809:  58%|[36m█████▊    [0m| 15/26 [00:14<00:11,  1.01s/it]Epoch: 1/10. Loss: 1.0543:  58%|[36m█████▊    [0m| 15/26 [00:15<00:11,  1.01s/it]Epoch: 1/10. Loss: 1.0543:  62%|[36m██████▏   [0m| 16/26 [00:15<00:09,  1.01it/s]Epoch: 1/10. Loss: 1.0463:  62%|[36m██████▏   [0m| 16/26 [00:16<00:09,  1.01it/s]Epoch: 1/10. Loss: 1.0463:  65%|[36m██████▌   [0m| 17/26 [00:16<00:08,  1.06it/s]Epoch: 1/10. Loss: 1.0054:  65%|[36m██████▌   [0m| 17/26 [00:17<00:08,  1.06it/s]Epoch: 1/10. Loss: 1.0054:  69%|[36m██████▉   [0m| 18/26 [00:17<00:07,  1.06it/s]Epoch: 1/10. Loss: 0.9408:  69%|[36m██████▉   [0m| 18/26 [00:17<00:07,  1.06it/s]Epoch: 1/10. Loss: 0.9408:  73%|[36m███████▎  [0m| 19/26 [00:17<00:06,  1.13it/s]Epoch: 1/10. Loss: 1.1436:  73%|[36m███████▎  [0m| 19/26 [00:19<00:06,  1.13it/s]Epoch: 1/10. Loss: 1.1436:  77%|[36m███████▋  [0m| 20/26 [00:19<00:06,  1.07s/it]Epoch: 1/10. Loss: 1.0169:  77%|[36m███████▋  [0m| 20/26 [00:20<00:06,  1.07s/it]Epoch: 1/10. Loss: 1.0169:  81%|[36m████████  [0m| 21/26 [00:20<00:05,  1.06s/it]Epoch: 1/10. Loss: 0.9952:  81%|[36m████████  [0m| 21/26 [00:23<00:05,  1.06s/it]Epoch: 1/10. Loss: 0.9952:  85%|[36m████████▍ [0m| 22/26 [00:23<00:06,  1.64s/it]Epoch: 1/10. Loss: 0.9557:  85%|[36m████████▍ [0m| 22/26 [00:24<00:06,  1.64s/it]Epoch: 1/10. Loss: 0.9557:  88%|[36m████████▊ [0m| 23/26 [00:24<00:04,  1.53s/it]Epoch: 1/10. Loss: 1.0179:  88%|[36m████████▊ [0m| 23/26 [00:25<00:04,  1.53s/it]Epoch: 1/10. Loss: 1.0179:  92%|[36m█████████▏[0m| 24/26 [00:25<00:02,  1.36s/it]Epoch: 1/10. Loss: 1.1273:  92%|[36m█████████▏[0m| 24/26 [00:26<00:02,  1.36s/it]Epoch: 1/10. Loss: 1.1273:  96%|[36m█████████▌[0m| 25/26 [00:26<00:01,  1.25s/it]Epoch: 1/10. Loss: 1.0101:  96%|[36m█████████▌[0m| 25/26 [00:27<00:01,  1.25s/it]Epoch: 1/10. Loss: 1.0101: 100%|[36m██████████[0m| 26/26 [00:27<00:00,  1.05s/it]Epoch: 1/10. Loss: 1.0101: 100%|[36m██████████[0m| 26/26 [00:27<00:00,  1.05s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:05,  1.06it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:05,  1.12s/it] 43%|[33m████▎     [0m| 3/7 [00:02<00:03,  1.03it/s] 57%|[33m█████▋    [0m| 4/7 [00:04<00:03,  1.15s/it] 71%|[33m███████▏  [0m| 5/7 [00:04<00:01,  1.11it/s] 86%|[33m████████▌ [0m| 6/7 [00:05<00:00,  1.14it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.47it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.17it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 2/10. Loss: 1.1092:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 2/10. Loss: 1.1092:   4%|[36m▍         [0m| 1/26 [00:00<00:22,  1.12it/s]Epoch: 2/10. Loss: 1.0442:   4%|[36m▍         [0m| 1/26 [00:01<00:22,  1.12it/s]Epoch: 2/10. Loss: 1.0442:   8%|[36m▊         [0m| 2/26 [00:01<00:21,  1.12it/s]Epoch: 2/10. Loss: 1.0449:   8%|[36m▊         [0m| 2/26 [00:02<00:21,  1.12it/s]Epoch: 2/10. Loss: 1.0449:  12%|[36m█▏        [0m| 3/26 [00:02<00:19,  1.18it/s]Epoch: 2/10. Loss: 1.0529:  12%|[36m█▏        [0m| 3/26 [00:03<00:19,  1.18it/s]Epoch: 2/10. Loss: 1.0529:  15%|[36m█▌        [0m| 4/26 [00:03<00:17,  1.22it/s]Epoch: 2/10. Loss: 1.0038:  15%|[36m█▌        [0m| 4/26 [00:04<00:17,  1.22it/s]Epoch: 2/10. Loss: 1.0038:  19%|[36m█▉        [0m| 5/26 [00:04<00:16,  1.25it/s]Epoch: 2/10. Loss: 1.0022:  19%|[36m█▉        [0m| 5/26 [00:05<00:16,  1.25it/s]Epoch: 2/10. Loss: 1.0022:  23%|[36m██▎       [0m| 6/26 [00:05<00:17,  1.11it/s]Epoch: 2/10. Loss: 0.9897:  23%|[36m██▎       [0m| 6/26 [00:06<00:17,  1.11it/s]Epoch: 2/10. Loss: 0.9897:  27%|[36m██▋       [0m| 7/26 [00:06<00:20,  1.08s/it]Epoch: 2/10. Loss: 1.0075:  27%|[36m██▋       [0m| 7/26 [00:07<00:20,  1.08s/it]Epoch: 2/10. Loss: 1.0075:  31%|[36m███       [0m| 8/26 [00:07<00:18,  1.04s/it]Epoch: 2/10. Loss: 1.1007:  31%|[36m███       [0m| 8/26 [00:08<00:18,  1.04s/it]Epoch: 2/10. Loss: 1.1007:  35%|[36m███▍      [0m| 9/26 [00:08<00:16,  1.02it/s]Epoch: 2/10. Loss: 0.9503:  35%|[36m███▍      [0m| 9/26 [00:09<00:16,  1.02it/s]Epoch: 2/10. Loss: 0.9503:  38%|[36m███▊      [0m| 10/26 [00:09<00:15,  1.01it/s]Epoch: 2/10. Loss: 1.0518:  38%|[36m███▊      [0m| 10/26 [00:10<00:15,  1.01it/s]Epoch: 2/10. Loss: 1.0518:  42%|[36m████▏     [0m| 11/26 [00:10<00:15,  1.01s/it]Epoch: 2/10. Loss: 0.9444:  42%|[36m████▏     [0m| 11/26 [00:11<00:15,  1.01s/it]Epoch: 2/10. Loss: 0.9444:  46%|[36m████▌     [0m| 12/26 [00:11<00:13,  1.05it/s]Epoch: 2/10. Loss: 1.0053:  46%|[36m████▌     [0m| 12/26 [00:12<00:13,  1.05it/s]Epoch: 2/10. Loss: 1.0053:  50%|[36m█████     [0m| 13/26 [00:12<00:11,  1.11it/s]Epoch: 2/10. Loss: 0.9536:  50%|[36m█████     [0m| 13/26 [00:12<00:11,  1.11it/s]Epoch: 2/10. Loss: 0.9536:  54%|[36m█████▍    [0m| 14/26 [00:12<00:10,  1.13it/s]Epoch: 2/10. Loss: 0.9670:  54%|[36m█████▍    [0m| 14/26 [00:13<00:10,  1.13it/s]Epoch: 2/10. Loss: 0.9670:  58%|[36m█████▊    [0m| 15/26 [00:13<00:10,  1.09it/s]Epoch: 2/10. Loss: 0.9713:  58%|[36m█████▊    [0m| 15/26 [00:14<00:10,  1.09it/s]Epoch: 2/10. Loss: 0.9713:  62%|[36m██████▏   [0m| 16/26 [00:14<00:09,  1.06it/s]Epoch: 2/10. Loss: 1.0144:  62%|[36m██████▏   [0m| 16/26 [00:16<00:09,  1.06it/s]Epoch: 2/10. Loss: 1.0144:  65%|[36m██████▌   [0m| 17/26 [00:16<00:08,  1.01it/s]Epoch: 2/10. Loss: 0.9067:  65%|[36m██████▌   [0m| 17/26 [00:19<00:08,  1.01it/s]Epoch: 2/10. Loss: 0.9067:  69%|[36m██████▉   [0m| 18/26 [00:19<00:13,  1.73s/it]Epoch: 2/10. Loss: 0.9662:  69%|[36m██████▉   [0m| 18/26 [00:20<00:13,  1.73s/it]Epoch: 2/10. Loss: 0.9662:  73%|[36m███████▎  [0m| 19/26 [00:20<00:10,  1.48s/it]Epoch: 2/10. Loss: 1.1938:  73%|[36m███████▎  [0m| 19/26 [00:21<00:10,  1.48s/it]Epoch: 2/10. Loss: 1.1938:  77%|[36m███████▋  [0m| 20/26 [00:21<00:07,  1.31s/it]Epoch: 2/10. Loss: 1.0526:  77%|[36m███████▋  [0m| 20/26 [00:22<00:07,  1.31s/it]Epoch: 2/10. Loss: 1.0526:  81%|[36m████████  [0m| 21/26 [00:22<00:06,  1.21s/it]Epoch: 2/10. Loss: 1.0202:  81%|[36m████████  [0m| 21/26 [00:23<00:06,  1.21s/it]Epoch: 2/10. Loss: 1.0202:  85%|[36m████████▍ [0m| 22/26 [00:23<00:04,  1.22s/it]Epoch: 2/10. Loss: 0.9764:  85%|[36m████████▍ [0m| 22/26 [00:24<00:04,  1.22s/it]Epoch: 2/10. Loss: 0.9764:  88%|[36m████████▊ [0m| 23/26 [00:24<00:03,  1.13s/it]Epoch: 2/10. Loss: 0.9299:  88%|[36m████████▊ [0m| 23/26 [00:25<00:03,  1.13s/it]Epoch: 2/10. Loss: 0.9299:  92%|[36m█████████▏[0m| 24/26 [00:25<00:02,  1.09s/it]Epoch: 2/10. Loss: 0.9828:  92%|[36m█████████▏[0m| 24/26 [00:26<00:02,  1.09s/it]Epoch: 2/10. Loss: 0.9828:  96%|[36m█████████▌[0m| 25/26 [00:26<00:01,  1.01s/it]Epoch: 2/10. Loss: 0.9974:  96%|[36m█████████▌[0m| 25/26 [00:26<00:01,  1.01s/it]Epoch: 2/10. Loss: 0.9974: 100%|[36m██████████[0m| 26/26 [00:26<00:00,  1.11it/s]Epoch: 2/10. Loss: 0.9974: 100%|[36m██████████[0m| 26/26 [00:26<00:00,  1.04s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:05,  1.03it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:05,  1.14s/it] 43%|[33m████▎     [0m| 3/7 [00:03<00:03,  1.01it/s] 57%|[33m█████▋    [0m| 4/7 [00:04<00:03,  1.15s/it] 71%|[33m███████▏  [0m| 5/7 [00:04<00:01,  1.12it/s] 86%|[33m████████▌ [0m| 6/7 [00:05<00:00,  1.14it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.48it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.17it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 3/10. Loss: 0.9714:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 3/10. Loss: 0.9714:   4%|[36m▍         [0m| 1/26 [00:00<00:24,  1.03it/s]Epoch: 3/10. Loss: 0.9867:   4%|[36m▍         [0m| 1/26 [00:01<00:24,  1.03it/s]Epoch: 3/10. Loss: 0.9867:   8%|[36m▊         [0m| 2/26 [00:01<00:21,  1.10it/s]Epoch: 3/10. Loss: 1.0736:   8%|[36m▊         [0m| 2/26 [00:02<00:21,  1.10it/s]Epoch: 3/10. Loss: 1.0736:  12%|[36m█▏        [0m| 3/26 [00:02<00:20,  1.10it/s]Epoch: 3/10. Loss: 1.0908:  12%|[36m█▏        [0m| 3/26 [00:03<00:20,  1.10it/s]Epoch: 3/10. Loss: 1.0908:  15%|[36m█▌        [0m| 4/26 [00:03<00:20,  1.10it/s]Epoch: 3/10. Loss: 1.0785:  15%|[36m█▌        [0m| 4/26 [00:04<00:20,  1.10it/s]Epoch: 3/10. Loss: 1.0785:  19%|[36m█▉        [0m| 5/26 [00:04<00:20,  1.04it/s]Epoch: 3/10. Loss: 1.0048:  19%|[36m█▉        [0m| 5/26 [00:05<00:20,  1.04it/s]Epoch: 3/10. Loss: 1.0048:  23%|[36m██▎       [0m| 6/26 [00:05<00:18,  1.07it/s]Epoch: 3/10. Loss: 0.9836:  23%|[36m██▎       [0m| 6/26 [00:06<00:18,  1.07it/s]Epoch: 3/10. Loss: 0.9836:  27%|[36m██▋       [0m| 7/26 [00:06<00:18,  1.01it/s]Epoch: 3/10. Loss: 0.9717:  27%|[36m██▋       [0m| 7/26 [00:07<00:18,  1.01it/s]Epoch: 3/10. Loss: 0.9717:  31%|[36m███       [0m| 8/26 [00:07<00:17,  1.02it/s]Epoch: 3/10. Loss: 0.9435:  31%|[36m███       [0m| 8/26 [00:08<00:17,  1.02it/s]Epoch: 3/10. Loss: 0.9435:  35%|[36m███▍      [0m| 9/26 [00:08<00:16,  1.03it/s]Epoch: 3/10. Loss: 0.9524:  35%|[36m███▍      [0m| 9/26 [00:09<00:16,  1.03it/s]Epoch: 3/10. Loss: 0.9524:  38%|[36m███▊      [0m| 10/26 [00:09<00:14,  1.08it/s]Epoch: 3/10. Loss: 0.9664:  38%|[36m███▊      [0m| 10/26 [00:10<00:14,  1.08it/s]Epoch: 3/10. Loss: 0.9664:  42%|[36m████▏     [0m| 11/26 [00:10<00:14,  1.07it/s]Epoch: 3/10. Loss: 0.9658:  42%|[36m████▏     [0m| 11/26 [00:11<00:14,  1.07it/s]Epoch: 3/10. Loss: 0.9658:  46%|[36m████▌     [0m| 12/26 [00:11<00:12,  1.10it/s]Epoch: 3/10. Loss: 0.9627:  46%|[36m████▌     [0m| 12/26 [00:12<00:12,  1.10it/s]Epoch: 3/10. Loss: 0.9627:  50%|[36m█████     [0m| 13/26 [00:12<00:11,  1.11it/s]Epoch: 3/10. Loss: 0.9917:  50%|[36m█████     [0m| 13/26 [00:12<00:11,  1.11it/s]Epoch: 3/10. Loss: 0.9917:  54%|[36m█████▍    [0m| 14/26 [00:12<00:10,  1.13it/s]Epoch: 3/10. Loss: 0.9478:  54%|[36m█████▍    [0m| 14/26 [00:13<00:10,  1.13it/s]Epoch: 3/10. Loss: 0.9478:  58%|[36m█████▊    [0m| 15/26 [00:13<00:09,  1.10it/s]Epoch: 3/10. Loss: 0.9852:  58%|[36m█████▊    [0m| 15/26 [00:14<00:09,  1.10it/s]Epoch: 3/10. Loss: 0.9852:  62%|[36m██████▏   [0m| 16/26 [00:14<00:08,  1.18it/s]Epoch: 3/10. Loss: 0.9827:  62%|[36m██████▏   [0m| 16/26 [00:15<00:08,  1.18it/s]Epoch: 3/10. Loss: 0.9827:  65%|[36m██████▌   [0m| 17/26 [00:15<00:07,  1.18it/s]Epoch: 3/10. Loss: 0.9927:  65%|[36m██████▌   [0m| 17/26 [00:16<00:07,  1.18it/s]Epoch: 3/10. Loss: 0.9927:  69%|[36m██████▉   [0m| 18/26 [00:16<00:06,  1.23it/s]Epoch: 3/10. Loss: 0.9831:  69%|[36m██████▉   [0m| 18/26 [00:18<00:06,  1.23it/s]Epoch: 3/10. Loss: 0.9831:  73%|[36m███████▎  [0m| 19/26 [00:18<00:07,  1.13s/it]Epoch: 3/10. Loss: 0.9789:  73%|[36m███████▎  [0m| 19/26 [00:20<00:07,  1.13s/it]Epoch: 3/10. Loss: 0.9789:  77%|[36m███████▋  [0m| 20/26 [00:20<00:08,  1.39s/it]Epoch: 3/10. Loss: 1.0346:  77%|[36m███████▋  [0m| 20/26 [00:20<00:08,  1.39s/it]Epoch: 3/10. Loss: 1.0346:  81%|[36m████████  [0m| 21/26 [00:20<00:06,  1.25s/it]Epoch: 3/10. Loss: 0.9707:  81%|[36m████████  [0m| 21/26 [00:23<00:06,  1.25s/it]Epoch: 3/10. Loss: 0.9707:  85%|[36m████████▍ [0m| 22/26 [00:23<00:06,  1.60s/it]Epoch: 3/10. Loss: 0.9817:  85%|[36m████████▍ [0m| 22/26 [00:24<00:06,  1.60s/it]Epoch: 3/10. Loss: 0.9817:  88%|[36m████████▊ [0m| 23/26 [00:24<00:04,  1.48s/it]Epoch: 3/10. Loss: 0.9318:  88%|[36m████████▊ [0m| 23/26 [00:25<00:04,  1.48s/it]Epoch: 3/10. Loss: 0.9318:  92%|[36m█████████▏[0m| 24/26 [00:25<00:02,  1.32s/it]Epoch: 3/10. Loss: 1.0078:  92%|[36m█████████▏[0m| 24/26 [00:26<00:02,  1.32s/it]Epoch: 3/10. Loss: 1.0078:  96%|[36m█████████▌[0m| 25/26 [00:26<00:01,  1.18s/it]Epoch: 3/10. Loss: 0.9840:  96%|[36m█████████▌[0m| 25/26 [00:26<00:01,  1.18s/it]Epoch: 3/10. Loss: 0.9840: 100%|[36m██████████[0m| 26/26 [00:26<00:00,  1.00it/s]Epoch: 3/10. Loss: 0.9840: 100%|[36m██████████[0m| 26/26 [00:26<00:00,  1.04s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:05,  1.02it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:05,  1.19s/it] 43%|[33m████▎     [0m| 3/7 [00:03<00:04,  1.01s/it] 57%|[33m█████▋    [0m| 4/7 [00:04<00:03,  1.17s/it] 71%|[33m███████▏  [0m| 5/7 [00:04<00:01,  1.10it/s] 86%|[33m████████▌ [0m| 6/7 [00:05<00:00,  1.14it/s]100%|[33m██████████[0m| 7/7 [00:06<00:00,  1.19it/s]100%|[33m██████████[0m| 7/7 [00:06<00:00,  1.07it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 4/10. Loss: 1.0289:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 4/10. Loss: 1.0289:   4%|[36m▍         [0m| 1/26 [00:00<00:21,  1.19it/s]Epoch: 4/10. Loss: 0.9402:   4%|[36m▍         [0m| 1/26 [00:03<00:21,  1.19it/s]Epoch: 4/10. Loss: 0.9402:   8%|[36m▊         [0m| 2/26 [00:03<00:41,  1.74s/it]Epoch: 4/10. Loss: 1.0751:   8%|[36m▊         [0m| 2/26 [00:04<00:41,  1.74s/it]Epoch: 4/10. Loss: 1.0751:  12%|[36m█▏        [0m| 3/26 [00:04<00:35,  1.52s/it]Epoch: 4/10. Loss: 0.9643:  12%|[36m█▏        [0m| 3/26 [00:05<00:35,  1.52s/it]Epoch: 4/10. Loss: 0.9643:  15%|[36m█▌        [0m| 4/26 [00:05<00:27,  1.26s/it]Epoch: 4/10. Loss: 0.9146:  15%|[36m█▌        [0m| 4/26 [00:06<00:27,  1.26s/it]Epoch: 4/10. Loss: 0.9146:  19%|[36m█▉        [0m| 5/26 [00:06<00:24,  1.18s/it]Epoch: 4/10. Loss: 0.9426:  19%|[36m█▉        [0m| 5/26 [00:07<00:24,  1.18s/it]Epoch: 4/10. Loss: 0.9426:  23%|[36m██▎       [0m| 6/26 [00:07<00:22,  1.14s/it]Epoch: 4/10. Loss: 0.9364:  23%|[36m██▎       [0m| 6/26 [00:08<00:22,  1.14s/it]Epoch: 4/10. Loss: 0.9364:  27%|[36m██▋       [0m| 7/26 [00:08<00:20,  1.08s/it]Epoch: 4/10. Loss: 1.0624:  27%|[36m██▋       [0m| 7/26 [00:10<00:20,  1.08s/it]Epoch: 4/10. Loss: 1.0624:  31%|[36m███       [0m| 8/26 [00:10<00:24,  1.34s/it]Epoch: 4/10. Loss: 0.9652:  31%|[36m███       [0m| 8/26 [00:11<00:24,  1.34s/it]Epoch: 4/10. Loss: 0.9652:  35%|[36m███▍      [0m| 9/26 [00:11<00:20,  1.23s/it]Epoch: 4/10. Loss: 1.0041:  35%|[36m███▍      [0m| 9/26 [00:12<00:20,  1.23s/it]Epoch: 4/10. Loss: 1.0041:  38%|[36m███▊      [0m| 10/26 [00:12<00:18,  1.13s/it]Epoch: 4/10. Loss: 0.9855:  38%|[36m███▊      [0m| 10/26 [00:12<00:18,  1.13s/it]Epoch: 4/10. Loss: 0.9855:  42%|[36m████▏     [0m| 11/26 [00:12<00:15,  1.03s/it]Epoch: 4/10. Loss: 0.9036:  42%|[36m████▏     [0m| 11/26 [00:13<00:15,  1.03s/it]Epoch: 4/10. Loss: 0.9036:  46%|[36m████▌     [0m| 12/26 [00:13<00:13,  1.03it/s]Epoch: 4/10. Loss: 0.8729:  46%|[36m████▌     [0m| 12/26 [00:14<00:13,  1.03it/s]Epoch: 4/10. Loss: 0.8729:  50%|[36m█████     [0m| 13/26 [00:14<00:12,  1.02it/s]Epoch: 4/10. Loss: 0.9401:  50%|[36m█████     [0m| 13/26 [00:15<00:12,  1.02it/s]Epoch: 4/10. Loss: 0.9401:  54%|[36m█████▍    [0m| 14/26 [00:15<00:11,  1.04it/s]Epoch: 4/10. Loss: 0.9282:  54%|[36m█████▍    [0m| 14/26 [00:16<00:11,  1.04it/s]Epoch: 4/10. Loss: 0.9282:  58%|[36m█████▊    [0m| 15/26 [00:16<00:10,  1.02it/s]Epoch: 4/10. Loss: 0.9276:  58%|[36m█████▊    [0m| 15/26 [00:17<00:10,  1.02it/s]Epoch: 4/10. Loss: 0.9276:  62%|[36m██████▏   [0m| 16/26 [00:17<00:09,  1.07it/s]Epoch: 4/10. Loss: 1.0123:  62%|[36m██████▏   [0m| 16/26 [00:18<00:09,  1.07it/s]Epoch: 4/10. Loss: 1.0123:  65%|[36m██████▌   [0m| 17/26 [00:18<00:07,  1.13it/s]Epoch: 4/10. Loss: 0.9066:  65%|[36m██████▌   [0m| 17/26 [00:19<00:07,  1.13it/s]Epoch: 4/10. Loss: 0.9066:  69%|[36m██████▉   [0m| 18/26 [00:19<00:07,  1.12it/s]Epoch: 4/10. Loss: 0.9794:  69%|[36m██████▉   [0m| 18/26 [00:20<00:07,  1.12it/s]Epoch: 4/10. Loss: 0.9794:  73%|[36m███████▎  [0m| 19/26 [00:20<00:06,  1.10it/s]Epoch: 4/10. Loss: 0.9920:  73%|[36m███████▎  [0m| 19/26 [00:21<00:06,  1.10it/s]Epoch: 4/10. Loss: 0.9920:  77%|[36m███████▋  [0m| 20/26 [00:21<00:05,  1.07it/s]Epoch: 4/10. Loss: 0.8742:  77%|[36m███████▋  [0m| 20/26 [00:22<00:05,  1.07it/s]Epoch: 4/10. Loss: 0.8742:  81%|[36m████████  [0m| 21/26 [00:22<00:04,  1.10it/s]Epoch: 4/10. Loss: 0.9333:  81%|[36m████████  [0m| 21/26 [00:22<00:04,  1.10it/s]Epoch: 4/10. Loss: 0.9333:  85%|[36m████████▍ [0m| 22/26 [00:22<00:03,  1.15it/s]Epoch: 4/10. Loss: 0.8829:  85%|[36m████████▍ [0m| 22/26 [00:23<00:03,  1.15it/s]Epoch: 4/10. Loss: 0.8829:  88%|[36m████████▊ [0m| 23/26 [00:23<00:02,  1.17it/s]Epoch: 4/10. Loss: 0.9494:  88%|[36m████████▊ [0m| 23/26 [00:24<00:02,  1.17it/s]Epoch: 4/10. Loss: 0.9494:  92%|[36m█████████▏[0m| 24/26 [00:24<00:01,  1.12it/s]Epoch: 4/10. Loss: 0.8582:  92%|[36m█████████▏[0m| 24/26 [00:25<00:01,  1.12it/s]Epoch: 4/10. Loss: 0.8582:  96%|[36m█████████▌[0m| 25/26 [00:25<00:00,  1.10it/s]Epoch: 4/10. Loss: 1.2772:  96%|[36m█████████▌[0m| 25/26 [00:26<00:00,  1.10it/s]Epoch: 4/10. Loss: 1.2772: 100%|[36m██████████[0m| 26/26 [00:26<00:00,  1.18it/s]Epoch: 4/10. Loss: 1.2772: 100%|[36m██████████[0m| 26/26 [00:26<00:00,  1.01s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:05,  1.04it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:05,  1.14s/it] 43%|[33m████▎     [0m| 3/7 [00:03<00:03,  1.01it/s] 57%|[33m█████▋    [0m| 4/7 [00:05<00:04,  1.47s/it] 71%|[33m███████▏  [0m| 5/7 [00:05<00:02,  1.15s/it] 86%|[33m████████▌ [0m| 6/7 [00:06<00:01,  1.09s/it]100%|[33m██████████[0m| 7/7 [00:07<00:00,  1.10s/it]100%|[33m██████████[0m| 7/7 [00:07<00:00,  1.13s/it]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 5/10. Loss: 1.0099:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 5/10. Loss: 1.0099:   4%|[36m▍         [0m| 1/26 [00:00<00:21,  1.15it/s]Epoch: 5/10. Loss: 1.0465:   4%|[36m▍         [0m| 1/26 [00:01<00:21,  1.15it/s]Epoch: 5/10. Loss: 1.0465:   8%|[36m▊         [0m| 2/26 [00:01<00:19,  1.21it/s]Epoch: 5/10. Loss: 0.9700:   8%|[36m▊         [0m| 2/26 [00:02<00:19,  1.21it/s]Epoch: 5/10. Loss: 0.9700:  12%|[36m█▏        [0m| 3/26 [00:02<00:20,  1.15it/s]Epoch: 5/10. Loss: 0.8906:  12%|[36m█▏        [0m| 3/26 [00:03<00:20,  1.15it/s]Epoch: 5/10. Loss: 0.8906:  15%|[36m█▌        [0m| 4/26 [00:03<00:20,  1.09it/s]Epoch: 5/10. Loss: 0.9953:  15%|[36m█▌        [0m| 4/26 [00:04<00:20,  1.09it/s]Epoch: 5/10. Loss: 0.9953:  19%|[36m█▉        [0m| 5/26 [00:04<00:18,  1.14it/s]Epoch: 5/10. Loss: 1.0388:  19%|[36m█▉        [0m| 5/26 [00:05<00:18,  1.14it/s]Epoch: 5/10. Loss: 1.0388:  23%|[36m██▎       [0m| 6/26 [00:05<00:17,  1.13it/s]Epoch: 5/10. Loss: 1.1401:  23%|[36m██▎       [0m| 6/26 [00:06<00:17,  1.13it/s]Epoch: 5/10. Loss: 1.1401:  27%|[36m██▋       [0m| 7/26 [00:06<00:16,  1.14it/s]Epoch: 5/10. Loss: 0.9351:  27%|[36m██▋       [0m| 7/26 [00:07<00:16,  1.14it/s]Epoch: 5/10. Loss: 0.9351:  31%|[36m███       [0m| 8/26 [00:07<00:16,  1.12it/s]Epoch: 5/10. Loss: 0.9461:  31%|[36m███       [0m| 8/26 [00:07<00:16,  1.12it/s]Epoch: 5/10. Loss: 0.9461:  35%|[36m███▍      [0m| 9/26 [00:08<00:15,  1.10it/s]Epoch: 5/10. Loss: 0.9855:  35%|[36m███▍      [0m| 9/26 [00:08<00:15,  1.10it/s]Epoch: 5/10. Loss: 0.9855:  38%|[36m███▊      [0m| 10/26 [00:08<00:14,  1.08it/s]Epoch: 5/10. Loss: 0.9492:  38%|[36m███▊      [0m| 10/26 [00:10<00:14,  1.08it/s]Epoch: 5/10. Loss: 0.9492:  42%|[36m████▏     [0m| 11/26 [00:10<00:14,  1.01it/s]Epoch: 5/10. Loss: 0.9825:  42%|[36m████▏     [0m| 11/26 [00:10<00:14,  1.01it/s]Epoch: 5/10. Loss: 0.9825:  46%|[36m████▌     [0m| 12/26 [00:10<00:13,  1.07it/s]Epoch: 5/10. Loss: 0.9409:  46%|[36m████▌     [0m| 12/26 [00:11<00:13,  1.07it/s]Epoch: 5/10. Loss: 0.9409:  50%|[36m█████     [0m| 13/26 [00:11<00:11,  1.09it/s]Epoch: 5/10. Loss: 0.9649:  50%|[36m█████     [0m| 13/26 [00:12<00:11,  1.09it/s]Epoch: 5/10. Loss: 0.9649:  54%|[36m█████▍    [0m| 14/26 [00:12<00:11,  1.06it/s]Epoch: 5/10. Loss: 0.9224:  54%|[36m█████▍    [0m| 14/26 [00:13<00:11,  1.06it/s]Epoch: 5/10. Loss: 0.9224:  58%|[36m█████▊    [0m| 15/26 [00:13<00:10,  1.08it/s]Epoch: 5/10. Loss: 0.8612:  58%|[36m█████▊    [0m| 15/26 [00:14<00:10,  1.08it/s]Epoch: 5/10. Loss: 0.8612:  62%|[36m██████▏   [0m| 16/26 [00:14<00:09,  1.05it/s]Epoch: 5/10. Loss: 0.8393:  62%|[36m██████▏   [0m| 16/26 [00:15<00:09,  1.05it/s]Epoch: 5/10. Loss: 0.8393:  65%|[36m██████▌   [0m| 17/26 [00:15<00:08,  1.11it/s]Epoch: 5/10. Loss: 1.0334:  65%|[36m██████▌   [0m| 17/26 [00:16<00:08,  1.11it/s]Epoch: 5/10. Loss: 1.0334:  69%|[36m██████▉   [0m| 18/26 [00:16<00:07,  1.10it/s]Epoch: 5/10. Loss: 0.9823:  69%|[36m██████▉   [0m| 18/26 [00:17<00:07,  1.10it/s]Epoch: 5/10. Loss: 0.9823:  73%|[36m███████▎  [0m| 19/26 [00:17<00:06,  1.15it/s]Epoch: 5/10. Loss: 1.0382:  73%|[36m███████▎  [0m| 19/26 [00:18<00:06,  1.15it/s]Epoch: 5/10. Loss: 1.0382:  77%|[36m███████▋  [0m| 20/26 [00:18<00:05,  1.13it/s]Epoch: 5/10. Loss: 0.9125:  77%|[36m███████▋  [0m| 20/26 [00:19<00:05,  1.13it/s]Epoch: 5/10. Loss: 0.9125:  81%|[36m████████  [0m| 21/26 [00:19<00:04,  1.09it/s]Epoch: 5/10. Loss: 0.8878:  81%|[36m████████  [0m| 21/26 [00:20<00:04,  1.09it/s]Epoch: 5/10. Loss: 0.8878:  85%|[36m████████▍ [0m| 22/26 [00:20<00:04,  1.05s/it]Epoch: 5/10. Loss: 0.9191:  85%|[36m████████▍ [0m| 22/26 [00:21<00:04,  1.05s/it]Epoch: 5/10. Loss: 0.9191:  88%|[36m████████▊ [0m| 23/26 [00:21<00:03,  1.02s/it]Epoch: 5/10. Loss: 0.9209:  88%|[36m████████▊ [0m| 23/26 [00:22<00:03,  1.02s/it]Epoch: 5/10. Loss: 0.9209:  92%|[36m█████████▏[0m| 24/26 [00:22<00:01,  1.01it/s]Epoch: 5/10. Loss: 0.8609:  92%|[36m█████████▏[0m| 24/26 [00:23<00:01,  1.01it/s]Epoch: 5/10. Loss: 0.8609:  96%|[36m█████████▌[0m| 25/26 [00:23<00:00,  1.02it/s]Epoch: 5/10. Loss: 0.9116:  96%|[36m█████████▌[0m| 25/26 [00:23<00:00,  1.02it/s]Epoch: 5/10. Loss: 0.9116: 100%|[36m██████████[0m| 26/26 [00:23<00:00,  1.13it/s]Epoch: 5/10. Loss: 0.9116: 100%|[36m██████████[0m| 26/26 [00:23<00:00,  1.09it/s]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:05,  1.04it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:06,  1.27s/it] 43%|[33m████▎     [0m| 3/7 [00:03<00:04,  1.08s/it] 57%|[33m█████▋    [0m| 4/7 [00:04<00:03,  1.24s/it] 71%|[33m███████▏  [0m| 5/7 [00:05<00:01,  1.05it/s] 86%|[33m████████▌ [0m| 6/7 [00:06<00:00,  1.08it/s]100%|[33m██████████[0m| 7/7 [00:07<00:00,  1.07it/s]100%|[33m██████████[0m| 7/7 [00:07<00:00,  1.01s/it]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 6/10. Loss: 0.9006:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 6/10. Loss: 0.9006:   4%|[36m▍         [0m| 1/26 [00:00<00:24,  1.01it/s]Epoch: 6/10. Loss: 0.9857:   4%|[36m▍         [0m| 1/26 [00:02<00:24,  1.01it/s]Epoch: 6/10. Loss: 0.9857:   8%|[36m▊         [0m| 2/26 [00:02<00:24,  1.01s/it]Epoch: 6/10. Loss: 0.8703:   8%|[36m▊         [0m| 2/26 [00:02<00:24,  1.01s/it]Epoch: 6/10. Loss: 0.8703:  12%|[36m█▏        [0m| 3/26 [00:02<00:21,  1.06it/s]Epoch: 6/10. Loss: 0.8839:  12%|[36m█▏        [0m| 3/26 [00:03<00:21,  1.06it/s]Epoch: 6/10. Loss: 0.8839:  15%|[36m█▌        [0m| 4/26 [00:03<00:20,  1.06it/s]Epoch: 6/10. Loss: 0.8594:  15%|[36m█▌        [0m| 4/26 [00:04<00:20,  1.06it/s]Epoch: 6/10. Loss: 0.8594:  19%|[36m█▉        [0m| 5/26 [00:04<00:19,  1.07it/s]Epoch: 6/10. Loss: 0.9487:  19%|[36m█▉        [0m| 5/26 [00:06<00:19,  1.07it/s]Epoch: 6/10. Loss: 0.9487:  23%|[36m██▎       [0m| 6/26 [00:06<00:21,  1.07s/it]Epoch: 6/10. Loss: 0.8503:  23%|[36m██▎       [0m| 6/26 [00:07<00:21,  1.07s/it]Epoch: 6/10. Loss: 0.8503:  27%|[36m██▋       [0m| 7/26 [00:07<00:19,  1.03s/it]Epoch: 6/10. Loss: 0.9363:  27%|[36m██▋       [0m| 7/26 [00:08<00:19,  1.03s/it]Epoch: 6/10. Loss: 0.9363:  31%|[36m███       [0m| 8/26 [00:08<00:18,  1.02s/it]Epoch: 6/10. Loss: 0.8616:  31%|[36m███       [0m| 8/26 [00:08<00:18,  1.02s/it]Epoch: 6/10. Loss: 0.8616:  35%|[36m███▍      [0m| 9/26 [00:08<00:16,  1.02it/s]Epoch: 6/10. Loss: 0.9073:  35%|[36m███▍      [0m| 9/26 [00:09<00:16,  1.02it/s]Epoch: 6/10. Loss: 0.9073:  38%|[36m███▊      [0m| 10/26 [00:09<00:15,  1.02it/s]Epoch: 6/10. Loss: 0.9773:  38%|[36m███▊      [0m| 10/26 [00:10<00:15,  1.02it/s]Epoch: 6/10. Loss: 0.9773:  42%|[36m████▏     [0m| 11/26 [00:10<00:13,  1.10it/s]Epoch: 6/10. Loss: 0.9927:  42%|[36m████▏     [0m| 11/26 [00:11<00:13,  1.10it/s]Epoch: 6/10. Loss: 0.9927:  46%|[36m████▌     [0m| 12/26 [00:11<00:12,  1.15it/s]Epoch: 6/10. Loss: 0.9354:  46%|[36m████▌     [0m| 12/26 [00:12<00:12,  1.15it/s]Epoch: 6/10. Loss: 0.9354:  50%|[36m█████     [0m| 13/26 [00:12<00:11,  1.12it/s]Epoch: 6/10. Loss: 0.9264:  50%|[36m█████     [0m| 13/26 [00:13<00:11,  1.12it/s]Epoch: 6/10. Loss: 0.9264:  54%|[36m█████▍    [0m| 14/26 [00:13<00:10,  1.11it/s]Epoch: 6/10. Loss: 0.9128:  54%|[36m█████▍    [0m| 14/26 [00:14<00:10,  1.11it/s]Epoch: 6/10. Loss: 0.9128:  58%|[36m█████▊    [0m| 15/26 [00:14<00:09,  1.13it/s]Epoch: 6/10. Loss: 0.9101:  58%|[36m█████▊    [0m| 15/26 [00:15<00:09,  1.13it/s]Epoch: 6/10. Loss: 0.9101:  62%|[36m██████▏   [0m| 16/26 [00:15<00:10,  1.09s/it]Epoch: 6/10. Loss: 0.8960:  62%|[36m██████▏   [0m| 16/26 [00:16<00:10,  1.09s/it]Epoch: 6/10. Loss: 0.8960:  65%|[36m██████▌   [0m| 17/26 [00:16<00:09,  1.03s/it]Epoch: 6/10. Loss: 0.9088:  65%|[36m██████▌   [0m| 17/26 [00:17<00:09,  1.03s/it]Epoch: 6/10. Loss: 0.9088:  69%|[36m██████▉   [0m| 18/26 [00:17<00:08,  1.02s/it]Epoch: 6/10. Loss: 0.9618:  69%|[36m██████▉   [0m| 18/26 [00:18<00:08,  1.02s/it]Epoch: 6/10. Loss: 0.9618:  73%|[36m███████▎  [0m| 19/26 [00:18<00:07,  1.03s/it]Epoch: 6/10. Loss: 0.9035:  73%|[36m███████▎  [0m| 19/26 [00:19<00:07,  1.03s/it]Epoch: 6/10. Loss: 0.9035:  77%|[36m███████▋  [0m| 20/26 [00:19<00:05,  1.03it/s]Epoch: 6/10. Loss: 0.9344:  77%|[36m███████▋  [0m| 20/26 [00:20<00:05,  1.03it/s]Epoch: 6/10. Loss: 0.9344:  81%|[36m████████  [0m| 21/26 [00:20<00:04,  1.02it/s]Epoch: 6/10. Loss: 0.9954:  81%|[36m████████  [0m| 21/26 [00:21<00:04,  1.02it/s]Epoch: 6/10. Loss: 0.9954:  85%|[36m████████▍ [0m| 22/26 [00:21<00:04,  1.04s/it]Epoch: 6/10. Loss: 0.9313:  85%|[36m████████▍ [0m| 22/26 [00:23<00:04,  1.04s/it]Epoch: 6/10. Loss: 0.9313:  88%|[36m████████▊ [0m| 23/26 [00:23<00:03,  1.21s/it]Epoch: 6/10. Loss: 0.8893:  88%|[36m████████▊ [0m| 23/26 [00:24<00:03,  1.21s/it]Epoch: 6/10. Loss: 0.8893:  92%|[36m█████████▏[0m| 24/26 [00:24<00:02,  1.11s/it]Epoch: 6/10. Loss: 0.9266:  92%|[36m█████████▏[0m| 24/26 [00:26<00:02,  1.11s/it]Epoch: 6/10. Loss: 0.9266:  96%|[36m█████████▌[0m| 25/26 [00:26<00:01,  1.43s/it]Epoch: 6/10. Loss: 0.9139:  96%|[36m█████████▌[0m| 25/26 [00:26<00:01,  1.43s/it]Epoch: 6/10. Loss: 0.9139: 100%|[36m██████████[0m| 26/26 [00:27<00:00,  1.21s/it]Epoch: 6/10. Loss: 0.9139: 100%|[36m██████████[0m| 26/26 [00:27<00:00,  1.04s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:05,  1.02it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:05,  1.15s/it] 43%|[33m████▎     [0m| 3/7 [00:02<00:03,  1.06it/s] 57%|[33m█████▋    [0m| 4/7 [00:05<00:04,  1.42s/it] 71%|[33m███████▏  [0m| 5/7 [00:05<00:02,  1.06s/it] 86%|[33m████████▌ [0m| 6/7 [00:06<00:00,  1.05it/s]100%|[33m██████████[0m| 7/7 [00:06<00:00,  1.40it/s]100%|[33m██████████[0m| 7/7 [00:06<00:00,  1.08it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 7/10. Loss: 0.9457:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 7/10. Loss: 0.9457:   4%|[36m▍         [0m| 1/26 [00:00<00:21,  1.15it/s]Epoch: 7/10. Loss: 0.9890:   4%|[36m▍         [0m| 1/26 [00:02<00:21,  1.15it/s]Epoch: 7/10. Loss: 0.9890:   8%|[36m▊         [0m| 2/26 [00:02<00:26,  1.12s/it]Epoch: 7/10. Loss: 0.9792:   8%|[36m▊         [0m| 2/26 [00:02<00:26,  1.12s/it]Epoch: 7/10. Loss: 0.9792:  12%|[36m█▏        [0m| 3/26 [00:02<00:21,  1.05it/s]Epoch: 7/10. Loss: 0.9859:  12%|[36m█▏        [0m| 3/26 [00:03<00:21,  1.05it/s]Epoch: 7/10. Loss: 0.9859:  15%|[36m█▌        [0m| 4/26 [00:03<00:20,  1.06it/s]Epoch: 7/10. Loss: 0.8446:  15%|[36m█▌        [0m| 4/26 [00:04<00:20,  1.06it/s]Epoch: 7/10. Loss: 0.8446:  19%|[36m█▉        [0m| 5/26 [00:04<00:20,  1.04it/s]Epoch: 7/10. Loss: 0.9251:  19%|[36m█▉        [0m| 5/26 [00:05<00:20,  1.04it/s]Epoch: 7/10. Loss: 0.9251:  23%|[36m██▎       [0m| 6/26 [00:05<00:20,  1.01s/it]Epoch: 7/10. Loss: 0.8681:  23%|[36m██▎       [0m| 6/26 [00:06<00:20,  1.01s/it]Epoch: 7/10. Loss: 0.8681:  27%|[36m██▋       [0m| 7/26 [00:06<00:18,  1.04it/s]Epoch: 7/10. Loss: 0.9076:  27%|[36m██▋       [0m| 7/26 [00:07<00:18,  1.04it/s]Epoch: 7/10. Loss: 0.9076:  31%|[36m███       [0m| 8/26 [00:07<00:16,  1.07it/s]Epoch: 7/10. Loss: 0.9117:  31%|[36m███       [0m| 8/26 [00:09<00:16,  1.07it/s]Epoch: 7/10. Loss: 0.9117:  35%|[36m███▍      [0m| 9/26 [00:09<00:19,  1.13s/it]Epoch: 7/10. Loss: 0.9230:  35%|[36m███▍      [0m| 9/26 [00:10<00:19,  1.13s/it]Epoch: 7/10. Loss: 0.9230:  38%|[36m███▊      [0m| 10/26 [00:10<00:19,  1.22s/it]Epoch: 7/10. Loss: 0.8681:  38%|[36m███▊      [0m| 10/26 [00:11<00:19,  1.22s/it]Epoch: 7/10. Loss: 0.8681:  42%|[36m████▏     [0m| 11/26 [00:11<00:16,  1.08s/it]Epoch: 7/10. Loss: 0.7992:  42%|[36m████▏     [0m| 11/26 [00:12<00:16,  1.08s/it]Epoch: 7/10. Loss: 0.7992:  46%|[36m████▌     [0m| 12/26 [00:12<00:14,  1.06s/it]Epoch: 7/10. Loss: 0.9568:  46%|[36m████▌     [0m| 12/26 [00:13<00:14,  1.06s/it]Epoch: 7/10. Loss: 0.9568:  50%|[36m█████     [0m| 13/26 [00:13<00:12,  1.06it/s]Epoch: 7/10. Loss: 0.9877:  50%|[36m█████     [0m| 13/26 [00:14<00:12,  1.06it/s]Epoch: 7/10. Loss: 0.9877:  54%|[36m█████▍    [0m| 14/26 [00:14<00:11,  1.06it/s]Epoch: 7/10. Loss: 0.8393:  54%|[36m█████▍    [0m| 14/26 [00:14<00:11,  1.06it/s]Epoch: 7/10. Loss: 0.8393:  58%|[36m█████▊    [0m| 15/26 [00:14<00:10,  1.07it/s]Epoch: 7/10. Loss: 0.8161:  58%|[36m█████▊    [0m| 15/26 [00:15<00:10,  1.07it/s]Epoch: 7/10. Loss: 0.8161:  62%|[36m██████▏   [0m| 16/26 [00:15<00:09,  1.05it/s]Epoch: 7/10. Loss: 0.9179:  62%|[36m██████▏   [0m| 16/26 [00:17<00:09,  1.05it/s]Epoch: 7/10. Loss: 0.9179:  65%|[36m██████▌   [0m| 17/26 [00:17<00:08,  1.00it/s]Epoch: 7/10. Loss: 0.8544:  65%|[36m██████▌   [0m| 17/26 [00:18<00:08,  1.00it/s]Epoch: 7/10. Loss: 0.8544:  69%|[36m██████▉   [0m| 18/26 [00:18<00:08,  1.01s/it]Epoch: 7/10. Loss: 0.9255:  69%|[36m██████▉   [0m| 18/26 [00:19<00:08,  1.01s/it]Epoch: 7/10. Loss: 0.9255:  73%|[36m███████▎  [0m| 19/26 [00:19<00:07,  1.00s/it]Epoch: 7/10. Loss: 0.8861:  73%|[36m███████▎  [0m| 19/26 [00:20<00:07,  1.00s/it]Epoch: 7/10. Loss: 0.8861:  77%|[36m███████▋  [0m| 20/26 [00:20<00:05,  1.00it/s]Epoch: 7/10. Loss: 0.9583:  77%|[36m███████▋  [0m| 20/26 [00:20<00:05,  1.00it/s]Epoch: 7/10. Loss: 0.9583:  81%|[36m████████  [0m| 21/26 [00:20<00:04,  1.03it/s]Epoch: 7/10. Loss: 0.8514:  81%|[36m████████  [0m| 21/26 [00:21<00:04,  1.03it/s]Epoch: 7/10. Loss: 0.8514:  85%|[36m████████▍ [0m| 22/26 [00:21<00:03,  1.05it/s]Epoch: 7/10. Loss: 0.8904:  85%|[36m████████▍ [0m| 22/26 [00:22<00:03,  1.05it/s]Epoch: 7/10. Loss: 0.8904:  88%|[36m████████▊ [0m| 23/26 [00:22<00:02,  1.14it/s]Epoch: 7/10. Loss: 0.8760:  88%|[36m████████▊ [0m| 23/26 [00:23<00:02,  1.14it/s]Epoch: 7/10. Loss: 0.8760:  92%|[36m█████████▏[0m| 24/26 [00:23<00:01,  1.15it/s]Epoch: 7/10. Loss: 0.8807:  92%|[36m█████████▏[0m| 24/26 [00:24<00:01,  1.15it/s]Epoch: 7/10. Loss: 0.8807:  96%|[36m█████████▌[0m| 25/26 [00:24<00:00,  1.11it/s]Epoch: 7/10. Loss: 0.9629:  96%|[36m█████████▌[0m| 25/26 [00:25<00:00,  1.11it/s]Epoch: 7/10. Loss: 0.9629: 100%|[36m██████████[0m| 26/26 [00:25<00:00,  1.21it/s]Epoch: 7/10. Loss: 0.9629: 100%|[36m██████████[0m| 26/26 [00:25<00:00,  1.04it/s]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:01<00:06,  1.03s/it] 29%|[33m██▊       [0m| 2/7 [00:03<00:07,  1.59s/it] 43%|[33m████▎     [0m| 3/7 [00:03<00:04,  1.22s/it] 57%|[33m█████▋    [0m| 4/7 [00:05<00:03,  1.29s/it] 71%|[33m███████▏  [0m| 5/7 [00:05<00:01,  1.04it/s] 86%|[33m████████▌ [0m| 6/7 [00:06<00:00,  1.12it/s]100%|[33m██████████[0m| 7/7 [00:06<00:00,  1.47it/s]100%|[33m██████████[0m| 7/7 [00:06<00:00,  1.07it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 8/10. Loss: 0.8286:   0%|[36m          [0m| 0/26 [00:01<?, ?it/s]Epoch: 8/10. Loss: 0.8286:   4%|[36m▍         [0m| 1/26 [00:01<00:27,  1.08s/it]Epoch: 8/10. Loss: 0.8679:   4%|[36m▍         [0m| 1/26 [00:01<00:27,  1.08s/it]Epoch: 8/10. Loss: 0.8679:   8%|[36m▊         [0m| 2/26 [00:01<00:22,  1.06it/s]Epoch: 8/10. Loss: 0.8163:   8%|[36m▊         [0m| 2/26 [00:02<00:22,  1.06it/s]Epoch: 8/10. Loss: 0.8163:  12%|[36m█▏        [0m| 3/26 [00:02<00:22,  1.03it/s]Epoch: 8/10. Loss: 0.9192:  12%|[36m█▏        [0m| 3/26 [00:03<00:22,  1.03it/s]Epoch: 8/10. Loss: 0.9192:  15%|[36m█▌        [0m| 4/26 [00:03<00:20,  1.07it/s]Epoch: 8/10. Loss: 0.8654:  15%|[36m█▌        [0m| 4/26 [00:04<00:20,  1.07it/s]Epoch: 8/10. Loss: 0.8654:  19%|[36m█▉        [0m| 5/26 [00:04<00:17,  1.18it/s]Epoch: 8/10. Loss: 0.9739:  19%|[36m█▉        [0m| 5/26 [00:05<00:17,  1.18it/s]Epoch: 8/10. Loss: 0.9739:  23%|[36m██▎       [0m| 6/26 [00:05<00:18,  1.09it/s]Epoch: 8/10. Loss: 0.9109:  23%|[36m██▎       [0m| 6/26 [00:06<00:18,  1.09it/s]Epoch: 8/10. Loss: 0.9109:  27%|[36m██▋       [0m| 7/26 [00:06<00:17,  1.11it/s]Epoch: 8/10. Loss: 0.8749:  27%|[36m██▋       [0m| 7/26 [00:07<00:17,  1.11it/s]Epoch: 8/10. Loss: 0.8749:  31%|[36m███       [0m| 8/26 [00:07<00:16,  1.09it/s]Epoch: 8/10. Loss: 0.8857:  31%|[36m███       [0m| 8/26 [00:08<00:16,  1.09it/s]Epoch: 8/10. Loss: 0.8857:  35%|[36m███▍      [0m| 9/26 [00:08<00:15,  1.07it/s]Epoch: 8/10. Loss: 0.8977:  35%|[36m███▍      [0m| 9/26 [00:09<00:15,  1.07it/s]Epoch: 8/10. Loss: 0.8977:  38%|[36m███▊      [0m| 10/26 [00:09<00:15,  1.04it/s]Epoch: 8/10. Loss: 0.8850:  38%|[36m███▊      [0m| 10/26 [00:10<00:15,  1.04it/s]Epoch: 8/10. Loss: 0.8850:  42%|[36m████▏     [0m| 11/26 [00:10<00:14,  1.04it/s]Epoch: 8/10. Loss: 0.7935:  42%|[36m████▏     [0m| 11/26 [00:11<00:14,  1.04it/s]Epoch: 8/10. Loss: 0.7935:  46%|[36m████▌     [0m| 12/26 [00:11<00:13,  1.06it/s]Epoch: 8/10. Loss: 0.8593:  46%|[36m████▌     [0m| 12/26 [00:12<00:13,  1.06it/s]Epoch: 8/10. Loss: 0.8593:  50%|[36m█████     [0m| 13/26 [00:12<00:11,  1.10it/s]Epoch: 8/10. Loss: 0.8795:  50%|[36m█████     [0m| 13/26 [00:13<00:11,  1.10it/s]Epoch: 8/10. Loss: 0.8795:  54%|[36m█████▍    [0m| 14/26 [00:13<00:11,  1.04it/s]Epoch: 8/10. Loss: 0.9021:  54%|[36m█████▍    [0m| 14/26 [00:15<00:11,  1.04it/s]Epoch: 8/10. Loss: 0.9021:  58%|[36m█████▊    [0m| 15/26 [00:15<00:15,  1.41s/it]Epoch: 8/10. Loss: 0.8426:  58%|[36m█████▊    [0m| 15/26 [00:16<00:15,  1.41s/it]Epoch: 8/10. Loss: 0.8426:  62%|[36m██████▏   [0m| 16/26 [00:16<00:12,  1.28s/it]Epoch: 8/10. Loss: 0.9839:  62%|[36m██████▏   [0m| 16/26 [00:17<00:12,  1.28s/it]Epoch: 8/10. Loss: 0.9839:  65%|[36m██████▌   [0m| 17/26 [00:17<00:10,  1.15s/it]Epoch: 8/10. Loss: 0.8374:  65%|[36m██████▌   [0m| 17/26 [00:18<00:10,  1.15s/it]Epoch: 8/10. Loss: 0.8374:  69%|[36m██████▉   [0m| 18/26 [00:18<00:08,  1.09s/it]Epoch: 8/10. Loss: 0.9220:  69%|[36m██████▉   [0m| 18/26 [00:19<00:08,  1.09s/it]Epoch: 8/10. Loss: 0.9220:  73%|[36m███████▎  [0m| 19/26 [00:19<00:07,  1.02s/it]Epoch: 8/10. Loss: 0.8666:  73%|[36m███████▎  [0m| 19/26 [00:21<00:07,  1.02s/it]Epoch: 8/10. Loss: 0.8666:  77%|[36m███████▋  [0m| 20/26 [00:21<00:09,  1.54s/it]Epoch: 8/10. Loss: 0.8460:  77%|[36m███████▋  [0m| 20/26 [00:23<00:09,  1.54s/it]Epoch: 8/10. Loss: 0.8460:  81%|[36m████████  [0m| 21/26 [00:23<00:08,  1.68s/it]Epoch: 8/10. Loss: 0.8665:  81%|[36m████████  [0m| 21/26 [00:24<00:08,  1.68s/it]Epoch: 8/10. Loss: 0.8665:  85%|[36m████████▍ [0m| 22/26 [00:24<00:05,  1.44s/it]Epoch: 8/10. Loss: 0.9239:  85%|[36m████████▍ [0m| 22/26 [00:25<00:05,  1.44s/it]Epoch: 8/10. Loss: 0.9239:  88%|[36m████████▊ [0m| 23/26 [00:25<00:03,  1.24s/it]Epoch: 8/10. Loss: 0.9145:  88%|[36m████████▊ [0m| 23/26 [00:26<00:03,  1.24s/it]Epoch: 8/10. Loss: 0.9145:  92%|[36m█████████▏[0m| 24/26 [00:26<00:02,  1.09s/it]Epoch: 8/10. Loss: 0.7916:  92%|[36m█████████▏[0m| 24/26 [00:27<00:02,  1.09s/it]Epoch: 8/10. Loss: 0.7916:  96%|[36m█████████▌[0m| 25/26 [00:27<00:01,  1.02s/it]Epoch: 8/10. Loss: 0.9217:  96%|[36m█████████▌[0m| 25/26 [00:27<00:01,  1.02s/it]Epoch: 8/10. Loss: 0.9217: 100%|[36m██████████[0m| 26/26 [00:27<00:00,  1.09it/s]Epoch: 8/10. Loss: 0.9217: 100%|[36m██████████[0m| 26/26 [00:27<00:00,  1.07s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:02<00:13,  2.18s/it] 29%|[33m██▊       [0m| 2/7 [00:03<00:08,  1.72s/it] 43%|[33m████▎     [0m| 3/7 [00:04<00:05,  1.27s/it] 57%|[33m█████▋    [0m| 4/7 [00:05<00:04,  1.36s/it] 71%|[33m███████▏  [0m| 5/7 [00:06<00:02,  1.01s/it] 86%|[33m████████▌ [0m| 6/7 [00:07<00:01,  1.06s/it]100%|[33m██████████[0m| 7/7 [00:07<00:00,  1.26it/s]100%|[33m██████████[0m| 7/7 [00:07<00:00,  1.09s/it]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 9/10. Loss: 0.9355:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 9/10. Loss: 0.9355:   4%|[36m▍         [0m| 1/26 [00:00<00:21,  1.14it/s]Epoch: 9/10. Loss: 0.9206:   4%|[36m▍         [0m| 1/26 [00:01<00:21,  1.14it/s]Epoch: 9/10. Loss: 0.9206:   8%|[36m▊         [0m| 2/26 [00:01<00:22,  1.07it/s]Epoch: 9/10. Loss: 0.8443:   8%|[36m▊         [0m| 2/26 [00:03<00:22,  1.07it/s]Epoch: 9/10. Loss: 0.8443:  12%|[36m█▏        [0m| 3/26 [00:03<00:25,  1.09s/it]Epoch: 9/10. Loss: 0.8660:  12%|[36m█▏        [0m| 3/26 [00:03<00:25,  1.09s/it]Epoch: 9/10. Loss: 0.8660:  15%|[36m█▌        [0m| 4/26 [00:04<00:22,  1.01s/it]Epoch: 9/10. Loss: 0.8315:  15%|[36m█▌        [0m| 4/26 [00:04<00:22,  1.01s/it]Epoch: 9/10. Loss: 0.8315:  19%|[36m█▉        [0m| 5/26 [00:04<00:20,  1.05it/s]Epoch: 9/10. Loss: 0.8722:  19%|[36m█▉        [0m| 5/26 [00:05<00:20,  1.05it/s]Epoch: 9/10. Loss: 0.8722:  23%|[36m██▎       [0m| 6/26 [00:05<00:19,  1.03it/s]Epoch: 9/10. Loss: 0.9270:  23%|[36m██▎       [0m| 6/26 [00:06<00:19,  1.03it/s]Epoch: 9/10. Loss: 0.9270:  27%|[36m██▋       [0m| 7/26 [00:06<00:18,  1.04it/s]Epoch: 9/10. Loss: 0.9357:  27%|[36m██▋       [0m| 7/26 [00:08<00:18,  1.04it/s]Epoch: 9/10. Loss: 0.9357:  31%|[36m███       [0m| 8/26 [00:08<00:19,  1.06s/it]Epoch: 9/10. Loss: 0.8170:  31%|[36m███       [0m| 8/26 [00:09<00:19,  1.06s/it]Epoch: 9/10. Loss: 0.8170:  35%|[36m███▍      [0m| 9/26 [00:09<00:17,  1.04s/it]Epoch: 9/10. Loss: 0.8789:  35%|[36m███▍      [0m| 9/26 [00:09<00:17,  1.04s/it]Epoch: 9/10. Loss: 0.8789:  38%|[36m███▊      [0m| 10/26 [00:09<00:15,  1.01it/s]Epoch: 9/10. Loss: 0.9645:  38%|[36m███▊      [0m| 10/26 [00:10<00:15,  1.01it/s]Epoch: 9/10. Loss: 0.9645:  42%|[36m████▏     [0m| 11/26 [00:10<00:14,  1.04it/s]Epoch: 9/10. Loss: 0.7927:  42%|[36m████▏     [0m| 11/26 [00:11<00:14,  1.04it/s]Epoch: 9/10. Loss: 0.7927:  46%|[36m████▌     [0m| 12/26 [00:11<00:13,  1.02it/s]Epoch: 9/10. Loss: 0.7352:  46%|[36m████▌     [0m| 12/26 [00:12<00:13,  1.02it/s]Epoch: 9/10. Loss: 0.7352:  50%|[36m█████     [0m| 13/26 [00:12<00:11,  1.10it/s]Epoch: 9/10. Loss: 0.9215:  50%|[36m█████     [0m| 13/26 [00:15<00:11,  1.10it/s]Epoch: 9/10. Loss: 0.9215:  54%|[36m█████▍    [0m| 14/26 [00:15<00:18,  1.54s/it]Epoch: 9/10. Loss: 0.8376:  54%|[36m█████▍    [0m| 14/26 [00:16<00:18,  1.54s/it]Epoch: 9/10. Loss: 0.8376:  58%|[36m█████▊    [0m| 15/26 [00:16<00:14,  1.34s/it]Epoch: 9/10. Loss: 0.9405:  58%|[36m█████▊    [0m| 15/26 [00:17<00:14,  1.34s/it]Epoch: 9/10. Loss: 0.9405:  62%|[36m██████▏   [0m| 16/26 [00:17<00:12,  1.25s/it]Epoch: 9/10. Loss: 0.7840:  62%|[36m██████▏   [0m| 16/26 [00:18<00:12,  1.25s/it]Epoch: 9/10. Loss: 0.7840:  65%|[36m██████▌   [0m| 17/26 [00:18<00:11,  1.27s/it]Epoch: 9/10. Loss: 0.8839:  65%|[36m██████▌   [0m| 17/26 [00:19<00:11,  1.27s/it]Epoch: 9/10. Loss: 0.8839:  69%|[36m██████▉   [0m| 18/26 [00:19<00:08,  1.12s/it]Epoch: 9/10. Loss: 0.9128:  69%|[36m██████▉   [0m| 18/26 [00:20<00:08,  1.12s/it]Epoch: 9/10. Loss: 0.9128:  73%|[36m███████▎  [0m| 19/26 [00:20<00:07,  1.06s/it]Epoch: 9/10. Loss: 0.8547:  73%|[36m███████▎  [0m| 19/26 [00:21<00:07,  1.06s/it]Epoch: 9/10. Loss: 0.8547:  77%|[36m███████▋  [0m| 20/26 [00:21<00:05,  1.01it/s]Epoch: 9/10. Loss: 0.8709:  77%|[36m███████▋  [0m| 20/26 [00:22<00:05,  1.01it/s]Epoch: 9/10. Loss: 0.8709:  81%|[36m████████  [0m| 21/26 [00:22<00:05,  1.01s/it]Epoch: 9/10. Loss: 0.8833:  81%|[36m████████  [0m| 21/26 [00:23<00:05,  1.01s/it]Epoch: 9/10. Loss: 0.8833:  85%|[36m████████▍ [0m| 22/26 [00:23<00:04,  1.02s/it]Epoch: 9/10. Loss: 0.9148:  85%|[36m████████▍ [0m| 22/26 [00:24<00:04,  1.02s/it]Epoch: 9/10. Loss: 0.9148:  88%|[36m████████▊ [0m| 23/26 [00:24<00:02,  1.07it/s]Epoch: 9/10. Loss: 0.8828:  88%|[36m████████▊ [0m| 23/26 [00:25<00:02,  1.07it/s]Epoch: 9/10. Loss: 0.8828:  92%|[36m█████████▏[0m| 24/26 [00:25<00:01,  1.03it/s]Epoch: 9/10. Loss: 0.8725:  92%|[36m█████████▏[0m| 24/26 [00:26<00:01,  1.03it/s]Epoch: 9/10. Loss: 0.8725:  96%|[36m█████████▌[0m| 25/26 [00:26<00:00,  1.02it/s]Epoch: 9/10. Loss: 0.9077:  96%|[36m█████████▌[0m| 25/26 [00:26<00:00,  1.02it/s]Epoch: 9/10. Loss: 0.9077: 100%|[36m██████████[0m| 26/26 [00:26<00:00,  1.21it/s]Epoch: 9/10. Loss: 0.9077: 100%|[36m██████████[0m| 26/26 [00:26<00:00,  1.03s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:05,  1.13it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:05,  1.10s/it] 43%|[33m████▎     [0m| 3/7 [00:02<00:03,  1.07it/s] 57%|[33m█████▋    [0m| 4/7 [00:04<00:03,  1.10s/it] 71%|[33m███████▏  [0m| 5/7 [00:04<00:01,  1.17it/s] 86%|[33m████████▌ [0m| 6/7 [00:05<00:00,  1.20it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.55it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.23it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 0/10. Loss: 1.2541:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 0/10. Loss: 1.2541:   4%|[36m▍         [0m| 1/26 [00:00<00:19,  1.25it/s]Epoch: 0/10. Loss: 3.0456:   4%|[36m▍         [0m| 1/26 [00:01<00:19,  1.25it/s]Epoch: 0/10. Loss: 3.0456:   8%|[36m▊         [0m| 2/26 [00:01<00:19,  1.20it/s]Epoch: 0/10. Loss: 2.3065:   8%|[36m▊         [0m| 2/26 [00:02<00:19,  1.20it/s]Epoch: 0/10. Loss: 2.3065:  12%|[36m█▏        [0m| 3/26 [00:02<00:19,  1.20it/s]Epoch: 0/10. Loss: 1.9467:  12%|[36m█▏        [0m| 3/26 [00:03<00:19,  1.20it/s]Epoch: 0/10. Loss: 1.9467:  15%|[36m█▌        [0m| 4/26 [00:03<00:18,  1.20it/s]Epoch: 0/10. Loss: 1.7077:  15%|[36m█▌        [0m| 4/26 [00:04<00:18,  1.20it/s]Epoch: 0/10. Loss: 1.7077:  19%|[36m█▉        [0m| 5/26 [00:04<00:17,  1.17it/s]Epoch: 0/10. Loss: 1.1512:  19%|[36m█▉        [0m| 5/26 [00:04<00:17,  1.17it/s]Epoch: 0/10. Loss: 1.1512:  23%|[36m██▎       [0m| 6/26 [00:04<00:16,  1.24it/s]Epoch: 0/10. Loss: 1.0485:  23%|[36m██▎       [0m| 6/26 [00:05<00:16,  1.24it/s]Epoch: 0/10. Loss: 1.0485:  27%|[36m██▋       [0m| 7/26 [00:05<00:16,  1.16it/s]Epoch: 0/10. Loss: 1.1508:  27%|[36m██▋       [0m| 7/26 [00:07<00:16,  1.16it/s]Epoch: 0/10. Loss: 1.1508:  31%|[36m███       [0m| 8/26 [00:07<00:17,  1.05it/s]Epoch: 0/10. Loss: 1.0965:  31%|[36m███       [0m| 8/26 [00:07<00:17,  1.05it/s]Epoch: 0/10. Loss: 1.0965:  35%|[36m███▍      [0m| 9/26 [00:07<00:15,  1.08it/s]Epoch: 0/10. Loss: 1.0835:  35%|[36m███▍      [0m| 9/26 [00:09<00:15,  1.08it/s]Epoch: 0/10. Loss: 1.0835:  38%|[36m███▊      [0m| 10/26 [00:09<00:15,  1.00it/s]Epoch: 0/10. Loss: 1.1916:  38%|[36m███▊      [0m| 10/26 [00:09<00:15,  1.00it/s]Epoch: 0/10. Loss: 1.1916:  42%|[36m████▏     [0m| 11/26 [00:09<00:14,  1.03it/s]Epoch: 0/10. Loss: 1.2449:  42%|[36m████▏     [0m| 11/26 [00:11<00:14,  1.03it/s]Epoch: 0/10. Loss: 1.2449:  46%|[36m████▌     [0m| 12/26 [00:11<00:14,  1.04s/it]Epoch: 0/10. Loss: 1.1204:  46%|[36m████▌     [0m| 12/26 [00:12<00:14,  1.04s/it]Epoch: 0/10. Loss: 1.1204:  50%|[36m█████     [0m| 13/26 [00:12<00:12,  1.00it/s]Epoch: 0/10. Loss: 1.1675:  50%|[36m█████     [0m| 13/26 [00:12<00:12,  1.00it/s]Epoch: 0/10. Loss: 1.1675:  54%|[36m█████▍    [0m| 14/26 [00:12<00:11,  1.08it/s]Epoch: 0/10. Loss: 1.2141:  54%|[36m█████▍    [0m| 14/26 [00:14<00:11,  1.08it/s]Epoch: 0/10. Loss: 1.2141:  58%|[36m█████▊    [0m| 15/26 [00:14<00:11,  1.04s/it]Epoch: 0/10. Loss: 1.2045:  58%|[36m█████▊    [0m| 15/26 [00:15<00:11,  1.04s/it]Epoch: 0/10. Loss: 1.2045:  62%|[36m██████▏   [0m| 16/26 [00:15<00:10,  1.01s/it]Epoch: 0/10. Loss: 1.0127:  62%|[36m██████▏   [0m| 16/26 [00:16<00:10,  1.01s/it]Epoch: 0/10. Loss: 1.0127:  65%|[36m██████▌   [0m| 17/26 [00:16<00:08,  1.02it/s]Epoch: 0/10. Loss: 1.0802:  65%|[36m██████▌   [0m| 17/26 [00:17<00:08,  1.02it/s]Epoch: 0/10. Loss: 1.0802:  69%|[36m██████▉   [0m| 18/26 [00:17<00:08,  1.05s/it]Epoch: 0/10. Loss: 1.1320:  69%|[36m██████▉   [0m| 18/26 [00:17<00:08,  1.05s/it]Epoch: 0/10. Loss: 1.1320:  73%|[36m███████▎  [0m| 19/26 [00:17<00:06,  1.06it/s]Epoch: 0/10. Loss: 1.1874:  73%|[36m███████▎  [0m| 19/26 [00:18<00:06,  1.06it/s]Epoch: 0/10. Loss: 1.1874:  77%|[36m███████▋  [0m| 20/26 [00:18<00:05,  1.02it/s]Epoch: 0/10. Loss: 1.0668:  77%|[36m███████▋  [0m| 20/26 [00:19<00:05,  1.02it/s]Epoch: 0/10. Loss: 1.0668:  81%|[36m████████  [0m| 21/26 [00:19<00:04,  1.04it/s]Epoch: 0/10. Loss: 1.0909:  81%|[36m████████  [0m| 21/26 [00:20<00:04,  1.04it/s]Epoch: 0/10. Loss: 1.0909:  85%|[36m████████▍ [0m| 22/26 [00:20<00:03,  1.06it/s]Epoch: 0/10. Loss: 1.0269:  85%|[36m████████▍ [0m| 22/26 [00:21<00:03,  1.06it/s]Epoch: 0/10. Loss: 1.0269:  88%|[36m████████▊ [0m| 23/26 [00:21<00:02,  1.06it/s]Epoch: 0/10. Loss: 1.0942:  88%|[36m████████▊ [0m| 23/26 [00:22<00:02,  1.06it/s]Epoch: 0/10. Loss: 1.0942:  92%|[36m█████████▏[0m| 24/26 [00:22<00:01,  1.02it/s]Epoch: 0/10. Loss: 1.0326:  92%|[36m█████████▏[0m| 24/26 [00:23<00:01,  1.02it/s]Epoch: 0/10. Loss: 1.0326:  96%|[36m█████████▌[0m| 25/26 [00:23<00:00,  1.09it/s]Epoch: 0/10. Loss: 0.9790:  96%|[36m█████████▌[0m| 25/26 [00:24<00:00,  1.09it/s]Epoch: 0/10. Loss: 0.9790: 100%|[36m██████████[0m| 26/26 [00:24<00:00,  1.19it/s]Epoch: 0/10. Loss: 0.9790: 100%|[36m██████████[0m| 26/26 [00:24<00:00,  1.07it/s]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:05,  1.12it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:05,  1.07s/it] 43%|[33m████▎     [0m| 3/7 [00:02<00:03,  1.09it/s] 57%|[33m█████▋    [0m| 4/7 [00:04<00:03,  1.29s/it] 71%|[33m███████▏  [0m| 5/7 [00:05<00:01,  1.03it/s] 86%|[33m████████▌ [0m| 6/7 [00:05<00:00,  1.10it/s]100%|[33m██████████[0m| 7/7 [00:06<00:00,  1.44it/s]100%|[33m██████████[0m| 7/7 [00:06<00:00,  1.14it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 1/10. Loss: 1.1062:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 1/10. Loss: 1.1062:   4%|[36m▍         [0m| 1/26 [00:00<00:19,  1.26it/s]Epoch: 1/10. Loss: 0.9242:   4%|[36m▍         [0m| 1/26 [00:01<00:19,  1.26it/s]Epoch: 1/10. Loss: 0.9242:   8%|[36m▊         [0m| 2/26 [00:01<00:18,  1.32it/s]Epoch: 1/10. Loss: 1.1015:   8%|[36m▊         [0m| 2/26 [00:02<00:18,  1.32it/s]Epoch: 1/10. Loss: 1.1015:  12%|[36m█▏        [0m| 3/26 [00:02<00:18,  1.27it/s]Epoch: 1/10. Loss: 1.2370:  12%|[36m█▏        [0m| 3/26 [00:03<00:18,  1.27it/s]Epoch: 1/10. Loss: 1.2370:  15%|[36m█▌        [0m| 4/26 [00:03<00:18,  1.20it/s]Epoch: 1/10. Loss: 0.9848:  15%|[36m█▌        [0m| 4/26 [00:04<00:18,  1.20it/s]Epoch: 1/10. Loss: 0.9848:  19%|[36m█▉        [0m| 5/26 [00:04<00:18,  1.16it/s]Epoch: 1/10. Loss: 0.9930:  19%|[36m█▉        [0m| 5/26 [00:05<00:18,  1.16it/s]Epoch: 1/10. Loss: 0.9930:  23%|[36m██▎       [0m| 6/26 [00:05<00:17,  1.14it/s]Epoch: 1/10. Loss: 1.0663:  23%|[36m██▎       [0m| 6/26 [00:05<00:17,  1.14it/s]Epoch: 1/10. Loss: 1.0663:  27%|[36m██▋       [0m| 7/26 [00:05<00:16,  1.15it/s]Epoch: 1/10. Loss: 1.0343:  27%|[36m██▋       [0m| 7/26 [00:06<00:16,  1.15it/s]Epoch: 1/10. Loss: 1.0343:  31%|[36m███       [0m| 8/26 [00:06<00:16,  1.11it/s]Epoch: 1/10. Loss: 0.9978:  31%|[36m███       [0m| 8/26 [00:07<00:16,  1.11it/s]Epoch: 1/10. Loss: 0.9978:  35%|[36m███▍      [0m| 9/26 [00:07<00:15,  1.08it/s]Epoch: 1/10. Loss: 0.9907:  35%|[36m███▍      [0m| 9/26 [00:08<00:15,  1.08it/s]Epoch: 1/10. Loss: 0.9907:  38%|[36m███▊      [0m| 10/26 [00:08<00:14,  1.08it/s]Epoch: 1/10. Loss: 1.0136:  38%|[36m███▊      [0m| 10/26 [00:09<00:14,  1.08it/s]Epoch: 1/10. Loss: 1.0136:  42%|[36m████▏     [0m| 11/26 [00:09<00:14,  1.07it/s]Epoch: 1/10. Loss: 0.9241:  42%|[36m████▏     [0m| 11/26 [00:10<00:14,  1.07it/s]Epoch: 1/10. Loss: 0.9241:  46%|[36m████▌     [0m| 12/26 [00:10<00:13,  1.04it/s]Epoch: 1/10. Loss: 0.9611:  46%|[36m████▌     [0m| 12/26 [00:11<00:13,  1.04it/s]Epoch: 1/10. Loss: 0.9611:  50%|[36m█████     [0m| 13/26 [00:11<00:11,  1.12it/s]Epoch: 1/10. Loss: 0.9516:  50%|[36m█████     [0m| 13/26 [00:12<00:11,  1.12it/s]Epoch: 1/10. Loss: 0.9516:  54%|[36m█████▍    [0m| 14/26 [00:12<00:10,  1.15it/s]Epoch: 1/10. Loss: 1.2204:  54%|[36m█████▍    [0m| 14/26 [00:13<00:10,  1.15it/s]Epoch: 1/10. Loss: 1.2204:  58%|[36m█████▊    [0m| 15/26 [00:13<00:09,  1.11it/s]Epoch: 1/10. Loss: 1.1654:  58%|[36m█████▊    [0m| 15/26 [00:14<00:09,  1.11it/s]Epoch: 1/10. Loss: 1.1654:  62%|[36m██████▏   [0m| 16/26 [00:14<00:08,  1.13it/s]Epoch: 1/10. Loss: 0.9077:  62%|[36m██████▏   [0m| 16/26 [00:15<00:08,  1.13it/s]Epoch: 1/10. Loss: 0.9077:  65%|[36m██████▌   [0m| 17/26 [00:15<00:08,  1.08it/s]Epoch: 1/10. Loss: 0.9277:  65%|[36m██████▌   [0m| 17/26 [00:15<00:08,  1.08it/s]Epoch: 1/10. Loss: 0.9277:  69%|[36m██████▉   [0m| 18/26 [00:15<00:07,  1.12it/s]Epoch: 1/10. Loss: 1.0576:  69%|[36m██████▉   [0m| 18/26 [00:16<00:07,  1.12it/s]Epoch: 1/10. Loss: 1.0576:  73%|[36m███████▎  [0m| 19/26 [00:16<00:05,  1.18it/s]Epoch: 1/10. Loss: 1.2485:  73%|[36m███████▎  [0m| 19/26 [00:17<00:05,  1.18it/s]Epoch: 1/10. Loss: 1.2485:  77%|[36m███████▋  [0m| 20/26 [00:17<00:05,  1.14it/s]Epoch: 1/10. Loss: 1.1046:  77%|[36m███████▋  [0m| 20/26 [00:18<00:05,  1.14it/s]Epoch: 1/10. Loss: 1.1046:  81%|[36m████████  [0m| 21/26 [00:18<00:04,  1.11it/s]Epoch: 1/10. Loss: 0.9510:  81%|[36m████████  [0m| 21/26 [00:19<00:04,  1.11it/s]Epoch: 1/10. Loss: 0.9510:  85%|[36m████████▍ [0m| 22/26 [00:19<00:03,  1.07it/s]Epoch: 1/10. Loss: 0.9040:  85%|[36m████████▍ [0m| 22/26 [00:20<00:03,  1.07it/s]Epoch: 1/10. Loss: 0.9040:  88%|[36m████████▊ [0m| 23/26 [00:20<00:02,  1.05it/s]Epoch: 1/10. Loss: 1.0001:  88%|[36m████████▊ [0m| 23/26 [00:21<00:02,  1.05it/s]Epoch: 1/10. Loss: 1.0001:  92%|[36m█████████▏[0m| 24/26 [00:21<00:01,  1.07it/s]Epoch: 1/10. Loss: 1.0727:  92%|[36m█████████▏[0m| 24/26 [00:22<00:01,  1.07it/s]Epoch: 1/10. Loss: 1.0727:  96%|[36m█████████▌[0m| 25/26 [00:22<00:00,  1.08it/s]Epoch: 1/10. Loss: 1.0051:  96%|[36m█████████▌[0m| 25/26 [00:22<00:00,  1.08it/s]Epoch: 1/10. Loss: 1.0051: 100%|[36m██████████[0m| 26/26 [00:22<00:00,  1.26it/s]Epoch: 1/10. Loss: 1.0051: 100%|[36m██████████[0m| 26/26 [00:22<00:00,  1.13it/s]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:05,  1.11it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:05,  1.08s/it] 43%|[33m████▎     [0m| 3/7 [00:02<00:03,  1.08it/s] 57%|[33m█████▋    [0m| 4/7 [00:04<00:03,  1.10s/it] 71%|[33m███████▏  [0m| 5/7 [00:04<00:01,  1.18it/s] 86%|[33m████████▌ [0m| 6/7 [00:05<00:00,  1.21it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.56it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.24it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 2/10. Loss: 1.0139:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 2/10. Loss: 1.0139:   4%|[36m▍         [0m| 1/26 [00:00<00:19,  1.28it/s]Epoch: 2/10. Loss: 1.0518:   4%|[36m▍         [0m| 1/26 [00:01<00:19,  1.28it/s]Epoch: 2/10. Loss: 1.0518:   8%|[36m▊         [0m| 2/26 [00:01<00:20,  1.19it/s]Epoch: 2/10. Loss: 0.9455:   8%|[36m▊         [0m| 2/26 [00:02<00:20,  1.19it/s]Epoch: 2/10. Loss: 0.9455:  12%|[36m█▏        [0m| 3/26 [00:02<00:20,  1.11it/s]Epoch: 2/10. Loss: 1.0177:  12%|[36m█▏        [0m| 3/26 [00:03<00:20,  1.11it/s]Epoch: 2/10. Loss: 1.0177:  15%|[36m█▌        [0m| 4/26 [00:03<00:20,  1.09it/s]Epoch: 2/10. Loss: 0.9130:  15%|[36m█▌        [0m| 4/26 [00:04<00:20,  1.09it/s]Epoch: 2/10. Loss: 0.9130:  19%|[36m█▉        [0m| 5/26 [00:04<00:19,  1.08it/s]Epoch: 2/10. Loss: 0.9441:  19%|[36m█▉        [0m| 5/26 [00:05<00:19,  1.08it/s]Epoch: 2/10. Loss: 0.9441:  23%|[36m██▎       [0m| 6/26 [00:05<00:17,  1.14it/s]Epoch: 2/10. Loss: 0.9510:  23%|[36m██▎       [0m| 6/26 [00:06<00:17,  1.14it/s]Epoch: 2/10. Loss: 0.9510:  27%|[36m██▋       [0m| 7/26 [00:06<00:17,  1.08it/s]Epoch: 2/10. Loss: 1.0271:  27%|[36m██▋       [0m| 7/26 [00:07<00:17,  1.08it/s]Epoch: 2/10. Loss: 1.0271:  31%|[36m███       [0m| 8/26 [00:07<00:16,  1.08it/s]Epoch: 2/10. Loss: 0.9057:  31%|[36m███       [0m| 8/26 [00:08<00:16,  1.08it/s]Epoch: 2/10. Loss: 0.9057:  35%|[36m███▍      [0m| 9/26 [00:08<00:15,  1.13it/s]Epoch: 2/10. Loss: 0.9556:  35%|[36m███▍      [0m| 9/26 [00:08<00:15,  1.13it/s]Epoch: 2/10. Loss: 0.9556:  38%|[36m███▊      [0m| 10/26 [00:08<00:14,  1.11it/s]Epoch: 2/10. Loss: 0.9489:  38%|[36m███▊      [0m| 10/26 [00:09<00:14,  1.11it/s]Epoch: 2/10. Loss: 0.9489:  42%|[36m████▏     [0m| 11/26 [00:09<00:13,  1.12it/s]Epoch: 2/10. Loss: 1.0104:  42%|[36m████▏     [0m| 11/26 [00:11<00:13,  1.12it/s]Epoch: 2/10. Loss: 1.0104:  46%|[36m████▌     [0m| 12/26 [00:11<00:14,  1.01s/it]Epoch: 2/10. Loss: 1.0048:  46%|[36m████▌     [0m| 12/26 [00:11<00:14,  1.01s/it]Epoch: 2/10. Loss: 1.0048:  50%|[36m█████     [0m| 13/26 [00:11<00:12,  1.05it/s]Epoch: 2/10. Loss: 0.8355:  50%|[36m█████     [0m| 13/26 [00:12<00:12,  1.05it/s]Epoch: 2/10. Loss: 0.8355:  54%|[36m█████▍    [0m| 14/26 [00:12<00:11,  1.08it/s]Epoch: 2/10. Loss: 0.9628:  54%|[36m█████▍    [0m| 14/26 [00:13<00:11,  1.08it/s]Epoch: 2/10. Loss: 0.9628:  58%|[36m█████▊    [0m| 15/26 [00:13<00:09,  1.14it/s]Epoch: 2/10. Loss: 0.8988:  58%|[36m█████▊    [0m| 15/26 [00:14<00:09,  1.14it/s]Epoch: 2/10. Loss: 0.8988:  62%|[36m██████▏   [0m| 16/26 [00:14<00:08,  1.18it/s]Epoch: 2/10. Loss: 0.8886:  62%|[36m██████▏   [0m| 16/26 [00:15<00:08,  1.18it/s]Epoch: 2/10. Loss: 0.8886:  65%|[36m██████▌   [0m| 17/26 [00:15<00:07,  1.21it/s]Epoch: 2/10. Loss: 0.8241:  65%|[36m██████▌   [0m| 17/26 [00:15<00:07,  1.21it/s]Epoch: 2/10. Loss: 0.8241:  69%|[36m██████▉   [0m| 18/26 [00:15<00:06,  1.22it/s]Epoch: 2/10. Loss: 0.9146:  69%|[36m██████▉   [0m| 18/26 [00:16<00:06,  1.22it/s]Epoch: 2/10. Loss: 0.9146:  73%|[36m███████▎  [0m| 19/26 [00:16<00:05,  1.20it/s]Epoch: 2/10. Loss: 0.9028:  73%|[36m███████▎  [0m| 19/26 [00:17<00:05,  1.20it/s]Epoch: 2/10. Loss: 0.9028:  77%|[36m███████▋  [0m| 20/26 [00:17<00:05,  1.20it/s]Epoch: 2/10. Loss: 0.8882:  77%|[36m███████▋  [0m| 20/26 [00:19<00:05,  1.20it/s]Epoch: 2/10. Loss: 0.8882:  81%|[36m████████  [0m| 21/26 [00:19<00:06,  1.22s/it]Epoch: 2/10. Loss: 0.8913:  81%|[36m████████  [0m| 21/26 [00:20<00:06,  1.22s/it]Epoch: 2/10. Loss: 0.8913:  85%|[36m████████▍ [0m| 22/26 [00:20<00:04,  1.09s/it]Epoch: 2/10. Loss: 0.9720:  85%|[36m████████▍ [0m| 22/26 [00:22<00:04,  1.09s/it]Epoch: 2/10. Loss: 0.9720:  88%|[36m████████▊ [0m| 23/26 [00:22<00:04,  1.50s/it]Epoch: 2/10. Loss: 0.8629:  88%|[36m████████▊ [0m| 23/26 [00:23<00:04,  1.50s/it]Epoch: 2/10. Loss: 0.8629:  92%|[36m█████████▏[0m| 24/26 [00:23<00:02,  1.33s/it]Epoch: 2/10. Loss: 0.9711:  92%|[36m█████████▏[0m| 24/26 [00:26<00:02,  1.33s/it]Epoch: 2/10. Loss: 0.9711:  96%|[36m█████████▌[0m| 25/26 [00:26<00:01,  1.68s/it]Epoch: 2/10. Loss: 0.8831:  96%|[36m█████████▌[0m| 25/26 [00:28<00:01,  1.68s/it]Epoch: 2/10. Loss: 0.8831: 100%|[36m██████████[0m| 26/26 [00:28<00:00,  1.93s/it]Epoch: 2/10. Loss: 0.8831: 100%|[36m██████████[0m| 26/26 [00:28<00:00,  1.11s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:05,  1.07it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:05,  1.19s/it] 43%|[33m████▎     [0m| 3/7 [00:03<00:03,  1.02it/s] 57%|[33m█████▋    [0m| 4/7 [00:04<00:03,  1.18s/it] 71%|[33m███████▏  [0m| 5/7 [00:04<00:01,  1.11it/s] 86%|[33m████████▌ [0m| 6/7 [00:05<00:00,  1.16it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.51it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.18it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 3/10. Loss: 0.8903:   0%|[36m          [0m| 0/26 [00:01<?, ?it/s]Epoch: 3/10. Loss: 0.8903:   4%|[36m▍         [0m| 1/26 [00:01<00:25,  1.01s/it]Epoch: 3/10. Loss: 0.8134:   4%|[36m▍         [0m| 1/26 [00:02<00:25,  1.01s/it]Epoch: 3/10. Loss: 0.8134:   8%|[36m▊         [0m| 2/26 [00:02<00:25,  1.05s/it]Epoch: 3/10. Loss: 0.9188:   8%|[36m▊         [0m| 2/26 [00:02<00:25,  1.05s/it]Epoch: 3/10. Loss: 0.9188:  12%|[36m█▏        [0m| 3/26 [00:02<00:20,  1.12it/s]Epoch: 3/10. Loss: 0.8915:  12%|[36m█▏        [0m| 3/26 [00:03<00:20,  1.12it/s]Epoch: 3/10. Loss: 0.8915:  15%|[36m█▌        [0m| 4/26 [00:03<00:20,  1.06it/s]Epoch: 3/10. Loss: 0.8929:  15%|[36m█▌        [0m| 4/26 [00:04<00:20,  1.06it/s]Epoch: 3/10. Loss: 0.8929:  19%|[36m█▉        [0m| 5/26 [00:04<00:19,  1.08it/s]Epoch: 3/10. Loss: 0.8592:  19%|[36m█▉        [0m| 5/26 [00:05<00:19,  1.08it/s]Epoch: 3/10. Loss: 0.8592:  23%|[36m██▎       [0m| 6/26 [00:05<00:19,  1.02it/s]Epoch: 3/10. Loss: 1.0899:  23%|[36m██▎       [0m| 6/26 [00:06<00:19,  1.02it/s]Epoch: 3/10. Loss: 1.0899:  27%|[36m██▋       [0m| 7/26 [00:06<00:18,  1.05it/s]Epoch: 3/10. Loss: 0.9363:  27%|[36m██▋       [0m| 7/26 [00:07<00:18,  1.05it/s]Epoch: 3/10. Loss: 0.9363:  31%|[36m███       [0m| 8/26 [00:07<00:16,  1.10it/s]Epoch: 3/10. Loss: 1.0123:  31%|[36m███       [0m| 8/26 [00:08<00:16,  1.10it/s]Epoch: 3/10. Loss: 1.0123:  35%|[36m███▍      [0m| 9/26 [00:08<00:15,  1.10it/s]Epoch: 3/10. Loss: 0.8496:  35%|[36m███▍      [0m| 9/26 [00:09<00:15,  1.10it/s]Epoch: 3/10. Loss: 0.8496:  38%|[36m███▊      [0m| 10/26 [00:09<00:15,  1.04it/s]Epoch: 3/10. Loss: 0.9005:  38%|[36m███▊      [0m| 10/26 [00:10<00:15,  1.04it/s]Epoch: 3/10. Loss: 0.9005:  42%|[36m████▏     [0m| 11/26 [00:10<00:14,  1.07it/s]Epoch: 3/10. Loss: 0.9732:  42%|[36m████▏     [0m| 11/26 [00:11<00:14,  1.07it/s]Epoch: 3/10. Loss: 0.9732:  46%|[36m████▌     [0m| 12/26 [00:11<00:12,  1.08it/s]Epoch: 3/10. Loss: 0.8397:  46%|[36m████▌     [0m| 12/26 [00:12<00:12,  1.08it/s]Epoch: 3/10. Loss: 0.8397:  50%|[36m█████     [0m| 13/26 [00:12<00:11,  1.09it/s]Epoch: 3/10. Loss: 0.9466:  50%|[36m█████     [0m| 13/26 [00:13<00:11,  1.09it/s]Epoch: 3/10. Loss: 0.9466:  54%|[36m█████▍    [0m| 14/26 [00:13<00:10,  1.10it/s]Epoch: 3/10. Loss: 1.0638:  54%|[36m█████▍    [0m| 14/26 [00:13<00:10,  1.10it/s]Epoch: 3/10. Loss: 1.0638:  58%|[36m█████▊    [0m| 15/26 [00:13<00:09,  1.14it/s]Epoch: 3/10. Loss: 0.9640:  58%|[36m█████▊    [0m| 15/26 [00:14<00:09,  1.14it/s]Epoch: 3/10. Loss: 0.9640:  62%|[36m██████▏   [0m| 16/26 [00:14<00:08,  1.17it/s]Epoch: 3/10. Loss: 0.9107:  62%|[36m██████▏   [0m| 16/26 [00:15<00:08,  1.17it/s]Epoch: 3/10. Loss: 0.9107:  65%|[36m██████▌   [0m| 17/26 [00:15<00:07,  1.25it/s]Epoch: 3/10. Loss: 0.8091:  65%|[36m██████▌   [0m| 17/26 [00:16<00:07,  1.25it/s]Epoch: 3/10. Loss: 0.8091:  69%|[36m██████▉   [0m| 18/26 [00:16<00:06,  1.19it/s]Epoch: 3/10. Loss: 0.9179:  69%|[36m██████▉   [0m| 18/26 [00:17<00:06,  1.19it/s]Epoch: 3/10. Loss: 0.9179:  73%|[36m███████▎  [0m| 19/26 [00:17<00:05,  1.18it/s]Epoch: 3/10. Loss: 0.9015:  73%|[36m███████▎  [0m| 19/26 [00:18<00:05,  1.18it/s]Epoch: 3/10. Loss: 0.9015:  77%|[36m███████▋  [0m| 20/26 [00:18<00:05,  1.14it/s]Epoch: 3/10. Loss: 0.8486:  77%|[36m███████▋  [0m| 20/26 [00:19<00:05,  1.14it/s]Epoch: 3/10. Loss: 0.8486:  81%|[36m████████  [0m| 21/26 [00:19<00:05,  1.11s/it]Epoch: 3/10. Loss: 0.9247:  81%|[36m████████  [0m| 21/26 [00:20<00:05,  1.11s/it]Epoch: 3/10. Loss: 0.9247:  85%|[36m████████▍ [0m| 22/26 [00:20<00:04,  1.01s/it]Epoch: 3/10. Loss: 0.9408:  85%|[36m████████▍ [0m| 22/26 [00:21<00:04,  1.01s/it]Epoch: 3/10. Loss: 0.9408:  88%|[36m████████▊ [0m| 23/26 [00:21<00:02,  1.03it/s]Epoch: 3/10. Loss: 0.9218:  88%|[36m████████▊ [0m| 23/26 [00:22<00:02,  1.03it/s]Epoch: 3/10. Loss: 0.9218:  92%|[36m█████████▏[0m| 24/26 [00:22<00:01,  1.05it/s]Epoch: 3/10. Loss: 0.9208:  92%|[36m█████████▏[0m| 24/26 [00:23<00:01,  1.05it/s]Epoch: 3/10. Loss: 0.9208:  96%|[36m█████████▌[0m| 25/26 [00:23<00:00,  1.14it/s]Epoch: 3/10. Loss: 0.8264:  96%|[36m█████████▌[0m| 25/26 [00:23<00:00,  1.14it/s]Epoch: 3/10. Loss: 0.8264: 100%|[36m██████████[0m| 26/26 [00:23<00:00,  1.22it/s]Epoch: 3/10. Loss: 0.8264: 100%|[36m██████████[0m| 26/26 [00:23<00:00,  1.10it/s]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:05,  1.07it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:05,  1.19s/it] 43%|[33m████▎     [0m| 3/7 [00:03<00:04,  1.03s/it] 57%|[33m█████▋    [0m| 4/7 [00:04<00:03,  1.23s/it] 71%|[33m███████▏  [0m| 5/7 [00:05<00:01,  1.06it/s] 86%|[33m████████▌ [0m| 6/7 [00:07<00:01,  1.32s/it]100%|[33m██████████[0m| 7/7 [00:07<00:00,  1.03it/s]100%|[33m██████████[0m| 7/7 [00:07<00:00,  1.06s/it]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 4/10. Loss: 0.9411:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 4/10. Loss: 0.9411:   4%|[36m▍         [0m| 1/26 [00:00<00:24,  1.03it/s]Epoch: 4/10. Loss: 0.9579:   4%|[36m▍         [0m| 1/26 [00:03<00:24,  1.03it/s]Epoch: 4/10. Loss: 0.9579:   8%|[36m▊         [0m| 2/26 [00:03<00:44,  1.85s/it]Epoch: 4/10. Loss: 0.8452:   8%|[36m▊         [0m| 2/26 [00:04<00:44,  1.85s/it]Epoch: 4/10. Loss: 0.8452:  12%|[36m█▏        [0m| 3/26 [00:04<00:37,  1.61s/it]Epoch: 4/10. Loss: 1.0507:  12%|[36m█▏        [0m| 3/26 [00:05<00:37,  1.61s/it]Epoch: 4/10. Loss: 1.0507:  15%|[36m█▌        [0m| 4/26 [00:05<00:29,  1.36s/it]Epoch: 4/10. Loss: 1.0130:  15%|[36m█▌        [0m| 4/26 [00:06<00:29,  1.36s/it]Epoch: 4/10. Loss: 1.0130:  19%|[36m█▉        [0m| 5/26 [00:06<00:24,  1.18s/it]Epoch: 4/10. Loss: 0.8407:  19%|[36m█▉        [0m| 5/26 [00:07<00:24,  1.18s/it]Epoch: 4/10. Loss: 0.8407:  23%|[36m██▎       [0m| 6/26 [00:07<00:20,  1.01s/it]Epoch: 4/10. Loss: 0.9695:  23%|[36m██▎       [0m| 6/26 [00:08<00:20,  1.01s/it]Epoch: 4/10. Loss: 0.9695:  27%|[36m██▋       [0m| 7/26 [00:08<00:18,  1.03it/s]Epoch: 4/10. Loss: 0.8030:  27%|[36m██▋       [0m| 7/26 [00:08<00:18,  1.03it/s]Epoch: 4/10. Loss: 0.8030:  31%|[36m███       [0m| 8/26 [00:08<00:15,  1.13it/s]Epoch: 4/10. Loss: 0.8741:  31%|[36m███       [0m| 8/26 [00:11<00:15,  1.13it/s]Epoch: 4/10. Loss: 0.8741:  35%|[36m███▍      [0m| 9/26 [00:11<00:25,  1.50s/it]Epoch: 4/10. Loss: 0.8814:  35%|[36m███▍      [0m| 9/26 [00:13<00:25,  1.50s/it]Epoch: 4/10. Loss: 0.8814:  38%|[36m███▊      [0m| 10/26 [00:13<00:24,  1.55s/it]Epoch: 4/10. Loss: 0.8899:  38%|[36m███▊      [0m| 10/26 [00:14<00:24,  1.55s/it]Epoch: 4/10. Loss: 0.8899:  42%|[36m████▏     [0m| 11/26 [00:14<00:20,  1.37s/it]Epoch: 4/10. Loss: 1.0044:  42%|[36m████▏     [0m| 11/26 [00:15<00:20,  1.37s/it]Epoch: 4/10. Loss: 1.0044:  46%|[36m████▌     [0m| 12/26 [00:15<00:16,  1.17s/it]Epoch: 4/10. Loss: 0.8990:  46%|[36m████▌     [0m| 12/26 [00:15<00:16,  1.17s/it]Epoch: 4/10. Loss: 0.8990:  50%|[36m█████     [0m| 13/26 [00:15<00:13,  1.05s/it]Epoch: 4/10. Loss: 0.8724:  50%|[36m█████     [0m| 13/26 [00:16<00:13,  1.05s/it]Epoch: 4/10. Loss: 0.8724:  54%|[36m█████▍    [0m| 14/26 [00:16<00:11,  1.06it/s]Epoch: 4/10. Loss: 0.8562:  54%|[36m█████▍    [0m| 14/26 [00:17<00:11,  1.06it/s]Epoch: 4/10. Loss: 0.8562:  58%|[36m█████▊    [0m| 15/26 [00:17<00:09,  1.12it/s]Epoch: 4/10. Loss: 0.9441:  58%|[36m█████▊    [0m| 15/26 [00:18<00:09,  1.12it/s]Epoch: 4/10. Loss: 0.9441:  62%|[36m██████▏   [0m| 16/26 [00:18<00:08,  1.13it/s]Epoch: 4/10. Loss: 0.8968:  62%|[36m██████▏   [0m| 16/26 [00:19<00:08,  1.13it/s]Epoch: 4/10. Loss: 0.8968:  65%|[36m██████▌   [0m| 17/26 [00:19<00:07,  1.14it/s]Epoch: 4/10. Loss: 0.8045:  65%|[36m██████▌   [0m| 17/26 [00:20<00:07,  1.14it/s]Epoch: 4/10. Loss: 0.8045:  69%|[36m██████▉   [0m| 18/26 [00:20<00:07,  1.10it/s]Epoch: 4/10. Loss: 0.9007:  69%|[36m██████▉   [0m| 18/26 [00:20<00:07,  1.10it/s]Epoch: 4/10. Loss: 0.9007:  73%|[36m███████▎  [0m| 19/26 [00:20<00:06,  1.16it/s]Epoch: 4/10. Loss: 0.8258:  73%|[36m███████▎  [0m| 19/26 [00:21<00:06,  1.16it/s]Epoch: 4/10. Loss: 0.8258:  77%|[36m███████▋  [0m| 20/26 [00:21<00:05,  1.09it/s]Epoch: 4/10. Loss: 0.8582:  77%|[36m███████▋  [0m| 20/26 [00:23<00:05,  1.09it/s]Epoch: 4/10. Loss: 0.8582:  81%|[36m████████  [0m| 21/26 [00:23<00:05,  1.00s/it]Epoch: 4/10. Loss: 0.8683:  81%|[36m████████  [0m| 21/26 [00:23<00:05,  1.00s/it]Epoch: 4/10. Loss: 0.8683:  85%|[36m████████▍ [0m| 22/26 [00:23<00:03,  1.04it/s]Epoch: 4/10. Loss: 0.8606:  85%|[36m████████▍ [0m| 22/26 [00:25<00:03,  1.04it/s]Epoch: 4/10. Loss: 0.8606:  88%|[36m████████▊ [0m| 23/26 [00:25<00:03,  1.03s/it]Epoch: 4/10. Loss: 0.8796:  88%|[36m████████▊ [0m| 23/26 [00:25<00:03,  1.03s/it]Epoch: 4/10. Loss: 0.8796:  92%|[36m█████████▏[0m| 24/26 [00:25<00:01,  1.02it/s]Epoch: 4/10. Loss: 0.8736:  92%|[36m█████████▏[0m| 24/26 [00:26<00:01,  1.02it/s]Epoch: 4/10. Loss: 0.8736:  96%|[36m█████████▌[0m| 25/26 [00:26<00:00,  1.06it/s]Epoch: 4/10. Loss: 0.9371:  96%|[36m█████████▌[0m| 25/26 [00:27<00:00,  1.06it/s]Epoch: 4/10. Loss: 0.9371: 100%|[36m██████████[0m| 26/26 [00:27<00:00,  1.18it/s]Epoch: 4/10. Loss: 0.9371: 100%|[36m██████████[0m| 26/26 [00:27<00:00,  1.05s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:05,  1.09it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:06,  1.29s/it] 43%|[33m████▎     [0m| 3/7 [00:03<00:04,  1.11s/it] 57%|[33m█████▋    [0m| 4/7 [00:04<00:03,  1.22s/it] 71%|[33m███████▏  [0m| 5/7 [00:05<00:01,  1.05it/s] 86%|[33m████████▌ [0m| 6/7 [00:06<00:00,  1.11it/s]100%|[33m██████████[0m| 7/7 [00:06<00:00,  1.46it/s]100%|[33m██████████[0m| 7/7 [00:06<00:00,  1.12it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 5/10. Loss: 0.9505:   0%|[36m          [0m| 0/26 [00:03<?, ?it/s]Epoch: 5/10. Loss: 0.9505:   4%|[36m▍         [0m| 1/26 [00:03<01:27,  3.49s/it]Epoch: 5/10. Loss: 0.8653:   4%|[36m▍         [0m| 1/26 [00:05<01:27,  3.49s/it]Epoch: 5/10. Loss: 0.8653:   8%|[36m▊         [0m| 2/26 [00:05<01:07,  2.83s/it]Epoch: 5/10. Loss: 0.8055:   8%|[36m▊         [0m| 2/26 [00:06<01:07,  2.83s/it]Epoch: 5/10. Loss: 0.8055:  12%|[36m█▏        [0m| 3/26 [00:06<00:43,  1.91s/it]Epoch: 5/10. Loss: 0.8607:  12%|[36m█▏        [0m| 3/26 [00:07<00:43,  1.91s/it]Epoch: 5/10. Loss: 0.8607:  15%|[36m█▌        [0m| 4/26 [00:07<00:32,  1.46s/it]Epoch: 5/10. Loss: 0.8422:  15%|[36m█▌        [0m| 4/26 [00:08<00:32,  1.46s/it]Epoch: 5/10. Loss: 0.8422:  19%|[36m█▉        [0m| 5/26 [00:08<00:27,  1.31s/it]Epoch: 5/10. Loss: 0.9718:  19%|[36m█▉        [0m| 5/26 [00:09<00:27,  1.31s/it]Epoch: 5/10. Loss: 0.9718:  23%|[36m██▎       [0m| 6/26 [00:09<00:22,  1.14s/it]Epoch: 5/10. Loss: 0.8453:  23%|[36m██▎       [0m| 6/26 [00:10<00:22,  1.14s/it]Epoch: 5/10. Loss: 0.8453:  27%|[36m██▋       [0m| 7/26 [00:10<00:19,  1.04s/it]Epoch: 5/10. Loss: 0.9517:  27%|[36m██▋       [0m| 7/26 [00:11<00:19,  1.04s/it]Epoch: 5/10. Loss: 0.9517:  31%|[36m███       [0m| 8/26 [00:11<00:19,  1.11s/it]Epoch: 5/10. Loss: 0.8908:  31%|[36m███       [0m| 8/26 [00:12<00:19,  1.11s/it]Epoch: 5/10. Loss: 0.8908:  35%|[36m███▍      [0m| 9/26 [00:12<00:17,  1.00s/it]Epoch: 5/10. Loss: 0.9514:  35%|[36m███▍      [0m| 9/26 [00:13<00:17,  1.00s/it]Epoch: 5/10. Loss: 0.9514:  38%|[36m███▊      [0m| 10/26 [00:13<00:16,  1.01s/it]Epoch: 5/10. Loss: 0.8970:  38%|[36m███▊      [0m| 10/26 [00:13<00:16,  1.01s/it]Epoch: 5/10. Loss: 0.8970:  42%|[36m████▏     [0m| 11/26 [00:13<00:13,  1.12it/s]Epoch: 5/10. Loss: 0.8245:  42%|[36m████▏     [0m| 11/26 [00:14<00:13,  1.12it/s]Epoch: 5/10. Loss: 0.8245:  46%|[36m████▌     [0m| 12/26 [00:14<00:12,  1.14it/s]Epoch: 5/10. Loss: 0.8417:  46%|[36m████▌     [0m| 12/26 [00:15<00:12,  1.14it/s]Epoch: 5/10. Loss: 0.8417:  50%|[36m█████     [0m| 13/26 [00:15<00:11,  1.17it/s]Epoch: 5/10. Loss: 0.9064:  50%|[36m█████     [0m| 13/26 [00:17<00:11,  1.17it/s]Epoch: 5/10. Loss: 0.9064:  54%|[36m█████▍    [0m| 14/26 [00:17<00:15,  1.32s/it]Epoch: 5/10. Loss: 0.8924:  54%|[36m█████▍    [0m| 14/26 [00:20<00:15,  1.32s/it]Epoch: 5/10. Loss: 0.8924:  58%|[36m█████▊    [0m| 15/26 [00:20<00:19,  1.80s/it]Epoch: 5/10. Loss: 0.8620:  58%|[36m█████▊    [0m| 15/26 [00:22<00:19,  1.80s/it]Epoch: 5/10. Loss: 0.8620:  62%|[36m██████▏   [0m| 16/26 [00:22<00:18,  1.80s/it]Epoch: 5/10. Loss: 0.9374:  62%|[36m██████▏   [0m| 16/26 [00:23<00:18,  1.80s/it]Epoch: 5/10. Loss: 0.9374:  65%|[36m██████▌   [0m| 17/26 [00:23<00:14,  1.60s/it]Epoch: 5/10. Loss: 0.8204:  65%|[36m██████▌   [0m| 17/26 [00:24<00:14,  1.60s/it]Epoch: 5/10. Loss: 0.8204:  69%|[36m██████▉   [0m| 18/26 [00:24<00:10,  1.37s/it]Epoch: 5/10. Loss: 0.8665:  69%|[36m██████▉   [0m| 18/26 [00:25<00:10,  1.37s/it]Epoch: 5/10. Loss: 0.8665:  73%|[36m███████▎  [0m| 19/26 [00:25<00:09,  1.33s/it]Epoch: 5/10. Loss: 0.9088:  73%|[36m███████▎  [0m| 19/26 [00:26<00:09,  1.33s/it]Epoch: 5/10. Loss: 0.9088:  77%|[36m███████▋  [0m| 20/26 [00:26<00:07,  1.23s/it]Epoch: 5/10. Loss: 0.9044:  77%|[36m███████▋  [0m| 20/26 [00:27<00:07,  1.23s/it]Epoch: 5/10. Loss: 0.9044:  81%|[36m████████  [0m| 21/26 [00:27<00:05,  1.19s/it]Epoch: 5/10. Loss: 0.8814:  81%|[36m████████  [0m| 21/26 [00:28<00:05,  1.19s/it]Epoch: 5/10. Loss: 0.8814:  85%|[36m████████▍ [0m| 22/26 [00:28<00:04,  1.11s/it]Epoch: 5/10. Loss: 0.8593:  85%|[36m████████▍ [0m| 22/26 [00:29<00:04,  1.11s/it]Epoch: 5/10. Loss: 0.8593:  88%|[36m████████▊ [0m| 23/26 [00:29<00:03,  1.02s/it]Epoch: 5/10. Loss: 0.8551:  88%|[36m████████▊ [0m| 23/26 [00:30<00:03,  1.02s/it]Epoch: 5/10. Loss: 0.8551:  92%|[36m█████████▏[0m| 24/26 [00:30<00:02,  1.00s/it]Epoch: 5/10. Loss: 0.9220:  92%|[36m█████████▏[0m| 24/26 [00:32<00:02,  1.00s/it]Epoch: 5/10. Loss: 0.9220:  96%|[36m█████████▌[0m| 25/26 [00:32<00:01,  1.34s/it]Epoch: 5/10. Loss: 0.9849:  96%|[36m█████████▌[0m| 25/26 [00:33<00:01,  1.34s/it]Epoch: 5/10. Loss: 0.9849: 100%|[36m██████████[0m| 26/26 [00:33<00:00,  1.30s/it]Epoch: 5/10. Loss: 0.9849: 100%|[36m██████████[0m| 26/26 [00:33<00:00,  1.30s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:05,  1.04it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:05,  1.16s/it] 43%|[33m████▎     [0m| 3/7 [00:03<00:03,  1.02it/s] 57%|[33m█████▋    [0m| 4/7 [00:04<00:03,  1.14s/it] 71%|[33m███████▏  [0m| 5/7 [00:04<00:01,  1.14it/s] 86%|[33m████████▌ [0m| 6/7 [00:05<00:00,  1.17it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.51it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.19it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 6/10. Loss: 0.8971:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 6/10. Loss: 0.8971:   4%|[36m▍         [0m| 1/26 [00:00<00:17,  1.45it/s]Epoch: 6/10. Loss: 0.7644:   4%|[36m▍         [0m| 1/26 [00:01<00:17,  1.45it/s]Epoch: 6/10. Loss: 0.7644:   8%|[36m▊         [0m| 2/26 [00:01<00:18,  1.29it/s]Epoch: 6/10. Loss: 0.8896:   8%|[36m▊         [0m| 2/26 [00:02<00:18,  1.29it/s]Epoch: 6/10. Loss: 0.8896:  12%|[36m█▏        [0m| 3/26 [00:02<00:20,  1.11it/s]Epoch: 6/10. Loss: 0.9696:  12%|[36m█▏        [0m| 3/26 [00:03<00:20,  1.11it/s]Epoch: 6/10. Loss: 0.9696:  15%|[36m█▌        [0m| 4/26 [00:03<00:19,  1.12it/s]Epoch: 6/10. Loss: 0.9028:  15%|[36m█▌        [0m| 4/26 [00:04<00:19,  1.12it/s]Epoch: 6/10. Loss: 0.9028:  19%|[36m█▉        [0m| 5/26 [00:04<00:18,  1.13it/s]Epoch: 6/10. Loss: 0.9966:  19%|[36m█▉        [0m| 5/26 [00:05<00:18,  1.13it/s]Epoch: 6/10. Loss: 0.9966:  23%|[36m██▎       [0m| 6/26 [00:05<00:17,  1.16it/s]Epoch: 6/10. Loss: 0.7517:  23%|[36m██▎       [0m| 6/26 [00:05<00:17,  1.16it/s]Epoch: 6/10. Loss: 0.7517:  27%|[36m██▋       [0m| 7/26 [00:05<00:16,  1.17it/s]Epoch: 6/10. Loss: 0.9912:  27%|[36m██▋       [0m| 7/26 [00:06<00:16,  1.17it/s]Epoch: 6/10. Loss: 0.9912:  31%|[36m███       [0m| 8/26 [00:06<00:15,  1.16it/s]Epoch: 6/10. Loss: 0.9642:  31%|[36m███       [0m| 8/26 [00:07<00:15,  1.16it/s]Epoch: 6/10. Loss: 0.9642:  35%|[36m███▍      [0m| 9/26 [00:07<00:14,  1.15it/s]Epoch: 6/10. Loss: 0.8352:  35%|[36m███▍      [0m| 9/26 [00:08<00:14,  1.15it/s]Epoch: 6/10. Loss: 0.8352:  38%|[36m███▊      [0m| 10/26 [00:08<00:13,  1.17it/s]Epoch: 6/10. Loss: 0.9008:  38%|[36m███▊      [0m| 10/26 [00:09<00:13,  1.17it/s]Epoch: 6/10. Loss: 0.9008:  42%|[36m████▏     [0m| 11/26 [00:09<00:13,  1.15it/s]Epoch: 6/10. Loss: 0.7342:  42%|[36m████▏     [0m| 11/26 [00:10<00:13,  1.15it/s]Epoch: 6/10. Loss: 0.7342:  46%|[36m████▌     [0m| 12/26 [00:10<00:11,  1.18it/s]Epoch: 6/10. Loss: 0.8786:  46%|[36m████▌     [0m| 12/26 [00:11<00:11,  1.18it/s]Epoch: 6/10. Loss: 0.8786:  50%|[36m█████     [0m| 13/26 [00:11<00:10,  1.21it/s]Epoch: 6/10. Loss: 0.7938:  50%|[36m█████     [0m| 13/26 [00:12<00:10,  1.21it/s]Epoch: 6/10. Loss: 0.7938:  54%|[36m█████▍    [0m| 14/26 [00:12<00:11,  1.02it/s]Epoch: 6/10. Loss: 0.8622:  54%|[36m█████▍    [0m| 14/26 [00:13<00:11,  1.02it/s]Epoch: 6/10. Loss: 0.8622:  58%|[36m█████▊    [0m| 15/26 [00:13<00:10,  1.02it/s]Epoch: 6/10. Loss: 0.8233:  58%|[36m█████▊    [0m| 15/26 [00:14<00:10,  1.02it/s]Epoch: 6/10. Loss: 0.8233:  62%|[36m██████▏   [0m| 16/26 [00:14<00:09,  1.10it/s]Epoch: 6/10. Loss: 0.9212:  62%|[36m██████▏   [0m| 16/26 [00:14<00:09,  1.10it/s]Epoch: 6/10. Loss: 0.9212:  65%|[36m██████▌   [0m| 17/26 [00:14<00:07,  1.14it/s]Epoch: 6/10. Loss: 0.8279:  65%|[36m██████▌   [0m| 17/26 [00:16<00:07,  1.14it/s]Epoch: 6/10. Loss: 0.8279:  69%|[36m██████▉   [0m| 18/26 [00:16<00:08,  1.01s/it]Epoch: 6/10. Loss: 0.8091:  69%|[36m██████▉   [0m| 18/26 [00:17<00:08,  1.01s/it]Epoch: 6/10. Loss: 0.8091:  73%|[36m███████▎  [0m| 19/26 [00:17<00:06,  1.02it/s]Epoch: 6/10. Loss: 0.8474:  73%|[36m███████▎  [0m| 19/26 [00:18<00:06,  1.02it/s]Epoch: 6/10. Loss: 0.8474:  77%|[36m███████▋  [0m| 20/26 [00:18<00:06,  1.01s/it]Epoch: 6/10. Loss: 0.9263:  77%|[36m███████▋  [0m| 20/26 [00:22<00:06,  1.01s/it]Epoch: 6/10. Loss: 0.9263:  81%|[36m████████  [0m| 21/26 [00:22<00:09,  1.91s/it]Epoch: 6/10. Loss: 0.9771:  81%|[36m████████  [0m| 21/26 [00:23<00:09,  1.91s/it]Epoch: 6/10. Loss: 0.9771:  85%|[36m████████▍ [0m| 22/26 [00:23<00:07,  1.76s/it]Epoch: 6/10. Loss: 0.8123:  85%|[36m████████▍ [0m| 22/26 [00:24<00:07,  1.76s/it]Epoch: 6/10. Loss: 0.8123:  88%|[36m████████▊ [0m| 23/26 [00:24<00:04,  1.47s/it]Epoch: 6/10. Loss: 0.8896:  88%|[36m████████▊ [0m| 23/26 [00:25<00:04,  1.47s/it]Epoch: 6/10. Loss: 0.8896:  92%|[36m█████████▏[0m| 24/26 [00:25<00:02,  1.32s/it]Epoch: 6/10. Loss: 0.7387:  92%|[36m█████████▏[0m| 24/26 [00:26<00:02,  1.32s/it]Epoch: 6/10. Loss: 0.7387:  96%|[36m█████████▌[0m| 25/26 [00:26<00:01,  1.19s/it]Epoch: 6/10. Loss: 0.9410:  96%|[36m█████████▌[0m| 25/26 [00:26<00:01,  1.19s/it]Epoch: 6/10. Loss: 0.9410: 100%|[36m██████████[0m| 26/26 [00:26<00:00,  1.02s/it]Epoch: 6/10. Loss: 0.9410: 100%|[36m██████████[0m| 26/26 [00:26<00:00,  1.04s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:05,  1.07it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:05,  1.12s/it] 43%|[33m████▎     [0m| 3/7 [00:02<00:03,  1.05it/s] 57%|[33m█████▋    [0m| 4/7 [00:04<00:03,  1.20s/it] 71%|[33m███████▏  [0m| 5/7 [00:04<00:01,  1.08it/s] 86%|[33m████████▌ [0m| 6/7 [00:05<00:00,  1.13it/s]100%|[33m██████████[0m| 7/7 [00:06<00:00,  1.09it/s]100%|[33m██████████[0m| 7/7 [00:06<00:00,  1.04it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 7/10. Loss: 0.8807:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 7/10. Loss: 0.8807:   4%|[36m▍         [0m| 1/26 [00:00<00:20,  1.25it/s]Epoch: 7/10. Loss: 1.0447:   4%|[36m▍         [0m| 1/26 [00:02<00:20,  1.25it/s]Epoch: 7/10. Loss: 1.0447:   8%|[36m▊         [0m| 2/26 [00:02<00:37,  1.57s/it]Epoch: 7/10. Loss: 0.8508:   8%|[36m▊         [0m| 2/26 [00:04<00:37,  1.57s/it]Epoch: 7/10. Loss: 0.8508:  12%|[36m█▏        [0m| 3/26 [00:04<00:37,  1.63s/it]Epoch: 7/10. Loss: 0.8036:  12%|[36m█▏        [0m| 3/26 [00:05<00:37,  1.63s/it]Epoch: 7/10. Loss: 0.8036:  15%|[36m█▌        [0m| 4/26 [00:05<00:29,  1.34s/it]Epoch: 7/10. Loss: 0.8717:  15%|[36m█▌        [0m| 4/26 [00:06<00:29,  1.34s/it]Epoch: 7/10. Loss: 0.8717:  19%|[36m█▉        [0m| 5/26 [00:06<00:25,  1.20s/it]Epoch: 7/10. Loss: 0.7481:  19%|[36m█▉        [0m| 5/26 [00:07<00:25,  1.20s/it]Epoch: 7/10. Loss: 0.7481:  23%|[36m██▎       [0m| 6/26 [00:07<00:21,  1.09s/it]Epoch: 7/10. Loss: 0.8714:  23%|[36m██▎       [0m| 6/26 [00:08<00:21,  1.09s/it]Epoch: 7/10. Loss: 0.8714:  27%|[36m██▋       [0m| 7/26 [00:08<00:19,  1.04s/it]Epoch: 7/10. Loss: 0.8791:  27%|[36m██▋       [0m| 7/26 [00:09<00:19,  1.04s/it]Epoch: 7/10. Loss: 0.8791:  31%|[36m███       [0m| 8/26 [00:09<00:17,  1.03it/s]Epoch: 7/10. Loss: 0.8529:  31%|[36m███       [0m| 8/26 [00:09<00:17,  1.03it/s]Epoch: 7/10. Loss: 0.8529:  35%|[36m███▍      [0m| 9/26 [00:09<00:15,  1.07it/s]Epoch: 7/10. Loss: 0.8482:  35%|[36m███▍      [0m| 9/26 [00:10<00:15,  1.07it/s]Epoch: 7/10. Loss: 0.8482:  38%|[36m███▊      [0m| 10/26 [00:10<00:14,  1.11it/s]Epoch: 7/10. Loss: 0.7844:  38%|[36m███▊      [0m| 10/26 [00:11<00:14,  1.11it/s]Epoch: 7/10. Loss: 0.7844:  42%|[36m████▏     [0m| 11/26 [00:11<00:12,  1.16it/s]Epoch: 7/10. Loss: 0.8946:  42%|[36m████▏     [0m| 11/26 [00:13<00:12,  1.16it/s]Epoch: 7/10. Loss: 0.8946:  46%|[36m████▌     [0m| 12/26 [00:13<00:18,  1.33s/it]Epoch: 7/10. Loss: 0.7826:  46%|[36m████▌     [0m| 12/26 [00:14<00:18,  1.33s/it]Epoch: 7/10. Loss: 0.7826:  50%|[36m█████     [0m| 13/26 [00:14<00:15,  1.18s/it]Epoch: 7/10. Loss: 0.7883:  50%|[36m█████     [0m| 13/26 [00:15<00:15,  1.18s/it]Epoch: 7/10. Loss: 0.7883:  54%|[36m█████▍    [0m| 14/26 [00:15<00:13,  1.13s/it]Epoch: 7/10. Loss: 0.7560:  54%|[36m█████▍    [0m| 14/26 [00:16<00:13,  1.13s/it]Epoch: 7/10. Loss: 0.7560:  58%|[36m█████▊    [0m| 15/26 [00:16<00:11,  1.08s/it]Epoch: 7/10. Loss: 0.8778:  58%|[36m█████▊    [0m| 15/26 [00:17<00:11,  1.08s/it]Epoch: 7/10. Loss: 0.8778:  62%|[36m██████▏   [0m| 16/26 [00:17<00:10,  1.05s/it]Epoch: 7/10. Loss: 1.0242:  62%|[36m██████▏   [0m| 16/26 [00:18<00:10,  1.05s/it]Epoch: 7/10. Loss: 1.0242:  65%|[36m██████▌   [0m| 17/26 [00:18<00:09,  1.01s/it]Epoch: 7/10. Loss: 0.9435:  65%|[36m██████▌   [0m| 17/26 [00:19<00:09,  1.01s/it]Epoch: 7/10. Loss: 0.9435:  69%|[36m██████▉   [0m| 18/26 [00:19<00:07,  1.02it/s]Epoch: 7/10. Loss: 0.7283:  69%|[36m██████▉   [0m| 18/26 [00:20<00:07,  1.02it/s]Epoch: 7/10. Loss: 0.7283:  73%|[36m███████▎  [0m| 19/26 [00:20<00:06,  1.01it/s]Epoch: 7/10. Loss: 0.7708:  73%|[36m███████▎  [0m| 19/26 [00:21<00:06,  1.01it/s]Epoch: 7/10. Loss: 0.7708:  77%|[36m███████▋  [0m| 20/26 [00:21<00:05,  1.05it/s]Epoch: 7/10. Loss: 0.7320:  77%|[36m███████▋  [0m| 20/26 [00:22<00:05,  1.05it/s]Epoch: 7/10. Loss: 0.7320:  81%|[36m████████  [0m| 21/26 [00:22<00:04,  1.14it/s]Epoch: 7/10. Loss: 0.9242:  81%|[36m████████  [0m| 21/26 [00:23<00:04,  1.14it/s]Epoch: 7/10. Loss: 0.9242:  85%|[36m████████▍ [0m| 22/26 [00:23<00:03,  1.13it/s]Epoch: 7/10. Loss: 0.9007:  85%|[36m████████▍ [0m| 22/26 [00:23<00:03,  1.13it/s]Epoch: 7/10. Loss: 0.9007:  88%|[36m████████▊ [0m| 23/26 [00:23<00:02,  1.11it/s]Epoch: 7/10. Loss: 0.8510:  88%|[36m████████▊ [0m| 23/26 [00:24<00:02,  1.11it/s]Epoch: 7/10. Loss: 0.8510:  92%|[36m█████████▏[0m| 24/26 [00:24<00:01,  1.12it/s]Epoch: 7/10. Loss: 0.9258:  92%|[36m█████████▏[0m| 24/26 [00:25<00:01,  1.12it/s]Epoch: 7/10. Loss: 0.9258:  96%|[36m█████████▌[0m| 25/26 [00:25<00:00,  1.13it/s]Epoch: 7/10. Loss: 0.7896:  96%|[36m█████████▌[0m| 25/26 [00:26<00:00,  1.13it/s]Epoch: 7/10. Loss: 0.7896: 100%|[36m██████████[0m| 26/26 [00:26<00:00,  1.28it/s]Epoch: 7/10. Loss: 0.7896: 100%|[36m██████████[0m| 26/26 [00:26<00:00,  1.01s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:01<00:09,  1.61s/it] 29%|[33m██▊       [0m| 2/7 [00:02<00:06,  1.39s/it] 43%|[33m████▎     [0m| 3/7 [00:03<00:04,  1.10s/it] 57%|[33m█████▋    [0m| 4/7 [00:04<00:03,  1.21s/it] 71%|[33m███████▏  [0m| 5/7 [00:05<00:01,  1.02it/s] 86%|[33m████████▌ [0m| 6/7 [00:06<00:00,  1.08it/s]100%|[33m██████████[0m| 7/7 [00:07<00:00,  1.01it/s]100%|[33m██████████[0m| 7/7 [00:07<00:00,  1.07s/it]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 8/10. Loss: 0.8135:   0%|[36m          [0m| 0/26 [00:01<?, ?it/s]Epoch: 8/10. Loss: 0.8135:   4%|[36m▍         [0m| 1/26 [00:01<00:37,  1.50s/it]Epoch: 8/10. Loss: 0.7828:   4%|[36m▍         [0m| 1/26 [00:02<00:37,  1.50s/it]Epoch: 8/10. Loss: 0.7828:   8%|[36m▊         [0m| 2/26 [00:02<00:26,  1.12s/it]Epoch: 8/10. Loss: 0.8191:   8%|[36m▊         [0m| 2/26 [00:03<00:26,  1.12s/it]Epoch: 8/10. Loss: 0.8191:  12%|[36m█▏        [0m| 3/26 [00:03<00:21,  1.05it/s]Epoch: 8/10. Loss: 0.7527:  12%|[36m█▏        [0m| 3/26 [00:05<00:21,  1.05it/s]Epoch: 8/10. Loss: 0.7527:  15%|[36m█▌        [0m| 4/26 [00:05<00:34,  1.56s/it]Epoch: 8/10. Loss: 0.8725:  15%|[36m█▌        [0m| 4/26 [00:06<00:34,  1.56s/it]Epoch: 8/10. Loss: 0.8725:  19%|[36m█▉        [0m| 5/26 [00:06<00:28,  1.34s/it]Epoch: 8/10. Loss: 0.8327:  19%|[36m█▉        [0m| 5/26 [00:07<00:28,  1.34s/it]Epoch: 8/10. Loss: 0.8327:  23%|[36m██▎       [0m| 6/26 [00:07<00:23,  1.16s/it]Epoch: 8/10. Loss: 0.8281:  23%|[36m██▎       [0m| 6/26 [00:08<00:23,  1.16s/it]Epoch: 8/10. Loss: 0.8281:  27%|[36m██▋       [0m| 7/26 [00:08<00:20,  1.09s/it]Epoch: 8/10. Loss: 0.8925:  27%|[36m██▋       [0m| 7/26 [00:09<00:20,  1.09s/it]Epoch: 8/10. Loss: 0.8925:  31%|[36m███       [0m| 8/26 [00:09<00:18,  1.02s/it]Epoch: 8/10. Loss: 0.9146:  31%|[36m███       [0m| 8/26 [00:10<00:18,  1.02s/it]Epoch: 8/10. Loss: 0.9146:  35%|[36m███▍      [0m| 9/26 [00:10<00:17,  1.04s/it]Epoch: 8/10. Loss: 0.9041:  35%|[36m███▍      [0m| 9/26 [00:11<00:17,  1.04s/it]Epoch: 8/10. Loss: 0.9041:  38%|[36m███▊      [0m| 10/26 [00:11<00:15,  1.00it/s]Epoch: 8/10. Loss: 0.8085:  38%|[36m███▊      [0m| 10/26 [00:12<00:15,  1.00it/s]Epoch: 8/10. Loss: 0.8085:  42%|[36m████▏     [0m| 11/26 [00:12<00:14,  1.02it/s]Epoch: 8/10. Loss: 0.7675:  42%|[36m████▏     [0m| 11/26 [00:12<00:14,  1.02it/s]Epoch: 8/10. Loss: 0.7675:  46%|[36m████▌     [0m| 12/26 [00:12<00:12,  1.08it/s]Epoch: 8/10. Loss: 0.7844:  46%|[36m████▌     [0m| 12/26 [00:14<00:12,  1.08it/s]Epoch: 8/10. Loss: 0.7844:  50%|[36m█████     [0m| 13/26 [00:14<00:13,  1.04s/it]Epoch: 8/10. Loss: 0.9134:  50%|[36m█████     [0m| 13/26 [00:15<00:13,  1.04s/it]Epoch: 8/10. Loss: 0.9134:  54%|[36m█████▍    [0m| 14/26 [00:15<00:12,  1.03s/it]Epoch: 8/10. Loss: 0.8086:  54%|[36m█████▍    [0m| 14/26 [00:16<00:12,  1.03s/it]Epoch: 8/10. Loss: 0.8086:  58%|[36m█████▊    [0m| 15/26 [00:16<00:10,  1.00it/s]Epoch: 8/10. Loss: 0.8294:  58%|[36m█████▊    [0m| 15/26 [00:17<00:10,  1.00it/s]Epoch: 8/10. Loss: 0.8294:  62%|[36m██████▏   [0m| 16/26 [00:17<00:10,  1.01s/it]Epoch: 8/10. Loss: 0.8396:  62%|[36m██████▏   [0m| 16/26 [00:19<00:10,  1.01s/it]Epoch: 8/10. Loss: 0.8396:  65%|[36m██████▌   [0m| 17/26 [00:19<00:13,  1.44s/it]Epoch: 8/10. Loss: 0.8936:  65%|[36m██████▌   [0m| 17/26 [00:20<00:13,  1.44s/it]Epoch: 8/10. Loss: 0.8936:  69%|[36m██████▉   [0m| 18/26 [00:20<00:10,  1.31s/it]Epoch: 8/10. Loss: 0.8650:  69%|[36m██████▉   [0m| 18/26 [00:21<00:10,  1.31s/it]Epoch: 8/10. Loss: 0.8650:  73%|[36m███████▎  [0m| 19/26 [00:21<00:08,  1.16s/it]Epoch: 8/10. Loss: 0.8144:  73%|[36m███████▎  [0m| 19/26 [00:22<00:08,  1.16s/it]Epoch: 8/10. Loss: 0.8144:  77%|[36m███████▋  [0m| 20/26 [00:22<00:07,  1.23s/it]Epoch: 8/10. Loss: 0.8362:  77%|[36m███████▋  [0m| 20/26 [00:23<00:07,  1.23s/it]Epoch: 8/10. Loss: 0.8362:  81%|[36m████████  [0m| 21/26 [00:23<00:05,  1.14s/it]Epoch: 8/10. Loss: 0.8945:  81%|[36m████████  [0m| 21/26 [00:24<00:05,  1.14s/it]Epoch: 8/10. Loss: 0.8945:  85%|[36m████████▍ [0m| 22/26 [00:24<00:04,  1.02s/it]Epoch: 8/10. Loss: 0.7331:  85%|[36m████████▍ [0m| 22/26 [00:25<00:04,  1.02s/it]Epoch: 8/10. Loss: 0.7331:  88%|[36m████████▊ [0m| 23/26 [00:25<00:02,  1.04it/s]Epoch: 8/10. Loss: 0.8290:  88%|[36m████████▊ [0m| 23/26 [00:26<00:02,  1.04it/s]Epoch: 8/10. Loss: 0.8290:  92%|[36m█████████▏[0m| 24/26 [00:26<00:02,  1.04s/it]Epoch: 8/10. Loss: 0.7989:  92%|[36m█████████▏[0m| 24/26 [00:27<00:02,  1.04s/it]Epoch: 8/10. Loss: 0.7989:  96%|[36m█████████▌[0m| 25/26 [00:27<00:01,  1.00s/it]Epoch: 8/10. Loss: 0.7664:  96%|[36m█████████▌[0m| 25/26 [00:28<00:01,  1.00s/it]Epoch: 8/10. Loss: 0.7664: 100%|[36m██████████[0m| 26/26 [00:28<00:00,  1.12it/s]Epoch: 8/10. Loss: 0.7664: 100%|[36m██████████[0m| 26/26 [00:28<00:00,  1.08s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:05,  1.10it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:05,  1.09s/it] 43%|[33m████▎     [0m| 3/7 [00:02<00:03,  1.06it/s] 57%|[33m█████▋    [0m| 4/7 [00:04<00:03,  1.13s/it] 71%|[33m███████▏  [0m| 5/7 [00:04<00:01,  1.14it/s] 86%|[33m████████▌ [0m| 6/7 [00:05<00:00,  1.17it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.52it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.21it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 9/10. Loss: 0.7342:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 9/10. Loss: 0.7342:   4%|[36m▍         [0m| 1/26 [00:00<00:22,  1.12it/s]Epoch: 9/10. Loss: 0.8766:   4%|[36m▍         [0m| 1/26 [00:01<00:22,  1.12it/s]Epoch: 9/10. Loss: 0.8766:   8%|[36m▊         [0m| 2/26 [00:01<00:20,  1.18it/s]Epoch: 9/10. Loss: 0.7580:   8%|[36m▊         [0m| 2/26 [00:03<00:20,  1.18it/s]Epoch: 9/10. Loss: 0.7580:  12%|[36m█▏        [0m| 3/26 [00:03<00:25,  1.09s/it]Epoch: 9/10. Loss: 0.8604:  12%|[36m█▏        [0m| 3/26 [00:03<00:25,  1.09s/it]Epoch: 9/10. Loss: 0.8604:  15%|[36m█▌        [0m| 4/26 [00:03<00:21,  1.03it/s]Epoch: 9/10. Loss: 0.8096:  15%|[36m█▌        [0m| 4/26 [00:04<00:21,  1.03it/s]Epoch: 9/10. Loss: 0.8096:  19%|[36m█▉        [0m| 5/26 [00:04<00:20,  1.04it/s]Epoch: 9/10. Loss: 0.9083:  19%|[36m█▉        [0m| 5/26 [00:06<00:20,  1.04it/s]Epoch: 9/10. Loss: 0.9083:  23%|[36m██▎       [0m| 6/26 [00:06<00:21,  1.06s/it]Epoch: 9/10. Loss: 0.8522:  23%|[36m██▎       [0m| 6/26 [00:06<00:21,  1.06s/it]Epoch: 9/10. Loss: 0.8522:  27%|[36m██▋       [0m| 7/26 [00:06<00:18,  1.03it/s]Epoch: 9/10. Loss: 0.7978:  27%|[36m██▋       [0m| 7/26 [00:07<00:18,  1.03it/s]Epoch: 9/10. Loss: 0.7978:  31%|[36m███       [0m| 8/26 [00:07<00:16,  1.07it/s]Epoch: 9/10. Loss: 0.6566:  31%|[36m███       [0m| 8/26 [00:08<00:16,  1.07it/s]Epoch: 9/10. Loss: 0.6566:  35%|[36m███▍      [0m| 9/26 [00:08<00:16,  1.03it/s]Epoch: 9/10. Loss: 0.7330:  35%|[36m███▍      [0m| 9/26 [00:09<00:16,  1.03it/s]Epoch: 9/10. Loss: 0.7330:  38%|[36m███▊      [0m| 10/26 [00:09<00:16,  1.01s/it]Epoch: 9/10. Loss: 0.8607:  38%|[36m███▊      [0m| 10/26 [00:10<00:16,  1.01s/it]Epoch: 9/10. Loss: 0.8607:  42%|[36m████▏     [0m| 11/26 [00:10<00:14,  1.04it/s]Epoch: 9/10. Loss: 0.7787:  42%|[36m████▏     [0m| 11/26 [00:11<00:14,  1.04it/s]Epoch: 9/10. Loss: 0.7787:  46%|[36m████▌     [0m| 12/26 [00:11<00:13,  1.07it/s]Epoch: 9/10. Loss: 0.7643:  46%|[36m████▌     [0m| 12/26 [00:12<00:13,  1.07it/s]Epoch: 9/10. Loss: 0.7643:  50%|[36m█████     [0m| 13/26 [00:12<00:11,  1.10it/s]Epoch: 9/10. Loss: 0.7761:  50%|[36m█████     [0m| 13/26 [00:13<00:11,  1.10it/s]Epoch: 9/10. Loss: 0.7761:  54%|[36m█████▍    [0m| 14/26 [00:13<00:10,  1.12it/s]Epoch: 9/10. Loss: 0.7499:  54%|[36m█████▍    [0m| 14/26 [00:14<00:10,  1.12it/s]Epoch: 9/10. Loss: 0.7499:  58%|[36m█████▊    [0m| 15/26 [00:14<00:09,  1.13it/s]Epoch: 9/10. Loss: 0.7181:  58%|[36m█████▊    [0m| 15/26 [00:14<00:09,  1.13it/s]Epoch: 9/10. Loss: 0.7181:  62%|[36m██████▏   [0m| 16/26 [00:14<00:08,  1.20it/s]Epoch: 9/10. Loss: 0.9041:  62%|[36m██████▏   [0m| 16/26 [00:16<00:08,  1.20it/s]Epoch: 9/10. Loss: 0.9041:  65%|[36m██████▌   [0m| 17/26 [00:16<00:08,  1.07it/s]Epoch: 9/10. Loss: 0.8387:  65%|[36m██████▌   [0m| 17/26 [00:16<00:08,  1.07it/s]Epoch: 9/10. Loss: 0.8387:  69%|[36m██████▉   [0m| 18/26 [00:16<00:07,  1.14it/s]Epoch: 9/10. Loss: 0.6800:  69%|[36m██████▉   [0m| 18/26 [00:17<00:07,  1.14it/s]Epoch: 9/10. Loss: 0.6800:  73%|[36m███████▎  [0m| 19/26 [00:17<00:06,  1.12it/s]Epoch: 9/10. Loss: 0.7178:  73%|[36m███████▎  [0m| 19/26 [00:18<00:06,  1.12it/s]Epoch: 9/10. Loss: 0.7178:  77%|[36m███████▋  [0m| 20/26 [00:18<00:05,  1.18it/s]Epoch: 9/10. Loss: 0.7569:  77%|[36m███████▋  [0m| 20/26 [00:19<00:05,  1.18it/s]Epoch: 9/10. Loss: 0.7569:  81%|[36m████████  [0m| 21/26 [00:19<00:04,  1.17it/s]Epoch: 9/10. Loss: 0.9167:  81%|[36m████████  [0m| 21/26 [00:20<00:04,  1.17it/s]Epoch: 9/10. Loss: 0.9167:  85%|[36m████████▍ [0m| 22/26 [00:20<00:03,  1.09it/s]Epoch: 9/10. Loss: 0.9341:  85%|[36m████████▍ [0m| 22/26 [00:21<00:03,  1.09it/s]Epoch: 9/10. Loss: 0.9341:  88%|[36m████████▊ [0m| 23/26 [00:21<00:02,  1.17it/s]Epoch: 9/10. Loss: 0.8007:  88%|[36m████████▊ [0m| 23/26 [00:22<00:02,  1.17it/s]Epoch: 9/10. Loss: 0.8007:  92%|[36m█████████▏[0m| 24/26 [00:22<00:01,  1.13it/s]Epoch: 9/10. Loss: 0.7454:  92%|[36m█████████▏[0m| 24/26 [00:22<00:01,  1.13it/s]Epoch: 9/10. Loss: 0.7454:  96%|[36m█████████▌[0m| 25/26 [00:22<00:00,  1.11it/s]Epoch: 9/10. Loss: 0.8607:  96%|[36m█████████▌[0m| 25/26 [00:23<00:00,  1.11it/s]Epoch: 9/10. Loss: 0.8607: 100%|[36m██████████[0m| 26/26 [00:23<00:00,  1.18it/s]Epoch: 9/10. Loss: 0.8607: 100%|[36m██████████[0m| 26/26 [00:23<00:00,  1.10it/s]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:01<00:08,  1.36s/it] 29%|[33m██▊       [0m| 2/7 [00:02<00:06,  1.28s/it] 43%|[33m████▎     [0m| 3/7 [00:03<00:04,  1.05s/it] 57%|[33m█████▋    [0m| 4/7 [00:05<00:03,  1.33s/it] 71%|[33m███████▏  [0m| 5/7 [00:05<00:02,  1.01s/it] 86%|[33m████████▌ [0m| 6/7 [00:06<00:00,  1.07it/s]100%|[33m██████████[0m| 7/7 [00:06<00:00,  1.40it/s]100%|[33m██████████[0m| 7/7 [00:06<00:00,  1.06it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 0/10. Loss: 1.0915:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 0/10. Loss: 1.0915:   4%|[36m▍         [0m| 1/26 [00:00<00:21,  1.14it/s]Epoch: 0/10. Loss: 1.5588:   4%|[36m▍         [0m| 1/26 [00:01<00:21,  1.14it/s]Epoch: 0/10. Loss: 1.5588:   8%|[36m▊         [0m| 2/26 [00:01<00:21,  1.14it/s]Epoch: 0/10. Loss: 2.2747:   8%|[36m▊         [0m| 2/26 [00:02<00:21,  1.14it/s]Epoch: 0/10. Loss: 2.2747:  12%|[36m█▏        [0m| 3/26 [00:02<00:20,  1.13it/s]Epoch: 0/10. Loss: 1.6888:  12%|[36m█▏        [0m| 3/26 [00:03<00:20,  1.13it/s]Epoch: 0/10. Loss: 1.6888:  15%|[36m█▌        [0m| 4/26 [00:03<00:22,  1.03s/it]Epoch: 0/10. Loss: 1.4421:  15%|[36m█▌        [0m| 4/26 [00:05<00:22,  1.03s/it]Epoch: 0/10. Loss: 1.4421:  19%|[36m█▉        [0m| 5/26 [00:05<00:26,  1.25s/it]Epoch: 0/10. Loss: 1.1297:  19%|[36m█▉        [0m| 5/26 [00:07<00:26,  1.25s/it]Epoch: 0/10. Loss: 1.1297:  23%|[36m██▎       [0m| 6/26 [00:07<00:30,  1.53s/it]Epoch: 0/10. Loss: 1.1058:  23%|[36m██▎       [0m| 6/26 [00:08<00:30,  1.53s/it]Epoch: 0/10. Loss: 1.1058:  27%|[36m██▋       [0m| 7/26 [00:08<00:27,  1.45s/it]Epoch: 0/10. Loss: 1.0001:  27%|[36m██▋       [0m| 7/26 [00:10<00:27,  1.45s/it]Epoch: 0/10. Loss: 1.0001:  31%|[36m███       [0m| 8/26 [00:10<00:26,  1.47s/it]Epoch: 0/10. Loss: 1.2439:  31%|[36m███       [0m| 8/26 [00:11<00:26,  1.47s/it]Epoch: 0/10. Loss: 1.2439:  35%|[36m███▍      [0m| 9/26 [00:11<00:25,  1.48s/it]Epoch: 0/10. Loss: 1.4503:  35%|[36m███▍      [0m| 9/26 [00:12<00:25,  1.48s/it]Epoch: 0/10. Loss: 1.4503:  38%|[36m███▊      [0m| 10/26 [00:12<00:20,  1.26s/it]Epoch: 0/10. Loss: 1.3692:  38%|[36m███▊      [0m| 10/26 [00:13<00:20,  1.26s/it]Epoch: 0/10. Loss: 1.3692:  42%|[36m████▏     [0m| 11/26 [00:13<00:16,  1.12s/it]Epoch: 0/10. Loss: 1.2289:  42%|[36m████▏     [0m| 11/26 [00:14<00:16,  1.12s/it]Epoch: 0/10. Loss: 1.2289:  46%|[36m████▌     [0m| 12/26 [00:14<00:14,  1.03s/it]Epoch: 0/10. Loss: 1.1435:  46%|[36m████▌     [0m| 12/26 [00:15<00:14,  1.03s/it]Epoch: 0/10. Loss: 1.1435:  50%|[36m█████     [0m| 13/26 [00:15<00:14,  1.08s/it]Epoch: 0/10. Loss: 1.3196:  50%|[36m█████     [0m| 13/26 [00:16<00:14,  1.08s/it]Epoch: 0/10. Loss: 1.3196:  54%|[36m█████▍    [0m| 14/26 [00:16<00:12,  1.02s/it]Epoch: 0/10. Loss: 1.1981:  54%|[36m█████▍    [0m| 14/26 [00:18<00:12,  1.02s/it]Epoch: 0/10. Loss: 1.1981:  58%|[36m█████▊    [0m| 15/26 [00:18<00:14,  1.28s/it]Epoch: 0/10. Loss: 1.1592:  58%|[36m█████▊    [0m| 15/26 [00:19<00:14,  1.28s/it]Epoch: 0/10. Loss: 1.1592:  62%|[36m██████▏   [0m| 16/26 [00:19<00:11,  1.18s/it]Epoch: 0/10. Loss: 1.0532:  62%|[36m██████▏   [0m| 16/26 [00:21<00:11,  1.18s/it]Epoch: 0/10. Loss: 1.0532:  65%|[36m██████▌   [0m| 17/26 [00:21<00:14,  1.56s/it]Epoch: 0/10. Loss: 1.2405:  65%|[36m██████▌   [0m| 17/26 [00:25<00:14,  1.56s/it]Epoch: 0/10. Loss: 1.2405:  69%|[36m██████▉   [0m| 18/26 [00:25<00:17,  2.22s/it]Epoch: 0/10. Loss: 1.1684:  69%|[36m██████▉   [0m| 18/26 [00:28<00:17,  2.22s/it]Epoch: 0/10. Loss: 1.1684:  73%|[36m███████▎  [0m| 19/26 [00:28<00:16,  2.40s/it]Epoch: 0/10. Loss: 1.0551:  73%|[36m███████▎  [0m| 19/26 [00:29<00:16,  2.40s/it]Epoch: 0/10. Loss: 1.0551:  77%|[36m███████▋  [0m| 20/26 [00:29<00:11,  1.97s/it]Epoch: 0/10. Loss: 0.9990:  77%|[36m███████▋  [0m| 20/26 [00:30<00:11,  1.97s/it]Epoch: 0/10. Loss: 0.9990:  81%|[36m████████  [0m| 21/26 [00:30<00:08,  1.72s/it]Epoch: 0/10. Loss: 1.0118:  81%|[36m████████  [0m| 21/26 [00:31<00:08,  1.72s/it]Epoch: 0/10. Loss: 1.0118:  85%|[36m████████▍ [0m| 22/26 [00:31<00:06,  1.65s/it]Epoch: 0/10. Loss: 1.0517:  85%|[36m████████▍ [0m| 22/26 [00:32<00:06,  1.65s/it]Epoch: 0/10. Loss: 1.0517:  88%|[36m████████▊ [0m| 23/26 [00:32<00:04,  1.42s/it]Epoch: 0/10. Loss: 1.0596:  88%|[36m████████▊ [0m| 23/26 [00:33<00:04,  1.42s/it]Epoch: 0/10. Loss: 1.0596:  92%|[36m█████████▏[0m| 24/26 [00:33<00:02,  1.29s/it]Epoch: 0/10. Loss: 1.0314:  92%|[36m█████████▏[0m| 24/26 [00:34<00:02,  1.29s/it]Epoch: 0/10. Loss: 1.0314:  96%|[36m█████████▌[0m| 25/26 [00:34<00:01,  1.18s/it]Epoch: 0/10. Loss: 0.9839:  96%|[36m█████████▌[0m| 25/26 [00:35<00:01,  1.18s/it]Epoch: 0/10. Loss: 0.9839: 100%|[36m██████████[0m| 26/26 [00:35<00:00,  1.05s/it]Epoch: 0/10. Loss: 0.9839: 100%|[36m██████████[0m| 26/26 [00:35<00:00,  1.36s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:05,  1.05it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:06,  1.22s/it] 43%|[33m████▎     [0m| 3/7 [00:03<00:04,  1.05s/it] 57%|[33m█████▋    [0m| 4/7 [00:04<00:03,  1.32s/it] 71%|[33m███████▏  [0m| 5/7 [00:05<00:02,  1.09s/it] 86%|[33m████████▌ [0m| 6/7 [00:06<00:01,  1.16s/it]100%|[33m██████████[0m| 7/7 [00:07<00:00,  1.15it/s]100%|[33m██████████[0m| 7/7 [00:07<00:00,  1.03s/it]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 1/10. Loss: 1.1399:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 1/10. Loss: 1.1399:   4%|[36m▍         [0m| 1/26 [00:00<00:20,  1.21it/s]Epoch: 1/10. Loss: 1.0312:   4%|[36m▍         [0m| 1/26 [00:01<00:20,  1.21it/s]Epoch: 1/10. Loss: 1.0312:   8%|[36m▊         [0m| 2/26 [00:01<00:22,  1.09it/s]Epoch: 1/10. Loss: 1.0034:   8%|[36m▊         [0m| 2/26 [00:02<00:22,  1.09it/s]Epoch: 1/10. Loss: 1.0034:  12%|[36m█▏        [0m| 3/26 [00:02<00:20,  1.10it/s]Epoch: 1/10. Loss: 1.2294:  12%|[36m█▏        [0m| 3/26 [00:03<00:20,  1.10it/s]Epoch: 1/10. Loss: 1.2294:  15%|[36m█▌        [0m| 4/26 [00:03<00:20,  1.05it/s]Epoch: 1/10. Loss: 1.0478:  15%|[36m█▌        [0m| 4/26 [00:04<00:20,  1.05it/s]Epoch: 1/10. Loss: 1.0478:  19%|[36m█▉        [0m| 5/26 [00:04<00:21,  1.01s/it]Epoch: 1/10. Loss: 1.0163:  19%|[36m█▉        [0m| 5/26 [00:06<00:21,  1.01s/it]Epoch: 1/10. Loss: 1.0163:  23%|[36m██▎       [0m| 6/26 [00:06<00:22,  1.10s/it]Epoch: 1/10. Loss: 1.1950:  23%|[36m██▎       [0m| 6/26 [00:06<00:22,  1.10s/it]Epoch: 1/10. Loss: 1.1950:  27%|[36m██▋       [0m| 7/26 [00:07<00:19,  1.03s/it]Epoch: 1/10. Loss: 1.0195:  27%|[36m██▋       [0m| 7/26 [00:07<00:19,  1.03s/it]Epoch: 1/10. Loss: 1.0195:  31%|[36m███       [0m| 8/26 [00:07<00:17,  1.03it/s]Epoch: 1/10. Loss: 1.0435:  31%|[36m███       [0m| 8/26 [00:10<00:17,  1.03it/s]Epoch: 1/10. Loss: 1.0435:  35%|[36m███▍      [0m| 9/26 [00:10<00:23,  1.39s/it]Epoch: 1/10. Loss: 1.0551:  35%|[36m███▍      [0m| 9/26 [00:12<00:23,  1.39s/it]Epoch: 1/10. Loss: 1.0551:  38%|[36m███▊      [0m| 10/26 [00:12<00:26,  1.66s/it]Epoch: 1/10. Loss: 1.0779:  38%|[36m███▊      [0m| 10/26 [00:13<00:26,  1.66s/it]Epoch: 1/10. Loss: 1.0779:  42%|[36m████▏     [0m| 11/26 [00:13<00:21,  1.45s/it]Epoch: 1/10. Loss: 1.0225:  42%|[36m████▏     [0m| 11/26 [00:14<00:21,  1.45s/it]Epoch: 1/10. Loss: 1.0225:  46%|[36m████▌     [0m| 12/26 [00:14<00:19,  1.36s/it]Epoch: 1/10. Loss: 1.0735:  46%|[36m████▌     [0m| 12/26 [00:15<00:19,  1.36s/it]Epoch: 1/10. Loss: 1.0735:  50%|[36m█████     [0m| 13/26 [00:15<00:15,  1.23s/it]Epoch: 1/10. Loss: 1.0291:  50%|[36m█████     [0m| 13/26 [00:16<00:15,  1.23s/it]Epoch: 1/10. Loss: 1.0291:  54%|[36m█████▍    [0m| 14/26 [00:16<00:15,  1.26s/it]Epoch: 1/10. Loss: 1.2636:  54%|[36m█████▍    [0m| 14/26 [00:17<00:15,  1.26s/it]Epoch: 1/10. Loss: 1.2636:  58%|[36m█████▊    [0m| 15/26 [00:17<00:12,  1.17s/it]Epoch: 1/10. Loss: 1.0936:  58%|[36m█████▊    [0m| 15/26 [00:18<00:12,  1.17s/it]Epoch: 1/10. Loss: 1.0936:  62%|[36m██████▏   [0m| 16/26 [00:18<00:11,  1.13s/it]Epoch: 1/10. Loss: 1.0361:  62%|[36m██████▏   [0m| 16/26 [00:19<00:11,  1.13s/it]Epoch: 1/10. Loss: 1.0361:  65%|[36m██████▌   [0m| 17/26 [00:19<00:09,  1.08s/it]Epoch: 1/10. Loss: 1.0630:  65%|[36m██████▌   [0m| 17/26 [00:20<00:09,  1.08s/it]Epoch: 1/10. Loss: 1.0630:  69%|[36m██████▉   [0m| 18/26 [00:20<00:08,  1.03s/it]Epoch: 1/10. Loss: 1.0960:  69%|[36m██████▉   [0m| 18/26 [00:21<00:08,  1.03s/it]Epoch: 1/10. Loss: 1.0960:  73%|[36m███████▎  [0m| 19/26 [00:21<00:07,  1.05s/it]Epoch: 1/10. Loss: 1.0761:  73%|[36m███████▎  [0m| 19/26 [00:22<00:07,  1.05s/it]Epoch: 1/10. Loss: 1.0761:  77%|[36m███████▋  [0m| 20/26 [00:22<00:06,  1.05s/it]Epoch: 1/10. Loss: 1.0986:  77%|[36m███████▋  [0m| 20/26 [00:23<00:06,  1.05s/it]Epoch: 1/10. Loss: 1.0986:  81%|[36m████████  [0m| 21/26 [00:23<00:05,  1.04s/it]Epoch: 1/10. Loss: 1.0036:  81%|[36m████████  [0m| 21/26 [00:24<00:05,  1.04s/it]Epoch: 1/10. Loss: 1.0036:  85%|[36m████████▍ [0m| 22/26 [00:24<00:03,  1.01it/s]Epoch: 1/10. Loss: 1.3992:  85%|[36m████████▍ [0m| 22/26 [00:25<00:03,  1.01it/s]Epoch: 1/10. Loss: 1.3992:  88%|[36m████████▊ [0m| 23/26 [00:25<00:02,  1.03it/s]Epoch: 1/10. Loss: 1.5113:  88%|[36m████████▊ [0m| 23/26 [00:26<00:02,  1.03it/s]Epoch: 1/10. Loss: 1.5113:  92%|[36m█████████▏[0m| 24/26 [00:26<00:01,  1.06it/s]Epoch: 1/10. Loss: 1.2827:  92%|[36m█████████▏[0m| 24/26 [00:27<00:01,  1.06it/s]Epoch: 1/10. Loss: 1.2827:  96%|[36m█████████▌[0m| 25/26 [00:27<00:00,  1.07it/s]Epoch: 1/10. Loss: 1.3418:  96%|[36m█████████▌[0m| 25/26 [00:28<00:00,  1.07it/s]Epoch: 1/10. Loss: 1.3418: 100%|[36m██████████[0m| 26/26 [00:28<00:00,  1.18it/s]Epoch: 1/10. Loss: 1.3418: 100%|[36m██████████[0m| 26/26 [00:28<00:00,  1.08s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:01<00:08,  1.39s/it] 29%|[33m██▊       [0m| 2/7 [00:02<00:06,  1.35s/it] 43%|[33m████▎     [0m| 3/7 [00:03<00:04,  1.14s/it] 57%|[33m█████▋    [0m| 4/7 [00:05<00:03,  1.26s/it] 71%|[33m███████▏  [0m| 5/7 [00:05<00:01,  1.02it/s] 86%|[33m████████▌ [0m| 6/7 [00:06<00:00,  1.07it/s]100%|[33m██████████[0m| 7/7 [00:06<00:00,  1.38it/s]100%|[33m██████████[0m| 7/7 [00:06<00:00,  1.05it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 2/10. Loss: 0.9778:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 2/10. Loss: 0.9778:   4%|[36m▍         [0m| 1/26 [00:00<00:24,  1.00it/s]Epoch: 2/10. Loss: 0.9785:   4%|[36m▍         [0m| 1/26 [00:02<00:24,  1.00it/s]Epoch: 2/10. Loss: 0.9785:   8%|[36m▊         [0m| 2/26 [00:02<00:25,  1.06s/it]Epoch: 2/10. Loss: 1.1198:   8%|[36m▊         [0m| 2/26 [00:04<00:25,  1.06s/it]Epoch: 2/10. Loss: 1.1198:  12%|[36m█▏        [0m| 3/26 [00:04<00:39,  1.73s/it]Epoch: 2/10. Loss: 1.0044:  12%|[36m█▏        [0m| 3/26 [00:06<00:39,  1.73s/it]Epoch: 2/10. Loss: 1.0044:  15%|[36m█▌        [0m| 4/26 [00:06<00:35,  1.62s/it]Epoch: 2/10. Loss: 1.0816:  15%|[36m█▌        [0m| 4/26 [00:07<00:35,  1.62s/it]Epoch: 2/10. Loss: 1.0816:  19%|[36m█▉        [0m| 5/26 [00:07<00:31,  1.50s/it]Epoch: 2/10. Loss: 0.9275:  19%|[36m█▉        [0m| 5/26 [00:08<00:31,  1.50s/it]Epoch: 2/10. Loss: 0.9275:  23%|[36m██▎       [0m| 6/26 [00:08<00:25,  1.28s/it]Epoch: 2/10. Loss: 1.0914:  23%|[36m██▎       [0m| 6/26 [00:09<00:25,  1.28s/it]Epoch: 2/10. Loss: 1.0914:  27%|[36m██▋       [0m| 7/26 [00:09<00:25,  1.36s/it]Epoch: 2/10. Loss: 1.0639:  27%|[36m██▋       [0m| 7/26 [00:10<00:25,  1.36s/it]Epoch: 2/10. Loss: 1.0639:  31%|[36m███       [0m| 8/26 [00:10<00:22,  1.25s/it]Epoch: 2/10. Loss: 1.0142:  31%|[36m███       [0m| 8/26 [00:11<00:22,  1.25s/it]Epoch: 2/10. Loss: 1.0142:  35%|[36m███▍      [0m| 9/26 [00:11<00:20,  1.18s/it]Epoch: 2/10. Loss: 1.1395:  35%|[36m███▍      [0m| 9/26 [00:12<00:20,  1.18s/it]Epoch: 2/10. Loss: 1.1395:  38%|[36m███▊      [0m| 10/26 [00:12<00:17,  1.08s/it]Epoch: 2/10. Loss: 1.0110:  38%|[36m███▊      [0m| 10/26 [00:13<00:17,  1.08s/it]Epoch: 2/10. Loss: 1.0110:  42%|[36m████▏     [0m| 11/26 [00:13<00:16,  1.13s/it]Epoch: 2/10. Loss: 1.0624:  42%|[36m████▏     [0m| 11/26 [00:14<00:16,  1.13s/it]Epoch: 2/10. Loss: 1.0624:  46%|[36m████▌     [0m| 12/26 [00:14<00:14,  1.06s/it]Epoch: 2/10. Loss: 1.0830:  46%|[36m████▌     [0m| 12/26 [00:15<00:14,  1.06s/it]Epoch: 2/10. Loss: 1.0830:  50%|[36m█████     [0m| 13/26 [00:15<00:13,  1.01s/it]Epoch: 2/10. Loss: 1.0374:  50%|[36m█████     [0m| 13/26 [00:16<00:13,  1.01s/it]Epoch: 2/10. Loss: 1.0374:  54%|[36m█████▍    [0m| 14/26 [00:16<00:12,  1.00s/it]Epoch: 2/10. Loss: 1.0717:  54%|[36m█████▍    [0m| 14/26 [00:17<00:12,  1.00s/it]Epoch: 2/10. Loss: 1.0717:  58%|[36m█████▊    [0m| 15/26 [00:17<00:10,  1.04it/s]Epoch: 2/10. Loss: 0.9639:  58%|[36m█████▊    [0m| 15/26 [00:18<00:10,  1.04it/s]Epoch: 2/10. Loss: 0.9639:  62%|[36m██████▏   [0m| 16/26 [00:18<00:09,  1.04it/s]Epoch: 2/10. Loss: 1.0405:  62%|[36m██████▏   [0m| 16/26 [00:19<00:09,  1.04it/s]Epoch: 2/10. Loss: 1.0405:  65%|[36m██████▌   [0m| 17/26 [00:19<00:08,  1.06it/s]Epoch: 2/10. Loss: 1.0874:  65%|[36m██████▌   [0m| 17/26 [00:20<00:08,  1.06it/s]Epoch: 2/10. Loss: 1.0874:  69%|[36m██████▉   [0m| 18/26 [00:20<00:07,  1.09it/s]Epoch: 2/10. Loss: 1.0553:  69%|[36m██████▉   [0m| 18/26 [00:21<00:07,  1.09it/s]Epoch: 2/10. Loss: 1.0553:  73%|[36m███████▎  [0m| 19/26 [00:21<00:06,  1.09it/s]Epoch: 2/10. Loss: 1.0485:  73%|[36m███████▎  [0m| 19/26 [00:22<00:06,  1.09it/s]Epoch: 2/10. Loss: 1.0485:  77%|[36m███████▋  [0m| 20/26 [00:22<00:05,  1.06it/s]Epoch: 2/10. Loss: 1.0862:  77%|[36m███████▋  [0m| 20/26 [00:23<00:05,  1.06it/s]Epoch: 2/10. Loss: 1.0862:  81%|[36m████████  [0m| 21/26 [00:23<00:04,  1.01it/s]Epoch: 2/10. Loss: 1.0234:  81%|[36m████████  [0m| 21/26 [00:24<00:04,  1.01it/s]Epoch: 2/10. Loss: 1.0234:  85%|[36m████████▍ [0m| 22/26 [00:24<00:04,  1.01s/it]Epoch: 2/10. Loss: 1.0017:  85%|[36m████████▍ [0m| 22/26 [00:25<00:04,  1.01s/it]Epoch: 2/10. Loss: 1.0017:  88%|[36m████████▊ [0m| 23/26 [00:25<00:02,  1.01it/s]Epoch: 2/10. Loss: 1.1162:  88%|[36m████████▊ [0m| 23/26 [00:26<00:02,  1.01it/s]Epoch: 2/10. Loss: 1.1162:  92%|[36m█████████▏[0m| 24/26 [00:26<00:01,  1.05it/s]Epoch: 2/10. Loss: 0.9705:  92%|[36m█████████▏[0m| 24/26 [00:26<00:01,  1.05it/s]Epoch: 2/10. Loss: 0.9705:  96%|[36m█████████▌[0m| 25/26 [00:26<00:00,  1.10it/s]Epoch: 2/10. Loss: 1.1316:  96%|[36m█████████▌[0m| 25/26 [00:27<00:00,  1.10it/s]Epoch: 2/10. Loss: 1.1316: 100%|[36m██████████[0m| 26/26 [00:27<00:00,  1.23it/s]Epoch: 2/10. Loss: 1.1316: 100%|[36m██████████[0m| 26/26 [00:27<00:00,  1.06s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:05,  1.13it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:05,  1.04s/it] 43%|[33m████▎     [0m| 3/7 [00:02<00:03,  1.12it/s] 57%|[33m█████▋    [0m| 4/7 [00:04<00:03,  1.10s/it] 71%|[33m███████▏  [0m| 5/7 [00:04<00:01,  1.14it/s] 86%|[33m████████▌ [0m| 6/7 [00:05<00:00,  1.15it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.47it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.21it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 3/10. Loss: 0.9752:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 3/10. Loss: 0.9752:   4%|[36m▍         [0m| 1/26 [00:00<00:20,  1.23it/s]Epoch: 3/10. Loss: 0.9196:   4%|[36m▍         [0m| 1/26 [00:02<00:20,  1.23it/s]Epoch: 3/10. Loss: 0.9196:   8%|[36m▊         [0m| 2/26 [00:02<00:25,  1.07s/it]Epoch: 3/10. Loss: 0.9508:   8%|[36m▊         [0m| 2/26 [00:02<00:25,  1.07s/it]Epoch: 3/10. Loss: 0.9508:  12%|[36m█▏        [0m| 3/26 [00:02<00:23,  1.00s/it]Epoch: 3/10. Loss: 0.9879:  12%|[36m█▏        [0m| 3/26 [00:03<00:23,  1.00s/it]Epoch: 3/10. Loss: 0.9879:  15%|[36m█▌        [0m| 4/26 [00:03<00:21,  1.02it/s]Epoch: 3/10. Loss: 0.9616:  15%|[36m█▌        [0m| 4/26 [00:04<00:21,  1.02it/s]Epoch: 3/10. Loss: 0.9616:  19%|[36m█▉        [0m| 5/26 [00:04<00:19,  1.05it/s]Epoch: 3/10. Loss: 1.0991:  19%|[36m█▉        [0m| 5/26 [00:05<00:19,  1.05it/s]Epoch: 3/10. Loss: 1.0991:  23%|[36m██▎       [0m| 6/26 [00:05<00:18,  1.07it/s]Epoch: 3/10. Loss: 1.4073:  23%|[36m██▎       [0m| 6/26 [00:06<00:18,  1.07it/s]Epoch: 3/10. Loss: 1.4073:  27%|[36m██▋       [0m| 7/26 [00:06<00:17,  1.07it/s]Epoch: 3/10. Loss: 0.9573:  27%|[36m██▋       [0m| 7/26 [00:07<00:17,  1.07it/s]Epoch: 3/10. Loss: 0.9573:  31%|[36m███       [0m| 8/26 [00:07<00:16,  1.07it/s]Epoch: 3/10. Loss: 1.3642:  31%|[36m███       [0m| 8/26 [00:08<00:16,  1.07it/s]Epoch: 3/10. Loss: 1.3642:  35%|[36m███▍      [0m| 9/26 [00:08<00:16,  1.02it/s]Epoch: 3/10. Loss: 1.0102:  35%|[36m███▍      [0m| 9/26 [00:09<00:16,  1.02it/s]Epoch: 3/10. Loss: 1.0102:  38%|[36m███▊      [0m| 10/26 [00:09<00:14,  1.07it/s]Epoch: 3/10. Loss: 1.1405:  38%|[36m███▊      [0m| 10/26 [00:10<00:14,  1.07it/s]Epoch: 3/10. Loss: 1.1405:  42%|[36m████▏     [0m| 11/26 [00:10<00:15,  1.01s/it]Epoch: 3/10. Loss: 1.0980:  42%|[36m████▏     [0m| 11/26 [00:11<00:15,  1.01s/it]Epoch: 3/10. Loss: 1.0980:  46%|[36m████▌     [0m| 12/26 [00:11<00:13,  1.01it/s]Epoch: 3/10. Loss: 1.1410:  46%|[36m████▌     [0m| 12/26 [00:14<00:13,  1.01it/s]Epoch: 3/10. Loss: 1.1410:  50%|[36m█████     [0m| 13/26 [00:14<00:21,  1.66s/it]Epoch: 3/10. Loss: 0.9365:  50%|[36m█████     [0m| 13/26 [00:15<00:21,  1.66s/it]Epoch: 3/10. Loss: 0.9365:  54%|[36m█████▍    [0m| 14/26 [00:15<00:18,  1.50s/it]Epoch: 3/10. Loss: 1.0701:  54%|[36m█████▍    [0m| 14/26 [00:16<00:18,  1.50s/it]Epoch: 3/10. Loss: 1.0701:  58%|[36m█████▊    [0m| 15/26 [00:16<00:14,  1.34s/it]Epoch: 3/10. Loss: 0.9553:  58%|[36m█████▊    [0m| 15/26 [00:17<00:14,  1.34s/it]Epoch: 3/10. Loss: 0.9553:  62%|[36m██████▏   [0m| 16/26 [00:17<00:12,  1.20s/it]Epoch: 3/10. Loss: 1.0370:  62%|[36m██████▏   [0m| 16/26 [00:18<00:12,  1.20s/it]Epoch: 3/10. Loss: 1.0370:  65%|[36m██████▌   [0m| 17/26 [00:18<00:10,  1.14s/it]Epoch: 3/10. Loss: 1.0511:  65%|[36m██████▌   [0m| 17/26 [00:19<00:10,  1.14s/it]Epoch: 3/10. Loss: 1.0511:  69%|[36m██████▉   [0m| 18/26 [00:19<00:08,  1.09s/it]Epoch: 3/10. Loss: 1.0809:  69%|[36m██████▉   [0m| 18/26 [00:20<00:08,  1.09s/it]Epoch: 3/10. Loss: 1.0809:  73%|[36m███████▎  [0m| 19/26 [00:20<00:07,  1.09s/it]Epoch: 3/10. Loss: 0.9969:  73%|[36m███████▎  [0m| 19/26 [00:22<00:07,  1.09s/it]Epoch: 3/10. Loss: 0.9969:  77%|[36m███████▋  [0m| 20/26 [00:22<00:07,  1.31s/it]Epoch: 3/10. Loss: 1.1294:  77%|[36m███████▋  [0m| 20/26 [00:23<00:07,  1.31s/it]Epoch: 3/10. Loss: 1.1294:  81%|[36m████████  [0m| 21/26 [00:23<00:06,  1.21s/it]Epoch: 3/10. Loss: 1.0453:  81%|[36m████████  [0m| 21/26 [00:24<00:06,  1.21s/it]Epoch: 3/10. Loss: 1.0453:  85%|[36m████████▍ [0m| 22/26 [00:24<00:04,  1.15s/it]Epoch: 3/10. Loss: 1.0295:  85%|[36m████████▍ [0m| 22/26 [00:26<00:04,  1.15s/it]Epoch: 3/10. Loss: 1.0295:  88%|[36m████████▊ [0m| 23/26 [00:26<00:03,  1.26s/it]Epoch: 3/10. Loss: 0.9793:  88%|[36m████████▊ [0m| 23/26 [00:27<00:03,  1.26s/it]Epoch: 3/10. Loss: 0.9793:  92%|[36m█████████▏[0m| 24/26 [00:27<00:02,  1.28s/it]Epoch: 3/10. Loss: 0.9992:  92%|[36m█████████▏[0m| 24/26 [00:28<00:02,  1.28s/it]Epoch: 3/10. Loss: 0.9992:  96%|[36m█████████▌[0m| 25/26 [00:28<00:01,  1.14s/it]Epoch: 3/10. Loss: 1.0769:  96%|[36m█████████▌[0m| 25/26 [00:28<00:01,  1.14s/it]Epoch: 3/10. Loss: 1.0769: 100%|[36m██████████[0m| 26/26 [00:29<00:00,  1.00it/s]Epoch: 3/10. Loss: 1.0769: 100%|[36m██████████[0m| 26/26 [00:29<00:00,  1.12s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:05,  1.09it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:05,  1.08s/it] 43%|[33m████▎     [0m| 3/7 [00:02<00:03,  1.07it/s] 57%|[33m█████▋    [0m| 4/7 [00:04<00:03,  1.14s/it] 71%|[33m███████▏  [0m| 5/7 [00:04<00:01,  1.09it/s] 86%|[33m████████▌ [0m| 6/7 [00:05<00:00,  1.12it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.44it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.17it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 4/10. Loss: 1.0035:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 4/10. Loss: 1.0035:   4%|[36m▍         [0m| 1/26 [00:00<00:23,  1.08it/s]Epoch: 4/10. Loss: 0.9349:   4%|[36m▍         [0m| 1/26 [00:01<00:23,  1.08it/s]Epoch: 4/10. Loss: 0.9349:   8%|[36m▊         [0m| 2/26 [00:01<00:21,  1.12it/s]Epoch: 4/10. Loss: 1.0734:   8%|[36m▊         [0m| 2/26 [00:02<00:21,  1.12it/s]Epoch: 4/10. Loss: 1.0734:  12%|[36m█▏        [0m| 3/26 [00:02<00:20,  1.13it/s]Epoch: 4/10. Loss: 0.9543:  12%|[36m█▏        [0m| 3/26 [00:03<00:20,  1.13it/s]Epoch: 4/10. Loss: 0.9543:  15%|[36m█▌        [0m| 4/26 [00:03<00:22,  1.04s/it]Epoch: 4/10. Loss: 0.9642:  15%|[36m█▌        [0m| 4/26 [00:05<00:22,  1.04s/it]Epoch: 4/10. Loss: 0.9642:  19%|[36m█▉        [0m| 5/26 [00:05<00:23,  1.10s/it]Epoch: 4/10. Loss: 1.1987:  19%|[36m█▉        [0m| 5/26 [00:06<00:23,  1.10s/it]Epoch: 4/10. Loss: 1.1987:  23%|[36m██▎       [0m| 6/26 [00:06<00:21,  1.10s/it]Epoch: 4/10. Loss: 1.0582:  23%|[36m██▎       [0m| 6/26 [00:07<00:21,  1.10s/it]Epoch: 4/10. Loss: 1.0582:  27%|[36m██▋       [0m| 7/26 [00:07<00:21,  1.12s/it]Epoch: 4/10. Loss: 0.9678:  27%|[36m██▋       [0m| 7/26 [00:08<00:21,  1.12s/it]Epoch: 4/10. Loss: 0.9678:  31%|[36m███       [0m| 8/26 [00:08<00:19,  1.06s/it]Epoch: 4/10. Loss: 0.9864:  31%|[36m███       [0m| 8/26 [00:11<00:19,  1.06s/it]Epoch: 4/10. Loss: 0.9864:  35%|[36m███▍      [0m| 9/26 [00:11<00:29,  1.72s/it]Epoch: 4/10. Loss: 1.0190:  35%|[36m███▍      [0m| 9/26 [00:12<00:29,  1.72s/it]Epoch: 4/10. Loss: 1.0190:  38%|[36m███▊      [0m| 10/26 [00:12<00:25,  1.61s/it]Epoch: 4/10. Loss: 1.0280:  38%|[36m███▊      [0m| 10/26 [00:13<00:25,  1.61s/it]Epoch: 4/10. Loss: 1.0280:  42%|[36m████▏     [0m| 11/26 [00:13<00:20,  1.36s/it]Epoch: 4/10. Loss: 1.0514:  42%|[36m████▏     [0m| 11/26 [00:14<00:20,  1.36s/it]Epoch: 4/10. Loss: 1.0514:  46%|[36m████▌     [0m| 12/26 [00:14<00:16,  1.17s/it]Epoch: 4/10. Loss: 0.9515:  46%|[36m████▌     [0m| 12/26 [00:15<00:16,  1.17s/it]Epoch: 4/10. Loss: 0.9515:  50%|[36m█████     [0m| 13/26 [00:15<00:14,  1.08s/it]Epoch: 4/10. Loss: 1.0322:  50%|[36m█████     [0m| 13/26 [00:16<00:14,  1.08s/it]Epoch: 4/10. Loss: 1.0322:  54%|[36m█████▍    [0m| 14/26 [00:16<00:12,  1.05s/it]Epoch: 4/10. Loss: 1.0002:  54%|[36m█████▍    [0m| 14/26 [00:17<00:12,  1.05s/it]Epoch: 4/10. Loss: 1.0002:  58%|[36m█████▊    [0m| 15/26 [00:17<00:11,  1.03s/it]Epoch: 4/10. Loss: 1.0465:  58%|[36m█████▊    [0m| 15/26 [00:18<00:11,  1.03s/it]Epoch: 4/10. Loss: 1.0465:  62%|[36m██████▏   [0m| 16/26 [00:18<00:09,  1.01it/s]Epoch: 4/10. Loss: 1.0828:  62%|[36m██████▏   [0m| 16/26 [00:19<00:09,  1.01it/s]Epoch: 4/10. Loss: 1.0828:  65%|[36m██████▌   [0m| 17/26 [00:19<00:09,  1.02s/it]Epoch: 4/10. Loss: 1.0304:  65%|[36m██████▌   [0m| 17/26 [00:20<00:09,  1.02s/it]Epoch: 4/10. Loss: 1.0304:  69%|[36m██████▉   [0m| 18/26 [00:20<00:08,  1.00s/it]Epoch: 4/10. Loss: 1.0191:  69%|[36m██████▉   [0m| 18/26 [00:21<00:08,  1.00s/it]Epoch: 4/10. Loss: 1.0191:  73%|[36m███████▎  [0m| 19/26 [00:21<00:06,  1.03it/s]Epoch: 4/10. Loss: 0.9664:  73%|[36m███████▎  [0m| 19/26 [00:22<00:06,  1.03it/s]Epoch: 4/10. Loss: 0.9664:  77%|[36m███████▋  [0m| 20/26 [00:22<00:05,  1.04it/s]Epoch: 4/10. Loss: 1.0029:  77%|[36m███████▋  [0m| 20/26 [00:23<00:05,  1.04it/s]Epoch: 4/10. Loss: 1.0029:  81%|[36m████████  [0m| 21/26 [00:23<00:04,  1.01it/s]Epoch: 4/10. Loss: 0.9649:  81%|[36m████████  [0m| 21/26 [00:24<00:04,  1.01it/s]Epoch: 4/10. Loss: 0.9649:  85%|[36m████████▍ [0m| 22/26 [00:24<00:04,  1.03s/it]Epoch: 4/10. Loss: 0.9591:  85%|[36m████████▍ [0m| 22/26 [00:25<00:04,  1.03s/it]Epoch: 4/10. Loss: 0.9591:  88%|[36m████████▊ [0m| 23/26 [00:25<00:02,  1.01it/s]Epoch: 4/10. Loss: 1.0197:  88%|[36m████████▊ [0m| 23/26 [00:25<00:02,  1.01it/s]Epoch: 4/10. Loss: 1.0197:  92%|[36m█████████▏[0m| 24/26 [00:25<00:01,  1.08it/s]Epoch: 4/10. Loss: 0.9454:  92%|[36m█████████▏[0m| 24/26 [00:26<00:01,  1.08it/s]Epoch: 4/10. Loss: 0.9454:  96%|[36m█████████▌[0m| 25/26 [00:26<00:00,  1.10it/s]Epoch: 4/10. Loss: 0.9741:  96%|[36m█████████▌[0m| 25/26 [00:28<00:00,  1.10it/s]Epoch: 4/10. Loss: 0.9741: 100%|[36m██████████[0m| 26/26 [00:28<00:00,  1.10s/it]Epoch: 4/10. Loss: 0.9741: 100%|[36m██████████[0m| 26/26 [00:28<00:00,  1.09s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:02<00:12,  2.10s/it] 29%|[33m██▊       [0m| 2/7 [00:03<00:07,  1.56s/it] 43%|[33m████▎     [0m| 3/7 [00:04<00:04,  1.21s/it] 57%|[33m█████▋    [0m| 4/7 [00:06<00:04,  1.54s/it] 71%|[33m███████▏  [0m| 5/7 [00:06<00:02,  1.15s/it] 86%|[33m████████▌ [0m| 6/7 [00:07<00:01,  1.20s/it]100%|[33m██████████[0m| 7/7 [00:08<00:00,  1.11it/s]100%|[33m██████████[0m| 7/7 [00:08<00:00,  1.16s/it]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 5/10. Loss: 0.9505:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 5/10. Loss: 0.9505:   4%|[36m▍         [0m| 1/26 [00:00<00:22,  1.09it/s]Epoch: 5/10. Loss: 0.9332:   4%|[36m▍         [0m| 1/26 [00:01<00:22,  1.09it/s]Epoch: 5/10. Loss: 0.9332:   8%|[36m▊         [0m| 2/26 [00:01<00:22,  1.05it/s]Epoch: 5/10. Loss: 1.0462:   8%|[36m▊         [0m| 2/26 [00:03<00:22,  1.05it/s]Epoch: 5/10. Loss: 1.0462:  12%|[36m█▏        [0m| 3/26 [00:03<00:24,  1.08s/it]Epoch: 5/10. Loss: 0.9608:  12%|[36m█▏        [0m| 3/26 [00:04<00:24,  1.08s/it]Epoch: 5/10. Loss: 0.9608:  15%|[36m█▌        [0m| 4/26 [00:04<00:22,  1.02s/it]Epoch: 5/10. Loss: 0.9810:  15%|[36m█▌        [0m| 4/26 [00:04<00:22,  1.02s/it]Epoch: 5/10. Loss: 0.9810:  19%|[36m█▉        [0m| 5/26 [00:05<00:21,  1.00s/it]Epoch: 5/10. Loss: 0.9854:  19%|[36m█▉        [0m| 5/26 [00:05<00:21,  1.00s/it]Epoch: 5/10. Loss: 0.9854:  23%|[36m██▎       [0m| 6/26 [00:05<00:19,  1.03it/s]Epoch: 5/10. Loss: 0.9851:  23%|[36m██▎       [0m| 6/26 [00:06<00:19,  1.03it/s]Epoch: 5/10. Loss: 0.9851:  27%|[36m██▋       [0m| 7/26 [00:06<00:18,  1.04it/s]Epoch: 5/10. Loss: 0.9754:  27%|[36m██▋       [0m| 7/26 [00:07<00:18,  1.04it/s]Epoch: 5/10. Loss: 0.9754:  31%|[36m███       [0m| 8/26 [00:07<00:16,  1.08it/s]Epoch: 5/10. Loss: 0.9911:  31%|[36m███       [0m| 8/26 [00:08<00:16,  1.08it/s]Epoch: 5/10. Loss: 0.9911:  35%|[36m███▍      [0m| 9/26 [00:08<00:16,  1.06it/s]Epoch: 5/10. Loss: 0.9880:  35%|[36m███▍      [0m| 9/26 [00:09<00:16,  1.06it/s]Epoch: 5/10. Loss: 0.9880:  38%|[36m███▊      [0m| 10/26 [00:09<00:14,  1.11it/s]Epoch: 5/10. Loss: 1.0116:  38%|[36m███▊      [0m| 10/26 [00:10<00:14,  1.11it/s]Epoch: 5/10. Loss: 1.0116:  42%|[36m████▏     [0m| 11/26 [00:10<00:13,  1.12it/s]Epoch: 5/10. Loss: 0.9365:  42%|[36m████▏     [0m| 11/26 [00:11<00:13,  1.12it/s]Epoch: 5/10. Loss: 0.9365:  46%|[36m████▌     [0m| 12/26 [00:11<00:12,  1.13it/s]Epoch: 5/10. Loss: 0.9519:  46%|[36m████▌     [0m| 12/26 [00:12<00:12,  1.13it/s]Epoch: 5/10. Loss: 0.9519:  50%|[36m█████     [0m| 13/26 [00:12<00:13,  1.03s/it]Epoch: 5/10. Loss: 0.9802:  50%|[36m█████     [0m| 13/26 [00:13<00:13,  1.03s/it]Epoch: 5/10. Loss: 0.9802:  54%|[36m█████▍    [0m| 14/26 [00:13<00:12,  1.04s/it]Epoch: 5/10. Loss: 0.9957:  54%|[36m█████▍    [0m| 14/26 [00:14<00:12,  1.04s/it]Epoch: 5/10. Loss: 0.9957:  58%|[36m█████▊    [0m| 15/26 [00:14<00:11,  1.04s/it]Epoch: 5/10. Loss: 0.9871:  58%|[36m█████▊    [0m| 15/26 [00:15<00:11,  1.04s/it]Epoch: 5/10. Loss: 0.9871:  62%|[36m██████▏   [0m| 16/26 [00:15<00:10,  1.06s/it]Epoch: 5/10. Loss: 0.9652:  62%|[36m██████▏   [0m| 16/26 [00:16<00:10,  1.06s/it]Epoch: 5/10. Loss: 0.9652:  65%|[36m██████▌   [0m| 17/26 [00:16<00:09,  1.02s/it]Epoch: 5/10. Loss: 0.9692:  65%|[36m██████▌   [0m| 17/26 [00:17<00:09,  1.02s/it]Epoch: 5/10. Loss: 0.9692:  69%|[36m██████▉   [0m| 18/26 [00:17<00:08,  1.00s/it]Epoch: 5/10. Loss: 1.0127:  69%|[36m██████▉   [0m| 18/26 [00:18<00:08,  1.00s/it]Epoch: 5/10. Loss: 1.0127:  73%|[36m███████▎  [0m| 19/26 [00:18<00:07,  1.02s/it]Epoch: 5/10. Loss: 0.9692:  73%|[36m███████▎  [0m| 19/26 [00:19<00:07,  1.02s/it]Epoch: 5/10. Loss: 0.9692:  77%|[36m███████▋  [0m| 20/26 [00:19<00:06,  1.06s/it]Epoch: 5/10. Loss: 0.9651:  77%|[36m███████▋  [0m| 20/26 [00:20<00:06,  1.06s/it]Epoch: 5/10. Loss: 0.9651:  81%|[36m████████  [0m| 21/26 [00:20<00:05,  1.06s/it]Epoch: 5/10. Loss: 1.0231:  81%|[36m████████  [0m| 21/26 [00:21<00:05,  1.06s/it]Epoch: 5/10. Loss: 1.0231:  85%|[36m████████▍ [0m| 22/26 [00:21<00:04,  1.01s/it]Epoch: 5/10. Loss: 1.0038:  85%|[36m████████▍ [0m| 22/26 [00:22<00:04,  1.01s/it]Epoch: 5/10. Loss: 1.0038:  88%|[36m████████▊ [0m| 23/26 [00:22<00:02,  1.01it/s]Epoch: 5/10. Loss: 0.9318:  88%|[36m████████▊ [0m| 23/26 [00:23<00:02,  1.01it/s]Epoch: 5/10. Loss: 0.9318:  92%|[36m█████████▏[0m| 24/26 [00:23<00:01,  1.07it/s]Epoch: 5/10. Loss: 0.9965:  92%|[36m█████████▏[0m| 24/26 [00:24<00:01,  1.07it/s]Epoch: 5/10. Loss: 0.9965:  96%|[36m█████████▌[0m| 25/26 [00:24<00:00,  1.06it/s]Epoch: 5/10. Loss: 0.9502:  96%|[36m█████████▌[0m| 25/26 [00:25<00:00,  1.06it/s]Epoch: 5/10. Loss: 0.9502: 100%|[36m██████████[0m| 26/26 [00:25<00:00,  1.21it/s]Epoch: 5/10. Loss: 0.9502: 100%|[36m██████████[0m| 26/26 [00:25<00:00,  1.03it/s]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:05,  1.07it/s] 29%|[33m██▊       [0m| 2/7 [00:04<00:12,  2.49s/it] 43%|[33m████▎     [0m| 3/7 [00:05<00:07,  1.94s/it] 57%|[33m█████▋    [0m| 4/7 [00:07<00:05,  1.75s/it] 71%|[33m███████▏  [0m| 5/7 [00:07<00:02,  1.29s/it] 86%|[33m████████▌ [0m| 6/7 [00:08<00:01,  1.15s/it]100%|[33m██████████[0m| 7/7 [00:08<00:00,  1.16it/s]100%|[33m██████████[0m| 7/7 [00:08<00:00,  1.27s/it]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 6/10. Loss: 0.9389:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 6/10. Loss: 0.9389:   4%|[36m▍         [0m| 1/26 [00:00<00:24,  1.01it/s]Epoch: 6/10. Loss: 0.9910:   4%|[36m▍         [0m| 1/26 [00:01<00:24,  1.01it/s]Epoch: 6/10. Loss: 0.9910:   8%|[36m▊         [0m| 2/26 [00:01<00:22,  1.09it/s]Epoch: 6/10. Loss: 0.9687:   8%|[36m▊         [0m| 2/26 [00:02<00:22,  1.09it/s]Epoch: 6/10. Loss: 0.9687:  12%|[36m█▏        [0m| 3/26 [00:02<00:22,  1.03it/s]Epoch: 6/10. Loss: 1.0095:  12%|[36m█▏        [0m| 3/26 [00:03<00:22,  1.03it/s]Epoch: 6/10. Loss: 1.0095:  15%|[36m█▌        [0m| 4/26 [00:03<00:22,  1.00s/it]Epoch: 6/10. Loss: 0.9645:  15%|[36m█▌        [0m| 4/26 [00:05<00:22,  1.00s/it]Epoch: 6/10. Loss: 0.9645:  19%|[36m█▉        [0m| 5/26 [00:05<00:23,  1.10s/it]Epoch: 6/10. Loss: 0.9179:  19%|[36m█▉        [0m| 5/26 [00:06<00:23,  1.10s/it]Epoch: 6/10. Loss: 0.9179:  23%|[36m██▎       [0m| 6/26 [00:06<00:21,  1.07s/it]Epoch: 6/10. Loss: 1.0131:  23%|[36m██▎       [0m| 6/26 [00:07<00:21,  1.07s/it]Epoch: 6/10. Loss: 1.0131:  27%|[36m██▋       [0m| 7/26 [00:07<00:22,  1.21s/it]Epoch: 6/10. Loss: 0.9727:  27%|[36m██▋       [0m| 7/26 [00:08<00:22,  1.21s/it]Epoch: 6/10. Loss: 0.9727:  31%|[36m███       [0m| 8/26 [00:08<00:21,  1.17s/it]Epoch: 6/10. Loss: 0.9002:  31%|[36m███       [0m| 8/26 [00:09<00:21,  1.17s/it]Epoch: 6/10. Loss: 0.9002:  35%|[36m███▍      [0m| 9/26 [00:09<00:19,  1.12s/it]Epoch: 6/10. Loss: 0.9649:  35%|[36m███▍      [0m| 9/26 [00:10<00:19,  1.12s/it]Epoch: 6/10. Loss: 0.9649:  38%|[36m███▊      [0m| 10/26 [00:10<00:16,  1.06s/it]Epoch: 6/10. Loss: 1.0183:  38%|[36m███▊      [0m| 10/26 [00:11<00:16,  1.06s/it]Epoch: 6/10. Loss: 1.0183:  42%|[36m████▏     [0m| 11/26 [00:11<00:15,  1.04s/it]Epoch: 6/10. Loss: 0.8995:  42%|[36m████▏     [0m| 11/26 [00:12<00:15,  1.04s/it]Epoch: 6/10. Loss: 0.8995:  46%|[36m████▌     [0m| 12/26 [00:12<00:13,  1.05it/s]Epoch: 6/10. Loss: 0.9911:  46%|[36m████▌     [0m| 12/26 [00:13<00:13,  1.05it/s]Epoch: 6/10. Loss: 0.9911:  50%|[36m█████     [0m| 13/26 [00:13<00:12,  1.06it/s]Epoch: 6/10. Loss: 0.9442:  50%|[36m█████     [0m| 13/26 [00:14<00:12,  1.06it/s]Epoch: 6/10. Loss: 0.9442:  54%|[36m█████▍    [0m| 14/26 [00:14<00:10,  1.09it/s]Epoch: 6/10. Loss: 0.9877:  54%|[36m█████▍    [0m| 14/26 [00:15<00:10,  1.09it/s]Epoch: 6/10. Loss: 0.9877:  58%|[36m█████▊    [0m| 15/26 [00:15<00:09,  1.12it/s]Epoch: 6/10. Loss: 0.8933:  58%|[36m█████▊    [0m| 15/26 [00:16<00:09,  1.12it/s]Epoch: 6/10. Loss: 0.8933:  62%|[36m██████▏   [0m| 16/26 [00:16<00:09,  1.11it/s]Epoch: 6/10. Loss: 0.9827:  62%|[36m██████▏   [0m| 16/26 [00:16<00:09,  1.11it/s]Epoch: 6/10. Loss: 0.9827:  65%|[36m██████▌   [0m| 17/26 [00:16<00:08,  1.09it/s]Epoch: 6/10. Loss: 0.9510:  65%|[36m██████▌   [0m| 17/26 [00:17<00:08,  1.09it/s]Epoch: 6/10. Loss: 0.9510:  69%|[36m██████▉   [0m| 18/26 [00:17<00:07,  1.10it/s]Epoch: 6/10. Loss: 1.0031:  69%|[36m██████▉   [0m| 18/26 [00:18<00:07,  1.10it/s]Epoch: 6/10. Loss: 1.0031:  73%|[36m███████▎  [0m| 19/26 [00:18<00:06,  1.09it/s]Epoch: 6/10. Loss: 0.9640:  73%|[36m███████▎  [0m| 19/26 [00:19<00:06,  1.09it/s]Epoch: 6/10. Loss: 0.9640:  77%|[36m███████▋  [0m| 20/26 [00:19<00:05,  1.11it/s]Epoch: 6/10. Loss: 0.9475:  77%|[36m███████▋  [0m| 20/26 [00:20<00:05,  1.11it/s]Epoch: 6/10. Loss: 0.9475:  81%|[36m████████  [0m| 21/26 [00:20<00:04,  1.10it/s]Epoch: 6/10. Loss: 1.0074:  81%|[36m████████  [0m| 21/26 [00:21<00:04,  1.10it/s]Epoch: 6/10. Loss: 1.0074:  85%|[36m████████▍ [0m| 22/26 [00:21<00:03,  1.02it/s]Epoch: 6/10. Loss: 0.8870:  85%|[36m████████▍ [0m| 22/26 [00:22<00:03,  1.02it/s]Epoch: 6/10. Loss: 0.8870:  88%|[36m████████▊ [0m| 23/26 [00:22<00:03,  1.00s/it]Epoch: 6/10. Loss: 0.9370:  88%|[36m████████▊ [0m| 23/26 [00:23<00:03,  1.00s/it]Epoch: 6/10. Loss: 0.9370:  92%|[36m█████████▏[0m| 24/26 [00:23<00:01,  1.05it/s]Epoch: 6/10. Loss: 0.9982:  92%|[36m█████████▏[0m| 24/26 [00:24<00:01,  1.05it/s]Epoch: 6/10. Loss: 0.9982:  96%|[36m█████████▌[0m| 25/26 [00:24<00:00,  1.03it/s]Epoch: 6/10. Loss: 0.8893:  96%|[36m█████████▌[0m| 25/26 [00:25<00:00,  1.03it/s]Epoch: 6/10. Loss: 0.8893: 100%|[36m██████████[0m| 26/26 [00:25<00:00,  1.16it/s]Epoch: 6/10. Loss: 0.8893: 100%|[36m██████████[0m| 26/26 [00:25<00:00,  1.03it/s]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:05,  1.04it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:05,  1.12s/it] 43%|[33m████▎     [0m| 3/7 [00:02<00:03,  1.03it/s] 57%|[33m█████▋    [0m| 4/7 [00:04<00:03,  1.16s/it] 71%|[33m███████▏  [0m| 5/7 [00:04<00:01,  1.09it/s] 86%|[33m████████▌ [0m| 6/7 [00:05<00:00,  1.12it/s]100%|[33m██████████[0m| 7/7 [00:06<00:00,  1.44it/s]100%|[33m██████████[0m| 7/7 [00:06<00:00,  1.16it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 7/10. Loss: 0.9451:   0%|[36m          [0m| 0/26 [00:01<?, ?it/s]Epoch: 7/10. Loss: 0.9451:   4%|[36m▍         [0m| 1/26 [00:01<00:27,  1.11s/it]Epoch: 7/10. Loss: 0.9919:   4%|[36m▍         [0m| 1/26 [00:02<00:27,  1.11s/it]Epoch: 7/10. Loss: 0.9919:   8%|[36m▊         [0m| 2/26 [00:02<00:25,  1.05s/it]Epoch: 7/10. Loss: 0.9924:   8%|[36m▊         [0m| 2/26 [00:03<00:25,  1.05s/it]Epoch: 7/10. Loss: 0.9924:  12%|[36m█▏        [0m| 3/26 [00:03<00:23,  1.01s/it]Epoch: 7/10. Loss: 0.9820:  12%|[36m█▏        [0m| 3/26 [00:04<00:23,  1.01s/it]Epoch: 7/10. Loss: 0.9820:  15%|[36m█▌        [0m| 4/26 [00:04<00:26,  1.18s/it]Epoch: 7/10. Loss: 0.9671:  15%|[36m█▌        [0m| 4/26 [00:05<00:26,  1.18s/it]Epoch: 7/10. Loss: 0.9671:  19%|[36m█▉        [0m| 5/26 [00:05<00:22,  1.05s/it]Epoch: 7/10. Loss: 0.9449:  19%|[36m█▉        [0m| 5/26 [00:06<00:22,  1.05s/it]Epoch: 7/10. Loss: 0.9449:  23%|[36m██▎       [0m| 6/26 [00:06<00:21,  1.08s/it]Epoch: 7/10. Loss: 0.9516:  23%|[36m██▎       [0m| 6/26 [00:07<00:21,  1.08s/it]Epoch: 7/10. Loss: 0.9516:  27%|[36m██▋       [0m| 7/26 [00:07<00:19,  1.01s/it]Epoch: 7/10. Loss: 0.9344:  27%|[36m██▋       [0m| 7/26 [00:08<00:19,  1.01s/it]Epoch: 7/10. Loss: 0.9344:  31%|[36m███       [0m| 8/26 [00:08<00:17,  1.02it/s]Epoch: 7/10. Loss: 0.9123:  31%|[36m███       [0m| 8/26 [00:11<00:17,  1.02it/s]Epoch: 7/10. Loss: 0.9123:  35%|[36m███▍      [0m| 9/26 [00:11<00:27,  1.63s/it]Epoch: 7/10. Loss: 1.0182:  35%|[36m███▍      [0m| 9/26 [00:13<00:27,  1.63s/it]Epoch: 7/10. Loss: 1.0182:  38%|[36m███▊      [0m| 10/26 [00:13<00:28,  1.77s/it]Epoch: 7/10. Loss: 0.9718:  38%|[36m███▊      [0m| 10/26 [00:14<00:28,  1.77s/it]Epoch: 7/10. Loss: 0.9718:  42%|[36m████▏     [0m| 11/26 [00:14<00:22,  1.49s/it]Epoch: 7/10. Loss: 0.9362:  42%|[36m████▏     [0m| 11/26 [00:15<00:22,  1.49s/it]Epoch: 7/10. Loss: 0.9362:  46%|[36m████▌     [0m| 12/26 [00:15<00:18,  1.32s/it]Epoch: 7/10. Loss: 0.9431:  46%|[36m████▌     [0m| 12/26 [00:16<00:18,  1.32s/it]Epoch: 7/10. Loss: 0.9431:  50%|[36m█████     [0m| 13/26 [00:16<00:15,  1.19s/it]Epoch: 7/10. Loss: 0.8865:  50%|[36m█████     [0m| 13/26 [00:17<00:15,  1.19s/it]Epoch: 7/10. Loss: 0.8865:  54%|[36m█████▍    [0m| 14/26 [00:17<00:13,  1.15s/it]Epoch: 7/10. Loss: 0.9087:  54%|[36m█████▍    [0m| 14/26 [00:18<00:13,  1.15s/it]Epoch: 7/10. Loss: 0.9087:  58%|[36m█████▊    [0m| 15/26 [00:18<00:12,  1.09s/it]Epoch: 7/10. Loss: 1.0060:  58%|[36m█████▊    [0m| 15/26 [00:18<00:12,  1.09s/it]Epoch: 7/10. Loss: 1.0060:  62%|[36m██████▏   [0m| 16/26 [00:19<00:10,  1.04s/it]Epoch: 7/10. Loss: 0.9246:  62%|[36m██████▏   [0m| 16/26 [00:19<00:10,  1.04s/it]Epoch: 7/10. Loss: 0.9246:  65%|[36m██████▌   [0m| 17/26 [00:19<00:09,  1.02s/it]Epoch: 7/10. Loss: 1.0062:  65%|[36m██████▌   [0m| 17/26 [00:20<00:09,  1.02s/it]Epoch: 7/10. Loss: 1.0062:  69%|[36m██████▉   [0m| 18/26 [00:20<00:08,  1.01s/it]Epoch: 7/10. Loss: 0.8919:  69%|[36m██████▉   [0m| 18/26 [00:22<00:08,  1.01s/it]Epoch: 7/10. Loss: 0.8919:  73%|[36m███████▎  [0m| 19/26 [00:22<00:07,  1.03s/it]Epoch: 7/10. Loss: 0.9194:  73%|[36m███████▎  [0m| 19/26 [00:22<00:07,  1.03s/it]Epoch: 7/10. Loss: 0.9194:  77%|[36m███████▋  [0m| 20/26 [00:22<00:05,  1.01it/s]Epoch: 7/10. Loss: 0.9617:  77%|[36m███████▋  [0m| 20/26 [00:23<00:05,  1.01it/s]Epoch: 7/10. Loss: 0.9617:  81%|[36m████████  [0m| 21/26 [00:23<00:04,  1.02it/s]Epoch: 7/10. Loss: 0.9490:  81%|[36m████████  [0m| 21/26 [00:24<00:04,  1.02it/s]Epoch: 7/10. Loss: 0.9490:  85%|[36m████████▍ [0m| 22/26 [00:24<00:03,  1.08it/s]Epoch: 7/10. Loss: 0.9697:  85%|[36m████████▍ [0m| 22/26 [00:25<00:03,  1.08it/s]Epoch: 7/10. Loss: 0.9697:  88%|[36m████████▊ [0m| 23/26 [00:25<00:02,  1.08it/s]Epoch: 7/10. Loss: 1.0552:  88%|[36m████████▊ [0m| 23/26 [00:26<00:02,  1.08it/s]Epoch: 7/10. Loss: 1.0552:  92%|[36m█████████▏[0m| 24/26 [00:26<00:01,  1.08it/s]Epoch: 7/10. Loss: 0.9472:  92%|[36m█████████▏[0m| 24/26 [00:27<00:01,  1.08it/s]Epoch: 7/10. Loss: 0.9472:  96%|[36m█████████▌[0m| 25/26 [00:27<00:00,  1.07it/s]Epoch: 7/10. Loss: 0.9492:  96%|[36m█████████▌[0m| 25/26 [00:28<00:00,  1.07it/s]Epoch: 7/10. Loss: 0.9492: 100%|[36m██████████[0m| 26/26 [00:28<00:00,  1.18it/s]Epoch: 7/10. Loss: 0.9492: 100%|[36m██████████[0m| 26/26 [00:28<00:00,  1.08s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:01<00:06,  1.13s/it] 29%|[33m██▊       [0m| 2/7 [00:02<00:05,  1.19s/it] 43%|[33m████▎     [0m| 3/7 [00:03<00:04,  1.00s/it] 57%|[33m█████▋    [0m| 4/7 [00:04<00:03,  1.15s/it] 71%|[33m███████▏  [0m| 5/7 [00:04<00:01,  1.13it/s] 86%|[33m████████▌ [0m| 6/7 [00:05<00:00,  1.19it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.56it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.18it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 8/10. Loss: 0.9358:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 8/10. Loss: 0.9358:   4%|[36m▍         [0m| 1/26 [00:00<00:20,  1.22it/s]Epoch: 8/10. Loss: 0.9321:   4%|[36m▍         [0m| 1/26 [00:01<00:20,  1.22it/s]Epoch: 8/10. Loss: 0.9321:   8%|[36m▊         [0m| 2/26 [00:01<00:23,  1.04it/s]Epoch: 8/10. Loss: 0.9344:   8%|[36m▊         [0m| 2/26 [00:02<00:23,  1.04it/s]Epoch: 8/10. Loss: 0.9344:  12%|[36m█▏        [0m| 3/26 [00:02<00:21,  1.07it/s]Epoch: 8/10. Loss: 0.9727:  12%|[36m█▏        [0m| 3/26 [00:05<00:21,  1.07it/s]Epoch: 8/10. Loss: 0.9727:  15%|[36m█▌        [0m| 4/26 [00:05<00:32,  1.46s/it]Epoch: 8/10. Loss: 0.9592:  15%|[36m█▌        [0m| 4/26 [00:06<00:32,  1.46s/it]Epoch: 8/10. Loss: 0.9592:  19%|[36m█▉        [0m| 5/26 [00:06<00:30,  1.46s/it]Epoch: 8/10. Loss: 0.8732:  19%|[36m█▉        [0m| 5/26 [00:07<00:30,  1.46s/it]Epoch: 8/10. Loss: 0.8732:  23%|[36m██▎       [0m| 6/26 [00:07<00:25,  1.25s/it]Epoch: 8/10. Loss: 0.9085:  23%|[36m██▎       [0m| 6/26 [00:08<00:25,  1.25s/it]Epoch: 8/10. Loss: 0.9085:  27%|[36m██▋       [0m| 7/26 [00:08<00:22,  1.18s/it]Epoch: 8/10. Loss: 0.9168:  27%|[36m██▋       [0m| 7/26 [00:09<00:22,  1.18s/it]Epoch: 8/10. Loss: 0.9168:  31%|[36m███       [0m| 8/26 [00:09<00:19,  1.08s/it]Epoch: 8/10. Loss: 0.9474:  31%|[36m███       [0m| 8/26 [00:10<00:19,  1.08s/it]Epoch: 8/10. Loss: 0.9474:  35%|[36m███▍      [0m| 9/26 [00:10<00:18,  1.07s/it]Epoch: 8/10. Loss: 0.8930:  35%|[36m███▍      [0m| 9/26 [00:11<00:18,  1.07s/it]Epoch: 8/10. Loss: 0.8930:  38%|[36m███▊      [0m| 10/26 [00:11<00:16,  1.00s/it]Epoch: 8/10. Loss: 0.9814:  38%|[36m███▊      [0m| 10/26 [00:11<00:16,  1.00s/it]Epoch: 8/10. Loss: 0.9814:  42%|[36m████▏     [0m| 11/26 [00:11<00:13,  1.08it/s]Epoch: 8/10. Loss: 1.0079:  42%|[36m████▏     [0m| 11/26 [00:13<00:13,  1.08it/s]Epoch: 8/10. Loss: 1.0079:  46%|[36m████▌     [0m| 12/26 [00:13<00:14,  1.01s/it]Epoch: 8/10. Loss: 0.8957:  46%|[36m████▌     [0m| 12/26 [00:13<00:14,  1.01s/it]Epoch: 8/10. Loss: 0.8957:  50%|[36m█████     [0m| 13/26 [00:13<00:12,  1.03it/s]Epoch: 8/10. Loss: 1.0645:  50%|[36m█████     [0m| 13/26 [00:15<00:12,  1.03it/s]Epoch: 8/10. Loss: 1.0645:  54%|[36m█████▍    [0m| 14/26 [00:15<00:12,  1.01s/it]Epoch: 8/10. Loss: 0.8734:  54%|[36m█████▍    [0m| 14/26 [00:16<00:12,  1.01s/it]Epoch: 8/10. Loss: 0.8734:  58%|[36m█████▊    [0m| 15/26 [00:16<00:11,  1.02s/it]Epoch: 8/10. Loss: 1.0301:  58%|[36m█████▊    [0m| 15/26 [00:17<00:11,  1.02s/it]Epoch: 8/10. Loss: 1.0301:  62%|[36m██████▏   [0m| 16/26 [00:17<00:10,  1.03s/it]Epoch: 8/10. Loss: 0.9645:  62%|[36m██████▏   [0m| 16/26 [00:17<00:10,  1.03s/it]Epoch: 8/10. Loss: 0.9645:  65%|[36m██████▌   [0m| 17/26 [00:18<00:08,  1.02it/s]Epoch: 8/10. Loss: 0.9046:  65%|[36m██████▌   [0m| 17/26 [00:19<00:08,  1.02it/s]Epoch: 8/10. Loss: 0.9046:  69%|[36m██████▉   [0m| 18/26 [00:19<00:08,  1.05s/it]Epoch: 8/10. Loss: 0.9714:  69%|[36m██████▉   [0m| 18/26 [00:20<00:08,  1.05s/it]Epoch: 8/10. Loss: 0.9714:  73%|[36m███████▎  [0m| 19/26 [00:20<00:06,  1.01it/s]Epoch: 8/10. Loss: 0.9781:  73%|[36m███████▎  [0m| 19/26 [00:21<00:06,  1.01it/s]Epoch: 8/10. Loss: 0.9781:  77%|[36m███████▋  [0m| 20/26 [00:21<00:05,  1.03it/s]Epoch: 8/10. Loss: 0.9222:  77%|[36m███████▋  [0m| 20/26 [00:22<00:05,  1.03it/s]Epoch: 8/10. Loss: 0.9222:  81%|[36m████████  [0m| 21/26 [00:22<00:05,  1.06s/it]Epoch: 8/10. Loss: 0.8912:  81%|[36m████████  [0m| 21/26 [00:23<00:05,  1.06s/it]Epoch: 8/10. Loss: 0.8912:  85%|[36m████████▍ [0m| 22/26 [00:23<00:04,  1.07s/it]Epoch: 8/10. Loss: 1.0027:  85%|[36m████████▍ [0m| 22/26 [00:26<00:04,  1.07s/it]Epoch: 8/10. Loss: 1.0027:  88%|[36m████████▊ [0m| 23/26 [00:26<00:04,  1.58s/it]Epoch: 8/10. Loss: 0.9255:  88%|[36m████████▊ [0m| 23/26 [00:27<00:04,  1.58s/it]Epoch: 8/10. Loss: 0.9255:  92%|[36m█████████▏[0m| 24/26 [00:27<00:03,  1.61s/it]Epoch: 8/10. Loss: 0.8834:  92%|[36m█████████▏[0m| 24/26 [00:28<00:03,  1.61s/it]Epoch: 8/10. Loss: 0.8834:  96%|[36m█████████▌[0m| 25/26 [00:28<00:01,  1.43s/it]Epoch: 8/10. Loss: 0.9450:  96%|[36m█████████▌[0m| 25/26 [00:29<00:01,  1.43s/it]Epoch: 8/10. Loss: 0.9450: 100%|[36m██████████[0m| 26/26 [00:29<00:00,  1.25s/it]Epoch: 8/10. Loss: 0.9450: 100%|[36m██████████[0m| 26/26 [00:29<00:00,  1.14s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:05,  1.01it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:05,  1.16s/it] 43%|[33m████▎     [0m| 3/7 [00:04<00:06,  1.74s/it] 57%|[33m█████▋    [0m| 4/7 [00:07<00:06,  2.04s/it] 71%|[33m███████▏  [0m| 5/7 [00:07<00:02,  1.45s/it] 86%|[33m████████▌ [0m| 6/7 [00:08<00:01,  1.23s/it]100%|[33m██████████[0m| 7/7 [00:08<00:00,  1.10it/s]100%|[33m██████████[0m| 7/7 [00:08<00:00,  1.23s/it]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 9/10. Loss: 0.9585:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 9/10. Loss: 0.9585:   4%|[36m▍         [0m| 1/26 [00:00<00:18,  1.33it/s]Epoch: 9/10. Loss: 0.9102:   4%|[36m▍         [0m| 1/26 [00:01<00:18,  1.33it/s]Epoch: 9/10. Loss: 0.9102:   8%|[36m▊         [0m| 2/26 [00:01<00:20,  1.20it/s]Epoch: 9/10. Loss: 0.9186:   8%|[36m▊         [0m| 2/26 [00:04<00:20,  1.20it/s]Epoch: 9/10. Loss: 0.9186:  12%|[36m█▏        [0m| 3/26 [00:04<00:42,  1.87s/it]Epoch: 9/10. Loss: 0.9558:  12%|[36m█▏        [0m| 3/26 [00:05<00:42,  1.87s/it]Epoch: 9/10. Loss: 0.9558:  15%|[36m█▌        [0m| 4/26 [00:05<00:31,  1.45s/it]Epoch: 9/10. Loss: 0.9046:  15%|[36m█▌        [0m| 4/26 [00:06<00:31,  1.45s/it]Epoch: 9/10. Loss: 0.9046:  19%|[36m█▉        [0m| 5/26 [00:06<00:26,  1.26s/it]Epoch: 9/10. Loss: 0.9116:  19%|[36m█▉        [0m| 5/26 [00:07<00:26,  1.26s/it]Epoch: 9/10. Loss: 0.9116:  23%|[36m██▎       [0m| 6/26 [00:07<00:23,  1.18s/it]Epoch: 9/10. Loss: 0.9176:  23%|[36m██▎       [0m| 6/26 [00:08<00:23,  1.18s/it]Epoch: 9/10. Loss: 0.9176:  27%|[36m██▋       [0m| 7/26 [00:08<00:22,  1.17s/it]Epoch: 9/10. Loss: 0.9279:  27%|[36m██▋       [0m| 7/26 [00:09<00:22,  1.17s/it]Epoch: 9/10. Loss: 0.9279:  31%|[36m███       [0m| 8/26 [00:09<00:19,  1.06s/it]Epoch: 9/10. Loss: 0.9017:  31%|[36m███       [0m| 8/26 [00:10<00:19,  1.06s/it]Epoch: 9/10. Loss: 0.9017:  35%|[36m███▍      [0m| 9/26 [00:10<00:17,  1.03s/it]Epoch: 9/10. Loss: 0.9008:  35%|[36m███▍      [0m| 9/26 [00:11<00:17,  1.03s/it]Epoch: 9/10. Loss: 0.9008:  38%|[36m███▊      [0m| 10/26 [00:11<00:16,  1.04s/it]Epoch: 9/10. Loss: 0.8997:  38%|[36m███▊      [0m| 10/26 [00:12<00:16,  1.04s/it]Epoch: 9/10. Loss: 0.8997:  42%|[36m████▏     [0m| 11/26 [00:12<00:15,  1.04s/it]Epoch: 9/10. Loss: 0.9284:  42%|[36m████▏     [0m| 11/26 [00:13<00:15,  1.04s/it]Epoch: 9/10. Loss: 0.9284:  46%|[36m████▌     [0m| 12/26 [00:13<00:14,  1.01s/it]Epoch: 9/10. Loss: 1.0020:  46%|[36m████▌     [0m| 12/26 [00:14<00:14,  1.01s/it]Epoch: 9/10. Loss: 1.0020:  50%|[36m█████     [0m| 13/26 [00:14<00:12,  1.02it/s]Epoch: 9/10. Loss: 0.9237:  50%|[36m█████     [0m| 13/26 [00:15<00:12,  1.02it/s]Epoch: 9/10. Loss: 0.9237:  54%|[36m█████▍    [0m| 14/26 [00:16<00:14,  1.17s/it]Epoch: 9/10. Loss: 0.9427:  54%|[36m█████▍    [0m| 14/26 [00:16<00:14,  1.17s/it]Epoch: 9/10. Loss: 0.9427:  58%|[36m█████▊    [0m| 15/26 [00:17<00:12,  1.12s/it]Epoch: 9/10. Loss: 0.9846:  58%|[36m█████▊    [0m| 15/26 [00:18<00:12,  1.12s/it]Epoch: 9/10. Loss: 0.9846:  62%|[36m██████▏   [0m| 16/26 [00:18<00:11,  1.12s/it]Epoch: 9/10. Loss: 0.8992:  62%|[36m██████▏   [0m| 16/26 [00:18<00:11,  1.12s/it]Epoch: 9/10. Loss: 0.8992:  65%|[36m██████▌   [0m| 17/26 [00:18<00:09,  1.03s/it]Epoch: 9/10. Loss: 0.8990:  65%|[36m██████▌   [0m| 17/26 [00:20<00:09,  1.03s/it]Epoch: 9/10. Loss: 0.8990:  69%|[36m██████▉   [0m| 18/26 [00:20<00:08,  1.05s/it]Epoch: 9/10. Loss: 0.8936:  69%|[36m██████▉   [0m| 18/26 [00:22<00:08,  1.05s/it]Epoch: 9/10. Loss: 0.8936:  73%|[36m███████▎  [0m| 19/26 [00:22<00:10,  1.55s/it]Epoch: 9/10. Loss: 0.9862:  73%|[36m███████▎  [0m| 19/26 [00:23<00:10,  1.55s/it]Epoch: 9/10. Loss: 0.9862:  77%|[36m███████▋  [0m| 20/26 [00:23<00:08,  1.38s/it]Epoch: 9/10. Loss: 0.9253:  77%|[36m███████▋  [0m| 20/26 [00:25<00:08,  1.38s/it]Epoch: 9/10. Loss: 0.9253:  81%|[36m████████  [0m| 21/26 [00:25<00:06,  1.40s/it]Epoch: 9/10. Loss: 0.9215:  81%|[36m████████  [0m| 21/26 [00:25<00:06,  1.40s/it]Epoch: 9/10. Loss: 0.9215:  85%|[36m████████▍ [0m| 22/26 [00:26<00:04,  1.23s/it]Epoch: 9/10. Loss: 0.9077:  85%|[36m████████▍ [0m| 22/26 [00:27<00:04,  1.23s/it]Epoch: 9/10. Loss: 0.9077:  88%|[36m████████▊ [0m| 23/26 [00:27<00:03,  1.18s/it]Epoch: 9/10. Loss: 0.9855:  88%|[36m████████▊ [0m| 23/26 [00:28<00:03,  1.18s/it]Epoch: 9/10. Loss: 0.9855:  92%|[36m█████████▏[0m| 24/26 [00:28<00:02,  1.14s/it]Epoch: 9/10. Loss: 0.9268:  92%|[36m█████████▏[0m| 24/26 [00:29<00:02,  1.14s/it]Epoch: 9/10. Loss: 0.9268:  96%|[36m█████████▌[0m| 25/26 [00:29<00:01,  1.09s/it]Epoch: 9/10. Loss: 1.0320:  96%|[36m█████████▌[0m| 25/26 [00:29<00:01,  1.09s/it]Epoch: 9/10. Loss: 1.0320: 100%|[36m██████████[0m| 26/26 [00:29<00:00,  1.07it/s]Epoch: 9/10. Loss: 1.0320: 100%|[36m██████████[0m| 26/26 [00:29<00:00,  1.14s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:02<00:12,  2.00s/it] 29%|[33m██▊       [0m| 2/7 [00:03<00:07,  1.58s/it] 43%|[33m████▎     [0m| 3/7 [00:04<00:04,  1.23s/it] 57%|[33m█████▋    [0m| 4/7 [00:05<00:03,  1.31s/it] 71%|[33m███████▏  [0m| 5/7 [00:05<00:01,  1.01it/s] 86%|[33m████████▌ [0m| 6/7 [00:06<00:00,  1.07it/s]100%|[33m██████████[0m| 7/7 [00:07<00:00,  1.39it/s]100%|[33m██████████[0m| 7/7 [00:07<00:00,  1.01s/it]
/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/models/inception.py:43: FutureWarning: The default weight initialization of inception_v3 will be changed in future releases of torchvision. If you wish to keep the old behavior (which leads to long initialization times due to scipy/scipy#11299), please set init_weights=True.
  warnings.warn(
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 0/10. Loss: 1.2280:   0%|[36m          [0m| 0/26 [00:01<?, ?it/s]Epoch: 0/10. Loss: 1.2280:   4%|[36m▍         [0m| 1/26 [00:01<00:42,  1.68s/it]Epoch: 0/10. Loss: 3.5764:   4%|[36m▍         [0m| 1/26 [00:02<00:42,  1.68s/it]Epoch: 0/10. Loss: 3.5764:   8%|[36m▊         [0m| 2/26 [00:02<00:31,  1.30s/it]Epoch: 0/10. Loss: 2.9758:   8%|[36m▊         [0m| 2/26 [00:03<00:31,  1.30s/it]Epoch: 0/10. Loss: 2.9758:  12%|[36m█▏        [0m| 3/26 [00:03<00:27,  1.19s/it]Epoch: 0/10. Loss: 3.6248:  12%|[36m█▏        [0m| 3/26 [00:04<00:27,  1.19s/it]Epoch: 0/10. Loss: 3.6248:  15%|[36m█▌        [0m| 4/26 [00:04<00:22,  1.01s/it]Epoch: 0/10. Loss: 2.4537:  15%|[36m█▌        [0m| 4/26 [00:05<00:22,  1.01s/it]Epoch: 0/10. Loss: 2.4537:  19%|[36m█▉        [0m| 5/26 [00:05<00:20,  1.05it/s]Epoch: 0/10. Loss: 2.1331:  19%|[36m█▉        [0m| 5/26 [00:06<00:20,  1.05it/s]Epoch: 0/10. Loss: 2.1331:  23%|[36m██▎       [0m| 6/26 [00:06<00:18,  1.07it/s]Epoch: 0/10. Loss: 1.7793:  23%|[36m██▎       [0m| 6/26 [00:07<00:18,  1.07it/s]Epoch: 0/10. Loss: 1.7793:  27%|[36m██▋       [0m| 7/26 [00:07<00:17,  1.09it/s]Epoch: 0/10. Loss: 1.3274:  27%|[36m██▋       [0m| 7/26 [00:08<00:17,  1.09it/s]Epoch: 0/10. Loss: 1.3274:  31%|[36m███       [0m| 8/26 [00:08<00:16,  1.07it/s]Epoch: 0/10. Loss: 1.3706:  31%|[36m███       [0m| 8/26 [00:08<00:16,  1.07it/s]Epoch: 0/10. Loss: 1.3706:  35%|[36m███▍      [0m| 9/26 [00:08<00:15,  1.11it/s]Epoch: 0/10. Loss: 1.4035:  35%|[36m███▍      [0m| 9/26 [00:09<00:15,  1.11it/s]Epoch: 0/10. Loss: 1.4035:  38%|[36m███▊      [0m| 10/26 [00:09<00:14,  1.13it/s]Epoch: 0/10. Loss: 1.4123:  38%|[36m███▊      [0m| 10/26 [00:10<00:14,  1.13it/s]Epoch: 0/10. Loss: 1.4123:  42%|[36m████▏     [0m| 11/26 [00:10<00:13,  1.14it/s]Epoch: 0/10. Loss: 1.0948:  42%|[36m████▏     [0m| 11/26 [00:11<00:13,  1.14it/s]Epoch: 0/10. Loss: 1.0948:  46%|[36m████▌     [0m| 12/26 [00:11<00:11,  1.18it/s]Epoch: 0/10. Loss: 1.5740:  46%|[36m████▌     [0m| 12/26 [00:12<00:11,  1.18it/s]Epoch: 0/10. Loss: 1.5740:  50%|[36m█████     [0m| 13/26 [00:12<00:10,  1.19it/s]Epoch: 0/10. Loss: 1.7524:  50%|[36m█████     [0m| 13/26 [00:13<00:10,  1.19it/s]Epoch: 0/10. Loss: 1.7524:  54%|[36m█████▍    [0m| 14/26 [00:13<00:10,  1.15it/s]Epoch: 0/10. Loss: 1.3792:  54%|[36m█████▍    [0m| 14/26 [00:14<00:10,  1.15it/s]Epoch: 0/10. Loss: 1.3792:  58%|[36m█████▊    [0m| 15/26 [00:14<00:09,  1.13it/s]Epoch: 0/10. Loss: 1.2177:  58%|[36m█████▊    [0m| 15/26 [00:14<00:09,  1.13it/s]Epoch: 0/10. Loss: 1.2177:  62%|[36m██████▏   [0m| 16/26 [00:14<00:08,  1.16it/s]Epoch: 0/10. Loss: 1.1136:  62%|[36m██████▏   [0m| 16/26 [00:16<00:08,  1.16it/s]Epoch: 0/10. Loss: 1.1136:  65%|[36m██████▌   [0m| 17/26 [00:16<00:08,  1.06it/s]Epoch: 0/10. Loss: 1.3286:  65%|[36m██████▌   [0m| 17/26 [00:17<00:08,  1.06it/s]Epoch: 0/10. Loss: 1.3286:  69%|[36m██████▉   [0m| 18/26 [00:17<00:08,  1.06s/it]Epoch: 0/10. Loss: 1.1050:  69%|[36m██████▉   [0m| 18/26 [00:18<00:08,  1.06s/it]Epoch: 0/10. Loss: 1.1050:  73%|[36m███████▎  [0m| 19/26 [00:18<00:06,  1.00it/s]Epoch: 0/10. Loss: 1.1220:  73%|[36m███████▎  [0m| 19/26 [00:19<00:06,  1.00it/s]Epoch: 0/10. Loss: 1.1220:  77%|[36m███████▋  [0m| 20/26 [00:19<00:06,  1.13s/it]Epoch: 0/10. Loss: 1.0693:  77%|[36m███████▋  [0m| 20/26 [00:20<00:06,  1.13s/it]Epoch: 0/10. Loss: 1.0693:  81%|[36m████████  [0m| 21/26 [00:20<00:05,  1.12s/it]Epoch: 0/10. Loss: 1.0489:  81%|[36m████████  [0m| 21/26 [00:21<00:05,  1.12s/it]Epoch: 0/10. Loss: 1.0489:  85%|[36m████████▍ [0m| 22/26 [00:21<00:04,  1.08s/it]Epoch: 0/10. Loss: 1.0825:  85%|[36m████████▍ [0m| 22/26 [00:22<00:04,  1.08s/it]Epoch: 0/10. Loss: 1.0825:  88%|[36m████████▊ [0m| 23/26 [00:22<00:03,  1.04s/it]Epoch: 0/10. Loss: 1.0025:  88%|[36m████████▊ [0m| 23/26 [00:23<00:03,  1.04s/it]Epoch: 0/10. Loss: 1.0025:  92%|[36m█████████▏[0m| 24/26 [00:23<00:02,  1.03s/it]Epoch: 0/10. Loss: 1.1432:  92%|[36m█████████▏[0m| 24/26 [00:24<00:02,  1.03s/it]Epoch: 0/10. Loss: 1.1432:  96%|[36m█████████▌[0m| 25/26 [00:24<00:01,  1.01s/it]Epoch: 0/10. Loss: 1.0735:  96%|[36m█████████▌[0m| 25/26 [00:25<00:01,  1.01s/it]Epoch: 0/10. Loss: 1.0735: 100%|[36m██████████[0m| 26/26 [00:25<00:00,  1.11it/s]Epoch: 0/10. Loss: 1.0735: 100%|[36m██████████[0m| 26/26 [00:25<00:00,  1.03it/s]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:05,  1.04it/s] 29%|[33m██▊       [0m| 2/7 [00:03<00:08,  1.65s/it] 43%|[33m████▎     [0m| 3/7 [00:06<00:09,  2.39s/it] 57%|[33m█████▋    [0m| 4/7 [00:08<00:06,  2.17s/it] 71%|[33m███████▏  [0m| 5/7 [00:08<00:03,  1.54s/it] 86%|[33m████████▌ [0m| 6/7 [00:09<00:01,  1.29s/it]100%|[33m██████████[0m| 7/7 [00:09<00:00,  1.06it/s]100%|[33m██████████[0m| 7/7 [00:09<00:00,  1.38s/it]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 1/10. Loss: 1.0572:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 1/10. Loss: 1.0572:   4%|[36m▍         [0m| 1/26 [00:00<00:22,  1.10it/s]Epoch: 1/10. Loss: 0.9402:   4%|[36m▍         [0m| 1/26 [00:01<00:22,  1.10it/s]Epoch: 1/10. Loss: 0.9402:   8%|[36m▊         [0m| 2/26 [00:01<00:24,  1.00s/it]Epoch: 1/10. Loss: 1.0322:   8%|[36m▊         [0m| 2/26 [00:02<00:24,  1.00s/it]Epoch: 1/10. Loss: 1.0322:  12%|[36m█▏        [0m| 3/26 [00:02<00:22,  1.03it/s]Epoch: 1/10. Loss: 1.1682:  12%|[36m█▏        [0m| 3/26 [00:03<00:22,  1.03it/s]Epoch: 1/10. Loss: 1.1682:  15%|[36m█▌        [0m| 4/26 [00:03<00:19,  1.12it/s]Epoch: 1/10. Loss: 0.9608:  15%|[36m█▌        [0m| 4/26 [00:04<00:19,  1.12it/s]Epoch: 1/10. Loss: 0.9608:  19%|[36m█▉        [0m| 5/26 [00:04<00:17,  1.17it/s]Epoch: 1/10. Loss: 1.2078:  19%|[36m█▉        [0m| 5/26 [00:05<00:17,  1.17it/s]Epoch: 1/10. Loss: 1.2078:  23%|[36m██▎       [0m| 6/26 [00:05<00:17,  1.11it/s]Epoch: 1/10. Loss: 1.0141:  23%|[36m██▎       [0m| 6/26 [00:06<00:17,  1.11it/s]Epoch: 1/10. Loss: 1.0141:  27%|[36m██▋       [0m| 7/26 [00:06<00:17,  1.06it/s]Epoch: 1/10. Loss: 0.9453:  27%|[36m██▋       [0m| 7/26 [00:07<00:17,  1.06it/s]Epoch: 1/10. Loss: 0.9453:  31%|[36m███       [0m| 8/26 [00:07<00:16,  1.06it/s]Epoch: 1/10. Loss: 0.9999:  31%|[36m███       [0m| 8/26 [00:08<00:16,  1.06it/s]Epoch: 1/10. Loss: 0.9999:  35%|[36m███▍      [0m| 9/26 [00:08<00:15,  1.10it/s]Epoch: 1/10. Loss: 1.1121:  35%|[36m███▍      [0m| 9/26 [00:09<00:15,  1.10it/s]Epoch: 1/10. Loss: 1.1121:  38%|[36m███▊      [0m| 10/26 [00:09<00:14,  1.12it/s]Epoch: 1/10. Loss: 0.9971:  38%|[36m███▊      [0m| 10/26 [00:10<00:14,  1.12it/s]Epoch: 1/10. Loss: 0.9971:  42%|[36m████▏     [0m| 11/26 [00:10<00:13,  1.10it/s]Epoch: 1/10. Loss: 1.0300:  42%|[36m████▏     [0m| 11/26 [00:10<00:13,  1.10it/s]Epoch: 1/10. Loss: 1.0300:  46%|[36m████▌     [0m| 12/26 [00:10<00:12,  1.11it/s]Epoch: 1/10. Loss: 1.0807:  46%|[36m████▌     [0m| 12/26 [00:11<00:12,  1.11it/s]Epoch: 1/10. Loss: 1.0807:  50%|[36m█████     [0m| 13/26 [00:11<00:11,  1.13it/s]Epoch: 1/10. Loss: 1.0413:  50%|[36m█████     [0m| 13/26 [00:12<00:11,  1.13it/s]Epoch: 1/10. Loss: 1.0413:  54%|[36m█████▍    [0m| 14/26 [00:12<00:10,  1.15it/s]Epoch: 1/10. Loss: 0.9708:  54%|[36m█████▍    [0m| 14/26 [00:13<00:10,  1.15it/s]Epoch: 1/10. Loss: 0.9708:  58%|[36m█████▊    [0m| 15/26 [00:13<00:09,  1.15it/s]Epoch: 1/10. Loss: 1.1496:  58%|[36m█████▊    [0m| 15/26 [00:14<00:09,  1.15it/s]Epoch: 1/10. Loss: 1.1496:  62%|[36m██████▏   [0m| 16/26 [00:14<00:08,  1.11it/s]Epoch: 1/10. Loss: 1.0714:  62%|[36m██████▏   [0m| 16/26 [00:15<00:08,  1.11it/s]Epoch: 1/10. Loss: 1.0714:  65%|[36m██████▌   [0m| 17/26 [00:15<00:08,  1.11it/s]Epoch: 1/10. Loss: 1.2047:  65%|[36m██████▌   [0m| 17/26 [00:17<00:08,  1.11it/s]Epoch: 1/10. Loss: 1.2047:  69%|[36m██████▉   [0m| 18/26 [00:17<00:10,  1.33s/it]Epoch: 1/10. Loss: 1.0648:  69%|[36m██████▉   [0m| 18/26 [00:18<00:10,  1.33s/it]Epoch: 1/10. Loss: 1.0648:  73%|[36m███████▎  [0m| 19/26 [00:18<00:08,  1.26s/it]Epoch: 1/10. Loss: 0.9815:  73%|[36m███████▎  [0m| 19/26 [00:20<00:08,  1.26s/it]Epoch: 1/10. Loss: 0.9815:  77%|[36m███████▋  [0m| 20/26 [00:20<00:07,  1.31s/it]Epoch: 1/10. Loss: 1.0281:  77%|[36m███████▋  [0m| 20/26 [00:21<00:07,  1.31s/it]Epoch: 1/10. Loss: 1.0281:  81%|[36m████████  [0m| 21/26 [00:21<00:05,  1.16s/it]Epoch: 1/10. Loss: 1.1689:  81%|[36m████████  [0m| 21/26 [00:21<00:05,  1.16s/it]Epoch: 1/10. Loss: 1.1689:  85%|[36m████████▍ [0m| 22/26 [00:21<00:04,  1.09s/it]Epoch: 1/10. Loss: 0.9858:  85%|[36m████████▍ [0m| 22/26 [00:23<00:04,  1.09s/it]Epoch: 1/10. Loss: 0.9858:  88%|[36m████████▊ [0m| 23/26 [00:23<00:03,  1.13s/it]Epoch: 1/10. Loss: 1.1312:  88%|[36m████████▊ [0m| 23/26 [00:24<00:03,  1.13s/it]Epoch: 1/10. Loss: 1.1312:  92%|[36m█████████▏[0m| 24/26 [00:24<00:02,  1.06s/it]Epoch: 1/10. Loss: 0.9873:  92%|[36m█████████▏[0m| 24/26 [00:25<00:02,  1.06s/it]Epoch: 1/10. Loss: 0.9873:  96%|[36m█████████▌[0m| 25/26 [00:25<00:01,  1.04s/it]Epoch: 1/10. Loss: 1.2242:  96%|[36m█████████▌[0m| 25/26 [00:25<00:01,  1.04s/it]Epoch: 1/10. Loss: 1.2242: 100%|[36m██████████[0m| 26/26 [00:25<00:00,  1.08it/s]Epoch: 1/10. Loss: 1.2242: 100%|[36m██████████[0m| 26/26 [00:25<00:00,  1.01it/s]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:05,  1.04it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:05,  1.14s/it] 43%|[33m████▎     [0m| 3/7 [00:03<00:03,  1.00it/s] 57%|[33m█████▋    [0m| 4/7 [00:04<00:03,  1.15s/it] 71%|[33m███████▏  [0m| 5/7 [00:04<00:01,  1.13it/s] 86%|[33m████████▌ [0m| 6/7 [00:05<00:00,  1.17it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.53it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.19it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 2/10. Loss: 0.9606:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 2/10. Loss: 0.9606:   4%|[36m▍         [0m| 1/26 [00:00<00:21,  1.15it/s]Epoch: 2/10. Loss: 0.9995:   4%|[36m▍         [0m| 1/26 [00:01<00:21,  1.15it/s]Epoch: 2/10. Loss: 0.9995:   8%|[36m▊         [0m| 2/26 [00:01<00:18,  1.27it/s]Epoch: 2/10. Loss: 1.1087:   8%|[36m▊         [0m| 2/26 [00:03<00:18,  1.27it/s]Epoch: 2/10. Loss: 1.1087:  12%|[36m█▏        [0m| 3/26 [00:03<00:26,  1.14s/it]Epoch: 2/10. Loss: 1.1110:  12%|[36m█▏        [0m| 3/26 [00:04<00:26,  1.14s/it]Epoch: 2/10. Loss: 1.1110:  15%|[36m█▌        [0m| 4/26 [00:04<00:24,  1.12s/it]Epoch: 2/10. Loss: 1.0499:  15%|[36m█▌        [0m| 4/26 [00:05<00:24,  1.12s/it]Epoch: 2/10. Loss: 1.0499:  19%|[36m█▉        [0m| 5/26 [00:05<00:21,  1.01s/it]Epoch: 2/10. Loss: 1.0414:  19%|[36m█▉        [0m| 5/26 [00:05<00:21,  1.01s/it]Epoch: 2/10. Loss: 1.0414:  23%|[36m██▎       [0m| 6/26 [00:05<00:19,  1.04it/s]Epoch: 2/10. Loss: 0.9952:  23%|[36m██▎       [0m| 6/26 [00:07<00:19,  1.04it/s]Epoch: 2/10. Loss: 0.9952:  27%|[36m██▋       [0m| 7/26 [00:07<00:19,  1.02s/it]Epoch: 2/10. Loss: 0.9871:  27%|[36m██▋       [0m| 7/26 [00:07<00:19,  1.02s/it]Epoch: 2/10. Loss: 0.9871:  31%|[36m███       [0m| 8/26 [00:07<00:17,  1.02it/s]Epoch: 2/10. Loss: 1.1748:  31%|[36m███       [0m| 8/26 [00:09<00:17,  1.02it/s]Epoch: 2/10. Loss: 1.1748:  35%|[36m███▍      [0m| 9/26 [00:09<00:17,  1.01s/it]Epoch: 2/10. Loss: 1.1314:  35%|[36m███▍      [0m| 9/26 [00:09<00:17,  1.01s/it]Epoch: 2/10. Loss: 1.1314:  38%|[36m███▊      [0m| 10/26 [00:09<00:15,  1.02it/s]Epoch: 2/10. Loss: 0.9647:  38%|[36m███▊      [0m| 10/26 [00:10<00:15,  1.02it/s]Epoch: 2/10. Loss: 0.9647:  42%|[36m████▏     [0m| 11/26 [00:10<00:14,  1.05it/s]Epoch: 2/10. Loss: 0.9557:  42%|[36m████▏     [0m| 11/26 [00:11<00:14,  1.05it/s]Epoch: 2/10. Loss: 0.9557:  46%|[36m████▌     [0m| 12/26 [00:11<00:12,  1.09it/s]Epoch: 2/10. Loss: 1.1937:  46%|[36m████▌     [0m| 12/26 [00:12<00:12,  1.09it/s]Epoch: 2/10. Loss: 1.1937:  50%|[36m█████     [0m| 13/26 [00:12<00:12,  1.03it/s]Epoch: 2/10. Loss: 0.9914:  50%|[36m█████     [0m| 13/26 [00:13<00:12,  1.03it/s]Epoch: 2/10. Loss: 0.9914:  54%|[36m█████▍    [0m| 14/26 [00:13<00:11,  1.05it/s]Epoch: 2/10. Loss: 0.9887:  54%|[36m█████▍    [0m| 14/26 [00:14<00:11,  1.05it/s]Epoch: 2/10. Loss: 0.9887:  58%|[36m█████▊    [0m| 15/26 [00:14<00:10,  1.08it/s]Epoch: 2/10. Loss: 1.0065:  58%|[36m█████▊    [0m| 15/26 [00:15<00:10,  1.08it/s]Epoch: 2/10. Loss: 1.0065:  62%|[36m██████▏   [0m| 16/26 [00:15<00:08,  1.13it/s]Epoch: 2/10. Loss: 0.9437:  62%|[36m██████▏   [0m| 16/26 [00:16<00:08,  1.13it/s]Epoch: 2/10. Loss: 0.9437:  65%|[36m██████▌   [0m| 17/26 [00:16<00:08,  1.10it/s]Epoch: 2/10. Loss: 1.0423:  65%|[36m██████▌   [0m| 17/26 [00:17<00:08,  1.10it/s]Epoch: 2/10. Loss: 1.0423:  69%|[36m██████▉   [0m| 18/26 [00:17<00:07,  1.05it/s]Epoch: 2/10. Loss: 0.9233:  69%|[36m██████▉   [0m| 18/26 [00:18<00:07,  1.05it/s]Epoch: 2/10. Loss: 0.9233:  73%|[36m███████▎  [0m| 19/26 [00:18<00:06,  1.09it/s]Epoch: 2/10. Loss: 1.1319:  73%|[36m███████▎  [0m| 19/26 [00:19<00:06,  1.09it/s]Epoch: 2/10. Loss: 1.1319:  77%|[36m███████▋  [0m| 20/26 [00:19<00:05,  1.07it/s]Epoch: 2/10. Loss: 1.0795:  77%|[36m███████▋  [0m| 20/26 [00:20<00:05,  1.07it/s]Epoch: 2/10. Loss: 1.0795:  81%|[36m████████  [0m| 21/26 [00:20<00:04,  1.04it/s]Epoch: 2/10. Loss: 1.0260:  81%|[36m████████  [0m| 21/26 [00:21<00:04,  1.04it/s]Epoch: 2/10. Loss: 1.0260:  85%|[36m████████▍ [0m| 22/26 [00:21<00:03,  1.03it/s]Epoch: 2/10. Loss: 0.9789:  85%|[36m████████▍ [0m| 22/26 [00:22<00:03,  1.03it/s]Epoch: 2/10. Loss: 0.9789:  88%|[36m████████▊ [0m| 23/26 [00:22<00:02,  1.06it/s]Epoch: 2/10. Loss: 0.9794:  88%|[36m████████▊ [0m| 23/26 [00:23<00:02,  1.06it/s]Epoch: 2/10. Loss: 0.9794:  92%|[36m█████████▏[0m| 24/26 [00:23<00:01,  1.01it/s]Epoch: 2/10. Loss: 1.0067:  92%|[36m█████████▏[0m| 24/26 [00:24<00:01,  1.01it/s]Epoch: 2/10. Loss: 1.0067:  96%|[36m█████████▌[0m| 25/26 [00:24<00:00,  1.01it/s]Epoch: 2/10. Loss: 1.0094:  96%|[36m█████████▌[0m| 25/26 [00:24<00:00,  1.01it/s]Epoch: 2/10. Loss: 1.0094: 100%|[36m██████████[0m| 26/26 [00:24<00:00,  1.10it/s]Epoch: 2/10. Loss: 1.0094: 100%|[36m██████████[0m| 26/26 [00:24<00:00,  1.05it/s]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:01<00:09,  1.61s/it] 29%|[33m██▊       [0m| 2/7 [00:02<00:07,  1.41s/it] 43%|[33m████▎     [0m| 3/7 [00:04<00:05,  1.42s/it] 57%|[33m█████▋    [0m| 4/7 [00:06<00:04,  1.67s/it] 71%|[33m███████▏  [0m| 5/7 [00:06<00:02,  1.22s/it] 86%|[33m████████▌ [0m| 6/7 [00:07<00:01,  1.06s/it]100%|[33m██████████[0m| 7/7 [00:07<00:00,  1.27it/s]100%|[33m██████████[0m| 7/7 [00:07<00:00,  1.11s/it]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 3/10. Loss: 1.0606:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 3/10. Loss: 1.0606:   4%|[36m▍         [0m| 1/26 [00:00<00:22,  1.11it/s]Epoch: 3/10. Loss: 0.9558:   4%|[36m▍         [0m| 1/26 [00:01<00:22,  1.11it/s]Epoch: 3/10. Loss: 0.9558:   8%|[36m▊         [0m| 2/26 [00:01<00:23,  1.02it/s]Epoch: 3/10. Loss: 1.0207:   8%|[36m▊         [0m| 2/26 [00:02<00:23,  1.02it/s]Epoch: 3/10. Loss: 1.0207:  12%|[36m█▏        [0m| 3/26 [00:02<00:21,  1.08it/s]Epoch: 3/10. Loss: 0.9244:  12%|[36m█▏        [0m| 3/26 [00:03<00:21,  1.08it/s]Epoch: 3/10. Loss: 0.9244:  15%|[36m█▌        [0m| 4/26 [00:03<00:20,  1.09it/s]Epoch: 3/10. Loss: 0.9380:  15%|[36m█▌        [0m| 4/26 [00:04<00:20,  1.09it/s]Epoch: 3/10. Loss: 0.9380:  19%|[36m█▉        [0m| 5/26 [00:04<00:18,  1.15it/s]Epoch: 3/10. Loss: 1.0225:  19%|[36m█▉        [0m| 5/26 [00:05<00:18,  1.15it/s]Epoch: 3/10. Loss: 1.0225:  23%|[36m██▎       [0m| 6/26 [00:05<00:18,  1.10it/s]Epoch: 3/10. Loss: 0.9726:  23%|[36m██▎       [0m| 6/26 [00:06<00:18,  1.10it/s]Epoch: 3/10. Loss: 0.9726:  27%|[36m██▋       [0m| 7/26 [00:06<00:16,  1.12it/s]Epoch: 3/10. Loss: 1.0486:  27%|[36m██▋       [0m| 7/26 [00:07<00:16,  1.12it/s]Epoch: 3/10. Loss: 1.0486:  31%|[36m███       [0m| 8/26 [00:07<00:16,  1.10it/s]Epoch: 3/10. Loss: 1.0160:  31%|[36m███       [0m| 8/26 [00:08<00:16,  1.10it/s]Epoch: 3/10. Loss: 1.0160:  35%|[36m███▍      [0m| 9/26 [00:08<00:15,  1.09it/s]Epoch: 3/10. Loss: 1.1714:  35%|[36m███▍      [0m| 9/26 [00:09<00:15,  1.09it/s]Epoch: 3/10. Loss: 1.1714:  38%|[36m███▊      [0m| 10/26 [00:09<00:14,  1.10it/s]Epoch: 3/10. Loss: 0.9958:  38%|[36m███▊      [0m| 10/26 [00:10<00:14,  1.10it/s]Epoch: 3/10. Loss: 0.9958:  42%|[36m████▏     [0m| 11/26 [00:10<00:15,  1.03s/it]Epoch: 3/10. Loss: 0.9996:  42%|[36m████▏     [0m| 11/26 [00:11<00:15,  1.03s/it]Epoch: 3/10. Loss: 0.9996:  46%|[36m████▌     [0m| 12/26 [00:11<00:14,  1.07s/it]Epoch: 3/10. Loss: 1.0176:  46%|[36m████▌     [0m| 12/26 [00:12<00:14,  1.07s/it]Epoch: 3/10. Loss: 1.0176:  50%|[36m█████     [0m| 13/26 [00:12<00:13,  1.01s/it]Epoch: 3/10. Loss: 0.9624:  50%|[36m█████     [0m| 13/26 [00:13<00:13,  1.01s/it]Epoch: 3/10. Loss: 0.9624:  54%|[36m█████▍    [0m| 14/26 [00:13<00:12,  1.01s/it]Epoch: 3/10. Loss: 0.9396:  54%|[36m█████▍    [0m| 14/26 [00:14<00:12,  1.01s/it]Epoch: 3/10. Loss: 0.9396:  58%|[36m█████▊    [0m| 15/26 [00:14<00:10,  1.09it/s]Epoch: 3/10. Loss: 1.0765:  58%|[36m█████▊    [0m| 15/26 [00:14<00:10,  1.09it/s]Epoch: 3/10. Loss: 1.0765:  62%|[36m██████▏   [0m| 16/26 [00:14<00:08,  1.13it/s]Epoch: 3/10. Loss: 0.9784:  62%|[36m██████▏   [0m| 16/26 [00:15<00:08,  1.13it/s]Epoch: 3/10. Loss: 0.9784:  65%|[36m██████▌   [0m| 17/26 [00:15<00:07,  1.15it/s]Epoch: 3/10. Loss: 0.9598:  65%|[36m██████▌   [0m| 17/26 [00:16<00:07,  1.15it/s]Epoch: 3/10. Loss: 0.9598:  69%|[36m██████▉   [0m| 18/26 [00:16<00:07,  1.10it/s]Epoch: 3/10. Loss: 1.0442:  69%|[36m██████▉   [0m| 18/26 [00:17<00:07,  1.10it/s]Epoch: 3/10. Loss: 1.0442:  73%|[36m███████▎  [0m| 19/26 [00:17<00:06,  1.13it/s]Epoch: 3/10. Loss: 1.1379:  73%|[36m███████▎  [0m| 19/26 [00:18<00:06,  1.13it/s]Epoch: 3/10. Loss: 1.1379:  77%|[36m███████▋  [0m| 20/26 [00:18<00:05,  1.11it/s]Epoch: 3/10. Loss: 1.0164:  77%|[36m███████▋  [0m| 20/26 [00:19<00:05,  1.11it/s]Epoch: 3/10. Loss: 1.0164:  81%|[36m████████  [0m| 21/26 [00:19<00:04,  1.19it/s]Epoch: 3/10. Loss: 0.9822:  81%|[36m████████  [0m| 21/26 [00:20<00:04,  1.19it/s]Epoch: 3/10. Loss: 0.9822:  85%|[36m████████▍ [0m| 22/26 [00:20<00:04,  1.02s/it]Epoch: 3/10. Loss: 0.9577:  85%|[36m████████▍ [0m| 22/26 [00:21<00:04,  1.02s/it]Epoch: 3/10. Loss: 0.9577:  88%|[36m████████▊ [0m| 23/26 [00:21<00:02,  1.04it/s]Epoch: 3/10. Loss: 1.0692:  88%|[36m████████▊ [0m| 23/26 [00:23<00:02,  1.04it/s]Epoch: 3/10. Loss: 1.0692:  92%|[36m█████████▏[0m| 24/26 [00:23<00:02,  1.19s/it]Epoch: 3/10. Loss: 1.2232:  92%|[36m█████████▏[0m| 24/26 [00:25<00:02,  1.19s/it]Epoch: 3/10. Loss: 1.2232:  96%|[36m█████████▌[0m| 25/26 [00:25<00:01,  1.39s/it]Epoch: 3/10. Loss: 1.0826:  96%|[36m█████████▌[0m| 25/26 [00:25<00:01,  1.39s/it]Epoch: 3/10. Loss: 1.0826: 100%|[36m██████████[0m| 26/26 [00:25<00:00,  1.18s/it]Epoch: 3/10. Loss: 1.0826: 100%|[36m██████████[0m| 26/26 [00:25<00:00,  1.01it/s]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:01<00:06,  1.02s/it] 29%|[33m██▊       [0m| 2/7 [00:02<00:05,  1.15s/it] 43%|[33m████▎     [0m| 3/7 [00:03<00:03,  1.03it/s] 57%|[33m█████▋    [0m| 4/7 [00:04<00:03,  1.15s/it] 71%|[33m███████▏  [0m| 5/7 [00:04<00:01,  1.12it/s] 86%|[33m████████▌ [0m| 6/7 [00:05<00:00,  1.17it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.54it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.19it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 4/10. Loss: 1.0947:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 4/10. Loss: 1.0947:   4%|[36m▍         [0m| 1/26 [00:00<00:23,  1.04it/s]Epoch: 4/10. Loss: 0.9889:   4%|[36m▍         [0m| 1/26 [00:01<00:23,  1.04it/s]Epoch: 4/10. Loss: 0.9889:   8%|[36m▊         [0m| 2/26 [00:01<00:23,  1.04it/s]Epoch: 4/10. Loss: 1.0327:   8%|[36m▊         [0m| 2/26 [00:02<00:23,  1.04it/s]Epoch: 4/10. Loss: 1.0327:  12%|[36m█▏        [0m| 3/26 [00:02<00:22,  1.03it/s]Epoch: 4/10. Loss: 1.3484:  12%|[36m█▏        [0m| 3/26 [00:03<00:22,  1.03it/s]Epoch: 4/10. Loss: 1.3484:  15%|[36m█▌        [0m| 4/26 [00:03<00:20,  1.07it/s]Epoch: 4/10. Loss: 0.9961:  15%|[36m█▌        [0m| 4/26 [00:04<00:20,  1.07it/s]Epoch: 4/10. Loss: 0.9961:  19%|[36m█▉        [0m| 5/26 [00:04<00:20,  1.00it/s]Epoch: 4/10. Loss: 1.2332:  19%|[36m█▉        [0m| 5/26 [00:07<00:20,  1.00it/s]Epoch: 4/10. Loss: 1.2332:  23%|[36m██▎       [0m| 6/26 [00:07<00:29,  1.49s/it]Epoch: 4/10. Loss: 1.0855:  23%|[36m██▎       [0m| 6/26 [00:08<00:29,  1.49s/it]Epoch: 4/10. Loss: 1.0855:  27%|[36m██▋       [0m| 7/26 [00:08<00:24,  1.30s/it]Epoch: 4/10. Loss: 0.9707:  27%|[36m██▋       [0m| 7/26 [00:09<00:24,  1.30s/it]Epoch: 4/10. Loss: 0.9707:  31%|[36m███       [0m| 8/26 [00:09<00:21,  1.17s/it]Epoch: 4/10. Loss: 1.0960:  31%|[36m███       [0m| 8/26 [00:10<00:21,  1.17s/it]Epoch: 4/10. Loss: 1.0960:  35%|[36m███▍      [0m| 9/26 [00:10<00:18,  1.09s/it]Epoch: 4/10. Loss: 1.2114:  35%|[36m███▍      [0m| 9/26 [00:10<00:18,  1.09s/it]Epoch: 4/10. Loss: 1.2114:  38%|[36m███▊      [0m| 10/26 [00:10<00:15,  1.01it/s]Epoch: 4/10. Loss: 1.0409:  38%|[36m███▊      [0m| 10/26 [00:11<00:15,  1.01it/s]Epoch: 4/10. Loss: 1.0409:  42%|[36m████▏     [0m| 11/26 [00:11<00:14,  1.02it/s]Epoch: 4/10. Loss: 0.9876:  42%|[36m████▏     [0m| 11/26 [00:12<00:14,  1.02it/s]Epoch: 4/10. Loss: 0.9876:  46%|[36m████▌     [0m| 12/26 [00:12<00:13,  1.05it/s]Epoch: 4/10. Loss: 1.0480:  46%|[36m████▌     [0m| 12/26 [00:13<00:13,  1.05it/s]Epoch: 4/10. Loss: 1.0480:  50%|[36m█████     [0m| 13/26 [00:13<00:12,  1.04it/s]Epoch: 4/10. Loss: 1.1316:  50%|[36m█████     [0m| 13/26 [00:14<00:12,  1.04it/s]Epoch: 4/10. Loss: 1.1316:  54%|[36m█████▍    [0m| 14/26 [00:14<00:11,  1.04it/s]Epoch: 4/10. Loss: 1.1719:  54%|[36m█████▍    [0m| 14/26 [00:15<00:11,  1.04it/s]Epoch: 4/10. Loss: 1.1719:  58%|[36m█████▊    [0m| 15/26 [00:15<00:10,  1.06it/s]Epoch: 4/10. Loss: 0.9253:  58%|[36m█████▊    [0m| 15/26 [00:16<00:10,  1.06it/s]Epoch: 4/10. Loss: 0.9253:  62%|[36m██████▏   [0m| 16/26 [00:16<00:09,  1.07it/s]Epoch: 4/10. Loss: 0.9850:  62%|[36m██████▏   [0m| 16/26 [00:17<00:09,  1.07it/s]Epoch: 4/10. Loss: 0.9850:  65%|[36m██████▌   [0m| 17/26 [00:17<00:07,  1.17it/s]Epoch: 4/10. Loss: 0.9876:  65%|[36m██████▌   [0m| 17/26 [00:18<00:07,  1.17it/s]Epoch: 4/10. Loss: 0.9876:  69%|[36m██████▉   [0m| 18/26 [00:18<00:07,  1.12it/s]Epoch: 4/10. Loss: 1.1095:  69%|[36m██████▉   [0m| 18/26 [00:19<00:07,  1.12it/s]Epoch: 4/10. Loss: 1.1095:  73%|[36m███████▎  [0m| 19/26 [00:19<00:06,  1.09it/s]Epoch: 4/10. Loss: 0.9234:  73%|[36m███████▎  [0m| 19/26 [00:19<00:06,  1.09it/s]Epoch: 4/10. Loss: 0.9234:  77%|[36m███████▋  [0m| 20/26 [00:19<00:05,  1.09it/s]Epoch: 4/10. Loss: 0.9548:  77%|[36m███████▋  [0m| 20/26 [00:20<00:05,  1.09it/s]Epoch: 4/10. Loss: 0.9548:  81%|[36m████████  [0m| 21/26 [00:20<00:04,  1.08it/s]Epoch: 4/10. Loss: 1.1051:  81%|[36m████████  [0m| 21/26 [00:21<00:04,  1.08it/s]Epoch: 4/10. Loss: 1.1051:  85%|[36m████████▍ [0m| 22/26 [00:21<00:03,  1.10it/s]Epoch: 4/10. Loss: 1.0622:  85%|[36m████████▍ [0m| 22/26 [00:22<00:03,  1.10it/s]Epoch: 4/10. Loss: 1.0622:  88%|[36m████████▊ [0m| 23/26 [00:22<00:02,  1.14it/s]Epoch: 4/10. Loss: 0.9621:  88%|[36m████████▊ [0m| 23/26 [00:23<00:02,  1.14it/s]Epoch: 4/10. Loss: 0.9621:  92%|[36m█████████▏[0m| 24/26 [00:23<00:01,  1.12it/s]Epoch: 4/10. Loss: 1.0632:  92%|[36m█████████▏[0m| 24/26 [00:24<00:01,  1.12it/s]Epoch: 4/10. Loss: 1.0632:  96%|[36m█████████▌[0m| 25/26 [00:24<00:00,  1.09it/s]Epoch: 4/10. Loss: 1.0717:  96%|[36m█████████▌[0m| 25/26 [00:25<00:00,  1.09it/s]Epoch: 4/10. Loss: 1.0717: 100%|[36m██████████[0m| 26/26 [00:25<00:00,  1.19it/s]Epoch: 4/10. Loss: 1.0717: 100%|[36m██████████[0m| 26/26 [00:25<00:00,  1.03it/s]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:05,  1.16it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:05,  1.03s/it] 43%|[33m████▎     [0m| 3/7 [00:02<00:03,  1.15it/s] 57%|[33m█████▋    [0m| 4/7 [00:03<00:03,  1.04s/it] 71%|[33m███████▏  [0m| 5/7 [00:04<00:01,  1.22it/s] 86%|[33m████████▌ [0m| 6/7 [00:05<00:00,  1.23it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.61it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.29it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 5/10. Loss: 1.1174:   0%|[36m          [0m| 0/26 [00:01<?, ?it/s]Epoch: 5/10. Loss: 1.1174:   4%|[36m▍         [0m| 1/26 [00:01<00:27,  1.11s/it]Epoch: 5/10. Loss: 0.9939:   4%|[36m▍         [0m| 1/26 [00:01<00:27,  1.11s/it]Epoch: 5/10. Loss: 0.9939:   8%|[36m▊         [0m| 2/26 [00:01<00:23,  1.03it/s]Epoch: 5/10. Loss: 1.1067:   8%|[36m▊         [0m| 2/26 [00:04<00:23,  1.03it/s]Epoch: 5/10. Loss: 1.1067:  12%|[36m█▏        [0m| 3/26 [00:04<00:38,  1.66s/it]Epoch: 5/10. Loss: 0.9783:  12%|[36m█▏        [0m| 3/26 [00:05<00:38,  1.66s/it]Epoch: 5/10. Loss: 0.9783:  15%|[36m█▌        [0m| 4/26 [00:05<00:30,  1.38s/it]Epoch: 5/10. Loss: 0.9517:  15%|[36m█▌        [0m| 4/26 [00:06<00:30,  1.38s/it]Epoch: 5/10. Loss: 0.9517:  19%|[36m█▉        [0m| 5/26 [00:06<00:26,  1.26s/it]Epoch: 5/10. Loss: 0.9666:  19%|[36m█▉        [0m| 5/26 [00:07<00:26,  1.26s/it]Epoch: 5/10. Loss: 0.9666:  23%|[36m██▎       [0m| 6/26 [00:07<00:21,  1.08s/it]Epoch: 5/10. Loss: 1.0797:  23%|[36m██▎       [0m| 6/26 [00:08<00:21,  1.08s/it]Epoch: 5/10. Loss: 1.0797:  27%|[36m██▋       [0m| 7/26 [00:08<00:19,  1.05s/it]Epoch: 5/10. Loss: 1.0948:  27%|[36m██▋       [0m| 7/26 [00:09<00:19,  1.05s/it]Epoch: 5/10. Loss: 1.0948:  31%|[36m███       [0m| 8/26 [00:09<00:18,  1.05s/it]Epoch: 5/10. Loss: 1.0051:  31%|[36m███       [0m| 8/26 [00:10<00:18,  1.05s/it]Epoch: 5/10. Loss: 1.0051:  35%|[36m███▍      [0m| 9/26 [00:10<00:17,  1.05s/it]Epoch: 5/10. Loss: 1.2881:  35%|[36m███▍      [0m| 9/26 [00:11<00:17,  1.05s/it]Epoch: 5/10. Loss: 1.2881:  38%|[36m███▊      [0m| 10/26 [00:11<00:16,  1.01s/it]Epoch: 5/10. Loss: 1.1028:  38%|[36m███▊      [0m| 10/26 [00:12<00:16,  1.01s/it]Epoch: 5/10. Loss: 1.1028:  42%|[36m████▏     [0m| 11/26 [00:12<00:15,  1.01s/it]Epoch: 5/10. Loss: 0.9954:  42%|[36m████▏     [0m| 11/26 [00:13<00:15,  1.01s/it]Epoch: 5/10. Loss: 0.9954:  46%|[36m████▌     [0m| 12/26 [00:13<00:13,  1.05it/s]Epoch: 5/10. Loss: 1.1062:  46%|[36m████▌     [0m| 12/26 [00:14<00:13,  1.05it/s]Epoch: 5/10. Loss: 1.1062:  50%|[36m█████     [0m| 13/26 [00:14<00:12,  1.01it/s]Epoch: 5/10. Loss: 1.0452:  50%|[36m█████     [0m| 13/26 [00:15<00:12,  1.01it/s]Epoch: 5/10. Loss: 1.0452:  54%|[36m█████▍    [0m| 14/26 [00:15<00:11,  1.02it/s]Epoch: 5/10. Loss: 1.0831:  54%|[36m█████▍    [0m| 14/26 [00:15<00:11,  1.02it/s]Epoch: 5/10. Loss: 1.0831:  58%|[36m█████▊    [0m| 15/26 [00:15<00:10,  1.06it/s]Epoch: 5/10. Loss: 0.9383:  58%|[36m█████▊    [0m| 15/26 [00:16<00:10,  1.06it/s]Epoch: 5/10. Loss: 0.9383:  62%|[36m██████▏   [0m| 16/26 [00:16<00:08,  1.15it/s]Epoch: 5/10. Loss: 1.1405:  62%|[36m██████▏   [0m| 16/26 [00:17<00:08,  1.15it/s]Epoch: 5/10. Loss: 1.1405:  65%|[36m██████▌   [0m| 17/26 [00:17<00:07,  1.15it/s]Epoch: 5/10. Loss: 1.0430:  65%|[36m██████▌   [0m| 17/26 [00:19<00:07,  1.15it/s]Epoch: 5/10. Loss: 1.0430:  69%|[36m██████▉   [0m| 18/26 [00:19<00:10,  1.28s/it]Epoch: 5/10. Loss: 0.8870:  69%|[36m██████▉   [0m| 18/26 [00:21<00:10,  1.28s/it]Epoch: 5/10. Loss: 0.8870:  73%|[36m███████▎  [0m| 19/26 [00:21<00:10,  1.47s/it]Epoch: 5/10. Loss: 0.9865:  73%|[36m███████▎  [0m| 19/26 [00:24<00:10,  1.47s/it]Epoch: 5/10. Loss: 0.9865:  77%|[36m███████▋  [0m| 20/26 [00:24<00:11,  1.91s/it]Epoch: 5/10. Loss: 1.2203:  77%|[36m███████▋  [0m| 20/26 [00:26<00:11,  1.91s/it]Epoch: 5/10. Loss: 1.2203:  81%|[36m████████  [0m| 21/26 [00:26<00:09,  1.87s/it]Epoch: 5/10. Loss: 1.0473:  81%|[36m████████  [0m| 21/26 [00:27<00:09,  1.87s/it]Epoch: 5/10. Loss: 1.0473:  85%|[36m████████▍ [0m| 22/26 [00:27<00:06,  1.57s/it]Epoch: 5/10. Loss: 0.9746:  85%|[36m████████▍ [0m| 22/26 [00:28<00:06,  1.57s/it]Epoch: 5/10. Loss: 0.9746:  88%|[36m████████▊ [0m| 23/26 [00:28<00:04,  1.38s/it]Epoch: 5/10. Loss: 0.9941:  88%|[36m████████▊ [0m| 23/26 [00:29<00:04,  1.38s/it]Epoch: 5/10. Loss: 0.9941:  92%|[36m█████████▏[0m| 24/26 [00:30<00:03,  1.53s/it]Epoch: 5/10. Loss: 0.9665:  92%|[36m█████████▏[0m| 24/26 [00:30<00:03,  1.53s/it]Epoch: 5/10. Loss: 0.9665:  96%|[36m█████████▌[0m| 25/26 [00:30<00:01,  1.32s/it]Epoch: 5/10. Loss: 1.0203:  96%|[36m█████████▌[0m| 25/26 [00:32<00:01,  1.32s/it]Epoch: 5/10. Loss: 1.0203: 100%|[36m██████████[0m| 26/26 [00:32<00:00,  1.49s/it]Epoch: 5/10. Loss: 1.0203: 100%|[36m██████████[0m| 26/26 [00:32<00:00,  1.26s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:01<00:06,  1.00s/it] 29%|[33m██▊       [0m| 2/7 [00:02<00:05,  1.08s/it] 43%|[33m████▎     [0m| 3/7 [00:02<00:03,  1.08it/s] 57%|[33m█████▋    [0m| 4/7 [00:04<00:03,  1.07s/it] 71%|[33m███████▏  [0m| 5/7 [00:04<00:01,  1.18it/s] 86%|[33m████████▌ [0m| 6/7 [00:05<00:00,  1.21it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.58it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.24it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 6/10. Loss: 0.9717:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 6/10. Loss: 0.9717:   4%|[36m▍         [0m| 1/26 [00:00<00:21,  1.14it/s]Epoch: 6/10. Loss: 0.9821:   4%|[36m▍         [0m| 1/26 [00:01<00:21,  1.14it/s]Epoch: 6/10. Loss: 0.9821:   8%|[36m▊         [0m| 2/26 [00:01<00:21,  1.11it/s]Epoch: 6/10. Loss: 0.9967:   8%|[36m▊         [0m| 2/26 [00:02<00:21,  1.11it/s]Epoch: 6/10. Loss: 0.9967:  12%|[36m█▏        [0m| 3/26 [00:02<00:21,  1.09it/s]Epoch: 6/10. Loss: 1.0764:  12%|[36m█▏        [0m| 3/26 [00:03<00:21,  1.09it/s]Epoch: 6/10. Loss: 1.0764:  15%|[36m█▌        [0m| 4/26 [00:03<00:22,  1.03s/it]Epoch: 6/10. Loss: 1.0414:  15%|[36m█▌        [0m| 4/26 [00:04<00:22,  1.03s/it]Epoch: 6/10. Loss: 1.0414:  19%|[36m█▉        [0m| 5/26 [00:04<00:20,  1.03it/s]Epoch: 6/10. Loss: 1.0065:  19%|[36m█▉        [0m| 5/26 [00:06<00:20,  1.03it/s]Epoch: 6/10. Loss: 1.0065:  23%|[36m██▎       [0m| 6/26 [00:06<00:21,  1.06s/it]Epoch: 6/10. Loss: 1.1625:  23%|[36m██▎       [0m| 6/26 [00:06<00:21,  1.06s/it]Epoch: 6/10. Loss: 1.1625:  27%|[36m██▋       [0m| 7/26 [00:06<00:19,  1.00s/it]Epoch: 6/10. Loss: 1.1272:  27%|[36m██▋       [0m| 7/26 [00:07<00:19,  1.00s/it]Epoch: 6/10. Loss: 1.1272:  31%|[36m███       [0m| 8/26 [00:07<00:17,  1.05it/s]Epoch: 6/10. Loss: 1.1191:  31%|[36m███       [0m| 8/26 [00:08<00:17,  1.05it/s]Epoch: 6/10. Loss: 1.1191:  35%|[36m███▍      [0m| 9/26 [00:08<00:15,  1.11it/s]Epoch: 6/10. Loss: 0.9372:  35%|[36m███▍      [0m| 9/26 [00:09<00:15,  1.11it/s]Epoch: 6/10. Loss: 0.9372:  38%|[36m███▊      [0m| 10/26 [00:09<00:14,  1.08it/s]Epoch: 6/10. Loss: 1.0501:  38%|[36m███▊      [0m| 10/26 [00:10<00:14,  1.08it/s]Epoch: 6/10. Loss: 1.0501:  42%|[36m████▏     [0m| 11/26 [00:10<00:15,  1.03s/it]Epoch: 6/10. Loss: 0.9681:  42%|[36m████▏     [0m| 11/26 [00:11<00:15,  1.03s/it]Epoch: 6/10. Loss: 0.9681:  46%|[36m████▌     [0m| 12/26 [00:11<00:13,  1.05it/s]Epoch: 6/10. Loss: 0.9784:  46%|[36m████▌     [0m| 12/26 [00:12<00:13,  1.05it/s]Epoch: 6/10. Loss: 0.9784:  50%|[36m█████     [0m| 13/26 [00:12<00:12,  1.04it/s]Epoch: 6/10. Loss: 1.1698:  50%|[36m█████     [0m| 13/26 [00:13<00:12,  1.04it/s]Epoch: 6/10. Loss: 1.1698:  54%|[36m█████▍    [0m| 14/26 [00:13<00:11,  1.07it/s]Epoch: 6/10. Loss: 1.0793:  54%|[36m█████▍    [0m| 14/26 [00:14<00:11,  1.07it/s]Epoch: 6/10. Loss: 1.0793:  58%|[36m█████▊    [0m| 15/26 [00:14<00:12,  1.09s/it]Epoch: 6/10. Loss: 1.1019:  58%|[36m█████▊    [0m| 15/26 [00:15<00:12,  1.09s/it]Epoch: 6/10. Loss: 1.1019:  62%|[36m██████▏   [0m| 16/26 [00:15<00:10,  1.07s/it]Epoch: 6/10. Loss: 0.9768:  62%|[36m██████▏   [0m| 16/26 [00:17<00:10,  1.07s/it]Epoch: 6/10. Loss: 0.9768:  65%|[36m██████▌   [0m| 17/26 [00:17<00:10,  1.14s/it]Epoch: 6/10. Loss: 1.0029:  65%|[36m██████▌   [0m| 17/26 [00:18<00:10,  1.14s/it]Epoch: 6/10. Loss: 1.0029:  69%|[36m██████▉   [0m| 18/26 [00:18<00:08,  1.09s/it]Epoch: 6/10. Loss: 1.1064:  69%|[36m██████▉   [0m| 18/26 [00:19<00:08,  1.09s/it]Epoch: 6/10. Loss: 1.1064:  73%|[36m███████▎  [0m| 19/26 [00:19<00:07,  1.07s/it]Epoch: 6/10. Loss: 0.9287:  73%|[36m███████▎  [0m| 19/26 [00:20<00:07,  1.07s/it]Epoch: 6/10. Loss: 0.9287:  77%|[36m███████▋  [0m| 20/26 [00:20<00:06,  1.03s/it]Epoch: 6/10. Loss: 1.0093:  77%|[36m███████▋  [0m| 20/26 [00:21<00:06,  1.03s/it]Epoch: 6/10. Loss: 1.0093:  81%|[36m████████  [0m| 21/26 [00:21<00:05,  1.01s/it]Epoch: 6/10. Loss: 0.9330:  81%|[36m████████  [0m| 21/26 [00:21<00:05,  1.01s/it]Epoch: 6/10. Loss: 0.9330:  85%|[36m████████▍ [0m| 22/26 [00:21<00:03,  1.06it/s]Epoch: 6/10. Loss: 0.9599:  85%|[36m████████▍ [0m| 22/26 [00:22<00:03,  1.06it/s]Epoch: 6/10. Loss: 0.9599:  88%|[36m████████▊ [0m| 23/26 [00:22<00:02,  1.07it/s]Epoch: 6/10. Loss: 0.9078:  88%|[36m████████▊ [0m| 23/26 [00:23<00:02,  1.07it/s]Epoch: 6/10. Loss: 0.9078:  92%|[36m█████████▏[0m| 24/26 [00:23<00:01,  1.10it/s]Epoch: 6/10. Loss: 1.0066:  92%|[36m█████████▏[0m| 24/26 [00:25<00:01,  1.10it/s]Epoch: 6/10. Loss: 1.0066:  96%|[36m█████████▌[0m| 25/26 [00:25<00:01,  1.30s/it]Epoch: 6/10. Loss: 0.9802:  96%|[36m█████████▌[0m| 25/26 [00:26<00:01,  1.30s/it]Epoch: 6/10. Loss: 0.9802: 100%|[36m██████████[0m| 26/26 [00:26<00:00,  1.09s/it]Epoch: 6/10. Loss: 0.9802: 100%|[36m██████████[0m| 26/26 [00:26<00:00,  1.02s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:05,  1.11it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:05,  1.13s/it] 43%|[33m████▎     [0m| 3/7 [00:02<00:03,  1.05it/s] 57%|[33m█████▋    [0m| 4/7 [00:04<00:03,  1.11s/it] 71%|[33m███████▏  [0m| 5/7 [00:04<00:01,  1.15it/s] 86%|[33m████████▌ [0m| 6/7 [00:05<00:00,  1.19it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.55it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.22it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 7/10. Loss: 1.0293:   0%|[36m          [0m| 0/26 [00:01<?, ?it/s]Epoch: 7/10. Loss: 1.0293:   4%|[36m▍         [0m| 1/26 [00:01<00:26,  1.08s/it]Epoch: 7/10. Loss: 0.9832:   4%|[36m▍         [0m| 1/26 [00:02<00:26,  1.08s/it]Epoch: 7/10. Loss: 0.9832:   8%|[36m▊         [0m| 2/26 [00:02<00:24,  1.03s/it]Epoch: 7/10. Loss: 0.9848:   8%|[36m▊         [0m| 2/26 [00:02<00:24,  1.03s/it]Epoch: 7/10. Loss: 0.9848:  12%|[36m█▏        [0m| 3/26 [00:02<00:20,  1.11it/s]Epoch: 7/10. Loss: 0.9036:  12%|[36m█▏        [0m| 3/26 [00:03<00:20,  1.11it/s]Epoch: 7/10. Loss: 0.9036:  15%|[36m█▌        [0m| 4/26 [00:03<00:19,  1.14it/s]Epoch: 7/10. Loss: 0.9767:  15%|[36m█▌        [0m| 4/26 [00:09<00:19,  1.14it/s]Epoch: 7/10. Loss: 0.9767:  19%|[36m█▉        [0m| 5/26 [00:09<00:57,  2.73s/it]Epoch: 7/10. Loss: 0.8837:  19%|[36m█▉        [0m| 5/26 [00:10<00:57,  2.73s/it]Epoch: 7/10. Loss: 0.8837:  23%|[36m██▎       [0m| 6/26 [00:10<00:43,  2.15s/it]Epoch: 7/10. Loss: 1.0934:  23%|[36m██▎       [0m| 6/26 [00:11<00:43,  2.15s/it]Epoch: 7/10. Loss: 1.0934:  27%|[36m██▋       [0m| 7/26 [00:11<00:33,  1.77s/it]Epoch: 7/10. Loss: 0.9921:  27%|[36m██▋       [0m| 7/26 [00:12<00:33,  1.77s/it]Epoch: 7/10. Loss: 0.9921:  31%|[36m███       [0m| 8/26 [00:12<00:26,  1.47s/it]Epoch: 7/10. Loss: 0.9936:  31%|[36m███       [0m| 8/26 [00:13<00:26,  1.47s/it]Epoch: 7/10. Loss: 0.9936:  35%|[36m███▍      [0m| 9/26 [00:13<00:21,  1.29s/it]Epoch: 7/10. Loss: 1.0845:  35%|[36m███▍      [0m| 9/26 [00:14<00:21,  1.29s/it]Epoch: 7/10. Loss: 1.0845:  38%|[36m███▊      [0m| 10/26 [00:14<00:18,  1.18s/it]Epoch: 7/10. Loss: 0.9714:  38%|[36m███▊      [0m| 10/26 [00:15<00:18,  1.18s/it]Epoch: 7/10. Loss: 0.9714:  42%|[36m████▏     [0m| 11/26 [00:15<00:16,  1.08s/it]Epoch: 7/10. Loss: 0.9454:  42%|[36m████▏     [0m| 11/26 [00:15<00:16,  1.08s/it]Epoch: 7/10. Loss: 0.9454:  46%|[36m████▌     [0m| 12/26 [00:16<00:13,  1.00it/s]Epoch: 7/10. Loss: 0.9683:  46%|[36m████▌     [0m| 12/26 [00:16<00:13,  1.00it/s]Epoch: 7/10. Loss: 0.9683:  50%|[36m█████     [0m| 13/26 [00:16<00:12,  1.03it/s]Epoch: 7/10. Loss: 0.9457:  50%|[36m█████     [0m| 13/26 [00:17<00:12,  1.03it/s]Epoch: 7/10. Loss: 0.9457:  54%|[36m█████▍    [0m| 14/26 [00:17<00:11,  1.06it/s]Epoch: 7/10. Loss: 1.0398:  54%|[36m█████▍    [0m| 14/26 [00:18<00:11,  1.06it/s]Epoch: 7/10. Loss: 1.0398:  58%|[36m█████▊    [0m| 15/26 [00:18<00:10,  1.03it/s]Epoch: 7/10. Loss: 0.9965:  58%|[36m█████▊    [0m| 15/26 [00:19<00:10,  1.03it/s]Epoch: 7/10. Loss: 0.9965:  62%|[36m██████▏   [0m| 16/26 [00:19<00:09,  1.06it/s]Epoch: 7/10. Loss: 0.9084:  62%|[36m██████▏   [0m| 16/26 [00:20<00:09,  1.06it/s]Epoch: 7/10. Loss: 0.9084:  65%|[36m██████▌   [0m| 17/26 [00:20<00:08,  1.06it/s]Epoch: 7/10. Loss: 0.9760:  65%|[36m██████▌   [0m| 17/26 [00:21<00:08,  1.06it/s]Epoch: 7/10. Loss: 0.9760:  69%|[36m██████▉   [0m| 18/26 [00:21<00:08,  1.03s/it]Epoch: 7/10. Loss: 0.9964:  69%|[36m██████▉   [0m| 18/26 [00:22<00:08,  1.03s/it]Epoch: 7/10. Loss: 0.9964:  73%|[36m███████▎  [0m| 19/26 [00:22<00:07,  1.02s/it]Epoch: 7/10. Loss: 1.2573:  73%|[36m███████▎  [0m| 19/26 [00:23<00:07,  1.02s/it]Epoch: 7/10. Loss: 1.2573:  77%|[36m███████▋  [0m| 20/26 [00:23<00:05,  1.01it/s]Epoch: 7/10. Loss: 1.0262:  77%|[36m███████▋  [0m| 20/26 [00:24<00:05,  1.01it/s]Epoch: 7/10. Loss: 1.0262:  81%|[36m████████  [0m| 21/26 [00:24<00:04,  1.06it/s]Epoch: 7/10. Loss: 0.9530:  81%|[36m████████  [0m| 21/26 [00:25<00:04,  1.06it/s]Epoch: 7/10. Loss: 0.9530:  85%|[36m████████▍ [0m| 22/26 [00:25<00:03,  1.05it/s]Epoch: 7/10. Loss: 0.8948:  85%|[36m████████▍ [0m| 22/26 [00:26<00:03,  1.05it/s]Epoch: 7/10. Loss: 0.8948:  88%|[36m████████▊ [0m| 23/26 [00:26<00:02,  1.07it/s]Epoch: 7/10. Loss: 0.9640:  88%|[36m████████▊ [0m| 23/26 [00:27<00:02,  1.07it/s]Epoch: 7/10. Loss: 0.9640:  92%|[36m█████████▏[0m| 24/26 [00:27<00:01,  1.09it/s]Epoch: 7/10. Loss: 0.8987:  92%|[36m█████████▏[0m| 24/26 [00:28<00:01,  1.09it/s]Epoch: 7/10. Loss: 0.8987:  96%|[36m█████████▌[0m| 25/26 [00:28<00:00,  1.08it/s]Epoch: 7/10. Loss: 1.0494:  96%|[36m█████████▌[0m| 25/26 [00:28<00:00,  1.08it/s]Epoch: 7/10. Loss: 1.0494: 100%|[36m██████████[0m| 26/26 [00:28<00:00,  1.22it/s]Epoch: 7/10. Loss: 1.0494: 100%|[36m██████████[0m| 26/26 [00:28<00:00,  1.11s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:05,  1.09it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:05,  1.09s/it] 43%|[33m████▎     [0m| 3/7 [00:02<00:03,  1.07it/s] 57%|[33m█████▋    [0m| 4/7 [00:04<00:03,  1.11s/it] 71%|[33m███████▏  [0m| 5/7 [00:04<00:01,  1.16it/s] 86%|[33m████████▌ [0m| 6/7 [00:05<00:00,  1.19it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.54it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.22it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 8/10. Loss: 1.0946:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 8/10. Loss: 1.0946:   4%|[36m▍         [0m| 1/26 [00:00<00:20,  1.21it/s]Epoch: 8/10. Loss: 0.9803:   4%|[36m▍         [0m| 1/26 [00:01<00:20,  1.21it/s]Epoch: 8/10. Loss: 0.9803:   8%|[36m▊         [0m| 2/26 [00:01<00:20,  1.16it/s]Epoch: 8/10. Loss: 1.0628:   8%|[36m▊         [0m| 2/26 [00:02<00:20,  1.16it/s]Epoch: 8/10. Loss: 1.0628:  12%|[36m█▏        [0m| 3/26 [00:02<00:22,  1.01it/s]Epoch: 8/10. Loss: 0.9583:  12%|[36m█▏        [0m| 3/26 [00:04<00:22,  1.01it/s]Epoch: 8/10. Loss: 0.9583:  15%|[36m█▌        [0m| 4/26 [00:04<00:24,  1.10s/it]Epoch: 8/10. Loss: 1.0225:  15%|[36m█▌        [0m| 4/26 [00:04<00:24,  1.10s/it]Epoch: 8/10. Loss: 1.0225:  19%|[36m█▉        [0m| 5/26 [00:04<00:20,  1.01it/s]Epoch: 8/10. Loss: 0.9419:  19%|[36m█▉        [0m| 5/26 [00:05<00:20,  1.01it/s]Epoch: 8/10. Loss: 0.9419:  23%|[36m██▎       [0m| 6/26 [00:05<00:19,  1.02it/s]Epoch: 8/10. Loss: 0.9031:  23%|[36m██▎       [0m| 6/26 [00:06<00:19,  1.02it/s]Epoch: 8/10. Loss: 0.9031:  27%|[36m██▋       [0m| 7/26 [00:06<00:17,  1.06it/s]Epoch: 8/10. Loss: 1.0137:  27%|[36m██▋       [0m| 7/26 [00:07<00:17,  1.06it/s]Epoch: 8/10. Loss: 1.0137:  31%|[36m███       [0m| 8/26 [00:07<00:15,  1.14it/s]Epoch: 8/10. Loss: 1.0270:  31%|[36m███       [0m| 8/26 [00:08<00:15,  1.14it/s]Epoch: 8/10. Loss: 1.0270:  35%|[36m███▍      [0m| 9/26 [00:08<00:15,  1.09it/s]Epoch: 8/10. Loss: 0.9758:  35%|[36m███▍      [0m| 9/26 [00:09<00:15,  1.09it/s]Epoch: 8/10. Loss: 0.9758:  38%|[36m███▊      [0m| 10/26 [00:09<00:14,  1.12it/s]Epoch: 8/10. Loss: 0.9910:  38%|[36m███▊      [0m| 10/26 [00:10<00:14,  1.12it/s]Epoch: 8/10. Loss: 0.9910:  42%|[36m████▏     [0m| 11/26 [00:10<00:13,  1.07it/s]Epoch: 8/10. Loss: 1.0293:  42%|[36m████▏     [0m| 11/26 [00:11<00:13,  1.07it/s]Epoch: 8/10. Loss: 1.0293:  46%|[36m████▌     [0m| 12/26 [00:11<00:12,  1.08it/s]Epoch: 8/10. Loss: 1.0675:  46%|[36m████▌     [0m| 12/26 [00:12<00:12,  1.08it/s]Epoch: 8/10. Loss: 1.0675:  50%|[36m█████     [0m| 13/26 [00:12<00:12,  1.06it/s]Epoch: 8/10. Loss: 0.8846:  50%|[36m█████     [0m| 13/26 [00:13<00:12,  1.06it/s]Epoch: 8/10. Loss: 0.8846:  54%|[36m█████▍    [0m| 14/26 [00:13<00:11,  1.05it/s]Epoch: 8/10. Loss: 1.0499:  54%|[36m█████▍    [0m| 14/26 [00:14<00:11,  1.05it/s]Epoch: 8/10. Loss: 1.0499:  58%|[36m█████▊    [0m| 15/26 [00:14<00:10,  1.09it/s]Epoch: 8/10. Loss: 0.9269:  58%|[36m█████▊    [0m| 15/26 [00:14<00:10,  1.09it/s]Epoch: 8/10. Loss: 0.9269:  62%|[36m██████▏   [0m| 16/26 [00:14<00:09,  1.09it/s]Epoch: 8/10. Loss: 0.9281:  62%|[36m██████▏   [0m| 16/26 [00:15<00:09,  1.09it/s]Epoch: 8/10. Loss: 0.9281:  65%|[36m██████▌   [0m| 17/26 [00:15<00:08,  1.12it/s]Epoch: 8/10. Loss: 1.0160:  65%|[36m██████▌   [0m| 17/26 [00:16<00:08,  1.12it/s]Epoch: 8/10. Loss: 1.0160:  69%|[36m██████▉   [0m| 18/26 [00:16<00:06,  1.17it/s]Epoch: 8/10. Loss: 0.9836:  69%|[36m██████▉   [0m| 18/26 [00:17<00:06,  1.17it/s]Epoch: 8/10. Loss: 0.9836:  73%|[36m███████▎  [0m| 19/26 [00:17<00:06,  1.13it/s]Epoch: 8/10. Loss: 1.0212:  73%|[36m███████▎  [0m| 19/26 [00:18<00:06,  1.13it/s]Epoch: 8/10. Loss: 1.0212:  77%|[36m███████▋  [0m| 20/26 [00:18<00:05,  1.17it/s]Epoch: 8/10. Loss: 0.8907:  77%|[36m███████▋  [0m| 20/26 [00:19<00:05,  1.17it/s]Epoch: 8/10. Loss: 0.8907:  81%|[36m████████  [0m| 21/26 [00:19<00:04,  1.14it/s]Epoch: 8/10. Loss: 0.9138:  81%|[36m████████  [0m| 21/26 [00:20<00:04,  1.14it/s]Epoch: 8/10. Loss: 0.9138:  85%|[36m████████▍ [0m| 22/26 [00:20<00:03,  1.09it/s]Epoch: 8/10. Loss: 0.8942:  85%|[36m████████▍ [0m| 22/26 [00:21<00:03,  1.09it/s]Epoch: 8/10. Loss: 0.8942:  88%|[36m████████▊ [0m| 23/26 [00:21<00:02,  1.13it/s]Epoch: 8/10. Loss: 1.0461:  88%|[36m████████▊ [0m| 23/26 [00:21<00:02,  1.13it/s]Epoch: 8/10. Loss: 1.0461:  92%|[36m█████████▏[0m| 24/26 [00:21<00:01,  1.16it/s]Epoch: 8/10. Loss: 0.9393:  92%|[36m█████████▏[0m| 24/26 [00:22<00:01,  1.16it/s]Epoch: 8/10. Loss: 0.9393:  96%|[36m█████████▌[0m| 25/26 [00:22<00:00,  1.14it/s]Epoch: 8/10. Loss: 0.8758:  96%|[36m█████████▌[0m| 25/26 [00:23<00:00,  1.14it/s]Epoch: 8/10. Loss: 0.8758: 100%|[36m██████████[0m| 26/26 [00:23<00:00,  1.15it/s]Epoch: 8/10. Loss: 0.8758: 100%|[36m██████████[0m| 26/26 [00:23<00:00,  1.10it/s]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:05,  1.08it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:05,  1.08s/it] 43%|[33m████▎     [0m| 3/7 [00:02<00:03,  1.08it/s] 57%|[33m█████▋    [0m| 4/7 [00:04<00:03,  1.18s/it] 71%|[33m███████▏  [0m| 5/7 [00:04<00:01,  1.09it/s] 86%|[33m████████▌ [0m| 6/7 [00:05<00:00,  1.13it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.48it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.18it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 9/10. Loss: 0.8894:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 9/10. Loss: 0.8894:   4%|[36m▍         [0m| 1/26 [00:00<00:23,  1.07it/s]Epoch: 9/10. Loss: 1.1596:   4%|[36m▍         [0m| 1/26 [00:01<00:23,  1.07it/s]Epoch: 9/10. Loss: 1.1596:   8%|[36m▊         [0m| 2/26 [00:01<00:23,  1.01it/s]Epoch: 9/10. Loss: 0.9143:   8%|[36m▊         [0m| 2/26 [00:02<00:23,  1.01it/s]Epoch: 9/10. Loss: 0.9143:  12%|[36m█▏        [0m| 3/26 [00:02<00:22,  1.01it/s]Epoch: 9/10. Loss: 0.9808:  12%|[36m█▏        [0m| 3/26 [00:03<00:22,  1.01it/s]Epoch: 9/10. Loss: 0.9808:  15%|[36m█▌        [0m| 4/26 [00:03<00:20,  1.05it/s]Epoch: 9/10. Loss: 0.9402:  15%|[36m█▌        [0m| 4/26 [00:04<00:20,  1.05it/s]Epoch: 9/10. Loss: 0.9402:  19%|[36m█▉        [0m| 5/26 [00:04<00:19,  1.05it/s]Epoch: 9/10. Loss: 0.9701:  19%|[36m█▉        [0m| 5/26 [00:05<00:19,  1.05it/s]Epoch: 9/10. Loss: 0.9701:  23%|[36m██▎       [0m| 6/26 [00:05<00:18,  1.08it/s]Epoch: 9/10. Loss: 0.9227:  23%|[36m██▎       [0m| 6/26 [00:06<00:18,  1.08it/s]Epoch: 9/10. Loss: 0.9227:  27%|[36m██▋       [0m| 7/26 [00:06<00:17,  1.10it/s]Epoch: 9/10. Loss: 0.9570:  27%|[36m██▋       [0m| 7/26 [00:07<00:17,  1.10it/s]Epoch: 9/10. Loss: 0.9570:  31%|[36m███       [0m| 8/26 [00:07<00:15,  1.14it/s]Epoch: 9/10. Loss: 0.9623:  31%|[36m███       [0m| 8/26 [00:08<00:15,  1.14it/s]Epoch: 9/10. Loss: 0.9623:  35%|[36m███▍      [0m| 9/26 [00:08<00:14,  1.16it/s]Epoch: 9/10. Loss: 1.0102:  35%|[36m███▍      [0m| 9/26 [00:09<00:14,  1.16it/s]Epoch: 9/10. Loss: 1.0102:  38%|[36m███▊      [0m| 10/26 [00:09<00:13,  1.16it/s]Epoch: 9/10. Loss: 0.9949:  38%|[36m███▊      [0m| 10/26 [00:09<00:13,  1.16it/s]Epoch: 9/10. Loss: 0.9949:  42%|[36m████▏     [0m| 11/26 [00:09<00:13,  1.13it/s]Epoch: 9/10. Loss: 1.0294:  42%|[36m████▏     [0m| 11/26 [00:10<00:13,  1.13it/s]Epoch: 9/10. Loss: 1.0294:  46%|[36m████▌     [0m| 12/26 [00:10<00:12,  1.11it/s]Epoch: 9/10. Loss: 0.9957:  46%|[36m████▌     [0m| 12/26 [00:11<00:12,  1.11it/s]Epoch: 9/10. Loss: 0.9957:  50%|[36m█████     [0m| 13/26 [00:11<00:11,  1.09it/s]Epoch: 9/10. Loss: 1.0344:  50%|[36m█████     [0m| 13/26 [00:12<00:11,  1.09it/s]Epoch: 9/10. Loss: 1.0344:  54%|[36m█████▍    [0m| 14/26 [00:12<00:10,  1.11it/s]Epoch: 9/10. Loss: 0.9624:  54%|[36m█████▍    [0m| 14/26 [00:14<00:10,  1.11it/s]Epoch: 9/10. Loss: 0.9624:  58%|[36m█████▊    [0m| 15/26 [00:14<00:12,  1.11s/it]Epoch: 9/10. Loss: 1.0538:  58%|[36m█████▊    [0m| 15/26 [00:15<00:12,  1.11s/it]Epoch: 9/10. Loss: 1.0538:  62%|[36m██████▏   [0m| 16/26 [00:15<00:10,  1.04s/it]Epoch: 9/10. Loss: 1.2215:  62%|[36m██████▏   [0m| 16/26 [00:16<00:10,  1.04s/it]Epoch: 9/10. Loss: 1.2215:  65%|[36m██████▌   [0m| 17/26 [00:16<00:10,  1.17s/it]Epoch: 9/10. Loss: 0.9048:  65%|[36m██████▌   [0m| 17/26 [00:18<00:10,  1.17s/it]Epoch: 9/10. Loss: 0.9048:  69%|[36m██████▉   [0m| 18/26 [00:18<00:09,  1.24s/it]Epoch: 9/10. Loss: 1.1101:  69%|[36m██████▉   [0m| 18/26 [00:18<00:09,  1.24s/it]Epoch: 9/10. Loss: 1.1101:  73%|[36m███████▎  [0m| 19/26 [00:18<00:07,  1.14s/it]Epoch: 9/10. Loss: 0.9976:  73%|[36m███████▎  [0m| 19/26 [00:19<00:07,  1.14s/it]Epoch: 9/10. Loss: 0.9976:  77%|[36m███████▋  [0m| 20/26 [00:19<00:06,  1.06s/it]Epoch: 9/10. Loss: 1.0432:  77%|[36m███████▋  [0m| 20/26 [00:20<00:06,  1.06s/it]Epoch: 9/10. Loss: 1.0432:  81%|[36m████████  [0m| 21/26 [00:20<00:05,  1.05s/it]Epoch: 9/10. Loss: 1.0061:  81%|[36m████████  [0m| 21/26 [00:21<00:05,  1.05s/it]Epoch: 9/10. Loss: 1.0061:  85%|[36m████████▍ [0m| 22/26 [00:21<00:03,  1.01it/s]Epoch: 9/10. Loss: 0.9330:  85%|[36m████████▍ [0m| 22/26 [00:22<00:03,  1.01it/s]Epoch: 9/10. Loss: 0.9330:  88%|[36m████████▊ [0m| 23/26 [00:22<00:02,  1.04it/s]Epoch: 9/10. Loss: 0.9433:  88%|[36m████████▊ [0m| 23/26 [00:23<00:02,  1.04it/s]Epoch: 9/10. Loss: 0.9433:  92%|[36m█████████▏[0m| 24/26 [00:23<00:01,  1.06it/s]Epoch: 9/10. Loss: 1.0487:  92%|[36m█████████▏[0m| 24/26 [00:24<00:01,  1.06it/s]Epoch: 9/10. Loss: 1.0487:  96%|[36m█████████▌[0m| 25/26 [00:24<00:00,  1.01it/s]Epoch: 9/10. Loss: 0.9641:  96%|[36m█████████▌[0m| 25/26 [00:25<00:00,  1.01it/s]Epoch: 9/10. Loss: 0.9641: 100%|[36m██████████[0m| 26/26 [00:25<00:00,  1.07it/s]Epoch: 9/10. Loss: 0.9641: 100%|[36m██████████[0m| 26/26 [00:25<00:00,  1.02it/s]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:05,  1.08it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:05,  1.08s/it] 43%|[33m████▎     [0m| 3/7 [00:03<00:05,  1.36s/it] 57%|[33m█████▋    [0m| 4/7 [00:05<00:04,  1.40s/it] 71%|[33m███████▏  [0m| 5/7 [00:05<00:02,  1.05s/it] 86%|[33m████████▌ [0m| 6/7 [00:06<00:00,  1.02it/s]100%|[33m██████████[0m| 7/7 [00:06<00:00,  1.34it/s]100%|[33m██████████[0m| 7/7 [00:06<00:00,  1.03it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 0/10. Loss: 1.1999:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 0/10. Loss: 1.1999:   4%|[36m▍         [0m| 1/26 [00:00<00:19,  1.29it/s]Epoch: 0/10. Loss: 2.2452:   4%|[36m▍         [0m| 1/26 [00:01<00:19,  1.29it/s]Epoch: 0/10. Loss: 2.2452:   8%|[36m▊         [0m| 2/26 [00:01<00:20,  1.14it/s]Epoch: 0/10. Loss: 3.2414:   8%|[36m▊         [0m| 2/26 [00:02<00:20,  1.14it/s]Epoch: 0/10. Loss: 3.2414:  12%|[36m█▏        [0m| 3/26 [00:02<00:20,  1.10it/s]Epoch: 0/10. Loss: 1.8799:  12%|[36m█▏        [0m| 3/26 [00:03<00:20,  1.10it/s]Epoch: 0/10. Loss: 1.8799:  15%|[36m█▌        [0m| 4/26 [00:03<00:19,  1.15it/s]Epoch: 0/10. Loss: 1.4765:  15%|[36m█▌        [0m| 4/26 [00:07<00:19,  1.15it/s]Epoch: 0/10. Loss: 1.4765:  19%|[36m█▉        [0m| 5/26 [00:07<00:43,  2.07s/it]Epoch: 0/10. Loss: 1.8468:  19%|[36m█▉        [0m| 5/26 [00:08<00:43,  2.07s/it]Epoch: 0/10. Loss: 1.8468:  23%|[36m██▎       [0m| 6/26 [00:08<00:34,  1.74s/it]Epoch: 0/10. Loss: 1.2354:  23%|[36m██▎       [0m| 6/26 [00:09<00:34,  1.74s/it]Epoch: 0/10. Loss: 1.2354:  27%|[36m██▋       [0m| 7/26 [00:09<00:29,  1.53s/it]Epoch: 0/10. Loss: 1.0806:  27%|[36m██▋       [0m| 7/26 [00:10<00:29,  1.53s/it]Epoch: 0/10. Loss: 1.0806:  31%|[36m███       [0m| 8/26 [00:10<00:23,  1.32s/it]Epoch: 0/10. Loss: 1.0912:  31%|[36m███       [0m| 8/26 [00:12<00:23,  1.32s/it]Epoch: 0/10. Loss: 1.0912:  35%|[36m███▍      [0m| 9/26 [00:12<00:25,  1.50s/it]Epoch: 0/10. Loss: 1.1807:  35%|[36m███▍      [0m| 9/26 [00:13<00:25,  1.50s/it]Epoch: 0/10. Loss: 1.1807:  38%|[36m███▊      [0m| 10/26 [00:13<00:21,  1.36s/it]Epoch: 0/10. Loss: 1.1633:  38%|[36m███▊      [0m| 10/26 [00:14<00:21,  1.36s/it]Epoch: 0/10. Loss: 1.1633:  42%|[36m████▏     [0m| 11/26 [00:14<00:18,  1.20s/it]Epoch: 0/10. Loss: 1.1781:  42%|[36m████▏     [0m| 11/26 [00:15<00:18,  1.20s/it]Epoch: 0/10. Loss: 1.1781:  46%|[36m████▌     [0m| 12/26 [00:15<00:15,  1.10s/it]Epoch: 0/10. Loss: 1.0822:  46%|[36m████▌     [0m| 12/26 [00:17<00:15,  1.10s/it]Epoch: 0/10. Loss: 1.0822:  50%|[36m█████     [0m| 13/26 [00:17<00:17,  1.35s/it]Epoch: 0/10. Loss: 1.0942:  50%|[36m█████     [0m| 13/26 [00:18<00:17,  1.35s/it]Epoch: 0/10. Loss: 1.0942:  54%|[36m█████▍    [0m| 14/26 [00:18<00:14,  1.22s/it]Epoch: 0/10. Loss: 1.0133:  54%|[36m█████▍    [0m| 14/26 [00:19<00:14,  1.22s/it]Epoch: 0/10. Loss: 1.0133:  58%|[36m█████▊    [0m| 15/26 [00:19<00:12,  1.11s/it]Epoch: 0/10. Loss: 1.0165:  58%|[36m█████▊    [0m| 15/26 [00:19<00:12,  1.11s/it]Epoch: 0/10. Loss: 1.0165:  62%|[36m██████▏   [0m| 16/26 [00:19<00:10,  1.00s/it]Epoch: 0/10. Loss: 1.0836:  62%|[36m██████▏   [0m| 16/26 [00:20<00:10,  1.00s/it]Epoch: 0/10. Loss: 1.0836:  65%|[36m██████▌   [0m| 17/26 [00:20<00:08,  1.03it/s]Epoch: 0/10. Loss: 1.0537:  65%|[36m██████▌   [0m| 17/26 [00:21<00:08,  1.03it/s]Epoch: 0/10. Loss: 1.0537:  69%|[36m██████▉   [0m| 18/26 [00:21<00:07,  1.01it/s]Epoch: 0/10. Loss: 1.1559:  69%|[36m██████▉   [0m| 18/26 [00:22<00:07,  1.01it/s]Epoch: 0/10. Loss: 1.1559:  73%|[36m███████▎  [0m| 19/26 [00:22<00:06,  1.08it/s]Epoch: 0/10. Loss: 1.0754:  73%|[36m███████▎  [0m| 19/26 [00:23<00:06,  1.08it/s]Epoch: 0/10. Loss: 1.0754:  77%|[36m███████▋  [0m| 20/26 [00:23<00:05,  1.06it/s]Epoch: 0/10. Loss: 1.0518:  77%|[36m███████▋  [0m| 20/26 [00:24<00:05,  1.06it/s]Epoch: 0/10. Loss: 1.0518:  81%|[36m████████  [0m| 21/26 [00:24<00:04,  1.06it/s]Epoch: 0/10. Loss: 1.0142:  81%|[36m████████  [0m| 21/26 [00:25<00:04,  1.06it/s]Epoch: 0/10. Loss: 1.0142:  85%|[36m████████▍ [0m| 22/26 [00:25<00:03,  1.10it/s]Epoch: 0/10. Loss: 1.1200:  85%|[36m████████▍ [0m| 22/26 [00:26<00:03,  1.10it/s]Epoch: 0/10. Loss: 1.1200:  88%|[36m████████▊ [0m| 23/26 [00:26<00:02,  1.17it/s]Epoch: 0/10. Loss: 1.1431:  88%|[36m████████▊ [0m| 23/26 [00:27<00:02,  1.17it/s]Epoch: 0/10. Loss: 1.1431:  92%|[36m█████████▏[0m| 24/26 [00:27<00:01,  1.09it/s]Epoch: 0/10. Loss: 1.0471:  92%|[36m█████████▏[0m| 24/26 [00:28<00:01,  1.09it/s]Epoch: 0/10. Loss: 1.0471:  96%|[36m█████████▌[0m| 25/26 [00:28<00:00,  1.07it/s]Epoch: 0/10. Loss: 1.0423:  96%|[36m█████████▌[0m| 25/26 [00:28<00:00,  1.07it/s]Epoch: 0/10. Loss: 1.0423: 100%|[36m██████████[0m| 26/26 [00:28<00:00,  1.16it/s]Epoch: 0/10. Loss: 1.0423: 100%|[36m██████████[0m| 26/26 [00:28<00:00,  1.11s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:05,  1.06it/s] 29%|[33m██▊       [0m| 2/7 [00:03<00:08,  1.64s/it] 43%|[33m████▎     [0m| 3/7 [00:03<00:04,  1.25s/it] 57%|[33m█████▋    [0m| 4/7 [00:05<00:03,  1.31s/it] 71%|[33m███████▏  [0m| 5/7 [00:05<00:02,  1.00s/it] 86%|[33m████████▌ [0m| 6/7 [00:06<00:00,  1.06it/s]100%|[33m██████████[0m| 7/7 [00:06<00:00,  1.39it/s]100%|[33m██████████[0m| 7/7 [00:06<00:00,  1.03it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 1/10. Loss: 1.0681:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 1/10. Loss: 1.0681:   4%|[36m▍         [0m| 1/26 [00:00<00:22,  1.10it/s]Epoch: 1/10. Loss: 1.0003:   4%|[36m▍         [0m| 1/26 [00:02<00:22,  1.10it/s]Epoch: 1/10. Loss: 1.0003:   8%|[36m▊         [0m| 2/26 [00:02<00:25,  1.06s/it]Epoch: 1/10. Loss: 1.0239:   8%|[36m▊         [0m| 2/26 [00:02<00:25,  1.06s/it]Epoch: 1/10. Loss: 1.0239:  12%|[36m█▏        [0m| 3/26 [00:02<00:22,  1.02it/s]Epoch: 1/10. Loss: 0.9770:  12%|[36m█▏        [0m| 3/26 [00:03<00:22,  1.02it/s]Epoch: 1/10. Loss: 0.9770:  15%|[36m█▌        [0m| 4/26 [00:03<00:19,  1.12it/s]Epoch: 1/10. Loss: 0.9726:  15%|[36m█▌        [0m| 4/26 [00:04<00:19,  1.12it/s]Epoch: 1/10. Loss: 0.9726:  19%|[36m█▉        [0m| 5/26 [00:04<00:19,  1.06it/s]Epoch: 1/10. Loss: 1.0314:  19%|[36m█▉        [0m| 5/26 [00:05<00:19,  1.06it/s]Epoch: 1/10. Loss: 1.0314:  23%|[36m██▎       [0m| 6/26 [00:05<00:18,  1.07it/s]Epoch: 1/10. Loss: 0.9885:  23%|[36m██▎       [0m| 6/26 [00:06<00:18,  1.07it/s]Epoch: 1/10. Loss: 0.9885:  27%|[36m██▋       [0m| 7/26 [00:06<00:17,  1.07it/s]Epoch: 1/10. Loss: 0.9094:  27%|[36m██▋       [0m| 7/26 [00:07<00:17,  1.07it/s]Epoch: 1/10. Loss: 0.9094:  31%|[36m███       [0m| 8/26 [00:07<00:16,  1.08it/s]Epoch: 1/10. Loss: 0.9233:  31%|[36m███       [0m| 8/26 [00:08<00:16,  1.08it/s]Epoch: 1/10. Loss: 0.9233:  35%|[36m███▍      [0m| 9/26 [00:08<00:16,  1.03it/s]Epoch: 1/10. Loss: 1.0460:  35%|[36m███▍      [0m| 9/26 [00:09<00:16,  1.03it/s]Epoch: 1/10. Loss: 1.0460:  38%|[36m███▊      [0m| 10/26 [00:09<00:16,  1.02s/it]Epoch: 1/10. Loss: 0.9264:  38%|[36m███▊      [0m| 10/26 [00:10<00:16,  1.02s/it]Epoch: 1/10. Loss: 0.9264:  42%|[36m████▏     [0m| 11/26 [00:10<00:14,  1.02it/s]Epoch: 1/10. Loss: 0.8687:  42%|[36m████▏     [0m| 11/26 [00:11<00:14,  1.02it/s]Epoch: 1/10. Loss: 0.8687:  46%|[36m████▌     [0m| 12/26 [00:11<00:13,  1.06it/s]Epoch: 1/10. Loss: 0.9426:  46%|[36m████▌     [0m| 12/26 [00:12<00:13,  1.06it/s]Epoch: 1/10. Loss: 0.9426:  50%|[36m█████     [0m| 13/26 [00:12<00:13,  1.01s/it]Epoch: 1/10. Loss: 0.9428:  50%|[36m█████     [0m| 13/26 [00:13<00:13,  1.01s/it]Epoch: 1/10. Loss: 0.9428:  54%|[36m█████▍    [0m| 14/26 [00:13<00:11,  1.05it/s]Epoch: 1/10. Loss: 0.8442:  54%|[36m█████▍    [0m| 14/26 [00:14<00:11,  1.05it/s]Epoch: 1/10. Loss: 0.8442:  58%|[36m█████▊    [0m| 15/26 [00:14<00:09,  1.13it/s]Epoch: 1/10. Loss: 0.9842:  58%|[36m█████▊    [0m| 15/26 [00:15<00:09,  1.13it/s]Epoch: 1/10. Loss: 0.9842:  62%|[36m██████▏   [0m| 16/26 [00:15<00:08,  1.13it/s]Epoch: 1/10. Loss: 0.8889:  62%|[36m██████▏   [0m| 16/26 [00:15<00:08,  1.13it/s]Epoch: 1/10. Loss: 0.8889:  65%|[36m██████▌   [0m| 17/26 [00:15<00:07,  1.13it/s]Epoch: 1/10. Loss: 0.8775:  65%|[36m██████▌   [0m| 17/26 [00:16<00:07,  1.13it/s]Epoch: 1/10. Loss: 0.8775:  69%|[36m██████▉   [0m| 18/26 [00:16<00:06,  1.15it/s]Epoch: 1/10. Loss: 0.9709:  69%|[36m██████▉   [0m| 18/26 [00:17<00:06,  1.15it/s]Epoch: 1/10. Loss: 0.9709:  73%|[36m███████▎  [0m| 19/26 [00:17<00:06,  1.17it/s]Epoch: 1/10. Loss: 0.8718:  73%|[36m███████▎  [0m| 19/26 [00:18<00:06,  1.17it/s]Epoch: 1/10. Loss: 0.8718:  77%|[36m███████▋  [0m| 20/26 [00:18<00:04,  1.21it/s]Epoch: 1/10. Loss: 0.9920:  77%|[36m███████▋  [0m| 20/26 [00:19<00:04,  1.21it/s]Epoch: 1/10. Loss: 0.9920:  81%|[36m████████  [0m| 21/26 [00:19<00:04,  1.13it/s]Epoch: 1/10. Loss: 0.9917:  81%|[36m████████  [0m| 21/26 [00:20<00:04,  1.13it/s]Epoch: 1/10. Loss: 0.9917:  85%|[36m████████▍ [0m| 22/26 [00:20<00:03,  1.09it/s]Epoch: 1/10. Loss: 0.8945:  85%|[36m████████▍ [0m| 22/26 [00:21<00:03,  1.09it/s]Epoch: 1/10. Loss: 0.8945:  88%|[36m████████▊ [0m| 23/26 [00:21<00:03,  1.10s/it]Epoch: 1/10. Loss: 0.9518:  88%|[36m████████▊ [0m| 23/26 [00:22<00:03,  1.10s/it]Epoch: 1/10. Loss: 0.9518:  92%|[36m█████████▏[0m| 24/26 [00:22<00:02,  1.06s/it]Epoch: 1/10. Loss: 0.8886:  92%|[36m█████████▏[0m| 24/26 [00:23<00:02,  1.06s/it]Epoch: 1/10. Loss: 0.8886:  96%|[36m█████████▌[0m| 25/26 [00:23<00:01,  1.01s/it]Epoch: 1/10. Loss: 0.9493:  96%|[36m█████████▌[0m| 25/26 [00:24<00:01,  1.01s/it]Epoch: 1/10. Loss: 0.9493: 100%|[36m██████████[0m| 26/26 [00:24<00:00,  1.09it/s]Epoch: 1/10. Loss: 0.9493: 100%|[36m██████████[0m| 26/26 [00:24<00:00,  1.06it/s]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:05,  1.08it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:05,  1.09s/it] 43%|[33m████▎     [0m| 3/7 [00:02<00:03,  1.09it/s] 57%|[33m█████▋    [0m| 4/7 [00:04<00:03,  1.13s/it] 71%|[33m███████▏  [0m| 5/7 [00:04<00:01,  1.17it/s] 86%|[33m████████▌ [0m| 6/7 [00:05<00:00,  1.24it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.62it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.25it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 2/10. Loss: 0.8660:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 2/10. Loss: 0.8660:   4%|[36m▍         [0m| 1/26 [00:00<00:23,  1.06it/s]Epoch: 2/10. Loss: 0.8949:   4%|[36m▍         [0m| 1/26 [00:01<00:23,  1.06it/s]Epoch: 2/10. Loss: 0.8949:   8%|[36m▊         [0m| 2/26 [00:01<00:21,  1.10it/s]Epoch: 2/10. Loss: 0.8696:   8%|[36m▊         [0m| 2/26 [00:02<00:21,  1.10it/s]Epoch: 2/10. Loss: 0.8696:  12%|[36m█▏        [0m| 3/26 [00:02<00:21,  1.07it/s]Epoch: 2/10. Loss: 0.8773:  12%|[36m█▏        [0m| 3/26 [00:03<00:21,  1.07it/s]Epoch: 2/10. Loss: 0.8773:  15%|[36m█▌        [0m| 4/26 [00:03<00:19,  1.11it/s]Epoch: 2/10. Loss: 0.8568:  15%|[36m█▌        [0m| 4/26 [00:04<00:19,  1.11it/s]Epoch: 2/10. Loss: 0.8568:  19%|[36m█▉        [0m| 5/26 [00:04<00:19,  1.06it/s]Epoch: 2/10. Loss: 0.8989:  19%|[36m█▉        [0m| 5/26 [00:06<00:19,  1.06it/s]Epoch: 2/10. Loss: 0.8989:  23%|[36m██▎       [0m| 6/26 [00:06<00:26,  1.30s/it]Epoch: 2/10. Loss: 0.8840:  23%|[36m██▎       [0m| 6/26 [00:08<00:26,  1.30s/it]Epoch: 2/10. Loss: 0.8840:  27%|[36m██▋       [0m| 7/26 [00:08<00:25,  1.32s/it]Epoch: 2/10. Loss: 0.8863:  27%|[36m██▋       [0m| 7/26 [00:08<00:25,  1.32s/it]Epoch: 2/10. Loss: 0.8863:  31%|[36m███       [0m| 8/26 [00:08<00:20,  1.13s/it]Epoch: 2/10. Loss: 0.8645:  31%|[36m███       [0m| 8/26 [00:10<00:20,  1.13s/it]Epoch: 2/10. Loss: 0.8645:  35%|[36m███▍      [0m| 9/26 [00:10<00:24,  1.43s/it]Epoch: 2/10. Loss: 0.8547:  35%|[36m███▍      [0m| 9/26 [00:11<00:24,  1.43s/it]Epoch: 2/10. Loss: 0.8547:  38%|[36m███▊      [0m| 10/26 [00:11<00:20,  1.29s/it]Epoch: 2/10. Loss: 0.8917:  38%|[36m███▊      [0m| 10/26 [00:13<00:20,  1.29s/it]Epoch: 2/10. Loss: 0.8917:  42%|[36m████▏     [0m| 11/26 [00:13<00:19,  1.33s/it]Epoch: 2/10. Loss: 0.9670:  42%|[36m████▏     [0m| 11/26 [00:13<00:19,  1.33s/it]Epoch: 2/10. Loss: 0.9670:  46%|[36m████▌     [0m| 12/26 [00:13<00:16,  1.15s/it]Epoch: 2/10. Loss: 0.9535:  46%|[36m████▌     [0m| 12/26 [00:14<00:16,  1.15s/it]Epoch: 2/10. Loss: 0.9535:  50%|[36m█████     [0m| 13/26 [00:14<00:13,  1.08s/it]Epoch: 2/10. Loss: 0.9247:  50%|[36m█████     [0m| 13/26 [00:15<00:13,  1.08s/it]Epoch: 2/10. Loss: 0.9247:  54%|[36m█████▍    [0m| 14/26 [00:15<00:12,  1.07s/it]Epoch: 2/10. Loss: 0.9046:  54%|[36m█████▍    [0m| 14/26 [00:16<00:12,  1.07s/it]Epoch: 2/10. Loss: 0.9046:  58%|[36m█████▊    [0m| 15/26 [00:16<00:10,  1.02it/s]Epoch: 2/10. Loss: 0.9509:  58%|[36m█████▊    [0m| 15/26 [00:17<00:10,  1.02it/s]Epoch: 2/10. Loss: 0.9509:  62%|[36m██████▏   [0m| 16/26 [00:17<00:10,  1.03s/it]Epoch: 2/10. Loss: 0.8907:  62%|[36m██████▏   [0m| 16/26 [00:18<00:10,  1.03s/it]Epoch: 2/10. Loss: 0.8907:  65%|[36m██████▌   [0m| 17/26 [00:18<00:09,  1.02s/it]Epoch: 2/10. Loss: 0.9508:  65%|[36m██████▌   [0m| 17/26 [00:20<00:09,  1.02s/it]Epoch: 2/10. Loss: 0.9508:  69%|[36m██████▉   [0m| 18/26 [00:20<00:09,  1.18s/it]Epoch: 2/10. Loss: 0.9868:  69%|[36m██████▉   [0m| 18/26 [00:21<00:09,  1.18s/it]Epoch: 2/10. Loss: 0.9868:  73%|[36m███████▎  [0m| 19/26 [00:21<00:07,  1.08s/it]Epoch: 2/10. Loss: 0.9168:  73%|[36m███████▎  [0m| 19/26 [00:22<00:07,  1.08s/it]Epoch: 2/10. Loss: 0.9168:  77%|[36m███████▋  [0m| 20/26 [00:22<00:06,  1.03s/it]Epoch: 2/10. Loss: 0.9987:  77%|[36m███████▋  [0m| 20/26 [00:22<00:06,  1.03s/it]Epoch: 2/10. Loss: 0.9987:  81%|[36m████████  [0m| 21/26 [00:22<00:04,  1.04it/s]Epoch: 2/10. Loss: 0.9987:  81%|[36m████████  [0m| 21/26 [00:23<00:04,  1.04it/s]Epoch: 2/10. Loss: 0.9987:  85%|[36m████████▍ [0m| 22/26 [00:23<00:03,  1.07it/s]Epoch: 2/10. Loss: 0.9366:  85%|[36m████████▍ [0m| 22/26 [00:24<00:03,  1.07it/s]Epoch: 2/10. Loss: 0.9366:  88%|[36m████████▊ [0m| 23/26 [00:24<00:02,  1.04it/s]Epoch: 2/10. Loss: 0.9711:  88%|[36m████████▊ [0m| 23/26 [00:25<00:02,  1.04it/s]Epoch: 2/10. Loss: 0.9711:  92%|[36m█████████▏[0m| 24/26 [00:25<00:01,  1.11it/s]Epoch: 2/10. Loss: 0.8260:  92%|[36m█████████▏[0m| 24/26 [00:26<00:01,  1.11it/s]Epoch: 2/10. Loss: 0.8260:  96%|[36m█████████▌[0m| 25/26 [00:26<00:00,  1.09it/s]Epoch: 2/10. Loss: 0.9749:  96%|[36m█████████▌[0m| 25/26 [00:27<00:00,  1.09it/s]Epoch: 2/10. Loss: 0.9749: 100%|[36m██████████[0m| 26/26 [00:27<00:00,  1.16it/s]Epoch: 2/10. Loss: 0.9749: 100%|[36m██████████[0m| 26/26 [00:27<00:00,  1.05s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:05,  1.03it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:05,  1.14s/it] 43%|[33m████▎     [0m| 3/7 [00:02<00:03,  1.04it/s] 57%|[33m█████▋    [0m| 4/7 [00:04<00:03,  1.33s/it] 71%|[33m███████▏  [0m| 5/7 [00:05<00:01,  1.01it/s] 86%|[33m████████▌ [0m| 6/7 [00:06<00:00,  1.00it/s]100%|[33m██████████[0m| 7/7 [00:06<00:00,  1.34it/s]100%|[33m██████████[0m| 7/7 [00:06<00:00,  1.08it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 3/10. Loss: 0.8797:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 3/10. Loss: 0.8797:   4%|[36m▍         [0m| 1/26 [00:00<00:20,  1.20it/s]Epoch: 3/10. Loss: 0.7862:   4%|[36m▍         [0m| 1/26 [00:01<00:20,  1.20it/s]Epoch: 3/10. Loss: 0.7862:   8%|[36m▊         [0m| 2/26 [00:01<00:19,  1.24it/s]Epoch: 3/10. Loss: 0.9435:   8%|[36m▊         [0m| 2/26 [00:02<00:19,  1.24it/s]Epoch: 3/10. Loss: 0.9435:  12%|[36m█▏        [0m| 3/26 [00:02<00:17,  1.28it/s]Epoch: 3/10. Loss: 1.0233:  12%|[36m█▏        [0m| 3/26 [00:03<00:17,  1.28it/s]Epoch: 3/10. Loss: 1.0233:  15%|[36m█▌        [0m| 4/26 [00:03<00:16,  1.30it/s]Epoch: 3/10. Loss: 0.8103:  15%|[36m█▌        [0m| 4/26 [00:03<00:16,  1.30it/s]Epoch: 3/10. Loss: 0.8103:  19%|[36m█▉        [0m| 5/26 [00:03<00:16,  1.25it/s]Epoch: 3/10. Loss: 0.8704:  19%|[36m█▉        [0m| 5/26 [00:04<00:16,  1.25it/s]Epoch: 3/10. Loss: 0.8704:  23%|[36m██▎       [0m| 6/26 [00:04<00:17,  1.15it/s]Epoch: 3/10. Loss: 0.9962:  23%|[36m██▎       [0m| 6/26 [00:05<00:17,  1.15it/s]Epoch: 3/10. Loss: 0.9962:  27%|[36m██▋       [0m| 7/26 [00:05<00:17,  1.09it/s]Epoch: 3/10. Loss: 0.8723:  27%|[36m██▋       [0m| 7/26 [00:06<00:17,  1.09it/s]Epoch: 3/10. Loss: 0.8723:  31%|[36m███       [0m| 8/26 [00:06<00:16,  1.07it/s]Epoch: 3/10. Loss: 0.9220:  31%|[36m███       [0m| 8/26 [00:07<00:16,  1.07it/s]Epoch: 3/10. Loss: 0.9220:  35%|[36m███▍      [0m| 9/26 [00:07<00:16,  1.04it/s]Epoch: 3/10. Loss: 0.8989:  35%|[36m███▍      [0m| 9/26 [00:08<00:16,  1.04it/s]Epoch: 3/10. Loss: 0.8989:  38%|[36m███▊      [0m| 10/26 [00:08<00:15,  1.03it/s]Epoch: 3/10. Loss: 0.9453:  38%|[36m███▊      [0m| 10/26 [00:09<00:15,  1.03it/s]Epoch: 3/10. Loss: 0.9453:  42%|[36m████▏     [0m| 11/26 [00:09<00:13,  1.11it/s]Epoch: 3/10. Loss: 0.8605:  42%|[36m████▏     [0m| 11/26 [00:10<00:13,  1.11it/s]Epoch: 3/10. Loss: 0.8605:  46%|[36m████▌     [0m| 12/26 [00:10<00:12,  1.14it/s]Epoch: 3/10. Loss: 0.9320:  46%|[36m████▌     [0m| 12/26 [00:11<00:12,  1.14it/s]Epoch: 3/10. Loss: 0.9320:  50%|[36m█████     [0m| 13/26 [00:11<00:11,  1.10it/s]Epoch: 3/10. Loss: 0.8385:  50%|[36m█████     [0m| 13/26 [00:12<00:11,  1.10it/s]Epoch: 3/10. Loss: 0.8385:  54%|[36m█████▍    [0m| 14/26 [00:12<00:12,  1.03s/it]Epoch: 3/10. Loss: 0.8860:  54%|[36m█████▍    [0m| 14/26 [00:13<00:12,  1.03s/it]Epoch: 3/10. Loss: 0.8860:  58%|[36m█████▊    [0m| 15/26 [00:13<00:10,  1.01it/s]Epoch: 3/10. Loss: 0.8859:  58%|[36m█████▊    [0m| 15/26 [00:14<00:10,  1.01it/s]Epoch: 3/10. Loss: 0.8859:  62%|[36m██████▏   [0m| 16/26 [00:14<00:09,  1.01it/s]Epoch: 3/10. Loss: 0.8860:  62%|[36m██████▏   [0m| 16/26 [00:15<00:09,  1.01it/s]Epoch: 3/10. Loss: 0.8860:  65%|[36m██████▌   [0m| 17/26 [00:15<00:08,  1.02it/s]Epoch: 3/10. Loss: 0.7841:  65%|[36m██████▌   [0m| 17/26 [00:18<00:08,  1.02it/s]Epoch: 3/10. Loss: 0.7841:  69%|[36m██████▉   [0m| 18/26 [00:18<00:12,  1.54s/it]Epoch: 3/10. Loss: 0.8582:  69%|[36m██████▉   [0m| 18/26 [00:22<00:12,  1.54s/it]Epoch: 3/10. Loss: 0.8582:  73%|[36m███████▎  [0m| 19/26 [00:22<00:15,  2.25s/it]Epoch: 3/10. Loss: 0.7903:  73%|[36m███████▎  [0m| 19/26 [00:23<00:15,  2.25s/it]Epoch: 3/10. Loss: 0.7903:  77%|[36m███████▋  [0m| 20/26 [00:23<00:11,  1.90s/it]Epoch: 3/10. Loss: 0.8421:  77%|[36m███████▋  [0m| 20/26 [00:25<00:11,  1.90s/it]Epoch: 3/10. Loss: 0.8421:  81%|[36m████████  [0m| 21/26 [00:25<00:09,  1.93s/it]Epoch: 3/10. Loss: 0.7637:  81%|[36m████████  [0m| 21/26 [00:26<00:09,  1.93s/it]Epoch: 3/10. Loss: 0.7637:  85%|[36m████████▍ [0m| 22/26 [00:26<00:06,  1.61s/it]Epoch: 3/10. Loss: 0.8034:  85%|[36m████████▍ [0m| 22/26 [00:27<00:06,  1.61s/it]Epoch: 3/10. Loss: 0.8034:  88%|[36m████████▊ [0m| 23/26 [00:27<00:04,  1.35s/it]Epoch: 3/10. Loss: 1.0054:  88%|[36m████████▊ [0m| 23/26 [00:28<00:04,  1.35s/it]Epoch: 3/10. Loss: 1.0054:  92%|[36m█████████▏[0m| 24/26 [00:28<00:02,  1.24s/it]Epoch: 3/10. Loss: 0.8776:  92%|[36m█████████▏[0m| 24/26 [00:29<00:02,  1.24s/it]Epoch: 3/10. Loss: 0.8776:  96%|[36m█████████▌[0m| 25/26 [00:29<00:01,  1.36s/it]Epoch: 3/10. Loss: 0.7007:  96%|[36m█████████▌[0m| 25/26 [00:30<00:01,  1.36s/it]Epoch: 3/10. Loss: 0.7007: 100%|[36m██████████[0m| 26/26 [00:30<00:00,  1.12s/it]Epoch: 3/10. Loss: 0.7007: 100%|[36m██████████[0m| 26/26 [00:30<00:00,  1.17s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:05,  1.17it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:05,  1.03s/it] 43%|[33m████▎     [0m| 3/7 [00:02<00:03,  1.13it/s] 57%|[33m█████▋    [0m| 4/7 [00:04<00:03,  1.05s/it] 71%|[33m███████▏  [0m| 5/7 [00:04<00:01,  1.25it/s] 86%|[33m████████▌ [0m| 6/7 [00:05<00:00,  1.30it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.69it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.32it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 4/10. Loss: 0.8225:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 4/10. Loss: 0.8225:   4%|[36m▍         [0m| 1/26 [00:00<00:21,  1.14it/s]Epoch: 4/10. Loss: 0.8310:   4%|[36m▍         [0m| 1/26 [00:01<00:21,  1.14it/s]Epoch: 4/10. Loss: 0.8310:   8%|[36m▊         [0m| 2/26 [00:01<00:21,  1.12it/s]Epoch: 4/10. Loss: 0.9820:   8%|[36m▊         [0m| 2/26 [00:02<00:21,  1.12it/s]Epoch: 4/10. Loss: 0.9820:  12%|[36m█▏        [0m| 3/26 [00:02<00:22,  1.01it/s]Epoch: 4/10. Loss: 0.8511:  12%|[36m█▏        [0m| 3/26 [00:03<00:22,  1.01it/s]Epoch: 4/10. Loss: 0.8511:  15%|[36m█▌        [0m| 4/26 [00:04<00:22,  1.04s/it]Epoch: 4/10. Loss: 0.8103:  15%|[36m█▌        [0m| 4/26 [00:04<00:22,  1.04s/it]Epoch: 4/10. Loss: 0.8103:  19%|[36m█▉        [0m| 5/26 [00:04<00:20,  1.03it/s]Epoch: 4/10. Loss: 0.8439:  19%|[36m█▉        [0m| 5/26 [00:05<00:20,  1.03it/s]Epoch: 4/10. Loss: 0.8439:  23%|[36m██▎       [0m| 6/26 [00:05<00:18,  1.06it/s]Epoch: 4/10. Loss: 0.7964:  23%|[36m██▎       [0m| 6/26 [00:06<00:18,  1.06it/s]Epoch: 4/10. Loss: 0.7964:  27%|[36m██▋       [0m| 7/26 [00:06<00:16,  1.12it/s]Epoch: 4/10. Loss: 0.7268:  27%|[36m██▋       [0m| 7/26 [00:07<00:16,  1.12it/s]Epoch: 4/10. Loss: 0.7268:  31%|[36m███       [0m| 8/26 [00:07<00:16,  1.09it/s]Epoch: 4/10. Loss: 0.7459:  31%|[36m███       [0m| 8/26 [00:08<00:16,  1.09it/s]Epoch: 4/10. Loss: 0.7459:  35%|[36m███▍      [0m| 9/26 [00:08<00:15,  1.13it/s]Epoch: 4/10. Loss: 0.9714:  35%|[36m███▍      [0m| 9/26 [00:09<00:15,  1.13it/s]Epoch: 4/10. Loss: 0.9714:  38%|[36m███▊      [0m| 10/26 [00:09<00:14,  1.07it/s]Epoch: 4/10. Loss: 0.8620:  38%|[36m███▊      [0m| 10/26 [00:10<00:14,  1.07it/s]Epoch: 4/10. Loss: 0.8620:  42%|[36m████▏     [0m| 11/26 [00:10<00:14,  1.07it/s]Epoch: 4/10. Loss: 0.9132:  42%|[36m████▏     [0m| 11/26 [00:11<00:14,  1.07it/s]Epoch: 4/10. Loss: 0.9132:  46%|[36m████▌     [0m| 12/26 [00:11<00:14,  1.06s/it]Epoch: 4/10. Loss: 0.7734:  46%|[36m████▌     [0m| 12/26 [00:12<00:14,  1.06s/it]Epoch: 4/10. Loss: 0.7734:  50%|[36m█████     [0m| 13/26 [00:12<00:13,  1.02s/it]Epoch: 4/10. Loss: 0.8368:  50%|[36m█████     [0m| 13/26 [00:13<00:13,  1.02s/it]Epoch: 4/10. Loss: 0.8368:  54%|[36m█████▍    [0m| 14/26 [00:13<00:11,  1.03it/s]Epoch: 4/10. Loss: 0.8308:  54%|[36m█████▍    [0m| 14/26 [00:14<00:11,  1.03it/s]Epoch: 4/10. Loss: 0.8308:  58%|[36m█████▊    [0m| 15/26 [00:14<00:10,  1.05it/s]Epoch: 4/10. Loss: 0.9017:  58%|[36m█████▊    [0m| 15/26 [00:15<00:10,  1.05it/s]Epoch: 4/10. Loss: 0.9017:  62%|[36m██████▏   [0m| 16/26 [00:15<00:09,  1.10it/s]Epoch: 4/10. Loss: 0.9507:  62%|[36m██████▏   [0m| 16/26 [00:16<00:09,  1.10it/s]Epoch: 4/10. Loss: 0.9507:  65%|[36m██████▌   [0m| 17/26 [00:16<00:08,  1.09it/s]Epoch: 4/10. Loss: 0.7982:  65%|[36m██████▌   [0m| 17/26 [00:16<00:08,  1.09it/s]Epoch: 4/10. Loss: 0.7982:  69%|[36m██████▉   [0m| 18/26 [00:16<00:07,  1.11it/s]Epoch: 4/10. Loss: 0.8181:  69%|[36m██████▉   [0m| 18/26 [00:17<00:07,  1.11it/s]Epoch: 4/10. Loss: 0.8181:  73%|[36m███████▎  [0m| 19/26 [00:17<00:06,  1.09it/s]Epoch: 4/10. Loss: 0.7971:  73%|[36m███████▎  [0m| 19/26 [00:18<00:06,  1.09it/s]Epoch: 4/10. Loss: 0.7971:  77%|[36m███████▋  [0m| 20/26 [00:18<00:05,  1.08it/s]Epoch: 4/10. Loss: 0.8123:  77%|[36m███████▋  [0m| 20/26 [00:20<00:05,  1.08it/s]Epoch: 4/10. Loss: 0.8123:  81%|[36m████████  [0m| 21/26 [00:20<00:05,  1.06s/it]Epoch: 4/10. Loss: 0.9597:  81%|[36m████████  [0m| 21/26 [00:20<00:05,  1.06s/it]Epoch: 4/10. Loss: 0.9597:  85%|[36m████████▍ [0m| 22/26 [00:21<00:03,  1.02it/s]Epoch: 4/10. Loss: 0.8161:  85%|[36m████████▍ [0m| 22/26 [00:21<00:03,  1.02it/s]Epoch: 4/10. Loss: 0.8161:  88%|[36m████████▊ [0m| 23/26 [00:21<00:02,  1.07it/s]Epoch: 4/10. Loss: 0.7872:  88%|[36m████████▊ [0m| 23/26 [00:22<00:02,  1.07it/s]Epoch: 4/10. Loss: 0.7872:  92%|[36m█████████▏[0m| 24/26 [00:22<00:01,  1.11it/s]Epoch: 4/10. Loss: 0.8107:  92%|[36m█████████▏[0m| 24/26 [00:24<00:01,  1.11it/s]Epoch: 4/10. Loss: 0.8107:  96%|[36m█████████▌[0m| 25/26 [00:24<00:01,  1.04s/it]Epoch: 4/10. Loss: 0.9115:  96%|[36m█████████▌[0m| 25/26 [00:24<00:01,  1.04s/it]Epoch: 4/10. Loss: 0.9115: 100%|[36m██████████[0m| 26/26 [00:24<00:00,  1.02it/s]Epoch: 4/10. Loss: 0.9115: 100%|[36m██████████[0m| 26/26 [00:24<00:00,  1.05it/s]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:05,  1.15it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:05,  1.03s/it] 43%|[33m████▎     [0m| 3/7 [00:02<00:03,  1.13it/s] 57%|[33m█████▋    [0m| 4/7 [00:04<00:03,  1.07s/it] 71%|[33m███████▏  [0m| 5/7 [00:04<00:01,  1.23it/s] 86%|[33m████████▌ [0m| 6/7 [00:05<00:00,  1.26it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.64it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.29it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 5/10. Loss: 0.8701:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 5/10. Loss: 0.8701:   4%|[36m▍         [0m| 1/26 [00:00<00:21,  1.17it/s]Epoch: 5/10. Loss: 0.7921:   4%|[36m▍         [0m| 1/26 [00:01<00:21,  1.17it/s]Epoch: 5/10. Loss: 0.7921:   8%|[36m▊         [0m| 2/26 [00:01<00:20,  1.16it/s]Epoch: 5/10. Loss: 0.7831:   8%|[36m▊         [0m| 2/26 [00:02<00:20,  1.16it/s]Epoch: 5/10. Loss: 0.7831:  12%|[36m█▏        [0m| 3/26 [00:02<00:20,  1.13it/s]Epoch: 5/10. Loss: 0.7966:  12%|[36m█▏        [0m| 3/26 [00:03<00:20,  1.13it/s]Epoch: 5/10. Loss: 0.7966:  15%|[36m█▌        [0m| 4/26 [00:03<00:21,  1.04it/s]Epoch: 5/10. Loss: 0.8017:  15%|[36m█▌        [0m| 4/26 [00:04<00:21,  1.04it/s]Epoch: 5/10. Loss: 0.8017:  19%|[36m█▉        [0m| 5/26 [00:04<00:19,  1.09it/s]Epoch: 5/10. Loss: 0.8832:  19%|[36m█▉        [0m| 5/26 [00:05<00:19,  1.09it/s]Epoch: 5/10. Loss: 0.8832:  23%|[36m██▎       [0m| 6/26 [00:05<00:19,  1.03it/s]Epoch: 5/10. Loss: 0.7657:  23%|[36m██▎       [0m| 6/26 [00:06<00:19,  1.03it/s]Epoch: 5/10. Loss: 0.7657:  27%|[36m██▋       [0m| 7/26 [00:06<00:17,  1.07it/s]Epoch: 5/10. Loss: 0.8330:  27%|[36m██▋       [0m| 7/26 [00:07<00:17,  1.07it/s]Epoch: 5/10. Loss: 0.8330:  31%|[36m███       [0m| 8/26 [00:07<00:16,  1.07it/s]Epoch: 5/10. Loss: 0.7799:  31%|[36m███       [0m| 8/26 [00:08<00:16,  1.07it/s]Epoch: 5/10. Loss: 0.7799:  35%|[36m███▍      [0m| 9/26 [00:08<00:15,  1.12it/s]Epoch: 5/10. Loss: 0.7020:  35%|[36m███▍      [0m| 9/26 [00:09<00:15,  1.12it/s]Epoch: 5/10. Loss: 0.7020:  38%|[36m███▊      [0m| 10/26 [00:09<00:17,  1.07s/it]Epoch: 5/10. Loss: 0.7050:  38%|[36m███▊      [0m| 10/26 [00:10<00:17,  1.07s/it]Epoch: 5/10. Loss: 0.7050:  42%|[36m████▏     [0m| 11/26 [00:10<00:14,  1.01it/s]Epoch: 5/10. Loss: 0.8023:  42%|[36m████▏     [0m| 11/26 [00:11<00:14,  1.01it/s]Epoch: 5/10. Loss: 0.8023:  46%|[36m████▌     [0m| 12/26 [00:11<00:13,  1.00it/s]Epoch: 5/10. Loss: 0.8373:  46%|[36m████▌     [0m| 12/26 [00:12<00:13,  1.00it/s]Epoch: 5/10. Loss: 0.8373:  50%|[36m█████     [0m| 13/26 [00:12<00:12,  1.04it/s]Epoch: 5/10. Loss: 0.8989:  50%|[36m█████     [0m| 13/26 [00:13<00:12,  1.04it/s]Epoch: 5/10. Loss: 0.8989:  54%|[36m█████▍    [0m| 14/26 [00:13<00:11,  1.02it/s]Epoch: 5/10. Loss: 0.8465:  54%|[36m█████▍    [0m| 14/26 [00:14<00:11,  1.02it/s]Epoch: 5/10. Loss: 0.8465:  58%|[36m█████▊    [0m| 15/26 [00:14<00:10,  1.06it/s]Epoch: 5/10. Loss: 0.9015:  58%|[36m█████▊    [0m| 15/26 [00:15<00:10,  1.06it/s]Epoch: 5/10. Loss: 0.9015:  62%|[36m██████▏   [0m| 16/26 [00:15<00:09,  1.07it/s]Epoch: 5/10. Loss: 0.7956:  62%|[36m██████▏   [0m| 16/26 [00:16<00:09,  1.07it/s]Epoch: 5/10. Loss: 0.7956:  65%|[36m██████▌   [0m| 17/26 [00:16<00:09,  1.05s/it]Epoch: 5/10. Loss: 0.8075:  65%|[36m██████▌   [0m| 17/26 [00:17<00:09,  1.05s/it]Epoch: 5/10. Loss: 0.8075:  69%|[36m██████▉   [0m| 18/26 [00:17<00:07,  1.03it/s]Epoch: 5/10. Loss: 0.8124:  69%|[36m██████▉   [0m| 18/26 [00:18<00:07,  1.03it/s]Epoch: 5/10. Loss: 0.8124:  73%|[36m███████▎  [0m| 19/26 [00:18<00:07,  1.02s/it]Epoch: 5/10. Loss: 0.8490:  73%|[36m███████▎  [0m| 19/26 [00:21<00:07,  1.02s/it]Epoch: 5/10. Loss: 0.8490:  77%|[36m███████▋  [0m| 20/26 [00:21<00:09,  1.58s/it]Epoch: 5/10. Loss: 0.9001:  77%|[36m███████▋  [0m| 20/26 [00:23<00:09,  1.58s/it]Epoch: 5/10. Loss: 0.9001:  81%|[36m████████  [0m| 21/26 [00:23<00:09,  1.80s/it]Epoch: 5/10. Loss: 0.7630:  81%|[36m████████  [0m| 21/26 [00:24<00:09,  1.80s/it]Epoch: 5/10. Loss: 0.7630:  85%|[36m████████▍ [0m| 22/26 [00:24<00:06,  1.52s/it]Epoch: 5/10. Loss: 0.7561:  85%|[36m████████▍ [0m| 22/26 [00:25<00:06,  1.52s/it]Epoch: 5/10. Loss: 0.7561:  88%|[36m████████▊ [0m| 23/26 [00:25<00:04,  1.34s/it]Epoch: 5/10. Loss: 0.8326:  88%|[36m████████▊ [0m| 23/26 [00:26<00:04,  1.34s/it]Epoch: 5/10. Loss: 0.8326:  92%|[36m█████████▏[0m| 24/26 [00:26<00:02,  1.20s/it]Epoch: 5/10. Loss: 0.8108:  92%|[36m█████████▏[0m| 24/26 [00:27<00:02,  1.20s/it]Epoch: 5/10. Loss: 0.8108:  96%|[36m█████████▌[0m| 25/26 [00:27<00:01,  1.09s/it]Epoch: 5/10. Loss: 0.7848:  96%|[36m█████████▌[0m| 25/26 [00:28<00:01,  1.09s/it]Epoch: 5/10. Loss: 0.7848: 100%|[36m██████████[0m| 26/26 [00:28<00:00,  1.13s/it]Epoch: 5/10. Loss: 0.7848: 100%|[36m██████████[0m| 26/26 [00:28<00:00,  1.09s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:01<00:06,  1.12s/it] 29%|[33m██▊       [0m| 2/7 [00:02<00:05,  1.14s/it] 43%|[33m████▎     [0m| 3/7 [00:02<00:03,  1.06it/s] 57%|[33m█████▋    [0m| 4/7 [00:04<00:03,  1.12s/it] 71%|[33m███████▏  [0m| 5/7 [00:04<00:01,  1.17it/s] 86%|[33m████████▌ [0m| 6/7 [00:05<00:00,  1.21it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.57it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.21it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 6/10. Loss: 0.6835:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 6/10. Loss: 0.6835:   4%|[36m▍         [0m| 1/26 [00:00<00:24,  1.03it/s]Epoch: 6/10. Loss: 0.7771:   4%|[36m▍         [0m| 1/26 [00:01<00:24,  1.03it/s]Epoch: 6/10. Loss: 0.7771:   8%|[36m▊         [0m| 2/26 [00:01<00:21,  1.13it/s]Epoch: 6/10. Loss: 0.7436:   8%|[36m▊         [0m| 2/26 [00:02<00:21,  1.13it/s]Epoch: 6/10. Loss: 0.7436:  12%|[36m█▏        [0m| 3/26 [00:02<00:22,  1.03it/s]Epoch: 6/10. Loss: 0.8329:  12%|[36m█▏        [0m| 3/26 [00:03<00:22,  1.03it/s]Epoch: 6/10. Loss: 0.8329:  15%|[36m█▌        [0m| 4/26 [00:03<00:21,  1.02it/s]Epoch: 6/10. Loss: 0.7964:  15%|[36m█▌        [0m| 4/26 [00:04<00:21,  1.02it/s]Epoch: 6/10. Loss: 0.7964:  19%|[36m█▉        [0m| 5/26 [00:04<00:19,  1.08it/s]Epoch: 6/10. Loss: 0.8257:  19%|[36m█▉        [0m| 5/26 [00:05<00:19,  1.08it/s]Epoch: 6/10. Loss: 0.8257:  23%|[36m██▎       [0m| 6/26 [00:05<00:18,  1.10it/s]Epoch: 6/10. Loss: 0.7790:  23%|[36m██▎       [0m| 6/26 [00:06<00:18,  1.10it/s]Epoch: 6/10. Loss: 0.7790:  27%|[36m██▋       [0m| 7/26 [00:06<00:17,  1.09it/s]Epoch: 6/10. Loss: 0.7321:  27%|[36m██▋       [0m| 7/26 [00:07<00:17,  1.09it/s]Epoch: 6/10. Loss: 0.7321:  31%|[36m███       [0m| 8/26 [00:07<00:16,  1.09it/s]Epoch: 6/10. Loss: 0.6944:  31%|[36m███       [0m| 8/26 [00:08<00:16,  1.09it/s]Epoch: 6/10. Loss: 0.6944:  35%|[36m███▍      [0m| 9/26 [00:08<00:15,  1.11it/s]Epoch: 6/10. Loss: 0.7071:  35%|[36m███▍      [0m| 9/26 [00:09<00:15,  1.11it/s]Epoch: 6/10. Loss: 0.7071:  38%|[36m███▊      [0m| 10/26 [00:09<00:14,  1.09it/s]Epoch: 6/10. Loss: 0.8881:  38%|[36m███▊      [0m| 10/26 [00:10<00:14,  1.09it/s]Epoch: 6/10. Loss: 0.8881:  42%|[36m████▏     [0m| 11/26 [00:10<00:13,  1.07it/s]Epoch: 6/10. Loss: 0.9454:  42%|[36m████▏     [0m| 11/26 [00:11<00:13,  1.07it/s]Epoch: 6/10. Loss: 0.9454:  46%|[36m████▌     [0m| 12/26 [00:11<00:13,  1.02it/s]Epoch: 6/10. Loss: 0.7904:  46%|[36m████▌     [0m| 12/26 [00:12<00:13,  1.02it/s]Epoch: 6/10. Loss: 0.7904:  50%|[36m█████     [0m| 13/26 [00:12<00:12,  1.04it/s]Epoch: 6/10. Loss: 0.7431:  50%|[36m█████     [0m| 13/26 [00:13<00:12,  1.04it/s]Epoch: 6/10. Loss: 0.7431:  54%|[36m█████▍    [0m| 14/26 [00:13<00:11,  1.01it/s]Epoch: 6/10. Loss: 0.8174:  54%|[36m█████▍    [0m| 14/26 [00:14<00:11,  1.01it/s]Epoch: 6/10. Loss: 0.8174:  58%|[36m█████▊    [0m| 15/26 [00:14<00:11,  1.05s/it]Epoch: 6/10. Loss: 0.7872:  58%|[36m█████▊    [0m| 15/26 [00:15<00:11,  1.05s/it]Epoch: 6/10. Loss: 0.7872:  62%|[36m██████▏   [0m| 16/26 [00:15<00:10,  1.01s/it]Epoch: 6/10. Loss: 0.7353:  62%|[36m██████▏   [0m| 16/26 [00:18<00:10,  1.01s/it]Epoch: 6/10. Loss: 0.7353:  65%|[36m██████▌   [0m| 17/26 [00:18<00:14,  1.61s/it]Epoch: 6/10. Loss: 0.8474:  65%|[36m██████▌   [0m| 17/26 [00:19<00:14,  1.61s/it]Epoch: 6/10. Loss: 0.8474:  69%|[36m██████▉   [0m| 18/26 [00:19<00:10,  1.35s/it]Epoch: 6/10. Loss: 0.7506:  69%|[36m██████▉   [0m| 18/26 [00:20<00:10,  1.35s/it]Epoch: 6/10. Loss: 0.7506:  73%|[36m███████▎  [0m| 19/26 [00:20<00:08,  1.25s/it]Epoch: 6/10. Loss: 0.8414:  73%|[36m███████▎  [0m| 19/26 [00:20<00:08,  1.25s/it]Epoch: 6/10. Loss: 0.8414:  77%|[36m███████▋  [0m| 20/26 [00:20<00:06,  1.12s/it]Epoch: 6/10. Loss: 0.7759:  77%|[36m███████▋  [0m| 20/26 [00:22<00:06,  1.12s/it]Epoch: 6/10. Loss: 0.7759:  81%|[36m████████  [0m| 21/26 [00:22<00:05,  1.19s/it]Epoch: 6/10. Loss: 0.7936:  81%|[36m████████  [0m| 21/26 [00:23<00:05,  1.19s/it]Epoch: 6/10. Loss: 0.7936:  85%|[36m████████▍ [0m| 22/26 [00:23<00:04,  1.08s/it]Epoch: 6/10. Loss: 0.7538:  85%|[36m████████▍ [0m| 22/26 [00:23<00:04,  1.08s/it]Epoch: 6/10. Loss: 0.7538:  88%|[36m████████▊ [0m| 23/26 [00:23<00:03,  1.01s/it]Epoch: 6/10. Loss: 0.7741:  88%|[36m████████▊ [0m| 23/26 [00:24<00:03,  1.01s/it]Epoch: 6/10. Loss: 0.7741:  92%|[36m█████████▏[0m| 24/26 [00:25<00:02,  1.01s/it]Epoch: 6/10. Loss: 0.8531:  92%|[36m█████████▏[0m| 24/26 [00:26<00:02,  1.01s/it]Epoch: 6/10. Loss: 0.8531:  96%|[36m█████████▌[0m| 25/26 [00:26<00:01,  1.02s/it]Epoch: 6/10. Loss: 0.7052:  96%|[36m█████████▌[0m| 25/26 [00:26<00:01,  1.02s/it]Epoch: 6/10. Loss: 0.7052: 100%|[36m██████████[0m| 26/26 [00:26<00:00,  1.14it/s]Epoch: 6/10. Loss: 0.7052: 100%|[36m██████████[0m| 26/26 [00:26<00:00,  1.02s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:05,  1.09it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:05,  1.09s/it] 43%|[33m████▎     [0m| 3/7 [00:02<00:03,  1.09it/s] 57%|[33m█████▋    [0m| 4/7 [00:04<00:03,  1.10s/it] 71%|[33m███████▏  [0m| 5/7 [00:04<00:01,  1.18it/s] 86%|[33m████████▌ [0m| 6/7 [00:05<00:00,  1.21it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.57it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.24it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 7/10. Loss: 0.7112:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 7/10. Loss: 0.7112:   4%|[36m▍         [0m| 1/26 [00:00<00:20,  1.22it/s]Epoch: 7/10. Loss: 0.8483:   4%|[36m▍         [0m| 1/26 [00:01<00:20,  1.22it/s]Epoch: 7/10. Loss: 0.8483:   8%|[36m▊         [0m| 2/26 [00:01<00:19,  1.20it/s]Epoch: 7/10. Loss: 0.8719:   8%|[36m▊         [0m| 2/26 [00:03<00:19,  1.20it/s]Epoch: 7/10. Loss: 0.8719:  12%|[36m█▏        [0m| 3/26 [00:03<00:26,  1.17s/it]Epoch: 7/10. Loss: 0.7999:  12%|[36m█▏        [0m| 3/26 [00:04<00:26,  1.17s/it]Epoch: 7/10. Loss: 0.7999:  15%|[36m█▌        [0m| 4/26 [00:04<00:23,  1.06s/it]Epoch: 7/10. Loss: 0.7506:  15%|[36m█▌        [0m| 4/26 [00:04<00:23,  1.06s/it]Epoch: 7/10. Loss: 0.7506:  19%|[36m█▉        [0m| 5/26 [00:04<00:19,  1.06it/s]Epoch: 7/10. Loss: 0.8487:  19%|[36m█▉        [0m| 5/26 [00:05<00:19,  1.06it/s]Epoch: 7/10. Loss: 0.8487:  23%|[36m██▎       [0m| 6/26 [00:05<00:18,  1.08it/s]Epoch: 7/10. Loss: 0.7636:  23%|[36m██▎       [0m| 6/26 [00:06<00:18,  1.08it/s]Epoch: 7/10. Loss: 0.7636:  27%|[36m██▋       [0m| 7/26 [00:06<00:16,  1.15it/s]Epoch: 7/10. Loss: 0.7552:  27%|[36m██▋       [0m| 7/26 [00:07<00:16,  1.15it/s]Epoch: 7/10. Loss: 0.7552:  31%|[36m███       [0m| 8/26 [00:07<00:15,  1.15it/s]Epoch: 7/10. Loss: 0.7297:  31%|[36m███       [0m| 8/26 [00:08<00:15,  1.15it/s]Epoch: 7/10. Loss: 0.7297:  35%|[36m███▍      [0m| 9/26 [00:08<00:14,  1.19it/s]Epoch: 7/10. Loss: 0.7666:  35%|[36m███▍      [0m| 9/26 [00:09<00:14,  1.19it/s]Epoch: 7/10. Loss: 0.7666:  38%|[36m███▊      [0m| 10/26 [00:09<00:13,  1.15it/s]Epoch: 7/10. Loss: 0.8733:  38%|[36m███▊      [0m| 10/26 [00:10<00:13,  1.15it/s]Epoch: 7/10. Loss: 0.8733:  42%|[36m████▏     [0m| 11/26 [00:10<00:13,  1.11it/s]Epoch: 7/10. Loss: 0.7350:  42%|[36m████▏     [0m| 11/26 [00:11<00:13,  1.11it/s]Epoch: 7/10. Loss: 0.7350:  46%|[36m████▌     [0m| 12/26 [00:11<00:14,  1.03s/it]Epoch: 7/10. Loss: 0.6651:  46%|[36m████▌     [0m| 12/26 [00:12<00:14,  1.03s/it]Epoch: 7/10. Loss: 0.6651:  50%|[36m█████     [0m| 13/26 [00:12<00:13,  1.02s/it]Epoch: 7/10. Loss: 0.7758:  50%|[36m█████     [0m| 13/26 [00:13<00:13,  1.02s/it]Epoch: 7/10. Loss: 0.7758:  54%|[36m█████▍    [0m| 14/26 [00:13<00:11,  1.03it/s]Epoch: 7/10. Loss: 0.7409:  54%|[36m█████▍    [0m| 14/26 [00:14<00:11,  1.03it/s]Epoch: 7/10. Loss: 0.7409:  58%|[36m█████▊    [0m| 15/26 [00:14<00:10,  1.04it/s]Epoch: 7/10. Loss: 0.7278:  58%|[36m█████▊    [0m| 15/26 [00:15<00:10,  1.04it/s]Epoch: 7/10. Loss: 0.7278:  62%|[36m██████▏   [0m| 16/26 [00:15<00:09,  1.08it/s]Epoch: 7/10. Loss: 0.7235:  62%|[36m██████▏   [0m| 16/26 [00:15<00:09,  1.08it/s]Epoch: 7/10. Loss: 0.7235:  65%|[36m██████▌   [0m| 17/26 [00:15<00:07,  1.13it/s]Epoch: 7/10. Loss: 0.7180:  65%|[36m██████▌   [0m| 17/26 [00:16<00:07,  1.13it/s]Epoch: 7/10. Loss: 0.7180:  69%|[36m██████▉   [0m| 18/26 [00:16<00:07,  1.13it/s]Epoch: 7/10. Loss: 0.7357:  69%|[36m██████▉   [0m| 18/26 [00:17<00:07,  1.13it/s]Epoch: 7/10. Loss: 0.7357:  73%|[36m███████▎  [0m| 19/26 [00:17<00:06,  1.06it/s]Epoch: 7/10. Loss: 0.8053:  73%|[36m███████▎  [0m| 19/26 [00:18<00:06,  1.06it/s]Epoch: 7/10. Loss: 0.8053:  77%|[36m███████▋  [0m| 20/26 [00:18<00:05,  1.03it/s]Epoch: 7/10. Loss: 0.7690:  77%|[36m███████▋  [0m| 20/26 [00:21<00:05,  1.03it/s]Epoch: 7/10. Loss: 0.7690:  81%|[36m████████  [0m| 21/26 [00:21<00:07,  1.46s/it]Epoch: 7/10. Loss: 0.8158:  81%|[36m████████  [0m| 21/26 [00:23<00:07,  1.46s/it]Epoch: 7/10. Loss: 0.8158:  85%|[36m████████▍ [0m| 22/26 [00:23<00:06,  1.57s/it]Epoch: 7/10. Loss: 0.7040:  85%|[36m████████▍ [0m| 22/26 [00:24<00:06,  1.57s/it]Epoch: 7/10. Loss: 0.7040:  88%|[36m████████▊ [0m| 23/26 [00:24<00:04,  1.39s/it]Epoch: 7/10. Loss: 0.7457:  88%|[36m████████▊ [0m| 23/26 [00:25<00:04,  1.39s/it]Epoch: 7/10. Loss: 0.7457:  92%|[36m█████████▏[0m| 24/26 [00:25<00:02,  1.26s/it]Epoch: 7/10. Loss: 0.7974:  92%|[36m█████████▏[0m| 24/26 [00:27<00:02,  1.26s/it]Epoch: 7/10. Loss: 0.7974:  96%|[36m█████████▌[0m| 25/26 [00:27<00:01,  1.52s/it]Epoch: 7/10. Loss: 0.6478:  96%|[36m█████████▌[0m| 25/26 [00:27<00:01,  1.52s/it]Epoch: 7/10. Loss: 0.6478: 100%|[36m██████████[0m| 26/26 [00:27<00:00,  1.26s/it]Epoch: 7/10. Loss: 0.6478: 100%|[36m██████████[0m| 26/26 [00:27<00:00,  1.07s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:05,  1.06it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:06,  1.27s/it] 43%|[33m████▎     [0m| 3/7 [00:03<00:04,  1.04s/it] 57%|[33m█████▋    [0m| 4/7 [00:05<00:04,  1.41s/it] 71%|[33m███████▏  [0m| 5/7 [00:05<00:02,  1.05s/it] 86%|[33m████████▌ [0m| 6/7 [00:06<00:01,  1.12s/it]100%|[33m██████████[0m| 7/7 [00:07<00:00,  1.04s/it]100%|[33m██████████[0m| 7/7 [00:07<00:00,  1.10s/it]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 8/10. Loss: 0.7189:   0%|[36m          [0m| 0/26 [00:01<?, ?it/s]Epoch: 8/10. Loss: 0.7189:   4%|[36m▍         [0m| 1/26 [00:01<00:25,  1.02s/it]Epoch: 8/10. Loss: 0.7327:   4%|[36m▍         [0m| 1/26 [00:01<00:25,  1.02s/it]Epoch: 8/10. Loss: 0.7327:   8%|[36m▊         [0m| 2/26 [00:01<00:22,  1.06it/s]Epoch: 8/10. Loss: 0.6827:   8%|[36m▊         [0m| 2/26 [00:02<00:22,  1.06it/s]Epoch: 8/10. Loss: 0.6827:  12%|[36m█▏        [0m| 3/26 [00:02<00:21,  1.08it/s]Epoch: 8/10. Loss: 0.7607:  12%|[36m█▏        [0m| 3/26 [00:03<00:21,  1.08it/s]Epoch: 8/10. Loss: 0.7607:  15%|[36m█▌        [0m| 4/26 [00:03<00:20,  1.07it/s]Epoch: 8/10. Loss: 0.7284:  15%|[36m█▌        [0m| 4/26 [00:04<00:20,  1.07it/s]Epoch: 8/10. Loss: 0.7284:  19%|[36m█▉        [0m| 5/26 [00:04<00:17,  1.18it/s]Epoch: 8/10. Loss: 0.6123:  19%|[36m█▉        [0m| 5/26 [00:06<00:17,  1.18it/s]Epoch: 8/10. Loss: 0.6123:  23%|[36m██▎       [0m| 6/26 [00:06<00:22,  1.11s/it]Epoch: 8/10. Loss: 0.7184:  23%|[36m██▎       [0m| 6/26 [00:06<00:22,  1.11s/it]Epoch: 8/10. Loss: 0.7184:  27%|[36m██▋       [0m| 7/26 [00:06<00:19,  1.04s/it]Epoch: 8/10. Loss: 0.6675:  27%|[36m██▋       [0m| 7/26 [00:08<00:19,  1.04s/it]Epoch: 8/10. Loss: 0.6675:  31%|[36m███       [0m| 8/26 [00:08<00:18,  1.04s/it]Epoch: 8/10. Loss: 0.7823:  31%|[36m███       [0m| 8/26 [00:09<00:18,  1.04s/it]Epoch: 8/10. Loss: 0.7823:  35%|[36m███▍      [0m| 9/26 [00:09<00:17,  1.05s/it]Epoch: 8/10. Loss: 0.6495:  35%|[36m███▍      [0m| 9/26 [00:09<00:17,  1.05s/it]Epoch: 8/10. Loss: 0.6495:  38%|[36m███▊      [0m| 10/26 [00:09<00:15,  1.00it/s]Epoch: 8/10. Loss: 0.6490:  38%|[36m███▊      [0m| 10/26 [00:10<00:15,  1.00it/s]Epoch: 8/10. Loss: 0.6490:  42%|[36m████▏     [0m| 11/26 [00:10<00:14,  1.06it/s]Epoch: 8/10. Loss: 0.7004:  42%|[36m████▏     [0m| 11/26 [00:11<00:14,  1.06it/s]Epoch: 8/10. Loss: 0.7004:  46%|[36m████▌     [0m| 12/26 [00:11<00:13,  1.06it/s]Epoch: 8/10. Loss: 0.6272:  46%|[36m████▌     [0m| 12/26 [00:12<00:13,  1.06it/s]Epoch: 8/10. Loss: 0.6272:  50%|[36m█████     [0m| 13/26 [00:12<00:12,  1.04it/s]Epoch: 8/10. Loss: 0.7196:  50%|[36m█████     [0m| 13/26 [00:13<00:12,  1.04it/s]Epoch: 8/10. Loss: 0.7196:  54%|[36m█████▍    [0m| 14/26 [00:13<00:11,  1.05it/s]Epoch: 8/10. Loss: 0.9674:  54%|[36m█████▍    [0m| 14/26 [00:15<00:11,  1.05it/s]Epoch: 8/10. Loss: 0.9674:  58%|[36m█████▊    [0m| 15/26 [00:15<00:13,  1.21s/it]Epoch: 8/10. Loss: 0.7256:  58%|[36m█████▊    [0m| 15/26 [00:16<00:13,  1.21s/it]Epoch: 8/10. Loss: 0.7256:  62%|[36m██████▏   [0m| 16/26 [00:16<00:11,  1.14s/it]Epoch: 8/10. Loss: 0.7377:  62%|[36m██████▏   [0m| 16/26 [00:17<00:11,  1.14s/it]Epoch: 8/10. Loss: 0.7377:  65%|[36m██████▌   [0m| 17/26 [00:17<00:11,  1.25s/it]Epoch: 8/10. Loss: 0.6515:  65%|[36m██████▌   [0m| 17/26 [00:18<00:11,  1.25s/it]Epoch: 8/10. Loss: 0.6515:  69%|[36m██████▉   [0m| 18/26 [00:18<00:09,  1.17s/it]Epoch: 8/10. Loss: 0.8330:  69%|[36m██████▉   [0m| 18/26 [00:19<00:09,  1.17s/it]Epoch: 8/10. Loss: 0.8330:  73%|[36m███████▎  [0m| 19/26 [00:19<00:07,  1.12s/it]Epoch: 8/10. Loss: 0.6891:  73%|[36m███████▎  [0m| 19/26 [00:20<00:07,  1.12s/it]Epoch: 8/10. Loss: 0.6891:  77%|[36m███████▋  [0m| 20/26 [00:20<00:06,  1.03s/it]Epoch: 8/10. Loss: 0.7708:  77%|[36m███████▋  [0m| 20/26 [00:21<00:06,  1.03s/it]Epoch: 8/10. Loss: 0.7708:  81%|[36m████████  [0m| 21/26 [00:21<00:04,  1.01it/s]Epoch: 8/10. Loss: 0.7877:  81%|[36m████████  [0m| 21/26 [00:22<00:04,  1.01it/s]Epoch: 8/10. Loss: 0.7877:  85%|[36m████████▍ [0m| 22/26 [00:22<00:03,  1.09it/s]Epoch: 8/10. Loss: 0.7301:  85%|[36m████████▍ [0m| 22/26 [00:23<00:03,  1.09it/s]Epoch: 8/10. Loss: 0.7301:  88%|[36m████████▊ [0m| 23/26 [00:23<00:02,  1.13it/s]Epoch: 8/10. Loss: 0.7922:  88%|[36m████████▊ [0m| 23/26 [00:24<00:02,  1.13it/s]Epoch: 8/10. Loss: 0.7922:  92%|[36m█████████▏[0m| 24/26 [00:24<00:01,  1.11it/s]Epoch: 8/10. Loss: 0.6839:  92%|[36m█████████▏[0m| 24/26 [00:25<00:01,  1.11it/s]Epoch: 8/10. Loss: 0.6839:  96%|[36m█████████▌[0m| 25/26 [00:25<00:00,  1.09it/s]Epoch: 8/10. Loss: 0.8245:  96%|[36m█████████▌[0m| 25/26 [00:25<00:00,  1.09it/s]Epoch: 8/10. Loss: 0.8245: 100%|[36m██████████[0m| 26/26 [00:25<00:00,  1.23it/s]Epoch: 8/10. Loss: 0.8245: 100%|[36m██████████[0m| 26/26 [00:25<00:00,  1.01it/s]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:05,  1.05it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:05,  1.16s/it] 43%|[33m████▎     [0m| 3/7 [00:03<00:03,  1.03it/s] 57%|[33m█████▋    [0m| 4/7 [00:04<00:03,  1.13s/it] 71%|[33m███████▏  [0m| 5/7 [00:04<00:01,  1.14it/s] 86%|[33m████████▌ [0m| 6/7 [00:05<00:00,  1.17it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.52it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.19it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 9/10. Loss: 0.7449:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 9/10. Loss: 0.7449:   4%|[36m▍         [0m| 1/26 [00:00<00:23,  1.04it/s]Epoch: 9/10. Loss: 0.7073:   4%|[36m▍         [0m| 1/26 [00:01<00:23,  1.04it/s]Epoch: 9/10. Loss: 0.7073:   8%|[36m▊         [0m| 2/26 [00:01<00:21,  1.11it/s]Epoch: 9/10. Loss: 0.6756:   8%|[36m▊         [0m| 2/26 [00:02<00:21,  1.11it/s]Epoch: 9/10. Loss: 0.6756:  12%|[36m█▏        [0m| 3/26 [00:02<00:19,  1.18it/s]Epoch: 9/10. Loss: 0.6345:  12%|[36m█▏        [0m| 3/26 [00:03<00:19,  1.18it/s]Epoch: 9/10. Loss: 0.6345:  15%|[36m█▌        [0m| 4/26 [00:03<00:17,  1.28it/s]Epoch: 9/10. Loss: 0.7016:  15%|[36m█▌        [0m| 4/26 [00:04<00:17,  1.28it/s]Epoch: 9/10. Loss: 0.7016:  19%|[36m█▉        [0m| 5/26 [00:04<00:17,  1.17it/s]Epoch: 9/10. Loss: 0.6782:  19%|[36m█▉        [0m| 5/26 [00:05<00:17,  1.17it/s]Epoch: 9/10. Loss: 0.6782:  23%|[36m██▎       [0m| 6/26 [00:05<00:17,  1.13it/s]Epoch: 9/10. Loss: 0.6516:  23%|[36m██▎       [0m| 6/26 [00:06<00:17,  1.13it/s]Epoch: 9/10. Loss: 0.6516:  27%|[36m██▋       [0m| 7/26 [00:06<00:17,  1.09it/s]Epoch: 9/10. Loss: 0.7482:  27%|[36m██▋       [0m| 7/26 [00:06<00:17,  1.09it/s]Epoch: 9/10. Loss: 0.7482:  31%|[36m███       [0m| 8/26 [00:06<00:15,  1.16it/s]Epoch: 9/10. Loss: 0.7781:  31%|[36m███       [0m| 8/26 [00:07<00:15,  1.16it/s]Epoch: 9/10. Loss: 0.7781:  35%|[36m███▍      [0m| 9/26 [00:07<00:15,  1.12it/s]Epoch: 9/10. Loss: 0.7830:  35%|[36m███▍      [0m| 9/26 [00:08<00:15,  1.12it/s]Epoch: 9/10. Loss: 0.7830:  38%|[36m███▊      [0m| 10/26 [00:08<00:13,  1.14it/s]Epoch: 9/10. Loss: 0.7917:  38%|[36m███▊      [0m| 10/26 [00:09<00:13,  1.14it/s]Epoch: 9/10. Loss: 0.7917:  42%|[36m████▏     [0m| 11/26 [00:09<00:13,  1.15it/s]Epoch: 9/10. Loss: 0.6558:  42%|[36m████▏     [0m| 11/26 [00:12<00:13,  1.15it/s]Epoch: 9/10. Loss: 0.6558:  46%|[36m████▌     [0m| 12/26 [00:12<00:18,  1.34s/it]Epoch: 9/10. Loss: 0.6900:  46%|[36m████▌     [0m| 12/26 [00:13<00:18,  1.34s/it]Epoch: 9/10. Loss: 0.6900:  50%|[36m█████     [0m| 13/26 [00:13<00:16,  1.25s/it]Epoch: 9/10. Loss: 0.7582:  50%|[36m█████     [0m| 13/26 [00:14<00:16,  1.25s/it]Epoch: 9/10. Loss: 0.7582:  54%|[36m█████▍    [0m| 14/26 [00:14<00:14,  1.19s/it]Epoch: 9/10. Loss: 0.6951:  54%|[36m█████▍    [0m| 14/26 [00:15<00:14,  1.19s/it]Epoch: 9/10. Loss: 0.6951:  58%|[36m█████▊    [0m| 15/26 [00:15<00:12,  1.12s/it]Epoch: 9/10. Loss: 0.7243:  58%|[36m█████▊    [0m| 15/26 [00:15<00:12,  1.12s/it]Epoch: 9/10. Loss: 0.7243:  62%|[36m██████▏   [0m| 16/26 [00:15<00:10,  1.06s/it]Epoch: 9/10. Loss: 0.6866:  62%|[36m██████▏   [0m| 16/26 [00:16<00:10,  1.06s/it]Epoch: 9/10. Loss: 0.6866:  65%|[36m██████▌   [0m| 17/26 [00:16<00:08,  1.00it/s]Epoch: 9/10. Loss: 0.7512:  65%|[36m██████▌   [0m| 17/26 [00:17<00:08,  1.00it/s]Epoch: 9/10. Loss: 0.7512:  69%|[36m██████▉   [0m| 18/26 [00:17<00:07,  1.03it/s]Epoch: 9/10. Loss: 0.6896:  69%|[36m██████▉   [0m| 18/26 [00:18<00:07,  1.03it/s]Epoch: 9/10. Loss: 0.6896:  73%|[36m███████▎  [0m| 19/26 [00:18<00:06,  1.10it/s]Epoch: 9/10. Loss: 0.7513:  73%|[36m███████▎  [0m| 19/26 [00:20<00:06,  1.10it/s]Epoch: 9/10. Loss: 0.7513:  77%|[36m███████▋  [0m| 20/26 [00:20<00:07,  1.18s/it]Epoch: 9/10. Loss: 0.8652:  77%|[36m███████▋  [0m| 20/26 [00:21<00:07,  1.18s/it]Epoch: 9/10. Loss: 0.8652:  81%|[36m████████  [0m| 21/26 [00:21<00:05,  1.12s/it]Epoch: 9/10. Loss: 0.8077:  81%|[36m████████  [0m| 21/26 [00:22<00:05,  1.12s/it]Epoch: 9/10. Loss: 0.8077:  85%|[36m████████▍ [0m| 22/26 [00:22<00:04,  1.04s/it]Epoch: 9/10. Loss: 0.7587:  85%|[36m████████▍ [0m| 22/26 [00:22<00:04,  1.04s/it]Epoch: 9/10. Loss: 0.7587:  88%|[36m████████▊ [0m| 23/26 [00:22<00:02,  1.03it/s]Epoch: 9/10. Loss: 0.7501:  88%|[36m████████▊ [0m| 23/26 [00:23<00:02,  1.03it/s]Epoch: 9/10. Loss: 0.7501:  92%|[36m█████████▏[0m| 24/26 [00:23<00:01,  1.03it/s]Epoch: 9/10. Loss: 0.7055:  92%|[36m█████████▏[0m| 24/26 [00:24<00:01,  1.03it/s]Epoch: 9/10. Loss: 0.7055:  96%|[36m█████████▌[0m| 25/26 [00:24<00:00,  1.08it/s]Epoch: 9/10. Loss: 0.8508:  96%|[36m█████████▌[0m| 25/26 [00:25<00:00,  1.08it/s]Epoch: 9/10. Loss: 0.8508: 100%|[36m██████████[0m| 26/26 [00:25<00:00,  1.19it/s]Epoch: 9/10. Loss: 0.8508: 100%|[36m██████████[0m| 26/26 [00:25<00:00,  1.02it/s]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:05,  1.06it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:05,  1.10s/it] 43%|[33m████▎     [0m| 3/7 [00:02<00:03,  1.04it/s] 57%|[33m█████▋    [0m| 4/7 [00:04<00:04,  1.34s/it] 71%|[33m███████▏  [0m| 5/7 [00:05<00:02,  1.01s/it] 86%|[33m████████▌ [0m| 6/7 [00:06<00:00,  1.06it/s]100%|[33m██████████[0m| 7/7 [00:06<00:00,  1.40it/s]100%|[33m██████████[0m| 7/7 [00:06<00:00,  1.10it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 0/10. Loss: 1.0987:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 0/10. Loss: 1.0987:   4%|[36m▍         [0m| 1/26 [00:00<00:18,  1.36it/s]Epoch: 0/10. Loss: 979862.3750:   4%|[36m▍         [0m| 1/26 [00:01<00:18,  1.36it/s]Epoch: 0/10. Loss: 979862.3750:   8%|[36m▊         [0m| 2/26 [00:01<00:22,  1.06it/s]Epoch: 0/10. Loss: 509.1805:   8%|[36m▊         [0m| 2/26 [00:02<00:22,  1.06it/s]   Epoch: 0/10. Loss: 509.1805:  12%|[36m█▏        [0m| 3/26 [00:02<00:20,  1.12it/s]Epoch: 0/10. Loss: 932.9894:  12%|[36m█▏        [0m| 3/26 [00:03<00:20,  1.12it/s]Epoch: 0/10. Loss: 932.9894:  15%|[36m█▌        [0m| 4/26 [00:03<00:18,  1.17it/s]Epoch: 0/10. Loss: 4603.8789:  15%|[36m█▌        [0m| 4/26 [00:04<00:18,  1.17it/s]Epoch: 0/10. Loss: 4603.8789:  19%|[36m█▉        [0m| 5/26 [00:04<00:20,  1.03it/s]Epoch: 0/10. Loss: 6924.3130:  19%|[36m█▉        [0m| 5/26 [00:05<00:20,  1.03it/s]Epoch: 0/10. Loss: 6924.3130:  23%|[36m██▎       [0m| 6/26 [00:05<00:19,  1.00it/s]Epoch: 0/10. Loss: 16787.5938:  23%|[36m██▎       [0m| 6/26 [00:06<00:19,  1.00it/s]Epoch: 0/10. Loss: 16787.5938:  27%|[36m██▋       [0m| 7/26 [00:06<00:18,  1.05it/s]Epoch: 0/10. Loss: 3229.5830:  27%|[36m██▋       [0m| 7/26 [00:07<00:18,  1.05it/s] Epoch: 0/10. Loss: 3229.5830:  31%|[36m███       [0m| 8/26 [00:07<00:16,  1.07it/s]Epoch: 0/10. Loss: 177.0111:  31%|[36m███       [0m| 8/26 [00:08<00:16,  1.07it/s] Epoch: 0/10. Loss: 177.0111:  35%|[36m███▍      [0m| 9/26 [00:08<00:15,  1.10it/s]Epoch: 0/10. Loss: 2.7863:  35%|[36m███▍      [0m| 9/26 [00:09<00:15,  1.10it/s]  Epoch: 0/10. Loss: 2.7863:  38%|[36m███▊      [0m| 10/26 [00:09<00:13,  1.17it/s]Epoch: 0/10. Loss: 717.0809:  38%|[36m███▊      [0m| 10/26 [00:10<00:13,  1.17it/s]Epoch: 0/10. Loss: 717.0809:  42%|[36m████▏     [0m| 11/26 [00:10<00:17,  1.19s/it]Epoch: 0/10. Loss: 2.0771:  42%|[36m████▏     [0m| 11/26 [00:12<00:17,  1.19s/it]  Epoch: 0/10. Loss: 2.0771:  46%|[36m████▌     [0m| 12/26 [00:12<00:17,  1.23s/it]Epoch: 0/10. Loss: 2.5195:  46%|[36m████▌     [0m| 12/26 [00:13<00:17,  1.23s/it]Epoch: 0/10. Loss: 2.5195:  50%|[36m█████     [0m| 13/26 [00:13<00:14,  1.13s/it]Epoch: 0/10. Loss: 2.8375:  50%|[36m█████     [0m| 13/26 [00:14<00:14,  1.13s/it]Epoch: 0/10. Loss: 2.8375:  54%|[36m█████▍    [0m| 14/26 [00:14<00:12,  1.07s/it]Epoch: 0/10. Loss: 1.9760:  54%|[36m█████▍    [0m| 14/26 [00:14<00:12,  1.07s/it]Epoch: 0/10. Loss: 1.9760:  58%|[36m█████▊    [0m| 15/26 [00:14<00:11,  1.01s/it]Epoch: 0/10. Loss: 1.9640:  58%|[36m█████▊    [0m| 15/26 [00:15<00:11,  1.01s/it]Epoch: 0/10. Loss: 1.9640:  62%|[36m██████▏   [0m| 16/26 [00:15<00:09,  1.00it/s]Epoch: 0/10. Loss: 1.7929:  62%|[36m██████▏   [0m| 16/26 [00:16<00:09,  1.00it/s]Epoch: 0/10. Loss: 1.7929:  65%|[36m██████▌   [0m| 17/26 [00:16<00:08,  1.05it/s]Epoch: 0/10. Loss: 1.6556:  65%|[36m██████▌   [0m| 17/26 [00:17<00:08,  1.05it/s]Epoch: 0/10. Loss: 1.6556:  69%|[36m██████▉   [0m| 18/26 [00:17<00:07,  1.07it/s]Epoch: 0/10. Loss: 1.3148:  69%|[36m██████▉   [0m| 18/26 [00:18<00:07,  1.07it/s]Epoch: 0/10. Loss: 1.3148:  73%|[36m███████▎  [0m| 19/26 [00:18<00:06,  1.11it/s]Epoch: 0/10. Loss: 1.2360:  73%|[36m███████▎  [0m| 19/26 [00:19<00:06,  1.11it/s]Epoch: 0/10. Loss: 1.2360:  77%|[36m███████▋  [0m| 20/26 [00:19<00:05,  1.13it/s]Epoch: 0/10. Loss: 1.0540:  77%|[36m███████▋  [0m| 20/26 [00:20<00:05,  1.13it/s]Epoch: 0/10. Loss: 1.0540:  81%|[36m████████  [0m| 21/26 [00:20<00:04,  1.14it/s]Epoch: 0/10. Loss: 1.0887:  81%|[36m████████  [0m| 21/26 [00:21<00:04,  1.14it/s]Epoch: 0/10. Loss: 1.0887:  85%|[36m████████▍ [0m| 22/26 [00:21<00:03,  1.15it/s]Epoch: 0/10. Loss: 1.1071:  85%|[36m████████▍ [0m| 22/26 [00:21<00:03,  1.15it/s]Epoch: 0/10. Loss: 1.1071:  88%|[36m████████▊ [0m| 23/26 [00:21<00:02,  1.16it/s]Epoch: 0/10. Loss: 1.1271:  88%|[36m████████▊ [0m| 23/26 [00:22<00:02,  1.16it/s]Epoch: 0/10. Loss: 1.1271:  92%|[36m█████████▏[0m| 24/26 [00:22<00:01,  1.17it/s]Epoch: 0/10. Loss: 1.1043:  92%|[36m█████████▏[0m| 24/26 [00:23<00:01,  1.17it/s]Epoch: 0/10. Loss: 1.1043:  96%|[36m█████████▌[0m| 25/26 [00:23<00:00,  1.13it/s]Epoch: 0/10. Loss: 1.0984:  96%|[36m█████████▌[0m| 25/26 [00:24<00:00,  1.13it/s]Epoch: 0/10. Loss: 1.0984: 100%|[36m██████████[0m| 26/26 [00:24<00:00,  1.22it/s]Epoch: 0/10. Loss: 1.0984: 100%|[36m██████████[0m| 26/26 [00:24<00:00,  1.07it/s]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:05,  1.10it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:05,  1.10s/it] 43%|[33m████▎     [0m| 3/7 [00:02<00:03,  1.07it/s] 57%|[33m█████▋    [0m| 4/7 [00:04<00:03,  1.13s/it] 71%|[33m███████▏  [0m| 5/7 [00:04<00:01,  1.15it/s] 86%|[33m████████▌ [0m| 6/7 [00:05<00:00,  1.15it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.50it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.20it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 1/10. Loss: 1.0967:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 1/10. Loss: 1.0967:   4%|[36m▍         [0m| 1/26 [00:00<00:20,  1.21it/s]Epoch: 1/10. Loss: 1.0665:   4%|[36m▍         [0m| 1/26 [00:02<00:20,  1.21it/s]Epoch: 1/10. Loss: 1.0665:   8%|[36m▊         [0m| 2/26 [00:02<00:27,  1.14s/it]Epoch: 1/10. Loss: 1.0553:   8%|[36m▊         [0m| 2/26 [00:03<00:27,  1.14s/it]Epoch: 1/10. Loss: 1.0553:  12%|[36m█▏        [0m| 3/26 [00:03<00:25,  1.12s/it]Epoch: 1/10. Loss: 1.0257:  12%|[36m█▏        [0m| 3/26 [00:04<00:25,  1.12s/it]Epoch: 1/10. Loss: 1.0257:  15%|[36m█▌        [0m| 4/26 [00:04<00:22,  1.04s/it]Epoch: 1/10. Loss: 1.0337:  15%|[36m█▌        [0m| 4/26 [00:04<00:22,  1.04s/it]Epoch: 1/10. Loss: 1.0337:  19%|[36m█▉        [0m| 5/26 [00:04<00:19,  1.09it/s]Epoch: 1/10. Loss: 1.0037:  19%|[36m█▉        [0m| 5/26 [00:05<00:19,  1.09it/s]Epoch: 1/10. Loss: 1.0037:  23%|[36m██▎       [0m| 6/26 [00:05<00:17,  1.12it/s]Epoch: 1/10. Loss: 1.0428:  23%|[36m██▎       [0m| 6/26 [00:06<00:17,  1.12it/s]Epoch: 1/10. Loss: 1.0428:  27%|[36m██▋       [0m| 7/26 [00:06<00:15,  1.20it/s]Epoch: 1/10. Loss: 1.0189:  27%|[36m██▋       [0m| 7/26 [00:07<00:15,  1.20it/s]Epoch: 1/10. Loss: 1.0189:  31%|[36m███       [0m| 8/26 [00:07<00:14,  1.26it/s]Epoch: 1/10. Loss: 0.9524:  31%|[36m███       [0m| 8/26 [00:08<00:14,  1.26it/s]Epoch: 1/10. Loss: 0.9524:  35%|[36m███▍      [0m| 9/26 [00:08<00:13,  1.22it/s]Epoch: 1/10. Loss: 1.0084:  35%|[36m███▍      [0m| 9/26 [00:09<00:13,  1.22it/s]Epoch: 1/10. Loss: 1.0084:  38%|[36m███▊      [0m| 10/26 [00:09<00:15,  1.06it/s]Epoch: 1/10. Loss: 0.9968:  38%|[36m███▊      [0m| 10/26 [00:10<00:15,  1.06it/s]Epoch: 1/10. Loss: 0.9968:  42%|[36m████▏     [0m| 11/26 [00:10<00:13,  1.13it/s]Epoch: 1/10. Loss: 1.0679:  42%|[36m████▏     [0m| 11/26 [00:11<00:13,  1.13it/s]Epoch: 1/10. Loss: 1.0679:  46%|[36m████▌     [0m| 12/26 [00:11<00:12,  1.09it/s]Epoch: 1/10. Loss: 1.0190:  46%|[36m████▌     [0m| 12/26 [00:11<00:12,  1.09it/s]Epoch: 1/10. Loss: 1.0190:  50%|[36m█████     [0m| 13/26 [00:11<00:11,  1.11it/s]Epoch: 1/10. Loss: 1.0416:  50%|[36m█████     [0m| 13/26 [00:12<00:11,  1.11it/s]Epoch: 1/10. Loss: 1.0416:  54%|[36m█████▍    [0m| 14/26 [00:12<00:10,  1.10it/s]Epoch: 1/10. Loss: 0.9711:  54%|[36m█████▍    [0m| 14/26 [00:13<00:10,  1.10it/s]Epoch: 1/10. Loss: 0.9711:  58%|[36m█████▊    [0m| 15/26 [00:13<00:09,  1.12it/s]Epoch: 1/10. Loss: 1.1216:  58%|[36m█████▊    [0m| 15/26 [00:14<00:09,  1.12it/s]Epoch: 1/10. Loss: 1.1216:  62%|[36m██████▏   [0m| 16/26 [00:14<00:08,  1.14it/s]Epoch: 1/10. Loss: 1.0993:  62%|[36m██████▏   [0m| 16/26 [00:15<00:08,  1.14it/s]Epoch: 1/10. Loss: 1.0993:  65%|[36m██████▌   [0m| 17/26 [00:15<00:08,  1.11it/s]Epoch: 1/10. Loss: 1.0546:  65%|[36m██████▌   [0m| 17/26 [00:16<00:08,  1.11it/s]Epoch: 1/10. Loss: 1.0546:  69%|[36m██████▉   [0m| 18/26 [00:16<00:08,  1.00s/it]Epoch: 1/10. Loss: 0.9944:  69%|[36m██████▉   [0m| 18/26 [00:17<00:08,  1.00s/it]Epoch: 1/10. Loss: 0.9944:  73%|[36m███████▎  [0m| 19/26 [00:17<00:06,  1.07it/s]Epoch: 1/10. Loss: 0.9969:  73%|[36m███████▎  [0m| 19/26 [00:18<00:06,  1.07it/s]Epoch: 1/10. Loss: 0.9969:  77%|[36m███████▋  [0m| 20/26 [00:18<00:05,  1.14it/s]Epoch: 1/10. Loss: 1.0364:  77%|[36m███████▋  [0m| 20/26 [00:20<00:05,  1.14it/s]Epoch: 1/10. Loss: 1.0364:  81%|[36m████████  [0m| 21/26 [00:20<00:05,  1.16s/it]Epoch: 1/10. Loss: 1.0193:  81%|[36m████████  [0m| 21/26 [00:20<00:05,  1.16s/it]Epoch: 1/10. Loss: 1.0193:  85%|[36m████████▍ [0m| 22/26 [00:20<00:04,  1.10s/it]Epoch: 1/10. Loss: 1.0224:  85%|[36m████████▍ [0m| 22/26 [00:21<00:04,  1.10s/it]Epoch: 1/10. Loss: 1.0224:  88%|[36m████████▊ [0m| 23/26 [00:21<00:02,  1.01it/s]Epoch: 1/10. Loss: 1.0104:  88%|[36m████████▊ [0m| 23/26 [00:22<00:02,  1.01it/s]Epoch: 1/10. Loss: 1.0104:  92%|[36m█████████▏[0m| 24/26 [00:22<00:01,  1.01it/s]Epoch: 1/10. Loss: 1.0161:  92%|[36m█████████▏[0m| 24/26 [00:23<00:01,  1.01it/s]Epoch: 1/10. Loss: 1.0161:  96%|[36m█████████▌[0m| 25/26 [00:23<00:01,  1.02s/it]Epoch: 1/10. Loss: 1.0061:  96%|[36m█████████▌[0m| 25/26 [00:25<00:01,  1.02s/it]Epoch: 1/10. Loss: 1.0061: 100%|[36m██████████[0m| 26/26 [00:25<00:00,  1.16s/it]Epoch: 1/10. Loss: 1.0061: 100%|[36m██████████[0m| 26/26 [00:25<00:00,  1.03it/s]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:01<00:06,  1.01s/it] 29%|[33m██▊       [0m| 2/7 [00:02<00:05,  1.13s/it] 43%|[33m████▎     [0m| 3/7 [00:02<00:03,  1.05it/s] 57%|[33m█████▋    [0m| 4/7 [00:04<00:03,  1.12s/it] 71%|[33m███████▏  [0m| 5/7 [00:04<00:01,  1.15it/s] 86%|[33m████████▌ [0m| 6/7 [00:05<00:00,  1.08it/s]100%|[33m██████████[0m| 7/7 [00:06<00:00,  1.42it/s]100%|[33m██████████[0m| 7/7 [00:06<00:00,  1.16it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 2/10. Loss: 1.0008:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 2/10. Loss: 1.0008:   4%|[36m▍         [0m| 1/26 [00:00<00:23,  1.06it/s]Epoch: 2/10. Loss: 1.0166:   4%|[36m▍         [0m| 1/26 [00:03<00:23,  1.06it/s]Epoch: 2/10. Loss: 1.0166:   8%|[36m▊         [0m| 2/26 [00:03<00:43,  1.80s/it]Epoch: 2/10. Loss: 1.0401:   8%|[36m▊         [0m| 2/26 [00:04<00:43,  1.80s/it]Epoch: 2/10. Loss: 1.0401:  12%|[36m█▏        [0m| 3/26 [00:04<00:33,  1.46s/it]Epoch: 2/10. Loss: 1.0413:  12%|[36m█▏        [0m| 3/26 [00:05<00:33,  1.46s/it]Epoch: 2/10. Loss: 1.0413:  15%|[36m█▌        [0m| 4/26 [00:05<00:32,  1.46s/it]Epoch: 2/10. Loss: 0.9786:  15%|[36m█▌        [0m| 4/26 [00:06<00:32,  1.46s/it]Epoch: 2/10. Loss: 0.9786:  19%|[36m█▉        [0m| 5/26 [00:06<00:26,  1.24s/it]Epoch: 2/10. Loss: 1.0184:  19%|[36m█▉        [0m| 5/26 [00:07<00:26,  1.24s/it]Epoch: 2/10. Loss: 1.0184:  23%|[36m██▎       [0m| 6/26 [00:07<00:22,  1.12s/it]Epoch: 2/10. Loss: 0.9936:  23%|[36m██▎       [0m| 6/26 [00:08<00:22,  1.12s/it]Epoch: 2/10. Loss: 0.9936:  27%|[36m██▋       [0m| 7/26 [00:08<00:20,  1.07s/it]Epoch: 2/10. Loss: 1.0614:  27%|[36m██▋       [0m| 7/26 [00:10<00:20,  1.07s/it]Epoch: 2/10. Loss: 1.0614:  31%|[36m███       [0m| 8/26 [00:10<00:21,  1.21s/it]Epoch: 2/10. Loss: 0.9655:  31%|[36m███       [0m| 8/26 [00:10<00:21,  1.21s/it]Epoch: 2/10. Loss: 0.9655:  35%|[36m███▍      [0m| 9/26 [00:10<00:18,  1.08s/it]Epoch: 2/10. Loss: 1.0329:  35%|[36m███▍      [0m| 9/26 [00:11<00:18,  1.08s/it]Epoch: 2/10. Loss: 1.0329:  38%|[36m███▊      [0m| 10/26 [00:11<00:16,  1.01s/it]Epoch: 2/10. Loss: 1.0393:  38%|[36m███▊      [0m| 10/26 [00:12<00:16,  1.01s/it]Epoch: 2/10. Loss: 1.0393:  42%|[36m████▏     [0m| 11/26 [00:12<00:14,  1.03it/s]Epoch: 2/10. Loss: 1.0491:  42%|[36m████▏     [0m| 11/26 [00:13<00:14,  1.03it/s]Epoch: 2/10. Loss: 1.0491:  46%|[36m████▌     [0m| 12/26 [00:13<00:12,  1.12it/s]Epoch: 2/10. Loss: 0.9765:  46%|[36m████▌     [0m| 12/26 [00:14<00:12,  1.12it/s]Epoch: 2/10. Loss: 0.9765:  50%|[36m█████     [0m| 13/26 [00:14<00:11,  1.17it/s]Epoch: 2/10. Loss: 1.0305:  50%|[36m█████     [0m| 13/26 [00:14<00:11,  1.17it/s]Epoch: 2/10. Loss: 1.0305:  54%|[36m█████▍    [0m| 14/26 [00:14<00:10,  1.16it/s]Epoch: 2/10. Loss: 0.9873:  54%|[36m█████▍    [0m| 14/26 [00:15<00:10,  1.16it/s]Epoch: 2/10. Loss: 0.9873:  58%|[36m█████▊    [0m| 15/26 [00:15<00:09,  1.18it/s]Epoch: 2/10. Loss: 1.0354:  58%|[36m█████▊    [0m| 15/26 [00:16<00:09,  1.18it/s]Epoch: 2/10. Loss: 1.0354:  62%|[36m██████▏   [0m| 16/26 [00:16<00:09,  1.08it/s]Epoch: 2/10. Loss: 1.0176:  62%|[36m██████▏   [0m| 16/26 [00:17<00:09,  1.08it/s]Epoch: 2/10. Loss: 1.0176:  65%|[36m██████▌   [0m| 17/26 [00:17<00:08,  1.02it/s]Epoch: 2/10. Loss: 1.0253:  65%|[36m██████▌   [0m| 17/26 [00:18<00:08,  1.02it/s]Epoch: 2/10. Loss: 1.0253:  69%|[36m██████▉   [0m| 18/26 [00:18<00:07,  1.04it/s]Epoch: 2/10. Loss: 1.0618:  69%|[36m██████▉   [0m| 18/26 [00:19<00:07,  1.04it/s]Epoch: 2/10. Loss: 1.0618:  73%|[36m███████▎  [0m| 19/26 [00:19<00:06,  1.07it/s]Epoch: 2/10. Loss: 0.9826:  73%|[36m███████▎  [0m| 19/26 [00:20<00:06,  1.07it/s]Epoch: 2/10. Loss: 0.9826:  77%|[36m███████▋  [0m| 20/26 [00:20<00:05,  1.11it/s]Epoch: 2/10. Loss: 0.9854:  77%|[36m███████▋  [0m| 20/26 [00:21<00:05,  1.11it/s]Epoch: 2/10. Loss: 0.9854:  81%|[36m████████  [0m| 21/26 [00:21<00:04,  1.04it/s]Epoch: 2/10. Loss: 0.9924:  81%|[36m████████  [0m| 21/26 [00:22<00:04,  1.04it/s]Epoch: 2/10. Loss: 0.9924:  85%|[36m████████▍ [0m| 22/26 [00:22<00:03,  1.08it/s]Epoch: 2/10. Loss: 1.0160:  85%|[36m████████▍ [0m| 22/26 [00:23<00:03,  1.08it/s]Epoch: 2/10. Loss: 1.0160:  88%|[36m████████▊ [0m| 23/26 [00:23<00:02,  1.07it/s]Epoch: 2/10. Loss: 1.0323:  88%|[36m████████▊ [0m| 23/26 [00:24<00:02,  1.07it/s]Epoch: 2/10. Loss: 1.0323:  92%|[36m█████████▏[0m| 24/26 [00:24<00:01,  1.10it/s]Epoch: 2/10. Loss: 1.0169:  92%|[36m█████████▏[0m| 24/26 [00:25<00:01,  1.10it/s]Epoch: 2/10. Loss: 1.0169:  96%|[36m█████████▌[0m| 25/26 [00:25<00:00,  1.18it/s]Epoch: 2/10. Loss: 1.0116:  96%|[36m█████████▌[0m| 25/26 [00:25<00:00,  1.18it/s]Epoch: 2/10. Loss: 1.0116: 100%|[36m██████████[0m| 26/26 [00:25<00:00,  1.35it/s]Epoch: 2/10. Loss: 1.0116: 100%|[36m██████████[0m| 26/26 [00:25<00:00,  1.02it/s]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:05,  1.06it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:05,  1.12s/it] 43%|[33m████▎     [0m| 3/7 [00:03<00:03,  1.01it/s] 57%|[33m█████▋    [0m| 4/7 [00:04<00:03,  1.16s/it] 71%|[33m███████▏  [0m| 5/7 [00:04<00:01,  1.12it/s] 86%|[33m████████▌ [0m| 6/7 [00:05<00:00,  1.16it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.54it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.19it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 3/10. Loss: 0.9896:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 3/10. Loss: 0.9896:   4%|[36m▍         [0m| 1/26 [00:00<00:20,  1.22it/s]Epoch: 3/10. Loss: 1.0524:   4%|[36m▍         [0m| 1/26 [00:01<00:20,  1.22it/s]Epoch: 3/10. Loss: 1.0524:   8%|[36m▊         [0m| 2/26 [00:01<00:20,  1.16it/s]Epoch: 3/10. Loss: 0.9947:   8%|[36m▊         [0m| 2/26 [00:02<00:20,  1.16it/s]Epoch: 3/10. Loss: 0.9947:  12%|[36m█▏        [0m| 3/26 [00:02<00:19,  1.17it/s]Epoch: 3/10. Loss: 1.0013:  12%|[36m█▏        [0m| 3/26 [00:03<00:19,  1.17it/s]Epoch: 3/10. Loss: 1.0013:  15%|[36m█▌        [0m| 4/26 [00:03<00:17,  1.26it/s]Epoch: 3/10. Loss: 0.9665:  15%|[36m█▌        [0m| 4/26 [00:04<00:17,  1.26it/s]Epoch: 3/10. Loss: 0.9665:  19%|[36m█▉        [0m| 5/26 [00:04<00:18,  1.14it/s]Epoch: 3/10. Loss: 0.9620:  19%|[36m█▉        [0m| 5/26 [00:05<00:18,  1.14it/s]Epoch: 3/10. Loss: 0.9620:  23%|[36m██▎       [0m| 6/26 [00:05<00:17,  1.17it/s]Epoch: 3/10. Loss: 1.0210:  23%|[36m██▎       [0m| 6/26 [00:06<00:17,  1.17it/s]Epoch: 3/10. Loss: 1.0210:  27%|[36m██▋       [0m| 7/26 [00:06<00:16,  1.13it/s]Epoch: 3/10. Loss: 1.0437:  27%|[36m██▋       [0m| 7/26 [00:06<00:16,  1.13it/s]Epoch: 3/10. Loss: 1.0437:  31%|[36m███       [0m| 8/26 [00:06<00:16,  1.11it/s]Epoch: 3/10. Loss: 1.0359:  31%|[36m███       [0m| 8/26 [00:07<00:16,  1.11it/s]Epoch: 3/10. Loss: 1.0359:  35%|[36m███▍      [0m| 9/26 [00:07<00:15,  1.11it/s]Epoch: 3/10. Loss: 1.0503:  35%|[36m███▍      [0m| 9/26 [00:08<00:15,  1.11it/s]Epoch: 3/10. Loss: 1.0503:  38%|[36m███▊      [0m| 10/26 [00:08<00:13,  1.16it/s]Epoch: 3/10. Loss: 1.0721:  38%|[36m███▊      [0m| 10/26 [00:09<00:13,  1.16it/s]Epoch: 3/10. Loss: 1.0721:  42%|[36m████▏     [0m| 11/26 [00:09<00:13,  1.08it/s]Epoch: 3/10. Loss: 0.9739:  42%|[36m████▏     [0m| 11/26 [00:10<00:13,  1.08it/s]Epoch: 3/10. Loss: 0.9739:  46%|[36m████▌     [0m| 12/26 [00:10<00:13,  1.03it/s]Epoch: 3/10. Loss: 1.0508:  46%|[36m████▌     [0m| 12/26 [00:11<00:13,  1.03it/s]Epoch: 3/10. Loss: 1.0508:  50%|[36m█████     [0m| 13/26 [00:11<00:11,  1.11it/s]Epoch: 3/10. Loss: 1.0139:  50%|[36m█████     [0m| 13/26 [00:12<00:11,  1.11it/s]Epoch: 3/10. Loss: 1.0139:  54%|[36m█████▍    [0m| 14/26 [00:12<00:10,  1.19it/s]Epoch: 3/10. Loss: 1.0195:  54%|[36m█████▍    [0m| 14/26 [00:13<00:10,  1.19it/s]Epoch: 3/10. Loss: 1.0195:  58%|[36m█████▊    [0m| 15/26 [00:13<00:09,  1.20it/s]Epoch: 3/10. Loss: 0.9859:  58%|[36m█████▊    [0m| 15/26 [00:13<00:09,  1.20it/s]Epoch: 3/10. Loss: 0.9859:  62%|[36m██████▏   [0m| 16/26 [00:13<00:08,  1.21it/s]Epoch: 3/10. Loss: 1.0431:  62%|[36m██████▏   [0m| 16/26 [00:14<00:08,  1.21it/s]Epoch: 3/10. Loss: 1.0431:  65%|[36m██████▌   [0m| 17/26 [00:14<00:07,  1.23it/s]Epoch: 3/10. Loss: 1.0480:  65%|[36m██████▌   [0m| 17/26 [00:15<00:07,  1.23it/s]Epoch: 3/10. Loss: 1.0480:  69%|[36m██████▉   [0m| 18/26 [00:15<00:06,  1.18it/s]Epoch: 3/10. Loss: 1.0025:  69%|[36m██████▉   [0m| 18/26 [00:16<00:06,  1.18it/s]Epoch: 3/10. Loss: 1.0025:  73%|[36m███████▎  [0m| 19/26 [00:16<00:06,  1.07it/s]Epoch: 3/10. Loss: 1.0193:  73%|[36m███████▎  [0m| 19/26 [00:17<00:06,  1.07it/s]Epoch: 3/10. Loss: 1.0193:  77%|[36m███████▋  [0m| 20/26 [00:17<00:05,  1.10it/s]Epoch: 3/10. Loss: 1.0105:  77%|[36m███████▋  [0m| 20/26 [00:18<00:05,  1.10it/s]Epoch: 3/10. Loss: 1.0105:  81%|[36m████████  [0m| 21/26 [00:18<00:04,  1.11it/s]Epoch: 3/10. Loss: 1.0183:  81%|[36m████████  [0m| 21/26 [00:19<00:04,  1.11it/s]Epoch: 3/10. Loss: 1.0183:  85%|[36m████████▍ [0m| 22/26 [00:19<00:03,  1.11it/s]Epoch: 3/10. Loss: 0.9714:  85%|[36m████████▍ [0m| 22/26 [00:20<00:03,  1.11it/s]Epoch: 3/10. Loss: 0.9714:  88%|[36m████████▊ [0m| 23/26 [00:20<00:02,  1.13it/s]Epoch: 3/10. Loss: 1.0061:  88%|[36m████████▊ [0m| 23/26 [00:20<00:02,  1.13it/s]Epoch: 3/10. Loss: 1.0061:  92%|[36m█████████▏[0m| 24/26 [00:20<00:01,  1.17it/s]Epoch: 3/10. Loss: 1.0209:  92%|[36m█████████▏[0m| 24/26 [00:22<00:01,  1.17it/s]Epoch: 3/10. Loss: 1.0209:  96%|[36m█████████▌[0m| 25/26 [00:22<00:01,  1.07s/it]Epoch: 3/10. Loss: 1.0262:  96%|[36m█████████▌[0m| 25/26 [00:23<00:01,  1.07s/it]Epoch: 3/10. Loss: 1.0262: 100%|[36m██████████[0m| 26/26 [00:23<00:00,  1.12it/s]Epoch: 3/10. Loss: 1.0262: 100%|[36m██████████[0m| 26/26 [00:23<00:00,  1.13it/s]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:05,  1.03it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:05,  1.13s/it] 43%|[33m████▎     [0m| 3/7 [00:02<00:03,  1.04it/s] 57%|[33m█████▋    [0m| 4/7 [00:04<00:03,  1.12s/it] 71%|[33m███████▏  [0m| 5/7 [00:04<00:01,  1.15it/s] 86%|[33m████████▌ [0m| 6/7 [00:05<00:00,  1.18it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.55it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.21it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 4/10. Loss: 0.9892:   0%|[36m          [0m| 0/26 [00:01<?, ?it/s]Epoch: 4/10. Loss: 0.9892:   4%|[36m▍         [0m| 1/26 [00:01<00:26,  1.07s/it]Epoch: 4/10. Loss: 0.9844:   4%|[36m▍         [0m| 1/26 [00:02<00:26,  1.07s/it]Epoch: 4/10. Loss: 0.9844:   8%|[36m▊         [0m| 2/26 [00:02<00:24,  1.02s/it]Epoch: 4/10. Loss: 0.9776:   8%|[36m▊         [0m| 2/26 [00:02<00:24,  1.02s/it]Epoch: 4/10. Loss: 0.9776:  12%|[36m█▏        [0m| 3/26 [00:02<00:22,  1.04it/s]Epoch: 4/10. Loss: 1.0046:  12%|[36m█▏        [0m| 3/26 [00:03<00:22,  1.04it/s]Epoch: 4/10. Loss: 1.0046:  15%|[36m█▌        [0m| 4/26 [00:03<00:20,  1.10it/s]Epoch: 4/10. Loss: 1.1270:  15%|[36m█▌        [0m| 4/26 [00:04<00:20,  1.10it/s]Epoch: 4/10. Loss: 1.1270:  19%|[36m█▉        [0m| 5/26 [00:04<00:19,  1.09it/s]Epoch: 4/10. Loss: 1.0091:  19%|[36m█▉        [0m| 5/26 [00:05<00:19,  1.09it/s]Epoch: 4/10. Loss: 1.0091:  23%|[36m██▎       [0m| 6/26 [00:05<00:17,  1.11it/s]Epoch: 4/10. Loss: 1.0239:  23%|[36m██▎       [0m| 6/26 [00:06<00:17,  1.11it/s]Epoch: 4/10. Loss: 1.0239:  27%|[36m██▋       [0m| 7/26 [00:06<00:16,  1.13it/s]Epoch: 4/10. Loss: 0.9630:  27%|[36m██▋       [0m| 7/26 [00:07<00:16,  1.13it/s]Epoch: 4/10. Loss: 0.9630:  31%|[36m███       [0m| 8/26 [00:07<00:17,  1.00it/s]Epoch: 4/10. Loss: 1.0311:  31%|[36m███       [0m| 8/26 [00:08<00:17,  1.00it/s]Epoch: 4/10. Loss: 1.0311:  35%|[36m███▍      [0m| 9/26 [00:08<00:16,  1.03it/s]Epoch: 4/10. Loss: 1.0535:  35%|[36m███▍      [0m| 9/26 [00:09<00:16,  1.03it/s]Epoch: 4/10. Loss: 1.0535:  38%|[36m███▊      [0m| 10/26 [00:09<00:15,  1.07it/s]Epoch: 4/10. Loss: 1.0110:  38%|[36m███▊      [0m| 10/26 [00:10<00:15,  1.07it/s]Epoch: 4/10. Loss: 1.0110:  42%|[36m████▏     [0m| 11/26 [00:10<00:13,  1.14it/s]Epoch: 4/10. Loss: 1.0201:  42%|[36m████▏     [0m| 11/26 [00:10<00:13,  1.14it/s]Epoch: 4/10. Loss: 1.0201:  46%|[36m████▌     [0m| 12/26 [00:10<00:11,  1.20it/s]Epoch: 4/10. Loss: 1.0211:  46%|[36m████▌     [0m| 12/26 [00:12<00:11,  1.20it/s]Epoch: 4/10. Loss: 1.0211:  50%|[36m█████     [0m| 13/26 [00:12<00:14,  1.10s/it]Epoch: 4/10. Loss: 0.9339:  50%|[36m█████     [0m| 13/26 [00:13<00:14,  1.10s/it]Epoch: 4/10. Loss: 0.9339:  54%|[36m█████▍    [0m| 14/26 [00:13<00:11,  1.01it/s]Epoch: 4/10. Loss: 0.9674:  54%|[36m█████▍    [0m| 14/26 [00:14<00:11,  1.01it/s]Epoch: 4/10. Loss: 0.9674:  58%|[36m█████▊    [0m| 15/26 [00:14<00:10,  1.00it/s]Epoch: 4/10. Loss: 1.0238:  58%|[36m█████▊    [0m| 15/26 [00:15<00:10,  1.00it/s]Epoch: 4/10. Loss: 1.0238:  62%|[36m██████▏   [0m| 16/26 [00:15<00:09,  1.09it/s]Epoch: 4/10. Loss: 1.0996:  62%|[36m██████▏   [0m| 16/26 [00:17<00:09,  1.09it/s]Epoch: 4/10. Loss: 1.0996:  65%|[36m██████▌   [0m| 17/26 [00:17<00:11,  1.28s/it]Epoch: 4/10. Loss: 1.0449:  65%|[36m██████▌   [0m| 17/26 [00:17<00:11,  1.28s/it]Epoch: 4/10. Loss: 1.0449:  69%|[36m██████▉   [0m| 18/26 [00:17<00:08,  1.12s/it]Epoch: 4/10. Loss: 0.9832:  69%|[36m██████▉   [0m| 18/26 [00:18<00:08,  1.12s/it]Epoch: 4/10. Loss: 0.9832:  73%|[36m███████▎  [0m| 19/26 [00:18<00:07,  1.08s/it]Epoch: 4/10. Loss: 1.0118:  73%|[36m███████▎  [0m| 19/26 [00:19<00:07,  1.08s/it]Epoch: 4/10. Loss: 1.0118:  77%|[36m███████▋  [0m| 20/26 [00:19<00:06,  1.02s/it]Epoch: 4/10. Loss: 1.0126:  77%|[36m███████▋  [0m| 20/26 [00:20<00:06,  1.02s/it]Epoch: 4/10. Loss: 1.0126:  81%|[36m████████  [0m| 21/26 [00:20<00:05,  1.04s/it]Epoch: 4/10. Loss: 0.9549:  81%|[36m████████  [0m| 21/26 [00:21<00:05,  1.04s/it]Epoch: 4/10. Loss: 0.9549:  85%|[36m████████▍ [0m| 22/26 [00:21<00:03,  1.05it/s]Epoch: 4/10. Loss: 1.0567:  85%|[36m████████▍ [0m| 22/26 [00:22<00:03,  1.05it/s]Epoch: 4/10. Loss: 1.0567:  88%|[36m████████▊ [0m| 23/26 [00:22<00:02,  1.10it/s]Epoch: 4/10. Loss: 0.9709:  88%|[36m████████▊ [0m| 23/26 [00:23<00:02,  1.10it/s]Epoch: 4/10. Loss: 0.9709:  92%|[36m█████████▏[0m| 24/26 [00:23<00:01,  1.19it/s]Epoch: 4/10. Loss: 1.0291:  92%|[36m█████████▏[0m| 24/26 [00:24<00:01,  1.19it/s]Epoch: 4/10. Loss: 1.0291:  96%|[36m█████████▌[0m| 25/26 [00:24<00:00,  1.18it/s]Epoch: 4/10. Loss: 1.0749:  96%|[36m█████████▌[0m| 25/26 [00:24<00:00,  1.18it/s]Epoch: 4/10. Loss: 1.0749: 100%|[36m██████████[0m| 26/26 [00:24<00:00,  1.21it/s]Epoch: 4/10. Loss: 1.0749: 100%|[36m██████████[0m| 26/26 [00:24<00:00,  1.05it/s]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:05,  1.03it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:05,  1.13s/it] 43%|[33m████▎     [0m| 3/7 [00:02<00:03,  1.05it/s] 57%|[33m█████▋    [0m| 4/7 [00:04<00:03,  1.09s/it] 71%|[33m███████▏  [0m| 5/7 [00:04<00:01,  1.21it/s] 86%|[33m████████▌ [0m| 6/7 [00:05<00:00,  1.26it/s]100%|[33m██████████[0m| 7/7 [00:06<00:00,  1.12it/s]100%|[33m██████████[0m| 7/7 [00:06<00:00,  1.09it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 5/10. Loss: 1.0001:   0%|[36m          [0m| 0/26 [00:01<?, ?it/s]Epoch: 5/10. Loss: 1.0001:   4%|[36m▍         [0m| 1/26 [00:01<00:25,  1.02s/it]Epoch: 5/10. Loss: 1.0166:   4%|[36m▍         [0m| 1/26 [00:01<00:25,  1.02s/it]Epoch: 5/10. Loss: 1.0166:   8%|[36m▊         [0m| 2/26 [00:01<00:20,  1.15it/s]Epoch: 5/10. Loss: 1.0252:   8%|[36m▊         [0m| 2/26 [00:02<00:20,  1.15it/s]Epoch: 5/10. Loss: 1.0252:  12%|[36m█▏        [0m| 3/26 [00:02<00:20,  1.13it/s]Epoch: 5/10. Loss: 0.9827:  12%|[36m█▏        [0m| 3/26 [00:03<00:20,  1.13it/s]Epoch: 5/10. Loss: 0.9827:  15%|[36m█▌        [0m| 4/26 [00:03<00:20,  1.09it/s]Epoch: 5/10. Loss: 1.0046:  15%|[36m█▌        [0m| 4/26 [00:04<00:20,  1.09it/s]Epoch: 5/10. Loss: 1.0046:  19%|[36m█▉        [0m| 5/26 [00:04<00:18,  1.13it/s]Epoch: 5/10. Loss: 1.0134:  19%|[36m█▉        [0m| 5/26 [00:05<00:18,  1.13it/s]Epoch: 5/10. Loss: 1.0134:  23%|[36m██▎       [0m| 6/26 [00:05<00:21,  1.09s/it]Epoch: 5/10. Loss: 1.0180:  23%|[36m██▎       [0m| 6/26 [00:06<00:21,  1.09s/it]Epoch: 5/10. Loss: 1.0180:  27%|[36m██▋       [0m| 7/26 [00:06<00:19,  1.01s/it]Epoch: 5/10. Loss: 1.0108:  27%|[36m██▋       [0m| 7/26 [00:07<00:19,  1.01s/it]Epoch: 5/10. Loss: 1.0108:  31%|[36m███       [0m| 8/26 [00:07<00:17,  1.02it/s]Epoch: 5/10. Loss: 1.0465:  31%|[36m███       [0m| 8/26 [00:08<00:17,  1.02it/s]Epoch: 5/10. Loss: 1.0465:  35%|[36m███▍      [0m| 9/26 [00:08<00:16,  1.05it/s]Epoch: 5/10. Loss: 1.0311:  35%|[36m███▍      [0m| 9/26 [00:09<00:16,  1.05it/s]Epoch: 5/10. Loss: 1.0311:  38%|[36m███▊      [0m| 10/26 [00:09<00:14,  1.09it/s]Epoch: 5/10. Loss: 1.0210:  38%|[36m███▊      [0m| 10/26 [00:10<00:14,  1.09it/s]Epoch: 5/10. Loss: 1.0210:  42%|[36m████▏     [0m| 11/26 [00:10<00:14,  1.07it/s]Epoch: 5/10. Loss: 1.0162:  42%|[36m████▏     [0m| 11/26 [00:11<00:14,  1.07it/s]Epoch: 5/10. Loss: 1.0162:  46%|[36m████▌     [0m| 12/26 [00:11<00:13,  1.07it/s]Epoch: 5/10. Loss: 1.0328:  46%|[36m████▌     [0m| 12/26 [00:12<00:13,  1.07it/s]Epoch: 5/10. Loss: 1.0328:  50%|[36m█████     [0m| 13/26 [00:12<00:13,  1.01s/it]Epoch: 5/10. Loss: 1.0455:  50%|[36m█████     [0m| 13/26 [00:13<00:13,  1.01s/it]Epoch: 5/10. Loss: 1.0455:  54%|[36m█████▍    [0m| 14/26 [00:13<00:11,  1.02it/s]Epoch: 5/10. Loss: 1.0167:  54%|[36m█████▍    [0m| 14/26 [00:14<00:11,  1.02it/s]Epoch: 5/10. Loss: 1.0167:  58%|[36m█████▊    [0m| 15/26 [00:14<00:09,  1.10it/s]Epoch: 5/10. Loss: 1.0300:  58%|[36m█████▊    [0m| 15/26 [00:14<00:09,  1.10it/s]Epoch: 5/10. Loss: 1.0300:  62%|[36m██████▏   [0m| 16/26 [00:14<00:08,  1.17it/s]Epoch: 5/10. Loss: 1.0722:  62%|[36m██████▏   [0m| 16/26 [00:15<00:08,  1.17it/s]Epoch: 5/10. Loss: 1.0722:  65%|[36m██████▌   [0m| 17/26 [00:15<00:07,  1.14it/s]Epoch: 5/10. Loss: 1.0043:  65%|[36m██████▌   [0m| 17/26 [00:16<00:07,  1.14it/s]Epoch: 5/10. Loss: 1.0043:  69%|[36m██████▉   [0m| 18/26 [00:16<00:06,  1.22it/s]Epoch: 5/10. Loss: 1.0053:  69%|[36m██████▉   [0m| 18/26 [00:17<00:06,  1.22it/s]Epoch: 5/10. Loss: 1.0053:  73%|[36m███████▎  [0m| 19/26 [00:17<00:06,  1.16it/s]Epoch: 5/10. Loss: 1.0251:  73%|[36m███████▎  [0m| 19/26 [00:18<00:06,  1.16it/s]Epoch: 5/10. Loss: 1.0251:  77%|[36m███████▋  [0m| 20/26 [00:18<00:05,  1.04it/s]Epoch: 5/10. Loss: 1.0343:  77%|[36m███████▋  [0m| 20/26 [00:19<00:05,  1.04it/s]Epoch: 5/10. Loss: 1.0343:  81%|[36m████████  [0m| 21/26 [00:19<00:04,  1.08it/s]Epoch: 5/10. Loss: 0.9792:  81%|[36m████████  [0m| 21/26 [00:20<00:04,  1.08it/s]Epoch: 5/10. Loss: 0.9792:  85%|[36m████████▍ [0m| 22/26 [00:20<00:03,  1.11it/s]Epoch: 5/10. Loss: 0.9977:  85%|[36m████████▍ [0m| 22/26 [00:21<00:03,  1.11it/s]Epoch: 5/10. Loss: 0.9977:  88%|[36m████████▊ [0m| 23/26 [00:21<00:02,  1.14it/s]Epoch: 5/10. Loss: 0.9998:  88%|[36m████████▊ [0m| 23/26 [00:22<00:02,  1.14it/s]Epoch: 5/10. Loss: 0.9998:  92%|[36m█████████▏[0m| 24/26 [00:22<00:01,  1.11it/s]Epoch: 5/10. Loss: 0.9651:  92%|[36m█████████▏[0m| 24/26 [00:24<00:01,  1.11it/s]Epoch: 5/10. Loss: 0.9651:  96%|[36m█████████▌[0m| 25/26 [00:24<00:01,  1.35s/it]Epoch: 5/10. Loss: 0.9695:  96%|[36m█████████▌[0m| 25/26 [00:25<00:01,  1.35s/it]Epoch: 5/10. Loss: 0.9695: 100%|[36m██████████[0m| 26/26 [00:25<00:00,  1.16s/it]Epoch: 5/10. Loss: 0.9695: 100%|[36m██████████[0m| 26/26 [00:25<00:00,  1.03it/s]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:05,  1.06it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:05,  1.12s/it] 43%|[33m████▎     [0m| 3/7 [00:03<00:04,  1.05s/it] 57%|[33m█████▋    [0m| 4/7 [00:04<00:03,  1.22s/it] 71%|[33m███████▏  [0m| 5/7 [00:04<00:01,  1.10it/s] 86%|[33m████████▌ [0m| 6/7 [00:05<00:00,  1.18it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.55it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.18it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 6/10. Loss: 1.0005:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 6/10. Loss: 1.0005:   4%|[36m▍         [0m| 1/26 [00:00<00:21,  1.15it/s]Epoch: 6/10. Loss: 1.0281:   4%|[36m▍         [0m| 1/26 [00:01<00:21,  1.15it/s]Epoch: 6/10. Loss: 1.0281:   8%|[36m▊         [0m| 2/26 [00:01<00:21,  1.14it/s]Epoch: 6/10. Loss: 1.0360:   8%|[36m▊         [0m| 2/26 [00:02<00:21,  1.14it/s]Epoch: 6/10. Loss: 1.0360:  12%|[36m█▏        [0m| 3/26 [00:02<00:19,  1.16it/s]Epoch: 6/10. Loss: 1.0079:  12%|[36m█▏        [0m| 3/26 [00:03<00:19,  1.16it/s]Epoch: 6/10. Loss: 1.0079:  15%|[36m█▌        [0m| 4/26 [00:03<00:19,  1.10it/s]Epoch: 6/10. Loss: 1.0215:  15%|[36m█▌        [0m| 4/26 [00:04<00:19,  1.10it/s]Epoch: 6/10. Loss: 1.0215:  19%|[36m█▉        [0m| 5/26 [00:04<00:18,  1.13it/s]Epoch: 6/10. Loss: 0.9746:  19%|[36m█▉        [0m| 5/26 [00:05<00:18,  1.13it/s]Epoch: 6/10. Loss: 0.9746:  23%|[36m██▎       [0m| 6/26 [00:05<00:17,  1.15it/s]Epoch: 6/10. Loss: 1.0159:  23%|[36m██▎       [0m| 6/26 [00:06<00:17,  1.15it/s]Epoch: 6/10. Loss: 1.0159:  27%|[36m██▋       [0m| 7/26 [00:06<00:17,  1.10it/s]Epoch: 6/10. Loss: 1.0137:  27%|[36m██▋       [0m| 7/26 [00:07<00:17,  1.10it/s]Epoch: 6/10. Loss: 1.0137:  31%|[36m███       [0m| 8/26 [00:07<00:16,  1.10it/s]Epoch: 6/10. Loss: 1.0134:  31%|[36m███       [0m| 8/26 [00:09<00:16,  1.10it/s]Epoch: 6/10. Loss: 1.0134:  35%|[36m███▍      [0m| 9/26 [00:09<00:22,  1.31s/it]Epoch: 6/10. Loss: 0.9862:  35%|[36m███▍      [0m| 9/26 [00:10<00:22,  1.31s/it]Epoch: 6/10. Loss: 0.9862:  38%|[36m███▊      [0m| 10/26 [00:10<00:20,  1.25s/it]Epoch: 6/10. Loss: 1.0511:  38%|[36m███▊      [0m| 10/26 [00:11<00:20,  1.25s/it]Epoch: 6/10. Loss: 1.0511:  42%|[36m████▏     [0m| 11/26 [00:11<00:16,  1.08s/it]Epoch: 6/10. Loss: 1.0284:  42%|[36m████▏     [0m| 11/26 [00:12<00:16,  1.08s/it]Epoch: 6/10. Loss: 1.0284:  46%|[36m████▌     [0m| 12/26 [00:12<00:14,  1.03s/it]Epoch: 6/10. Loss: 1.0367:  46%|[36m████▌     [0m| 12/26 [00:12<00:14,  1.03s/it]Epoch: 6/10. Loss: 1.0367:  50%|[36m█████     [0m| 13/26 [00:12<00:12,  1.02it/s]Epoch: 6/10. Loss: 1.0281:  50%|[36m█████     [0m| 13/26 [00:13<00:12,  1.02it/s]Epoch: 6/10. Loss: 1.0281:  54%|[36m█████▍    [0m| 14/26 [00:13<00:11,  1.07it/s]Epoch: 6/10. Loss: 1.0088:  54%|[36m█████▍    [0m| 14/26 [00:14<00:11,  1.07it/s]Epoch: 6/10. Loss: 1.0088:  58%|[36m█████▊    [0m| 15/26 [00:14<00:10,  1.02it/s]Epoch: 6/10. Loss: 1.0838:  58%|[36m█████▊    [0m| 15/26 [00:15<00:10,  1.02it/s]Epoch: 6/10. Loss: 1.0838:  62%|[36m██████▏   [0m| 16/26 [00:15<00:09,  1.06it/s]Epoch: 6/10. Loss: 1.0249:  62%|[36m██████▏   [0m| 16/26 [00:17<00:09,  1.06it/s]Epoch: 6/10. Loss: 1.0249:  65%|[36m██████▌   [0m| 17/26 [00:17<00:11,  1.28s/it]Epoch: 6/10. Loss: 1.0868:  65%|[36m██████▌   [0m| 17/26 [00:18<00:11,  1.28s/it]Epoch: 6/10. Loss: 1.0868:  69%|[36m██████▉   [0m| 18/26 [00:18<00:09,  1.20s/it]Epoch: 6/10. Loss: 1.0316:  69%|[36m██████▉   [0m| 18/26 [00:19<00:09,  1.20s/it]Epoch: 6/10. Loss: 1.0316:  73%|[36m███████▎  [0m| 19/26 [00:19<00:07,  1.09s/it]Epoch: 6/10. Loss: 1.0048:  73%|[36m███████▎  [0m| 19/26 [00:20<00:07,  1.09s/it]Epoch: 6/10. Loss: 1.0048:  77%|[36m███████▋  [0m| 20/26 [00:20<00:06,  1.01s/it]Epoch: 6/10. Loss: 1.0319:  77%|[36m███████▋  [0m| 20/26 [00:21<00:06,  1.01s/it]Epoch: 6/10. Loss: 1.0319:  81%|[36m████████  [0m| 21/26 [00:21<00:04,  1.06it/s]Epoch: 6/10. Loss: 1.0031:  81%|[36m████████  [0m| 21/26 [00:22<00:04,  1.06it/s]Epoch: 6/10. Loss: 1.0031:  85%|[36m████████▍ [0m| 22/26 [00:22<00:03,  1.10it/s]Epoch: 6/10. Loss: 0.9780:  85%|[36m████████▍ [0m| 22/26 [00:23<00:03,  1.10it/s]Epoch: 6/10. Loss: 0.9780:  88%|[36m████████▊ [0m| 23/26 [00:23<00:02,  1.04it/s]Epoch: 6/10. Loss: 0.9875:  88%|[36m████████▊ [0m| 23/26 [00:23<00:02,  1.04it/s]Epoch: 6/10. Loss: 0.9875:  92%|[36m█████████▏[0m| 24/26 [00:23<00:01,  1.11it/s]Epoch: 6/10. Loss: 0.9710:  92%|[36m█████████▏[0m| 24/26 [00:25<00:01,  1.11it/s]Epoch: 6/10. Loss: 0.9710:  96%|[36m█████████▌[0m| 25/26 [00:25<00:00,  1.03it/s]Epoch: 6/10. Loss: 0.9401:  96%|[36m█████████▌[0m| 25/26 [00:25<00:00,  1.03it/s]Epoch: 6/10. Loss: 0.9401: 100%|[36m██████████[0m| 26/26 [00:25<00:00,  1.19it/s]Epoch: 6/10. Loss: 0.9401: 100%|[36m██████████[0m| 26/26 [00:25<00:00,  1.02it/s]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:04,  1.20it/s] 29%|[33m██▊       [0m| 2/7 [00:03<00:10,  2.03s/it] 43%|[33m████▎     [0m| 3/7 [00:05<00:08,  2.06s/it] 57%|[33m█████▋    [0m| 4/7 [00:07<00:05,  1.75s/it] 71%|[33m███████▏  [0m| 5/7 [00:07<00:02,  1.24s/it] 86%|[33m████████▌ [0m| 6/7 [00:08<00:01,  1.07s/it]100%|[33m██████████[0m| 7/7 [00:08<00:00,  1.26it/s]100%|[33m██████████[0m| 7/7 [00:08<00:00,  1.20s/it]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 7/10. Loss: 1.0022:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 7/10. Loss: 1.0022:   4%|[36m▍         [0m| 1/26 [00:00<00:19,  1.25it/s]Epoch: 7/10. Loss: 1.0749:   4%|[36m▍         [0m| 1/26 [00:01<00:19,  1.25it/s]Epoch: 7/10. Loss: 1.0749:   8%|[36m▊         [0m| 2/26 [00:01<00:20,  1.19it/s]Epoch: 7/10. Loss: 1.0215:   8%|[36m▊         [0m| 2/26 [00:02<00:20,  1.19it/s]Epoch: 7/10. Loss: 1.0215:  12%|[36m█▏        [0m| 3/26 [00:02<00:19,  1.16it/s]Epoch: 7/10. Loss: 1.0043:  12%|[36m█▏        [0m| 3/26 [00:03<00:19,  1.16it/s]Epoch: 7/10. Loss: 1.0043:  15%|[36m█▌        [0m| 4/26 [00:03<00:18,  1.16it/s]Epoch: 7/10. Loss: 0.9518:  15%|[36m█▌        [0m| 4/26 [00:04<00:18,  1.16it/s]Epoch: 7/10. Loss: 0.9518:  19%|[36m█▉        [0m| 5/26 [00:04<00:21,  1.00s/it]Epoch: 7/10. Loss: 1.0046:  19%|[36m█▉        [0m| 5/26 [00:05<00:21,  1.00s/it]Epoch: 7/10. Loss: 1.0046:  23%|[36m██▎       [0m| 6/26 [00:05<00:18,  1.06it/s]Epoch: 7/10. Loss: 1.0118:  23%|[36m██▎       [0m| 6/26 [00:06<00:18,  1.06it/s]Epoch: 7/10. Loss: 1.0118:  27%|[36m██▋       [0m| 7/26 [00:06<00:18,  1.03it/s]Epoch: 7/10. Loss: 1.0067:  27%|[36m██▋       [0m| 7/26 [00:07<00:18,  1.03it/s]Epoch: 7/10. Loss: 1.0067:  31%|[36m███       [0m| 8/26 [00:07<00:16,  1.09it/s]Epoch: 7/10. Loss: 1.0293:  31%|[36m███       [0m| 8/26 [00:08<00:16,  1.09it/s]Epoch: 7/10. Loss: 1.0293:  35%|[36m███▍      [0m| 9/26 [00:08<00:15,  1.10it/s]Epoch: 7/10. Loss: 1.0301:  35%|[36m███▍      [0m| 9/26 [00:09<00:15,  1.10it/s]Epoch: 7/10. Loss: 1.0301:  38%|[36m███▊      [0m| 10/26 [00:09<00:16,  1.05s/it]Epoch: 7/10. Loss: 1.0502:  38%|[36m███▊      [0m| 10/26 [00:10<00:16,  1.05s/it]Epoch: 7/10. Loss: 1.0502:  42%|[36m████▏     [0m| 11/26 [00:10<00:16,  1.07s/it]Epoch: 7/10. Loss: 1.0211:  42%|[36m████▏     [0m| 11/26 [00:11<00:16,  1.07s/it]Epoch: 7/10. Loss: 1.0211:  46%|[36m████▌     [0m| 12/26 [00:11<00:15,  1.12s/it]Epoch: 7/10. Loss: 1.0239:  46%|[36m████▌     [0m| 12/26 [00:12<00:15,  1.12s/it]Epoch: 7/10. Loss: 1.0239:  50%|[36m█████     [0m| 13/26 [00:12<00:13,  1.02s/it]Epoch: 7/10. Loss: 1.0363:  50%|[36m█████     [0m| 13/26 [00:13<00:13,  1.02s/it]Epoch: 7/10. Loss: 1.0363:  54%|[36m█████▍    [0m| 14/26 [00:13<00:11,  1.02it/s]Epoch: 7/10. Loss: 1.0657:  54%|[36m█████▍    [0m| 14/26 [00:15<00:11,  1.02it/s]Epoch: 7/10. Loss: 1.0657:  58%|[36m█████▊    [0m| 15/26 [00:15<00:12,  1.10s/it]Epoch: 7/10. Loss: 1.0026:  58%|[36m█████▊    [0m| 15/26 [00:15<00:12,  1.10s/it]Epoch: 7/10. Loss: 1.0026:  62%|[36m██████▏   [0m| 16/26 [00:15<00:10,  1.06s/it]Epoch: 7/10. Loss: 0.9691:  62%|[36m██████▏   [0m| 16/26 [00:16<00:10,  1.06s/it]Epoch: 7/10. Loss: 0.9691:  65%|[36m██████▌   [0m| 17/26 [00:16<00:08,  1.01it/s]Epoch: 7/10. Loss: 0.9913:  65%|[36m██████▌   [0m| 17/26 [00:17<00:08,  1.01it/s]Epoch: 7/10. Loss: 0.9913:  69%|[36m██████▉   [0m| 18/26 [00:17<00:07,  1.03it/s]Epoch: 7/10. Loss: 1.0125:  69%|[36m██████▉   [0m| 18/26 [00:18<00:07,  1.03it/s]Epoch: 7/10. Loss: 1.0125:  73%|[36m███████▎  [0m| 19/26 [00:18<00:06,  1.11it/s]Epoch: 7/10. Loss: 0.9778:  73%|[36m███████▎  [0m| 19/26 [00:19<00:06,  1.11it/s]Epoch: 7/10. Loss: 0.9778:  77%|[36m███████▋  [0m| 20/26 [00:19<00:05,  1.06it/s]Epoch: 7/10. Loss: 1.0823:  77%|[36m███████▋  [0m| 20/26 [00:20<00:05,  1.06it/s]Epoch: 7/10. Loss: 1.0823:  81%|[36m████████  [0m| 21/26 [00:20<00:04,  1.05it/s]Epoch: 7/10. Loss: 0.9349:  81%|[36m████████  [0m| 21/26 [00:21<00:04,  1.05it/s]Epoch: 7/10. Loss: 0.9349:  85%|[36m████████▍ [0m| 22/26 [00:21<00:03,  1.06it/s]Epoch: 7/10. Loss: 1.0179:  85%|[36m████████▍ [0m| 22/26 [00:22<00:03,  1.06it/s]Epoch: 7/10. Loss: 1.0179:  88%|[36m████████▊ [0m| 23/26 [00:22<00:02,  1.09it/s]Epoch: 7/10. Loss: 1.0094:  88%|[36m████████▊ [0m| 23/26 [00:23<00:02,  1.09it/s]Epoch: 7/10. Loss: 1.0094:  92%|[36m█████████▏[0m| 24/26 [00:23<00:01,  1.09it/s]Epoch: 7/10. Loss: 0.9971:  92%|[36m█████████▏[0m| 24/26 [00:23<00:01,  1.09it/s]Epoch: 7/10. Loss: 0.9971:  96%|[36m█████████▌[0m| 25/26 [00:23<00:00,  1.13it/s]Epoch: 7/10. Loss: 1.0510:  96%|[36m█████████▌[0m| 25/26 [00:24<00:00,  1.13it/s]Epoch: 7/10. Loss: 1.0510: 100%|[36m██████████[0m| 26/26 [00:24<00:00,  1.23it/s]Epoch: 7/10. Loss: 1.0510: 100%|[36m██████████[0m| 26/26 [00:24<00:00,  1.06it/s]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:05,  1.15it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:05,  1.03s/it] 43%|[33m████▎     [0m| 3/7 [00:02<00:03,  1.15it/s] 57%|[33m█████▋    [0m| 4/7 [00:03<00:03,  1.04s/it] 71%|[33m███████▏  [0m| 5/7 [00:04<00:01,  1.26it/s] 86%|[33m████████▌ [0m| 6/7 [00:05<00:00,  1.30it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.68it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.32it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 8/10. Loss: 1.0375:   0%|[36m          [0m| 0/26 [00:02<?, ?it/s]Epoch: 8/10. Loss: 1.0375:   4%|[36m▍         [0m| 1/26 [00:02<01:00,  2.43s/it]Epoch: 8/10. Loss: 1.0739:   4%|[36m▍         [0m| 1/26 [00:05<01:00,  2.43s/it]Epoch: 8/10. Loss: 1.0739:   8%|[36m▊         [0m| 2/26 [00:05<01:13,  3.08s/it]Epoch: 8/10. Loss: 1.0057:   8%|[36m▊         [0m| 2/26 [00:06<01:13,  3.08s/it]Epoch: 8/10. Loss: 1.0057:  12%|[36m█▏        [0m| 3/26 [00:06<00:48,  2.12s/it]Epoch: 8/10. Loss: 1.0280:  12%|[36m█▏        [0m| 3/26 [00:07<00:48,  2.12s/it]Epoch: 8/10. Loss: 1.0280:  15%|[36m█▌        [0m| 4/26 [00:07<00:35,  1.62s/it]Epoch: 8/10. Loss: 0.9795:  15%|[36m█▌        [0m| 4/26 [00:11<00:35,  1.62s/it]Epoch: 8/10. Loss: 0.9795:  19%|[36m█▉        [0m| 5/26 [00:11<00:51,  2.43s/it]Epoch: 8/10. Loss: 1.0188:  19%|[36m█▉        [0m| 5/26 [00:12<00:51,  2.43s/it]Epoch: 8/10. Loss: 1.0188:  23%|[36m██▎       [0m| 6/26 [00:12<00:37,  1.87s/it]Epoch: 8/10. Loss: 1.0709:  23%|[36m██▎       [0m| 6/26 [00:13<00:37,  1.87s/it]Epoch: 8/10. Loss: 1.0709:  27%|[36m██▋       [0m| 7/26 [00:13<00:29,  1.54s/it]Epoch: 8/10. Loss: 1.0012:  27%|[36m██▋       [0m| 7/26 [00:14<00:29,  1.54s/it]Epoch: 8/10. Loss: 1.0012:  31%|[36m███       [0m| 8/26 [00:14<00:23,  1.32s/it]Epoch: 8/10. Loss: 1.0925:  31%|[36m███       [0m| 8/26 [00:14<00:23,  1.32s/it]Epoch: 8/10. Loss: 1.0925:  35%|[36m███▍      [0m| 9/26 [00:14<00:18,  1.11s/it]Epoch: 8/10. Loss: 0.9889:  35%|[36m███▍      [0m| 9/26 [00:15<00:18,  1.11s/it]Epoch: 8/10. Loss: 0.9889:  38%|[36m███▊      [0m| 10/26 [00:15<00:16,  1.04s/it]Epoch: 8/10. Loss: 1.0356:  38%|[36m███▊      [0m| 10/26 [00:16<00:16,  1.04s/it]Epoch: 8/10. Loss: 1.0356:  42%|[36m████▏     [0m| 11/26 [00:16<00:14,  1.03it/s]Epoch: 8/10. Loss: 0.9984:  42%|[36m████▏     [0m| 11/26 [00:17<00:14,  1.03it/s]Epoch: 8/10. Loss: 0.9984:  46%|[36m████▌     [0m| 12/26 [00:17<00:13,  1.00it/s]Epoch: 8/10. Loss: 0.9977:  46%|[36m████▌     [0m| 12/26 [00:18<00:13,  1.00it/s]Epoch: 8/10. Loss: 0.9977:  50%|[36m█████     [0m| 13/26 [00:18<00:12,  1.01it/s]Epoch: 8/10. Loss: 0.9980:  50%|[36m█████     [0m| 13/26 [00:19<00:12,  1.01it/s]Epoch: 8/10. Loss: 0.9980:  54%|[36m█████▍    [0m| 14/26 [00:19<00:11,  1.01it/s]Epoch: 8/10. Loss: 0.9734:  54%|[36m█████▍    [0m| 14/26 [00:20<00:11,  1.01it/s]Epoch: 8/10. Loss: 0.9734:  58%|[36m█████▊    [0m| 15/26 [00:20<00:10,  1.04it/s]Epoch: 8/10. Loss: 1.0072:  58%|[36m█████▊    [0m| 15/26 [00:21<00:10,  1.04it/s]Epoch: 8/10. Loss: 1.0072:  62%|[36m██████▏   [0m| 16/26 [00:21<00:08,  1.12it/s]Epoch: 8/10. Loss: 1.0152:  62%|[36m██████▏   [0m| 16/26 [00:21<00:08,  1.12it/s]Epoch: 8/10. Loss: 1.0152:  65%|[36m██████▌   [0m| 17/26 [00:21<00:07,  1.17it/s]Epoch: 8/10. Loss: 1.0354:  65%|[36m██████▌   [0m| 17/26 [00:23<00:07,  1.17it/s]Epoch: 8/10. Loss: 1.0354:  69%|[36m██████▉   [0m| 18/26 [00:23<00:07,  1.05it/s]Epoch: 8/10. Loss: 0.9694:  69%|[36m██████▉   [0m| 18/26 [00:25<00:07,  1.05it/s]Epoch: 8/10. Loss: 0.9694:  73%|[36m███████▎  [0m| 19/26 [00:25<00:09,  1.39s/it]Epoch: 8/10. Loss: 1.0371:  73%|[36m███████▎  [0m| 19/26 [00:26<00:09,  1.39s/it]Epoch: 8/10. Loss: 1.0371:  77%|[36m███████▋  [0m| 20/26 [00:26<00:08,  1.40s/it]Epoch: 8/10. Loss: 1.0240:  77%|[36m███████▋  [0m| 20/26 [00:29<00:08,  1.40s/it]Epoch: 8/10. Loss: 1.0240:  81%|[36m████████  [0m| 21/26 [00:29<00:08,  1.65s/it]Epoch: 8/10. Loss: 0.9859:  81%|[36m████████  [0m| 21/26 [00:29<00:08,  1.65s/it]Epoch: 8/10. Loss: 0.9859:  85%|[36m████████▍ [0m| 22/26 [00:29<00:05,  1.37s/it]Epoch: 8/10. Loss: 1.0187:  85%|[36m████████▍ [0m| 22/26 [00:30<00:05,  1.37s/it]Epoch: 8/10. Loss: 1.0187:  88%|[36m████████▊ [0m| 23/26 [00:30<00:03,  1.19s/it]Epoch: 8/10. Loss: 1.0072:  88%|[36m████████▊ [0m| 23/26 [00:31<00:03,  1.19s/it]Epoch: 8/10. Loss: 1.0072:  92%|[36m█████████▏[0m| 24/26 [00:31<00:02,  1.05s/it]Epoch: 8/10. Loss: 0.9945:  92%|[36m█████████▏[0m| 24/26 [00:32<00:02,  1.05s/it]Epoch: 8/10. Loss: 0.9945:  96%|[36m█████████▌[0m| 25/26 [00:32<00:00,  1.02it/s]Epoch: 8/10. Loss: 0.9617:  96%|[36m█████████▌[0m| 25/26 [00:32<00:00,  1.02it/s]Epoch: 8/10. Loss: 0.9617: 100%|[36m██████████[0m| 26/26 [00:32<00:00,  1.13it/s]Epoch: 8/10. Loss: 0.9617: 100%|[36m██████████[0m| 26/26 [00:32<00:00,  1.26s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:05,  1.09it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:05,  1.04s/it] 43%|[33m████▎     [0m| 3/7 [00:02<00:03,  1.12it/s] 57%|[33m█████▋    [0m| 4/7 [00:04<00:03,  1.07s/it] 71%|[33m███████▏  [0m| 5/7 [00:04<00:01,  1.23it/s] 86%|[33m████████▌ [0m| 6/7 [00:05<00:00,  1.25it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.62it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.28it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 9/10. Loss: 1.0464:   0%|[36m          [0m| 0/26 [00:01<?, ?it/s]Epoch: 9/10. Loss: 1.0464:   4%|[36m▍         [0m| 1/26 [00:01<00:25,  1.01s/it]Epoch: 9/10. Loss: 1.0553:   4%|[36m▍         [0m| 1/26 [00:01<00:25,  1.01s/it]Epoch: 9/10. Loss: 1.0553:   8%|[36m▊         [0m| 2/26 [00:01<00:21,  1.10it/s]Epoch: 9/10. Loss: 0.9449:   8%|[36m▊         [0m| 2/26 [00:02<00:21,  1.10it/s]Epoch: 9/10. Loss: 0.9449:  12%|[36m█▏        [0m| 3/26 [00:02<00:18,  1.24it/s]Epoch: 9/10. Loss: 1.0320:  12%|[36m█▏        [0m| 3/26 [00:03<00:18,  1.24it/s]Epoch: 9/10. Loss: 1.0320:  15%|[36m█▌        [0m| 4/26 [00:03<00:19,  1.15it/s]Epoch: 9/10. Loss: 1.0062:  15%|[36m█▌        [0m| 4/26 [00:04<00:19,  1.15it/s]Epoch: 9/10. Loss: 1.0062:  19%|[36m█▉        [0m| 5/26 [00:04<00:18,  1.16it/s]Epoch: 9/10. Loss: 1.0246:  19%|[36m█▉        [0m| 5/26 [00:05<00:18,  1.16it/s]Epoch: 9/10. Loss: 1.0246:  23%|[36m██▎       [0m| 6/26 [00:05<00:17,  1.16it/s]Epoch: 9/10. Loss: 0.9916:  23%|[36m██▎       [0m| 6/26 [00:05<00:17,  1.16it/s]Epoch: 9/10. Loss: 0.9916:  27%|[36m██▋       [0m| 7/26 [00:05<00:15,  1.20it/s]Epoch: 9/10. Loss: 1.0143:  27%|[36m██▋       [0m| 7/26 [00:06<00:15,  1.20it/s]Epoch: 9/10. Loss: 1.0143:  31%|[36m███       [0m| 8/26 [00:06<00:15,  1.20it/s]Epoch: 9/10. Loss: 1.0285:  31%|[36m███       [0m| 8/26 [00:07<00:15,  1.20it/s]Epoch: 9/10. Loss: 1.0285:  35%|[36m███▍      [0m| 9/26 [00:07<00:14,  1.14it/s]Epoch: 9/10. Loss: 0.9490:  35%|[36m███▍      [0m| 9/26 [00:08<00:14,  1.14it/s]Epoch: 9/10. Loss: 0.9490:  38%|[36m███▊      [0m| 10/26 [00:08<00:14,  1.10it/s]Epoch: 9/10. Loss: 0.9755:  38%|[36m███▊      [0m| 10/26 [00:09<00:14,  1.10it/s]Epoch: 9/10. Loss: 0.9755:  42%|[36m████▏     [0m| 11/26 [00:09<00:13,  1.15it/s]Epoch: 9/10. Loss: 1.0300:  42%|[36m████▏     [0m| 11/26 [00:10<00:13,  1.15it/s]Epoch: 9/10. Loss: 1.0300:  46%|[36m████▌     [0m| 12/26 [00:10<00:11,  1.23it/s]Epoch: 9/10. Loss: 0.9719:  46%|[36m████▌     [0m| 12/26 [00:11<00:11,  1.23it/s]Epoch: 9/10. Loss: 0.9719:  50%|[36m█████     [0m| 13/26 [00:11<00:11,  1.17it/s]Epoch: 9/10. Loss: 1.0335:  50%|[36m█████     [0m| 13/26 [00:12<00:11,  1.17it/s]Epoch: 9/10. Loss: 1.0335:  54%|[36m█████▍    [0m| 14/26 [00:12<00:10,  1.11it/s]Epoch: 9/10. Loss: 1.0717:  54%|[36m█████▍    [0m| 14/26 [00:13<00:10,  1.11it/s]Epoch: 9/10. Loss: 1.0717:  58%|[36m█████▊    [0m| 15/26 [00:13<00:12,  1.17s/it]Epoch: 9/10. Loss: 1.0217:  58%|[36m█████▊    [0m| 15/26 [00:14<00:12,  1.17s/it]Epoch: 9/10. Loss: 1.0217:  62%|[36m██████▏   [0m| 16/26 [00:14<00:11,  1.12s/it]Epoch: 9/10. Loss: 1.0210:  62%|[36m██████▏   [0m| 16/26 [00:16<00:11,  1.12s/it]Epoch: 9/10. Loss: 1.0210:  65%|[36m██████▌   [0m| 17/26 [00:16<00:11,  1.33s/it]Epoch: 9/10. Loss: 1.0509:  65%|[36m██████▌   [0m| 17/26 [00:17<00:11,  1.33s/it]Epoch: 9/10. Loss: 1.0509:  69%|[36m██████▉   [0m| 18/26 [00:17<00:09,  1.15s/it]Epoch: 9/10. Loss: 1.0297:  69%|[36m██████▉   [0m| 18/26 [00:18<00:09,  1.15s/it]Epoch: 9/10. Loss: 1.0297:  73%|[36m███████▎  [0m| 19/26 [00:18<00:07,  1.02s/it]Epoch: 9/10. Loss: 1.0208:  73%|[36m███████▎  [0m| 19/26 [00:19<00:07,  1.02s/it]Epoch: 9/10. Loss: 1.0208:  77%|[36m███████▋  [0m| 20/26 [00:19<00:05,  1.04it/s]Epoch: 9/10. Loss: 1.0015:  77%|[36m███████▋  [0m| 20/26 [00:20<00:05,  1.04it/s]Epoch: 9/10. Loss: 1.0015:  81%|[36m████████  [0m| 21/26 [00:20<00:04,  1.04it/s]Epoch: 9/10. Loss: 1.0146:  81%|[36m████████  [0m| 21/26 [00:20<00:04,  1.04it/s]Epoch: 9/10. Loss: 1.0146:  85%|[36m████████▍ [0m| 22/26 [00:20<00:03,  1.13it/s]Epoch: 9/10. Loss: 1.0276:  85%|[36m████████▍ [0m| 22/26 [00:21<00:03,  1.13it/s]Epoch: 9/10. Loss: 1.0276:  88%|[36m████████▊ [0m| 23/26 [00:21<00:02,  1.08it/s]Epoch: 9/10. Loss: 0.9894:  88%|[36m████████▊ [0m| 23/26 [00:22<00:02,  1.08it/s]Epoch: 9/10. Loss: 0.9894:  92%|[36m█████████▏[0m| 24/26 [00:22<00:01,  1.12it/s]Epoch: 9/10. Loss: 1.0307:  92%|[36m█████████▏[0m| 24/26 [00:23<00:01,  1.12it/s]Epoch: 9/10. Loss: 1.0307:  96%|[36m█████████▌[0m| 25/26 [00:23<00:00,  1.06it/s]Epoch: 9/10. Loss: 0.9789:  96%|[36m█████████▌[0m| 25/26 [00:24<00:00,  1.06it/s]Epoch: 9/10. Loss: 0.9789: 100%|[36m██████████[0m| 26/26 [00:24<00:00,  1.19it/s]Epoch: 9/10. Loss: 0.9789: 100%|[36m██████████[0m| 26/26 [00:24<00:00,  1.07it/s]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:05,  1.13it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:05,  1.05s/it] 43%|[33m████▎     [0m| 3/7 [00:02<00:03,  1.10it/s] 57%|[33m█████▋    [0m| 4/7 [00:04<00:03,  1.09s/it] 71%|[33m███████▏  [0m| 5/7 [00:04<00:01,  1.19it/s] 86%|[33m████████▌ [0m| 6/7 [00:05<00:00,  1.22it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.59it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.26it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 0/10. Loss: 7.0748:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 0/10. Loss: 7.0748:   4%|[36m▍         [0m| 1/26 [00:01<00:26,  1.06s/it]Epoch: 0/10. Loss: 3.7588:   4%|[36m▍         [0m| 1/26 [00:01<00:26,  1.06s/it]Epoch: 0/10. Loss: 3.7588:   8%|[36m▊         [0m| 2/26 [00:01<00:23,  1.03it/s]Epoch: 0/10. Loss: 1.4507:   8%|[36m▊         [0m| 2/26 [00:02<00:23,  1.03it/s]Epoch: 0/10. Loss: 1.4507:  12%|[36m█▏        [0m| 3/26 [00:02<00:22,  1.02it/s]Epoch: 0/10. Loss: 1.3199:  12%|[36m█▏        [0m| 3/26 [00:03<00:22,  1.02it/s]Epoch: 0/10. Loss: 1.3199:  15%|[36m█▌        [0m| 4/26 [00:03<00:21,  1.02it/s]Epoch: 0/10. Loss: 1.3584:  15%|[36m█▌        [0m| 4/26 [00:04<00:21,  1.02it/s]Epoch: 0/10. Loss: 1.3584:  19%|[36m█▉        [0m| 5/26 [00:04<00:20,  1.05it/s]Epoch: 0/10. Loss: 1.0846:  19%|[36m█▉        [0m| 5/26 [00:05<00:20,  1.05it/s]Epoch: 0/10. Loss: 1.0846:  23%|[36m██▎       [0m| 6/26 [00:05<00:17,  1.14it/s]Epoch: 0/10. Loss: 1.0728:  23%|[36m██▎       [0m| 6/26 [00:06<00:17,  1.14it/s]Epoch: 0/10. Loss: 1.0728:  27%|[36m██▋       [0m| 7/26 [00:06<00:17,  1.09it/s]Epoch: 0/10. Loss: 1.0715:  27%|[36m██▋       [0m| 7/26 [00:07<00:17,  1.09it/s]Epoch: 0/10. Loss: 1.0715:  31%|[36m███       [0m| 8/26 [00:07<00:17,  1.05it/s]Epoch: 0/10. Loss: 1.0789:  31%|[36m███       [0m| 8/26 [00:08<00:17,  1.05it/s]Epoch: 0/10. Loss: 1.0789:  35%|[36m███▍      [0m| 9/26 [00:08<00:15,  1.07it/s]Epoch: 0/10. Loss: 1.1670:  35%|[36m███▍      [0m| 9/26 [00:09<00:15,  1.07it/s]Epoch: 0/10. Loss: 1.1670:  38%|[36m███▊      [0m| 10/26 [00:09<00:14,  1.09it/s]Epoch: 0/10. Loss: 0.9334:  38%|[36m███▊      [0m| 10/26 [00:10<00:14,  1.09it/s]Epoch: 0/10. Loss: 0.9334:  42%|[36m████▏     [0m| 11/26 [00:10<00:14,  1.07it/s]Epoch: 0/10. Loss: 1.0295:  42%|[36m████▏     [0m| 11/26 [00:11<00:14,  1.07it/s]Epoch: 0/10. Loss: 1.0295:  46%|[36m████▌     [0m| 12/26 [00:11<00:13,  1.06it/s]Epoch: 0/10. Loss: 1.2371:  46%|[36m████▌     [0m| 12/26 [00:12<00:13,  1.06it/s]Epoch: 0/10. Loss: 1.2371:  50%|[36m█████     [0m| 13/26 [00:12<00:11,  1.12it/s]Epoch: 0/10. Loss: 1.1483:  50%|[36m█████     [0m| 13/26 [00:13<00:11,  1.12it/s]Epoch: 0/10. Loss: 1.1483:  54%|[36m█████▍    [0m| 14/26 [00:13<00:10,  1.09it/s]Epoch: 0/10. Loss: 1.0984:  54%|[36m█████▍    [0m| 14/26 [00:13<00:10,  1.09it/s]Epoch: 0/10. Loss: 1.0984:  58%|[36m█████▊    [0m| 15/26 [00:13<00:10,  1.09it/s]Epoch: 0/10. Loss: 0.9691:  58%|[36m█████▊    [0m| 15/26 [00:14<00:10,  1.09it/s]Epoch: 0/10. Loss: 0.9691:  62%|[36m██████▏   [0m| 16/26 [00:14<00:08,  1.15it/s]Epoch: 0/10. Loss: 0.9986:  62%|[36m██████▏   [0m| 16/26 [00:15<00:08,  1.15it/s]Epoch: 0/10. Loss: 0.9986:  65%|[36m██████▌   [0m| 17/26 [00:15<00:08,  1.10it/s]Epoch: 0/10. Loss: 1.0274:  65%|[36m██████▌   [0m| 17/26 [00:16<00:08,  1.10it/s]Epoch: 0/10. Loss: 1.0274:  69%|[36m██████▉   [0m| 18/26 [00:16<00:07,  1.06it/s]Epoch: 0/10. Loss: 1.0808:  69%|[36m██████▉   [0m| 18/26 [00:17<00:07,  1.06it/s]Epoch: 0/10. Loss: 1.0808:  73%|[36m███████▎  [0m| 19/26 [00:17<00:06,  1.08it/s]Epoch: 0/10. Loss: 1.0331:  73%|[36m███████▎  [0m| 19/26 [00:18<00:06,  1.08it/s]Epoch: 0/10. Loss: 1.0331:  77%|[36m███████▋  [0m| 20/26 [00:18<00:05,  1.09it/s]Epoch: 0/10. Loss: 1.0302:  77%|[36m███████▋  [0m| 20/26 [00:19<00:05,  1.09it/s]Epoch: 0/10. Loss: 1.0302:  81%|[36m████████  [0m| 21/26 [00:19<00:04,  1.06it/s]Epoch: 0/10. Loss: 1.0283:  81%|[36m████████  [0m| 21/26 [00:20<00:04,  1.06it/s]Epoch: 0/10. Loss: 1.0283:  85%|[36m████████▍ [0m| 22/26 [00:20<00:04,  1.07s/it]Epoch: 0/10. Loss: 1.0090:  85%|[36m████████▍ [0m| 22/26 [00:23<00:04,  1.07s/it]Epoch: 0/10. Loss: 1.0090:  88%|[36m████████▊ [0m| 23/26 [00:23<00:04,  1.65s/it]Epoch: 0/10. Loss: 0.9911:  88%|[36m████████▊ [0m| 23/26 [00:24<00:04,  1.65s/it]Epoch: 0/10. Loss: 0.9911:  92%|[36m█████████▏[0m| 24/26 [00:25<00:02,  1.48s/it]Epoch: 0/10. Loss: 0.8944:  92%|[36m█████████▏[0m| 24/26 [00:26<00:02,  1.48s/it]Epoch: 0/10. Loss: 0.8944:  96%|[36m█████████▌[0m| 25/26 [00:26<00:01,  1.56s/it]Epoch: 0/10. Loss: 1.1267:  96%|[36m█████████▌[0m| 25/26 [00:27<00:01,  1.56s/it]Epoch: 0/10. Loss: 1.1267: 100%|[36m██████████[0m| 26/26 [00:27<00:00,  1.30s/it]Epoch: 0/10. Loss: 1.1267: 100%|[36m██████████[0m| 26/26 [00:27<00:00,  1.06s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:05,  1.06it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:05,  1.12s/it] 43%|[33m████▎     [0m| 3/7 [00:02<00:03,  1.03it/s] 57%|[33m█████▋    [0m| 4/7 [00:04<00:03,  1.16s/it] 71%|[33m███████▏  [0m| 5/7 [00:04<00:01,  1.11it/s] 86%|[33m████████▌ [0m| 6/7 [00:05<00:00,  1.14it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.46it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.17it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 1/10. Loss: 0.9545:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 1/10. Loss: 0.9545:   4%|[36m▍         [0m| 1/26 [00:01<00:25,  1.03s/it]Epoch: 1/10. Loss: 1.0164:   4%|[36m▍         [0m| 1/26 [00:02<00:25,  1.03s/it]Epoch: 1/10. Loss: 1.0164:   8%|[36m▊         [0m| 2/26 [00:02<00:24,  1.02s/it]Epoch: 1/10. Loss: 0.9483:   8%|[36m▊         [0m| 2/26 [00:02<00:24,  1.02s/it]Epoch: 1/10. Loss: 0.9483:  12%|[36m█▏        [0m| 3/26 [00:02<00:22,  1.02it/s]Epoch: 1/10. Loss: 1.0136:  12%|[36m█▏        [0m| 3/26 [00:04<00:22,  1.02it/s]Epoch: 1/10. Loss: 1.0136:  15%|[36m█▌        [0m| 4/26 [00:04<00:23,  1.05s/it]Epoch: 1/10. Loss: 0.9808:  15%|[36m█▌        [0m| 4/26 [00:04<00:23,  1.05s/it]Epoch: 1/10. Loss: 0.9808:  19%|[36m█▉        [0m| 5/26 [00:04<00:20,  1.03it/s]Epoch: 1/10. Loss: 0.9960:  19%|[36m█▉        [0m| 5/26 [00:05<00:20,  1.03it/s]Epoch: 1/10. Loss: 0.9960:  23%|[36m██▎       [0m| 6/26 [00:05<00:18,  1.08it/s]Epoch: 1/10. Loss: 1.0377:  23%|[36m██▎       [0m| 6/26 [00:09<00:18,  1.08it/s]Epoch: 1/10. Loss: 1.0377:  27%|[36m██▋       [0m| 7/26 [00:09<00:32,  1.71s/it]Epoch: 1/10. Loss: 0.9555:  27%|[36m██▋       [0m| 7/26 [00:10<00:32,  1.71s/it]Epoch: 1/10. Loss: 0.9555:  31%|[36m███       [0m| 8/26 [00:10<00:27,  1.52s/it]Epoch: 1/10. Loss: 1.0677:  31%|[36m███       [0m| 8/26 [00:11<00:27,  1.52s/it]Epoch: 1/10. Loss: 1.0677:  35%|[36m███▍      [0m| 9/26 [00:11<00:22,  1.34s/it]Epoch: 1/10. Loss: 1.0252:  35%|[36m███▍      [0m| 9/26 [00:12<00:22,  1.34s/it]Epoch: 1/10. Loss: 1.0252:  38%|[36m███▊      [0m| 10/26 [00:12<00:20,  1.26s/it]Epoch: 1/10. Loss: 0.9963:  38%|[36m███▊      [0m| 10/26 [00:14<00:20,  1.26s/it]Epoch: 1/10. Loss: 0.9963:  42%|[36m████▏     [0m| 11/26 [00:14<00:23,  1.60s/it]Epoch: 1/10. Loss: 1.0058:  42%|[36m████▏     [0m| 11/26 [00:16<00:23,  1.60s/it]Epoch: 1/10. Loss: 1.0058:  46%|[36m████▌     [0m| 12/26 [00:16<00:23,  1.67s/it]Epoch: 1/10. Loss: 0.9386:  46%|[36m████▌     [0m| 12/26 [00:17<00:23,  1.67s/it]Epoch: 1/10. Loss: 0.9386:  50%|[36m█████     [0m| 13/26 [00:17<00:18,  1.43s/it]Epoch: 1/10. Loss: 0.9922:  50%|[36m█████     [0m| 13/26 [00:18<00:18,  1.43s/it]Epoch: 1/10. Loss: 0.9922:  54%|[36m█████▍    [0m| 14/26 [00:18<00:15,  1.32s/it]Epoch: 1/10. Loss: 1.0438:  54%|[36m█████▍    [0m| 14/26 [00:19<00:15,  1.32s/it]Epoch: 1/10. Loss: 1.0438:  58%|[36m█████▊    [0m| 15/26 [00:19<00:14,  1.32s/it]Epoch: 1/10. Loss: 0.9710:  58%|[36m█████▊    [0m| 15/26 [00:20<00:14,  1.32s/it]Epoch: 1/10. Loss: 0.9710:  62%|[36m██████▏   [0m| 16/26 [00:20<00:12,  1.21s/it]Epoch: 1/10. Loss: 1.0195:  62%|[36m██████▏   [0m| 16/26 [00:21<00:12,  1.21s/it]Epoch: 1/10. Loss: 1.0195:  65%|[36m██████▌   [0m| 17/26 [00:21<00:10,  1.14s/it]Epoch: 1/10. Loss: 0.9435:  65%|[36m██████▌   [0m| 17/26 [00:22<00:10,  1.14s/it]Epoch: 1/10. Loss: 0.9435:  69%|[36m██████▉   [0m| 18/26 [00:22<00:08,  1.05s/it]Epoch: 1/10. Loss: 1.1324:  69%|[36m██████▉   [0m| 18/26 [00:23<00:08,  1.05s/it]Epoch: 1/10. Loss: 1.1324:  73%|[36m███████▎  [0m| 19/26 [00:23<00:07,  1.04s/it]Epoch: 1/10. Loss: 0.8884:  73%|[36m███████▎  [0m| 19/26 [00:24<00:07,  1.04s/it]Epoch: 1/10. Loss: 0.8884:  77%|[36m███████▋  [0m| 20/26 [00:24<00:05,  1.05it/s]Epoch: 1/10. Loss: 0.9683:  77%|[36m███████▋  [0m| 20/26 [00:25<00:05,  1.05it/s]Epoch: 1/10. Loss: 0.9683:  81%|[36m████████  [0m| 21/26 [00:25<00:04,  1.02it/s]Epoch: 1/10. Loss: 0.9442:  81%|[36m████████  [0m| 21/26 [00:27<00:04,  1.02it/s]Epoch: 1/10. Loss: 0.9442:  85%|[36m████████▍ [0m| 22/26 [00:27<00:04,  1.23s/it]Epoch: 1/10. Loss: 1.0877:  85%|[36m████████▍ [0m| 22/26 [00:28<00:04,  1.23s/it]Epoch: 1/10. Loss: 1.0877:  88%|[36m████████▊ [0m| 23/26 [00:28<00:03,  1.18s/it]Epoch: 1/10. Loss: 0.9826:  88%|[36m████████▊ [0m| 23/26 [00:29<00:03,  1.18s/it]Epoch: 1/10. Loss: 0.9826:  92%|[36m█████████▏[0m| 24/26 [00:29<00:02,  1.11s/it]Epoch: 1/10. Loss: 0.9734:  92%|[36m█████████▏[0m| 24/26 [00:29<00:02,  1.11s/it]Epoch: 1/10. Loss: 0.9734:  96%|[36m█████████▌[0m| 25/26 [00:29<00:01,  1.04s/it]Epoch: 1/10. Loss: 0.9637:  96%|[36m█████████▌[0m| 25/26 [00:30<00:01,  1.04s/it]Epoch: 1/10. Loss: 0.9637: 100%|[36m██████████[0m| 26/26 [00:30<00:00,  1.15it/s]Epoch: 1/10. Loss: 0.9637: 100%|[36m██████████[0m| 26/26 [00:30<00:00,  1.17s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:01<00:06,  1.02s/it] 29%|[33m██▊       [0m| 2/7 [00:02<00:05,  1.17s/it] 43%|[33m████▎     [0m| 3/7 [00:03<00:03,  1.01it/s] 57%|[33m█████▋    [0m| 4/7 [00:04<00:03,  1.19s/it] 71%|[33m███████▏  [0m| 5/7 [00:05<00:01,  1.08it/s] 86%|[33m████████▌ [0m| 6/7 [00:05<00:00,  1.12it/s]100%|[33m██████████[0m| 7/7 [00:06<00:00,  1.44it/s]100%|[33m██████████[0m| 7/7 [00:06<00:00,  1.14it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 2/10. Loss: 0.8789:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 2/10. Loss: 0.8789:   4%|[36m▍         [0m| 1/26 [00:00<00:24,  1.00it/s]Epoch: 2/10. Loss: 1.0167:   4%|[36m▍         [0m| 1/26 [00:02<00:24,  1.00it/s]Epoch: 2/10. Loss: 1.0167:   8%|[36m▊         [0m| 2/26 [00:02<00:27,  1.15s/it]Epoch: 2/10. Loss: 0.9058:   8%|[36m▊         [0m| 2/26 [00:03<00:27,  1.15s/it]Epoch: 2/10. Loss: 0.9058:  12%|[36m█▏        [0m| 3/26 [00:03<00:22,  1.01it/s]Epoch: 2/10. Loss: 1.0083:  12%|[36m█▏        [0m| 3/26 [00:04<00:22,  1.01it/s]Epoch: 2/10. Loss: 1.0083:  15%|[36m█▌        [0m| 4/26 [00:04<00:21,  1.00it/s]Epoch: 2/10. Loss: 1.0231:  15%|[36m█▌        [0m| 4/26 [00:06<00:21,  1.00it/s]Epoch: 2/10. Loss: 1.0231:  19%|[36m█▉        [0m| 5/26 [00:06<00:31,  1.51s/it]Epoch: 2/10. Loss: 0.9717:  19%|[36m█▉        [0m| 5/26 [00:07<00:31,  1.51s/it]Epoch: 2/10. Loss: 0.9717:  23%|[36m██▎       [0m| 6/26 [00:07<00:27,  1.36s/it]Epoch: 2/10. Loss: 1.0303:  23%|[36m██▎       [0m| 6/26 [00:08<00:27,  1.36s/it]Epoch: 2/10. Loss: 1.0303:  27%|[36m██▋       [0m| 7/26 [00:08<00:22,  1.21s/it]Epoch: 2/10. Loss: 1.0445:  27%|[36m██▋       [0m| 7/26 [00:09<00:22,  1.21s/it]Epoch: 2/10. Loss: 1.0445:  31%|[36m███       [0m| 8/26 [00:09<00:20,  1.13s/it]Epoch: 2/10. Loss: 0.9414:  31%|[36m███       [0m| 8/26 [00:10<00:20,  1.13s/it]Epoch: 2/10. Loss: 0.9414:  35%|[36m███▍      [0m| 9/26 [00:10<00:18,  1.09s/it]Epoch: 2/10. Loss: 1.0898:  35%|[36m███▍      [0m| 9/26 [00:11<00:18,  1.09s/it]Epoch: 2/10. Loss: 1.0898:  38%|[36m███▊      [0m| 10/26 [00:11<00:17,  1.08s/it]Epoch: 2/10. Loss: 1.0226:  38%|[36m███▊      [0m| 10/26 [00:12<00:17,  1.08s/it]Epoch: 2/10. Loss: 1.0226:  42%|[36m████▏     [0m| 11/26 [00:12<00:15,  1.04s/it]Epoch: 2/10. Loss: 1.0267:  42%|[36m████▏     [0m| 11/26 [00:13<00:15,  1.04s/it]Epoch: 2/10. Loss: 1.0267:  46%|[36m████▌     [0m| 12/26 [00:13<00:14,  1.06s/it]Epoch: 2/10. Loss: 0.9216:  46%|[36m████▌     [0m| 12/26 [00:14<00:14,  1.06s/it]Epoch: 2/10. Loss: 0.9216:  50%|[36m█████     [0m| 13/26 [00:14<00:13,  1.08s/it]Epoch: 2/10. Loss: 0.9463:  50%|[36m█████     [0m| 13/26 [00:15<00:13,  1.08s/it]Epoch: 2/10. Loss: 0.9463:  54%|[36m█████▍    [0m| 14/26 [00:15<00:12,  1.05s/it]Epoch: 2/10. Loss: 0.9391:  54%|[36m█████▍    [0m| 14/26 [00:16<00:12,  1.05s/it]Epoch: 2/10. Loss: 0.9391:  58%|[36m█████▊    [0m| 15/26 [00:16<00:11,  1.04s/it]Epoch: 2/10. Loss: 0.9810:  58%|[36m█████▊    [0m| 15/26 [00:17<00:11,  1.04s/it]Epoch: 2/10. Loss: 0.9810:  62%|[36m██████▏   [0m| 16/26 [00:17<00:10,  1.01s/it]Epoch: 2/10. Loss: 0.9443:  62%|[36m██████▏   [0m| 16/26 [00:18<00:10,  1.01s/it]Epoch: 2/10. Loss: 0.9443:  65%|[36m██████▌   [0m| 17/26 [00:18<00:08,  1.02it/s]Epoch: 2/10. Loss: 0.9448:  65%|[36m██████▌   [0m| 17/26 [00:19<00:08,  1.02it/s]Epoch: 2/10. Loss: 0.9448:  69%|[36m██████▉   [0m| 18/26 [00:19<00:07,  1.07it/s]Epoch: 2/10. Loss: 1.0126:  69%|[36m██████▉   [0m| 18/26 [00:20<00:07,  1.07it/s]Epoch: 2/10. Loss: 1.0126:  73%|[36m███████▎  [0m| 19/26 [00:20<00:06,  1.09it/s]Epoch: 2/10. Loss: 0.9195:  73%|[36m███████▎  [0m| 19/26 [00:21<00:06,  1.09it/s]Epoch: 2/10. Loss: 0.9195:  77%|[36m███████▋  [0m| 20/26 [00:21<00:05,  1.03it/s]Epoch: 2/10. Loss: 1.0317:  77%|[36m███████▋  [0m| 20/26 [00:22<00:05,  1.03it/s]Epoch: 2/10. Loss: 1.0317:  81%|[36m████████  [0m| 21/26 [00:22<00:04,  1.07it/s]Epoch: 2/10. Loss: 0.8938:  81%|[36m████████  [0m| 21/26 [00:23<00:04,  1.07it/s]Epoch: 2/10. Loss: 0.8938:  85%|[36m████████▍ [0m| 22/26 [00:23<00:03,  1.07it/s]Epoch: 2/10. Loss: 0.9179:  85%|[36m████████▍ [0m| 22/26 [00:24<00:03,  1.07it/s]Epoch: 2/10. Loss: 0.9179:  88%|[36m████████▊ [0m| 23/26 [00:24<00:02,  1.06it/s]Epoch: 2/10. Loss: 1.0497:  88%|[36m████████▊ [0m| 23/26 [00:24<00:02,  1.06it/s]Epoch: 2/10. Loss: 1.0497:  92%|[36m█████████▏[0m| 24/26 [00:24<00:01,  1.06it/s]Epoch: 2/10. Loss: 0.9957:  92%|[36m█████████▏[0m| 24/26 [00:25<00:01,  1.06it/s]Epoch: 2/10. Loss: 0.9957:  96%|[36m█████████▌[0m| 25/26 [00:25<00:00,  1.10it/s]Epoch: 2/10. Loss: 1.0459:  96%|[36m█████████▌[0m| 25/26 [00:26<00:00,  1.10it/s]Epoch: 2/10. Loss: 1.0459: 100%|[36m██████████[0m| 26/26 [00:26<00:00,  1.17it/s]Epoch: 2/10. Loss: 1.0459: 100%|[36m██████████[0m| 26/26 [00:26<00:00,  1.02s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:05,  1.01it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:07,  1.52s/it] 43%|[33m████▎     [0m| 3/7 [00:04<00:07,  1.77s/it] 57%|[33m█████▋    [0m| 4/7 [00:07<00:05,  1.93s/it] 71%|[33m███████▏  [0m| 5/7 [00:07<00:02,  1.39s/it] 86%|[33m████████▌ [0m| 6/7 [00:08<00:01,  1.21s/it]100%|[33m██████████[0m| 7/7 [00:08<00:00,  1.10it/s]100%|[33m██████████[0m| 7/7 [00:08<00:00,  1.24s/it]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 3/10. Loss: 0.9579:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 3/10. Loss: 0.9579:   4%|[36m▍         [0m| 1/26 [00:00<00:21,  1.18it/s]Epoch: 3/10. Loss: 0.9622:   4%|[36m▍         [0m| 1/26 [00:01<00:21,  1.18it/s]Epoch: 3/10. Loss: 0.9622:   8%|[36m▊         [0m| 2/26 [00:01<00:21,  1.14it/s]Epoch: 3/10. Loss: 1.0326:   8%|[36m▊         [0m| 2/26 [00:02<00:21,  1.14it/s]Epoch: 3/10. Loss: 1.0326:  12%|[36m█▏        [0m| 3/26 [00:02<00:21,  1.07it/s]Epoch: 3/10. Loss: 0.9361:  12%|[36m█▏        [0m| 3/26 [00:03<00:21,  1.07it/s]Epoch: 3/10. Loss: 0.9361:  15%|[36m█▌        [0m| 4/26 [00:03<00:21,  1.04it/s]Epoch: 3/10. Loss: 0.8810:  15%|[36m█▌        [0m| 4/26 [00:04<00:21,  1.04it/s]Epoch: 3/10. Loss: 0.8810:  19%|[36m█▉        [0m| 5/26 [00:04<00:18,  1.11it/s]Epoch: 3/10. Loss: 0.9924:  19%|[36m█▉        [0m| 5/26 [00:05<00:18,  1.11it/s]Epoch: 3/10. Loss: 0.9924:  23%|[36m██▎       [0m| 6/26 [00:05<00:17,  1.15it/s]Epoch: 3/10. Loss: 1.1218:  23%|[36m██▎       [0m| 6/26 [00:06<00:17,  1.15it/s]Epoch: 3/10. Loss: 1.1218:  27%|[36m██▋       [0m| 7/26 [00:06<00:17,  1.07it/s]Epoch: 3/10. Loss: 0.9155:  27%|[36m██▋       [0m| 7/26 [00:07<00:17,  1.07it/s]Epoch: 3/10. Loss: 0.9155:  31%|[36m███       [0m| 8/26 [00:07<00:16,  1.07it/s]Epoch: 3/10. Loss: 1.0638:  31%|[36m███       [0m| 8/26 [00:08<00:16,  1.07it/s]Epoch: 3/10. Loss: 1.0638:  35%|[36m███▍      [0m| 9/26 [00:08<00:16,  1.02it/s]Epoch: 3/10. Loss: 1.0405:  35%|[36m███▍      [0m| 9/26 [00:09<00:16,  1.02it/s]Epoch: 3/10. Loss: 1.0405:  38%|[36m███▊      [0m| 10/26 [00:09<00:15,  1.03it/s]Epoch: 3/10. Loss: 1.0475:  38%|[36m███▊      [0m| 10/26 [00:10<00:15,  1.03it/s]Epoch: 3/10. Loss: 1.0475:  42%|[36m████▏     [0m| 11/26 [00:10<00:14,  1.07it/s]Epoch: 3/10. Loss: 0.9718:  42%|[36m████▏     [0m| 11/26 [00:11<00:14,  1.07it/s]Epoch: 3/10. Loss: 0.9718:  46%|[36m████▌     [0m| 12/26 [00:11<00:13,  1.03it/s]Epoch: 3/10. Loss: 1.0124:  46%|[36m████▌     [0m| 12/26 [00:12<00:13,  1.03it/s]Epoch: 3/10. Loss: 1.0124:  50%|[36m█████     [0m| 13/26 [00:12<00:13,  1.02s/it]Epoch: 3/10. Loss: 0.9809:  50%|[36m█████     [0m| 13/26 [00:13<00:13,  1.02s/it]Epoch: 3/10. Loss: 0.9809:  54%|[36m█████▍    [0m| 14/26 [00:13<00:11,  1.03it/s]Epoch: 3/10. Loss: 1.0010:  54%|[36m█████▍    [0m| 14/26 [00:14<00:11,  1.03it/s]Epoch: 3/10. Loss: 1.0010:  58%|[36m█████▊    [0m| 15/26 [00:14<00:11,  1.01s/it]Epoch: 3/10. Loss: 1.0390:  58%|[36m█████▊    [0m| 15/26 [00:15<00:11,  1.01s/it]Epoch: 3/10. Loss: 1.0390:  62%|[36m██████▏   [0m| 16/26 [00:15<00:09,  1.06it/s]Epoch: 3/10. Loss: 1.1116:  62%|[36m██████▏   [0m| 16/26 [00:16<00:09,  1.06it/s]Epoch: 3/10. Loss: 1.1116:  65%|[36m██████▌   [0m| 17/26 [00:16<00:09,  1.07s/it]Epoch: 3/10. Loss: 0.9202:  65%|[36m██████▌   [0m| 17/26 [00:18<00:09,  1.07s/it]Epoch: 3/10. Loss: 0.9202:  69%|[36m██████▉   [0m| 18/26 [00:18<00:09,  1.20s/it]Epoch: 3/10. Loss: 0.9382:  69%|[36m██████▉   [0m| 18/26 [00:18<00:09,  1.20s/it]Epoch: 3/10. Loss: 0.9382:  73%|[36m███████▎  [0m| 19/26 [00:18<00:07,  1.08s/it]Epoch: 3/10. Loss: 0.8606:  73%|[36m███████▎  [0m| 19/26 [00:20<00:07,  1.08s/it]Epoch: 3/10. Loss: 0.8606:  77%|[36m███████▋  [0m| 20/26 [00:20<00:06,  1.14s/it]Epoch: 3/10. Loss: 1.0688:  77%|[36m███████▋  [0m| 20/26 [00:20<00:06,  1.14s/it]Epoch: 3/10. Loss: 1.0688:  81%|[36m████████  [0m| 21/26 [00:20<00:05,  1.06s/it]Epoch: 3/10. Loss: 1.0021:  81%|[36m████████  [0m| 21/26 [00:22<00:05,  1.06s/it]Epoch: 3/10. Loss: 1.0021:  85%|[36m████████▍ [0m| 22/26 [00:22<00:04,  1.10s/it]Epoch: 3/10. Loss: 0.9138:  85%|[36m████████▍ [0m| 22/26 [00:23<00:04,  1.10s/it]Epoch: 3/10. Loss: 0.9138:  88%|[36m████████▊ [0m| 23/26 [00:23<00:03,  1.11s/it]Epoch: 3/10. Loss: 0.8881:  88%|[36m████████▊ [0m| 23/26 [00:26<00:03,  1.11s/it]Epoch: 3/10. Loss: 0.8881:  92%|[36m█████████▏[0m| 24/26 [00:26<00:03,  1.60s/it]Epoch: 3/10. Loss: 0.9675:  92%|[36m█████████▏[0m| 24/26 [00:27<00:03,  1.60s/it]Epoch: 3/10. Loss: 0.9675:  96%|[36m█████████▌[0m| 25/26 [00:27<00:01,  1.45s/it]Epoch: 3/10. Loss: 1.0933:  96%|[36m█████████▌[0m| 25/26 [00:27<00:01,  1.45s/it]Epoch: 3/10. Loss: 1.0933: 100%|[36m██████████[0m| 26/26 [00:27<00:00,  1.18s/it]Epoch: 3/10. Loss: 1.0933: 100%|[36m██████████[0m| 26/26 [00:27<00:00,  1.07s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:05,  1.13it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:05,  1.05s/it] 43%|[33m████▎     [0m| 3/7 [00:02<00:03,  1.04it/s] 57%|[33m█████▋    [0m| 4/7 [00:04<00:03,  1.16s/it] 71%|[33m███████▏  [0m| 5/7 [00:04<00:01,  1.11it/s] 86%|[33m████████▌ [0m| 6/7 [00:05<00:00,  1.13it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.45it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.18it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 4/10. Loss: 0.9840:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 4/10. Loss: 0.9840:   4%|[36m▍         [0m| 1/26 [00:00<00:24,  1.03it/s]Epoch: 4/10. Loss: 1.0379:   4%|[36m▍         [0m| 1/26 [00:01<00:24,  1.03it/s]Epoch: 4/10. Loss: 1.0379:   8%|[36m▊         [0m| 2/26 [00:02<00:24,  1.01s/it]Epoch: 4/10. Loss: 0.9911:   8%|[36m▊         [0m| 2/26 [00:02<00:24,  1.01s/it]Epoch: 4/10. Loss: 0.9911:  12%|[36m█▏        [0m| 3/26 [00:02<00:22,  1.04it/s]Epoch: 4/10. Loss: 0.9689:  12%|[36m█▏        [0m| 3/26 [00:03<00:22,  1.04it/s]Epoch: 4/10. Loss: 0.9689:  15%|[36m█▌        [0m| 4/26 [00:04<00:22,  1.02s/it]Epoch: 4/10. Loss: 0.8363:  15%|[36m█▌        [0m| 4/26 [00:04<00:22,  1.02s/it]Epoch: 4/10. Loss: 0.8363:  19%|[36m█▉        [0m| 5/26 [00:04<00:20,  1.04it/s]Epoch: 4/10. Loss: 0.8418:  19%|[36m█▉        [0m| 5/26 [00:07<00:20,  1.04it/s]Epoch: 4/10. Loss: 0.8418:  23%|[36m██▎       [0m| 6/26 [00:07<00:28,  1.41s/it]Epoch: 4/10. Loss: 0.9136:  23%|[36m██▎       [0m| 6/26 [00:08<00:28,  1.41s/it]Epoch: 4/10. Loss: 0.9136:  27%|[36m██▋       [0m| 7/26 [00:09<00:29,  1.55s/it]Epoch: 4/10. Loss: 0.9822:  27%|[36m██▋       [0m| 7/26 [00:09<00:29,  1.55s/it]Epoch: 4/10. Loss: 0.9822:  31%|[36m███       [0m| 8/26 [00:09<00:23,  1.33s/it]Epoch: 4/10. Loss: 0.8510:  31%|[36m███       [0m| 8/26 [00:10<00:23,  1.33s/it]Epoch: 4/10. Loss: 0.8510:  35%|[36m███▍      [0m| 9/26 [00:10<00:20,  1.20s/it]Epoch: 4/10. Loss: 0.8834:  35%|[36m███▍      [0m| 9/26 [00:11<00:20,  1.20s/it]Epoch: 4/10. Loss: 0.8834:  38%|[36m███▊      [0m| 10/26 [00:11<00:18,  1.13s/it]Epoch: 4/10. Loss: 0.8887:  38%|[36m███▊      [0m| 10/26 [00:12<00:18,  1.13s/it]Epoch: 4/10. Loss: 0.8887:  42%|[36m████▏     [0m| 11/26 [00:12<00:16,  1.12s/it]Epoch: 4/10. Loss: 0.8642:  42%|[36m████▏     [0m| 11/26 [00:13<00:16,  1.12s/it]Epoch: 4/10. Loss: 0.8642:  46%|[36m████▌     [0m| 12/26 [00:13<00:14,  1.07s/it]Epoch: 4/10. Loss: 1.0378:  46%|[36m████▌     [0m| 12/26 [00:14<00:14,  1.07s/it]Epoch: 4/10. Loss: 1.0378:  50%|[36m█████     [0m| 13/26 [00:14<00:13,  1.04s/it]Epoch: 4/10. Loss: 0.9155:  50%|[36m█████     [0m| 13/26 [00:15<00:13,  1.04s/it]Epoch: 4/10. Loss: 0.9155:  54%|[36m█████▍    [0m| 14/26 [00:15<00:12,  1.04s/it]Epoch: 4/10. Loss: 0.9286:  54%|[36m█████▍    [0m| 14/26 [00:16<00:12,  1.04s/it]Epoch: 4/10. Loss: 0.9286:  58%|[36m█████▊    [0m| 15/26 [00:16<00:10,  1.00it/s]Epoch: 4/10. Loss: 0.9197:  58%|[36m█████▊    [0m| 15/26 [00:17<00:10,  1.00it/s]Epoch: 4/10. Loss: 0.9197:  62%|[36m██████▏   [0m| 16/26 [00:17<00:09,  1.03it/s]Epoch: 4/10. Loss: 0.8991:  62%|[36m██████▏   [0m| 16/26 [00:19<00:09,  1.03it/s]Epoch: 4/10. Loss: 0.8991:  65%|[36m██████▌   [0m| 17/26 [00:19<00:11,  1.32s/it]Epoch: 4/10. Loss: 1.0105:  65%|[36m██████▌   [0m| 17/26 [00:20<00:11,  1.32s/it]Epoch: 4/10. Loss: 1.0105:  69%|[36m██████▉   [0m| 18/26 [00:20<00:09,  1.21s/it]Epoch: 4/10. Loss: 0.9616:  69%|[36m██████▉   [0m| 18/26 [00:23<00:09,  1.21s/it]Epoch: 4/10. Loss: 0.9616:  73%|[36m███████▎  [0m| 19/26 [00:23<00:11,  1.61s/it]Epoch: 4/10. Loss: 0.9519:  73%|[36m███████▎  [0m| 19/26 [00:25<00:11,  1.61s/it]Epoch: 4/10. Loss: 0.9519:  77%|[36m███████▋  [0m| 20/26 [00:25<00:10,  1.71s/it]Epoch: 4/10. Loss: 0.8872:  77%|[36m███████▋  [0m| 20/26 [00:26<00:10,  1.71s/it]Epoch: 4/10. Loss: 0.8872:  81%|[36m████████  [0m| 21/26 [00:26<00:07,  1.50s/it]Epoch: 4/10. Loss: 0.9634:  81%|[36m████████  [0m| 21/26 [00:27<00:07,  1.50s/it]Epoch: 4/10. Loss: 0.9634:  85%|[36m████████▍ [0m| 22/26 [00:27<00:06,  1.58s/it]Epoch: 4/10. Loss: 0.9248:  85%|[36m████████▍ [0m| 22/26 [00:28<00:06,  1.58s/it]Epoch: 4/10. Loss: 0.9248:  88%|[36m████████▊ [0m| 23/26 [00:28<00:04,  1.35s/it]Epoch: 4/10. Loss: 0.9480:  88%|[36m████████▊ [0m| 23/26 [00:29<00:04,  1.35s/it]Epoch: 4/10. Loss: 0.9480:  92%|[36m█████████▏[0m| 24/26 [00:29<00:02,  1.23s/it]Epoch: 4/10. Loss: 0.9333:  92%|[36m█████████▏[0m| 24/26 [00:30<00:02,  1.23s/it]Epoch: 4/10. Loss: 0.9333:  96%|[36m█████████▌[0m| 25/26 [00:30<00:01,  1.18s/it]Epoch: 4/10. Loss: 0.8207:  96%|[36m█████████▌[0m| 25/26 [00:31<00:01,  1.18s/it]Epoch: 4/10. Loss: 0.8207: 100%|[36m██████████[0m| 26/26 [00:31<00:00,  1.06s/it]Epoch: 4/10. Loss: 0.8207: 100%|[36m██████████[0m| 26/26 [00:31<00:00,  1.21s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:05,  1.09it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:05,  1.09s/it] 43%|[33m████▎     [0m| 3/7 [00:02<00:03,  1.06it/s] 57%|[33m█████▋    [0m| 4/7 [00:04<00:03,  1.14s/it] 71%|[33m███████▏  [0m| 5/7 [00:04<00:01,  1.08it/s] 86%|[33m████████▌ [0m| 6/7 [00:05<00:00,  1.10it/s]100%|[33m██████████[0m| 7/7 [00:06<00:00,  1.42it/s]100%|[33m██████████[0m| 7/7 [00:06<00:00,  1.16it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 5/10. Loss: 0.9191:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 5/10. Loss: 0.9191:   4%|[36m▍         [0m| 1/26 [00:00<00:19,  1.26it/s]Epoch: 5/10. Loss: 0.8451:   4%|[36m▍         [0m| 1/26 [00:01<00:19,  1.26it/s]Epoch: 5/10. Loss: 0.8451:   8%|[36m▊         [0m| 2/26 [00:01<00:20,  1.15it/s]Epoch: 5/10. Loss: 0.9142:   8%|[36m▊         [0m| 2/26 [00:02<00:20,  1.15it/s]Epoch: 5/10. Loss: 0.9142:  12%|[36m█▏        [0m| 3/26 [00:02<00:19,  1.17it/s]Epoch: 5/10. Loss: 0.7589:  12%|[36m█▏        [0m| 3/26 [00:03<00:19,  1.17it/s]Epoch: 5/10. Loss: 0.7589:  15%|[36m█▌        [0m| 4/26 [00:03<00:19,  1.13it/s]Epoch: 5/10. Loss: 0.8753:  15%|[36m█▌        [0m| 4/26 [00:04<00:19,  1.13it/s]Epoch: 5/10. Loss: 0.8753:  19%|[36m█▉        [0m| 5/26 [00:04<00:18,  1.11it/s]Epoch: 5/10. Loss: 0.9406:  19%|[36m█▉        [0m| 5/26 [00:05<00:18,  1.11it/s]Epoch: 5/10. Loss: 0.9406:  23%|[36m██▎       [0m| 6/26 [00:05<00:17,  1.12it/s]Epoch: 5/10. Loss: 0.8515:  23%|[36m██▎       [0m| 6/26 [00:06<00:17,  1.12it/s]Epoch: 5/10. Loss: 0.8515:  27%|[36m██▋       [0m| 7/26 [00:06<00:16,  1.17it/s]Epoch: 5/10. Loss: 0.8994:  27%|[36m██▋       [0m| 7/26 [00:06<00:16,  1.17it/s]Epoch: 5/10. Loss: 0.8994:  31%|[36m███       [0m| 8/26 [00:06<00:15,  1.17it/s]Epoch: 5/10. Loss: 0.8303:  31%|[36m███       [0m| 8/26 [00:08<00:15,  1.17it/s]Epoch: 5/10. Loss: 0.8303:  35%|[36m███▍      [0m| 9/26 [00:08<00:15,  1.07it/s]Epoch: 5/10. Loss: 0.8676:  35%|[36m███▍      [0m| 9/26 [00:09<00:15,  1.07it/s]Epoch: 5/10. Loss: 0.8676:  38%|[36m███▊      [0m| 10/26 [00:09<00:15,  1.04it/s]Epoch: 5/10. Loss: 1.0367:  38%|[36m███▊      [0m| 10/26 [00:10<00:15,  1.04it/s]Epoch: 5/10. Loss: 1.0367:  42%|[36m████▏     [0m| 11/26 [00:10<00:14,  1.03it/s]Epoch: 5/10. Loss: 0.8598:  42%|[36m████▏     [0m| 11/26 [00:10<00:14,  1.03it/s]Epoch: 5/10. Loss: 0.8598:  46%|[36m████▌     [0m| 12/26 [00:10<00:13,  1.04it/s]Epoch: 5/10. Loss: 1.0205:  46%|[36m████▌     [0m| 12/26 [00:11<00:13,  1.04it/s]Epoch: 5/10. Loss: 1.0205:  50%|[36m█████     [0m| 13/26 [00:11<00:12,  1.04it/s]Epoch: 5/10. Loss: 0.9927:  50%|[36m█████     [0m| 13/26 [00:12<00:12,  1.04it/s]Epoch: 5/10. Loss: 0.9927:  54%|[36m█████▍    [0m| 14/26 [00:12<00:11,  1.06it/s]Epoch: 5/10. Loss: 0.9380:  54%|[36m█████▍    [0m| 14/26 [00:14<00:11,  1.06it/s]Epoch: 5/10. Loss: 0.9380:  58%|[36m█████▊    [0m| 15/26 [00:14<00:12,  1.17s/it]Epoch: 5/10. Loss: 0.7764:  58%|[36m█████▊    [0m| 15/26 [00:15<00:12,  1.17s/it]Epoch: 5/10. Loss: 0.7764:  62%|[36m██████▏   [0m| 16/26 [00:15<00:11,  1.17s/it]Epoch: 5/10. Loss: 0.8850:  62%|[36m██████▏   [0m| 16/26 [00:16<00:11,  1.17s/it]Epoch: 5/10. Loss: 0.8850:  65%|[36m██████▌   [0m| 17/26 [00:16<00:10,  1.11s/it]Epoch: 5/10. Loss: 0.8337:  65%|[36m██████▌   [0m| 17/26 [00:17<00:10,  1.11s/it]Epoch: 5/10. Loss: 0.8337:  69%|[36m██████▉   [0m| 18/26 [00:17<00:08,  1.06s/it]Epoch: 5/10. Loss: 1.0015:  69%|[36m██████▉   [0m| 18/26 [00:18<00:08,  1.06s/it]Epoch: 5/10. Loss: 1.0015:  73%|[36m███████▎  [0m| 19/26 [00:18<00:07,  1.03s/it]Epoch: 5/10. Loss: 0.8664:  73%|[36m███████▎  [0m| 19/26 [00:19<00:07,  1.03s/it]Epoch: 5/10. Loss: 0.8664:  77%|[36m███████▋  [0m| 20/26 [00:19<00:05,  1.03it/s]Epoch: 5/10. Loss: 0.8535:  77%|[36m███████▋  [0m| 20/26 [00:20<00:05,  1.03it/s]Epoch: 5/10. Loss: 0.8535:  81%|[36m████████  [0m| 21/26 [00:20<00:05,  1.01s/it]Epoch: 5/10. Loss: 0.7926:  81%|[36m████████  [0m| 21/26 [00:21<00:05,  1.01s/it]Epoch: 5/10. Loss: 0.7926:  85%|[36m████████▍ [0m| 22/26 [00:21<00:04,  1.04s/it]Epoch: 5/10. Loss: 0.8810:  85%|[36m████████▍ [0m| 22/26 [00:22<00:04,  1.04s/it]Epoch: 5/10. Loss: 0.8810:  88%|[36m████████▊ [0m| 23/26 [00:22<00:02,  1.01it/s]Epoch: 5/10. Loss: 0.8678:  88%|[36m████████▊ [0m| 23/26 [00:23<00:02,  1.01it/s]Epoch: 5/10. Loss: 0.8678:  92%|[36m█████████▏[0m| 24/26 [00:23<00:02,  1.03s/it]Epoch: 5/10. Loss: 0.8503:  92%|[36m█████████▏[0m| 24/26 [00:24<00:02,  1.03s/it]Epoch: 5/10. Loss: 0.8503:  96%|[36m█████████▌[0m| 25/26 [00:24<00:00,  1.03it/s]Epoch: 5/10. Loss: 1.0044:  96%|[36m█████████▌[0m| 25/26 [00:25<00:00,  1.03it/s]Epoch: 5/10. Loss: 1.0044: 100%|[36m██████████[0m| 26/26 [00:25<00:00,  1.10it/s]Epoch: 5/10. Loss: 1.0044: 100%|[36m██████████[0m| 26/26 [00:25<00:00,  1.03it/s]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:05,  1.07it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:05,  1.10s/it] 43%|[33m████▎     [0m| 3/7 [00:02<00:03,  1.06it/s] 57%|[33m█████▋    [0m| 4/7 [00:04<00:03,  1.16s/it] 71%|[33m███████▏  [0m| 5/7 [00:04<00:01,  1.10it/s] 86%|[33m████████▌ [0m| 6/7 [00:05<00:00,  1.06it/s]100%|[33m██████████[0m| 7/7 [00:06<00:00,  1.38it/s]100%|[33m██████████[0m| 7/7 [00:06<00:00,  1.14it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 6/10. Loss: 0.7925:   0%|[36m          [0m| 0/26 [00:01<?, ?it/s]Epoch: 6/10. Loss: 0.7925:   4%|[36m▍         [0m| 1/26 [00:01<00:26,  1.06s/it]Epoch: 6/10. Loss: 0.9928:   4%|[36m▍         [0m| 1/26 [00:01<00:26,  1.06s/it]Epoch: 6/10. Loss: 0.9928:   8%|[36m▊         [0m| 2/26 [00:01<00:22,  1.07it/s]Epoch: 6/10. Loss: 0.8563:   8%|[36m▊         [0m| 2/26 [00:02<00:22,  1.07it/s]Epoch: 6/10. Loss: 0.8563:  12%|[36m█▏        [0m| 3/26 [00:02<00:21,  1.09it/s]Epoch: 6/10. Loss: 0.8190:  12%|[36m█▏        [0m| 3/26 [00:03<00:21,  1.09it/s]Epoch: 6/10. Loss: 0.8190:  15%|[36m█▌        [0m| 4/26 [00:03<00:20,  1.05it/s]Epoch: 6/10. Loss: 1.0240:  15%|[36m█▌        [0m| 4/26 [00:04<00:20,  1.05it/s]Epoch: 6/10. Loss: 1.0240:  19%|[36m█▉        [0m| 5/26 [00:04<00:21,  1.03s/it]Epoch: 6/10. Loss: 0.8060:  19%|[36m█▉        [0m| 5/26 [00:05<00:21,  1.03s/it]Epoch: 6/10. Loss: 0.8060:  23%|[36m██▎       [0m| 6/26 [00:06<00:20,  1.03s/it]Epoch: 6/10. Loss: 0.8877:  23%|[36m██▎       [0m| 6/26 [00:06<00:20,  1.03s/it]Epoch: 6/10. Loss: 0.8877:  27%|[36m██▋       [0m| 7/26 [00:06<00:18,  1.02it/s]Epoch: 6/10. Loss: 1.0188:  27%|[36m██▋       [0m| 7/26 [00:07<00:18,  1.02it/s]Epoch: 6/10. Loss: 1.0188:  31%|[36m███       [0m| 8/26 [00:07<00:17,  1.00it/s]Epoch: 6/10. Loss: 0.7903:  31%|[36m███       [0m| 8/26 [00:08<00:17,  1.00it/s]Epoch: 6/10. Loss: 0.7903:  35%|[36m███▍      [0m| 9/26 [00:08<00:17,  1.00s/it]Epoch: 6/10. Loss: 0.8158:  35%|[36m███▍      [0m| 9/26 [00:10<00:17,  1.00s/it]Epoch: 6/10. Loss: 0.8158:  38%|[36m███▊      [0m| 10/26 [00:10<00:17,  1.07s/it]Epoch: 6/10. Loss: 0.8876:  38%|[36m███▊      [0m| 10/26 [00:11<00:17,  1.07s/it]Epoch: 6/10. Loss: 0.8876:  42%|[36m████▏     [0m| 11/26 [00:11<00:15,  1.05s/it]Epoch: 6/10. Loss: 0.8941:  42%|[36m████▏     [0m| 11/26 [00:12<00:15,  1.05s/it]Epoch: 6/10. Loss: 0.8941:  46%|[36m████▌     [0m| 12/26 [00:12<00:15,  1.09s/it]Epoch: 6/10. Loss: 0.7659:  46%|[36m████▌     [0m| 12/26 [00:13<00:15,  1.09s/it]Epoch: 6/10. Loss: 0.7659:  50%|[36m█████     [0m| 13/26 [00:13<00:13,  1.03s/it]Epoch: 6/10. Loss: 0.8326:  50%|[36m█████     [0m| 13/26 [00:14<00:13,  1.03s/it]Epoch: 6/10. Loss: 0.8326:  54%|[36m█████▍    [0m| 14/26 [00:14<00:12,  1.01s/it]Epoch: 6/10. Loss: 0.8021:  54%|[36m█████▍    [0m| 14/26 [00:15<00:12,  1.01s/it]Epoch: 6/10. Loss: 0.8021:  58%|[36m█████▊    [0m| 15/26 [00:15<00:10,  1.01it/s]Epoch: 6/10. Loss: 0.9177:  58%|[36m█████▊    [0m| 15/26 [00:16<00:10,  1.01it/s]Epoch: 6/10. Loss: 0.9177:  62%|[36m██████▏   [0m| 16/26 [00:16<00:09,  1.03it/s]Epoch: 6/10. Loss: 0.9253:  62%|[36m██████▏   [0m| 16/26 [00:17<00:09,  1.03it/s]Epoch: 6/10. Loss: 0.9253:  65%|[36m██████▌   [0m| 17/26 [00:17<00:08,  1.03it/s]Epoch: 6/10. Loss: 0.8257:  65%|[36m██████▌   [0m| 17/26 [00:18<00:08,  1.03it/s]Epoch: 6/10. Loss: 0.8257:  69%|[36m██████▉   [0m| 18/26 [00:18<00:07,  1.01it/s]Epoch: 6/10. Loss: 0.8726:  69%|[36m██████▉   [0m| 18/26 [00:18<00:07,  1.01it/s]Epoch: 6/10. Loss: 0.8726:  73%|[36m███████▎  [0m| 19/26 [00:18<00:06,  1.08it/s]Epoch: 6/10. Loss: 1.0165:  73%|[36m███████▎  [0m| 19/26 [00:19<00:06,  1.08it/s]Epoch: 6/10. Loss: 1.0165:  77%|[36m███████▋  [0m| 20/26 [00:19<00:05,  1.04it/s]Epoch: 6/10. Loss: 0.8660:  77%|[36m███████▋  [0m| 20/26 [00:20<00:05,  1.04it/s]Epoch: 6/10. Loss: 0.8660:  81%|[36m████████  [0m| 21/26 [00:20<00:04,  1.01it/s]Epoch: 6/10. Loss: 0.8850:  81%|[36m████████  [0m| 21/26 [00:21<00:04,  1.01it/s]Epoch: 6/10. Loss: 0.8850:  85%|[36m████████▍ [0m| 22/26 [00:21<00:03,  1.07it/s]Epoch: 6/10. Loss: 0.8873:  85%|[36m████████▍ [0m| 22/26 [00:22<00:03,  1.07it/s]Epoch: 6/10. Loss: 0.8873:  88%|[36m████████▊ [0m| 23/26 [00:22<00:02,  1.09it/s]Epoch: 6/10. Loss: 0.8051:  88%|[36m████████▊ [0m| 23/26 [00:23<00:02,  1.09it/s]Epoch: 6/10. Loss: 0.8051:  92%|[36m█████████▏[0m| 24/26 [00:23<00:01,  1.09it/s]Epoch: 6/10. Loss: 0.8613:  92%|[36m█████████▏[0m| 24/26 [00:24<00:01,  1.09it/s]Epoch: 6/10. Loss: 0.8613:  96%|[36m█████████▌[0m| 25/26 [00:24<00:00,  1.02it/s]Epoch: 6/10. Loss: 0.8640:  96%|[36m█████████▌[0m| 25/26 [00:25<00:00,  1.02it/s]Epoch: 6/10. Loss: 0.8640: 100%|[36m██████████[0m| 26/26 [00:25<00:00,  1.09it/s]Epoch: 6/10. Loss: 0.8640: 100%|[36m██████████[0m| 26/26 [00:25<00:00,  1.02it/s]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:05,  1.06it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:06,  1.35s/it] 43%|[33m████▎     [0m| 3/7 [00:03<00:04,  1.13s/it] 57%|[33m█████▋    [0m| 4/7 [00:04<00:03,  1.25s/it] 71%|[33m███████▏  [0m| 5/7 [00:05<00:01,  1.04it/s] 86%|[33m████████▌ [0m| 6/7 [00:06<00:01,  1.05s/it]100%|[33m██████████[0m| 7/7 [00:06<00:00,  1.25it/s]100%|[33m██████████[0m| 7/7 [00:06<00:00,  1.03it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 7/10. Loss: 0.9097:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 7/10. Loss: 0.9097:   4%|[36m▍         [0m| 1/26 [00:01<00:25,  1.01s/it]Epoch: 7/10. Loss: 0.8614:   4%|[36m▍         [0m| 1/26 [00:01<00:25,  1.01s/it]Epoch: 7/10. Loss: 0.8614:   8%|[36m▊         [0m| 2/26 [00:02<00:24,  1.02s/it]Epoch: 7/10. Loss: 0.8354:   8%|[36m▊         [0m| 2/26 [00:03<00:24,  1.02s/it]Epoch: 7/10. Loss: 0.8354:  12%|[36m█▏        [0m| 3/26 [00:03<00:30,  1.31s/it]Epoch: 7/10. Loss: 0.7766:  12%|[36m█▏        [0m| 3/26 [00:04<00:30,  1.31s/it]Epoch: 7/10. Loss: 0.7766:  15%|[36m█▌        [0m| 4/26 [00:04<00:24,  1.13s/it]Epoch: 7/10. Loss: 1.0663:  15%|[36m█▌        [0m| 4/26 [00:05<00:24,  1.13s/it]Epoch: 7/10. Loss: 1.0663:  19%|[36m█▉        [0m| 5/26 [00:05<00:22,  1.08s/it]Epoch: 7/10. Loss: 0.9133:  19%|[36m█▉        [0m| 5/26 [00:06<00:22,  1.08s/it]Epoch: 7/10. Loss: 0.9133:  23%|[36m██▎       [0m| 6/26 [00:06<00:20,  1.04s/it]Epoch: 7/10. Loss: 0.7837:  23%|[36m██▎       [0m| 6/26 [00:07<00:20,  1.04s/it]Epoch: 7/10. Loss: 0.7837:  27%|[36m██▋       [0m| 7/26 [00:07<00:19,  1.03s/it]Epoch: 7/10. Loss: 0.9118:  27%|[36m██▋       [0m| 7/26 [00:08<00:19,  1.03s/it]Epoch: 7/10. Loss: 0.9118:  31%|[36m███       [0m| 8/26 [00:08<00:17,  1.02it/s]Epoch: 7/10. Loss: 0.9421:  31%|[36m███       [0m| 8/26 [00:09<00:17,  1.02it/s]Epoch: 7/10. Loss: 0.9421:  35%|[36m███▍      [0m| 9/26 [00:09<00:16,  1.02it/s]Epoch: 7/10. Loss: 0.8485:  35%|[36m███▍      [0m| 9/26 [00:10<00:16,  1.02it/s]Epoch: 7/10. Loss: 0.8485:  38%|[36m███▊      [0m| 10/26 [00:10<00:15,  1.03it/s]Epoch: 7/10. Loss: 0.7346:  38%|[36m███▊      [0m| 10/26 [00:11<00:15,  1.03it/s]Epoch: 7/10. Loss: 0.7346:  42%|[36m████▏     [0m| 11/26 [00:11<00:15,  1.03s/it]Epoch: 7/10. Loss: 0.8758:  42%|[36m████▏     [0m| 11/26 [00:12<00:15,  1.03s/it]Epoch: 7/10. Loss: 0.8758:  46%|[36m████▌     [0m| 12/26 [00:12<00:14,  1.02s/it]Epoch: 7/10. Loss: 0.8946:  46%|[36m████▌     [0m| 12/26 [00:13<00:14,  1.02s/it]Epoch: 7/10. Loss: 0.8946:  50%|[36m█████     [0m| 13/26 [00:13<00:12,  1.02it/s]Epoch: 7/10. Loss: 0.9544:  50%|[36m█████     [0m| 13/26 [00:14<00:12,  1.02it/s]Epoch: 7/10. Loss: 0.9544:  54%|[36m█████▍    [0m| 14/26 [00:14<00:12,  1.06s/it]Epoch: 7/10. Loss: 0.8780:  54%|[36m█████▍    [0m| 14/26 [00:15<00:12,  1.06s/it]Epoch: 7/10. Loss: 0.8780:  58%|[36m█████▊    [0m| 15/26 [00:15<00:11,  1.01s/it]Epoch: 7/10. Loss: 0.8692:  58%|[36m█████▊    [0m| 15/26 [00:18<00:11,  1.01s/it]Epoch: 7/10. Loss: 0.8692:  62%|[36m██████▏   [0m| 16/26 [00:18<00:16,  1.65s/it]Epoch: 7/10. Loss: 0.8514:  62%|[36m██████▏   [0m| 16/26 [00:19<00:16,  1.65s/it]Epoch: 7/10. Loss: 0.8514:  65%|[36m██████▌   [0m| 17/26 [00:19<00:12,  1.44s/it]Epoch: 7/10. Loss: 0.9568:  65%|[36m██████▌   [0m| 17/26 [00:20<00:12,  1.44s/it]Epoch: 7/10. Loss: 0.9568:  69%|[36m██████▉   [0m| 18/26 [00:20<00:10,  1.26s/it]Epoch: 7/10. Loss: 0.9360:  69%|[36m██████▉   [0m| 18/26 [00:21<00:10,  1.26s/it]Epoch: 7/10. Loss: 0.9360:  73%|[36m███████▎  [0m| 19/26 [00:21<00:07,  1.13s/it]Epoch: 7/10. Loss: 0.8734:  73%|[36m███████▎  [0m| 19/26 [00:22<00:07,  1.13s/it]Epoch: 7/10. Loss: 0.8734:  77%|[36m███████▋  [0m| 20/26 [00:22<00:06,  1.08s/it]Epoch: 7/10. Loss: 0.8152:  77%|[36m███████▋  [0m| 20/26 [00:23<00:06,  1.08s/it]Epoch: 7/10. Loss: 0.8152:  81%|[36m████████  [0m| 21/26 [00:23<00:05,  1.03s/it]Epoch: 7/10. Loss: 1.0427:  81%|[36m████████  [0m| 21/26 [00:23<00:05,  1.03s/it]Epoch: 7/10. Loss: 1.0427:  85%|[36m████████▍ [0m| 22/26 [00:24<00:03,  1.01it/s]Epoch: 7/10. Loss: 0.9260:  85%|[36m████████▍ [0m| 22/26 [00:25<00:03,  1.01it/s]Epoch: 7/10. Loss: 0.9260:  88%|[36m████████▊ [0m| 23/26 [00:25<00:03,  1.02s/it]Epoch: 7/10. Loss: 0.9546:  88%|[36m████████▊ [0m| 23/26 [00:26<00:03,  1.02s/it]Epoch: 7/10. Loss: 0.9546:  92%|[36m█████████▏[0m| 24/26 [00:26<00:02,  1.01s/it]Epoch: 7/10. Loss: 0.7906:  92%|[36m█████████▏[0m| 24/26 [00:27<00:02,  1.01s/it]Epoch: 7/10. Loss: 0.7906:  96%|[36m█████████▌[0m| 25/26 [00:27<00:01,  1.00s/it]Epoch: 7/10. Loss: 0.8725:  96%|[36m█████████▌[0m| 25/26 [00:27<00:01,  1.00s/it]Epoch: 7/10. Loss: 0.8725: 100%|[36m██████████[0m| 26/26 [00:27<00:00,  1.10it/s]Epoch: 7/10. Loss: 0.8725: 100%|[36m██████████[0m| 26/26 [00:27<00:00,  1.07s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:05,  1.02it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:05,  1.15s/it] 43%|[33m████▎     [0m| 3/7 [00:03<00:03,  1.01it/s] 57%|[33m█████▋    [0m| 4/7 [00:04<00:03,  1.18s/it] 71%|[33m███████▏  [0m| 5/7 [00:05<00:01,  1.07it/s] 86%|[33m████████▌ [0m| 6/7 [00:05<00:00,  1.09it/s]100%|[33m██████████[0m| 7/7 [00:06<00:00,  1.41it/s]100%|[33m██████████[0m| 7/7 [00:06<00:00,  1.13it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 8/10. Loss: 0.8973:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 8/10. Loss: 0.8973:   4%|[36m▍         [0m| 1/26 [00:00<00:24,  1.03it/s]Epoch: 8/10. Loss: 0.9746:   4%|[36m▍         [0m| 1/26 [00:02<00:24,  1.03it/s]Epoch: 8/10. Loss: 0.9746:   8%|[36m▊         [0m| 2/26 [00:02<00:35,  1.49s/it]Epoch: 8/10. Loss: 0.8996:   8%|[36m▊         [0m| 2/26 [00:03<00:35,  1.49s/it]Epoch: 8/10. Loss: 0.8996:  12%|[36m█▏        [0m| 3/26 [00:03<00:30,  1.33s/it]Epoch: 8/10. Loss: 0.7078:  12%|[36m█▏        [0m| 3/26 [00:04<00:30,  1.33s/it]Epoch: 8/10. Loss: 0.7078:  15%|[36m█▌        [0m| 4/26 [00:04<00:25,  1.15s/it]Epoch: 8/10. Loss: 0.9272:  15%|[36m█▌        [0m| 4/26 [00:05<00:25,  1.15s/it]Epoch: 8/10. Loss: 0.9272:  19%|[36m█▉        [0m| 5/26 [00:05<00:24,  1.15s/it]Epoch: 8/10. Loss: 0.9487:  19%|[36m█▉        [0m| 5/26 [00:06<00:24,  1.15s/it]Epoch: 8/10. Loss: 0.9487:  23%|[36m██▎       [0m| 6/26 [00:06<00:21,  1.08s/it]Epoch: 8/10. Loss: 0.9665:  23%|[36m██▎       [0m| 6/26 [00:07<00:21,  1.08s/it]Epoch: 8/10. Loss: 0.9665:  27%|[36m██▋       [0m| 7/26 [00:07<00:18,  1.00it/s]Epoch: 8/10. Loss: 0.9127:  27%|[36m██▋       [0m| 7/26 [00:08<00:18,  1.00it/s]Epoch: 8/10. Loss: 0.9127:  31%|[36m███       [0m| 8/26 [00:08<00:18,  1.01s/it]Epoch: 8/10. Loss: 0.9242:  31%|[36m███       [0m| 8/26 [00:09<00:18,  1.01s/it]Epoch: 8/10. Loss: 0.9242:  35%|[36m███▍      [0m| 9/26 [00:09<00:17,  1.04s/it]Epoch: 8/10. Loss: 0.8530:  35%|[36m███▍      [0m| 9/26 [00:10<00:17,  1.04s/it]Epoch: 8/10. Loss: 0.8530:  38%|[36m███▊      [0m| 10/26 [00:10<00:15,  1.01it/s]Epoch: 8/10. Loss: 0.8785:  38%|[36m███▊      [0m| 10/26 [00:11<00:15,  1.01it/s]Epoch: 8/10. Loss: 0.8785:  42%|[36m████▏     [0m| 11/26 [00:11<00:15,  1.01s/it]Epoch: 8/10. Loss: 0.7899:  42%|[36m████▏     [0m| 11/26 [00:12<00:15,  1.01s/it]Epoch: 8/10. Loss: 0.7899:  46%|[36m████▌     [0m| 12/26 [00:12<00:14,  1.04s/it]Epoch: 8/10. Loss: 0.8107:  46%|[36m████▌     [0m| 12/26 [00:13<00:14,  1.04s/it]Epoch: 8/10. Loss: 0.8107:  50%|[36m█████     [0m| 13/26 [00:13<00:13,  1.01s/it]Epoch: 8/10. Loss: 0.8059:  50%|[36m█████     [0m| 13/26 [00:16<00:13,  1.01s/it]Epoch: 8/10. Loss: 0.8059:  54%|[36m█████▍    [0m| 14/26 [00:16<00:16,  1.39s/it]Epoch: 8/10. Loss: 0.7315:  54%|[36m█████▍    [0m| 14/26 [00:17<00:16,  1.39s/it]Epoch: 8/10. Loss: 0.7315:  58%|[36m█████▊    [0m| 15/26 [00:17<00:14,  1.27s/it]Epoch: 8/10. Loss: 0.8665:  58%|[36m█████▊    [0m| 15/26 [00:17<00:14,  1.27s/it]Epoch: 8/10. Loss: 0.8665:  62%|[36m██████▏   [0m| 16/26 [00:17<00:11,  1.14s/it]Epoch: 8/10. Loss: 0.8480:  62%|[36m██████▏   [0m| 16/26 [00:19<00:11,  1.14s/it]Epoch: 8/10. Loss: 0.8480:  65%|[36m██████▌   [0m| 17/26 [00:19<00:10,  1.13s/it]Epoch: 8/10. Loss: 0.8168:  65%|[36m██████▌   [0m| 17/26 [00:19<00:10,  1.13s/it]Epoch: 8/10. Loss: 0.8168:  69%|[36m██████▉   [0m| 18/26 [00:19<00:08,  1.02s/it]Epoch: 8/10. Loss: 0.7965:  69%|[36m██████▉   [0m| 18/26 [00:20<00:08,  1.02s/it]Epoch: 8/10. Loss: 0.7965:  73%|[36m███████▎  [0m| 19/26 [00:20<00:07,  1.04s/it]Epoch: 8/10. Loss: 0.9750:  73%|[36m███████▎  [0m| 19/26 [00:21<00:07,  1.04s/it]Epoch: 8/10. Loss: 0.9750:  77%|[36m███████▋  [0m| 20/26 [00:21<00:06,  1.03s/it]Epoch: 8/10. Loss: 0.9078:  77%|[36m███████▋  [0m| 20/26 [00:22<00:06,  1.03s/it]Epoch: 8/10. Loss: 0.9078:  81%|[36m████████  [0m| 21/26 [00:22<00:04,  1.02it/s]Epoch: 8/10. Loss: 0.9033:  81%|[36m████████  [0m| 21/26 [00:23<00:04,  1.02it/s]Epoch: 8/10. Loss: 0.9033:  85%|[36m████████▍ [0m| 22/26 [00:23<00:04,  1.03s/it]Epoch: 8/10. Loss: 0.9172:  85%|[36m████████▍ [0m| 22/26 [00:24<00:04,  1.03s/it]Epoch: 8/10. Loss: 0.9172:  88%|[36m████████▊ [0m| 23/26 [00:24<00:02,  1.00it/s]Epoch: 8/10. Loss: 0.7435:  88%|[36m████████▊ [0m| 23/26 [00:25<00:02,  1.00it/s]Epoch: 8/10. Loss: 0.7435:  92%|[36m█████████▏[0m| 24/26 [00:25<00:01,  1.00it/s]Epoch: 8/10. Loss: 0.8747:  92%|[36m█████████▏[0m| 24/26 [00:26<00:01,  1.00it/s]Epoch: 8/10. Loss: 0.8747:  96%|[36m█████████▌[0m| 25/26 [00:26<00:00,  1.01it/s]Epoch: 8/10. Loss: 0.8356:  96%|[36m█████████▌[0m| 25/26 [00:27<00:00,  1.01it/s]Epoch: 8/10. Loss: 0.8356: 100%|[36m██████████[0m| 26/26 [00:27<00:00,  1.16it/s]Epoch: 8/10. Loss: 0.8356: 100%|[36m██████████[0m| 26/26 [00:27<00:00,  1.05s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:01<00:06,  1.01s/it] 29%|[33m██▊       [0m| 2/7 [00:02<00:05,  1.19s/it] 43%|[33m████▎     [0m| 3/7 [00:03<00:04,  1.01s/it] 57%|[33m█████▋    [0m| 4/7 [00:04<00:03,  1.19s/it] 71%|[33m███████▏  [0m| 5/7 [00:05<00:01,  1.08it/s] 86%|[33m████████▌ [0m| 6/7 [00:05<00:00,  1.10it/s]100%|[33m██████████[0m| 7/7 [00:06<00:00,  1.46it/s]100%|[33m██████████[0m| 7/7 [00:06<00:00,  1.14it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 9/10. Loss: 0.8425:   0%|[36m          [0m| 0/26 [00:01<?, ?it/s]Epoch: 9/10. Loss: 0.8425:   4%|[36m▍         [0m| 1/26 [00:01<00:26,  1.07s/it]Epoch: 9/10. Loss: 0.8483:   4%|[36m▍         [0m| 1/26 [00:01<00:26,  1.07s/it]Epoch: 9/10. Loss: 0.8483:   8%|[36m▊         [0m| 2/26 [00:01<00:22,  1.06it/s]Epoch: 9/10. Loss: 0.7824:   8%|[36m▊         [0m| 2/26 [00:02<00:22,  1.06it/s]Epoch: 9/10. Loss: 0.7824:  12%|[36m█▏        [0m| 3/26 [00:02<00:22,  1.03it/s]Epoch: 9/10. Loss: 0.7563:  12%|[36m█▏        [0m| 3/26 [00:03<00:22,  1.03it/s]Epoch: 9/10. Loss: 0.7563:  15%|[36m█▌        [0m| 4/26 [00:03<00:19,  1.13it/s]Epoch: 9/10. Loss: 0.8168:  15%|[36m█▌        [0m| 4/26 [00:04<00:19,  1.13it/s]Epoch: 9/10. Loss: 0.8168:  19%|[36m█▉        [0m| 5/26 [00:04<00:20,  1.01it/s]Epoch: 9/10. Loss: 0.7858:  19%|[36m█▉        [0m| 5/26 [00:05<00:20,  1.01it/s]Epoch: 9/10. Loss: 0.7858:  23%|[36m██▎       [0m| 6/26 [00:05<00:20,  1.02s/it]Epoch: 9/10. Loss: 0.7104:  23%|[36m██▎       [0m| 6/26 [00:07<00:20,  1.02s/it]Epoch: 9/10. Loss: 0.7104:  27%|[36m██▋       [0m| 7/26 [00:07<00:19,  1.05s/it]Epoch: 9/10. Loss: 0.8104:  27%|[36m██▋       [0m| 7/26 [00:07<00:19,  1.05s/it]Epoch: 9/10. Loss: 0.8104:  31%|[36m███       [0m| 8/26 [00:07<00:18,  1.00s/it]Epoch: 9/10. Loss: 0.7613:  31%|[36m███       [0m| 8/26 [00:08<00:18,  1.00s/it]Epoch: 9/10. Loss: 0.7613:  35%|[36m███▍      [0m| 9/26 [00:08<00:16,  1.01it/s]Epoch: 9/10. Loss: 0.7243:  35%|[36m███▍      [0m| 9/26 [00:09<00:16,  1.01it/s]Epoch: 9/10. Loss: 0.7243:  38%|[36m███▊      [0m| 10/26 [00:09<00:15,  1.05it/s]Epoch: 9/10. Loss: 0.8845:  38%|[36m███▊      [0m| 10/26 [00:10<00:15,  1.05it/s]Epoch: 9/10. Loss: 0.8845:  42%|[36m████▏     [0m| 11/26 [00:10<00:14,  1.07it/s]Epoch: 9/10. Loss: 0.8049:  42%|[36m████▏     [0m| 11/26 [00:11<00:14,  1.07it/s]Epoch: 9/10. Loss: 0.8049:  46%|[36m████▌     [0m| 12/26 [00:11<00:12,  1.10it/s]Epoch: 9/10. Loss: 0.8995:  46%|[36m████▌     [0m| 12/26 [00:13<00:12,  1.10it/s]Epoch: 9/10. Loss: 0.8995:  50%|[36m█████     [0m| 13/26 [00:13<00:17,  1.33s/it]Epoch: 9/10. Loss: 0.9017:  50%|[36m█████     [0m| 13/26 [00:14<00:17,  1.33s/it]Epoch: 9/10. Loss: 0.9017:  54%|[36m█████▍    [0m| 14/26 [00:14<00:14,  1.20s/it]Epoch: 9/10. Loss: 0.7917:  54%|[36m█████▍    [0m| 14/26 [00:15<00:14,  1.20s/it]Epoch: 9/10. Loss: 0.7917:  58%|[36m█████▊    [0m| 15/26 [00:15<00:12,  1.10s/it]Epoch: 9/10. Loss: 0.7520:  58%|[36m█████▊    [0m| 15/26 [00:16<00:12,  1.10s/it]Epoch: 9/10. Loss: 0.7520:  62%|[36m██████▏   [0m| 16/26 [00:16<00:11,  1.20s/it]Epoch: 9/10. Loss: 0.7786:  62%|[36m██████▏   [0m| 16/26 [00:17<00:11,  1.20s/it]Epoch: 9/10. Loss: 0.7786:  65%|[36m██████▌   [0m| 17/26 [00:17<00:10,  1.13s/it]Epoch: 9/10. Loss: 0.8447:  65%|[36m██████▌   [0m| 17/26 [00:18<00:10,  1.13s/it]Epoch: 9/10. Loss: 0.8447:  69%|[36m██████▉   [0m| 18/26 [00:18<00:08,  1.07s/it]Epoch: 9/10. Loss: 0.8528:  69%|[36m██████▉   [0m| 18/26 [00:19<00:08,  1.07s/it]Epoch: 9/10. Loss: 0.8528:  73%|[36m███████▎  [0m| 19/26 [00:19<00:07,  1.05s/it]Epoch: 9/10. Loss: 0.7488:  73%|[36m███████▎  [0m| 19/26 [00:20<00:07,  1.05s/it]Epoch: 9/10. Loss: 0.7488:  77%|[36m███████▋  [0m| 20/26 [00:20<00:06,  1.00s/it]Epoch: 9/10. Loss: 0.7221:  77%|[36m███████▋  [0m| 20/26 [00:21<00:06,  1.00s/it]Epoch: 9/10. Loss: 0.7221:  81%|[36m████████  [0m| 21/26 [00:21<00:05,  1.04s/it]Epoch: 9/10. Loss: 0.8651:  81%|[36m████████  [0m| 21/26 [00:22<00:05,  1.04s/it]Epoch: 9/10. Loss: 0.8651:  85%|[36m████████▍ [0m| 22/26 [00:22<00:03,  1.04it/s]Epoch: 9/10. Loss: 0.7959:  85%|[36m████████▍ [0m| 22/26 [00:23<00:03,  1.04it/s]Epoch: 9/10. Loss: 0.7959:  88%|[36m████████▊ [0m| 23/26 [00:23<00:02,  1.05it/s]Epoch: 9/10. Loss: 0.8662:  88%|[36m████████▊ [0m| 23/26 [00:24<00:02,  1.05it/s]Epoch: 9/10. Loss: 0.8662:  92%|[36m█████████▏[0m| 24/26 [00:24<00:01,  1.09it/s]Epoch: 9/10. Loss: 0.8179:  92%|[36m█████████▏[0m| 24/26 [00:25<00:01,  1.09it/s]Epoch: 9/10. Loss: 0.8179:  96%|[36m█████████▌[0m| 25/26 [00:25<00:00,  1.01it/s]Epoch: 9/10. Loss: 0.7097:  96%|[36m█████████▌[0m| 25/26 [00:26<00:00,  1.01it/s]Epoch: 9/10. Loss: 0.7097: 100%|[36m██████████[0m| 26/26 [00:26<00:00,  1.06it/s]Epoch: 9/10. Loss: 0.7097: 100%|[36m██████████[0m| 26/26 [00:26<00:00,  1.02s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:05,  1.03it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:05,  1.17s/it] 43%|[33m████▎     [0m| 3/7 [00:03<00:04,  1.16s/it] 57%|[33m█████▋    [0m| 4/7 [00:05<00:04,  1.36s/it] 71%|[33m███████▏  [0m| 5/7 [00:05<00:02,  1.03s/it] 86%|[33m████████▌ [0m| 6/7 [00:06<00:01,  1.01s/it]100%|[33m██████████[0m| 7/7 [00:06<00:00,  1.32it/s]100%|[33m██████████[0m| 7/7 [00:06<00:00,  1.04it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 0/10. Loss: 1.1029:   0%|[36m          [0m| 0/26 [00:01<?, ?it/s]Epoch: 0/10. Loss: 1.1029:   4%|[36m▍         [0m| 1/26 [00:01<00:30,  1.21s/it]Epoch: 0/10. Loss: 2.3279:   4%|[36m▍         [0m| 1/26 [00:02<00:30,  1.21s/it]Epoch: 0/10. Loss: 2.3279:   8%|[36m▊         [0m| 2/26 [00:02<00:25,  1.08s/it]Epoch: 0/10. Loss: 2.1047:   8%|[36m▊         [0m| 2/26 [00:03<00:25,  1.08s/it]Epoch: 0/10. Loss: 2.1047:  12%|[36m█▏        [0m| 3/26 [00:03<00:22,  1.02it/s]Epoch: 0/10. Loss: 2.8188:  12%|[36m█▏        [0m| 3/26 [00:03<00:22,  1.02it/s]Epoch: 0/10. Loss: 2.8188:  15%|[36m█▌        [0m| 4/26 [00:03<00:21,  1.05it/s]Epoch: 0/10. Loss: 1.7614:  15%|[36m█▌        [0m| 4/26 [00:04<00:21,  1.05it/s]Epoch: 0/10. Loss: 1.7614:  19%|[36m█▉        [0m| 5/26 [00:04<00:18,  1.12it/s]Epoch: 0/10. Loss: 1.7245:  19%|[36m█▉        [0m| 5/26 [00:05<00:18,  1.12it/s]Epoch: 0/10. Loss: 1.7245:  23%|[36m██▎       [0m| 6/26 [00:05<00:18,  1.10it/s]Epoch: 0/10. Loss: 2.0913:  23%|[36m██▎       [0m| 6/26 [00:06<00:18,  1.10it/s]Epoch: 0/10. Loss: 2.0913:  27%|[36m██▋       [0m| 7/26 [00:06<00:16,  1.13it/s]Epoch: 0/10. Loss: 1.5910:  27%|[36m██▋       [0m| 7/26 [00:07<00:16,  1.13it/s]Epoch: 0/10. Loss: 1.5910:  31%|[36m███       [0m| 8/26 [00:07<00:16,  1.09it/s]Epoch: 0/10. Loss: 1.1858:  31%|[36m███       [0m| 8/26 [00:08<00:16,  1.09it/s]Epoch: 0/10. Loss: 1.1858:  35%|[36m███▍      [0m| 9/26 [00:08<00:15,  1.12it/s]Epoch: 0/10. Loss: 1.1327:  35%|[36m███▍      [0m| 9/26 [00:09<00:15,  1.12it/s]Epoch: 0/10. Loss: 1.1327:  38%|[36m███▊      [0m| 10/26 [00:09<00:14,  1.07it/s]Epoch: 0/10. Loss: 1.1331:  38%|[36m███▊      [0m| 10/26 [00:10<00:14,  1.07it/s]Epoch: 0/10. Loss: 1.1331:  42%|[36m████▏     [0m| 11/26 [00:10<00:13,  1.09it/s]Epoch: 0/10. Loss: 1.2410:  42%|[36m████▏     [0m| 11/26 [00:11<00:13,  1.09it/s]Epoch: 0/10. Loss: 1.2410:  46%|[36m████▌     [0m| 12/26 [00:11<00:12,  1.09it/s]Epoch: 0/10. Loss: 1.2256:  46%|[36m████▌     [0m| 12/26 [00:12<00:12,  1.09it/s]Epoch: 0/10. Loss: 1.2256:  50%|[36m█████     [0m| 13/26 [00:12<00:12,  1.05it/s]Epoch: 0/10. Loss: 1.0588:  50%|[36m█████     [0m| 13/26 [00:13<00:12,  1.05it/s]Epoch: 0/10. Loss: 1.0588:  54%|[36m█████▍    [0m| 14/26 [00:13<00:11,  1.02it/s]Epoch: 0/10. Loss: 1.1433:  54%|[36m█████▍    [0m| 14/26 [00:14<00:11,  1.02it/s]Epoch: 0/10. Loss: 1.1433:  58%|[36m█████▊    [0m| 15/26 [00:14<00:11,  1.00s/it]Epoch: 0/10. Loss: 1.1651:  58%|[36m█████▊    [0m| 15/26 [00:15<00:11,  1.00s/it]Epoch: 0/10. Loss: 1.1651:  62%|[36m██████▏   [0m| 16/26 [00:15<00:09,  1.06it/s]Epoch: 0/10. Loss: 1.0117:  62%|[36m██████▏   [0m| 16/26 [00:15<00:09,  1.06it/s]Epoch: 0/10. Loss: 1.0117:  65%|[36m██████▌   [0m| 17/26 [00:15<00:07,  1.13it/s]Epoch: 0/10. Loss: 1.0899:  65%|[36m██████▌   [0m| 17/26 [00:16<00:07,  1.13it/s]Epoch: 0/10. Loss: 1.0899:  69%|[36m██████▉   [0m| 18/26 [00:16<00:07,  1.11it/s]Epoch: 0/10. Loss: 0.9936:  69%|[36m██████▉   [0m| 18/26 [00:17<00:07,  1.11it/s]Epoch: 0/10. Loss: 0.9936:  73%|[36m███████▎  [0m| 19/26 [00:17<00:06,  1.03it/s]Epoch: 0/10. Loss: 1.1167:  73%|[36m███████▎  [0m| 19/26 [00:18<00:06,  1.03it/s]Epoch: 0/10. Loss: 1.1167:  77%|[36m███████▋  [0m| 20/26 [00:18<00:05,  1.03it/s]Epoch: 0/10. Loss: 1.0595:  77%|[36m███████▋  [0m| 20/26 [00:20<00:05,  1.03it/s]Epoch: 0/10. Loss: 1.0595:  81%|[36m████████  [0m| 21/26 [00:20<00:06,  1.22s/it]Epoch: 0/10. Loss: 0.9513:  81%|[36m████████  [0m| 21/26 [00:21<00:06,  1.22s/it]Epoch: 0/10. Loss: 0.9513:  85%|[36m████████▍ [0m| 22/26 [00:21<00:04,  1.09s/it]Epoch: 0/10. Loss: 1.0594:  85%|[36m████████▍ [0m| 22/26 [00:23<00:04,  1.09s/it]Epoch: 0/10. Loss: 1.0594:  88%|[36m████████▊ [0m| 23/26 [00:23<00:03,  1.24s/it]Epoch: 0/10. Loss: 1.0762:  88%|[36m████████▊ [0m| 23/26 [00:25<00:03,  1.24s/it]Epoch: 0/10. Loss: 1.0762:  92%|[36m█████████▏[0m| 24/26 [00:25<00:03,  1.63s/it]Epoch: 0/10. Loss: 1.0405:  92%|[36m█████████▏[0m| 24/26 [00:26<00:03,  1.63s/it]Epoch: 0/10. Loss: 1.0405:  96%|[36m█████████▌[0m| 25/26 [00:26<00:01,  1.37s/it]Epoch: 0/10. Loss: 1.0703:  96%|[36m█████████▌[0m| 25/26 [00:27<00:01,  1.37s/it]Epoch: 0/10. Loss: 1.0703: 100%|[36m██████████[0m| 26/26 [00:27<00:00,  1.16s/it]Epoch: 0/10. Loss: 1.0703: 100%|[36m██████████[0m| 26/26 [00:27<00:00,  1.04s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:01<00:06,  1.11s/it] 29%|[33m██▊       [0m| 2/7 [00:03<00:08,  1.68s/it] 43%|[33m████▎     [0m| 3/7 [00:04<00:05,  1.37s/it] 57%|[33m█████▋    [0m| 4/7 [00:05<00:04,  1.34s/it] 71%|[33m███████▏  [0m| 5/7 [00:05<00:01,  1.02it/s] 86%|[33m████████▌ [0m| 6/7 [00:06<00:00,  1.09it/s]100%|[33m██████████[0m| 7/7 [00:07<00:00,  1.01it/s]100%|[33m██████████[0m| 7/7 [00:07<00:00,  1.11s/it]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 1/10. Loss: 1.0071:   0%|[36m          [0m| 0/26 [00:02<?, ?it/s]Epoch: 1/10. Loss: 1.0071:   4%|[36m▍         [0m| 1/26 [00:02<00:59,  2.38s/it]Epoch: 1/10. Loss: 1.2055:   4%|[36m▍         [0m| 1/26 [00:03<00:59,  2.38s/it]Epoch: 1/10. Loss: 1.2055:   8%|[36m▊         [0m| 2/26 [00:03<00:37,  1.57s/it]Epoch: 1/10. Loss: 1.0321:   8%|[36m▊         [0m| 2/26 [00:04<00:37,  1.57s/it]Epoch: 1/10. Loss: 1.0321:  12%|[36m█▏        [0m| 3/26 [00:04<00:28,  1.25s/it]Epoch: 1/10. Loss: 1.0910:  12%|[36m█▏        [0m| 3/26 [00:05<00:28,  1.25s/it]Epoch: 1/10. Loss: 1.0910:  15%|[36m█▌        [0m| 4/26 [00:05<00:25,  1.15s/it]Epoch: 1/10. Loss: 1.2962:  15%|[36m█▌        [0m| 4/26 [00:06<00:25,  1.15s/it]Epoch: 1/10. Loss: 1.2962:  19%|[36m█▉        [0m| 5/26 [00:06<00:22,  1.07s/it]Epoch: 1/10. Loss: 1.0619:  19%|[36m█▉        [0m| 5/26 [00:07<00:22,  1.07s/it]Epoch: 1/10. Loss: 1.0619:  23%|[36m██▎       [0m| 6/26 [00:07<00:20,  1.01s/it]Epoch: 1/10. Loss: 1.1349:  23%|[36m██▎       [0m| 6/26 [00:07<00:20,  1.01s/it]Epoch: 1/10. Loss: 1.1349:  27%|[36m██▋       [0m| 7/26 [00:07<00:18,  1.04it/s]Epoch: 1/10. Loss: 1.0882:  27%|[36m██▋       [0m| 7/26 [00:09<00:18,  1.04it/s]Epoch: 1/10. Loss: 1.0882:  31%|[36m███       [0m| 8/26 [00:09<00:19,  1.07s/it]Epoch: 1/10. Loss: 1.1170:  31%|[36m███       [0m| 8/26 [00:10<00:19,  1.07s/it]Epoch: 1/10. Loss: 1.1170:  35%|[36m███▍      [0m| 9/26 [00:10<00:17,  1.04s/it]Epoch: 1/10. Loss: 1.0814:  35%|[36m███▍      [0m| 9/26 [00:13<00:17,  1.04s/it]Epoch: 1/10. Loss: 1.0814:  38%|[36m███▊      [0m| 10/26 [00:13<00:28,  1.81s/it]Epoch: 1/10. Loss: 1.0515:  38%|[36m███▊      [0m| 10/26 [00:14<00:28,  1.81s/it]Epoch: 1/10. Loss: 1.0515:  42%|[36m████▏     [0m| 11/26 [00:14<00:22,  1.48s/it]Epoch: 1/10. Loss: 1.1005:  42%|[36m████▏     [0m| 11/26 [00:15<00:22,  1.48s/it]Epoch: 1/10. Loss: 1.1005:  46%|[36m████▌     [0m| 12/26 [00:15<00:18,  1.32s/it]Epoch: 1/10. Loss: 1.1432:  46%|[36m████▌     [0m| 12/26 [00:16<00:18,  1.32s/it]Epoch: 1/10. Loss: 1.1432:  50%|[36m█████     [0m| 13/26 [00:16<00:15,  1.20s/it]Epoch: 1/10. Loss: 1.2635:  50%|[36m█████     [0m| 13/26 [00:17<00:15,  1.20s/it]Epoch: 1/10. Loss: 1.2635:  54%|[36m█████▍    [0m| 14/26 [00:17<00:13,  1.15s/it]Epoch: 1/10. Loss: 1.0805:  54%|[36m█████▍    [0m| 14/26 [00:18<00:13,  1.15s/it]Epoch: 1/10. Loss: 1.0805:  58%|[36m█████▊    [0m| 15/26 [00:18<00:11,  1.06s/it]Epoch: 1/10. Loss: 1.1700:  58%|[36m█████▊    [0m| 15/26 [00:19<00:11,  1.06s/it]Epoch: 1/10. Loss: 1.1700:  62%|[36m██████▏   [0m| 16/26 [00:19<00:09,  1.01it/s]Epoch: 1/10. Loss: 1.1159:  62%|[36m██████▏   [0m| 16/26 [00:19<00:09,  1.01it/s]Epoch: 1/10. Loss: 1.1159:  65%|[36m██████▌   [0m| 17/26 [00:19<00:08,  1.04it/s]Epoch: 1/10. Loss: 1.1438:  65%|[36m██████▌   [0m| 17/26 [00:21<00:08,  1.04it/s]Epoch: 1/10. Loss: 1.1438:  69%|[36m██████▉   [0m| 18/26 [00:21<00:08,  1.06s/it]Epoch: 1/10. Loss: 1.1631:  69%|[36m██████▉   [0m| 18/26 [00:21<00:08,  1.06s/it]Epoch: 1/10. Loss: 1.1631:  73%|[36m███████▎  [0m| 19/26 [00:21<00:06,  1.05it/s]Epoch: 1/10. Loss: 1.1541:  73%|[36m███████▎  [0m| 19/26 [00:22<00:06,  1.05it/s]Epoch: 1/10. Loss: 1.1541:  77%|[36m███████▋  [0m| 20/26 [00:22<00:05,  1.10it/s]Epoch: 1/10. Loss: 1.0875:  77%|[36m███████▋  [0m| 20/26 [00:23<00:05,  1.10it/s]Epoch: 1/10. Loss: 1.0875:  81%|[36m████████  [0m| 21/26 [00:23<00:04,  1.08it/s]Epoch: 1/10. Loss: 1.0170:  81%|[36m████████  [0m| 21/26 [00:24<00:04,  1.08it/s]Epoch: 1/10. Loss: 1.0170:  85%|[36m████████▍ [0m| 22/26 [00:24<00:03,  1.16it/s]Epoch: 1/10. Loss: 1.0778:  85%|[36m████████▍ [0m| 22/26 [00:27<00:03,  1.16it/s]Epoch: 1/10. Loss: 1.0778:  88%|[36m████████▊ [0m| 23/26 [00:27<00:04,  1.49s/it]Epoch: 1/10. Loss: 1.0006:  88%|[36m████████▊ [0m| 23/26 [00:28<00:04,  1.49s/it]Epoch: 1/10. Loss: 1.0006:  92%|[36m█████████▏[0m| 24/26 [00:28<00:02,  1.44s/it]Epoch: 1/10. Loss: 0.9869:  92%|[36m█████████▏[0m| 24/26 [00:29<00:02,  1.44s/it]Epoch: 1/10. Loss: 0.9869:  96%|[36m█████████▌[0m| 25/26 [00:29<00:01,  1.28s/it]Epoch: 1/10. Loss: 1.1683:  96%|[36m█████████▌[0m| 25/26 [00:30<00:01,  1.28s/it]Epoch: 1/10. Loss: 1.1683: 100%|[36m██████████[0m| 26/26 [00:30<00:00,  1.10s/it]Epoch: 1/10. Loss: 1.1683: 100%|[36m██████████[0m| 26/26 [00:30<00:00,  1.16s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:05,  1.13it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:05,  1.04s/it] 43%|[33m████▎     [0m| 3/7 [00:02<00:03,  1.12it/s] 57%|[33m█████▋    [0m| 4/7 [00:04<00:03,  1.07s/it] 71%|[33m███████▏  [0m| 5/7 [00:04<00:01,  1.23it/s] 86%|[33m████████▌ [0m| 6/7 [00:05<00:00,  1.23it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.60it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.27it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 2/10. Loss: 1.1946:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 2/10. Loss: 1.1946:   4%|[36m▍         [0m| 1/26 [00:00<00:22,  1.12it/s]Epoch: 2/10. Loss: 0.9979:   4%|[36m▍         [0m| 1/26 [00:01<00:22,  1.12it/s]Epoch: 2/10. Loss: 0.9979:   8%|[36m▊         [0m| 2/26 [00:01<00:19,  1.20it/s]Epoch: 2/10. Loss: 1.1184:   8%|[36m▊         [0m| 2/26 [00:02<00:19,  1.20it/s]Epoch: 2/10. Loss: 1.1184:  12%|[36m█▏        [0m| 3/26 [00:02<00:18,  1.22it/s]Epoch: 2/10. Loss: 1.0338:  12%|[36m█▏        [0m| 3/26 [00:03<00:18,  1.22it/s]Epoch: 2/10. Loss: 1.0338:  15%|[36m█▌        [0m| 4/26 [00:03<00:19,  1.15it/s]Epoch: 2/10. Loss: 1.0350:  15%|[36m█▌        [0m| 4/26 [00:04<00:19,  1.15it/s]Epoch: 2/10. Loss: 1.0350:  19%|[36m█▉        [0m| 5/26 [00:04<00:18,  1.15it/s]Epoch: 2/10. Loss: 1.0932:  19%|[36m█▉        [0m| 5/26 [00:05<00:18,  1.15it/s]Epoch: 2/10. Loss: 1.0932:  23%|[36m██▎       [0m| 6/26 [00:05<00:17,  1.14it/s]Epoch: 2/10. Loss: 1.0706:  23%|[36m██▎       [0m| 6/26 [00:05<00:17,  1.14it/s]Epoch: 2/10. Loss: 1.0706:  27%|[36m██▋       [0m| 7/26 [00:05<00:16,  1.18it/s]Epoch: 2/10. Loss: 1.0214:  27%|[36m██▋       [0m| 7/26 [00:06<00:16,  1.18it/s]Epoch: 2/10. Loss: 1.0214:  31%|[36m███       [0m| 8/26 [00:06<00:14,  1.25it/s]Epoch: 2/10. Loss: 1.0565:  31%|[36m███       [0m| 8/26 [00:07<00:14,  1.25it/s]Epoch: 2/10. Loss: 1.0565:  35%|[36m███▍      [0m| 9/26 [00:07<00:14,  1.15it/s]Epoch: 2/10. Loss: 1.0477:  35%|[36m███▍      [0m| 9/26 [00:08<00:14,  1.15it/s]Epoch: 2/10. Loss: 1.0477:  38%|[36m███▊      [0m| 10/26 [00:08<00:14,  1.08it/s]Epoch: 2/10. Loss: 1.0462:  38%|[36m███▊      [0m| 10/26 [00:09<00:14,  1.08it/s]Epoch: 2/10. Loss: 1.0462:  42%|[36m████▏     [0m| 11/26 [00:09<00:13,  1.07it/s]Epoch: 2/10. Loss: 0.9823:  42%|[36m████▏     [0m| 11/26 [00:10<00:13,  1.07it/s]Epoch: 2/10. Loss: 0.9823:  46%|[36m████▌     [0m| 12/26 [00:10<00:14,  1.00s/it]Epoch: 2/10. Loss: 1.0255:  46%|[36m████▌     [0m| 12/26 [00:11<00:14,  1.00s/it]Epoch: 2/10. Loss: 1.0255:  50%|[36m█████     [0m| 13/26 [00:11<00:12,  1.03it/s]Epoch: 2/10. Loss: 0.9846:  50%|[36m█████     [0m| 13/26 [00:12<00:12,  1.03it/s]Epoch: 2/10. Loss: 0.9846:  54%|[36m█████▍    [0m| 14/26 [00:12<00:11,  1.05it/s]Epoch: 2/10. Loss: 1.0584:  54%|[36m█████▍    [0m| 14/26 [00:13<00:11,  1.05it/s]Epoch: 2/10. Loss: 1.0584:  58%|[36m█████▊    [0m| 15/26 [00:13<00:10,  1.02it/s]Epoch: 2/10. Loss: 1.0373:  58%|[36m█████▊    [0m| 15/26 [00:14<00:10,  1.02it/s]Epoch: 2/10. Loss: 1.0373:  62%|[36m██████▏   [0m| 16/26 [00:14<00:10,  1.06s/it]Epoch: 2/10. Loss: 0.9611:  62%|[36m██████▏   [0m| 16/26 [00:15<00:10,  1.06s/it]Epoch: 2/10. Loss: 0.9611:  65%|[36m██████▌   [0m| 17/26 [00:15<00:09,  1.03s/it]Epoch: 2/10. Loss: 1.0709:  65%|[36m██████▌   [0m| 17/26 [00:16<00:09,  1.03s/it]Epoch: 2/10. Loss: 1.0709:  69%|[36m██████▉   [0m| 18/26 [00:16<00:08,  1.00s/it]Epoch: 2/10. Loss: 0.9725:  69%|[36m██████▉   [0m| 18/26 [00:17<00:08,  1.00s/it]Epoch: 2/10. Loss: 0.9725:  73%|[36m███████▎  [0m| 19/26 [00:17<00:06,  1.02it/s]Epoch: 2/10. Loss: 1.0612:  73%|[36m███████▎  [0m| 19/26 [00:20<00:06,  1.02it/s]Epoch: 2/10. Loss: 1.0612:  77%|[36m███████▋  [0m| 20/26 [00:20<00:08,  1.41s/it]Epoch: 2/10. Loss: 0.9904:  77%|[36m███████▋  [0m| 20/26 [00:21<00:08,  1.41s/it]Epoch: 2/10. Loss: 0.9904:  81%|[36m████████  [0m| 21/26 [00:21<00:07,  1.41s/it]Epoch: 2/10. Loss: 1.0230:  81%|[36m████████  [0m| 21/26 [00:22<00:07,  1.41s/it]Epoch: 2/10. Loss: 1.0230:  85%|[36m████████▍ [0m| 22/26 [00:22<00:05,  1.35s/it]Epoch: 2/10. Loss: 1.0511:  85%|[36m████████▍ [0m| 22/26 [00:24<00:05,  1.35s/it]Epoch: 2/10. Loss: 1.0511:  88%|[36m████████▊ [0m| 23/26 [00:24<00:03,  1.33s/it]Epoch: 2/10. Loss: 0.9899:  88%|[36m████████▊ [0m| 23/26 [00:24<00:03,  1.33s/it]Epoch: 2/10. Loss: 0.9899:  92%|[36m█████████▏[0m| 24/26 [00:24<00:02,  1.18s/it]Epoch: 2/10. Loss: 1.0262:  92%|[36m█████████▏[0m| 24/26 [00:25<00:02,  1.18s/it]Epoch: 2/10. Loss: 1.0262:  96%|[36m█████████▌[0m| 25/26 [00:25<00:01,  1.09s/it]Epoch: 2/10. Loss: 0.9679:  96%|[36m█████████▌[0m| 25/26 [00:26<00:01,  1.09s/it]Epoch: 2/10. Loss: 0.9679: 100%|[36m██████████[0m| 26/26 [00:26<00:00,  1.07it/s]Epoch: 2/10. Loss: 0.9679: 100%|[36m██████████[0m| 26/26 [00:26<00:00,  1.01s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:05,  1.11it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:06,  1.28s/it] 43%|[33m████▎     [0m| 3/7 [00:03<00:04,  1.03s/it] 57%|[33m█████▋    [0m| 4/7 [00:04<00:03,  1.16s/it] 71%|[33m███████▏  [0m| 5/7 [00:04<00:01,  1.14it/s] 86%|[33m████████▌ [0m| 6/7 [00:05<00:00,  1.17it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.54it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.18it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 3/10. Loss: 0.9624:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 3/10. Loss: 0.9624:   4%|[36m▍         [0m| 1/26 [00:00<00:20,  1.22it/s]Epoch: 3/10. Loss: 0.9971:   4%|[36m▍         [0m| 1/26 [00:01<00:20,  1.22it/s]Epoch: 3/10. Loss: 0.9971:   8%|[36m▊         [0m| 2/26 [00:01<00:21,  1.13it/s]Epoch: 3/10. Loss: 0.9605:   8%|[36m▊         [0m| 2/26 [00:02<00:21,  1.13it/s]Epoch: 3/10. Loss: 0.9605:  12%|[36m█▏        [0m| 3/26 [00:02<00:19,  1.19it/s]Epoch: 3/10. Loss: 0.9626:  12%|[36m█▏        [0m| 3/26 [00:03<00:19,  1.19it/s]Epoch: 3/10. Loss: 0.9626:  15%|[36m█▌        [0m| 4/26 [00:03<00:20,  1.09it/s]Epoch: 3/10. Loss: 1.0513:  15%|[36m█▌        [0m| 4/26 [00:04<00:20,  1.09it/s]Epoch: 3/10. Loss: 1.0513:  19%|[36m█▉        [0m| 5/26 [00:04<00:22,  1.08s/it]Epoch: 3/10. Loss: 0.9497:  19%|[36m█▉        [0m| 5/26 [00:05<00:22,  1.08s/it]Epoch: 3/10. Loss: 0.9497:  23%|[36m██▎       [0m| 6/26 [00:05<00:20,  1.01s/it]Epoch: 3/10. Loss: 1.0173:  23%|[36m██▎       [0m| 6/26 [00:09<00:20,  1.01s/it]Epoch: 3/10. Loss: 1.0173:  27%|[36m██▋       [0m| 7/26 [00:09<00:35,  1.89s/it]Epoch: 3/10. Loss: 1.0182:  27%|[36m██▋       [0m| 7/26 [00:10<00:35,  1.89s/it]Epoch: 3/10. Loss: 1.0182:  31%|[36m███       [0m| 8/26 [00:10<00:28,  1.57s/it]Epoch: 3/10. Loss: 0.8967:  31%|[36m███       [0m| 8/26 [00:11<00:28,  1.57s/it]Epoch: 3/10. Loss: 0.8967:  35%|[36m███▍      [0m| 9/26 [00:11<00:22,  1.33s/it]Epoch: 3/10. Loss: 1.0241:  35%|[36m███▍      [0m| 9/26 [00:12<00:22,  1.33s/it]Epoch: 3/10. Loss: 1.0241:  38%|[36m███▊      [0m| 10/26 [00:12<00:19,  1.25s/it]Epoch: 3/10. Loss: 1.0302:  38%|[36m███▊      [0m| 10/26 [00:14<00:19,  1.25s/it]Epoch: 3/10. Loss: 1.0302:  42%|[36m████▏     [0m| 11/26 [00:14<00:21,  1.41s/it]Epoch: 3/10. Loss: 1.0269:  42%|[36m████▏     [0m| 11/26 [00:15<00:21,  1.41s/it]Epoch: 3/10. Loss: 1.0269:  46%|[36m████▌     [0m| 12/26 [00:15<00:18,  1.31s/it]Epoch: 3/10. Loss: 1.0121:  46%|[36m████▌     [0m| 12/26 [00:16<00:18,  1.31s/it]Epoch: 3/10. Loss: 1.0121:  50%|[36m█████     [0m| 13/26 [00:16<00:15,  1.22s/it]Epoch: 3/10. Loss: 1.0906:  50%|[36m█████     [0m| 13/26 [00:17<00:15,  1.22s/it]Epoch: 3/10. Loss: 1.0906:  54%|[36m█████▍    [0m| 14/26 [00:17<00:13,  1.15s/it]Epoch: 3/10. Loss: 1.0155:  54%|[36m█████▍    [0m| 14/26 [00:18<00:13,  1.15s/it]Epoch: 3/10. Loss: 1.0155:  58%|[36m█████▊    [0m| 15/26 [00:18<00:11,  1.08s/it]Epoch: 3/10. Loss: 0.9540:  58%|[36m█████▊    [0m| 15/26 [00:19<00:11,  1.08s/it]Epoch: 3/10. Loss: 0.9540:  62%|[36m██████▏   [0m| 16/26 [00:19<00:10,  1.08s/it]Epoch: 3/10. Loss: 0.9982:  62%|[36m██████▏   [0m| 16/26 [00:19<00:10,  1.08s/it]Epoch: 3/10. Loss: 0.9982:  65%|[36m██████▌   [0m| 17/26 [00:19<00:08,  1.01it/s]Epoch: 3/10. Loss: 0.9513:  65%|[36m██████▌   [0m| 17/26 [00:20<00:08,  1.01it/s]Epoch: 3/10. Loss: 0.9513:  69%|[36m██████▉   [0m| 18/26 [00:20<00:07,  1.05it/s]Epoch: 3/10. Loss: 0.9798:  69%|[36m██████▉   [0m| 18/26 [00:21<00:07,  1.05it/s]Epoch: 3/10. Loss: 0.9798:  73%|[36m███████▎  [0m| 19/26 [00:21<00:06,  1.12it/s]Epoch: 3/10. Loss: 0.9073:  73%|[36m███████▎  [0m| 19/26 [00:22<00:06,  1.12it/s]Epoch: 3/10. Loss: 0.9073:  77%|[36m███████▋  [0m| 20/26 [00:22<00:05,  1.10it/s]Epoch: 3/10. Loss: 0.9517:  77%|[36m███████▋  [0m| 20/26 [00:23<00:05,  1.10it/s]Epoch: 3/10. Loss: 0.9517:  81%|[36m████████  [0m| 21/26 [00:23<00:04,  1.07it/s]Epoch: 3/10. Loss: 0.9868:  81%|[36m████████  [0m| 21/26 [00:24<00:04,  1.07it/s]Epoch: 3/10. Loss: 0.9868:  85%|[36m████████▍ [0m| 22/26 [00:24<00:03,  1.07it/s]Epoch: 3/10. Loss: 0.9807:  85%|[36m████████▍ [0m| 22/26 [00:25<00:03,  1.07it/s]Epoch: 3/10. Loss: 0.9807:  88%|[36m████████▊ [0m| 23/26 [00:25<00:02,  1.08it/s]Epoch: 3/10. Loss: 0.9519:  88%|[36m████████▊ [0m| 23/26 [00:26<00:02,  1.08it/s]Epoch: 3/10. Loss: 0.9519:  92%|[36m█████████▏[0m| 24/26 [00:26<00:01,  1.12it/s]Epoch: 3/10. Loss: 0.9942:  92%|[36m█████████▏[0m| 24/26 [00:26<00:01,  1.12it/s]Epoch: 3/10. Loss: 0.9942:  96%|[36m█████████▌[0m| 25/26 [00:26<00:00,  1.16it/s]Epoch: 3/10. Loss: 0.9832:  96%|[36m█████████▌[0m| 25/26 [00:27<00:00,  1.16it/s]Epoch: 3/10. Loss: 0.9832: 100%|[36m██████████[0m| 26/26 [00:27<00:00,  1.22it/s]Epoch: 3/10. Loss: 0.9832: 100%|[36m██████████[0m| 26/26 [00:27<00:00,  1.06s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:05,  1.07it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:06,  1.24s/it] 43%|[33m████▎     [0m| 3/7 [00:03<00:04,  1.00s/it] 57%|[33m█████▋    [0m| 4/7 [00:04<00:03,  1.31s/it] 71%|[33m███████▏  [0m| 5/7 [00:05<00:01,  1.03it/s] 86%|[33m████████▌ [0m| 6/7 [00:06<00:00,  1.10it/s]100%|[33m██████████[0m| 7/7 [00:06<00:00,  1.44it/s]100%|[33m██████████[0m| 7/7 [00:06<00:00,  1.11it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 4/10. Loss: 0.9757:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 4/10. Loss: 0.9757:   4%|[36m▍         [0m| 1/26 [00:00<00:21,  1.14it/s]Epoch: 4/10. Loss: 0.8961:   4%|[36m▍         [0m| 1/26 [00:01<00:21,  1.14it/s]Epoch: 4/10. Loss: 0.8961:   8%|[36m▊         [0m| 2/26 [00:01<00:18,  1.26it/s]Epoch: 4/10. Loss: 1.0064:   8%|[36m▊         [0m| 2/26 [00:03<00:18,  1.26it/s]Epoch: 4/10. Loss: 1.0064:  12%|[36m█▏        [0m| 3/26 [00:03<00:29,  1.28s/it]Epoch: 4/10. Loss: 1.0155:  12%|[36m█▏        [0m| 3/26 [00:04<00:29,  1.28s/it]Epoch: 4/10. Loss: 1.0155:  15%|[36m█▌        [0m| 4/26 [00:04<00:24,  1.12s/it]Epoch: 4/10. Loss: 0.9429:  15%|[36m█▌        [0m| 4/26 [00:05<00:24,  1.12s/it]Epoch: 4/10. Loss: 0.9429:  19%|[36m█▉        [0m| 5/26 [00:05<00:21,  1.03s/it]Epoch: 4/10. Loss: 1.0099:  19%|[36m█▉        [0m| 5/26 [00:06<00:21,  1.03s/it]Epoch: 4/10. Loss: 1.0099:  23%|[36m██▎       [0m| 6/26 [00:06<00:20,  1.02s/it]Epoch: 4/10. Loss: 0.9911:  23%|[36m██▎       [0m| 6/26 [00:07<00:20,  1.02s/it]Epoch: 4/10. Loss: 0.9911:  27%|[36m██▋       [0m| 7/26 [00:07<00:18,  1.02it/s]Epoch: 4/10. Loss: 1.0429:  27%|[36m██▋       [0m| 7/26 [00:08<00:18,  1.02it/s]Epoch: 4/10. Loss: 1.0429:  31%|[36m███       [0m| 8/26 [00:08<00:17,  1.02it/s]Epoch: 4/10. Loss: 0.8765:  31%|[36m███       [0m| 8/26 [00:09<00:17,  1.02it/s]Epoch: 4/10. Loss: 0.8765:  35%|[36m███▍      [0m| 9/26 [00:09<00:17,  1.02s/it]Epoch: 4/10. Loss: 1.0018:  35%|[36m███▍      [0m| 9/26 [00:11<00:17,  1.02s/it]Epoch: 4/10. Loss: 1.0018:  38%|[36m███▊      [0m| 10/26 [00:11<00:24,  1.51s/it]Epoch: 4/10. Loss: 0.9213:  38%|[36m███▊      [0m| 10/26 [00:12<00:24,  1.51s/it]Epoch: 4/10. Loss: 0.9213:  42%|[36m████▏     [0m| 11/26 [00:12<00:18,  1.26s/it]Epoch: 4/10. Loss: 0.8517:  42%|[36m████▏     [0m| 11/26 [00:13<00:18,  1.26s/it]Epoch: 4/10. Loss: 0.8517:  46%|[36m████▌     [0m| 12/26 [00:13<00:15,  1.14s/it]Epoch: 4/10. Loss: 0.9411:  46%|[36m████▌     [0m| 12/26 [00:14<00:15,  1.14s/it]Epoch: 4/10. Loss: 0.9411:  50%|[36m█████     [0m| 13/26 [00:14<00:13,  1.06s/it]Epoch: 4/10. Loss: 0.8573:  50%|[36m█████     [0m| 13/26 [00:15<00:13,  1.06s/it]Epoch: 4/10. Loss: 0.8573:  54%|[36m█████▍    [0m| 14/26 [00:15<00:12,  1.08s/it]Epoch: 4/10. Loss: 1.0119:  54%|[36m█████▍    [0m| 14/26 [00:16<00:12,  1.08s/it]Epoch: 4/10. Loss: 1.0119:  58%|[36m█████▊    [0m| 15/26 [00:16<00:12,  1.12s/it]Epoch: 4/10. Loss: 0.9578:  58%|[36m█████▊    [0m| 15/26 [00:17<00:12,  1.12s/it]Epoch: 4/10. Loss: 0.9578:  62%|[36m██████▏   [0m| 16/26 [00:17<00:10,  1.02s/it]Epoch: 4/10. Loss: 1.0293:  62%|[36m██████▏   [0m| 16/26 [00:18<00:10,  1.02s/it]Epoch: 4/10. Loss: 1.0293:  65%|[36m██████▌   [0m| 17/26 [00:18<00:08,  1.04it/s]Epoch: 4/10. Loss: 0.9355:  65%|[36m██████▌   [0m| 17/26 [00:19<00:08,  1.04it/s]Epoch: 4/10. Loss: 0.9355:  69%|[36m██████▉   [0m| 18/26 [00:19<00:07,  1.02it/s]Epoch: 4/10. Loss: 0.9097:  69%|[36m██████▉   [0m| 18/26 [00:20<00:07,  1.02it/s]Epoch: 4/10. Loss: 0.9097:  73%|[36m███████▎  [0m| 19/26 [00:20<00:08,  1.15s/it]Epoch: 4/10. Loss: 1.0134:  73%|[36m███████▎  [0m| 19/26 [00:21<00:08,  1.15s/it]Epoch: 4/10. Loss: 1.0134:  77%|[36m███████▋  [0m| 20/26 [00:21<00:06,  1.06s/it]Epoch: 4/10. Loss: 0.9564:  77%|[36m███████▋  [0m| 20/26 [00:22<00:06,  1.06s/it]Epoch: 4/10. Loss: 0.9564:  81%|[36m████████  [0m| 21/26 [00:22<00:05,  1.00s/it]Epoch: 4/10. Loss: 0.9676:  81%|[36m████████  [0m| 21/26 [00:23<00:05,  1.00s/it]Epoch: 4/10. Loss: 0.9676:  85%|[36m████████▍ [0m| 22/26 [00:23<00:03,  1.03it/s]Epoch: 4/10. Loss: 0.9172:  85%|[36m████████▍ [0m| 22/26 [00:24<00:03,  1.03it/s]Epoch: 4/10. Loss: 0.9172:  88%|[36m████████▊ [0m| 23/26 [00:24<00:02,  1.06it/s]Epoch: 4/10. Loss: 0.9101:  88%|[36m████████▊ [0m| 23/26 [00:25<00:02,  1.06it/s]Epoch: 4/10. Loss: 0.9101:  92%|[36m█████████▏[0m| 24/26 [00:25<00:01,  1.09it/s]Epoch: 4/10. Loss: 0.9603:  92%|[36m█████████▏[0m| 24/26 [00:27<00:01,  1.09it/s]Epoch: 4/10. Loss: 0.9603:  96%|[36m█████████▌[0m| 25/26 [00:27<00:01,  1.26s/it]Epoch: 4/10. Loss: 0.9912:  96%|[36m█████████▌[0m| 25/26 [00:27<00:01,  1.26s/it]Epoch: 4/10. Loss: 0.9912: 100%|[36m██████████[0m| 26/26 [00:27<00:00,  1.05s/it]Epoch: 4/10. Loss: 0.9912: 100%|[36m██████████[0m| 26/26 [00:27<00:00,  1.07s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:05,  1.08it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:05,  1.07s/it] 43%|[33m████▎     [0m| 3/7 [00:02<00:03,  1.06it/s] 57%|[33m█████▋    [0m| 4/7 [00:04<00:03,  1.11s/it] 71%|[33m███████▏  [0m| 5/7 [00:04<00:01,  1.18it/s] 86%|[33m████████▌ [0m| 6/7 [00:05<00:00,  1.20it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.55it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.23it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 5/10. Loss: 0.9092:   0%|[36m          [0m| 0/26 [00:01<?, ?it/s]Epoch: 5/10. Loss: 0.9092:   4%|[36m▍         [0m| 1/26 [00:01<00:47,  1.91s/it]Epoch: 5/10. Loss: 0.8162:   4%|[36m▍         [0m| 1/26 [00:02<00:47,  1.91s/it]Epoch: 5/10. Loss: 0.8162:   8%|[36m▊         [0m| 2/26 [00:02<00:31,  1.32s/it]Epoch: 5/10. Loss: 0.9060:   8%|[36m▊         [0m| 2/26 [00:03<00:31,  1.32s/it]Epoch: 5/10. Loss: 0.9060:  12%|[36m█▏        [0m| 3/26 [00:03<00:24,  1.06s/it]Epoch: 5/10. Loss: 0.8938:  12%|[36m█▏        [0m| 3/26 [00:04<00:24,  1.06s/it]Epoch: 5/10. Loss: 0.8938:  15%|[36m█▌        [0m| 4/26 [00:04<00:21,  1.02it/s]Epoch: 5/10. Loss: 0.8763:  15%|[36m█▌        [0m| 4/26 [00:05<00:21,  1.02it/s]Epoch: 5/10. Loss: 0.8763:  19%|[36m█▉        [0m| 5/26 [00:05<00:21,  1.01s/it]Epoch: 5/10. Loss: 0.8837:  19%|[36m█▉        [0m| 5/26 [00:06<00:21,  1.01s/it]Epoch: 5/10. Loss: 0.8837:  23%|[36m██▎       [0m| 6/26 [00:06<00:19,  1.04it/s]Epoch: 5/10. Loss: 0.9891:  23%|[36m██▎       [0m| 6/26 [00:07<00:19,  1.04it/s]Epoch: 5/10. Loss: 0.9891:  27%|[36m██▋       [0m| 7/26 [00:07<00:17,  1.06it/s]Epoch: 5/10. Loss: 1.0268:  27%|[36m██▋       [0m| 7/26 [00:08<00:17,  1.06it/s]Epoch: 5/10. Loss: 1.0268:  31%|[36m███       [0m| 8/26 [00:08<00:16,  1.08it/s]Epoch: 5/10. Loss: 0.8907:  31%|[36m███       [0m| 8/26 [00:08<00:16,  1.08it/s]Epoch: 5/10. Loss: 0.8907:  35%|[36m███▍      [0m| 9/26 [00:08<00:14,  1.15it/s]Epoch: 5/10. Loss: 0.9330:  35%|[36m███▍      [0m| 9/26 [00:10<00:14,  1.15it/s]Epoch: 5/10. Loss: 0.9330:  38%|[36m███▊      [0m| 10/26 [00:10<00:18,  1.15s/it]Epoch: 5/10. Loss: 0.9502:  38%|[36m███▊      [0m| 10/26 [00:11<00:18,  1.15s/it]Epoch: 5/10. Loss: 0.9502:  42%|[36m████▏     [0m| 11/26 [00:11<00:16,  1.13s/it]Epoch: 5/10. Loss: 1.0305:  42%|[36m████▏     [0m| 11/26 [00:12<00:16,  1.13s/it]Epoch: 5/10. Loss: 1.0305:  46%|[36m████▌     [0m| 12/26 [00:12<00:14,  1.05s/it]Epoch: 5/10. Loss: 1.0623:  46%|[36m████▌     [0m| 12/26 [00:13<00:14,  1.05s/it]Epoch: 5/10. Loss: 1.0623:  50%|[36m█████     [0m| 13/26 [00:13<00:13,  1.03s/it]Epoch: 5/10. Loss: 0.8813:  50%|[36m█████     [0m| 13/26 [00:14<00:13,  1.03s/it]Epoch: 5/10. Loss: 0.8813:  54%|[36m█████▍    [0m| 14/26 [00:14<00:11,  1.08it/s]Epoch: 5/10. Loss: 1.0735:  54%|[36m█████▍    [0m| 14/26 [00:15<00:11,  1.08it/s]Epoch: 5/10. Loss: 1.0735:  58%|[36m█████▊    [0m| 15/26 [00:15<00:09,  1.14it/s]Epoch: 5/10. Loss: 1.0036:  58%|[36m█████▊    [0m| 15/26 [00:15<00:09,  1.14it/s]Epoch: 5/10. Loss: 1.0036:  62%|[36m██████▏   [0m| 16/26 [00:16<00:08,  1.11it/s]Epoch: 5/10. Loss: 0.9958:  62%|[36m██████▏   [0m| 16/26 [00:16<00:08,  1.11it/s]Epoch: 5/10. Loss: 0.9958:  65%|[36m██████▌   [0m| 17/26 [00:16<00:07,  1.18it/s]Epoch: 5/10. Loss: 0.9279:  65%|[36m██████▌   [0m| 17/26 [00:17<00:07,  1.18it/s]Epoch: 5/10. Loss: 0.9279:  69%|[36m██████▉   [0m| 18/26 [00:17<00:06,  1.15it/s]Epoch: 5/10. Loss: 0.8869:  69%|[36m██████▉   [0m| 18/26 [00:18<00:06,  1.15it/s]Epoch: 5/10. Loss: 0.8869:  73%|[36m███████▎  [0m| 19/26 [00:18<00:06,  1.12it/s]Epoch: 5/10. Loss: 0.9075:  73%|[36m███████▎  [0m| 19/26 [00:19<00:06,  1.12it/s]Epoch: 5/10. Loss: 0.9075:  77%|[36m███████▋  [0m| 20/26 [00:19<00:04,  1.21it/s]Epoch: 5/10. Loss: 0.9011:  77%|[36m███████▋  [0m| 20/26 [00:20<00:04,  1.21it/s]Epoch: 5/10. Loss: 0.9011:  81%|[36m████████  [0m| 21/26 [00:20<00:04,  1.11it/s]Epoch: 5/10. Loss: 0.9381:  81%|[36m████████  [0m| 21/26 [00:21<00:04,  1.11it/s]Epoch: 5/10. Loss: 0.9381:  85%|[36m████████▍ [0m| 22/26 [00:21<00:03,  1.07it/s]Epoch: 5/10. Loss: 0.9220:  85%|[36m████████▍ [0m| 22/26 [00:22<00:03,  1.07it/s]Epoch: 5/10. Loss: 0.9220:  88%|[36m████████▊ [0m| 23/26 [00:22<00:02,  1.02it/s]Epoch: 5/10. Loss: 0.9016:  88%|[36m████████▊ [0m| 23/26 [00:23<00:02,  1.02it/s]Epoch: 5/10. Loss: 0.9016:  92%|[36m█████████▏[0m| 24/26 [00:23<00:01,  1.03it/s]Epoch: 5/10. Loss: 0.9172:  92%|[36m█████████▏[0m| 24/26 [00:24<00:01,  1.03it/s]Epoch: 5/10. Loss: 0.9172:  96%|[36m█████████▌[0m| 25/26 [00:24<00:00,  1.07it/s]Epoch: 5/10. Loss: 0.9874:  96%|[36m█████████▌[0m| 25/26 [00:24<00:00,  1.07it/s]Epoch: 5/10. Loss: 0.9874: 100%|[36m██████████[0m| 26/26 [00:24<00:00,  1.19it/s]Epoch: 5/10. Loss: 0.9874: 100%|[36m██████████[0m| 26/26 [00:24<00:00,  1.04it/s]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:05,  1.10it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:05,  1.11s/it] 43%|[33m████▎     [0m| 3/7 [00:02<00:03,  1.05it/s] 57%|[33m█████▋    [0m| 4/7 [00:04<00:03,  1.17s/it] 71%|[33m███████▏  [0m| 5/7 [00:04<00:01,  1.12it/s] 86%|[33m████████▌ [0m| 6/7 [00:05<00:00,  1.15it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.50it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.19it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 6/10. Loss: 0.9052:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 6/10. Loss: 0.9052:   4%|[36m▍         [0m| 1/26 [00:00<00:19,  1.29it/s]Epoch: 6/10. Loss: 0.9555:   4%|[36m▍         [0m| 1/26 [00:01<00:19,  1.29it/s]Epoch: 6/10. Loss: 0.9555:   8%|[36m▊         [0m| 2/26 [00:01<00:18,  1.28it/s]Epoch: 6/10. Loss: 0.8357:   8%|[36m▊         [0m| 2/26 [00:02<00:18,  1.28it/s]Epoch: 6/10. Loss: 0.8357:  12%|[36m█▏        [0m| 3/26 [00:02<00:22,  1.03it/s]Epoch: 6/10. Loss: 0.7964:  12%|[36m█▏        [0m| 3/26 [00:03<00:22,  1.03it/s]Epoch: 6/10. Loss: 0.7964:  15%|[36m█▌        [0m| 4/26 [00:03<00:21,  1.00it/s]Epoch: 6/10. Loss: 0.9104:  15%|[36m█▌        [0m| 4/26 [00:04<00:21,  1.00it/s]Epoch: 6/10. Loss: 0.9104:  19%|[36m█▉        [0m| 5/26 [00:04<00:19,  1.09it/s]Epoch: 6/10. Loss: 0.8537:  19%|[36m█▉        [0m| 5/26 [00:05<00:19,  1.09it/s]Epoch: 6/10. Loss: 0.8537:  23%|[36m██▎       [0m| 6/26 [00:05<00:18,  1.11it/s]Epoch: 6/10. Loss: 0.9428:  23%|[36m██▎       [0m| 6/26 [00:06<00:18,  1.11it/s]Epoch: 6/10. Loss: 0.9428:  27%|[36m██▋       [0m| 7/26 [00:06<00:16,  1.13it/s]Epoch: 6/10. Loss: 0.9037:  27%|[36m██▋       [0m| 7/26 [00:07<00:16,  1.13it/s]Epoch: 6/10. Loss: 0.9037:  31%|[36m███       [0m| 8/26 [00:07<00:17,  1.06it/s]Epoch: 6/10. Loss: 0.9328:  31%|[36m███       [0m| 8/26 [00:08<00:17,  1.06it/s]Epoch: 6/10. Loss: 0.9328:  35%|[36m███▍      [0m| 9/26 [00:08<00:15,  1.12it/s]Epoch: 6/10. Loss: 0.8994:  35%|[36m███▍      [0m| 9/26 [00:08<00:15,  1.12it/s]Epoch: 6/10. Loss: 0.8994:  38%|[36m███▊      [0m| 10/26 [00:08<00:13,  1.15it/s]Epoch: 6/10. Loss: 0.8444:  38%|[36m███▊      [0m| 10/26 [00:09<00:13,  1.15it/s]Epoch: 6/10. Loss: 0.8444:  42%|[36m████▏     [0m| 11/26 [00:09<00:13,  1.12it/s]Epoch: 6/10. Loss: 0.8345:  42%|[36m████▏     [0m| 11/26 [00:10<00:13,  1.12it/s]Epoch: 6/10. Loss: 0.8345:  46%|[36m████▌     [0m| 12/26 [00:10<00:12,  1.11it/s]Epoch: 6/10. Loss: 0.7786:  46%|[36m████▌     [0m| 12/26 [00:11<00:12,  1.11it/s]Epoch: 6/10. Loss: 0.7786:  50%|[36m█████     [0m| 13/26 [00:11<00:12,  1.05it/s]Epoch: 6/10. Loss: 0.9605:  50%|[36m█████     [0m| 13/26 [00:12<00:12,  1.05it/s]Epoch: 6/10. Loss: 0.9605:  54%|[36m█████▍    [0m| 14/26 [00:12<00:11,  1.02it/s]Epoch: 6/10. Loss: 0.8905:  54%|[36m█████▍    [0m| 14/26 [00:13<00:11,  1.02it/s]Epoch: 6/10. Loss: 0.8905:  58%|[36m█████▊    [0m| 15/26 [00:13<00:10,  1.07it/s]Epoch: 6/10. Loss: 0.8622:  58%|[36m█████▊    [0m| 15/26 [00:14<00:10,  1.07it/s]Epoch: 6/10. Loss: 0.8622:  62%|[36m██████▏   [0m| 16/26 [00:14<00:09,  1.03it/s]Epoch: 6/10. Loss: 0.9310:  62%|[36m██████▏   [0m| 16/26 [00:15<00:09,  1.03it/s]Epoch: 6/10. Loss: 0.9310:  65%|[36m██████▌   [0m| 17/26 [00:15<00:08,  1.01it/s]Epoch: 6/10. Loss: 0.8819:  65%|[36m██████▌   [0m| 17/26 [00:16<00:08,  1.01it/s]Epoch: 6/10. Loss: 0.8819:  69%|[36m██████▉   [0m| 18/26 [00:16<00:07,  1.03it/s]Epoch: 6/10. Loss: 0.9500:  69%|[36m██████▉   [0m| 18/26 [00:17<00:07,  1.03it/s]Epoch: 6/10. Loss: 0.9500:  73%|[36m███████▎  [0m| 19/26 [00:17<00:06,  1.09it/s]Epoch: 6/10. Loss: 0.9298:  73%|[36m███████▎  [0m| 19/26 [00:18<00:06,  1.09it/s]Epoch: 6/10. Loss: 0.9298:  77%|[36m███████▋  [0m| 20/26 [00:18<00:05,  1.15it/s]Epoch: 6/10. Loss: 0.9129:  77%|[36m███████▋  [0m| 20/26 [00:19<00:05,  1.15it/s]Epoch: 6/10. Loss: 0.9129:  81%|[36m████████  [0m| 21/26 [00:19<00:04,  1.10it/s]Epoch: 6/10. Loss: 0.9887:  81%|[36m████████  [0m| 21/26 [00:20<00:04,  1.10it/s]Epoch: 6/10. Loss: 0.9887:  85%|[36m████████▍ [0m| 22/26 [00:20<00:03,  1.09it/s]Epoch: 6/10. Loss: 1.0230:  85%|[36m████████▍ [0m| 22/26 [00:20<00:03,  1.09it/s]Epoch: 6/10. Loss: 1.0230:  88%|[36m████████▊ [0m| 23/26 [00:20<00:02,  1.17it/s]Epoch: 6/10. Loss: 0.9053:  88%|[36m████████▊ [0m| 23/26 [00:21<00:02,  1.17it/s]Epoch: 6/10. Loss: 0.9053:  92%|[36m█████████▏[0m| 24/26 [00:21<00:01,  1.17it/s]Epoch: 6/10. Loss: 0.9453:  92%|[36m█████████▏[0m| 24/26 [00:22<00:01,  1.17it/s]Epoch: 6/10. Loss: 0.9453:  96%|[36m█████████▌[0m| 25/26 [00:22<00:00,  1.18it/s]Epoch: 6/10. Loss: 0.9409:  96%|[36m█████████▌[0m| 25/26 [00:23<00:00,  1.18it/s]Epoch: 6/10. Loss: 0.9409: 100%|[36m██████████[0m| 26/26 [00:23<00:00,  1.28it/s]Epoch: 6/10. Loss: 0.9409: 100%|[36m██████████[0m| 26/26 [00:23<00:00,  1.12it/s]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:05,  1.09it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:05,  1.09s/it] 43%|[33m████▎     [0m| 3/7 [00:02<00:03,  1.06it/s] 57%|[33m█████▋    [0m| 4/7 [00:04<00:03,  1.12s/it] 71%|[33m███████▏  [0m| 5/7 [00:04<00:01,  1.15it/s] 86%|[33m████████▌ [0m| 6/7 [00:05<00:00,  1.18it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.53it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.21it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 7/10. Loss: 0.9626:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 7/10. Loss: 0.9626:   4%|[36m▍         [0m| 1/26 [00:00<00:22,  1.11it/s]Epoch: 7/10. Loss: 0.9883:   4%|[36m▍         [0m| 1/26 [00:01<00:22,  1.11it/s]Epoch: 7/10. Loss: 0.9883:   8%|[36m▊         [0m| 2/26 [00:01<00:18,  1.30it/s]Epoch: 7/10. Loss: 0.8466:   8%|[36m▊         [0m| 2/26 [00:02<00:18,  1.30it/s]Epoch: 7/10. Loss: 0.8466:  12%|[36m█▏        [0m| 3/26 [00:02<00:19,  1.16it/s]Epoch: 7/10. Loss: 0.9263:  12%|[36m█▏        [0m| 3/26 [00:03<00:19,  1.16it/s]Epoch: 7/10. Loss: 0.9263:  15%|[36m█▌        [0m| 4/26 [00:03<00:19,  1.14it/s]Epoch: 7/10. Loss: 0.9143:  15%|[36m█▌        [0m| 4/26 [00:04<00:19,  1.14it/s]Epoch: 7/10. Loss: 0.9143:  19%|[36m█▉        [0m| 5/26 [00:04<00:19,  1.10it/s]Epoch: 7/10. Loss: 1.0342:  19%|[36m█▉        [0m| 5/26 [00:05<00:19,  1.10it/s]Epoch: 7/10. Loss: 1.0342:  23%|[36m██▎       [0m| 6/26 [00:05<00:17,  1.12it/s]Epoch: 7/10. Loss: 0.9173:  23%|[36m██▎       [0m| 6/26 [00:06<00:17,  1.12it/s]Epoch: 7/10. Loss: 0.9173:  27%|[36m██▋       [0m| 7/26 [00:06<00:17,  1.08it/s]Epoch: 7/10. Loss: 0.9320:  27%|[36m██▋       [0m| 7/26 [00:06<00:17,  1.08it/s]Epoch: 7/10. Loss: 0.9320:  31%|[36m███       [0m| 8/26 [00:06<00:15,  1.18it/s]Epoch: 7/10. Loss: 0.9735:  31%|[36m███       [0m| 8/26 [00:07<00:15,  1.18it/s]Epoch: 7/10. Loss: 0.9735:  35%|[36m███▍      [0m| 9/26 [00:07<00:15,  1.10it/s]Epoch: 7/10. Loss: 0.9000:  35%|[36m███▍      [0m| 9/26 [00:08<00:15,  1.10it/s]Epoch: 7/10. Loss: 0.9000:  38%|[36m███▊      [0m| 10/26 [00:08<00:14,  1.09it/s]Epoch: 7/10. Loss: 0.9360:  38%|[36m███▊      [0m| 10/26 [00:09<00:14,  1.09it/s]Epoch: 7/10. Loss: 0.9360:  42%|[36m████▏     [0m| 11/26 [00:09<00:13,  1.13it/s]Epoch: 7/10. Loss: 0.8638:  42%|[36m████▏     [0m| 11/26 [00:10<00:13,  1.13it/s]Epoch: 7/10. Loss: 0.8638:  46%|[36m████▌     [0m| 12/26 [00:10<00:12,  1.11it/s]Epoch: 7/10. Loss: 0.8609:  46%|[36m████▌     [0m| 12/26 [00:13<00:12,  1.11it/s]Epoch: 7/10. Loss: 0.8609:  50%|[36m█████     [0m| 13/26 [00:13<00:17,  1.35s/it]Epoch: 7/10. Loss: 0.8605:  50%|[36m█████     [0m| 13/26 [00:14<00:17,  1.35s/it]Epoch: 7/10. Loss: 0.8605:  54%|[36m█████▍    [0m| 14/26 [00:14<00:15,  1.30s/it]Epoch: 7/10. Loss: 0.7910:  54%|[36m█████▍    [0m| 14/26 [00:15<00:15,  1.30s/it]Epoch: 7/10. Loss: 0.7910:  58%|[36m█████▊    [0m| 15/26 [00:15<00:13,  1.19s/it]Epoch: 7/10. Loss: 0.9330:  58%|[36m█████▊    [0m| 15/26 [00:15<00:13,  1.19s/it]Epoch: 7/10. Loss: 0.9330:  62%|[36m██████▏   [0m| 16/26 [00:15<00:10,  1.07s/it]Epoch: 7/10. Loss: 0.8679:  62%|[36m██████▏   [0m| 16/26 [00:16<00:10,  1.07s/it]Epoch: 7/10. Loss: 0.8679:  65%|[36m██████▌   [0m| 17/26 [00:16<00:08,  1.01it/s]Epoch: 7/10. Loss: 1.0066:  65%|[36m██████▌   [0m| 17/26 [00:17<00:08,  1.01it/s]Epoch: 7/10. Loss: 1.0066:  69%|[36m██████▉   [0m| 18/26 [00:17<00:07,  1.07it/s]Epoch: 7/10. Loss: 0.8335:  69%|[36m██████▉   [0m| 18/26 [00:18<00:07,  1.07it/s]Epoch: 7/10. Loss: 0.8335:  73%|[36m███████▎  [0m| 19/26 [00:18<00:06,  1.06it/s]Epoch: 7/10. Loss: 0.8296:  73%|[36m███████▎  [0m| 19/26 [00:19<00:06,  1.06it/s]Epoch: 7/10. Loss: 0.8296:  77%|[36m███████▋  [0m| 20/26 [00:19<00:05,  1.03it/s]Epoch: 7/10. Loss: 0.7968:  77%|[36m███████▋  [0m| 20/26 [00:21<00:05,  1.03it/s]Epoch: 7/10. Loss: 0.7968:  81%|[36m████████  [0m| 21/26 [00:21<00:05,  1.13s/it]Epoch: 7/10. Loss: 0.8537:  81%|[36m████████  [0m| 21/26 [00:22<00:05,  1.13s/it]Epoch: 7/10. Loss: 0.8537:  85%|[36m████████▍ [0m| 22/26 [00:22<00:04,  1.08s/it]Epoch: 7/10. Loss: 0.8891:  85%|[36m████████▍ [0m| 22/26 [00:22<00:04,  1.08s/it]Epoch: 7/10. Loss: 0.8891:  88%|[36m████████▊ [0m| 23/26 [00:22<00:03,  1.03s/it]Epoch: 7/10. Loss: 0.9150:  88%|[36m████████▊ [0m| 23/26 [00:23<00:03,  1.03s/it]Epoch: 7/10. Loss: 0.9150:  92%|[36m█████████▏[0m| 24/26 [00:23<00:01,  1.05it/s]Epoch: 7/10. Loss: 0.8187:  92%|[36m█████████▏[0m| 24/26 [00:24<00:01,  1.05it/s]Epoch: 7/10. Loss: 0.8187:  96%|[36m█████████▌[0m| 25/26 [00:24<00:00,  1.08it/s]Epoch: 7/10. Loss: 0.9004:  96%|[36m█████████▌[0m| 25/26 [00:25<00:00,  1.08it/s]Epoch: 7/10. Loss: 0.9004: 100%|[36m██████████[0m| 26/26 [00:25<00:00,  1.15it/s]Epoch: 7/10. Loss: 0.9004: 100%|[36m██████████[0m| 26/26 [00:25<00:00,  1.03it/s]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:05,  1.09it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:05,  1.08s/it] 43%|[33m████▎     [0m| 3/7 [00:03<00:04,  1.06s/it] 57%|[33m█████▋    [0m| 4/7 [00:05<00:04,  1.43s/it] 71%|[33m███████▏  [0m| 5/7 [00:05<00:02,  1.06s/it] 86%|[33m████████▌ [0m| 6/7 [00:06<00:00,  1.03it/s]100%|[33m██████████[0m| 7/7 [00:06<00:00,  1.35it/s]100%|[33m██████████[0m| 7/7 [00:06<00:00,  1.06it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 8/10. Loss: 0.8140:   0%|[36m          [0m| 0/26 [00:01<?, ?it/s]Epoch: 8/10. Loss: 0.8140:   4%|[36m▍         [0m| 1/26 [00:01<00:26,  1.05s/it]Epoch: 8/10. Loss: 0.8145:   4%|[36m▍         [0m| 1/26 [00:02<00:26,  1.05s/it]Epoch: 8/10. Loss: 0.8145:   8%|[36m▊         [0m| 2/26 [00:02<00:26,  1.12s/it]Epoch: 8/10. Loss: 0.8075:   8%|[36m▊         [0m| 2/26 [00:02<00:26,  1.12s/it]Epoch: 8/10. Loss: 0.8075:  12%|[36m█▏        [0m| 3/26 [00:02<00:21,  1.07it/s]Epoch: 8/10. Loss: 0.7852:  12%|[36m█▏        [0m| 3/26 [00:03<00:21,  1.07it/s]Epoch: 8/10. Loss: 0.7852:  15%|[36m█▌        [0m| 4/26 [00:03<00:19,  1.14it/s]Epoch: 8/10. Loss: 0.9810:  15%|[36m█▌        [0m| 4/26 [00:04<00:19,  1.14it/s]Epoch: 8/10. Loss: 0.9810:  19%|[36m█▉        [0m| 5/26 [00:04<00:19,  1.10it/s]Epoch: 8/10. Loss: 0.8839:  19%|[36m█▉        [0m| 5/26 [00:05<00:19,  1.10it/s]Epoch: 8/10. Loss: 0.8839:  23%|[36m██▎       [0m| 6/26 [00:05<00:17,  1.12it/s]Epoch: 8/10. Loss: 0.8841:  23%|[36m██▎       [0m| 6/26 [00:06<00:17,  1.12it/s]Epoch: 8/10. Loss: 0.8841:  27%|[36m██▋       [0m| 7/26 [00:06<00:17,  1.12it/s]Epoch: 8/10. Loss: 0.8548:  27%|[36m██▋       [0m| 7/26 [00:07<00:17,  1.12it/s]Epoch: 8/10. Loss: 0.8548:  31%|[36m███       [0m| 8/26 [00:07<00:15,  1.17it/s]Epoch: 8/10. Loss: 0.8436:  31%|[36m███       [0m| 8/26 [00:08<00:15,  1.17it/s]Epoch: 8/10. Loss: 0.8436:  35%|[36m███▍      [0m| 9/26 [00:08<00:14,  1.18it/s]Epoch: 8/10. Loss: 0.8367:  35%|[36m███▍      [0m| 9/26 [00:09<00:14,  1.18it/s]Epoch: 8/10. Loss: 0.8367:  38%|[36m███▊      [0m| 10/26 [00:09<00:14,  1.13it/s]Epoch: 8/10. Loss: 0.8048:  38%|[36m███▊      [0m| 10/26 [00:09<00:14,  1.13it/s]Epoch: 8/10. Loss: 0.8048:  42%|[36m████▏     [0m| 11/26 [00:09<00:13,  1.11it/s]Epoch: 8/10. Loss: 0.8054:  42%|[36m████▏     [0m| 11/26 [00:10<00:13,  1.11it/s]Epoch: 8/10. Loss: 0.8054:  46%|[36m████▌     [0m| 12/26 [00:11<00:13,  1.06it/s]Epoch: 8/10. Loss: 0.9043:  46%|[36m████▌     [0m| 12/26 [00:11<00:13,  1.06it/s]Epoch: 8/10. Loss: 0.9043:  50%|[36m█████     [0m| 13/26 [00:11<00:11,  1.13it/s]Epoch: 8/10. Loss: 0.8508:  50%|[36m█████     [0m| 13/26 [00:12<00:11,  1.13it/s]Epoch: 8/10. Loss: 0.8508:  54%|[36m█████▍    [0m| 14/26 [00:12<00:10,  1.14it/s]Epoch: 8/10. Loss: 0.9413:  54%|[36m█████▍    [0m| 14/26 [00:13<00:10,  1.14it/s]Epoch: 8/10. Loss: 0.9413:  58%|[36m█████▊    [0m| 15/26 [00:13<00:09,  1.21it/s]Epoch: 8/10. Loss: 0.8887:  58%|[36m█████▊    [0m| 15/26 [00:14<00:09,  1.21it/s]Epoch: 8/10. Loss: 0.8887:  62%|[36m██████▏   [0m| 16/26 [00:14<00:08,  1.20it/s]Epoch: 8/10. Loss: 0.8803:  62%|[36m██████▏   [0m| 16/26 [00:15<00:08,  1.20it/s]Epoch: 8/10. Loss: 0.8803:  65%|[36m██████▌   [0m| 17/26 [00:15<00:07,  1.14it/s]Epoch: 8/10. Loss: 0.8863:  65%|[36m██████▌   [0m| 17/26 [00:15<00:07,  1.14it/s]Epoch: 8/10. Loss: 0.8863:  69%|[36m██████▉   [0m| 18/26 [00:15<00:06,  1.19it/s]Epoch: 8/10. Loss: 0.9127:  69%|[36m██████▉   [0m| 18/26 [00:16<00:06,  1.19it/s]Epoch: 8/10. Loss: 0.9127:  73%|[36m███████▎  [0m| 19/26 [00:16<00:05,  1.25it/s]Epoch: 8/10. Loss: 0.9147:  73%|[36m███████▎  [0m| 19/26 [00:17<00:05,  1.25it/s]Epoch: 8/10. Loss: 0.9147:  77%|[36m███████▋  [0m| 20/26 [00:17<00:04,  1.22it/s]Epoch: 8/10. Loss: 0.8557:  77%|[36m███████▋  [0m| 20/26 [00:18<00:04,  1.22it/s]Epoch: 8/10. Loss: 0.8557:  81%|[36m████████  [0m| 21/26 [00:18<00:04,  1.20it/s]Epoch: 8/10. Loss: 0.8113:  81%|[36m████████  [0m| 21/26 [00:19<00:04,  1.20it/s]Epoch: 8/10. Loss: 0.8113:  85%|[36m████████▍ [0m| 22/26 [00:19<00:03,  1.17it/s]Epoch: 8/10. Loss: 0.8918:  85%|[36m████████▍ [0m| 22/26 [00:20<00:03,  1.17it/s]Epoch: 8/10. Loss: 0.8918:  88%|[36m████████▊ [0m| 23/26 [00:20<00:02,  1.18it/s]Epoch: 8/10. Loss: 0.9109:  88%|[36m████████▊ [0m| 23/26 [00:21<00:02,  1.18it/s]Epoch: 8/10. Loss: 0.9109:  92%|[36m█████████▏[0m| 24/26 [00:21<00:01,  1.14it/s]Epoch: 8/10. Loss: 0.9448:  92%|[36m█████████▏[0m| 24/26 [00:22<00:01,  1.14it/s]Epoch: 8/10. Loss: 0.9448:  96%|[36m█████████▌[0m| 25/26 [00:22<00:01,  1.10s/it]Epoch: 8/10. Loss: 0.8480:  96%|[36m█████████▌[0m| 25/26 [00:23<00:01,  1.10s/it]Epoch: 8/10. Loss: 0.8480: 100%|[36m██████████[0m| 26/26 [00:23<00:00,  1.01it/s]Epoch: 8/10. Loss: 0.8480: 100%|[36m██████████[0m| 26/26 [00:23<00:00,  1.11it/s]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:05,  1.08it/s] 29%|[33m██▊       [0m| 2/7 [00:03<00:10,  2.13s/it] 43%|[33m████▎     [0m| 3/7 [00:04<00:06,  1.51s/it] 57%|[33m█████▋    [0m| 4/7 [00:06<00:04,  1.47s/it] 71%|[33m███████▏  [0m| 5/7 [00:06<00:02,  1.10s/it] 86%|[33m████████▌ [0m| 6/7 [00:07<00:00,  1.00it/s]100%|[33m██████████[0m| 7/7 [00:07<00:00,  1.34it/s]100%|[33m██████████[0m| 7/7 [00:07<00:00,  1.08s/it]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 9/10. Loss: 0.7584:   0%|[36m          [0m| 0/26 [00:01<?, ?it/s]Epoch: 9/10. Loss: 0.7584:   4%|[36m▍         [0m| 1/26 [00:01<00:26,  1.06s/it]Epoch: 9/10. Loss: 0.7644:   4%|[36m▍         [0m| 1/26 [00:03<00:26,  1.06s/it]Epoch: 9/10. Loss: 0.7644:   8%|[36m▊         [0m| 2/26 [00:03<00:47,  1.99s/it]Epoch: 9/10. Loss: 0.8158:   8%|[36m▊         [0m| 2/26 [00:04<00:47,  1.99s/it]Epoch: 9/10. Loss: 0.8158:  12%|[36m█▏        [0m| 3/26 [00:04<00:32,  1.43s/it]Epoch: 9/10. Loss: 0.7795:  12%|[36m█▏        [0m| 3/26 [00:06<00:32,  1.43s/it]Epoch: 9/10. Loss: 0.7795:  15%|[36m█▌        [0m| 4/26 [00:06<00:35,  1.60s/it]Epoch: 9/10. Loss: 0.9160:  15%|[36m█▌        [0m| 4/26 [00:07<00:35,  1.60s/it]Epoch: 9/10. Loss: 0.9160:  19%|[36m█▉        [0m| 5/26 [00:07<00:26,  1.27s/it]Epoch: 9/10. Loss: 0.8527:  19%|[36m█▉        [0m| 5/26 [00:09<00:26,  1.27s/it]Epoch: 9/10. Loss: 0.8527:  23%|[36m██▎       [0m| 6/26 [00:09<00:35,  1.80s/it]Epoch: 9/10. Loss: 1.0129:  23%|[36m██▎       [0m| 6/26 [00:10<00:35,  1.80s/it]Epoch: 9/10. Loss: 1.0129:  27%|[36m██▋       [0m| 7/26 [00:10<00:29,  1.56s/it]Epoch: 9/10. Loss: 0.7863:  27%|[36m██▋       [0m| 7/26 [00:11<00:29,  1.56s/it]Epoch: 9/10. Loss: 0.7863:  31%|[36m███       [0m| 8/26 [00:11<00:23,  1.29s/it]Epoch: 9/10. Loss: 0.8144:  31%|[36m███       [0m| 8/26 [00:12<00:23,  1.29s/it]Epoch: 9/10. Loss: 0.8144:  35%|[36m███▍      [0m| 9/26 [00:12<00:20,  1.20s/it]Epoch: 9/10. Loss: 0.9049:  35%|[36m███▍      [0m| 9/26 [00:13<00:20,  1.20s/it]Epoch: 9/10. Loss: 0.9049:  38%|[36m███▊      [0m| 10/26 [00:13<00:17,  1.10s/it]Epoch: 9/10. Loss: 0.8722:  38%|[36m███▊      [0m| 10/26 [00:14<00:17,  1.10s/it]Epoch: 9/10. Loss: 0.8722:  42%|[36m████▏     [0m| 11/26 [00:14<00:16,  1.08s/it]Epoch: 9/10. Loss: 0.8364:  42%|[36m████▏     [0m| 11/26 [00:15<00:16,  1.08s/it]Epoch: 9/10. Loss: 0.8364:  46%|[36m████▌     [0m| 12/26 [00:15<00:14,  1.03s/it]Epoch: 9/10. Loss: 0.8747:  46%|[36m████▌     [0m| 12/26 [00:16<00:14,  1.03s/it]Epoch: 9/10. Loss: 0.8747:  50%|[36m█████     [0m| 13/26 [00:16<00:12,  1.04it/s]Epoch: 9/10. Loss: 0.9308:  50%|[36m█████     [0m| 13/26 [00:17<00:12,  1.04it/s]Epoch: 9/10. Loss: 0.9308:  54%|[36m█████▍    [0m| 14/26 [00:17<00:11,  1.02it/s]Epoch: 9/10. Loss: 0.8312:  54%|[36m█████▍    [0m| 14/26 [00:18<00:11,  1.02it/s]Epoch: 9/10. Loss: 0.8312:  58%|[36m█████▊    [0m| 15/26 [00:18<00:10,  1.04it/s]Epoch: 9/10. Loss: 0.7776:  58%|[36m█████▊    [0m| 15/26 [00:19<00:10,  1.04it/s]Epoch: 9/10. Loss: 0.7776:  62%|[36m██████▏   [0m| 16/26 [00:19<00:10,  1.01s/it]Epoch: 9/10. Loss: 0.9107:  62%|[36m██████▏   [0m| 16/26 [00:20<00:10,  1.01s/it]Epoch: 9/10. Loss: 0.9107:  65%|[36m██████▌   [0m| 17/26 [00:20<00:08,  1.03it/s]Epoch: 9/10. Loss: 0.7918:  65%|[36m██████▌   [0m| 17/26 [00:20<00:08,  1.03it/s]Epoch: 9/10. Loss: 0.7918:  69%|[36m██████▉   [0m| 18/26 [00:20<00:07,  1.09it/s]Epoch: 9/10. Loss: 0.7937:  69%|[36m██████▉   [0m| 18/26 [00:21<00:07,  1.09it/s]Epoch: 9/10. Loss: 0.7937:  73%|[36m███████▎  [0m| 19/26 [00:21<00:06,  1.12it/s]Epoch: 9/10. Loss: 0.8835:  73%|[36m███████▎  [0m| 19/26 [00:22<00:06,  1.12it/s]Epoch: 9/10. Loss: 0.8835:  77%|[36m███████▋  [0m| 20/26 [00:22<00:05,  1.15it/s]Epoch: 9/10. Loss: 0.8640:  77%|[36m███████▋  [0m| 20/26 [00:23<00:05,  1.15it/s]Epoch: 9/10. Loss: 0.8640:  81%|[36m████████  [0m| 21/26 [00:23<00:04,  1.14it/s]Epoch: 9/10. Loss: 0.7968:  81%|[36m████████  [0m| 21/26 [00:26<00:04,  1.14it/s]Epoch: 9/10. Loss: 0.7968:  85%|[36m████████▍ [0m| 22/26 [00:26<00:05,  1.41s/it]Epoch: 9/10. Loss: 0.8413:  85%|[36m████████▍ [0m| 22/26 [00:27<00:05,  1.41s/it]Epoch: 9/10. Loss: 0.8413:  88%|[36m████████▊ [0m| 23/26 [00:27<00:03,  1.27s/it]Epoch: 9/10. Loss: 0.7838:  88%|[36m████████▊ [0m| 23/26 [00:27<00:03,  1.27s/it]Epoch: 9/10. Loss: 0.7838:  92%|[36m█████████▏[0m| 24/26 [00:27<00:02,  1.14s/it]Epoch: 9/10. Loss: 0.8723:  92%|[36m█████████▏[0m| 24/26 [00:28<00:02,  1.14s/it]Epoch: 9/10. Loss: 0.8723:  96%|[36m█████████▌[0m| 25/26 [00:28<00:01,  1.10s/it]Epoch: 9/10. Loss: 0.8384:  96%|[36m█████████▌[0m| 25/26 [00:29<00:01,  1.10s/it]Epoch: 9/10. Loss: 0.8384: 100%|[36m██████████[0m| 26/26 [00:29<00:00,  1.02it/s]Epoch: 9/10. Loss: 0.8384: 100%|[36m██████████[0m| 26/26 [00:29<00:00,  1.14s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:05,  1.05it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:05,  1.12s/it] 43%|[33m████▎     [0m| 3/7 [00:02<00:03,  1.03it/s] 57%|[33m█████▋    [0m| 4/7 [00:04<00:03,  1.15s/it] 71%|[33m███████▏  [0m| 5/7 [00:04<00:01,  1.16it/s] 86%|[33m████████▌ [0m| 6/7 [00:05<00:00,  1.23it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.61it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.23it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 0/10. Loss: 1.1494:   0%|[36m          [0m| 0/26 [00:01<?, ?it/s]Epoch: 0/10. Loss: 1.1494:   4%|[36m▍         [0m| 1/26 [00:01<00:33,  1.32s/it]Epoch: 0/10. Loss: 10.3979:   4%|[36m▍         [0m| 1/26 [00:02<00:33,  1.32s/it]Epoch: 0/10. Loss: 10.3979:   8%|[36m▊         [0m| 2/26 [00:02<00:27,  1.15s/it]Epoch: 0/10. Loss: 4.3084:   8%|[36m▊         [0m| 2/26 [00:03<00:27,  1.15s/it] Epoch: 0/10. Loss: 4.3084:  12%|[36m█▏        [0m| 3/26 [00:03<00:22,  1.00it/s]Epoch: 0/10. Loss: 3.6129:  12%|[36m█▏        [0m| 3/26 [00:03<00:22,  1.00it/s]Epoch: 0/10. Loss: 3.6129:  15%|[36m█▌        [0m| 4/26 [00:04<00:20,  1.07it/s]Epoch: 0/10. Loss: 1.3957:  15%|[36m█▌        [0m| 4/26 [00:04<00:20,  1.07it/s]Epoch: 0/10. Loss: 1.3957:  19%|[36m█▉        [0m| 5/26 [00:04<00:19,  1.09it/s]Epoch: 0/10. Loss: 1.8085:  19%|[36m█▉        [0m| 5/26 [00:05<00:19,  1.09it/s]Epoch: 0/10. Loss: 1.8085:  23%|[36m██▎       [0m| 6/26 [00:05<00:17,  1.12it/s]Epoch: 0/10. Loss: 1.0912:  23%|[36m██▎       [0m| 6/26 [00:06<00:17,  1.12it/s]Epoch: 0/10. Loss: 1.0912:  27%|[36m██▋       [0m| 7/26 [00:06<00:17,  1.11it/s]Epoch: 0/10. Loss: 2.1251:  27%|[36m██▋       [0m| 7/26 [00:07<00:17,  1.11it/s]Epoch: 0/10. Loss: 2.1251:  31%|[36m███       [0m| 8/26 [00:07<00:17,  1.03it/s]Epoch: 0/10. Loss: 2.0141:  31%|[36m███       [0m| 8/26 [00:08<00:17,  1.03it/s]Epoch: 0/10. Loss: 2.0141:  35%|[36m███▍      [0m| 9/26 [00:08<00:16,  1.04it/s]Epoch: 0/10. Loss: 1.2903:  35%|[36m███▍      [0m| 9/26 [00:09<00:16,  1.04it/s]Epoch: 0/10. Loss: 1.2903:  38%|[36m███▊      [0m| 10/26 [00:09<00:15,  1.05it/s]Epoch: 0/10. Loss: 1.4241:  38%|[36m███▊      [0m| 10/26 [00:10<00:15,  1.05it/s]Epoch: 0/10. Loss: 1.4241:  42%|[36m████▏     [0m| 11/26 [00:10<00:14,  1.05it/s]Epoch: 0/10. Loss: 1.9267:  42%|[36m████▏     [0m| 11/26 [00:11<00:14,  1.05it/s]Epoch: 0/10. Loss: 1.9267:  46%|[36m████▌     [0m| 12/26 [00:11<00:13,  1.07it/s]Epoch: 0/10. Loss: 1.9957:  46%|[36m████▌     [0m| 12/26 [00:12<00:13,  1.07it/s]Epoch: 0/10. Loss: 1.9957:  50%|[36m█████     [0m| 13/26 [00:12<00:13,  1.05s/it]Epoch: 0/10. Loss: 1.4764:  50%|[36m█████     [0m| 13/26 [00:13<00:13,  1.05s/it]Epoch: 0/10. Loss: 1.4764:  54%|[36m█████▍    [0m| 14/26 [00:13<00:11,  1.01it/s]Epoch: 0/10. Loss: 1.8845:  54%|[36m█████▍    [0m| 14/26 [00:15<00:11,  1.01it/s]Epoch: 0/10. Loss: 1.8845:  58%|[36m█████▊    [0m| 15/26 [00:15<00:14,  1.31s/it]Epoch: 0/10. Loss: 1.0293:  58%|[36m█████▊    [0m| 15/26 [00:17<00:14,  1.31s/it]Epoch: 0/10. Loss: 1.0293:  62%|[36m██████▏   [0m| 16/26 [00:17<00:13,  1.33s/it]Epoch: 0/10. Loss: 2.9571:  62%|[36m██████▏   [0m| 16/26 [00:17<00:13,  1.33s/it]Epoch: 0/10. Loss: 2.9571:  65%|[36m██████▌   [0m| 17/26 [00:17<00:10,  1.20s/it]Epoch: 0/10. Loss: 1.1476:  65%|[36m██████▌   [0m| 17/26 [00:18<00:10,  1.20s/it]Epoch: 0/10. Loss: 1.1476:  69%|[36m██████▉   [0m| 18/26 [00:18<00:08,  1.08s/it]Epoch: 0/10. Loss: 0.9783:  69%|[36m██████▉   [0m| 18/26 [00:19<00:08,  1.08s/it]Epoch: 0/10. Loss: 0.9783:  73%|[36m███████▎  [0m| 19/26 [00:19<00:07,  1.03s/it]Epoch: 0/10. Loss: 1.1775:  73%|[36m███████▎  [0m| 19/26 [00:20<00:07,  1.03s/it]Epoch: 0/10. Loss: 1.1775:  77%|[36m███████▋  [0m| 20/26 [00:20<00:05,  1.00it/s]Epoch: 0/10. Loss: 4.2788:  77%|[36m███████▋  [0m| 20/26 [00:21<00:05,  1.00it/s]Epoch: 0/10. Loss: 4.2788:  81%|[36m████████  [0m| 21/26 [00:21<00:04,  1.04it/s]Epoch: 0/10. Loss: 1.0721:  81%|[36m████████  [0m| 21/26 [00:22<00:04,  1.04it/s]Epoch: 0/10. Loss: 1.0721:  85%|[36m████████▍ [0m| 22/26 [00:22<00:04,  1.01s/it]Epoch: 0/10. Loss: 2.4086:  85%|[36m████████▍ [0m| 22/26 [00:23<00:04,  1.01s/it]Epoch: 0/10. Loss: 2.4086:  88%|[36m████████▊ [0m| 23/26 [00:23<00:02,  1.06it/s]Epoch: 0/10. Loss: 1.1203:  88%|[36m████████▊ [0m| 23/26 [00:24<00:02,  1.06it/s]Epoch: 0/10. Loss: 1.1203:  92%|[36m█████████▏[0m| 24/26 [00:24<00:01,  1.02it/s]Epoch: 0/10. Loss: 2.0554:  92%|[36m█████████▏[0m| 24/26 [00:25<00:01,  1.02it/s]Epoch: 0/10. Loss: 2.0554:  96%|[36m█████████▌[0m| 25/26 [00:25<00:01,  1.11s/it]Epoch: 0/10. Loss: 0.9989:  96%|[36m█████████▌[0m| 25/26 [00:26<00:01,  1.11s/it]Epoch: 0/10. Loss: 0.9989: 100%|[36m██████████[0m| 26/26 [00:26<00:00,  1.03it/s]Epoch: 0/10. Loss: 0.9989: 100%|[36m██████████[0m| 26/26 [00:26<00:00,  1.02s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:05,  1.02it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:05,  1.14s/it] 43%|[33m████▎     [0m| 3/7 [00:03<00:03,  1.02it/s] 57%|[33m█████▋    [0m| 4/7 [00:04<00:03,  1.15s/it] 71%|[33m███████▏  [0m| 5/7 [00:04<00:01,  1.13it/s] 86%|[33m████████▌ [0m| 6/7 [00:05<00:00,  1.18it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.53it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.19it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 1/10. Loss: 1.1589:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 1/10. Loss: 1.1589:   4%|[36m▍         [0m| 1/26 [00:00<00:20,  1.24it/s]Epoch: 1/10. Loss: 2.0862:   4%|[36m▍         [0m| 1/26 [00:01<00:20,  1.24it/s]Epoch: 1/10. Loss: 2.0862:   8%|[36m▊         [0m| 2/26 [00:01<00:24,  1.01s/it]Epoch: 1/10. Loss: 0.9735:   8%|[36m▊         [0m| 2/26 [00:02<00:24,  1.01s/it]Epoch: 1/10. Loss: 0.9735:  12%|[36m█▏        [0m| 3/26 [00:02<00:21,  1.07it/s]Epoch: 1/10. Loss: 1.1850:  12%|[36m█▏        [0m| 3/26 [00:03<00:21,  1.07it/s]Epoch: 1/10. Loss: 1.1850:  15%|[36m█▌        [0m| 4/26 [00:03<00:20,  1.09it/s]Epoch: 1/10. Loss: 0.9769:  15%|[36m█▌        [0m| 4/26 [00:04<00:20,  1.09it/s]Epoch: 1/10. Loss: 0.9769:  19%|[36m█▉        [0m| 5/26 [00:04<00:18,  1.15it/s]Epoch: 1/10. Loss: 1.0015:  19%|[36m█▉        [0m| 5/26 [00:05<00:18,  1.15it/s]Epoch: 1/10. Loss: 1.0015:  23%|[36m██▎       [0m| 6/26 [00:05<00:18,  1.11it/s]Epoch: 1/10. Loss: 1.0084:  23%|[36m██▎       [0m| 6/26 [00:06<00:18,  1.11it/s]Epoch: 1/10. Loss: 1.0084:  27%|[36m██▋       [0m| 7/26 [00:06<00:17,  1.08it/s]Epoch: 1/10. Loss: 1.0560:  27%|[36m██▋       [0m| 7/26 [00:07<00:17,  1.08it/s]Epoch: 1/10. Loss: 1.0560:  31%|[36m███       [0m| 8/26 [00:07<00:16,  1.10it/s]Epoch: 1/10. Loss: 1.0697:  31%|[36m███       [0m| 8/26 [00:08<00:16,  1.10it/s]Epoch: 1/10. Loss: 1.0697:  35%|[36m███▍      [0m| 9/26 [00:08<00:15,  1.08it/s]Epoch: 1/10. Loss: 0.9947:  35%|[36m███▍      [0m| 9/26 [00:09<00:15,  1.08it/s]Epoch: 1/10. Loss: 0.9947:  38%|[36m███▊      [0m| 10/26 [00:09<00:14,  1.14it/s]Epoch: 1/10. Loss: 0.9995:  38%|[36m███▊      [0m| 10/26 [00:09<00:14,  1.14it/s]Epoch: 1/10. Loss: 0.9995:  42%|[36m████▏     [0m| 11/26 [00:09<00:13,  1.12it/s]Epoch: 1/10. Loss: 0.9788:  42%|[36m████▏     [0m| 11/26 [00:10<00:13,  1.12it/s]Epoch: 1/10. Loss: 0.9788:  46%|[36m████▌     [0m| 12/26 [00:10<00:12,  1.12it/s]Epoch: 1/10. Loss: 0.9390:  46%|[36m████▌     [0m| 12/26 [00:11<00:12,  1.12it/s]Epoch: 1/10. Loss: 0.9390:  50%|[36m█████     [0m| 13/26 [00:11<00:12,  1.05it/s]Epoch: 1/10. Loss: 1.1482:  50%|[36m█████     [0m| 13/26 [00:12<00:12,  1.05it/s]Epoch: 1/10. Loss: 1.1482:  54%|[36m█████▍    [0m| 14/26 [00:12<00:10,  1.10it/s]Epoch: 1/10. Loss: 1.1535:  54%|[36m█████▍    [0m| 14/26 [00:13<00:10,  1.10it/s]Epoch: 1/10. Loss: 1.1535:  58%|[36m█████▊    [0m| 15/26 [00:13<00:09,  1.15it/s]Epoch: 1/10. Loss: 1.1557:  58%|[36m█████▊    [0m| 15/26 [00:14<00:09,  1.15it/s]Epoch: 1/10. Loss: 1.1557:  62%|[36m██████▏   [0m| 16/26 [00:14<00:08,  1.11it/s]Epoch: 1/10. Loss: 0.9762:  62%|[36m██████▏   [0m| 16/26 [00:15<00:08,  1.11it/s]Epoch: 1/10. Loss: 0.9762:  65%|[36m██████▌   [0m| 17/26 [00:15<00:07,  1.19it/s]Epoch: 1/10. Loss: 0.9816:  65%|[36m██████▌   [0m| 17/26 [00:16<00:07,  1.19it/s]Epoch: 1/10. Loss: 0.9816:  69%|[36m██████▉   [0m| 18/26 [00:16<00:07,  1.13it/s]Epoch: 1/10. Loss: 1.1635:  69%|[36m██████▉   [0m| 18/26 [00:17<00:07,  1.13it/s]Epoch: 1/10. Loss: 1.1635:  73%|[36m███████▎  [0m| 19/26 [00:17<00:06,  1.06it/s]Epoch: 1/10. Loss: 1.0047:  73%|[36m███████▎  [0m| 19/26 [00:18<00:06,  1.06it/s]Epoch: 1/10. Loss: 1.0047:  77%|[36m███████▋  [0m| 20/26 [00:18<00:05,  1.06it/s]Epoch: 1/10. Loss: 1.1023:  77%|[36m███████▋  [0m| 20/26 [00:19<00:05,  1.06it/s]Epoch: 1/10. Loss: 1.1023:  81%|[36m████████  [0m| 21/26 [00:19<00:04,  1.04it/s]Epoch: 1/10. Loss: 1.1744:  81%|[36m████████  [0m| 21/26 [00:20<00:04,  1.04it/s]Epoch: 1/10. Loss: 1.1744:  85%|[36m████████▍ [0m| 22/26 [00:20<00:03,  1.05it/s]Epoch: 1/10. Loss: 1.0864:  85%|[36m████████▍ [0m| 22/26 [00:22<00:03,  1.05it/s]Epoch: 1/10. Loss: 1.0864:  88%|[36m████████▊ [0m| 23/26 [00:22<00:03,  1.27s/it]Epoch: 1/10. Loss: 0.9996:  88%|[36m████████▊ [0m| 23/26 [00:23<00:03,  1.27s/it]Epoch: 1/10. Loss: 0.9996:  92%|[36m█████████▏[0m| 24/26 [00:23<00:02,  1.20s/it]Epoch: 1/10. Loss: 1.0216:  92%|[36m█████████▏[0m| 24/26 [00:26<00:02,  1.20s/it]Epoch: 1/10. Loss: 1.0216:  96%|[36m█████████▌[0m| 25/26 [00:26<00:01,  1.76s/it]Epoch: 1/10. Loss: 1.0158:  96%|[36m█████████▌[0m| 25/26 [00:26<00:01,  1.76s/it]Epoch: 1/10. Loss: 1.0158: 100%|[36m██████████[0m| 26/26 [00:26<00:00,  1.45s/it]Epoch: 1/10. Loss: 1.0158: 100%|[36m██████████[0m| 26/26 [00:26<00:00,  1.04s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:05,  1.13it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:05,  1.04s/it] 43%|[33m████▎     [0m| 3/7 [00:02<00:03,  1.07it/s] 57%|[33m█████▋    [0m| 4/7 [00:04<00:03,  1.13s/it] 71%|[33m███████▏  [0m| 5/7 [00:04<00:01,  1.15it/s] 86%|[33m████████▌ [0m| 6/7 [00:05<00:00,  1.19it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.54it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.23it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 2/10. Loss: 1.1101:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 2/10. Loss: 1.1101:   4%|[36m▍         [0m| 1/26 [00:00<00:23,  1.07it/s]Epoch: 2/10. Loss: 1.0911:   4%|[36m▍         [0m| 1/26 [00:02<00:23,  1.07it/s]Epoch: 2/10. Loss: 1.0911:   8%|[36m▊         [0m| 2/26 [00:02<00:24,  1.03s/it]Epoch: 2/10. Loss: 1.1100:   8%|[36m▊         [0m| 2/26 [00:02<00:24,  1.03s/it]Epoch: 2/10. Loss: 1.1100:  12%|[36m█▏        [0m| 3/26 [00:02<00:21,  1.09it/s]Epoch: 2/10. Loss: 0.9760:  12%|[36m█▏        [0m| 3/26 [00:03<00:21,  1.09it/s]Epoch: 2/10. Loss: 0.9760:  15%|[36m█▌        [0m| 4/26 [00:03<00:19,  1.15it/s]Epoch: 2/10. Loss: 1.1705:  15%|[36m█▌        [0m| 4/26 [00:04<00:19,  1.15it/s]Epoch: 2/10. Loss: 1.1705:  19%|[36m█▉        [0m| 5/26 [00:04<00:17,  1.18it/s]Epoch: 2/10. Loss: 1.0631:  19%|[36m█▉        [0m| 5/26 [00:05<00:17,  1.18it/s]Epoch: 2/10. Loss: 1.0631:  23%|[36m██▎       [0m| 6/26 [00:05<00:16,  1.22it/s]Epoch: 2/10. Loss: 0.9464:  23%|[36m██▎       [0m| 6/26 [00:06<00:16,  1.22it/s]Epoch: 2/10. Loss: 0.9464:  27%|[36m██▋       [0m| 7/26 [00:06<00:16,  1.15it/s]Epoch: 2/10. Loss: 0.9756:  27%|[36m██▋       [0m| 7/26 [00:06<00:16,  1.15it/s]Epoch: 2/10. Loss: 0.9756:  31%|[36m███       [0m| 8/26 [00:06<00:15,  1.17it/s]Epoch: 2/10. Loss: 1.0306:  31%|[36m███       [0m| 8/26 [00:09<00:15,  1.17it/s]Epoch: 2/10. Loss: 1.0306:  35%|[36m███▍      [0m| 9/26 [00:09<00:25,  1.50s/it]Epoch: 2/10. Loss: 1.1812:  35%|[36m███▍      [0m| 9/26 [00:11<00:25,  1.50s/it]Epoch: 2/10. Loss: 1.1812:  38%|[36m███▊      [0m| 10/26 [00:11<00:23,  1.48s/it]Epoch: 2/10. Loss: 0.9971:  38%|[36m███▊      [0m| 10/26 [00:12<00:23,  1.48s/it]Epoch: 2/10. Loss: 0.9971:  42%|[36m████▏     [0m| 11/26 [00:12<00:19,  1.33s/it]Epoch: 2/10. Loss: 1.1974:  42%|[36m████▏     [0m| 11/26 [00:13<00:19,  1.33s/it]Epoch: 2/10. Loss: 1.1974:  46%|[36m████▌     [0m| 12/26 [00:13<00:16,  1.16s/it]Epoch: 2/10. Loss: 1.0752:  46%|[36m████▌     [0m| 12/26 [00:14<00:16,  1.16s/it]Epoch: 2/10. Loss: 1.0752:  50%|[36m█████     [0m| 13/26 [00:14<00:16,  1.23s/it]Epoch: 2/10. Loss: 1.0993:  50%|[36m█████     [0m| 13/26 [00:15<00:16,  1.23s/it]Epoch: 2/10. Loss: 1.0993:  54%|[36m█████▍    [0m| 14/26 [00:15<00:13,  1.14s/it]Epoch: 2/10. Loss: 0.9591:  54%|[36m█████▍    [0m| 14/26 [00:16<00:13,  1.14s/it]Epoch: 2/10. Loss: 0.9591:  58%|[36m█████▊    [0m| 15/26 [00:16<00:11,  1.03s/it]Epoch: 2/10. Loss: 0.9512:  58%|[36m█████▊    [0m| 15/26 [00:17<00:11,  1.03s/it]Epoch: 2/10. Loss: 0.9512:  62%|[36m██████▏   [0m| 16/26 [00:17<00:09,  1.03it/s]Epoch: 2/10. Loss: 1.0686:  62%|[36m██████▏   [0m| 16/26 [00:17<00:09,  1.03it/s]Epoch: 2/10. Loss: 1.0686:  65%|[36m██████▌   [0m| 17/26 [00:17<00:08,  1.04it/s]Epoch: 2/10. Loss: 0.9901:  65%|[36m██████▌   [0m| 17/26 [00:18<00:08,  1.04it/s]Epoch: 2/10. Loss: 0.9901:  69%|[36m██████▉   [0m| 18/26 [00:18<00:07,  1.03it/s]Epoch: 2/10. Loss: 0.9771:  69%|[36m██████▉   [0m| 18/26 [00:19<00:07,  1.03it/s]Epoch: 2/10. Loss: 0.9771:  73%|[36m███████▎  [0m| 19/26 [00:19<00:06,  1.02it/s]Epoch: 2/10. Loss: 0.8686:  73%|[36m███████▎  [0m| 19/26 [00:21<00:06,  1.02it/s]Epoch: 2/10. Loss: 0.8686:  77%|[36m███████▋  [0m| 20/26 [00:21<00:06,  1.01s/it]Epoch: 2/10. Loss: 0.9685:  77%|[36m███████▋  [0m| 20/26 [00:21<00:06,  1.01s/it]Epoch: 2/10. Loss: 0.9685:  81%|[36m████████  [0m| 21/26 [00:21<00:04,  1.03it/s]Epoch: 2/10. Loss: 1.0645:  81%|[36m████████  [0m| 21/26 [00:22<00:04,  1.03it/s]Epoch: 2/10. Loss: 1.0645:  85%|[36m████████▍ [0m| 22/26 [00:22<00:03,  1.01it/s]Epoch: 2/10. Loss: 1.0562:  85%|[36m████████▍ [0m| 22/26 [00:23<00:03,  1.01it/s]Epoch: 2/10. Loss: 1.0562:  88%|[36m████████▊ [0m| 23/26 [00:23<00:02,  1.01it/s]Epoch: 2/10. Loss: 1.0003:  88%|[36m████████▊ [0m| 23/26 [00:24<00:02,  1.01it/s]Epoch: 2/10. Loss: 1.0003:  92%|[36m█████████▏[0m| 24/26 [00:24<00:01,  1.02it/s]Epoch: 2/10. Loss: 0.9862:  92%|[36m█████████▏[0m| 24/26 [00:26<00:01,  1.02it/s]Epoch: 2/10. Loss: 0.9862:  96%|[36m█████████▌[0m| 25/26 [00:26<00:01,  1.29s/it]Epoch: 2/10. Loss: 1.0143:  96%|[36m█████████▌[0m| 25/26 [00:27<00:01,  1.29s/it]Epoch: 2/10. Loss: 1.0143: 100%|[36m██████████[0m| 26/26 [00:27<00:00,  1.06s/it]Epoch: 2/10. Loss: 1.0143: 100%|[36m██████████[0m| 26/26 [00:27<00:00,  1.06s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:05,  1.12it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:05,  1.06s/it] 43%|[33m████▎     [0m| 3/7 [00:02<00:03,  1.06it/s] 57%|[33m█████▋    [0m| 4/7 [00:04<00:03,  1.12s/it] 71%|[33m███████▏  [0m| 5/7 [00:04<00:01,  1.16it/s] 86%|[33m████████▌ [0m| 6/7 [00:05<00:00,  1.19it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.55it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.23it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 3/10. Loss: 0.9858:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 3/10. Loss: 0.9858:   4%|[36m▍         [0m| 1/26 [00:00<00:21,  1.18it/s]Epoch: 3/10. Loss: 0.9684:   4%|[36m▍         [0m| 1/26 [00:01<00:21,  1.18it/s]Epoch: 3/10. Loss: 0.9684:   8%|[36m▊         [0m| 2/26 [00:01<00:21,  1.12it/s]Epoch: 3/10. Loss: 1.0285:   8%|[36m▊         [0m| 2/26 [00:02<00:21,  1.12it/s]Epoch: 3/10. Loss: 1.0285:  12%|[36m█▏        [0m| 3/26 [00:02<00:20,  1.12it/s]Epoch: 3/10. Loss: 1.0855:  12%|[36m█▏        [0m| 3/26 [00:03<00:20,  1.12it/s]Epoch: 3/10. Loss: 1.0855:  15%|[36m█▌        [0m| 4/26 [00:03<00:18,  1.16it/s]Epoch: 3/10. Loss: 1.0195:  15%|[36m█▌        [0m| 4/26 [00:04<00:18,  1.16it/s]Epoch: 3/10. Loss: 1.0195:  19%|[36m█▉        [0m| 5/26 [00:04<00:17,  1.18it/s]Epoch: 3/10. Loss: 0.9851:  19%|[36m█▉        [0m| 5/26 [00:05<00:17,  1.18it/s]Epoch: 3/10. Loss: 0.9851:  23%|[36m██▎       [0m| 6/26 [00:05<00:18,  1.09it/s]Epoch: 3/10. Loss: 0.9440:  23%|[36m██▎       [0m| 6/26 [00:06<00:18,  1.09it/s]Epoch: 3/10. Loss: 0.9440:  27%|[36m██▋       [0m| 7/26 [00:06<00:17,  1.08it/s]Epoch: 3/10. Loss: 0.9607:  27%|[36m██▋       [0m| 7/26 [00:07<00:17,  1.08it/s]Epoch: 3/10. Loss: 0.9607:  31%|[36m███       [0m| 8/26 [00:07<00:16,  1.11it/s]Epoch: 3/10. Loss: 1.0052:  31%|[36m███       [0m| 8/26 [00:08<00:16,  1.11it/s]Epoch: 3/10. Loss: 1.0052:  35%|[36m███▍      [0m| 9/26 [00:08<00:15,  1.09it/s]Epoch: 3/10. Loss: 0.9806:  35%|[36m███▍      [0m| 9/26 [00:09<00:15,  1.09it/s]Epoch: 3/10. Loss: 0.9806:  38%|[36m███▊      [0m| 10/26 [00:09<00:17,  1.07s/it]Epoch: 3/10. Loss: 0.9377:  38%|[36m███▊      [0m| 10/26 [00:10<00:17,  1.07s/it]Epoch: 3/10. Loss: 0.9377:  42%|[36m████▏     [0m| 11/26 [00:10<00:15,  1.00s/it]Epoch: 3/10. Loss: 0.9690:  42%|[36m████▏     [0m| 11/26 [00:11<00:15,  1.00s/it]Epoch: 3/10. Loss: 0.9690:  46%|[36m████▌     [0m| 12/26 [00:11<00:13,  1.04it/s]Epoch: 3/10. Loss: 0.9382:  46%|[36m████▌     [0m| 12/26 [00:14<00:13,  1.04it/s]Epoch: 3/10. Loss: 0.9382:  50%|[36m█████     [0m| 13/26 [00:14<00:22,  1.71s/it]Epoch: 3/10. Loss: 1.0396:  50%|[36m█████     [0m| 13/26 [00:15<00:22,  1.71s/it]Epoch: 3/10. Loss: 1.0396:  54%|[36m█████▍    [0m| 14/26 [00:15<00:17,  1.46s/it]Epoch: 3/10. Loss: 0.9497:  54%|[36m█████▍    [0m| 14/26 [00:16<00:17,  1.46s/it]Epoch: 3/10. Loss: 0.9497:  58%|[36m█████▊    [0m| 15/26 [00:16<00:14,  1.32s/it]Epoch: 3/10. Loss: 0.9661:  58%|[36m█████▊    [0m| 15/26 [00:17<00:14,  1.32s/it]Epoch: 3/10. Loss: 0.9661:  62%|[36m██████▏   [0m| 16/26 [00:17<00:12,  1.25s/it]Epoch: 3/10. Loss: 1.0112:  62%|[36m██████▏   [0m| 16/26 [00:19<00:12,  1.25s/it]Epoch: 3/10. Loss: 1.0112:  65%|[36m██████▌   [0m| 17/26 [00:19<00:12,  1.38s/it]Epoch: 3/10. Loss: 0.9713:  65%|[36m██████▌   [0m| 17/26 [00:20<00:12,  1.38s/it]Epoch: 3/10. Loss: 0.9713:  69%|[36m██████▉   [0m| 18/26 [00:20<00:11,  1.41s/it]Epoch: 3/10. Loss: 0.9375:  69%|[36m██████▉   [0m| 18/26 [00:21<00:11,  1.41s/it]Epoch: 3/10. Loss: 0.9375:  73%|[36m███████▎  [0m| 19/26 [00:21<00:08,  1.27s/it]Epoch: 3/10. Loss: 0.9908:  73%|[36m███████▎  [0m| 19/26 [00:22<00:08,  1.27s/it]Epoch: 3/10. Loss: 0.9908:  77%|[36m███████▋  [0m| 20/26 [00:22<00:06,  1.14s/it]Epoch: 3/10. Loss: 0.9442:  77%|[36m███████▋  [0m| 20/26 [00:23<00:06,  1.14s/it]Epoch: 3/10. Loss: 0.9442:  81%|[36m████████  [0m| 21/26 [00:23<00:05,  1.11s/it]Epoch: 3/10. Loss: 0.9332:  81%|[36m████████  [0m| 21/26 [00:24<00:05,  1.11s/it]Epoch: 3/10. Loss: 0.9332:  85%|[36m████████▍ [0m| 22/26 [00:24<00:04,  1.07s/it]Epoch: 3/10. Loss: 1.0554:  85%|[36m████████▍ [0m| 22/26 [00:25<00:04,  1.07s/it]Epoch: 3/10. Loss: 1.0554:  88%|[36m████████▊ [0m| 23/26 [00:25<00:02,  1.00it/s]Epoch: 3/10. Loss: 1.0380:  88%|[36m████████▊ [0m| 23/26 [00:26<00:02,  1.00it/s]Epoch: 3/10. Loss: 1.0380:  92%|[36m█████████▏[0m| 24/26 [00:26<00:01,  1.07it/s]Epoch: 3/10. Loss: 0.9649:  92%|[36m█████████▏[0m| 24/26 [00:27<00:01,  1.07it/s]Epoch: 3/10. Loss: 0.9649:  96%|[36m█████████▌[0m| 25/26 [00:27<00:00,  1.04it/s]Epoch: 3/10. Loss: 0.9544:  96%|[36m█████████▌[0m| 25/26 [00:27<00:00,  1.04it/s]Epoch: 3/10. Loss: 0.9544: 100%|[36m██████████[0m| 26/26 [00:27<00:00,  1.13it/s]Epoch: 3/10. Loss: 0.9544: 100%|[36m██████████[0m| 26/26 [00:27<00:00,  1.07s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:05,  1.07it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:05,  1.09s/it] 43%|[33m████▎     [0m| 3/7 [00:02<00:03,  1.05it/s] 57%|[33m█████▋    [0m| 4/7 [00:04<00:03,  1.23s/it] 71%|[33m███████▏  [0m| 5/7 [00:05<00:01,  1.06it/s] 86%|[33m████████▌ [0m| 6/7 [00:05<00:00,  1.10it/s]100%|[33m██████████[0m| 7/7 [00:06<00:00,  1.43it/s]100%|[33m██████████[0m| 7/7 [00:06<00:00,  1.14it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 4/10. Loss: 0.9851:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 4/10. Loss: 0.9851:   4%|[36m▍         [0m| 1/26 [00:00<00:23,  1.06it/s]Epoch: 4/10. Loss: 0.8531:   4%|[36m▍         [0m| 1/26 [00:02<00:23,  1.06it/s]Epoch: 4/10. Loss: 0.8531:   8%|[36m▊         [0m| 2/26 [00:02<00:29,  1.25s/it]Epoch: 4/10. Loss: 1.0019:   8%|[36m▊         [0m| 2/26 [00:03<00:29,  1.25s/it]Epoch: 4/10. Loss: 1.0019:  12%|[36m█▏        [0m| 3/26 [00:03<00:25,  1.10s/it]Epoch: 4/10. Loss: 1.0008:  12%|[36m█▏        [0m| 3/26 [00:04<00:25,  1.10s/it]Epoch: 4/10. Loss: 1.0008:  15%|[36m█▌        [0m| 4/26 [00:04<00:23,  1.08s/it]Epoch: 4/10. Loss: 0.9016:  15%|[36m█▌        [0m| 4/26 [00:05<00:23,  1.08s/it]Epoch: 4/10. Loss: 0.9016:  19%|[36m█▉        [0m| 5/26 [00:05<00:23,  1.11s/it]Epoch: 4/10. Loss: 1.0281:  19%|[36m█▉        [0m| 5/26 [00:06<00:23,  1.11s/it]Epoch: 4/10. Loss: 1.0281:  23%|[36m██▎       [0m| 6/26 [00:06<00:21,  1.06s/it]Epoch: 4/10. Loss: 0.9830:  23%|[36m██▎       [0m| 6/26 [00:07<00:21,  1.06s/it]Epoch: 4/10. Loss: 0.9830:  27%|[36m██▋       [0m| 7/26 [00:07<00:19,  1.00s/it]Epoch: 4/10. Loss: 0.9565:  27%|[36m██▋       [0m| 7/26 [00:09<00:19,  1.00s/it]Epoch: 4/10. Loss: 0.9565:  31%|[36m███       [0m| 8/26 [00:09<00:22,  1.25s/it]Epoch: 4/10. Loss: 0.9668:  31%|[36m███       [0m| 8/26 [00:10<00:22,  1.25s/it]Epoch: 4/10. Loss: 0.9668:  35%|[36m███▍      [0m| 9/26 [00:10<00:19,  1.14s/it]Epoch: 4/10. Loss: 0.9697:  35%|[36m███▍      [0m| 9/26 [00:10<00:19,  1.14s/it]Epoch: 4/10. Loss: 0.9697:  38%|[36m███▊      [0m| 10/26 [00:10<00:17,  1.06s/it]Epoch: 4/10. Loss: 0.9530:  38%|[36m███▊      [0m| 10/26 [00:11<00:17,  1.06s/it]Epoch: 4/10. Loss: 0.9530:  42%|[36m████▏     [0m| 11/26 [00:11<00:15,  1.01s/it]Epoch: 4/10. Loss: 0.9209:  42%|[36m████▏     [0m| 11/26 [00:12<00:15,  1.01s/it]Epoch: 4/10. Loss: 0.9209:  46%|[36m████▌     [0m| 12/26 [00:12<00:13,  1.00it/s]Epoch: 4/10. Loss: 0.9999:  46%|[36m████▌     [0m| 12/26 [00:13<00:13,  1.00it/s]Epoch: 4/10. Loss: 0.9999:  50%|[36m█████     [0m| 13/26 [00:13<00:12,  1.02it/s]Epoch: 4/10. Loss: 0.9791:  50%|[36m█████     [0m| 13/26 [00:14<00:12,  1.02it/s]Epoch: 4/10. Loss: 0.9791:  54%|[36m█████▍    [0m| 14/26 [00:14<00:11,  1.00it/s]Epoch: 4/10. Loss: 0.9454:  54%|[36m█████▍    [0m| 14/26 [00:15<00:11,  1.00it/s]Epoch: 4/10. Loss: 0.9454:  58%|[36m█████▊    [0m| 15/26 [00:15<00:10,  1.09it/s]Epoch: 4/10. Loss: 0.8966:  58%|[36m█████▊    [0m| 15/26 [00:16<00:10,  1.09it/s]Epoch: 4/10. Loss: 0.8966:  62%|[36m██████▏   [0m| 16/26 [00:16<00:09,  1.11it/s]Epoch: 4/10. Loss: 0.9867:  62%|[36m██████▏   [0m| 16/26 [00:17<00:09,  1.11it/s]Epoch: 4/10. Loss: 0.9867:  65%|[36m██████▌   [0m| 17/26 [00:17<00:07,  1.15it/s]Epoch: 4/10. Loss: 0.9611:  65%|[36m██████▌   [0m| 17/26 [00:17<00:07,  1.15it/s]Epoch: 4/10. Loss: 0.9611:  69%|[36m██████▉   [0m| 18/26 [00:17<00:06,  1.19it/s]Epoch: 4/10. Loss: 1.0094:  69%|[36m██████▉   [0m| 18/26 [00:19<00:06,  1.19it/s]Epoch: 4/10. Loss: 1.0094:  73%|[36m███████▎  [0m| 19/26 [00:19<00:06,  1.10it/s]Epoch: 4/10. Loss: 0.9092:  73%|[36m███████▎  [0m| 19/26 [00:19<00:06,  1.10it/s]Epoch: 4/10. Loss: 0.9092:  77%|[36m███████▋  [0m| 20/26 [00:19<00:05,  1.11it/s]Epoch: 4/10. Loss: 0.9054:  77%|[36m███████▋  [0m| 20/26 [00:20<00:05,  1.11it/s]Epoch: 4/10. Loss: 0.9054:  81%|[36m████████  [0m| 21/26 [00:20<00:04,  1.12it/s]Epoch: 4/10. Loss: 0.9642:  81%|[36m████████  [0m| 21/26 [00:21<00:04,  1.12it/s]Epoch: 4/10. Loss: 0.9642:  85%|[36m████████▍ [0m| 22/26 [00:21<00:03,  1.15it/s]Epoch: 4/10. Loss: 0.8565:  85%|[36m████████▍ [0m| 22/26 [00:22<00:03,  1.15it/s]Epoch: 4/10. Loss: 0.8565:  88%|[36m████████▊ [0m| 23/26 [00:22<00:02,  1.13it/s]Epoch: 4/10. Loss: 0.9893:  88%|[36m████████▊ [0m| 23/26 [00:23<00:02,  1.13it/s]Epoch: 4/10. Loss: 0.9893:  92%|[36m█████████▏[0m| 24/26 [00:23<00:01,  1.12it/s]Epoch: 4/10. Loss: 1.0125:  92%|[36m█████████▏[0m| 24/26 [00:24<00:01,  1.12it/s]Epoch: 4/10. Loss: 1.0125:  96%|[36m█████████▌[0m| 25/26 [00:24<00:00,  1.09it/s]Epoch: 4/10. Loss: 0.9089:  96%|[36m█████████▌[0m| 25/26 [00:25<00:00,  1.09it/s]Epoch: 4/10. Loss: 0.9089: 100%|[36m██████████[0m| 26/26 [00:25<00:00,  1.21it/s]Epoch: 4/10. Loss: 0.9089: 100%|[36m██████████[0m| 26/26 [00:25<00:00,  1.04it/s]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:05,  1.05it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:05,  1.10s/it] 43%|[33m████▎     [0m| 3/7 [00:02<00:03,  1.04it/s] 57%|[33m█████▋    [0m| 4/7 [00:04<00:03,  1.19s/it] 71%|[33m███████▏  [0m| 5/7 [00:04<00:01,  1.08it/s] 86%|[33m████████▌ [0m| 6/7 [00:05<00:00,  1.12it/s]100%|[33m██████████[0m| 7/7 [00:06<00:00,  1.45it/s]100%|[33m██████████[0m| 7/7 [00:06<00:00,  1.16it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 5/10. Loss: 0.9828:   0%|[36m          [0m| 0/26 [00:01<?, ?it/s]Epoch: 5/10. Loss: 0.9828:   4%|[36m▍         [0m| 1/26 [00:01<00:30,  1.21s/it]Epoch: 5/10. Loss: 0.8632:   4%|[36m▍         [0m| 1/26 [00:02<00:30,  1.21s/it]Epoch: 5/10. Loss: 0.8632:   8%|[36m▊         [0m| 2/26 [00:02<00:24,  1.00s/it]Epoch: 5/10. Loss: 0.8919:   8%|[36m▊         [0m| 2/26 [00:02<00:24,  1.00s/it]Epoch: 5/10. Loss: 0.8919:  12%|[36m█▏        [0m| 3/26 [00:02<00:19,  1.16it/s]Epoch: 5/10. Loss: 0.9658:  12%|[36m█▏        [0m| 3/26 [00:03<00:19,  1.16it/s]Epoch: 5/10. Loss: 0.9658:  15%|[36m█▌        [0m| 4/26 [00:03<00:19,  1.11it/s]Epoch: 5/10. Loss: 0.8083:  15%|[36m█▌        [0m| 4/26 [00:04<00:19,  1.11it/s]Epoch: 5/10. Loss: 0.8083:  19%|[36m█▉        [0m| 5/26 [00:04<00:18,  1.15it/s]Epoch: 5/10. Loss: 0.9661:  19%|[36m█▉        [0m| 5/26 [00:05<00:18,  1.15it/s]Epoch: 5/10. Loss: 0.9661:  23%|[36m██▎       [0m| 6/26 [00:05<00:17,  1.13it/s]Epoch: 5/10. Loss: 0.9495:  23%|[36m██▎       [0m| 6/26 [00:06<00:17,  1.13it/s]Epoch: 5/10. Loss: 0.9495:  27%|[36m██▋       [0m| 7/26 [00:06<00:16,  1.13it/s]Epoch: 5/10. Loss: 0.9480:  27%|[36m██▋       [0m| 7/26 [00:07<00:16,  1.13it/s]Epoch: 5/10. Loss: 0.9480:  31%|[36m███       [0m| 8/26 [00:07<00:20,  1.11s/it]Epoch: 5/10. Loss: 0.8928:  31%|[36m███       [0m| 8/26 [00:08<00:20,  1.11s/it]Epoch: 5/10. Loss: 0.8928:  35%|[36m███▍      [0m| 9/26 [00:08<00:17,  1.04s/it]Epoch: 5/10. Loss: 0.9764:  35%|[36m███▍      [0m| 9/26 [00:09<00:17,  1.04s/it]Epoch: 5/10. Loss: 0.9764:  38%|[36m███▊      [0m| 10/26 [00:09<00:16,  1.01s/it]Epoch: 5/10. Loss: 0.8773:  38%|[36m███▊      [0m| 10/26 [00:10<00:16,  1.01s/it]Epoch: 5/10. Loss: 0.8773:  42%|[36m████▏     [0m| 11/26 [00:10<00:14,  1.02it/s]Epoch: 5/10. Loss: 0.8993:  42%|[36m████▏     [0m| 11/26 [00:11<00:14,  1.02it/s]Epoch: 5/10. Loss: 0.8993:  46%|[36m████▌     [0m| 12/26 [00:11<00:13,  1.05it/s]Epoch: 5/10. Loss: 1.0283:  46%|[36m████▌     [0m| 12/26 [00:12<00:13,  1.05it/s]Epoch: 5/10. Loss: 1.0283:  50%|[36m█████     [0m| 13/26 [00:12<00:12,  1.02it/s]Epoch: 5/10. Loss: 0.9113:  50%|[36m█████     [0m| 13/26 [00:13<00:12,  1.02it/s]Epoch: 5/10. Loss: 0.9113:  54%|[36m█████▍    [0m| 14/26 [00:13<00:10,  1.10it/s]Epoch: 5/10. Loss: 0.9193:  54%|[36m█████▍    [0m| 14/26 [00:14<00:10,  1.10it/s]Epoch: 5/10. Loss: 0.9193:  58%|[36m█████▊    [0m| 15/26 [00:14<00:10,  1.07it/s]Epoch: 5/10. Loss: 0.9158:  58%|[36m█████▊    [0m| 15/26 [00:16<00:10,  1.07it/s]Epoch: 5/10. Loss: 0.9158:  62%|[36m██████▏   [0m| 16/26 [00:16<00:13,  1.30s/it]Epoch: 5/10. Loss: 1.0141:  62%|[36m██████▏   [0m| 16/26 [00:17<00:13,  1.30s/it]Epoch: 5/10. Loss: 1.0141:  65%|[36m██████▌   [0m| 17/26 [00:17<00:10,  1.15s/it]Epoch: 5/10. Loss: 0.9254:  65%|[36m██████▌   [0m| 17/26 [00:18<00:10,  1.15s/it]Epoch: 5/10. Loss: 0.9254:  69%|[36m██████▉   [0m| 18/26 [00:18<00:08,  1.10s/it]Epoch: 5/10. Loss: 0.9614:  69%|[36m██████▉   [0m| 18/26 [00:21<00:08,  1.10s/it]Epoch: 5/10. Loss: 0.9614:  73%|[36m███████▎  [0m| 19/26 [00:21<00:12,  1.75s/it]Epoch: 5/10. Loss: 0.8669:  73%|[36m███████▎  [0m| 19/26 [00:22<00:12,  1.75s/it]Epoch: 5/10. Loss: 0.8669:  77%|[36m███████▋  [0m| 20/26 [00:22<00:09,  1.59s/it]Epoch: 5/10. Loss: 0.9474:  77%|[36m███████▋  [0m| 20/26 [00:23<00:09,  1.59s/it]Epoch: 5/10. Loss: 0.9474:  81%|[36m████████  [0m| 21/26 [00:23<00:07,  1.43s/it]Epoch: 5/10. Loss: 0.9269:  81%|[36m████████  [0m| 21/26 [00:25<00:07,  1.43s/it]Epoch: 5/10. Loss: 0.9269:  85%|[36m████████▍ [0m| 22/26 [00:25<00:05,  1.36s/it]Epoch: 5/10. Loss: 0.8953:  85%|[36m████████▍ [0m| 22/26 [00:26<00:05,  1.36s/it]Epoch: 5/10. Loss: 0.8953:  88%|[36m████████▊ [0m| 23/26 [00:26<00:04,  1.37s/it]Epoch: 5/10. Loss: 0.9216:  88%|[36m████████▊ [0m| 23/26 [00:27<00:04,  1.37s/it]Epoch: 5/10. Loss: 0.9216:  92%|[36m█████████▏[0m| 24/26 [00:27<00:02,  1.24s/it]Epoch: 5/10. Loss: 0.8898:  92%|[36m█████████▏[0m| 24/26 [00:28<00:02,  1.24s/it]Epoch: 5/10. Loss: 0.8898:  96%|[36m█████████▌[0m| 25/26 [00:28<00:01,  1.13s/it]Epoch: 5/10. Loss: 0.8917:  96%|[36m█████████▌[0m| 25/26 [00:28<00:01,  1.13s/it]Epoch: 5/10. Loss: 0.8917: 100%|[36m██████████[0m| 26/26 [00:28<00:00,  1.04it/s]Epoch: 5/10. Loss: 0.8917: 100%|[36m██████████[0m| 26/26 [00:28<00:00,  1.11s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:05,  1.06it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:05,  1.10s/it] 43%|[33m████▎     [0m| 3/7 [00:02<00:03,  1.04it/s] 57%|[33m█████▋    [0m| 4/7 [00:04<00:03,  1.15s/it] 71%|[33m███████▏  [0m| 5/7 [00:04<00:01,  1.12it/s] 86%|[33m████████▌ [0m| 6/7 [00:05<00:00,  1.10it/s]100%|[33m██████████[0m| 7/7 [00:06<00:00,  1.43it/s]100%|[33m██████████[0m| 7/7 [00:06<00:00,  1.16it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 6/10. Loss: 0.9158:   0%|[36m          [0m| 0/26 [00:01<?, ?it/s]Epoch: 6/10. Loss: 0.9158:   4%|[36m▍         [0m| 1/26 [00:01<00:25,  1.03s/it]Epoch: 6/10. Loss: 0.9024:   4%|[36m▍         [0m| 1/26 [00:01<00:25,  1.03s/it]Epoch: 6/10. Loss: 0.9024:   8%|[36m▊         [0m| 2/26 [00:01<00:23,  1.02it/s]Epoch: 6/10. Loss: 0.8873:   8%|[36m▊         [0m| 2/26 [00:02<00:23,  1.02it/s]Epoch: 6/10. Loss: 0.8873:  12%|[36m█▏        [0m| 3/26 [00:02<00:22,  1.02it/s]Epoch: 6/10. Loss: 0.9365:  12%|[36m█▏        [0m| 3/26 [00:03<00:22,  1.02it/s]Epoch: 6/10. Loss: 0.9365:  15%|[36m█▌        [0m| 4/26 [00:03<00:21,  1.00it/s]Epoch: 6/10. Loss: 0.9703:  15%|[36m█▌        [0m| 4/26 [00:04<00:21,  1.00it/s]Epoch: 6/10. Loss: 0.9703:  19%|[36m█▉        [0m| 5/26 [00:04<00:19,  1.06it/s]Epoch: 6/10. Loss: 0.8262:  19%|[36m█▉        [0m| 5/26 [00:05<00:19,  1.06it/s]Epoch: 6/10. Loss: 0.8262:  23%|[36m██▎       [0m| 6/26 [00:05<00:18,  1.06it/s]Epoch: 6/10. Loss: 0.9795:  23%|[36m██▎       [0m| 6/26 [00:06<00:18,  1.06it/s]Epoch: 6/10. Loss: 0.9795:  27%|[36m██▋       [0m| 7/26 [00:06<00:17,  1.08it/s]Epoch: 6/10. Loss: 1.0133:  27%|[36m██▋       [0m| 7/26 [00:07<00:17,  1.08it/s]Epoch: 6/10. Loss: 1.0133:  31%|[36m███       [0m| 8/26 [00:07<00:16,  1.11it/s]Epoch: 6/10. Loss: 0.8512:  31%|[36m███       [0m| 8/26 [00:08<00:16,  1.11it/s]Epoch: 6/10. Loss: 0.8512:  35%|[36m███▍      [0m| 9/26 [00:08<00:15,  1.12it/s]Epoch: 6/10. Loss: 0.9732:  35%|[36m███▍      [0m| 9/26 [00:09<00:15,  1.12it/s]Epoch: 6/10. Loss: 0.9732:  38%|[36m███▊      [0m| 10/26 [00:09<00:14,  1.10it/s]Epoch: 6/10. Loss: 0.8803:  38%|[36m███▊      [0m| 10/26 [00:10<00:14,  1.10it/s]Epoch: 6/10. Loss: 0.8803:  42%|[36m████▏     [0m| 11/26 [00:10<00:13,  1.14it/s]Epoch: 6/10. Loss: 0.9244:  42%|[36m████▏     [0m| 11/26 [00:10<00:13,  1.14it/s]Epoch: 6/10. Loss: 0.9244:  46%|[36m████▌     [0m| 12/26 [00:10<00:12,  1.17it/s]Epoch: 6/10. Loss: 0.8697:  46%|[36m████▌     [0m| 12/26 [00:11<00:12,  1.17it/s]Epoch: 6/10. Loss: 0.8697:  50%|[36m█████     [0m| 13/26 [00:11<00:11,  1.11it/s]Epoch: 6/10. Loss: 0.8580:  50%|[36m█████     [0m| 13/26 [00:12<00:11,  1.11it/s]Epoch: 6/10. Loss: 0.8580:  54%|[36m█████▍    [0m| 14/26 [00:12<00:11,  1.09it/s]Epoch: 6/10. Loss: 0.8901:  54%|[36m█████▍    [0m| 14/26 [00:13<00:11,  1.09it/s]Epoch: 6/10. Loss: 0.8901:  58%|[36m█████▊    [0m| 15/26 [00:13<00:10,  1.08it/s]Epoch: 6/10. Loss: 0.8991:  58%|[36m█████▊    [0m| 15/26 [00:14<00:10,  1.08it/s]Epoch: 6/10. Loss: 0.8991:  62%|[36m██████▏   [0m| 16/26 [00:14<00:09,  1.06it/s]Epoch: 6/10. Loss: 0.9014:  62%|[36m██████▏   [0m| 16/26 [00:15<00:09,  1.06it/s]Epoch: 6/10. Loss: 0.9014:  65%|[36m██████▌   [0m| 17/26 [00:15<00:08,  1.02it/s]Epoch: 6/10. Loss: 0.9353:  65%|[36m██████▌   [0m| 17/26 [00:16<00:08,  1.02it/s]Epoch: 6/10. Loss: 0.9353:  69%|[36m██████▉   [0m| 18/26 [00:16<00:07,  1.03it/s]Epoch: 6/10. Loss: 0.8017:  69%|[36m██████▉   [0m| 18/26 [00:17<00:07,  1.03it/s]Epoch: 6/10. Loss: 0.8017:  73%|[36m███████▎  [0m| 19/26 [00:17<00:06,  1.07it/s]Epoch: 6/10. Loss: 0.9781:  73%|[36m███████▎  [0m| 19/26 [00:18<00:06,  1.07it/s]Epoch: 6/10. Loss: 0.9781:  77%|[36m███████▋  [0m| 20/26 [00:18<00:05,  1.05it/s]Epoch: 6/10. Loss: 0.9567:  77%|[36m███████▋  [0m| 20/26 [00:19<00:05,  1.05it/s]Epoch: 6/10. Loss: 0.9567:  81%|[36m████████  [0m| 21/26 [00:19<00:05,  1.02s/it]Epoch: 6/10. Loss: 0.8343:  81%|[36m████████  [0m| 21/26 [00:20<00:05,  1.02s/it]Epoch: 6/10. Loss: 0.8343:  85%|[36m████████▍ [0m| 22/26 [00:20<00:03,  1.01it/s]Epoch: 6/10. Loss: 0.9577:  85%|[36m████████▍ [0m| 22/26 [00:21<00:03,  1.01it/s]Epoch: 6/10. Loss: 0.9577:  88%|[36m████████▊ [0m| 23/26 [00:21<00:03,  1.02s/it]Epoch: 6/10. Loss: 0.9244:  88%|[36m████████▊ [0m| 23/26 [00:22<00:03,  1.02s/it]Epoch: 6/10. Loss: 0.9244:  92%|[36m█████████▏[0m| 24/26 [00:22<00:01,  1.07it/s]Epoch: 6/10. Loss: 0.8792:  92%|[36m█████████▏[0m| 24/26 [00:23<00:01,  1.07it/s]Epoch: 6/10. Loss: 0.8792:  96%|[36m█████████▌[0m| 25/26 [00:23<00:00,  1.09it/s]Epoch: 6/10. Loss: 0.8960:  96%|[36m█████████▌[0m| 25/26 [00:24<00:00,  1.09it/s]Epoch: 6/10. Loss: 0.8960: 100%|[36m██████████[0m| 26/26 [00:24<00:00,  1.22it/s]Epoch: 6/10. Loss: 0.8960: 100%|[36m██████████[0m| 26/26 [00:24<00:00,  1.08it/s]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:05,  1.05it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:05,  1.12s/it] 43%|[33m████▎     [0m| 3/7 [00:02<00:03,  1.03it/s] 57%|[33m█████▋    [0m| 4/7 [00:04<00:03,  1.16s/it] 71%|[33m███████▏  [0m| 5/7 [00:04<00:01,  1.11it/s] 86%|[33m████████▌ [0m| 6/7 [00:05<00:00,  1.11it/s]100%|[33m██████████[0m| 7/7 [00:06<00:00,  1.43it/s]100%|[33m██████████[0m| 7/7 [00:06<00:00,  1.15it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 7/10. Loss: 0.8599:   0%|[36m          [0m| 0/26 [00:01<?, ?it/s]Epoch: 7/10. Loss: 0.8599:   4%|[36m▍         [0m| 1/26 [00:01<00:28,  1.13s/it]Epoch: 7/10. Loss: 0.8866:   4%|[36m▍         [0m| 1/26 [00:01<00:28,  1.13s/it]Epoch: 7/10. Loss: 0.8866:   8%|[36m▊         [0m| 2/26 [00:01<00:23,  1.03it/s]Epoch: 7/10. Loss: 0.9204:   8%|[36m▊         [0m| 2/26 [00:02<00:23,  1.03it/s]Epoch: 7/10. Loss: 0.9204:  12%|[36m█▏        [0m| 3/26 [00:02<00:21,  1.05it/s]Epoch: 7/10. Loss: 0.9521:  12%|[36m█▏        [0m| 3/26 [00:07<00:21,  1.05it/s]Epoch: 7/10. Loss: 0.9521:  15%|[36m█▌        [0m| 4/26 [00:07<00:48,  2.22s/it]Epoch: 7/10. Loss: 0.9690:  15%|[36m█▌        [0m| 4/26 [00:08<00:48,  2.22s/it]Epoch: 7/10. Loss: 0.9690:  19%|[36m█▉        [0m| 5/26 [00:08<00:37,  1.79s/it]Epoch: 7/10. Loss: 0.9316:  19%|[36m█▉        [0m| 5/26 [00:08<00:37,  1.79s/it]Epoch: 7/10. Loss: 0.9316:  23%|[36m██▎       [0m| 6/26 [00:08<00:29,  1.47s/it]Epoch: 7/10. Loss: 0.9201:  23%|[36m██▎       [0m| 6/26 [00:09<00:29,  1.47s/it]Epoch: 7/10. Loss: 0.9201:  27%|[36m██▋       [0m| 7/26 [00:09<00:23,  1.24s/it]Epoch: 7/10. Loss: 0.9544:  27%|[36m██▋       [0m| 7/26 [00:10<00:23,  1.24s/it]Epoch: 7/10. Loss: 0.9544:  31%|[36m███       [0m| 8/26 [00:10<00:20,  1.12s/it]Epoch: 7/10. Loss: 0.7975:  31%|[36m███       [0m| 8/26 [00:12<00:20,  1.12s/it]Epoch: 7/10. Loss: 0.7975:  35%|[36m███▍      [0m| 9/26 [00:12<00:25,  1.51s/it]Epoch: 7/10. Loss: 0.8956:  35%|[36m███▍      [0m| 9/26 [00:13<00:25,  1.51s/it]Epoch: 7/10. Loss: 0.8956:  38%|[36m███▊      [0m| 10/26 [00:13<00:21,  1.34s/it]Epoch: 7/10. Loss: 0.7841:  38%|[36m███▊      [0m| 10/26 [00:14<00:21,  1.34s/it]Epoch: 7/10. Loss: 0.7841:  42%|[36m████▏     [0m| 11/26 [00:14<00:18,  1.23s/it]Epoch: 7/10. Loss: 0.8888:  42%|[36m████▏     [0m| 11/26 [00:15<00:18,  1.23s/it]Epoch: 7/10. Loss: 0.8888:  46%|[36m████▌     [0m| 12/26 [00:15<00:16,  1.17s/it]Epoch: 7/10. Loss: 0.8231:  46%|[36m████▌     [0m| 12/26 [00:16<00:16,  1.17s/it]Epoch: 7/10. Loss: 0.8231:  50%|[36m█████     [0m| 13/26 [00:16<00:14,  1.13s/it]Epoch: 7/10. Loss: 0.9139:  50%|[36m█████     [0m| 13/26 [00:17<00:14,  1.13s/it]Epoch: 7/10. Loss: 0.9139:  54%|[36m█████▍    [0m| 14/26 [00:17<00:12,  1.05s/it]Epoch: 7/10. Loss: 0.8348:  54%|[36m█████▍    [0m| 14/26 [00:18<00:12,  1.05s/it]Epoch: 7/10. Loss: 0.8348:  58%|[36m█████▊    [0m| 15/26 [00:18<00:10,  1.02it/s]Epoch: 7/10. Loss: 0.9147:  58%|[36m█████▊    [0m| 15/26 [00:20<00:10,  1.02it/s]Epoch: 7/10. Loss: 0.9147:  62%|[36m██████▏   [0m| 16/26 [00:20<00:12,  1.28s/it]Epoch: 7/10. Loss: 0.9055:  62%|[36m██████▏   [0m| 16/26 [00:21<00:12,  1.28s/it]Epoch: 7/10. Loss: 0.9055:  65%|[36m██████▌   [0m| 17/26 [00:21<00:10,  1.21s/it]Epoch: 7/10. Loss: 0.9165:  65%|[36m██████▌   [0m| 17/26 [00:22<00:10,  1.21s/it]Epoch: 7/10. Loss: 0.9165:  69%|[36m██████▉   [0m| 18/26 [00:22<00:09,  1.15s/it]Epoch: 7/10. Loss: 0.9577:  69%|[36m██████▉   [0m| 18/26 [00:24<00:09,  1.15s/it]Epoch: 7/10. Loss: 0.9577:  73%|[36m███████▎  [0m| 19/26 [00:24<00:08,  1.25s/it]Epoch: 7/10. Loss: 0.8978:  73%|[36m███████▎  [0m| 19/26 [00:25<00:08,  1.25s/it]Epoch: 7/10. Loss: 0.8978:  77%|[36m███████▋  [0m| 20/26 [00:25<00:06,  1.16s/it]Epoch: 7/10. Loss: 0.8993:  77%|[36m███████▋  [0m| 20/26 [00:26<00:06,  1.16s/it]Epoch: 7/10. Loss: 0.8993:  81%|[36m████████  [0m| 21/26 [00:26<00:06,  1.29s/it]Epoch: 7/10. Loss: 0.8520:  81%|[36m████████  [0m| 21/26 [00:27<00:06,  1.29s/it]Epoch: 7/10. Loss: 0.8520:  85%|[36m████████▍ [0m| 22/26 [00:27<00:04,  1.12s/it]Epoch: 7/10. Loss: 0.8452:  85%|[36m████████▍ [0m| 22/26 [00:28<00:04,  1.12s/it]Epoch: 7/10. Loss: 0.8452:  88%|[36m████████▊ [0m| 23/26 [00:28<00:03,  1.12s/it]Epoch: 7/10. Loss: 0.9063:  88%|[36m████████▊ [0m| 23/26 [00:29<00:03,  1.12s/it]Epoch: 7/10. Loss: 0.9063:  92%|[36m█████████▏[0m| 24/26 [00:29<00:02,  1.11s/it]Epoch: 7/10. Loss: 0.8622:  92%|[36m█████████▏[0m| 24/26 [00:30<00:02,  1.11s/it]Epoch: 7/10. Loss: 0.8622:  96%|[36m█████████▌[0m| 25/26 [00:30<00:01,  1.05s/it]Epoch: 7/10. Loss: 0.7888:  96%|[36m█████████▌[0m| 25/26 [00:31<00:01,  1.05s/it]Epoch: 7/10. Loss: 0.7888: 100%|[36m██████████[0m| 26/26 [00:31<00:00,  1.11it/s]Epoch: 7/10. Loss: 0.7888: 100%|[36m██████████[0m| 26/26 [00:31<00:00,  1.20s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:05,  1.04it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:05,  1.14s/it] 43%|[33m████▎     [0m| 3/7 [00:03<00:04,  1.00s/it] 57%|[33m█████▋    [0m| 4/7 [00:04<00:03,  1.19s/it] 71%|[33m███████▏  [0m| 5/7 [00:04<00:01,  1.08it/s] 86%|[33m████████▌ [0m| 6/7 [00:05<00:00,  1.11it/s]100%|[33m██████████[0m| 7/7 [00:06<00:00,  1.44it/s]100%|[33m██████████[0m| 7/7 [00:06<00:00,  1.14it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 8/10. Loss: 0.8125:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 8/10. Loss: 0.8125:   4%|[36m▍         [0m| 1/26 [00:00<00:21,  1.14it/s]Epoch: 8/10. Loss: 0.9045:   4%|[36m▍         [0m| 1/26 [00:01<00:21,  1.14it/s]Epoch: 8/10. Loss: 0.9045:   8%|[36m▊         [0m| 2/26 [00:01<00:20,  1.16it/s]Epoch: 8/10. Loss: 0.8496:   8%|[36m▊         [0m| 2/26 [00:02<00:20,  1.16it/s]Epoch: 8/10. Loss: 0.8496:  12%|[36m█▏        [0m| 3/26 [00:02<00:20,  1.11it/s]Epoch: 8/10. Loss: 0.9698:  12%|[36m█▏        [0m| 3/26 [00:03<00:20,  1.11it/s]Epoch: 8/10. Loss: 0.9698:  15%|[36m█▌        [0m| 4/26 [00:03<00:20,  1.10it/s]Epoch: 8/10. Loss: 0.8479:  15%|[36m█▌        [0m| 4/26 [00:04<00:20,  1.10it/s]Epoch: 8/10. Loss: 0.8479:  19%|[36m█▉        [0m| 5/26 [00:04<00:19,  1.09it/s]Epoch: 8/10. Loss: 0.9613:  19%|[36m█▉        [0m| 5/26 [00:05<00:19,  1.09it/s]Epoch: 8/10. Loss: 0.9613:  23%|[36m██▎       [0m| 6/26 [00:05<00:19,  1.03it/s]Epoch: 8/10. Loss: 0.9487:  23%|[36m██▎       [0m| 6/26 [00:06<00:19,  1.03it/s]Epoch: 8/10. Loss: 0.9487:  27%|[36m██▋       [0m| 7/26 [00:06<00:19,  1.03s/it]Epoch: 8/10. Loss: 0.8998:  27%|[36m██▋       [0m| 7/26 [00:07<00:19,  1.03s/it]Epoch: 8/10. Loss: 0.8998:  31%|[36m███       [0m| 8/26 [00:07<00:17,  1.02it/s]Epoch: 8/10. Loss: 0.8489:  31%|[36m███       [0m| 8/26 [00:08<00:17,  1.02it/s]Epoch: 8/10. Loss: 0.8489:  35%|[36m███▍      [0m| 9/26 [00:08<00:16,  1.02it/s]Epoch: 8/10. Loss: 0.9170:  35%|[36m███▍      [0m| 9/26 [00:09<00:16,  1.02it/s]Epoch: 8/10. Loss: 0.9170:  38%|[36m███▊      [0m| 10/26 [00:09<00:14,  1.08it/s]Epoch: 8/10. Loss: 0.8706:  38%|[36m███▊      [0m| 10/26 [00:10<00:14,  1.08it/s]Epoch: 8/10. Loss: 0.8706:  42%|[36m████▏     [0m| 11/26 [00:10<00:14,  1.00it/s]Epoch: 8/10. Loss: 0.8954:  42%|[36m████▏     [0m| 11/26 [00:11<00:14,  1.00it/s]Epoch: 8/10. Loss: 0.8954:  46%|[36m████▌     [0m| 12/26 [00:11<00:14,  1.01s/it]Epoch: 8/10. Loss: 0.8498:  46%|[36m████▌     [0m| 12/26 [00:12<00:14,  1.01s/it]Epoch: 8/10. Loss: 0.8498:  50%|[36m█████     [0m| 13/26 [00:12<00:12,  1.08it/s]Epoch: 8/10. Loss: 0.8280:  50%|[36m█████     [0m| 13/26 [00:13<00:12,  1.08it/s]Epoch: 8/10. Loss: 0.8280:  54%|[36m█████▍    [0m| 14/26 [00:13<00:10,  1.13it/s]Epoch: 8/10. Loss: 0.9230:  54%|[36m█████▍    [0m| 14/26 [00:13<00:10,  1.13it/s]Epoch: 8/10. Loss: 0.9230:  58%|[36m█████▊    [0m| 15/26 [00:13<00:09,  1.15it/s]Epoch: 8/10. Loss: 0.9054:  58%|[36m█████▊    [0m| 15/26 [00:14<00:09,  1.15it/s]Epoch: 8/10. Loss: 0.9054:  62%|[36m██████▏   [0m| 16/26 [00:14<00:09,  1.10it/s]Epoch: 8/10. Loss: 0.8875:  62%|[36m██████▏   [0m| 16/26 [00:16<00:09,  1.10it/s]Epoch: 8/10. Loss: 0.8875:  65%|[36m██████▌   [0m| 17/26 [00:16<00:08,  1.01it/s]Epoch: 8/10. Loss: 0.7734:  65%|[36m██████▌   [0m| 17/26 [00:16<00:08,  1.01it/s]Epoch: 8/10. Loss: 0.7734:  69%|[36m██████▉   [0m| 18/26 [00:16<00:07,  1.06it/s]Epoch: 8/10. Loss: 0.9143:  69%|[36m██████▉   [0m| 18/26 [00:18<00:07,  1.06it/s]Epoch: 8/10. Loss: 0.9143:  73%|[36m███████▎  [0m| 19/26 [00:18<00:06,  1.03it/s]Epoch: 8/10. Loss: 0.9248:  73%|[36m███████▎  [0m| 19/26 [00:18<00:06,  1.03it/s]Epoch: 8/10. Loss: 0.9248:  77%|[36m███████▋  [0m| 20/26 [00:18<00:05,  1.06it/s]Epoch: 8/10. Loss: 0.8483:  77%|[36m███████▋  [0m| 20/26 [00:19<00:05,  1.06it/s]Epoch: 8/10. Loss: 0.8483:  81%|[36m████████  [0m| 21/26 [00:19<00:04,  1.06it/s]Epoch: 8/10. Loss: 0.8162:  81%|[36m████████  [0m| 21/26 [00:21<00:04,  1.06it/s]Epoch: 8/10. Loss: 0.8162:  85%|[36m████████▍ [0m| 22/26 [00:21<00:04,  1.25s/it]Epoch: 8/10. Loss: 0.8493:  85%|[36m████████▍ [0m| 22/26 [00:22<00:04,  1.25s/it]Epoch: 8/10. Loss: 0.8493:  88%|[36m████████▊ [0m| 23/26 [00:22<00:03,  1.11s/it]Epoch: 8/10. Loss: 0.8055:  88%|[36m████████▊ [0m| 23/26 [00:23<00:03,  1.11s/it]Epoch: 8/10. Loss: 0.8055:  92%|[36m█████████▏[0m| 24/26 [00:23<00:02,  1.07s/it]Epoch: 8/10. Loss: 0.7945:  92%|[36m█████████▏[0m| 24/26 [00:24<00:02,  1.07s/it]Epoch: 8/10. Loss: 0.7945:  96%|[36m█████████▌[0m| 25/26 [00:24<00:00,  1.01it/s]Epoch: 8/10. Loss: 0.7328:  96%|[36m█████████▌[0m| 25/26 [00:25<00:00,  1.01it/s]Epoch: 8/10. Loss: 0.7328: 100%|[36m██████████[0m| 26/26 [00:25<00:00,  1.12it/s]Epoch: 8/10. Loss: 0.7328: 100%|[36m██████████[0m| 26/26 [00:25<00:00,  1.04it/s]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:01<00:09,  1.51s/it] 29%|[33m██▊       [0m| 2/7 [00:02<00:06,  1.37s/it] 43%|[33m████▎     [0m| 3/7 [00:03<00:04,  1.08s/it] 57%|[33m█████▋    [0m| 4/7 [00:05<00:03,  1.30s/it] 71%|[33m███████▏  [0m| 5/7 [00:05<00:01,  1.04it/s] 86%|[33m████████▌ [0m| 6/7 [00:06<00:00,  1.09it/s]100%|[33m██████████[0m| 7/7 [00:06<00:00,  1.43it/s]100%|[33m██████████[0m| 7/7 [00:06<00:00,  1.06it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 9/10. Loss: 0.8085:   0%|[36m          [0m| 0/26 [00:01<?, ?it/s]Epoch: 9/10. Loss: 0.8085:   4%|[36m▍         [0m| 1/26 [00:01<00:43,  1.73s/it]Epoch: 9/10. Loss: 0.8150:   4%|[36m▍         [0m| 1/26 [00:02<00:43,  1.73s/it]Epoch: 9/10. Loss: 0.8150:   8%|[36m▊         [0m| 2/26 [00:02<00:32,  1.34s/it]Epoch: 9/10. Loss: 0.9079:   8%|[36m▊         [0m| 2/26 [00:03<00:32,  1.34s/it]Epoch: 9/10. Loss: 0.9079:  12%|[36m█▏        [0m| 3/26 [00:03<00:28,  1.26s/it]Epoch: 9/10. Loss: 0.8514:  12%|[36m█▏        [0m| 3/26 [00:05<00:28,  1.26s/it]Epoch: 9/10. Loss: 0.8514:  15%|[36m█▌        [0m| 4/26 [00:05<00:28,  1.32s/it]Epoch: 9/10. Loss: 0.7325:  15%|[36m█▌        [0m| 4/26 [00:06<00:28,  1.32s/it]Epoch: 9/10. Loss: 0.7325:  19%|[36m█▉        [0m| 5/26 [00:06<00:24,  1.19s/it]Epoch: 9/10. Loss: 0.8725:  19%|[36m█▉        [0m| 5/26 [00:07<00:24,  1.19s/it]Epoch: 9/10. Loss: 0.8725:  23%|[36m██▎       [0m| 6/26 [00:07<00:21,  1.07s/it]Epoch: 9/10. Loss: 0.8379:  23%|[36m██▎       [0m| 6/26 [00:08<00:21,  1.07s/it]Epoch: 9/10. Loss: 0.8379:  27%|[36m██▋       [0m| 7/26 [00:08<00:20,  1.07s/it]Epoch: 9/10. Loss: 0.8645:  27%|[36m██▋       [0m| 7/26 [00:09<00:20,  1.07s/it]Epoch: 9/10. Loss: 0.8645:  31%|[36m███       [0m| 8/26 [00:09<00:19,  1.09s/it]Epoch: 9/10. Loss: 0.8112:  31%|[36m███       [0m| 8/26 [00:10<00:19,  1.09s/it]Epoch: 9/10. Loss: 0.8112:  35%|[36m███▍      [0m| 9/26 [00:10<00:18,  1.06s/it]Epoch: 9/10. Loss: 0.9160:  35%|[36m███▍      [0m| 9/26 [00:11<00:18,  1.06s/it]Epoch: 9/10. Loss: 0.9160:  38%|[36m███▊      [0m| 10/26 [00:11<00:19,  1.19s/it]Epoch: 9/10. Loss: 0.9120:  38%|[36m███▊      [0m| 10/26 [00:12<00:19,  1.19s/it]Epoch: 9/10. Loss: 0.9120:  42%|[36m████▏     [0m| 11/26 [00:12<00:16,  1.11s/it]Epoch: 9/10. Loss: 0.7921:  42%|[36m████▏     [0m| 11/26 [00:13<00:16,  1.11s/it]Epoch: 9/10. Loss: 0.7921:  46%|[36m████▌     [0m| 12/26 [00:13<00:15,  1.07s/it]Epoch: 9/10. Loss: 0.8691:  46%|[36m████▌     [0m| 12/26 [00:14<00:15,  1.07s/it]Epoch: 9/10. Loss: 0.8691:  50%|[36m█████     [0m| 13/26 [00:14<00:13,  1.06s/it]Epoch: 9/10. Loss: 0.8908:  50%|[36m█████     [0m| 13/26 [00:15<00:13,  1.06s/it]Epoch: 9/10. Loss: 0.8908:  54%|[36m█████▍    [0m| 14/26 [00:15<00:12,  1.04s/it]Epoch: 9/10. Loss: 0.7795:  54%|[36m█████▍    [0m| 14/26 [00:16<00:12,  1.04s/it]Epoch: 9/10. Loss: 0.7795:  58%|[36m█████▊    [0m| 15/26 [00:16<00:11,  1.03s/it]Epoch: 9/10. Loss: 0.7842:  58%|[36m█████▊    [0m| 15/26 [00:17<00:11,  1.03s/it]Epoch: 9/10. Loss: 0.7842:  62%|[36m██████▏   [0m| 16/26 [00:17<00:09,  1.02it/s]Epoch: 9/10. Loss: 0.8472:  62%|[36m██████▏   [0m| 16/26 [00:22<00:09,  1.02it/s]Epoch: 9/10. Loss: 0.8472:  65%|[36m██████▌   [0m| 17/26 [00:22<00:18,  2.04s/it]Epoch: 9/10. Loss: 0.9684:  65%|[36m██████▌   [0m| 17/26 [00:24<00:18,  2.04s/it]Epoch: 9/10. Loss: 0.9684:  69%|[36m██████▉   [0m| 18/26 [00:24<00:16,  2.01s/it]Epoch: 9/10. Loss: 0.9273:  69%|[36m██████▉   [0m| 18/26 [00:24<00:16,  2.01s/it]Epoch: 9/10. Loss: 0.9273:  73%|[36m███████▎  [0m| 19/26 [00:24<00:11,  1.67s/it]Epoch: 9/10. Loss: 0.8292:  73%|[36m███████▎  [0m| 19/26 [00:25<00:11,  1.67s/it]Epoch: 9/10. Loss: 0.8292:  77%|[36m███████▋  [0m| 20/26 [00:25<00:08,  1.39s/it]Epoch: 9/10. Loss: 0.8251:  77%|[36m███████▋  [0m| 20/26 [00:26<00:08,  1.39s/it]Epoch: 9/10. Loss: 0.8251:  81%|[36m████████  [0m| 21/26 [00:26<00:06,  1.24s/it]Epoch: 9/10. Loss: 0.8656:  81%|[36m████████  [0m| 21/26 [00:27<00:06,  1.24s/it]Epoch: 9/10. Loss: 0.8656:  85%|[36m████████▍ [0m| 22/26 [00:27<00:04,  1.09s/it]Epoch: 9/10. Loss: 0.8909:  85%|[36m████████▍ [0m| 22/26 [00:29<00:04,  1.09s/it]Epoch: 9/10. Loss: 0.8909:  88%|[36m████████▊ [0m| 23/26 [00:29<00:04,  1.39s/it]Epoch: 9/10. Loss: 0.8941:  88%|[36m████████▊ [0m| 23/26 [00:30<00:04,  1.39s/it]Epoch: 9/10. Loss: 0.8941:  92%|[36m█████████▏[0m| 24/26 [00:30<00:02,  1.24s/it]Epoch: 9/10. Loss: 0.8222:  92%|[36m█████████▏[0m| 24/26 [00:31<00:02,  1.24s/it]Epoch: 9/10. Loss: 0.8222:  96%|[36m█████████▌[0m| 25/26 [00:31<00:01,  1.11s/it]Epoch: 9/10. Loss: 0.8035:  96%|[36m█████████▌[0m| 25/26 [00:31<00:01,  1.11s/it]Epoch: 9/10. Loss: 0.8035: 100%|[36m██████████[0m| 26/26 [00:31<00:00,  1.05it/s]Epoch: 9/10. Loss: 0.8035: 100%|[36m██████████[0m| 26/26 [00:31<00:00,  1.22s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:05,  1.12it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:05,  1.05s/it] 43%|[33m████▎     [0m| 3/7 [00:03<00:04,  1.21s/it] 57%|[33m█████▋    [0m| 4/7 [00:05<00:04,  1.60s/it] 71%|[33m███████▏  [0m| 5/7 [00:06<00:02,  1.17s/it] 86%|[33m████████▌ [0m| 6/7 [00:06<00:01,  1.06s/it]100%|[33m██████████[0m| 7/7 [00:07<00:00,  1.25it/s]100%|[33m██████████[0m| 7/7 [00:07<00:00,  1.02s/it]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 0/10. Loss: 1.2573:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 0/10. Loss: 1.2573:   4%|[36m▍         [0m| 1/26 [00:00<00:22,  1.11it/s]Epoch: 0/10. Loss: 2.8429:   4%|[36m▍         [0m| 1/26 [00:02<00:22,  1.11it/s]Epoch: 0/10. Loss: 2.8429:   8%|[36m▊         [0m| 2/26 [00:02<00:26,  1.10s/it]Epoch: 0/10. Loss: 3.1872:   8%|[36m▊         [0m| 2/26 [00:02<00:26,  1.10s/it]Epoch: 0/10. Loss: 3.1872:  12%|[36m█▏        [0m| 3/26 [00:02<00:21,  1.08it/s]Epoch: 0/10. Loss: 2.4541:  12%|[36m█▏        [0m| 3/26 [00:03<00:21,  1.08it/s]Epoch: 0/10. Loss: 2.4541:  15%|[36m█▌        [0m| 4/26 [00:03<00:20,  1.08it/s]Epoch: 0/10. Loss: 1.1344:  15%|[36m█▌        [0m| 4/26 [00:04<00:20,  1.08it/s]Epoch: 0/10. Loss: 1.1344:  19%|[36m█▉        [0m| 5/26 [00:04<00:18,  1.12it/s]Epoch: 0/10. Loss: 1.1720:  19%|[36m█▉        [0m| 5/26 [00:05<00:18,  1.12it/s]Epoch: 0/10. Loss: 1.1720:  23%|[36m██▎       [0m| 6/26 [00:05<00:17,  1.16it/s]Epoch: 0/10. Loss: 1.0796:  23%|[36m██▎       [0m| 6/26 [00:06<00:17,  1.16it/s]Epoch: 0/10. Loss: 1.0796:  27%|[36m██▋       [0m| 7/26 [00:06<00:18,  1.05it/s]Epoch: 0/10. Loss: 1.0291:  27%|[36m██▋       [0m| 7/26 [00:07<00:18,  1.05it/s]Epoch: 0/10. Loss: 1.0291:  31%|[36m███       [0m| 8/26 [00:07<00:16,  1.11it/s]Epoch: 0/10. Loss: 1.1046:  31%|[36m███       [0m| 8/26 [00:08<00:16,  1.11it/s]Epoch: 0/10. Loss: 1.1046:  35%|[36m███▍      [0m| 9/26 [00:08<00:15,  1.12it/s]Epoch: 0/10. Loss: 1.0047:  35%|[36m███▍      [0m| 9/26 [00:09<00:15,  1.12it/s]Epoch: 0/10. Loss: 1.0047:  38%|[36m███▊      [0m| 10/26 [00:09<00:15,  1.04it/s]Epoch: 0/10. Loss: 1.1690:  38%|[36m███▊      [0m| 10/26 [00:10<00:15,  1.04it/s]Epoch: 0/10. Loss: 1.1690:  42%|[36m████▏     [0m| 11/26 [00:10<00:14,  1.04it/s]Epoch: 0/10. Loss: 1.0266:  42%|[36m████▏     [0m| 11/26 [00:11<00:14,  1.04it/s]Epoch: 0/10. Loss: 1.0266:  46%|[36m████▌     [0m| 12/26 [00:11<00:13,  1.06it/s]Epoch: 0/10. Loss: 1.0313:  46%|[36m████▌     [0m| 12/26 [00:12<00:13,  1.06it/s]Epoch: 0/10. Loss: 1.0313:  50%|[36m█████     [0m| 13/26 [00:12<00:11,  1.09it/s]Epoch: 0/10. Loss: 1.4717:  50%|[36m█████     [0m| 13/26 [00:12<00:11,  1.09it/s]Epoch: 0/10. Loss: 1.4717:  54%|[36m█████▍    [0m| 14/26 [00:12<00:11,  1.09it/s]Epoch: 0/10. Loss: 1.2499:  54%|[36m█████▍    [0m| 14/26 [00:13<00:11,  1.09it/s]Epoch: 0/10. Loss: 1.2499:  58%|[36m█████▊    [0m| 15/26 [00:13<00:10,  1.10it/s]Epoch: 0/10. Loss: 1.0822:  58%|[36m█████▊    [0m| 15/26 [00:14<00:10,  1.10it/s]Epoch: 0/10. Loss: 1.0822:  62%|[36m██████▏   [0m| 16/26 [00:14<00:09,  1.10it/s]Epoch: 0/10. Loss: 1.2984:  62%|[36m██████▏   [0m| 16/26 [00:15<00:09,  1.10it/s]Epoch: 0/10. Loss: 1.2984:  65%|[36m██████▌   [0m| 17/26 [00:15<00:08,  1.09it/s]Epoch: 0/10. Loss: 1.2884:  65%|[36m██████▌   [0m| 17/26 [00:16<00:08,  1.09it/s]Epoch: 0/10. Loss: 1.2884:  69%|[36m██████▉   [0m| 18/26 [00:16<00:07,  1.10it/s]Epoch: 0/10. Loss: 1.1413:  69%|[36m██████▉   [0m| 18/26 [00:17<00:07,  1.10it/s]Epoch: 0/10. Loss: 1.1413:  73%|[36m███████▎  [0m| 19/26 [00:17<00:06,  1.08it/s]Epoch: 0/10. Loss: 1.1517:  73%|[36m███████▎  [0m| 19/26 [00:18<00:06,  1.08it/s]Epoch: 0/10. Loss: 1.1517:  77%|[36m███████▋  [0m| 20/26 [00:18<00:05,  1.11it/s]Epoch: 0/10. Loss: 1.2220:  77%|[36m███████▋  [0m| 20/26 [00:19<00:05,  1.11it/s]Epoch: 0/10. Loss: 1.2220:  81%|[36m████████  [0m| 21/26 [00:19<00:04,  1.10it/s]Epoch: 0/10. Loss: 1.0787:  81%|[36m████████  [0m| 21/26 [00:22<00:04,  1.10it/s]Epoch: 0/10. Loss: 1.0787:  85%|[36m████████▍ [0m| 22/26 [00:22<00:05,  1.45s/it]Epoch: 0/10. Loss: 1.0927:  85%|[36m████████▍ [0m| 22/26 [00:22<00:05,  1.45s/it]Epoch: 0/10. Loss: 1.0927:  88%|[36m████████▊ [0m| 23/26 [00:22<00:03,  1.25s/it]Epoch: 0/10. Loss: 1.0475:  88%|[36m████████▊ [0m| 23/26 [00:24<00:03,  1.25s/it]Epoch: 0/10. Loss: 1.0475:  92%|[36m█████████▏[0m| 24/26 [00:24<00:02,  1.44s/it]Epoch: 0/10. Loss: 1.2764:  92%|[36m█████████▏[0m| 24/26 [00:25<00:02,  1.44s/it]Epoch: 0/10. Loss: 1.2764:  96%|[36m█████████▌[0m| 25/26 [00:25<00:01,  1.25s/it]Epoch: 0/10. Loss: 1.0253:  96%|[36m█████████▌[0m| 25/26 [00:26<00:01,  1.25s/it]Epoch: 0/10. Loss: 1.0253: 100%|[36m██████████[0m| 26/26 [00:26<00:00,  1.16s/it]Epoch: 0/10. Loss: 1.0253: 100%|[36m██████████[0m| 26/26 [00:26<00:00,  1.02s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:05,  1.13it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:05,  1.08s/it] 43%|[33m████▎     [0m| 3/7 [00:02<00:03,  1.10it/s] 57%|[33m█████▋    [0m| 4/7 [00:04<00:03,  1.21s/it] 71%|[33m███████▏  [0m| 5/7 [00:04<00:01,  1.10it/s] 86%|[33m████████▌ [0m| 6/7 [00:05<00:00,  1.15it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.49it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.18it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 1/10. Loss: 1.0115:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 1/10. Loss: 1.0115:   4%|[36m▍         [0m| 1/26 [00:00<00:19,  1.29it/s]Epoch: 1/10. Loss: 1.1744:   4%|[36m▍         [0m| 1/26 [00:01<00:19,  1.29it/s]Epoch: 1/10. Loss: 1.1744:   8%|[36m▊         [0m| 2/26 [00:01<00:20,  1.18it/s]Epoch: 1/10. Loss: 1.2236:   8%|[36m▊         [0m| 2/26 [00:04<00:20,  1.18it/s]Epoch: 1/10. Loss: 1.2236:  12%|[36m█▏        [0m| 3/26 [00:04<00:36,  1.59s/it]Epoch: 1/10. Loss: 1.2803:  12%|[36m█▏        [0m| 3/26 [00:05<00:36,  1.59s/it]Epoch: 1/10. Loss: 1.2803:  15%|[36m█▌        [0m| 4/26 [00:05<00:31,  1.42s/it]Epoch: 1/10. Loss: 1.1297:  15%|[36m█▌        [0m| 4/26 [00:06<00:31,  1.42s/it]Epoch: 1/10. Loss: 1.1297:  19%|[36m█▉        [0m| 5/26 [00:06<00:30,  1.47s/it]Epoch: 1/10. Loss: 1.0119:  19%|[36m█▉        [0m| 5/26 [00:07<00:30,  1.47s/it]Epoch: 1/10. Loss: 1.0119:  23%|[36m██▎       [0m| 6/26 [00:07<00:25,  1.25s/it]Epoch: 1/10. Loss: 1.2082:  23%|[36m██▎       [0m| 6/26 [00:08<00:25,  1.25s/it]Epoch: 1/10. Loss: 1.2082:  27%|[36m██▋       [0m| 7/26 [00:08<00:21,  1.11s/it]Epoch: 1/10. Loss: 1.1228:  27%|[36m██▋       [0m| 7/26 [00:09<00:21,  1.11s/it]Epoch: 1/10. Loss: 1.1228:  31%|[36m███       [0m| 8/26 [00:09<00:17,  1.00it/s]Epoch: 1/10. Loss: 1.2997:  31%|[36m███       [0m| 8/26 [00:10<00:17,  1.00it/s]Epoch: 1/10. Loss: 1.2997:  35%|[36m███▍      [0m| 9/26 [00:10<00:17,  1.03s/it]Epoch: 1/10. Loss: 1.0233:  35%|[36m███▍      [0m| 9/26 [00:11<00:17,  1.03s/it]Epoch: 1/10. Loss: 1.0233:  38%|[36m███▊      [0m| 10/26 [00:11<00:16,  1.01s/it]Epoch: 1/10. Loss: 1.0760:  38%|[36m███▊      [0m| 10/26 [00:12<00:16,  1.01s/it]Epoch: 1/10. Loss: 1.0760:  42%|[36m████▏     [0m| 11/26 [00:12<00:14,  1.03it/s]Epoch: 1/10. Loss: 1.0532:  42%|[36m████▏     [0m| 11/26 [00:12<00:14,  1.03it/s]Epoch: 1/10. Loss: 1.0532:  46%|[36m████▌     [0m| 12/26 [00:12<00:12,  1.11it/s]Epoch: 1/10. Loss: 1.0878:  46%|[36m████▌     [0m| 12/26 [00:13<00:12,  1.11it/s]Epoch: 1/10. Loss: 1.0878:  50%|[36m█████     [0m| 13/26 [00:13<00:11,  1.15it/s]Epoch: 1/10. Loss: 1.0635:  50%|[36m█████     [0m| 13/26 [00:14<00:11,  1.15it/s]Epoch: 1/10. Loss: 1.0635:  54%|[36m█████▍    [0m| 14/26 [00:14<00:11,  1.07it/s]Epoch: 1/10. Loss: 0.9781:  54%|[36m█████▍    [0m| 14/26 [00:15<00:11,  1.07it/s]Epoch: 1/10. Loss: 0.9781:  58%|[36m█████▊    [0m| 15/26 [00:15<00:10,  1.03it/s]Epoch: 1/10. Loss: 1.0476:  58%|[36m█████▊    [0m| 15/26 [00:16<00:10,  1.03it/s]Epoch: 1/10. Loss: 1.0476:  62%|[36m██████▏   [0m| 16/26 [00:16<00:10,  1.00s/it]Epoch: 1/10. Loss: 0.9804:  62%|[36m██████▏   [0m| 16/26 [00:17<00:10,  1.00s/it]Epoch: 1/10. Loss: 0.9804:  65%|[36m██████▌   [0m| 17/26 [00:17<00:08,  1.04it/s]Epoch: 1/10. Loss: 1.1220:  65%|[36m██████▌   [0m| 17/26 [00:18<00:08,  1.04it/s]Epoch: 1/10. Loss: 1.1220:  69%|[36m██████▉   [0m| 18/26 [00:18<00:07,  1.06it/s]Epoch: 1/10. Loss: 0.9886:  69%|[36m██████▉   [0m| 18/26 [00:19<00:07,  1.06it/s]Epoch: 1/10. Loss: 0.9886:  73%|[36m███████▎  [0m| 19/26 [00:19<00:06,  1.02it/s]Epoch: 1/10. Loss: 0.9508:  73%|[36m███████▎  [0m| 19/26 [00:20<00:06,  1.02it/s]Epoch: 1/10. Loss: 0.9508:  77%|[36m███████▋  [0m| 20/26 [00:20<00:05,  1.01it/s]Epoch: 1/10. Loss: 1.1069:  77%|[36m███████▋  [0m| 20/26 [00:21<00:05,  1.01it/s]Epoch: 1/10. Loss: 1.1069:  81%|[36m████████  [0m| 21/26 [00:21<00:04,  1.06it/s]Epoch: 1/10. Loss: 1.0201:  81%|[36m████████  [0m| 21/26 [00:22<00:04,  1.06it/s]Epoch: 1/10. Loss: 1.0201:  85%|[36m████████▍ [0m| 22/26 [00:22<00:03,  1.07it/s]Epoch: 1/10. Loss: 1.0763:  85%|[36m████████▍ [0m| 22/26 [00:23<00:03,  1.07it/s]Epoch: 1/10. Loss: 1.0763:  88%|[36m████████▊ [0m| 23/26 [00:23<00:02,  1.08it/s]Epoch: 1/10. Loss: 0.9753:  88%|[36m████████▊ [0m| 23/26 [00:24<00:02,  1.08it/s]Epoch: 1/10. Loss: 0.9753:  92%|[36m█████████▏[0m| 24/26 [00:24<00:01,  1.15it/s]Epoch: 1/10. Loss: 1.0595:  92%|[36m█████████▏[0m| 24/26 [00:25<00:01,  1.15it/s]Epoch: 1/10. Loss: 1.0595:  96%|[36m█████████▌[0m| 25/26 [00:25<00:00,  1.17it/s]Epoch: 1/10. Loss: 0.9816:  96%|[36m█████████▌[0m| 25/26 [00:25<00:00,  1.17it/s]Epoch: 1/10. Loss: 0.9816: 100%|[36m██████████[0m| 26/26 [00:25<00:00,  1.34it/s]Epoch: 1/10. Loss: 0.9816: 100%|[36m██████████[0m| 26/26 [00:25<00:00,  1.02it/s]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:05,  1.08it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:05,  1.09s/it] 43%|[33m████▎     [0m| 3/7 [00:02<00:03,  1.07it/s] 57%|[33m█████▋    [0m| 4/7 [00:04<00:03,  1.20s/it] 71%|[33m███████▏  [0m| 5/7 [00:04<00:01,  1.06it/s] 86%|[33m████████▌ [0m| 6/7 [00:06<00:00,  1.02it/s]100%|[33m██████████[0m| 7/7 [00:06<00:00,  1.34it/s]100%|[33m██████████[0m| 7/7 [00:06<00:00,  1.11it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 2/10. Loss: 1.1505:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 2/10. Loss: 1.1505:   4%|[36m▍         [0m| 1/26 [00:01<00:25,  1.02s/it]Epoch: 2/10. Loss: 0.9934:   4%|[36m▍         [0m| 1/26 [00:01<00:25,  1.02s/it]Epoch: 2/10. Loss: 0.9934:   8%|[36m▊         [0m| 2/26 [00:01<00:22,  1.06it/s]Epoch: 2/10. Loss: 1.0958:   8%|[36m▊         [0m| 2/26 [00:02<00:22,  1.06it/s]Epoch: 2/10. Loss: 1.0958:  12%|[36m█▏        [0m| 3/26 [00:02<00:20,  1.14it/s]Epoch: 2/10. Loss: 0.9480:  12%|[36m█▏        [0m| 3/26 [00:03<00:20,  1.14it/s]Epoch: 2/10. Loss: 0.9480:  15%|[36m█▌        [0m| 4/26 [00:03<00:19,  1.13it/s]Epoch: 2/10. Loss: 0.9723:  15%|[36m█▌        [0m| 4/26 [00:04<00:19,  1.13it/s]Epoch: 2/10. Loss: 0.9723:  19%|[36m█▉        [0m| 5/26 [00:04<00:19,  1.08it/s]Epoch: 2/10. Loss: 1.0873:  19%|[36m█▉        [0m| 5/26 [00:05<00:19,  1.08it/s]Epoch: 2/10. Loss: 1.0873:  23%|[36m██▎       [0m| 6/26 [00:05<00:20,  1.00s/it]Epoch: 2/10. Loss: 1.0584:  23%|[36m██▎       [0m| 6/26 [00:06<00:20,  1.00s/it]Epoch: 2/10. Loss: 1.0584:  27%|[36m██▋       [0m| 7/26 [00:06<00:18,  1.04it/s]Epoch: 2/10. Loss: 1.0485:  27%|[36m██▋       [0m| 7/26 [00:07<00:18,  1.04it/s]Epoch: 2/10. Loss: 1.0485:  31%|[36m███       [0m| 8/26 [00:07<00:16,  1.07it/s]Epoch: 2/10. Loss: 1.1660:  31%|[36m███       [0m| 8/26 [00:09<00:16,  1.07it/s]Epoch: 2/10. Loss: 1.1660:  35%|[36m███▍      [0m| 9/26 [00:09<00:20,  1.23s/it]Epoch: 2/10. Loss: 1.0103:  35%|[36m███▍      [0m| 9/26 [00:10<00:20,  1.23s/it]Epoch: 2/10. Loss: 1.0103:  38%|[36m███▊      [0m| 10/26 [00:10<00:17,  1.10s/it]Epoch: 2/10. Loss: 0.9954:  38%|[36m███▊      [0m| 10/26 [00:10<00:17,  1.10s/it]Epoch: 2/10. Loss: 0.9954:  42%|[36m████▏     [0m| 11/26 [00:10<00:14,  1.02it/s]Epoch: 2/10. Loss: 0.9291:  42%|[36m████▏     [0m| 11/26 [00:11<00:14,  1.02it/s]Epoch: 2/10. Loss: 0.9291:  46%|[36m████▌     [0m| 12/26 [00:11<00:13,  1.06it/s]Epoch: 2/10. Loss: 0.9151:  46%|[36m████▌     [0m| 12/26 [00:12<00:13,  1.06it/s]Epoch: 2/10. Loss: 0.9151:  50%|[36m█████     [0m| 13/26 [00:12<00:12,  1.06it/s]Epoch: 2/10. Loss: 1.1509:  50%|[36m█████     [0m| 13/26 [00:13<00:12,  1.06it/s]Epoch: 2/10. Loss: 1.1509:  54%|[36m█████▍    [0m| 14/26 [00:13<00:10,  1.10it/s]Epoch: 2/10. Loss: 1.0613:  54%|[36m█████▍    [0m| 14/26 [00:14<00:10,  1.10it/s]Epoch: 2/10. Loss: 1.0613:  58%|[36m█████▊    [0m| 15/26 [00:14<00:09,  1.14it/s]Epoch: 2/10. Loss: 1.3371:  58%|[36m█████▊    [0m| 15/26 [00:15<00:09,  1.14it/s]Epoch: 2/10. Loss: 1.3371:  62%|[36m██████▏   [0m| 16/26 [00:15<00:08,  1.15it/s]Epoch: 2/10. Loss: 1.0867:  62%|[36m██████▏   [0m| 16/26 [00:15<00:08,  1.15it/s]Epoch: 2/10. Loss: 1.0867:  65%|[36m██████▌   [0m| 17/26 [00:16<00:07,  1.17it/s]Epoch: 2/10. Loss: 1.1514:  65%|[36m██████▌   [0m| 17/26 [00:16<00:07,  1.17it/s]Epoch: 2/10. Loss: 1.1514:  69%|[36m██████▉   [0m| 18/26 [00:16<00:06,  1.19it/s]Epoch: 2/10. Loss: 1.1387:  69%|[36m██████▉   [0m| 18/26 [00:17<00:06,  1.19it/s]Epoch: 2/10. Loss: 1.1387:  73%|[36m███████▎  [0m| 19/26 [00:17<00:05,  1.22it/s]Epoch: 2/10. Loss: 1.0972:  73%|[36m███████▎  [0m| 19/26 [00:18<00:05,  1.22it/s]Epoch: 2/10. Loss: 1.0972:  77%|[36m███████▋  [0m| 20/26 [00:18<00:05,  1.13it/s]Epoch: 2/10. Loss: 1.0688:  77%|[36m███████▋  [0m| 20/26 [00:19<00:05,  1.13it/s]Epoch: 2/10. Loss: 1.0688:  81%|[36m████████  [0m| 21/26 [00:19<00:04,  1.11it/s]Epoch: 2/10. Loss: 1.0760:  81%|[36m████████  [0m| 21/26 [00:21<00:04,  1.11it/s]Epoch: 2/10. Loss: 1.0760:  85%|[36m████████▍ [0m| 22/26 [00:21<00:04,  1.17s/it]Epoch: 2/10. Loss: 0.9846:  85%|[36m████████▍ [0m| 22/26 [00:22<00:04,  1.17s/it]Epoch: 2/10. Loss: 0.9846:  88%|[36m████████▊ [0m| 23/26 [00:22<00:03,  1.08s/it]Epoch: 2/10. Loss: 1.0464:  88%|[36m████████▊ [0m| 23/26 [00:23<00:03,  1.08s/it]Epoch: 2/10. Loss: 1.0464:  92%|[36m█████████▏[0m| 24/26 [00:23<00:02,  1.03s/it]Epoch: 2/10. Loss: 0.9846:  92%|[36m█████████▏[0m| 24/26 [00:23<00:02,  1.03s/it]Epoch: 2/10. Loss: 0.9846:  96%|[36m█████████▌[0m| 25/26 [00:24<00:00,  1.02it/s]Epoch: 2/10. Loss: 1.2712:  96%|[36m█████████▌[0m| 25/26 [00:24<00:00,  1.02it/s]Epoch: 2/10. Loss: 1.2712: 100%|[36m██████████[0m| 26/26 [00:24<00:00,  1.13it/s]Epoch: 2/10. Loss: 1.2712: 100%|[36m██████████[0m| 26/26 [00:24<00:00,  1.05it/s]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:05,  1.04it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:05,  1.14s/it] 43%|[33m████▎     [0m| 3/7 [00:02<00:03,  1.05it/s] 57%|[33m█████▋    [0m| 4/7 [00:04<00:03,  1.13s/it] 71%|[33m███████▏  [0m| 5/7 [00:06<00:02,  1.40s/it] 86%|[33m████████▌ [0m| 6/7 [00:07<00:01,  1.30s/it]100%|[33m██████████[0m| 7/7 [00:07<00:00,  1.05it/s]100%|[33m██████████[0m| 7/7 [00:07<00:00,  1.08s/it]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 3/10. Loss: 1.3546:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 3/10. Loss: 1.3546:   4%|[36m▍         [0m| 1/26 [00:00<00:24,  1.01it/s]Epoch: 3/10. Loss: 1.1037:   4%|[36m▍         [0m| 1/26 [00:01<00:24,  1.01it/s]Epoch: 3/10. Loss: 1.1037:   8%|[36m▊         [0m| 2/26 [00:01<00:21,  1.12it/s]Epoch: 3/10. Loss: 0.9450:   8%|[36m▊         [0m| 2/26 [00:02<00:21,  1.12it/s]Epoch: 3/10. Loss: 0.9450:  12%|[36m█▏        [0m| 3/26 [00:02<00:19,  1.15it/s]Epoch: 3/10. Loss: 0.9983:  12%|[36m█▏        [0m| 3/26 [00:03<00:19,  1.15it/s]Epoch: 3/10. Loss: 0.9983:  15%|[36m█▌        [0m| 4/26 [00:03<00:19,  1.14it/s]Epoch: 3/10. Loss: 1.0106:  15%|[36m█▌        [0m| 4/26 [00:04<00:19,  1.14it/s]Epoch: 3/10. Loss: 1.0106:  19%|[36m█▉        [0m| 5/26 [00:04<00:18,  1.15it/s]Epoch: 3/10. Loss: 0.9589:  19%|[36m█▉        [0m| 5/26 [00:05<00:18,  1.15it/s]Epoch: 3/10. Loss: 0.9589:  23%|[36m██▎       [0m| 6/26 [00:05<00:20,  1.04s/it]Epoch: 3/10. Loss: 0.9719:  23%|[36m██▎       [0m| 6/26 [00:06<00:20,  1.04s/it]Epoch: 3/10. Loss: 0.9719:  27%|[36m██▋       [0m| 7/26 [00:06<00:18,  1.03it/s]Epoch: 3/10. Loss: 0.9679:  27%|[36m██▋       [0m| 7/26 [00:07<00:18,  1.03it/s]Epoch: 3/10. Loss: 0.9679:  31%|[36m███       [0m| 8/26 [00:07<00:16,  1.10it/s]Epoch: 3/10. Loss: 1.1479:  31%|[36m███       [0m| 8/26 [00:08<00:16,  1.10it/s]Epoch: 3/10. Loss: 1.1479:  35%|[36m███▍      [0m| 9/26 [00:08<00:14,  1.14it/s]Epoch: 3/10. Loss: 0.9516:  35%|[36m███▍      [0m| 9/26 [00:09<00:14,  1.14it/s]Epoch: 3/10. Loss: 0.9516:  38%|[36m███▊      [0m| 10/26 [00:09<00:14,  1.11it/s]Epoch: 3/10. Loss: 1.0165:  38%|[36m███▊      [0m| 10/26 [00:12<00:14,  1.11it/s]Epoch: 3/10. Loss: 1.0165:  42%|[36m████▏     [0m| 11/26 [00:12<00:24,  1.63s/it]Epoch: 3/10. Loss: 0.9577:  42%|[36m████▏     [0m| 11/26 [00:13<00:24,  1.63s/it]Epoch: 3/10. Loss: 0.9577:  46%|[36m████▌     [0m| 12/26 [00:13<00:19,  1.38s/it]Epoch: 3/10. Loss: 1.1119:  46%|[36m████▌     [0m| 12/26 [00:14<00:19,  1.38s/it]Epoch: 3/10. Loss: 1.1119:  50%|[36m█████     [0m| 13/26 [00:14<00:15,  1.21s/it]Epoch: 3/10. Loss: 0.9216:  50%|[36m█████     [0m| 13/26 [00:15<00:15,  1.21s/it]Epoch: 3/10. Loss: 0.9216:  54%|[36m█████▍    [0m| 14/26 [00:15<00:13,  1.14s/it]Epoch: 3/10. Loss: 0.9401:  54%|[36m█████▍    [0m| 14/26 [00:16<00:13,  1.14s/it]Epoch: 3/10. Loss: 0.9401:  58%|[36m█████▊    [0m| 15/26 [00:16<00:13,  1.20s/it]Epoch: 3/10. Loss: 0.8988:  58%|[36m█████▊    [0m| 15/26 [00:17<00:13,  1.20s/it]Epoch: 3/10. Loss: 0.8988:  62%|[36m██████▏   [0m| 16/26 [00:17<00:11,  1.10s/it]Epoch: 3/10. Loss: 0.9784:  62%|[36m██████▏   [0m| 16/26 [00:18<00:11,  1.10s/it]Epoch: 3/10. Loss: 0.9784:  65%|[36m██████▌   [0m| 17/26 [00:18<00:09,  1.02s/it]Epoch: 3/10. Loss: 0.9016:  65%|[36m██████▌   [0m| 17/26 [00:19<00:09,  1.02s/it]Epoch: 3/10. Loss: 0.9016:  69%|[36m██████▉   [0m| 18/26 [00:19<00:08,  1.01s/it]Epoch: 3/10. Loss: 0.8760:  69%|[36m██████▉   [0m| 18/26 [00:20<00:08,  1.01s/it]Epoch: 3/10. Loss: 0.8760:  73%|[36m███████▎  [0m| 19/26 [00:20<00:07,  1.09s/it]Epoch: 3/10. Loss: 1.0923:  73%|[36m███████▎  [0m| 19/26 [00:21<00:07,  1.09s/it]Epoch: 3/10. Loss: 1.0923:  77%|[36m███████▋  [0m| 20/26 [00:21<00:06,  1.02s/it]Epoch: 3/10. Loss: 0.8827:  77%|[36m███████▋  [0m| 20/26 [00:22<00:06,  1.02s/it]Epoch: 3/10. Loss: 0.8827:  81%|[36m████████  [0m| 21/26 [00:22<00:05,  1.02s/it]Epoch: 3/10. Loss: 1.0050:  81%|[36m████████  [0m| 21/26 [00:23<00:05,  1.02s/it]Epoch: 3/10. Loss: 1.0050:  85%|[36m████████▍ [0m| 22/26 [00:23<00:04,  1.02s/it]Epoch: 3/10. Loss: 1.0591:  85%|[36m████████▍ [0m| 22/26 [00:23<00:04,  1.02s/it]Epoch: 3/10. Loss: 1.0591:  88%|[36m████████▊ [0m| 23/26 [00:23<00:02,  1.06it/s]Epoch: 3/10. Loss: 0.9136:  88%|[36m████████▊ [0m| 23/26 [00:24<00:02,  1.06it/s]Epoch: 3/10. Loss: 0.9136:  92%|[36m█████████▏[0m| 24/26 [00:24<00:01,  1.09it/s]Epoch: 3/10. Loss: 0.9747:  92%|[36m█████████▏[0m| 24/26 [00:25<00:01,  1.09it/s]Epoch: 3/10. Loss: 0.9747:  96%|[36m█████████▌[0m| 25/26 [00:25<00:00,  1.16it/s]Epoch: 3/10. Loss: 0.8641:  96%|[36m█████████▌[0m| 25/26 [00:26<00:00,  1.16it/s]Epoch: 3/10. Loss: 0.8641: 100%|[36m██████████[0m| 26/26 [00:26<00:00,  1.27it/s]Epoch: 3/10. Loss: 0.8641: 100%|[36m██████████[0m| 26/26 [00:26<00:00,  1.01s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:05,  1.05it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:05,  1.09s/it] 43%|[33m████▎     [0m| 3/7 [00:02<00:03,  1.05it/s] 57%|[33m█████▋    [0m| 4/7 [00:06<00:06,  2.11s/it] 71%|[33m███████▏  [0m| 5/7 [00:07<00:02,  1.50s/it] 86%|[33m████████▌ [0m| 6/7 [00:08<00:01,  1.29s/it]100%|[33m██████████[0m| 7/7 [00:08<00:00,  1.04it/s]100%|[33m██████████[0m| 7/7 [00:08<00:00,  1.20s/it]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 4/10. Loss: 0.8896:   0%|[36m          [0m| 0/26 [00:01<?, ?it/s]Epoch: 4/10. Loss: 0.8896:   4%|[36m▍         [0m| 1/26 [00:01<00:38,  1.54s/it]Epoch: 4/10. Loss: 0.8998:   4%|[36m▍         [0m| 1/26 [00:02<00:38,  1.54s/it]Epoch: 4/10. Loss: 0.8998:   8%|[36m▊         [0m| 2/26 [00:02<00:30,  1.27s/it]Epoch: 4/10. Loss: 0.9194:   8%|[36m▊         [0m| 2/26 [00:03<00:30,  1.27s/it]Epoch: 4/10. Loss: 0.9194:  12%|[36m█▏        [0m| 3/26 [00:03<00:23,  1.04s/it]Epoch: 4/10. Loss: 0.9073:  12%|[36m█▏        [0m| 3/26 [00:04<00:23,  1.04s/it]Epoch: 4/10. Loss: 0.9073:  15%|[36m█▌        [0m| 4/26 [00:04<00:21,  1.02it/s]Epoch: 4/10. Loss: 0.8586:  15%|[36m█▌        [0m| 4/26 [00:05<00:21,  1.02it/s]Epoch: 4/10. Loss: 0.8586:  19%|[36m█▉        [0m| 5/26 [00:05<00:23,  1.12s/it]Epoch: 4/10. Loss: 0.9186:  19%|[36m█▉        [0m| 5/26 [00:06<00:23,  1.12s/it]Epoch: 4/10. Loss: 0.9186:  23%|[36m██▎       [0m| 6/26 [00:06<00:20,  1.02s/it]Epoch: 4/10. Loss: 0.8287:  23%|[36m██▎       [0m| 6/26 [00:07<00:20,  1.02s/it]Epoch: 4/10. Loss: 0.8287:  27%|[36m██▋       [0m| 7/26 [00:07<00:18,  1.05it/s]Epoch: 4/10. Loss: 0.9502:  27%|[36m██▋       [0m| 7/26 [00:08<00:18,  1.05it/s]Epoch: 4/10. Loss: 0.9502:  31%|[36m███       [0m| 8/26 [00:08<00:16,  1.07it/s]Epoch: 4/10. Loss: 0.8525:  31%|[36m███       [0m| 8/26 [00:09<00:16,  1.07it/s]Epoch: 4/10. Loss: 0.8525:  35%|[36m███▍      [0m| 9/26 [00:09<00:15,  1.09it/s]Epoch: 4/10. Loss: 0.8747:  35%|[36m███▍      [0m| 9/26 [00:10<00:15,  1.09it/s]Epoch: 4/10. Loss: 0.8747:  38%|[36m███▊      [0m| 10/26 [00:10<00:15,  1.04it/s]Epoch: 4/10. Loss: 0.8046:  38%|[36m███▊      [0m| 10/26 [00:11<00:15,  1.04it/s]Epoch: 4/10. Loss: 0.8046:  42%|[36m████▏     [0m| 11/26 [00:11<00:15,  1.03s/it]Epoch: 4/10. Loss: 0.9601:  42%|[36m████▏     [0m| 11/26 [00:12<00:15,  1.03s/it]Epoch: 4/10. Loss: 0.9601:  46%|[36m████▌     [0m| 12/26 [00:12<00:13,  1.02it/s]Epoch: 4/10. Loss: 0.8978:  46%|[36m████▌     [0m| 12/26 [00:13<00:13,  1.02it/s]Epoch: 4/10. Loss: 0.8978:  50%|[36m█████     [0m| 13/26 [00:13<00:12,  1.04it/s]Epoch: 4/10. Loss: 0.9432:  50%|[36m█████     [0m| 13/26 [00:13<00:12,  1.04it/s]Epoch: 4/10. Loss: 0.9432:  54%|[36m█████▍    [0m| 14/26 [00:13<00:11,  1.07it/s]Epoch: 4/10. Loss: 0.9718:  54%|[36m█████▍    [0m| 14/26 [00:14<00:11,  1.07it/s]Epoch: 4/10. Loss: 0.9718:  58%|[36m█████▊    [0m| 15/26 [00:14<00:10,  1.09it/s]Epoch: 4/10. Loss: 0.8069:  58%|[36m█████▊    [0m| 15/26 [00:15<00:10,  1.09it/s]Epoch: 4/10. Loss: 0.8069:  62%|[36m██████▏   [0m| 16/26 [00:15<00:08,  1.13it/s]Epoch: 4/10. Loss: 0.8562:  62%|[36m██████▏   [0m| 16/26 [00:16<00:08,  1.13it/s]Epoch: 4/10. Loss: 0.8562:  65%|[36m██████▌   [0m| 17/26 [00:16<00:08,  1.11it/s]Epoch: 4/10. Loss: 0.8711:  65%|[36m██████▌   [0m| 17/26 [00:17<00:08,  1.11it/s]Epoch: 4/10. Loss: 0.8711:  69%|[36m██████▉   [0m| 18/26 [00:17<00:07,  1.06it/s]Epoch: 4/10. Loss: 0.7875:  69%|[36m██████▉   [0m| 18/26 [00:18<00:07,  1.06it/s]Epoch: 4/10. Loss: 0.7875:  73%|[36m███████▎  [0m| 19/26 [00:18<00:06,  1.04it/s]Epoch: 4/10. Loss: 0.9226:  73%|[36m███████▎  [0m| 19/26 [00:19<00:06,  1.04it/s]Epoch: 4/10. Loss: 0.9226:  77%|[36m███████▋  [0m| 20/26 [00:19<00:05,  1.03it/s]Epoch: 4/10. Loss: 0.8675:  77%|[36m███████▋  [0m| 20/26 [00:20<00:05,  1.03it/s]Epoch: 4/10. Loss: 0.8675:  81%|[36m████████  [0m| 21/26 [00:20<00:04,  1.05it/s]Epoch: 4/10. Loss: 0.8761:  81%|[36m████████  [0m| 21/26 [00:21<00:04,  1.05it/s]Epoch: 4/10. Loss: 0.8761:  85%|[36m████████▍ [0m| 22/26 [00:21<00:03,  1.10it/s]Epoch: 4/10. Loss: 0.8806:  85%|[36m████████▍ [0m| 22/26 [00:22<00:03,  1.10it/s]Epoch: 4/10. Loss: 0.8806:  88%|[36m████████▊ [0m| 23/26 [00:22<00:02,  1.14it/s]Epoch: 4/10. Loss: 0.8720:  88%|[36m████████▊ [0m| 23/26 [00:22<00:02,  1.14it/s]Epoch: 4/10. Loss: 0.8720:  92%|[36m█████████▏[0m| 24/26 [00:22<00:01,  1.21it/s]Epoch: 4/10. Loss: 0.8600:  92%|[36m█████████▏[0m| 24/26 [00:23<00:01,  1.21it/s]Epoch: 4/10. Loss: 0.8600:  96%|[36m█████████▌[0m| 25/26 [00:23<00:00,  1.15it/s]Epoch: 4/10. Loss: 0.8976:  96%|[36m█████████▌[0m| 25/26 [00:24<00:00,  1.15it/s]Epoch: 4/10. Loss: 0.8976: 100%|[36m██████████[0m| 26/26 [00:24<00:00,  1.26it/s]Epoch: 4/10. Loss: 0.8976: 100%|[36m██████████[0m| 26/26 [00:24<00:00,  1.06it/s]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:05,  1.08it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:05,  1.09s/it] 43%|[33m████▎     [0m| 3/7 [00:02<00:03,  1.08it/s] 57%|[33m█████▋    [0m| 4/7 [00:04<00:03,  1.10s/it] 71%|[33m███████▏  [0m| 5/7 [00:04<00:01,  1.17it/s] 86%|[33m████████▌ [0m| 6/7 [00:05<00:00,  1.17it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.51it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.21it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 5/10. Loss: 0.7662:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 5/10. Loss: 0.7662:   4%|[36m▍         [0m| 1/26 [00:00<00:19,  1.29it/s]Epoch: 5/10. Loss: 0.8307:   4%|[36m▍         [0m| 1/26 [00:01<00:19,  1.29it/s]Epoch: 5/10. Loss: 0.8307:   8%|[36m▊         [0m| 2/26 [00:01<00:18,  1.28it/s]Epoch: 5/10. Loss: 0.9175:   8%|[36m▊         [0m| 2/26 [00:03<00:18,  1.28it/s]Epoch: 5/10. Loss: 0.9175:  12%|[36m█▏        [0m| 3/26 [00:03<00:28,  1.22s/it]Epoch: 5/10. Loss: 0.8272:  12%|[36m█▏        [0m| 3/26 [00:04<00:28,  1.22s/it]Epoch: 5/10. Loss: 0.8272:  15%|[36m█▌        [0m| 4/26 [00:04<00:24,  1.11s/it]Epoch: 5/10. Loss: 0.8413:  15%|[36m█▌        [0m| 4/26 [00:05<00:24,  1.11s/it]Epoch: 5/10. Loss: 0.8413:  19%|[36m█▉        [0m| 5/26 [00:05<00:22,  1.07s/it]Epoch: 5/10. Loss: 0.8212:  19%|[36m█▉        [0m| 5/26 [00:06<00:22,  1.07s/it]Epoch: 5/10. Loss: 0.8212:  23%|[36m██▎       [0m| 6/26 [00:06<00:21,  1.08s/it]Epoch: 5/10. Loss: 0.8222:  23%|[36m██▎       [0m| 6/26 [00:07<00:21,  1.08s/it]Epoch: 5/10. Loss: 0.8222:  27%|[36m██▋       [0m| 7/26 [00:07<00:19,  1.02s/it]Epoch: 5/10. Loss: 0.9747:  27%|[36m██▋       [0m| 7/26 [00:08<00:19,  1.02s/it]Epoch: 5/10. Loss: 0.9747:  31%|[36m███       [0m| 8/26 [00:08<00:17,  1.03it/s]Epoch: 5/10. Loss: 0.8417:  31%|[36m███       [0m| 8/26 [00:08<00:17,  1.03it/s]Epoch: 5/10. Loss: 0.8417:  35%|[36m███▍      [0m| 9/26 [00:08<00:15,  1.10it/s]Epoch: 5/10. Loss: 0.7889:  35%|[36m███▍      [0m| 9/26 [00:09<00:15,  1.10it/s]Epoch: 5/10. Loss: 0.7889:  38%|[36m███▊      [0m| 10/26 [00:09<00:13,  1.16it/s]Epoch: 5/10. Loss: 0.8399:  38%|[36m███▊      [0m| 10/26 [00:10<00:13,  1.16it/s]Epoch: 5/10. Loss: 0.8399:  42%|[36m████▏     [0m| 11/26 [00:10<00:13,  1.14it/s]Epoch: 5/10. Loss: 0.8364:  42%|[36m████▏     [0m| 11/26 [00:11<00:13,  1.14it/s]Epoch: 5/10. Loss: 0.8364:  46%|[36m████▌     [0m| 12/26 [00:11<00:12,  1.13it/s]Epoch: 5/10. Loss: 0.8931:  46%|[36m████▌     [0m| 12/26 [00:12<00:12,  1.13it/s]Epoch: 5/10. Loss: 0.8931:  50%|[36m█████     [0m| 13/26 [00:12<00:12,  1.07it/s]Epoch: 5/10. Loss: 0.8947:  50%|[36m█████     [0m| 13/26 [00:13<00:12,  1.07it/s]Epoch: 5/10. Loss: 0.8947:  54%|[36m█████▍    [0m| 14/26 [00:13<00:11,  1.08it/s]Epoch: 5/10. Loss: 0.8886:  54%|[36m█████▍    [0m| 14/26 [00:14<00:11,  1.08it/s]Epoch: 5/10. Loss: 0.8886:  58%|[36m█████▊    [0m| 15/26 [00:14<00:09,  1.12it/s]Epoch: 5/10. Loss: 0.7820:  58%|[36m█████▊    [0m| 15/26 [00:15<00:09,  1.12it/s]Epoch: 5/10. Loss: 0.7820:  62%|[36m██████▏   [0m| 16/26 [00:15<00:08,  1.16it/s]Epoch: 5/10. Loss: 0.7620:  62%|[36m██████▏   [0m| 16/26 [00:16<00:08,  1.16it/s]Epoch: 5/10. Loss: 0.7620:  65%|[36m██████▌   [0m| 17/26 [00:16<00:08,  1.09it/s]Epoch: 5/10. Loss: 0.8367:  65%|[36m██████▌   [0m| 17/26 [00:17<00:08,  1.09it/s]Epoch: 5/10. Loss: 0.8367:  69%|[36m██████▉   [0m| 18/26 [00:17<00:07,  1.06it/s]Epoch: 5/10. Loss: 0.8409:  69%|[36m██████▉   [0m| 18/26 [00:19<00:07,  1.06it/s]Epoch: 5/10. Loss: 0.8409:  73%|[36m███████▎  [0m| 19/26 [00:19<00:10,  1.46s/it]Epoch: 5/10. Loss: 0.9748:  73%|[36m███████▎  [0m| 19/26 [00:20<00:10,  1.46s/it]Epoch: 5/10. Loss: 0.9748:  77%|[36m███████▋  [0m| 20/26 [00:20<00:08,  1.40s/it]Epoch: 5/10. Loss: 0.7406:  77%|[36m███████▋  [0m| 20/26 [00:21<00:08,  1.40s/it]Epoch: 5/10. Loss: 0.7406:  81%|[36m████████  [0m| 21/26 [00:21<00:06,  1.26s/it]Epoch: 5/10. Loss: 0.8189:  81%|[36m████████  [0m| 21/26 [00:23<00:06,  1.26s/it]Epoch: 5/10. Loss: 0.8189:  85%|[36m████████▍ [0m| 22/26 [00:23<00:04,  1.22s/it]Epoch: 5/10. Loss: 0.9348:  85%|[36m████████▍ [0m| 22/26 [00:23<00:04,  1.22s/it]Epoch: 5/10. Loss: 0.9348:  88%|[36m████████▊ [0m| 23/26 [00:23<00:03,  1.07s/it]Epoch: 5/10. Loss: 0.8855:  88%|[36m████████▊ [0m| 23/26 [00:24<00:03,  1.07s/it]Epoch: 5/10. Loss: 0.8855:  92%|[36m█████████▏[0m| 24/26 [00:24<00:01,  1.01it/s]Epoch: 5/10. Loss: 1.0295:  92%|[36m█████████▏[0m| 24/26 [00:25<00:01,  1.01it/s]Epoch: 5/10. Loss: 1.0295:  96%|[36m█████████▌[0m| 25/26 [00:25<00:00,  1.05it/s]Epoch: 5/10. Loss: 0.7658:  96%|[36m█████████▌[0m| 25/26 [00:25<00:00,  1.05it/s]Epoch: 5/10. Loss: 0.7658: 100%|[36m██████████[0m| 26/26 [00:26<00:00,  1.19it/s]Epoch: 5/10. Loss: 0.7658: 100%|[36m██████████[0m| 26/26 [00:26<00:00,  1.00s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:05,  1.05it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:06,  1.24s/it] 43%|[33m████▎     [0m| 3/7 [00:03<00:04,  1.09s/it] 57%|[33m█████▋    [0m| 4/7 [00:04<00:03,  1.20s/it] 71%|[33m███████▏  [0m| 5/7 [00:05<00:01,  1.02it/s] 86%|[33m████████▌ [0m| 6/7 [00:06<00:00,  1.08it/s]100%|[33m██████████[0m| 7/7 [00:06<00:00,  1.41it/s]100%|[33m██████████[0m| 7/7 [00:06<00:00,  1.10it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 6/10. Loss: 0.8211:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 6/10. Loss: 0.8211:   4%|[36m▍         [0m| 1/26 [00:00<00:21,  1.15it/s]Epoch: 6/10. Loss: 0.8138:   4%|[36m▍         [0m| 1/26 [00:01<00:21,  1.15it/s]Epoch: 6/10. Loss: 0.8138:   8%|[36m▊         [0m| 2/26 [00:01<00:23,  1.00it/s]Epoch: 6/10. Loss: 0.7787:   8%|[36m▊         [0m| 2/26 [00:02<00:23,  1.00it/s]Epoch: 6/10. Loss: 0.7787:  12%|[36m█▏        [0m| 3/26 [00:02<00:22,  1.04it/s]Epoch: 6/10. Loss: 0.8290:  12%|[36m█▏        [0m| 3/26 [00:03<00:22,  1.04it/s]Epoch: 6/10. Loss: 0.8290:  15%|[36m█▌        [0m| 4/26 [00:03<00:19,  1.12it/s]Epoch: 6/10. Loss: 0.8482:  15%|[36m█▌        [0m| 4/26 [00:04<00:19,  1.12it/s]Epoch: 6/10. Loss: 0.8482:  19%|[36m█▉        [0m| 5/26 [00:04<00:17,  1.17it/s]Epoch: 6/10. Loss: 0.7860:  19%|[36m█▉        [0m| 5/26 [00:05<00:17,  1.17it/s]Epoch: 6/10. Loss: 0.7860:  23%|[36m██▎       [0m| 6/26 [00:05<00:18,  1.07it/s]Epoch: 6/10. Loss: 0.8748:  23%|[36m██▎       [0m| 6/26 [00:06<00:18,  1.07it/s]Epoch: 6/10. Loss: 0.8748:  27%|[36m██▋       [0m| 7/26 [00:06<00:18,  1.02it/s]Epoch: 6/10. Loss: 0.9128:  27%|[36m██▋       [0m| 7/26 [00:07<00:18,  1.02it/s]Epoch: 6/10. Loss: 0.9128:  31%|[36m███       [0m| 8/26 [00:07<00:17,  1.01it/s]Epoch: 6/10. Loss: 0.7805:  31%|[36m███       [0m| 8/26 [00:08<00:17,  1.01it/s]Epoch: 6/10. Loss: 0.7805:  35%|[36m███▍      [0m| 9/26 [00:08<00:16,  1.03it/s]Epoch: 6/10. Loss: 0.7664:  35%|[36m███▍      [0m| 9/26 [00:09<00:16,  1.03it/s]Epoch: 6/10. Loss: 0.7664:  38%|[36m███▊      [0m| 10/26 [00:09<00:14,  1.12it/s]Epoch: 6/10. Loss: 0.7660:  38%|[36m███▊      [0m| 10/26 [00:10<00:14,  1.12it/s]Epoch: 6/10. Loss: 0.7660:  42%|[36m████▏     [0m| 11/26 [00:10<00:13,  1.15it/s]Epoch: 6/10. Loss: 0.7833:  42%|[36m████▏     [0m| 11/26 [00:10<00:13,  1.15it/s]Epoch: 6/10. Loss: 0.7833:  46%|[36m████▌     [0m| 12/26 [00:10<00:12,  1.14it/s]Epoch: 6/10. Loss: 0.8452:  46%|[36m████▌     [0m| 12/26 [00:11<00:12,  1.14it/s]Epoch: 6/10. Loss: 0.8452:  50%|[36m█████     [0m| 13/26 [00:11<00:11,  1.13it/s]Epoch: 6/10. Loss: 0.8295:  50%|[36m█████     [0m| 13/26 [00:12<00:11,  1.13it/s]Epoch: 6/10. Loss: 0.8295:  54%|[36m█████▍    [0m| 14/26 [00:12<00:10,  1.10it/s]Epoch: 6/10. Loss: 0.8223:  54%|[36m█████▍    [0m| 14/26 [00:13<00:10,  1.10it/s]Epoch: 6/10. Loss: 0.8223:  58%|[36m█████▊    [0m| 15/26 [00:13<00:09,  1.14it/s]Epoch: 6/10. Loss: 0.8606:  58%|[36m█████▊    [0m| 15/26 [00:14<00:09,  1.14it/s]Epoch: 6/10. Loss: 0.8606:  62%|[36m██████▏   [0m| 16/26 [00:14<00:08,  1.14it/s]Epoch: 6/10. Loss: 0.7351:  62%|[36m██████▏   [0m| 16/26 [00:15<00:08,  1.14it/s]Epoch: 6/10. Loss: 0.7351:  65%|[36m██████▌   [0m| 17/26 [00:15<00:07,  1.14it/s]Epoch: 6/10. Loss: 0.7109:  65%|[36m██████▌   [0m| 17/26 [00:16<00:07,  1.14it/s]Epoch: 6/10. Loss: 0.7109:  69%|[36m██████▉   [0m| 18/26 [00:16<00:07,  1.05it/s]Epoch: 6/10. Loss: 0.8323:  69%|[36m██████▉   [0m| 18/26 [00:17<00:07,  1.05it/s]Epoch: 6/10. Loss: 0.8323:  73%|[36m███████▎  [0m| 19/26 [00:17<00:06,  1.09it/s]Epoch: 6/10. Loss: 0.8578:  73%|[36m███████▎  [0m| 19/26 [00:18<00:06,  1.09it/s]Epoch: 6/10. Loss: 0.8578:  77%|[36m███████▋  [0m| 20/26 [00:18<00:05,  1.09it/s]Epoch: 6/10. Loss: 0.8208:  77%|[36m███████▋  [0m| 20/26 [00:18<00:05,  1.09it/s]Epoch: 6/10. Loss: 0.8208:  81%|[36m████████  [0m| 21/26 [00:18<00:04,  1.20it/s]Epoch: 6/10. Loss: 0.6799:  81%|[36m████████  [0m| 21/26 [00:19<00:04,  1.20it/s]Epoch: 6/10. Loss: 0.6799:  85%|[36m████████▍ [0m| 22/26 [00:19<00:03,  1.13it/s]Epoch: 6/10. Loss: 0.7751:  85%|[36m████████▍ [0m| 22/26 [00:20<00:03,  1.13it/s]Epoch: 6/10. Loss: 0.7751:  88%|[36m████████▊ [0m| 23/26 [00:20<00:02,  1.09it/s]Epoch: 6/10. Loss: 0.8183:  88%|[36m████████▊ [0m| 23/26 [00:22<00:02,  1.09it/s]Epoch: 6/10. Loss: 0.8183:  92%|[36m█████████▏[0m| 24/26 [00:22<00:02,  1.13s/it]Epoch: 6/10. Loss: 0.8053:  92%|[36m█████████▏[0m| 24/26 [00:23<00:02,  1.13s/it]Epoch: 6/10. Loss: 0.8053:  96%|[36m█████████▌[0m| 25/26 [00:23<00:01,  1.09s/it]Epoch: 6/10. Loss: 0.8657:  96%|[36m█████████▌[0m| 25/26 [00:24<00:01,  1.09s/it]Epoch: 6/10. Loss: 0.8657: 100%|[36m██████████[0m| 26/26 [00:24<00:00,  1.07it/s]Epoch: 6/10. Loss: 0.8657: 100%|[36m██████████[0m| 26/26 [00:24<00:00,  1.08it/s]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:05,  1.07it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:06,  1.34s/it] 43%|[33m████▎     [0m| 3/7 [00:03<00:04,  1.14s/it] 57%|[33m█████▋    [0m| 4/7 [00:04<00:03,  1.24s/it] 71%|[33m███████▏  [0m| 5/7 [00:05<00:01,  1.06it/s] 86%|[33m████████▌ [0m| 6/7 [00:06<00:00,  1.10it/s]100%|[33m██████████[0m| 7/7 [00:06<00:00,  1.44it/s]100%|[33m██████████[0m| 7/7 [00:06<00:00,  1.10it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 7/10. Loss: 0.7348:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 7/10. Loss: 0.7348:   4%|[36m▍         [0m| 1/26 [00:00<00:24,  1.01it/s]Epoch: 7/10. Loss: 0.7483:   4%|[36m▍         [0m| 1/26 [00:02<00:24,  1.01it/s]Epoch: 7/10. Loss: 0.7483:   8%|[36m▊         [0m| 2/26 [00:02<00:37,  1.58s/it]Epoch: 7/10. Loss: 0.6912:   8%|[36m▊         [0m| 2/26 [00:03<00:37,  1.58s/it]Epoch: 7/10. Loss: 0.6912:  12%|[36m█▏        [0m| 3/26 [00:03<00:29,  1.27s/it]Epoch: 7/10. Loss: 0.8423:  12%|[36m█▏        [0m| 3/26 [00:04<00:29,  1.27s/it]Epoch: 7/10. Loss: 0.8423:  15%|[36m█▌        [0m| 4/26 [00:04<00:24,  1.10s/it]Epoch: 7/10. Loss: 0.7390:  15%|[36m█▌        [0m| 4/26 [00:05<00:24,  1.10s/it]Epoch: 7/10. Loss: 0.7390:  19%|[36m█▉        [0m| 5/26 [00:05<00:21,  1.01s/it]Epoch: 7/10. Loss: 0.7735:  19%|[36m█▉        [0m| 5/26 [00:06<00:21,  1.01s/it]Epoch: 7/10. Loss: 0.7735:  23%|[36m██▎       [0m| 6/26 [00:06<00:21,  1.06s/it]Epoch: 7/10. Loss: 0.7256:  23%|[36m██▎       [0m| 6/26 [00:08<00:21,  1.06s/it]Epoch: 7/10. Loss: 0.7256:  27%|[36m██▋       [0m| 7/26 [00:08<00:23,  1.22s/it]Epoch: 7/10. Loss: 0.7066:  27%|[36m██▋       [0m| 7/26 [00:09<00:23,  1.22s/it]Epoch: 7/10. Loss: 0.7066:  31%|[36m███       [0m| 8/26 [00:09<00:20,  1.15s/it]Epoch: 7/10. Loss: 0.7326:  31%|[36m███       [0m| 8/26 [00:10<00:20,  1.15s/it]Epoch: 7/10. Loss: 0.7326:  35%|[36m███▍      [0m| 9/26 [00:10<00:19,  1.14s/it]Epoch: 7/10. Loss: 0.7349:  35%|[36m███▍      [0m| 9/26 [00:11<00:19,  1.14s/it]Epoch: 7/10. Loss: 0.7349:  38%|[36m███▊      [0m| 10/26 [00:11<00:16,  1.06s/it]Epoch: 7/10. Loss: 0.7866:  38%|[36m███▊      [0m| 10/26 [00:12<00:16,  1.06s/it]Epoch: 7/10. Loss: 0.7866:  42%|[36m████▏     [0m| 11/26 [00:12<00:14,  1.01it/s]Epoch: 7/10. Loss: 0.7082:  42%|[36m████▏     [0m| 11/26 [00:12<00:14,  1.01it/s]Epoch: 7/10. Loss: 0.7082:  46%|[36m████▌     [0m| 12/26 [00:12<00:12,  1.13it/s]Epoch: 7/10. Loss: 0.7174:  46%|[36m████▌     [0m| 12/26 [00:13<00:12,  1.13it/s]Epoch: 7/10. Loss: 0.7174:  50%|[36m█████     [0m| 13/26 [00:13<00:12,  1.07it/s]Epoch: 7/10. Loss: 0.7627:  50%|[36m█████     [0m| 13/26 [00:14<00:12,  1.07it/s]Epoch: 7/10. Loss: 0.7627:  54%|[36m█████▍    [0m| 14/26 [00:14<00:11,  1.08it/s]Epoch: 7/10. Loss: 0.8599:  54%|[36m█████▍    [0m| 14/26 [00:15<00:11,  1.08it/s]Epoch: 7/10. Loss: 0.8599:  58%|[36m█████▊    [0m| 15/26 [00:15<00:10,  1.09it/s]Epoch: 7/10. Loss: 0.7253:  58%|[36m█████▊    [0m| 15/26 [00:17<00:10,  1.09it/s]Epoch: 7/10. Loss: 0.7253:  62%|[36m██████▏   [0m| 16/26 [00:17<00:11,  1.15s/it]Epoch: 7/10. Loss: 0.7714:  62%|[36m██████▏   [0m| 16/26 [00:18<00:11,  1.15s/it]Epoch: 7/10. Loss: 0.7714:  65%|[36m██████▌   [0m| 17/26 [00:18<00:11,  1.31s/it]Epoch: 7/10. Loss: 0.7062:  65%|[36m██████▌   [0m| 17/26 [00:19<00:11,  1.31s/it]Epoch: 7/10. Loss: 0.7062:  69%|[36m██████▉   [0m| 18/26 [00:19<00:09,  1.21s/it]Epoch: 7/10. Loss: 0.8052:  69%|[36m██████▉   [0m| 18/26 [00:20<00:09,  1.21s/it]Epoch: 7/10. Loss: 0.8052:  73%|[36m███████▎  [0m| 19/26 [00:20<00:07,  1.13s/it]Epoch: 7/10. Loss: 0.8413:  73%|[36m███████▎  [0m| 19/26 [00:22<00:07,  1.13s/it]Epoch: 7/10. Loss: 0.8413:  77%|[36m███████▋  [0m| 20/26 [00:22<00:07,  1.19s/it]Epoch: 7/10. Loss: 0.8853:  77%|[36m███████▋  [0m| 20/26 [00:23<00:07,  1.19s/it]Epoch: 7/10. Loss: 0.8853:  81%|[36m████████  [0m| 21/26 [00:23<00:05,  1.10s/it]Epoch: 7/10. Loss: 0.6945:  81%|[36m████████  [0m| 21/26 [00:23<00:05,  1.10s/it]Epoch: 7/10. Loss: 0.6945:  85%|[36m████████▍ [0m| 22/26 [00:23<00:04,  1.02s/it]Epoch: 7/10. Loss: 0.7400:  85%|[36m████████▍ [0m| 22/26 [00:24<00:04,  1.02s/it]Epoch: 7/10. Loss: 0.7400:  88%|[36m████████▊ [0m| 23/26 [00:24<00:02,  1.01it/s]Epoch: 7/10. Loss: 0.9455:  88%|[36m████████▊ [0m| 23/26 [00:25<00:02,  1.01it/s]Epoch: 7/10. Loss: 0.9455:  92%|[36m█████████▏[0m| 24/26 [00:25<00:01,  1.05it/s]Epoch: 7/10. Loss: 0.7464:  92%|[36m█████████▏[0m| 24/26 [00:26<00:01,  1.05it/s]Epoch: 7/10. Loss: 0.7464:  96%|[36m█████████▌[0m| 25/26 [00:26<00:00,  1.05it/s]Epoch: 7/10. Loss: 0.6944:  96%|[36m█████████▌[0m| 25/26 [00:27<00:00,  1.05it/s]Epoch: 7/10. Loss: 0.6944: 100%|[36m██████████[0m| 26/26 [00:27<00:00,  1.18it/s]Epoch: 7/10. Loss: 0.6944: 100%|[36m██████████[0m| 26/26 [00:27<00:00,  1.05s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:05,  1.07it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:05,  1.09s/it] 43%|[33m████▎     [0m| 3/7 [00:02<00:03,  1.06it/s] 57%|[33m█████▋    [0m| 4/7 [00:04<00:03,  1.11s/it] 71%|[33m███████▏  [0m| 5/7 [00:04<00:01,  1.19it/s] 86%|[33m████████▌ [0m| 6/7 [00:05<00:00,  1.26it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.65it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.26it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 8/10. Loss: 0.6289:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 8/10. Loss: 0.6289:   4%|[36m▍         [0m| 1/26 [00:00<00:22,  1.09it/s]Epoch: 8/10. Loss: 0.8813:   4%|[36m▍         [0m| 1/26 [00:01<00:22,  1.09it/s]Epoch: 8/10. Loss: 0.8813:   8%|[36m▊         [0m| 2/26 [00:01<00:21,  1.13it/s]Epoch: 8/10. Loss: 0.7412:   8%|[36m▊         [0m| 2/26 [00:02<00:21,  1.13it/s]Epoch: 8/10. Loss: 0.7412:  12%|[36m█▏        [0m| 3/26 [00:02<00:18,  1.22it/s]Epoch: 8/10. Loss: 0.7751:  12%|[36m█▏        [0m| 3/26 [00:03<00:18,  1.22it/s]Epoch: 8/10. Loss: 0.7751:  15%|[36m█▌        [0m| 4/26 [00:03<00:18,  1.21it/s]Epoch: 8/10. Loss: 0.7411:  15%|[36m█▌        [0m| 4/26 [00:04<00:18,  1.21it/s]Epoch: 8/10. Loss: 0.7411:  19%|[36m█▉        [0m| 5/26 [00:04<00:16,  1.24it/s]Epoch: 8/10. Loss: 0.7627:  19%|[36m█▉        [0m| 5/26 [00:05<00:16,  1.24it/s]Epoch: 8/10. Loss: 0.7627:  23%|[36m██▎       [0m| 6/26 [00:05<00:16,  1.18it/s]Epoch: 8/10. Loss: 0.8151:  23%|[36m██▎       [0m| 6/26 [00:05<00:16,  1.18it/s]Epoch: 8/10. Loss: 0.8151:  27%|[36m██▋       [0m| 7/26 [00:05<00:16,  1.15it/s]Epoch: 8/10. Loss: 0.8048:  27%|[36m██▋       [0m| 7/26 [00:07<00:16,  1.15it/s]Epoch: 8/10. Loss: 0.8048:  31%|[36m███       [0m| 8/26 [00:07<00:16,  1.07it/s]Epoch: 8/10. Loss: 0.6878:  31%|[36m███       [0m| 8/26 [00:08<00:16,  1.07it/s]Epoch: 8/10. Loss: 0.6878:  35%|[36m███▍      [0m| 9/26 [00:08<00:16,  1.04it/s]Epoch: 8/10. Loss: 0.7268:  35%|[36m███▍      [0m| 9/26 [00:09<00:16,  1.04it/s]Epoch: 8/10. Loss: 0.7268:  38%|[36m███▊      [0m| 10/26 [00:09<00:15,  1.00it/s]Epoch: 8/10. Loss: 0.8796:  38%|[36m███▊      [0m| 10/26 [00:09<00:15,  1.00it/s]Epoch: 8/10. Loss: 0.8796:  42%|[36m████▏     [0m| 11/26 [00:09<00:13,  1.08it/s]Epoch: 8/10. Loss: 0.7509:  42%|[36m████▏     [0m| 11/26 [00:10<00:13,  1.08it/s]Epoch: 8/10. Loss: 0.7509:  46%|[36m████▌     [0m| 12/26 [00:10<00:13,  1.06it/s]Epoch: 8/10. Loss: 0.7438:  46%|[36m████▌     [0m| 12/26 [00:11<00:13,  1.06it/s]Epoch: 8/10. Loss: 0.7438:  50%|[36m█████     [0m| 13/26 [00:11<00:12,  1.06it/s]Epoch: 8/10. Loss: 0.6547:  50%|[36m█████     [0m| 13/26 [00:12<00:12,  1.06it/s]Epoch: 8/10. Loss: 0.6547:  54%|[36m█████▍    [0m| 14/26 [00:12<00:10,  1.10it/s]Epoch: 8/10. Loss: 0.7701:  54%|[36m█████▍    [0m| 14/26 [00:13<00:10,  1.10it/s]Epoch: 8/10. Loss: 0.7701:  58%|[36m█████▊    [0m| 15/26 [00:13<00:09,  1.10it/s]Epoch: 8/10. Loss: 0.8110:  58%|[36m█████▊    [0m| 15/26 [00:14<00:09,  1.10it/s]Epoch: 8/10. Loss: 0.8110:  62%|[36m██████▏   [0m| 16/26 [00:14<00:08,  1.12it/s]Epoch: 8/10. Loss: 0.8369:  62%|[36m██████▏   [0m| 16/26 [00:15<00:08,  1.12it/s]Epoch: 8/10. Loss: 0.8369:  65%|[36m██████▌   [0m| 17/26 [00:15<00:07,  1.15it/s]Epoch: 8/10. Loss: 0.7378:  65%|[36m██████▌   [0m| 17/26 [00:16<00:07,  1.15it/s]Epoch: 8/10. Loss: 0.7378:  69%|[36m██████▉   [0m| 18/26 [00:16<00:06,  1.15it/s]Epoch: 8/10. Loss: 0.8809:  69%|[36m██████▉   [0m| 18/26 [00:16<00:06,  1.15it/s]Epoch: 8/10. Loss: 0.8809:  73%|[36m███████▎  [0m| 19/26 [00:16<00:05,  1.18it/s]Epoch: 8/10. Loss: 0.7821:  73%|[36m███████▎  [0m| 19/26 [00:18<00:05,  1.18it/s]Epoch: 8/10. Loss: 0.7821:  77%|[36m███████▋  [0m| 20/26 [00:18<00:05,  1.00it/s]Epoch: 8/10. Loss: 0.7367:  77%|[36m███████▋  [0m| 20/26 [00:20<00:05,  1.00it/s]Epoch: 8/10. Loss: 0.7367:  81%|[36m████████  [0m| 21/26 [00:20<00:07,  1.43s/it]Epoch: 8/10. Loss: 0.7344:  81%|[36m████████  [0m| 21/26 [00:21<00:07,  1.43s/it]Epoch: 8/10. Loss: 0.7344:  85%|[36m████████▍ [0m| 22/26 [00:21<00:05,  1.31s/it]Epoch: 8/10. Loss: 0.7571:  85%|[36m████████▍ [0m| 22/26 [00:22<00:05,  1.31s/it]Epoch: 8/10. Loss: 0.7571:  88%|[36m████████▊ [0m| 23/26 [00:22<00:03,  1.18s/it]Epoch: 8/10. Loss: 0.7835:  88%|[36m████████▊ [0m| 23/26 [00:23<00:03,  1.18s/it]Epoch: 8/10. Loss: 0.7835:  92%|[36m█████████▏[0m| 24/26 [00:23<00:02,  1.12s/it]Epoch: 8/10. Loss: 0.6791:  92%|[36m█████████▏[0m| 24/26 [00:24<00:02,  1.12s/it]Epoch: 8/10. Loss: 0.6791:  96%|[36m█████████▌[0m| 25/26 [00:24<00:01,  1.02s/it]Epoch: 8/10. Loss: 0.7977:  96%|[36m█████████▌[0m| 25/26 [00:24<00:01,  1.02s/it]Epoch: 8/10. Loss: 0.7977: 100%|[36m██████████[0m| 26/26 [00:24<00:00,  1.12it/s]Epoch: 8/10. Loss: 0.7977: 100%|[36m██████████[0m| 26/26 [00:24<00:00,  1.04it/s]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:05,  1.04it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:05,  1.11s/it] 43%|[33m████▎     [0m| 3/7 [00:02<00:03,  1.05it/s] 57%|[33m█████▋    [0m| 4/7 [00:04<00:03,  1.12s/it] 71%|[33m███████▏  [0m| 5/7 [00:04<00:01,  1.18it/s] 86%|[33m████████▌ [0m| 6/7 [00:05<00:00,  1.23it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.55it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.22it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 9/10. Loss: 0.6939:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 9/10. Loss: 0.6939:   4%|[36m▍         [0m| 1/26 [00:01<00:25,  1.01s/it]Epoch: 9/10. Loss: 0.8657:   4%|[36m▍         [0m| 1/26 [00:01<00:25,  1.01s/it]Epoch: 9/10. Loss: 0.8657:   8%|[36m▊         [0m| 2/26 [00:01<00:22,  1.05it/s]Epoch: 9/10. Loss: 0.7171:   8%|[36m▊         [0m| 2/26 [00:03<00:22,  1.05it/s]Epoch: 9/10. Loss: 0.7171:  12%|[36m█▏        [0m| 3/26 [00:03<00:28,  1.25s/it]Epoch: 9/10. Loss: 0.7527:  12%|[36m█▏        [0m| 3/26 [00:04<00:28,  1.25s/it]Epoch: 9/10. Loss: 0.7527:  15%|[36m█▌        [0m| 4/26 [00:04<00:22,  1.05s/it]Epoch: 9/10. Loss: 0.7472:  15%|[36m█▌        [0m| 4/26 [00:05<00:22,  1.05s/it]Epoch: 9/10. Loss: 0.7472:  19%|[36m█▉        [0m| 5/26 [00:05<00:20,  1.02it/s]Epoch: 9/10. Loss: 0.6879:  19%|[36m█▉        [0m| 5/26 [00:05<00:20,  1.02it/s]Epoch: 9/10. Loss: 0.6879:  23%|[36m██▎       [0m| 6/26 [00:05<00:17,  1.12it/s]Epoch: 9/10. Loss: 0.6236:  23%|[36m██▎       [0m| 6/26 [00:06<00:17,  1.12it/s]Epoch: 9/10. Loss: 0.6236:  27%|[36m██▋       [0m| 7/26 [00:07<00:18,  1.02it/s]Epoch: 9/10. Loss: 0.6793:  27%|[36m██▋       [0m| 7/26 [00:09<00:18,  1.02it/s]Epoch: 9/10. Loss: 0.6793:  31%|[36m███       [0m| 8/26 [00:09<00:24,  1.37s/it]Epoch: 9/10. Loss: 0.8529:  31%|[36m███       [0m| 8/26 [00:10<00:24,  1.37s/it]Epoch: 9/10. Loss: 0.8529:  35%|[36m███▍      [0m| 9/26 [00:10<00:21,  1.25s/it]Epoch: 9/10. Loss: 0.7301:  35%|[36m███▍      [0m| 9/26 [00:11<00:21,  1.25s/it]Epoch: 9/10. Loss: 0.7301:  38%|[36m███▊      [0m| 10/26 [00:11<00:18,  1.16s/it]Epoch: 9/10. Loss: 0.6556:  38%|[36m███▊      [0m| 10/26 [00:12<00:18,  1.16s/it]Epoch: 9/10. Loss: 0.6556:  42%|[36m████▏     [0m| 11/26 [00:12<00:16,  1.07s/it]Epoch: 9/10. Loss: 0.7508:  42%|[36m████▏     [0m| 11/26 [00:13<00:16,  1.07s/it]Epoch: 9/10. Loss: 0.7508:  46%|[36m████▌     [0m| 12/26 [00:13<00:15,  1.11s/it]Epoch: 9/10. Loss: 0.7363:  46%|[36m████▌     [0m| 12/26 [00:14<00:15,  1.11s/it]Epoch: 9/10. Loss: 0.7363:  50%|[36m█████     [0m| 13/26 [00:14<00:13,  1.06s/it]Epoch: 9/10. Loss: 0.7149:  50%|[36m█████     [0m| 13/26 [00:15<00:13,  1.06s/it]Epoch: 9/10. Loss: 0.7149:  54%|[36m█████▍    [0m| 14/26 [00:15<00:12,  1.08s/it]Epoch: 9/10. Loss: 0.6803:  54%|[36m█████▍    [0m| 14/26 [00:17<00:12,  1.08s/it]Epoch: 9/10. Loss: 0.6803:  58%|[36m█████▊    [0m| 15/26 [00:17<00:14,  1.33s/it]Epoch: 9/10. Loss: 0.7723:  58%|[36m█████▊    [0m| 15/26 [00:20<00:14,  1.33s/it]Epoch: 9/10. Loss: 0.7723:  62%|[36m██████▏   [0m| 16/26 [00:20<00:19,  1.94s/it]Epoch: 9/10. Loss: 0.8202:  62%|[36m██████▏   [0m| 16/26 [00:22<00:19,  1.94s/it]Epoch: 9/10. Loss: 0.8202:  65%|[36m██████▌   [0m| 17/26 [00:22<00:17,  1.99s/it]Epoch: 9/10. Loss: 0.6778:  65%|[36m██████▌   [0m| 17/26 [00:25<00:17,  1.99s/it]Epoch: 9/10. Loss: 0.6778:  69%|[36m██████▉   [0m| 18/26 [00:25<00:17,  2.14s/it]Epoch: 9/10. Loss: 0.6853:  69%|[36m██████▉   [0m| 18/26 [00:25<00:17,  2.14s/it]Epoch: 9/10. Loss: 0.6853:  73%|[36m███████▎  [0m| 19/26 [00:26<00:12,  1.75s/it]Epoch: 9/10. Loss: 0.7970:  73%|[36m███████▎  [0m| 19/26 [00:26<00:12,  1.75s/it]Epoch: 9/10. Loss: 0.7970:  77%|[36m███████▋  [0m| 20/26 [00:26<00:09,  1.50s/it]Epoch: 9/10. Loss: 0.7453:  77%|[36m███████▋  [0m| 20/26 [00:27<00:09,  1.50s/it]Epoch: 9/10. Loss: 0.7453:  81%|[36m████████  [0m| 21/26 [00:27<00:06,  1.32s/it]Epoch: 9/10. Loss: 0.7015:  81%|[36m████████  [0m| 21/26 [00:28<00:06,  1.32s/it]Epoch: 9/10. Loss: 0.7015:  85%|[36m████████▍ [0m| 22/26 [00:28<00:04,  1.18s/it]Epoch: 9/10. Loss: 0.7362:  85%|[36m████████▍ [0m| 22/26 [00:29<00:04,  1.18s/it]Epoch: 9/10. Loss: 0.7362:  88%|[36m████████▊ [0m| 23/26 [00:29<00:03,  1.11s/it]Epoch: 9/10. Loss: 0.6968:  88%|[36m████████▊ [0m| 23/26 [00:32<00:03,  1.11s/it]Epoch: 9/10. Loss: 0.6968:  92%|[36m█████████▏[0m| 24/26 [00:32<00:03,  1.63s/it]Epoch: 9/10. Loss: 0.7561:  92%|[36m█████████▏[0m| 24/26 [00:34<00:03,  1.63s/it]Epoch: 9/10. Loss: 0.7561:  96%|[36m█████████▌[0m| 25/26 [00:34<00:01,  1.65s/it]Epoch: 9/10. Loss: 0.7272:  96%|[36m█████████▌[0m| 25/26 [00:34<00:01,  1.65s/it]Epoch: 9/10. Loss: 0.7272: 100%|[36m██████████[0m| 26/26 [00:34<00:00,  1.35s/it]Epoch: 9/10. Loss: 0.7272: 100%|[36m██████████[0m| 26/26 [00:34<00:00,  1.34s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:01<00:09,  1.59s/it] 29%|[33m██▊       [0m| 2/7 [00:03<00:07,  1.50s/it] 43%|[33m████▎     [0m| 3/7 [00:03<00:04,  1.12s/it] 57%|[33m█████▋    [0m| 4/7 [00:04<00:03,  1.19s/it] 71%|[33m███████▏  [0m| 5/7 [00:05<00:01,  1.13it/s] 86%|[33m████████▌ [0m| 6/7 [00:06<00:00,  1.22it/s]100%|[33m██████████[0m| 7/7 [00:06<00:00,  1.60it/s]100%|[33m██████████[0m| 7/7 [00:06<00:00,  1.12it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 0/10. Loss: 1.1445:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 0/10. Loss: 1.1445:   4%|[36m▍         [0m| 1/26 [00:01<00:26,  1.06s/it]Epoch: 0/10. Loss: 4.0752:   4%|[36m▍         [0m| 1/26 [00:02<00:26,  1.06s/it]Epoch: 0/10. Loss: 4.0752:   8%|[36m▊         [0m| 2/26 [00:02<00:24,  1.04s/it]Epoch: 0/10. Loss: 1.4890:   8%|[36m▊         [0m| 2/26 [00:02<00:24,  1.04s/it]Epoch: 0/10. Loss: 1.4890:  12%|[36m█▏        [0m| 3/26 [00:02<00:21,  1.05it/s]Epoch: 0/10. Loss: 1.2580:  12%|[36m█▏        [0m| 3/26 [00:06<00:21,  1.05it/s]Epoch: 0/10. Loss: 1.2580:  15%|[36m█▌        [0m| 4/26 [00:06<00:42,  1.92s/it]Epoch: 0/10. Loss: 1.2275:  15%|[36m█▌        [0m| 4/26 [00:07<00:42,  1.92s/it]Epoch: 0/10. Loss: 1.2275:  19%|[36m█▉        [0m| 5/26 [00:07<00:36,  1.74s/it]Epoch: 0/10. Loss: 2.1327:  19%|[36m█▉        [0m| 5/26 [00:08<00:36,  1.74s/it]Epoch: 0/10. Loss: 2.1327:  23%|[36m██▎       [0m| 6/26 [00:08<00:29,  1.46s/it]Epoch: 0/10. Loss: 1.1838:  23%|[36m██▎       [0m| 6/26 [00:09<00:29,  1.46s/it]Epoch: 0/10. Loss: 1.1838:  27%|[36m██▋       [0m| 7/26 [00:09<00:24,  1.31s/it]Epoch: 0/10. Loss: 1.1443:  27%|[36m██▋       [0m| 7/26 [00:10<00:24,  1.31s/it]Epoch: 0/10. Loss: 1.1443:  31%|[36m███       [0m| 8/26 [00:10<00:21,  1.22s/it]Epoch: 0/10. Loss: 1.1182:  31%|[36m███       [0m| 8/26 [00:11<00:21,  1.22s/it]Epoch: 0/10. Loss: 1.1182:  35%|[36m███▍      [0m| 9/26 [00:11<00:19,  1.15s/it]Epoch: 0/10. Loss: 1.0552:  35%|[36m███▍      [0m| 9/26 [00:12<00:19,  1.15s/it]Epoch: 0/10. Loss: 1.0552:  38%|[36m███▊      [0m| 10/26 [00:12<00:16,  1.03s/it]Epoch: 0/10. Loss: 0.9885:  38%|[36m███▊      [0m| 10/26 [00:13<00:16,  1.03s/it]Epoch: 0/10. Loss: 0.9885:  42%|[36m████▏     [0m| 11/26 [00:13<00:15,  1.06s/it]Epoch: 0/10. Loss: 1.1408:  42%|[36m████▏     [0m| 11/26 [00:14<00:15,  1.06s/it]Epoch: 0/10. Loss: 1.1408:  46%|[36m████▌     [0m| 12/26 [00:14<00:14,  1.05s/it]Epoch: 0/10. Loss: 2.3100:  46%|[36m████▌     [0m| 12/26 [00:15<00:14,  1.05s/it]Epoch: 0/10. Loss: 2.3100:  50%|[36m█████     [0m| 13/26 [00:15<00:13,  1.01s/it]Epoch: 0/10. Loss: 1.0514:  50%|[36m█████     [0m| 13/26 [00:16<00:13,  1.01s/it]Epoch: 0/10. Loss: 1.0514:  54%|[36m█████▍    [0m| 14/26 [00:16<00:11,  1.02it/s]Epoch: 0/10. Loss: 1.0065:  54%|[36m█████▍    [0m| 14/26 [00:17<00:11,  1.02it/s]Epoch: 0/10. Loss: 1.0065:  58%|[36m█████▊    [0m| 15/26 [00:17<00:10,  1.05it/s]Epoch: 0/10. Loss: 1.9381:  58%|[36m█████▊    [0m| 15/26 [00:19<00:10,  1.05it/s]Epoch: 0/10. Loss: 1.9381:  62%|[36m██████▏   [0m| 16/26 [00:19<00:14,  1.44s/it]Epoch: 0/10. Loss: 1.5965:  62%|[36m██████▏   [0m| 16/26 [00:21<00:14,  1.44s/it]Epoch: 0/10. Loss: 1.5965:  65%|[36m██████▌   [0m| 17/26 [00:21<00:12,  1.36s/it]Epoch: 0/10. Loss: 1.3919:  65%|[36m██████▌   [0m| 17/26 [00:22<00:12,  1.36s/it]Epoch: 0/10. Loss: 1.3919:  69%|[36m██████▉   [0m| 18/26 [00:22<00:10,  1.29s/it]Epoch: 0/10. Loss: 1.2636:  69%|[36m██████▉   [0m| 18/26 [00:23<00:10,  1.29s/it]Epoch: 0/10. Loss: 1.2636:  73%|[36m███████▎  [0m| 19/26 [00:23<00:08,  1.18s/it]Epoch: 0/10. Loss: 1.2113:  73%|[36m███████▎  [0m| 19/26 [00:24<00:08,  1.18s/it]Epoch: 0/10. Loss: 1.2113:  77%|[36m███████▋  [0m| 20/26 [00:24<00:06,  1.15s/it]Epoch: 0/10. Loss: 0.9920:  77%|[36m███████▋  [0m| 20/26 [00:25<00:06,  1.15s/it]Epoch: 0/10. Loss: 0.9920:  81%|[36m████████  [0m| 21/26 [00:25<00:05,  1.12s/it]Epoch: 0/10. Loss: 1.2120:  81%|[36m████████  [0m| 21/26 [00:26<00:05,  1.12s/it]Epoch: 0/10. Loss: 1.2120:  85%|[36m████████▍ [0m| 22/26 [00:26<00:04,  1.08s/it]Epoch: 0/10. Loss: 1.3084:  85%|[36m████████▍ [0m| 22/26 [00:27<00:04,  1.08s/it]Epoch: 0/10. Loss: 1.3084:  88%|[36m████████▊ [0m| 23/26 [00:27<00:03,  1.03s/it]Epoch: 0/10. Loss: 0.9874:  88%|[36m████████▊ [0m| 23/26 [00:28<00:03,  1.03s/it]Epoch: 0/10. Loss: 0.9874:  92%|[36m█████████▏[0m| 24/26 [00:28<00:02,  1.02s/it]Epoch: 0/10. Loss: 1.2924:  92%|[36m█████████▏[0m| 24/26 [00:29<00:02,  1.02s/it]Epoch: 0/10. Loss: 1.2924:  96%|[36m█████████▌[0m| 25/26 [00:29<00:01,  1.01s/it]Epoch: 0/10. Loss: 0.9956:  96%|[36m█████████▌[0m| 25/26 [00:29<00:01,  1.01s/it]Epoch: 0/10. Loss: 0.9956: 100%|[36m██████████[0m| 26/26 [00:29<00:00,  1.12it/s]Epoch: 0/10. Loss: 0.9956: 100%|[36m██████████[0m| 26/26 [00:29<00:00,  1.14s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:05,  1.04it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:05,  1.09s/it] 43%|[33m████▎     [0m| 3/7 [00:02<00:03,  1.07it/s] 57%|[33m█████▋    [0m| 4/7 [00:04<00:03,  1.11s/it] 71%|[33m███████▏  [0m| 5/7 [00:04<00:01,  1.18it/s] 86%|[33m████████▌ [0m| 6/7 [00:05<00:00,  1.22it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.58it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.24it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 1/10. Loss: 0.9863:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 1/10. Loss: 0.9863:   4%|[36m▍         [0m| 1/26 [00:00<00:22,  1.11it/s]Epoch: 1/10. Loss: 1.1074:   4%|[36m▍         [0m| 1/26 [00:01<00:22,  1.11it/s]Epoch: 1/10. Loss: 1.1074:   8%|[36m▊         [0m| 2/26 [00:01<00:23,  1.01it/s]Epoch: 1/10. Loss: 1.0495:   8%|[36m▊         [0m| 2/26 [00:02<00:23,  1.01it/s]Epoch: 1/10. Loss: 1.0495:  12%|[36m█▏        [0m| 3/26 [00:02<00:21,  1.07it/s]Epoch: 1/10. Loss: 1.1553:  12%|[36m█▏        [0m| 3/26 [00:03<00:21,  1.07it/s]Epoch: 1/10. Loss: 1.1553:  15%|[36m█▌        [0m| 4/26 [00:03<00:20,  1.09it/s]Epoch: 1/10. Loss: 0.9541:  15%|[36m█▌        [0m| 4/26 [00:04<00:20,  1.09it/s]Epoch: 1/10. Loss: 0.9541:  19%|[36m█▉        [0m| 5/26 [00:04<00:18,  1.11it/s]Epoch: 1/10. Loss: 1.0742:  19%|[36m█▉        [0m| 5/26 [00:05<00:18,  1.11it/s]Epoch: 1/10. Loss: 1.0742:  23%|[36m██▎       [0m| 6/26 [00:05<00:17,  1.11it/s]Epoch: 1/10. Loss: 1.0548:  23%|[36m██▎       [0m| 6/26 [00:06<00:17,  1.11it/s]Epoch: 1/10. Loss: 1.0548:  27%|[36m██▋       [0m| 7/26 [00:06<00:17,  1.06it/s]Epoch: 1/10. Loss: 1.0209:  27%|[36m██▋       [0m| 7/26 [00:07<00:17,  1.06it/s]Epoch: 1/10. Loss: 1.0209:  31%|[36m███       [0m| 8/26 [00:07<00:17,  1.05it/s]Epoch: 1/10. Loss: 1.0322:  31%|[36m███       [0m| 8/26 [00:08<00:17,  1.05it/s]Epoch: 1/10. Loss: 1.0322:  35%|[36m███▍      [0m| 9/26 [00:08<00:16,  1.04it/s]Epoch: 1/10. Loss: 0.9944:  35%|[36m███▍      [0m| 9/26 [00:09<00:16,  1.04it/s]Epoch: 1/10. Loss: 0.9944:  38%|[36m███▊      [0m| 10/26 [00:09<00:15,  1.06it/s]Epoch: 1/10. Loss: 0.9560:  38%|[36m███▊      [0m| 10/26 [00:10<00:15,  1.06it/s]Epoch: 1/10. Loss: 0.9560:  42%|[36m████▏     [0m| 11/26 [00:10<00:14,  1.07it/s]Epoch: 1/10. Loss: 0.9810:  42%|[36m████▏     [0m| 11/26 [00:11<00:14,  1.07it/s]Epoch: 1/10. Loss: 0.9810:  46%|[36m████▌     [0m| 12/26 [00:11<00:14,  1.03s/it]Epoch: 1/10. Loss: 0.9971:  46%|[36m████▌     [0m| 12/26 [00:12<00:14,  1.03s/it]Epoch: 1/10. Loss: 0.9971:  50%|[36m█████     [0m| 13/26 [00:12<00:14,  1.11s/it]Epoch: 1/10. Loss: 1.0805:  50%|[36m█████     [0m| 13/26 [00:15<00:14,  1.11s/it]Epoch: 1/10. Loss: 1.0805:  54%|[36m█████▍    [0m| 14/26 [00:15<00:19,  1.59s/it]Epoch: 1/10. Loss: 1.0627:  54%|[36m█████▍    [0m| 14/26 [00:17<00:19,  1.59s/it]Epoch: 1/10. Loss: 1.0627:  58%|[36m█████▊    [0m| 15/26 [00:17<00:18,  1.68s/it]Epoch: 1/10. Loss: 1.0129:  58%|[36m█████▊    [0m| 15/26 [00:18<00:18,  1.68s/it]Epoch: 1/10. Loss: 1.0129:  62%|[36m██████▏   [0m| 16/26 [00:18<00:14,  1.48s/it]Epoch: 1/10. Loss: 0.9542:  62%|[36m██████▏   [0m| 16/26 [00:19<00:14,  1.48s/it]Epoch: 1/10. Loss: 0.9542:  65%|[36m██████▌   [0m| 17/26 [00:19<00:11,  1.29s/it]Epoch: 1/10. Loss: 1.1217:  65%|[36m██████▌   [0m| 17/26 [00:20<00:11,  1.29s/it]Epoch: 1/10. Loss: 1.1217:  69%|[36m██████▉   [0m| 18/26 [00:20<00:09,  1.21s/it]Epoch: 1/10. Loss: 1.0939:  69%|[36m██████▉   [0m| 18/26 [00:21<00:09,  1.21s/it]Epoch: 1/10. Loss: 1.0939:  73%|[36m███████▎  [0m| 19/26 [00:21<00:07,  1.14s/it]Epoch: 1/10. Loss: 0.9591:  73%|[36m███████▎  [0m| 19/26 [00:23<00:07,  1.14s/it]Epoch: 1/10. Loss: 0.9591:  77%|[36m███████▋  [0m| 20/26 [00:23<00:08,  1.36s/it]Epoch: 1/10. Loss: 0.9497:  77%|[36m███████▋  [0m| 20/26 [00:24<00:08,  1.36s/it]Epoch: 1/10. Loss: 0.9497:  81%|[36m████████  [0m| 21/26 [00:24<00:06,  1.24s/it]Epoch: 1/10. Loss: 1.0431:  81%|[36m████████  [0m| 21/26 [00:25<00:06,  1.24s/it]Epoch: 1/10. Loss: 1.0431:  85%|[36m████████▍ [0m| 22/26 [00:25<00:04,  1.17s/it]Epoch: 1/10. Loss: 0.9959:  85%|[36m████████▍ [0m| 22/26 [00:26<00:04,  1.17s/it]Epoch: 1/10. Loss: 0.9959:  88%|[36m████████▊ [0m| 23/26 [00:26<00:03,  1.15s/it]Epoch: 1/10. Loss: 0.9663:  88%|[36m████████▊ [0m| 23/26 [00:27<00:03,  1.15s/it]Epoch: 1/10. Loss: 0.9663:  92%|[36m█████████▏[0m| 24/26 [00:27<00:02,  1.07s/it]Epoch: 1/10. Loss: 1.0052:  92%|[36m█████████▏[0m| 24/26 [00:27<00:02,  1.07s/it]Epoch: 1/10. Loss: 1.0052:  96%|[36m█████████▌[0m| 25/26 [00:27<00:00,  1.00it/s]Epoch: 1/10. Loss: 0.9152:  96%|[36m█████████▌[0m| 25/26 [00:28<00:00,  1.00it/s]Epoch: 1/10. Loss: 0.9152: 100%|[36m██████████[0m| 26/26 [00:28<00:00,  1.16it/s]Epoch: 1/10. Loss: 0.9152: 100%|[36m██████████[0m| 26/26 [00:28<00:00,  1.09s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:01<00:07,  1.22s/it] 29%|[33m██▊       [0m| 2/7 [00:02<00:06,  1.21s/it] 43%|[33m████▎     [0m| 3/7 [00:03<00:03,  1.01it/s] 57%|[33m█████▋    [0m| 4/7 [00:04<00:03,  1.14s/it] 71%|[33m███████▏  [0m| 5/7 [00:04<00:01,  1.14it/s] 86%|[33m████████▌ [0m| 6/7 [00:05<00:00,  1.19it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.54it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.17it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 2/10. Loss: 1.0244:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 2/10. Loss: 1.0244:   4%|[36m▍         [0m| 1/26 [00:01<00:25,  1.01s/it]Epoch: 2/10. Loss: 0.9087:   4%|[36m▍         [0m| 1/26 [00:01<00:25,  1.01s/it]Epoch: 2/10. Loss: 0.9087:   8%|[36m▊         [0m| 2/26 [00:01<00:22,  1.08it/s]Epoch: 2/10. Loss: 1.0598:   8%|[36m▊         [0m| 2/26 [00:02<00:22,  1.08it/s]Epoch: 2/10. Loss: 1.0598:  12%|[36m█▏        [0m| 3/26 [00:02<00:20,  1.12it/s]Epoch: 2/10. Loss: 1.0228:  12%|[36m█▏        [0m| 3/26 [00:03<00:20,  1.12it/s]Epoch: 2/10. Loss: 1.0228:  15%|[36m█▌        [0m| 4/26 [00:03<00:19,  1.11it/s]Epoch: 2/10. Loss: 1.0091:  15%|[36m█▌        [0m| 4/26 [00:07<00:19,  1.11it/s]Epoch: 2/10. Loss: 1.0091:  19%|[36m█▉        [0m| 5/26 [00:07<00:39,  1.87s/it]Epoch: 2/10. Loss: 1.0131:  19%|[36m█▉        [0m| 5/26 [00:08<00:39,  1.87s/it]Epoch: 2/10. Loss: 1.0131:  23%|[36m██▎       [0m| 6/26 [00:08<00:31,  1.59s/it]Epoch: 2/10. Loss: 0.9597:  23%|[36m██▎       [0m| 6/26 [00:09<00:31,  1.59s/it]Epoch: 2/10. Loss: 0.9597:  27%|[36m██▋       [0m| 7/26 [00:09<00:26,  1.41s/it]Epoch: 2/10. Loss: 0.9802:  27%|[36m██▋       [0m| 7/26 [00:10<00:26,  1.41s/it]Epoch: 2/10. Loss: 0.9802:  31%|[36m███       [0m| 8/26 [00:10<00:22,  1.23s/it]Epoch: 2/10. Loss: 0.9029:  31%|[36m███       [0m| 8/26 [00:11<00:22,  1.23s/it]Epoch: 2/10. Loss: 0.9029:  35%|[36m███▍      [0m| 9/26 [00:11<00:19,  1.15s/it]Epoch: 2/10. Loss: 1.0712:  35%|[36m███▍      [0m| 9/26 [00:12<00:19,  1.15s/it]Epoch: 2/10. Loss: 1.0712:  38%|[36m███▊      [0m| 10/26 [00:12<00:18,  1.18s/it]Epoch: 2/10. Loss: 0.9636:  38%|[36m███▊      [0m| 10/26 [00:13<00:18,  1.18s/it]Epoch: 2/10. Loss: 0.9636:  42%|[36m████▏     [0m| 11/26 [00:13<00:18,  1.21s/it]Epoch: 2/10. Loss: 1.0012:  42%|[36m████▏     [0m| 11/26 [00:14<00:18,  1.21s/it]Epoch: 2/10. Loss: 1.0012:  46%|[36m████▌     [0m| 12/26 [00:14<00:15,  1.08s/it]Epoch: 2/10. Loss: 0.9273:  46%|[36m████▌     [0m| 12/26 [00:15<00:15,  1.08s/it]Epoch: 2/10. Loss: 0.9273:  50%|[36m█████     [0m| 13/26 [00:15<00:14,  1.12s/it]Epoch: 2/10. Loss: 0.9814:  50%|[36m█████     [0m| 13/26 [00:16<00:14,  1.12s/it]Epoch: 2/10. Loss: 0.9814:  54%|[36m█████▍    [0m| 14/26 [00:16<00:13,  1.11s/it]Epoch: 2/10. Loss: 0.9367:  54%|[36m█████▍    [0m| 14/26 [00:19<00:13,  1.11s/it]Epoch: 2/10. Loss: 0.9367:  58%|[36m█████▊    [0m| 15/26 [00:19<00:16,  1.54s/it]Epoch: 2/10. Loss: 0.9430:  58%|[36m█████▊    [0m| 15/26 [00:20<00:16,  1.54s/it]Epoch: 2/10. Loss: 0.9430:  62%|[36m██████▏   [0m| 16/26 [00:20<00:14,  1.41s/it]Epoch: 2/10. Loss: 0.9670:  62%|[36m██████▏   [0m| 16/26 [00:21<00:14,  1.41s/it]Epoch: 2/10. Loss: 0.9670:  65%|[36m██████▌   [0m| 17/26 [00:21<00:11,  1.23s/it]Epoch: 2/10. Loss: 1.0674:  65%|[36m██████▌   [0m| 17/26 [00:22<00:11,  1.23s/it]Epoch: 2/10. Loss: 1.0674:  69%|[36m██████▉   [0m| 18/26 [00:22<00:09,  1.13s/it]Epoch: 2/10. Loss: 0.9408:  69%|[36m██████▉   [0m| 18/26 [00:22<00:09,  1.13s/it]Epoch: 2/10. Loss: 0.9408:  73%|[36m███████▎  [0m| 19/26 [00:22<00:07,  1.06s/it]Epoch: 2/10. Loss: 0.9474:  73%|[36m███████▎  [0m| 19/26 [00:24<00:07,  1.06s/it]Epoch: 2/10. Loss: 0.9474:  77%|[36m███████▋  [0m| 20/26 [00:24<00:07,  1.20s/it]Epoch: 2/10. Loss: 0.9323:  77%|[36m███████▋  [0m| 20/26 [00:25<00:07,  1.20s/it]Epoch: 2/10. Loss: 0.9323:  81%|[36m████████  [0m| 21/26 [00:25<00:05,  1.14s/it]Epoch: 2/10. Loss: 0.8997:  81%|[36m████████  [0m| 21/26 [00:26<00:05,  1.14s/it]Epoch: 2/10. Loss: 0.8997:  85%|[36m████████▍ [0m| 22/26 [00:26<00:04,  1.10s/it]Epoch: 2/10. Loss: 0.9103:  85%|[36m████████▍ [0m| 22/26 [00:27<00:04,  1.10s/it]Epoch: 2/10. Loss: 0.9103:  88%|[36m████████▊ [0m| 23/26 [00:27<00:03,  1.05s/it]Epoch: 2/10. Loss: 0.9048:  88%|[36m████████▊ [0m| 23/26 [00:30<00:03,  1.05s/it]Epoch: 2/10. Loss: 0.9048:  92%|[36m█████████▏[0m| 24/26 [00:30<00:03,  1.58s/it]Epoch: 2/10. Loss: 1.0073:  92%|[36m█████████▏[0m| 24/26 [00:31<00:03,  1.58s/it]Epoch: 2/10. Loss: 1.0073:  96%|[36m█████████▌[0m| 25/26 [00:31<00:01,  1.40s/it]Epoch: 2/10. Loss: 0.8119:  96%|[36m█████████▌[0m| 25/26 [00:31<00:01,  1.40s/it]Epoch: 2/10. Loss: 0.8119: 100%|[36m██████████[0m| 26/26 [00:31<00:00,  1.18s/it]Epoch: 2/10. Loss: 0.8119: 100%|[36m██████████[0m| 26/26 [00:31<00:00,  1.23s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:01<00:08,  1.43s/it] 29%|[33m██▊       [0m| 2/7 [00:02<00:06,  1.37s/it] 43%|[33m████▎     [0m| 3/7 [00:03<00:04,  1.09s/it] 57%|[33m█████▋    [0m| 4/7 [00:06<00:06,  2.00s/it] 71%|[33m███████▏  [0m| 5/7 [00:07<00:02,  1.43s/it] 86%|[33m████████▌ [0m| 6/7 [00:08<00:01,  1.22s/it]100%|[33m██████████[0m| 7/7 [00:08<00:00,  1.11it/s]100%|[33m██████████[0m| 7/7 [00:08<00:00,  1.20s/it]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 3/10. Loss: 0.8592:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 3/10. Loss: 0.8592:   4%|[36m▍         [0m| 1/26 [00:00<00:20,  1.21it/s]Epoch: 3/10. Loss: 0.8783:   4%|[36m▍         [0m| 1/26 [00:01<00:20,  1.21it/s]Epoch: 3/10. Loss: 0.8783:   8%|[36m▊         [0m| 2/26 [00:01<00:24,  1.01s/it]Epoch: 3/10. Loss: 0.9018:   8%|[36m▊         [0m| 2/26 [00:05<00:24,  1.01s/it]Epoch: 3/10. Loss: 0.9018:  12%|[36m█▏        [0m| 3/26 [00:05<00:46,  2.00s/it]Epoch: 3/10. Loss: 0.9167:  12%|[36m█▏        [0m| 3/26 [00:05<00:46,  2.00s/it]Epoch: 3/10. Loss: 0.9167:  15%|[36m█▌        [0m| 4/26 [00:06<00:34,  1.55s/it]Epoch: 3/10. Loss: 1.1032:  15%|[36m█▌        [0m| 4/26 [00:07<00:34,  1.55s/it]Epoch: 3/10. Loss: 1.1032:  19%|[36m█▉        [0m| 5/26 [00:07<00:29,  1.42s/it]Epoch: 3/10. Loss: 0.9639:  19%|[36m█▉        [0m| 5/26 [00:08<00:29,  1.42s/it]Epoch: 3/10. Loss: 0.9639:  23%|[36m██▎       [0m| 6/26 [00:08<00:24,  1.23s/it]Epoch: 3/10. Loss: 1.0040:  23%|[36m██▎       [0m| 6/26 [00:09<00:24,  1.23s/it]Epoch: 3/10. Loss: 1.0040:  27%|[36m██▋       [0m| 7/26 [00:09<00:22,  1.20s/it]Epoch: 3/10. Loss: 0.8750:  27%|[36m██▋       [0m| 7/26 [00:10<00:22,  1.20s/it]Epoch: 3/10. Loss: 0.8750:  31%|[36m███       [0m| 8/26 [00:10<00:20,  1.13s/it]Epoch: 3/10. Loss: 0.9788:  31%|[36m███       [0m| 8/26 [00:11<00:20,  1.13s/it]Epoch: 3/10. Loss: 0.9788:  35%|[36m███▍      [0m| 9/26 [00:11<00:18,  1.06s/it]Epoch: 3/10. Loss: 0.9343:  35%|[36m███▍      [0m| 9/26 [00:12<00:18,  1.06s/it]Epoch: 3/10. Loss: 0.9343:  38%|[36m███▊      [0m| 10/26 [00:12<00:16,  1.05s/it]Epoch: 3/10. Loss: 0.8954:  38%|[36m███▊      [0m| 10/26 [00:13<00:16,  1.05s/it]Epoch: 3/10. Loss: 0.8954:  42%|[36m████▏     [0m| 11/26 [00:13<00:16,  1.10s/it]Epoch: 3/10. Loss: 0.8233:  42%|[36m████▏     [0m| 11/26 [00:14<00:16,  1.10s/it]Epoch: 3/10. Loss: 0.8233:  46%|[36m████▌     [0m| 12/26 [00:14<00:14,  1.05s/it]Epoch: 3/10. Loss: 0.9373:  46%|[36m████▌     [0m| 12/26 [00:14<00:14,  1.05s/it]Epoch: 3/10. Loss: 0.9373:  50%|[36m█████     [0m| 13/26 [00:15<00:12,  1.04it/s]Epoch: 3/10. Loss: 1.0987:  50%|[36m█████     [0m| 13/26 [00:15<00:12,  1.04it/s]Epoch: 3/10. Loss: 1.0987:  54%|[36m█████▍    [0m| 14/26 [00:15<00:11,  1.04it/s]Epoch: 3/10. Loss: 1.1109:  54%|[36m█████▍    [0m| 14/26 [00:16<00:11,  1.04it/s]Epoch: 3/10. Loss: 1.1109:  58%|[36m█████▊    [0m| 15/26 [00:16<00:10,  1.03it/s]Epoch: 3/10. Loss: 0.8955:  58%|[36m█████▊    [0m| 15/26 [00:17<00:10,  1.03it/s]Epoch: 3/10. Loss: 0.8955:  62%|[36m██████▏   [0m| 16/26 [00:17<00:09,  1.07it/s]Epoch: 3/10. Loss: 1.0323:  62%|[36m██████▏   [0m| 16/26 [00:18<00:09,  1.07it/s]Epoch: 3/10. Loss: 1.0323:  65%|[36m██████▌   [0m| 17/26 [00:18<00:08,  1.09it/s]Epoch: 3/10. Loss: 0.9762:  65%|[36m██████▌   [0m| 17/26 [00:19<00:08,  1.09it/s]Epoch: 3/10. Loss: 0.9762:  69%|[36m██████▉   [0m| 18/26 [00:19<00:06,  1.18it/s]Epoch: 3/10. Loss: 0.9245:  69%|[36m██████▉   [0m| 18/26 [00:20<00:06,  1.18it/s]Epoch: 3/10. Loss: 0.9245:  73%|[36m███████▎  [0m| 19/26 [00:20<00:06,  1.11it/s]Epoch: 3/10. Loss: 0.9600:  73%|[36m███████▎  [0m| 19/26 [00:21<00:06,  1.11it/s]Epoch: 3/10. Loss: 0.9600:  77%|[36m███████▋  [0m| 20/26 [00:21<00:05,  1.13it/s]Epoch: 3/10. Loss: 0.9789:  77%|[36m███████▋  [0m| 20/26 [00:22<00:05,  1.13it/s]Epoch: 3/10. Loss: 0.9789:  81%|[36m████████  [0m| 21/26 [00:22<00:04,  1.11it/s]Epoch: 3/10. Loss: 1.0177:  81%|[36m████████  [0m| 21/26 [00:23<00:04,  1.11it/s]Epoch: 3/10. Loss: 1.0177:  85%|[36m████████▍ [0m| 22/26 [00:23<00:03,  1.12it/s]Epoch: 3/10. Loss: 0.9630:  85%|[36m████████▍ [0m| 22/26 [00:26<00:03,  1.12it/s]Epoch: 3/10. Loss: 0.9630:  88%|[36m████████▊ [0m| 23/26 [00:26<00:04,  1.66s/it]Epoch: 3/10. Loss: 1.0310:  88%|[36m████████▊ [0m| 23/26 [00:27<00:04,  1.66s/it]Epoch: 3/10. Loss: 1.0310:  92%|[36m█████████▏[0m| 24/26 [00:27<00:02,  1.48s/it]Epoch: 3/10. Loss: 1.0419:  92%|[36m█████████▏[0m| 24/26 [00:28<00:02,  1.48s/it]Epoch: 3/10. Loss: 1.0419:  96%|[36m█████████▌[0m| 25/26 [00:28<00:01,  1.45s/it]Epoch: 3/10. Loss: 0.9065:  96%|[36m█████████▌[0m| 25/26 [00:29<00:01,  1.45s/it]Epoch: 3/10. Loss: 0.9065: 100%|[36m██████████[0m| 26/26 [00:29<00:00,  1.22s/it]Epoch: 3/10. Loss: 0.9065: 100%|[36m██████████[0m| 26/26 [00:29<00:00,  1.14s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:05,  1.06it/s] 29%|[33m██▊       [0m| 2/7 [00:03<00:10,  2.02s/it] 43%|[33m████▎     [0m| 3/7 [00:04<00:05,  1.45s/it] 57%|[33m█████▋    [0m| 4/7 [00:06<00:04,  1.49s/it] 71%|[33m███████▏  [0m| 5/7 [00:06<00:02,  1.10s/it] 86%|[33m████████▌ [0m| 6/7 [00:07<00:00,  1.00it/s]100%|[33m██████████[0m| 7/7 [00:07<00:00,  1.29it/s]100%|[33m██████████[0m| 7/7 [00:07<00:00,  1.08s/it]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 4/10. Loss: 0.9536:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 4/10. Loss: 0.9536:   4%|[36m▍         [0m| 1/26 [00:00<00:21,  1.14it/s]Epoch: 4/10. Loss: 0.9720:   4%|[36m▍         [0m| 1/26 [00:01<00:21,  1.14it/s]Epoch: 4/10. Loss: 0.9720:   8%|[36m▊         [0m| 2/26 [00:01<00:21,  1.14it/s]Epoch: 4/10. Loss: 0.9042:   8%|[36m▊         [0m| 2/26 [00:02<00:21,  1.14it/s]Epoch: 4/10. Loss: 0.9042:  12%|[36m█▏        [0m| 3/26 [00:02<00:18,  1.22it/s]Epoch: 4/10. Loss: 0.8527:  12%|[36m█▏        [0m| 3/26 [00:03<00:18,  1.22it/s]Epoch: 4/10. Loss: 0.8527:  15%|[36m█▌        [0m| 4/26 [00:03<00:20,  1.08it/s]Epoch: 4/10. Loss: 0.8903:  15%|[36m█▌        [0m| 4/26 [00:04<00:20,  1.08it/s]Epoch: 4/10. Loss: 0.8903:  19%|[36m█▉        [0m| 5/26 [00:04<00:19,  1.09it/s]Epoch: 4/10. Loss: 0.9362:  19%|[36m█▉        [0m| 5/26 [00:05<00:19,  1.09it/s]Epoch: 4/10. Loss: 0.9362:  23%|[36m██▎       [0m| 6/26 [00:05<00:18,  1.10it/s]Epoch: 4/10. Loss: 0.8595:  23%|[36m██▎       [0m| 6/26 [00:06<00:18,  1.10it/s]Epoch: 4/10. Loss: 0.8595:  27%|[36m██▋       [0m| 7/26 [00:06<00:16,  1.12it/s]Epoch: 4/10. Loss: 0.8549:  27%|[36m██▋       [0m| 7/26 [00:07<00:16,  1.12it/s]Epoch: 4/10. Loss: 0.8549:  31%|[36m███       [0m| 8/26 [00:07<00:15,  1.15it/s]Epoch: 4/10. Loss: 1.0144:  31%|[36m███       [0m| 8/26 [00:08<00:15,  1.15it/s]Epoch: 4/10. Loss: 1.0144:  35%|[36m███▍      [0m| 9/26 [00:08<00:15,  1.10it/s]Epoch: 4/10. Loss: 0.9968:  35%|[36m███▍      [0m| 9/26 [00:08<00:15,  1.10it/s]Epoch: 4/10. Loss: 0.9968:  38%|[36m███▊      [0m| 10/26 [00:08<00:14,  1.10it/s]Epoch: 4/10. Loss: 0.8628:  38%|[36m███▊      [0m| 10/26 [00:09<00:14,  1.10it/s]Epoch: 4/10. Loss: 0.8628:  42%|[36m████▏     [0m| 11/26 [00:09<00:13,  1.08it/s]Epoch: 4/10. Loss: 0.8840:  42%|[36m████▏     [0m| 11/26 [00:10<00:13,  1.08it/s]Epoch: 4/10. Loss: 0.8840:  46%|[36m████▌     [0m| 12/26 [00:10<00:12,  1.13it/s]Epoch: 4/10. Loss: 0.8811:  46%|[36m████▌     [0m| 12/26 [00:11<00:12,  1.13it/s]Epoch: 4/10. Loss: 0.8811:  50%|[36m█████     [0m| 13/26 [00:11<00:11,  1.09it/s]Epoch: 4/10. Loss: 0.9493:  50%|[36m█████     [0m| 13/26 [00:12<00:11,  1.09it/s]Epoch: 4/10. Loss: 0.9493:  54%|[36m█████▍    [0m| 14/26 [00:12<00:11,  1.07it/s]Epoch: 4/10. Loss: 0.9510:  54%|[36m█████▍    [0m| 14/26 [00:14<00:11,  1.07it/s]Epoch: 4/10. Loss: 0.9510:  58%|[36m█████▊    [0m| 15/26 [00:14<00:12,  1.12s/it]Epoch: 4/10. Loss: 0.9319:  58%|[36m█████▊    [0m| 15/26 [00:15<00:12,  1.12s/it]Epoch: 4/10. Loss: 0.9319:  62%|[36m██████▏   [0m| 16/26 [00:15<00:10,  1.09s/it]Epoch: 4/10. Loss: 0.9033:  62%|[36m██████▏   [0m| 16/26 [00:16<00:10,  1.09s/it]Epoch: 4/10. Loss: 0.9033:  65%|[36m██████▌   [0m| 17/26 [00:16<00:09,  1.02s/it]Epoch: 4/10. Loss: 0.8960:  65%|[36m██████▌   [0m| 17/26 [00:17<00:09,  1.02s/it]Epoch: 4/10. Loss: 0.8960:  69%|[36m██████▉   [0m| 18/26 [00:17<00:08,  1.00s/it]Epoch: 4/10. Loss: 0.8386:  69%|[36m██████▉   [0m| 18/26 [00:17<00:08,  1.00s/it]Epoch: 4/10. Loss: 0.8386:  73%|[36m███████▎  [0m| 19/26 [00:18<00:06,  1.02it/s]Epoch: 4/10. Loss: 0.8432:  73%|[36m███████▎  [0m| 19/26 [00:18<00:06,  1.02it/s]Epoch: 4/10. Loss: 0.8432:  77%|[36m███████▋  [0m| 20/26 [00:18<00:05,  1.04it/s]Epoch: 4/10. Loss: 0.8501:  77%|[36m███████▋  [0m| 20/26 [00:22<00:05,  1.04it/s]Epoch: 4/10. Loss: 0.8501:  81%|[36m████████  [0m| 21/26 [00:22<00:08,  1.66s/it]Epoch: 4/10. Loss: 0.9331:  81%|[36m████████  [0m| 21/26 [00:24<00:08,  1.66s/it]Epoch: 4/10. Loss: 0.9331:  85%|[36m████████▍ [0m| 22/26 [00:24<00:06,  1.75s/it]Epoch: 4/10. Loss: 0.9469:  85%|[36m████████▍ [0m| 22/26 [00:25<00:06,  1.75s/it]Epoch: 4/10. Loss: 0.9469:  88%|[36m████████▊ [0m| 23/26 [00:25<00:04,  1.51s/it]Epoch: 4/10. Loss: 0.8714:  88%|[36m████████▊ [0m| 23/26 [00:26<00:04,  1.51s/it]Epoch: 4/10. Loss: 0.8714:  92%|[36m█████████▏[0m| 24/26 [00:26<00:02,  1.35s/it]Epoch: 4/10. Loss: 0.8451:  92%|[36m█████████▏[0m| 24/26 [00:28<00:02,  1.35s/it]Epoch: 4/10. Loss: 0.8451:  96%|[36m█████████▌[0m| 25/26 [00:28<00:01,  1.66s/it]Epoch: 4/10. Loss: 0.9370:  96%|[36m█████████▌[0m| 25/26 [00:29<00:01,  1.66s/it]Epoch: 4/10. Loss: 0.9370: 100%|[36m██████████[0m| 26/26 [00:29<00:00,  1.37s/it]Epoch: 4/10. Loss: 0.9370: 100%|[36m██████████[0m| 26/26 [00:29<00:00,  1.12s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:05,  1.12it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:05,  1.08s/it] 43%|[33m████▎     [0m| 3/7 [00:02<00:03,  1.03it/s] 57%|[33m█████▋    [0m| 4/7 [00:04<00:03,  1.17s/it] 71%|[33m███████▏  [0m| 5/7 [00:04<00:01,  1.11it/s] 86%|[33m████████▌ [0m| 6/7 [00:05<00:00,  1.14it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.48it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.18it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 5/10. Loss: 0.8185:   0%|[36m          [0m| 0/26 [00:02<?, ?it/s]Epoch: 5/10. Loss: 0.8185:   4%|[36m▍         [0m| 1/26 [00:02<00:54,  2.17s/it]Epoch: 5/10. Loss: 0.7664:   4%|[36m▍         [0m| 1/26 [00:03<00:54,  2.17s/it]Epoch: 5/10. Loss: 0.7664:   8%|[36m▊         [0m| 2/26 [00:03<00:40,  1.69s/it]Epoch: 5/10. Loss: 0.9092:   8%|[36m▊         [0m| 2/26 [00:04<00:40,  1.69s/it]Epoch: 5/10. Loss: 0.9092:  12%|[36m█▏        [0m| 3/26 [00:04<00:34,  1.49s/it]Epoch: 5/10. Loss: 0.8087:  12%|[36m█▏        [0m| 3/26 [00:05<00:34,  1.49s/it]Epoch: 5/10. Loss: 0.8087:  15%|[36m█▌        [0m| 4/26 [00:05<00:28,  1.28s/it]Epoch: 5/10. Loss: 0.8905:  15%|[36m█▌        [0m| 4/26 [00:06<00:28,  1.28s/it]Epoch: 5/10. Loss: 0.8905:  19%|[36m█▉        [0m| 5/26 [00:06<00:23,  1.11s/it]Epoch: 5/10. Loss: 0.9027:  19%|[36m█▉        [0m| 5/26 [00:07<00:23,  1.11s/it]Epoch: 5/10. Loss: 0.9027:  23%|[36m██▎       [0m| 6/26 [00:07<00:22,  1.13s/it]Epoch: 5/10. Loss: 0.8626:  23%|[36m██▎       [0m| 6/26 [00:08<00:22,  1.13s/it]Epoch: 5/10. Loss: 0.8626:  27%|[36m██▋       [0m| 7/26 [00:08<00:21,  1.11s/it]Epoch: 5/10. Loss: 0.8204:  27%|[36m██▋       [0m| 7/26 [00:09<00:21,  1.11s/it]Epoch: 5/10. Loss: 0.8204:  31%|[36m███       [0m| 8/26 [00:09<00:18,  1.04s/it]Epoch: 5/10. Loss: 0.7875:  31%|[36m███       [0m| 8/26 [00:10<00:18,  1.04s/it]Epoch: 5/10. Loss: 0.7875:  35%|[36m███▍      [0m| 9/26 [00:10<00:17,  1.04s/it]Epoch: 5/10. Loss: 0.9734:  35%|[36m███▍      [0m| 9/26 [00:11<00:17,  1.04s/it]Epoch: 5/10. Loss: 0.9734:  38%|[36m███▊      [0m| 10/26 [00:11<00:16,  1.04s/it]Epoch: 5/10. Loss: 0.9291:  38%|[36m███▊      [0m| 10/26 [00:13<00:16,  1.04s/it]Epoch: 5/10. Loss: 0.9291:  42%|[36m████▏     [0m| 11/26 [00:13<00:16,  1.12s/it]Epoch: 5/10. Loss: 0.8580:  42%|[36m████▏     [0m| 11/26 [00:14<00:16,  1.12s/it]Epoch: 5/10. Loss: 0.8580:  46%|[36m████▌     [0m| 12/26 [00:14<00:15,  1.14s/it]Epoch: 5/10. Loss: 0.9133:  46%|[36m████▌     [0m| 12/26 [00:15<00:15,  1.14s/it]Epoch: 5/10. Loss: 0.9133:  50%|[36m█████     [0m| 13/26 [00:15<00:13,  1.06s/it]Epoch: 5/10. Loss: 0.8130:  50%|[36m█████     [0m| 13/26 [00:16<00:13,  1.06s/it]Epoch: 5/10. Loss: 0.8130:  54%|[36m█████▍    [0m| 14/26 [00:16<00:12,  1.03s/it]Epoch: 5/10. Loss: 0.7887:  54%|[36m█████▍    [0m| 14/26 [00:16<00:12,  1.03s/it]Epoch: 5/10. Loss: 0.7887:  58%|[36m█████▊    [0m| 15/26 [00:16<00:10,  1.02it/s]Epoch: 5/10. Loss: 0.8884:  58%|[36m█████▊    [0m| 15/26 [00:17<00:10,  1.02it/s]Epoch: 5/10. Loss: 0.8884:  62%|[36m██████▏   [0m| 16/26 [00:17<00:09,  1.07it/s]Epoch: 5/10. Loss: 0.9296:  62%|[36m██████▏   [0m| 16/26 [00:18<00:09,  1.07it/s]Epoch: 5/10. Loss: 0.9296:  65%|[36m██████▌   [0m| 17/26 [00:18<00:08,  1.07it/s]Epoch: 5/10. Loss: 0.8484:  65%|[36m██████▌   [0m| 17/26 [00:19<00:08,  1.07it/s]Epoch: 5/10. Loss: 0.8484:  69%|[36m██████▉   [0m| 18/26 [00:19<00:07,  1.04it/s]Epoch: 5/10. Loss: 0.9005:  69%|[36m██████▉   [0m| 18/26 [00:20<00:07,  1.04it/s]Epoch: 5/10. Loss: 0.9005:  73%|[36m███████▎  [0m| 19/26 [00:20<00:06,  1.03it/s]Epoch: 5/10. Loss: 0.7917:  73%|[36m███████▎  [0m| 19/26 [00:22<00:06,  1.03it/s]Epoch: 5/10. Loss: 0.7917:  77%|[36m███████▋  [0m| 20/26 [00:22<00:06,  1.10s/it]Epoch: 5/10. Loss: 0.7944:  77%|[36m███████▋  [0m| 20/26 [00:22<00:06,  1.10s/it]Epoch: 5/10. Loss: 0.7944:  81%|[36m████████  [0m| 21/26 [00:23<00:05,  1.03s/it]Epoch: 5/10. Loss: 0.8352:  81%|[36m████████  [0m| 21/26 [00:23<00:05,  1.03s/it]Epoch: 5/10. Loss: 0.8352:  85%|[36m████████▍ [0m| 22/26 [00:23<00:04,  1.01s/it]Epoch: 5/10. Loss: 0.7734:  85%|[36m████████▍ [0m| 22/26 [00:24<00:04,  1.01s/it]Epoch: 5/10. Loss: 0.7734:  88%|[36m████████▊ [0m| 23/26 [00:24<00:02,  1.04it/s]Epoch: 5/10. Loss: 0.9161:  88%|[36m████████▊ [0m| 23/26 [00:25<00:02,  1.04it/s]Epoch: 5/10. Loss: 0.9161:  92%|[36m█████████▏[0m| 24/26 [00:25<00:01,  1.09it/s]Epoch: 5/10. Loss: 0.8090:  92%|[36m█████████▏[0m| 24/26 [00:26<00:01,  1.09it/s]Epoch: 5/10. Loss: 0.8090:  96%|[36m█████████▌[0m| 25/26 [00:26<00:00,  1.11it/s]Epoch: 5/10. Loss: 0.9657:  96%|[36m█████████▌[0m| 25/26 [00:27<00:00,  1.11it/s]Epoch: 5/10. Loss: 0.9657: 100%|[36m██████████[0m| 26/26 [00:27<00:00,  1.21it/s]Epoch: 5/10. Loss: 0.9657: 100%|[36m██████████[0m| 26/26 [00:27<00:00,  1.04s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:05,  1.11it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:05,  1.09s/it] 43%|[33m████▎     [0m| 3/7 [00:02<00:03,  1.04it/s] 57%|[33m█████▋    [0m| 4/7 [00:04<00:03,  1.24s/it] 71%|[33m███████▏  [0m| 5/7 [00:05<00:01,  1.05it/s] 86%|[33m████████▌ [0m| 6/7 [00:05<00:00,  1.10it/s]100%|[33m██████████[0m| 7/7 [00:06<00:00,  1.43it/s]100%|[33m██████████[0m| 7/7 [00:06<00:00,  1.14it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 6/10. Loss: 0.8757:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 6/10. Loss: 0.8757:   4%|[36m▍         [0m| 1/26 [00:00<00:23,  1.06it/s]Epoch: 6/10. Loss: 0.9019:   4%|[36m▍         [0m| 1/26 [00:01<00:23,  1.06it/s]Epoch: 6/10. Loss: 0.9019:   8%|[36m▊         [0m| 2/26 [00:01<00:20,  1.17it/s]Epoch: 6/10. Loss: 0.8404:   8%|[36m▊         [0m| 2/26 [00:02<00:20,  1.17it/s]Epoch: 6/10. Loss: 0.8404:  12%|[36m█▏        [0m| 3/26 [00:02<00:21,  1.06it/s]Epoch: 6/10. Loss: 0.8680:  12%|[36m█▏        [0m| 3/26 [00:03<00:21,  1.06it/s]Epoch: 6/10. Loss: 0.8680:  15%|[36m█▌        [0m| 4/26 [00:03<00:20,  1.06it/s]Epoch: 6/10. Loss: 0.8314:  15%|[36m█▌        [0m| 4/26 [00:04<00:20,  1.06it/s]Epoch: 6/10. Loss: 0.8314:  19%|[36m█▉        [0m| 5/26 [00:04<00:19,  1.09it/s]Epoch: 6/10. Loss: 0.7984:  19%|[36m█▉        [0m| 5/26 [00:05<00:19,  1.09it/s]Epoch: 6/10. Loss: 0.7984:  23%|[36m██▎       [0m| 6/26 [00:05<00:21,  1.06s/it]Epoch: 6/10. Loss: 0.8641:  23%|[36m██▎       [0m| 6/26 [00:06<00:21,  1.06s/it]Epoch: 6/10. Loss: 0.8641:  27%|[36m██▋       [0m| 7/26 [00:06<00:19,  1.03s/it]Epoch: 6/10. Loss: 0.8060:  27%|[36m██▋       [0m| 7/26 [00:07<00:19,  1.03s/it]Epoch: 6/10. Loss: 0.8060:  31%|[36m███       [0m| 8/26 [00:07<00:18,  1.02s/it]Epoch: 6/10. Loss: 0.8861:  31%|[36m███       [0m| 8/26 [00:08<00:18,  1.02s/it]Epoch: 6/10. Loss: 0.8861:  35%|[36m███▍      [0m| 9/26 [00:08<00:17,  1.03s/it]Epoch: 6/10. Loss: 0.9398:  35%|[36m███▍      [0m| 9/26 [00:09<00:17,  1.03s/it]Epoch: 6/10. Loss: 0.9398:  38%|[36m███▊      [0m| 10/26 [00:09<00:15,  1.05it/s]Epoch: 6/10. Loss: 0.8464:  38%|[36m███▊      [0m| 10/26 [00:10<00:15,  1.05it/s]Epoch: 6/10. Loss: 0.8464:  42%|[36m████▏     [0m| 11/26 [00:10<00:14,  1.02it/s]Epoch: 6/10. Loss: 0.8434:  42%|[36m████▏     [0m| 11/26 [00:11<00:14,  1.02it/s]Epoch: 6/10. Loss: 0.8434:  46%|[36m████▌     [0m| 12/26 [00:11<00:13,  1.04it/s]Epoch: 6/10. Loss: 0.8569:  46%|[36m████▌     [0m| 12/26 [00:12<00:13,  1.04it/s]Epoch: 6/10. Loss: 0.8569:  50%|[36m█████     [0m| 13/26 [00:12<00:12,  1.07it/s]Epoch: 6/10. Loss: 0.7575:  50%|[36m█████     [0m| 13/26 [00:13<00:12,  1.07it/s]Epoch: 6/10. Loss: 0.7575:  54%|[36m█████▍    [0m| 14/26 [00:13<00:11,  1.08it/s]Epoch: 6/10. Loss: 0.9102:  54%|[36m█████▍    [0m| 14/26 [00:14<00:11,  1.08it/s]Epoch: 6/10. Loss: 0.9102:  58%|[36m█████▊    [0m| 15/26 [00:14<00:10,  1.09it/s]Epoch: 6/10. Loss: 0.7710:  58%|[36m█████▊    [0m| 15/26 [00:15<00:10,  1.09it/s]Epoch: 6/10. Loss: 0.7710:  62%|[36m██████▏   [0m| 16/26 [00:15<00:08,  1.12it/s]Epoch: 6/10. Loss: 0.7832:  62%|[36m██████▏   [0m| 16/26 [00:15<00:08,  1.12it/s]Epoch: 6/10. Loss: 0.7832:  65%|[36m██████▌   [0m| 17/26 [00:15<00:07,  1.16it/s]Epoch: 6/10. Loss: 0.8922:  65%|[36m██████▌   [0m| 17/26 [00:16<00:07,  1.16it/s]Epoch: 6/10. Loss: 0.8922:  69%|[36m██████▉   [0m| 18/26 [00:16<00:07,  1.14it/s]Epoch: 6/10. Loss: 0.8258:  69%|[36m██████▉   [0m| 18/26 [00:17<00:07,  1.14it/s]Epoch: 6/10. Loss: 0.8258:  73%|[36m███████▎  [0m| 19/26 [00:17<00:06,  1.15it/s]Epoch: 6/10. Loss: 0.8832:  73%|[36m███████▎  [0m| 19/26 [00:18<00:06,  1.15it/s]Epoch: 6/10. Loss: 0.8832:  77%|[36m███████▋  [0m| 20/26 [00:18<00:05,  1.11it/s]Epoch: 6/10. Loss: 0.8394:  77%|[36m███████▋  [0m| 20/26 [00:19<00:05,  1.11it/s]Epoch: 6/10. Loss: 0.8394:  81%|[36m████████  [0m| 21/26 [00:19<00:04,  1.10it/s]Epoch: 6/10. Loss: 0.8593:  81%|[36m████████  [0m| 21/26 [00:20<00:04,  1.10it/s]Epoch: 6/10. Loss: 0.8593:  85%|[36m████████▍ [0m| 22/26 [00:20<00:04,  1.01s/it]Epoch: 6/10. Loss: 0.8699:  85%|[36m████████▍ [0m| 22/26 [00:21<00:04,  1.01s/it]Epoch: 6/10. Loss: 0.8699:  88%|[36m████████▊ [0m| 23/26 [00:21<00:02,  1.04it/s]Epoch: 6/10. Loss: 0.8608:  88%|[36m████████▊ [0m| 23/26 [00:22<00:02,  1.04it/s]Epoch: 6/10. Loss: 0.8608:  92%|[36m█████████▏[0m| 24/26 [00:22<00:01,  1.12it/s]Epoch: 6/10. Loss: 0.7612:  92%|[36m█████████▏[0m| 24/26 [00:23<00:01,  1.12it/s]Epoch: 6/10. Loss: 0.7612:  96%|[36m█████████▌[0m| 25/26 [00:23<00:00,  1.13it/s]Epoch: 6/10. Loss: 0.8711:  96%|[36m█████████▌[0m| 25/26 [00:23<00:00,  1.13it/s]Epoch: 6/10. Loss: 0.8711: 100%|[36m██████████[0m| 26/26 [00:23<00:00,  1.28it/s]Epoch: 6/10. Loss: 0.8711: 100%|[36m██████████[0m| 26/26 [00:23<00:00,  1.09it/s]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:05,  1.10it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:06,  1.23s/it] 43%|[33m████▎     [0m| 3/7 [00:03<00:04,  1.18s/it] 57%|[33m█████▋    [0m| 4/7 [00:04<00:03,  1.26s/it] 71%|[33m███████▏  [0m| 5/7 [00:05<00:01,  1.03it/s] 86%|[33m████████▌ [0m| 6/7 [00:06<00:00,  1.08it/s]100%|[33m██████████[0m| 7/7 [00:06<00:00,  1.41it/s]100%|[33m██████████[0m| 7/7 [00:06<00:00,  1.09it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 7/10. Loss: 0.8545:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 7/10. Loss: 0.8545:   4%|[36m▍         [0m| 1/26 [00:00<00:24,  1.02it/s]Epoch: 7/10. Loss: 0.9670:   4%|[36m▍         [0m| 1/26 [00:01<00:24,  1.02it/s]Epoch: 7/10. Loss: 0.9670:   8%|[36m▊         [0m| 2/26 [00:02<00:24,  1.02s/it]Epoch: 7/10. Loss: 0.8036:   8%|[36m▊         [0m| 2/26 [00:03<00:24,  1.02s/it]Epoch: 7/10. Loss: 0.8036:  12%|[36m█▏        [0m| 3/26 [00:03<00:24,  1.08s/it]Epoch: 7/10. Loss: 0.7864:  12%|[36m█▏        [0m| 3/26 [00:04<00:24,  1.08s/it]Epoch: 7/10. Loss: 0.7864:  15%|[36m█▌        [0m| 4/26 [00:04<00:27,  1.24s/it]Epoch: 7/10. Loss: 0.8604:  15%|[36m█▌        [0m| 4/26 [00:05<00:27,  1.24s/it]Epoch: 7/10. Loss: 0.8604:  19%|[36m█▉        [0m| 5/26 [00:05<00:23,  1.14s/it]Epoch: 7/10. Loss: 0.9627:  19%|[36m█▉        [0m| 5/26 [00:06<00:23,  1.14s/it]Epoch: 7/10. Loss: 0.9627:  23%|[36m██▎       [0m| 6/26 [00:06<00:21,  1.06s/it]Epoch: 7/10. Loss: 0.8056:  23%|[36m██▎       [0m| 6/26 [00:07<00:21,  1.06s/it]Epoch: 7/10. Loss: 0.8056:  27%|[36m██▋       [0m| 7/26 [00:07<00:18,  1.01it/s]Epoch: 7/10. Loss: 0.7804:  27%|[36m██▋       [0m| 7/26 [00:08<00:18,  1.01it/s]Epoch: 7/10. Loss: 0.7804:  31%|[36m███       [0m| 8/26 [00:08<00:17,  1.01it/s]Epoch: 7/10. Loss: 0.8181:  31%|[36m███       [0m| 8/26 [00:09<00:17,  1.01it/s]Epoch: 7/10. Loss: 0.8181:  35%|[36m███▍      [0m| 9/26 [00:09<00:16,  1.06it/s]Epoch: 7/10. Loss: 0.7978:  35%|[36m███▍      [0m| 9/26 [00:09<00:16,  1.06it/s]Epoch: 7/10. Loss: 0.7978:  38%|[36m███▊      [0m| 10/26 [00:09<00:14,  1.12it/s]Epoch: 7/10. Loss: 0.8670:  38%|[36m███▊      [0m| 10/26 [00:10<00:14,  1.12it/s]Epoch: 7/10. Loss: 0.8670:  42%|[36m████▏     [0m| 11/26 [00:11<00:13,  1.08it/s]Epoch: 7/10. Loss: 0.8778:  42%|[36m████▏     [0m| 11/26 [00:11<00:13,  1.08it/s]Epoch: 7/10. Loss: 0.8778:  46%|[36m████▌     [0m| 12/26 [00:11<00:13,  1.06it/s]Epoch: 7/10. Loss: 0.7017:  46%|[36m████▌     [0m| 12/26 [00:12<00:13,  1.06it/s]Epoch: 7/10. Loss: 0.7017:  50%|[36m█████     [0m| 13/26 [00:12<00:12,  1.08it/s]Epoch: 7/10. Loss: 0.8206:  50%|[36m█████     [0m| 13/26 [00:13<00:12,  1.08it/s]Epoch: 7/10. Loss: 0.8206:  54%|[36m█████▍    [0m| 14/26 [00:13<00:11,  1.04it/s]Epoch: 7/10. Loss: 0.7615:  54%|[36m█████▍    [0m| 14/26 [00:14<00:11,  1.04it/s]Epoch: 7/10. Loss: 0.7615:  58%|[36m█████▊    [0m| 15/26 [00:14<00:10,  1.09it/s]Epoch: 7/10. Loss: 0.8039:  58%|[36m█████▊    [0m| 15/26 [00:15<00:10,  1.09it/s]Epoch: 7/10. Loss: 0.8039:  62%|[36m██████▏   [0m| 16/26 [00:15<00:08,  1.13it/s]Epoch: 7/10. Loss: 0.8108:  62%|[36m██████▏   [0m| 16/26 [00:16<00:08,  1.13it/s]Epoch: 7/10. Loss: 0.8108:  65%|[36m██████▌   [0m| 17/26 [00:16<00:08,  1.11it/s]Epoch: 7/10. Loss: 0.7682:  65%|[36m██████▌   [0m| 17/26 [00:17<00:08,  1.11it/s]Epoch: 7/10. Loss: 0.7682:  69%|[36m██████▉   [0m| 18/26 [00:17<00:07,  1.09it/s]Epoch: 7/10. Loss: 0.7006:  69%|[36m██████▉   [0m| 18/26 [00:18<00:07,  1.09it/s]Epoch: 7/10. Loss: 0.7006:  73%|[36m███████▎  [0m| 19/26 [00:18<00:06,  1.12it/s]Epoch: 7/10. Loss: 0.7636:  73%|[36m███████▎  [0m| 19/26 [00:19<00:06,  1.12it/s]Epoch: 7/10. Loss: 0.7636:  77%|[36m███████▋  [0m| 20/26 [00:19<00:05,  1.08it/s]Epoch: 7/10. Loss: 0.7299:  77%|[36m███████▋  [0m| 20/26 [00:21<00:05,  1.08it/s]Epoch: 7/10. Loss: 0.7299:  81%|[36m████████  [0m| 21/26 [00:21<00:07,  1.45s/it]Epoch: 7/10. Loss: 0.7300:  81%|[36m████████  [0m| 21/26 [00:22<00:07,  1.45s/it]Epoch: 7/10. Loss: 0.7300:  85%|[36m████████▍ [0m| 22/26 [00:22<00:05,  1.32s/it]Epoch: 7/10. Loss: 0.9678:  85%|[36m████████▍ [0m| 22/26 [00:23<00:05,  1.32s/it]Epoch: 7/10. Loss: 0.9678:  88%|[36m████████▊ [0m| 23/26 [00:23<00:03,  1.19s/it]Epoch: 7/10. Loss: 0.8066:  88%|[36m████████▊ [0m| 23/26 [00:24<00:03,  1.19s/it]Epoch: 7/10. Loss: 0.8066:  92%|[36m█████████▏[0m| 24/26 [00:24<00:02,  1.15s/it]Epoch: 7/10. Loss: 0.8137:  92%|[36m█████████▏[0m| 24/26 [00:25<00:02,  1.15s/it]Epoch: 7/10. Loss: 0.8137:  96%|[36m█████████▌[0m| 25/26 [00:25<00:01,  1.07s/it]Epoch: 7/10. Loss: 0.7557:  96%|[36m█████████▌[0m| 25/26 [00:26<00:01,  1.07s/it]Epoch: 7/10. Loss: 0.7557: 100%|[36m██████████[0m| 26/26 [00:26<00:00,  1.06it/s]Epoch: 7/10. Loss: 0.7557: 100%|[36m██████████[0m| 26/26 [00:26<00:00,  1.02s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:05,  1.08it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:05,  1.14s/it] 43%|[33m████▎     [0m| 3/7 [00:02<00:03,  1.02it/s] 57%|[33m█████▋    [0m| 4/7 [00:04<00:03,  1.16s/it] 71%|[33m███████▏  [0m| 5/7 [00:04<00:01,  1.11it/s] 86%|[33m████████▌ [0m| 6/7 [00:05<00:00,  1.08it/s]100%|[33m██████████[0m| 7/7 [00:06<00:00,  1.41it/s]100%|[33m██████████[0m| 7/7 [00:06<00:00,  1.14it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 8/10. Loss: 0.8755:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 8/10. Loss: 0.8755:   4%|[36m▍         [0m| 1/26 [00:00<00:18,  1.34it/s]Epoch: 8/10. Loss: 0.8060:   4%|[36m▍         [0m| 1/26 [00:01<00:18,  1.34it/s]Epoch: 8/10. Loss: 0.8060:   8%|[36m▊         [0m| 2/26 [00:01<00:19,  1.26it/s]Epoch: 8/10. Loss: 0.8450:   8%|[36m▊         [0m| 2/26 [00:02<00:19,  1.26it/s]Epoch: 8/10. Loss: 0.8450:  12%|[36m█▏        [0m| 3/26 [00:02<00:18,  1.26it/s]Epoch: 8/10. Loss: 0.8716:  12%|[36m█▏        [0m| 3/26 [00:03<00:18,  1.26it/s]Epoch: 8/10. Loss: 0.8716:  15%|[36m█▌        [0m| 4/26 [00:03<00:19,  1.14it/s]Epoch: 8/10. Loss: 0.8532:  15%|[36m█▌        [0m| 4/26 [00:05<00:19,  1.14it/s]Epoch: 8/10. Loss: 0.8532:  19%|[36m█▉        [0m| 5/26 [00:05<00:28,  1.36s/it]Epoch: 8/10. Loss: 0.7979:  19%|[36m█▉        [0m| 5/26 [00:06<00:28,  1.36s/it]Epoch: 8/10. Loss: 0.7979:  23%|[36m██▎       [0m| 6/26 [00:06<00:24,  1.22s/it]Epoch: 8/10. Loss: 0.8041:  23%|[36m██▎       [0m| 6/26 [00:07<00:24,  1.22s/it]Epoch: 8/10. Loss: 0.8041:  27%|[36m██▋       [0m| 7/26 [00:07<00:20,  1.09s/it]Epoch: 8/10. Loss: 0.8502:  27%|[36m██▋       [0m| 7/26 [00:08<00:20,  1.09s/it]Epoch: 8/10. Loss: 0.8502:  31%|[36m███       [0m| 8/26 [00:08<00:20,  1.13s/it]Epoch: 8/10. Loss: 0.7826:  31%|[36m███       [0m| 8/26 [00:09<00:20,  1.13s/it]Epoch: 8/10. Loss: 0.7826:  35%|[36m███▍      [0m| 9/26 [00:09<00:18,  1.08s/it]Epoch: 8/10. Loss: 0.7186:  35%|[36m███▍      [0m| 9/26 [00:10<00:18,  1.08s/it]Epoch: 8/10. Loss: 0.7186:  38%|[36m███▊      [0m| 10/26 [00:10<00:16,  1.06s/it]Epoch: 8/10. Loss: 0.8370:  38%|[36m███▊      [0m| 10/26 [00:11<00:16,  1.06s/it]Epoch: 8/10. Loss: 0.8370:  42%|[36m████▏     [0m| 11/26 [00:11<00:15,  1.02s/it]Epoch: 8/10. Loss: 0.9684:  42%|[36m████▏     [0m| 11/26 [00:12<00:15,  1.02s/it]Epoch: 8/10. Loss: 0.9684:  46%|[36m████▌     [0m| 12/26 [00:12<00:13,  1.01it/s]Epoch: 8/10. Loss: 0.8504:  46%|[36m████▌     [0m| 12/26 [00:13<00:13,  1.01it/s]Epoch: 8/10. Loss: 0.8504:  50%|[36m█████     [0m| 13/26 [00:13<00:12,  1.03it/s]Epoch: 8/10. Loss: 0.8467:  50%|[36m█████     [0m| 13/26 [00:14<00:12,  1.03it/s]Epoch: 8/10. Loss: 0.8467:  54%|[36m█████▍    [0m| 14/26 [00:14<00:11,  1.05it/s]Epoch: 8/10. Loss: 0.7968:  54%|[36m█████▍    [0m| 14/26 [00:15<00:11,  1.05it/s]Epoch: 8/10. Loss: 0.7968:  58%|[36m█████▊    [0m| 15/26 [00:15<00:10,  1.04it/s]Epoch: 8/10. Loss: 0.7296:  58%|[36m█████▊    [0m| 15/26 [00:16<00:10,  1.04it/s]Epoch: 8/10. Loss: 0.7296:  62%|[36m██████▏   [0m| 16/26 [00:16<00:09,  1.03it/s]Epoch: 8/10. Loss: 0.8263:  62%|[36m██████▏   [0m| 16/26 [00:17<00:09,  1.03it/s]Epoch: 8/10. Loss: 0.8263:  65%|[36m██████▌   [0m| 17/26 [00:17<00:08,  1.05it/s]Epoch: 8/10. Loss: 0.8978:  65%|[36m██████▌   [0m| 17/26 [00:18<00:08,  1.05it/s]Epoch: 8/10. Loss: 0.8978:  69%|[36m██████▉   [0m| 18/26 [00:18<00:07,  1.06it/s]Epoch: 8/10. Loss: 0.7395:  69%|[36m██████▉   [0m| 18/26 [00:18<00:07,  1.06it/s]Epoch: 8/10. Loss: 0.7395:  73%|[36m███████▎  [0m| 19/26 [00:18<00:06,  1.07it/s]Epoch: 8/10. Loss: 0.7506:  73%|[36m███████▎  [0m| 19/26 [00:19<00:06,  1.07it/s]Epoch: 8/10. Loss: 0.7506:  77%|[36m███████▋  [0m| 20/26 [00:20<00:05,  1.04it/s]Epoch: 8/10. Loss: 0.8043:  77%|[36m███████▋  [0m| 20/26 [00:20<00:05,  1.04it/s]Epoch: 8/10. Loss: 0.8043:  81%|[36m████████  [0m| 21/26 [00:20<00:04,  1.09it/s]Epoch: 8/10. Loss: 0.8466:  81%|[36m████████  [0m| 21/26 [00:22<00:04,  1.09it/s]Epoch: 8/10. Loss: 0.8466:  85%|[36m████████▍ [0m| 22/26 [00:22<00:04,  1.05s/it]Epoch: 8/10. Loss: 0.7462:  85%|[36m████████▍ [0m| 22/26 [00:23<00:04,  1.05s/it]Epoch: 8/10. Loss: 0.7462:  88%|[36m████████▊ [0m| 23/26 [00:23<00:03,  1.01s/it]Epoch: 8/10. Loss: 0.7640:  88%|[36m████████▊ [0m| 23/26 [00:24<00:03,  1.01s/it]Epoch: 8/10. Loss: 0.7640:  92%|[36m█████████▏[0m| 24/26 [00:24<00:01,  1.00it/s]Epoch: 8/10. Loss: 0.8016:  92%|[36m█████████▏[0m| 24/26 [00:24<00:01,  1.00it/s]Epoch: 8/10. Loss: 0.8016:  96%|[36m█████████▌[0m| 25/26 [00:25<00:00,  1.01it/s]Epoch: 8/10. Loss: 0.5532:  96%|[36m█████████▌[0m| 25/26 [00:25<00:00,  1.01it/s]Epoch: 8/10. Loss: 0.5532: 100%|[36m██████████[0m| 26/26 [00:25<00:00,  1.14it/s]Epoch: 8/10. Loss: 0.5532: 100%|[36m██████████[0m| 26/26 [00:25<00:00,  1.01it/s]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:05,  1.06it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:05,  1.14s/it] 43%|[33m████▎     [0m| 3/7 [00:03<00:03,  1.02it/s] 57%|[33m█████▋    [0m| 4/7 [00:04<00:03,  1.15s/it] 71%|[33m███████▏  [0m| 5/7 [00:06<00:02,  1.43s/it] 86%|[33m████████▌ [0m| 6/7 [00:07<00:01,  1.23s/it]100%|[33m██████████[0m| 7/7 [00:07<00:00,  1.09it/s]100%|[33m██████████[0m| 7/7 [00:07<00:00,  1.07s/it]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 9/10. Loss: 0.6328:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 9/10. Loss: 0.6328:   4%|[36m▍         [0m| 1/26 [00:00<00:23,  1.08it/s]Epoch: 9/10. Loss: 0.9382:   4%|[36m▍         [0m| 1/26 [00:02<00:23,  1.08it/s]Epoch: 9/10. Loss: 0.9382:   8%|[36m▊         [0m| 2/26 [00:02<00:35,  1.49s/it]Epoch: 9/10. Loss: 0.8516:   8%|[36m▊         [0m| 2/26 [00:04<00:35,  1.49s/it]Epoch: 9/10. Loss: 0.8516:  12%|[36m█▏        [0m| 3/26 [00:04<00:31,  1.38s/it]Epoch: 9/10. Loss: 0.8109:  12%|[36m█▏        [0m| 3/26 [00:04<00:31,  1.38s/it]Epoch: 9/10. Loss: 0.8109:  15%|[36m█▌        [0m| 4/26 [00:04<00:26,  1.20s/it]Epoch: 9/10. Loss: 0.7317:  15%|[36m█▌        [0m| 4/26 [00:05<00:26,  1.20s/it]Epoch: 9/10. Loss: 0.7317:  19%|[36m█▉        [0m| 5/26 [00:05<00:22,  1.09s/it]Epoch: 9/10. Loss: 0.7628:  19%|[36m█▉        [0m| 5/26 [00:06<00:22,  1.09s/it]Epoch: 9/10. Loss: 0.7628:  23%|[36m██▎       [0m| 6/26 [00:06<00:20,  1.02s/it]Epoch: 9/10. Loss: 0.8306:  23%|[36m██▎       [0m| 6/26 [00:07<00:20,  1.02s/it]Epoch: 9/10. Loss: 0.8306:  27%|[36m██▋       [0m| 7/26 [00:07<00:18,  1.01it/s]Epoch: 9/10. Loss: 0.6805:  27%|[36m██▋       [0m| 7/26 [00:08<00:18,  1.01it/s]Epoch: 9/10. Loss: 0.6805:  31%|[36m███       [0m| 8/26 [00:08<00:17,  1.05it/s]Epoch: 9/10. Loss: 0.8024:  31%|[36m███       [0m| 8/26 [00:09<00:17,  1.05it/s]Epoch: 9/10. Loss: 0.8024:  35%|[36m███▍      [0m| 9/26 [00:09<00:15,  1.08it/s]Epoch: 9/10. Loss: 0.7402:  35%|[36m███▍      [0m| 9/26 [00:10<00:15,  1.08it/s]Epoch: 9/10. Loss: 0.7402:  38%|[36m███▊      [0m| 10/26 [00:10<00:14,  1.12it/s]Epoch: 9/10. Loss: 0.7524:  38%|[36m███▊      [0m| 10/26 [00:11<00:14,  1.12it/s]Epoch: 9/10. Loss: 0.7524:  42%|[36m████▏     [0m| 11/26 [00:11<00:13,  1.11it/s]Epoch: 9/10. Loss: 0.7718:  42%|[36m████▏     [0m| 11/26 [00:12<00:13,  1.11it/s]Epoch: 9/10. Loss: 0.7718:  46%|[36m████▌     [0m| 12/26 [00:12<00:12,  1.09it/s]Epoch: 9/10. Loss: 0.8370:  46%|[36m████▌     [0m| 12/26 [00:13<00:12,  1.09it/s]Epoch: 9/10. Loss: 0.8370:  50%|[36m█████     [0m| 13/26 [00:13<00:12,  1.07it/s]Epoch: 9/10. Loss: 0.7537:  50%|[36m█████     [0m| 13/26 [00:14<00:12,  1.07it/s]Epoch: 9/10. Loss: 0.7537:  54%|[36m█████▍    [0m| 14/26 [00:14<00:11,  1.04it/s]Epoch: 9/10. Loss: 0.6992:  54%|[36m█████▍    [0m| 14/26 [00:14<00:11,  1.04it/s]Epoch: 9/10. Loss: 0.6992:  58%|[36m█████▊    [0m| 15/26 [00:14<00:10,  1.08it/s]Epoch: 9/10. Loss: 0.7303:  58%|[36m█████▊    [0m| 15/26 [00:15<00:10,  1.08it/s]Epoch: 9/10. Loss: 0.7303:  62%|[36m██████▏   [0m| 16/26 [00:15<00:08,  1.12it/s]Epoch: 9/10. Loss: 0.7726:  62%|[36m██████▏   [0m| 16/26 [00:16<00:08,  1.12it/s]Epoch: 9/10. Loss: 0.7726:  65%|[36m██████▌   [0m| 17/26 [00:16<00:08,  1.05it/s]Epoch: 9/10. Loss: 0.8777:  65%|[36m██████▌   [0m| 17/26 [00:17<00:08,  1.05it/s]Epoch: 9/10. Loss: 0.8777:  69%|[36m██████▉   [0m| 18/26 [00:17<00:07,  1.06it/s]Epoch: 9/10. Loss: 0.9111:  69%|[36m██████▉   [0m| 18/26 [00:18<00:07,  1.06it/s]Epoch: 9/10. Loss: 0.9111:  73%|[36m███████▎  [0m| 19/26 [00:18<00:06,  1.08it/s]Epoch: 9/10. Loss: 0.7472:  73%|[36m███████▎  [0m| 19/26 [00:19<00:06,  1.08it/s]Epoch: 9/10. Loss: 0.7472:  77%|[36m███████▋  [0m| 20/26 [00:19<00:05,  1.09it/s]Epoch: 9/10. Loss: 0.8834:  77%|[36m███████▋  [0m| 20/26 [00:20<00:05,  1.09it/s]Epoch: 9/10. Loss: 0.8834:  81%|[36m████████  [0m| 21/26 [00:20<00:04,  1.01it/s]Epoch: 9/10. Loss: 0.7951:  81%|[36m████████  [0m| 21/26 [00:21<00:04,  1.01it/s]Epoch: 9/10. Loss: 0.7951:  85%|[36m████████▍ [0m| 22/26 [00:21<00:03,  1.05it/s]Epoch: 9/10. Loss: 0.8286:  85%|[36m████████▍ [0m| 22/26 [00:22<00:03,  1.05it/s]Epoch: 9/10. Loss: 0.8286:  88%|[36m████████▊ [0m| 23/26 [00:22<00:02,  1.09it/s]Epoch: 9/10. Loss: 0.8076:  88%|[36m████████▊ [0m| 23/26 [00:23<00:02,  1.09it/s]Epoch: 9/10. Loss: 0.8076:  92%|[36m█████████▏[0m| 24/26 [00:23<00:01,  1.04it/s]Epoch: 9/10. Loss: 0.7272:  92%|[36m█████████▏[0m| 24/26 [00:24<00:01,  1.04it/s]Epoch: 9/10. Loss: 0.7272:  96%|[36m█████████▌[0m| 25/26 [00:24<00:00,  1.05it/s]Epoch: 9/10. Loss: 0.9445:  96%|[36m█████████▌[0m| 25/26 [00:24<00:00,  1.05it/s]Epoch: 9/10. Loss: 0.9445: 100%|[36m██████████[0m| 26/26 [00:25<00:00,  1.19it/s]Epoch: 9/10. Loss: 0.9445: 100%|[36m██████████[0m| 26/26 [00:25<00:00,  1.04it/s]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:01<00:06,  1.07s/it] 29%|[33m██▊       [0m| 2/7 [00:02<00:06,  1.22s/it] 43%|[33m████▎     [0m| 3/7 [00:03<00:04,  1.03s/it] 57%|[33m█████▋    [0m| 4/7 [00:06<00:05,  1.78s/it] 71%|[33m███████▏  [0m| 5/7 [00:06<00:02,  1.30s/it] 86%|[33m████████▌ [0m| 6/7 [00:09<00:01,  1.77s/it]100%|[33m██████████[0m| 7/7 [00:11<00:00,  2.07s/it]100%|[33m██████████[0m| 7/7 [00:11<00:00,  1.71s/it]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 0/10. Loss: 1.2413:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 0/10. Loss: 1.2413:   4%|[36m▍         [0m| 1/26 [00:00<00:24,  1.02it/s]Epoch: 0/10. Loss: 4.1468:   4%|[36m▍         [0m| 1/26 [00:01<00:24,  1.02it/s]Epoch: 0/10. Loss: 4.1468:   8%|[36m▊         [0m| 2/26 [00:01<00:22,  1.08it/s]Epoch: 0/10. Loss: 6.2565:   8%|[36m▊         [0m| 2/26 [00:02<00:22,  1.08it/s]Epoch: 0/10. Loss: 6.2565:  12%|[36m█▏        [0m| 3/26 [00:02<00:20,  1.11it/s]Epoch: 0/10. Loss: 3.4218:  12%|[36m█▏        [0m| 3/26 [00:03<00:20,  1.11it/s]Epoch: 0/10. Loss: 3.4218:  15%|[36m█▌        [0m| 4/26 [00:03<00:18,  1.17it/s]Epoch: 0/10. Loss: 3.8364:  15%|[36m█▌        [0m| 4/26 [00:04<00:18,  1.17it/s]Epoch: 0/10. Loss: 3.8364:  19%|[36m█▉        [0m| 5/26 [00:04<00:18,  1.12it/s]Epoch: 0/10. Loss: 1.7676:  19%|[36m█▉        [0m| 5/26 [00:05<00:18,  1.12it/s]Epoch: 0/10. Loss: 1.7676:  23%|[36m██▎       [0m| 6/26 [00:06<00:22,  1.11s/it]Epoch: 0/10. Loss: 1.1776:  23%|[36m██▎       [0m| 6/26 [00:08<00:22,  1.11s/it]Epoch: 0/10. Loss: 1.1776:  27%|[36m██▋       [0m| 7/26 [00:08<00:27,  1.44s/it]Epoch: 0/10. Loss: 1.1373:  27%|[36m██▋       [0m| 7/26 [00:12<00:27,  1.44s/it]Epoch: 0/10. Loss: 1.1373:  31%|[36m███       [0m| 8/26 [00:12<00:40,  2.27s/it]Epoch: 0/10. Loss: 1.0596:  31%|[36m███       [0m| 8/26 [00:14<00:40,  2.27s/it]Epoch: 0/10. Loss: 1.0596:  35%|[36m███▍      [0m| 9/26 [00:14<00:41,  2.42s/it]Epoch: 0/10. Loss: 1.3963:  35%|[36m███▍      [0m| 9/26 [00:18<00:41,  2.42s/it]Epoch: 0/10. Loss: 1.3963:  38%|[36m███▊      [0m| 10/26 [00:18<00:42,  2.68s/it]Epoch: 0/10. Loss: 1.1087:  38%|[36m███▊      [0m| 10/26 [00:19<00:42,  2.68s/it]Epoch: 0/10. Loss: 1.1087:  42%|[36m████▏     [0m| 11/26 [00:19<00:35,  2.35s/it]Epoch: 0/10. Loss: 6.4173:  42%|[36m████▏     [0m| 11/26 [00:20<00:35,  2.35s/it]Epoch: 0/10. Loss: 6.4173:  46%|[36m████▌     [0m| 12/26 [00:20<00:25,  1.84s/it]Epoch: 0/10. Loss: 6.4128:  46%|[36m████▌     [0m| 12/26 [00:21<00:25,  1.84s/it]Epoch: 0/10. Loss: 6.4128:  50%|[36m█████     [0m| 13/26 [00:21<00:20,  1.54s/it]Epoch: 0/10. Loss: 2.4297:  50%|[36m█████     [0m| 13/26 [00:22<00:20,  1.54s/it]Epoch: 0/10. Loss: 2.4297:  54%|[36m█████▍    [0m| 14/26 [00:22<00:15,  1.33s/it]Epoch: 0/10. Loss: 3.9888:  54%|[36m█████▍    [0m| 14/26 [00:23<00:15,  1.33s/it]Epoch: 0/10. Loss: 3.9888:  58%|[36m█████▊    [0m| 15/26 [00:23<00:14,  1.34s/it]Epoch: 0/10. Loss: 2.5784:  58%|[36m█████▊    [0m| 15/26 [00:24<00:14,  1.34s/it]Epoch: 0/10. Loss: 2.5784:  62%|[36m██████▏   [0m| 16/26 [00:24<00:12,  1.23s/it]Epoch: 0/10. Loss: 2.4144:  62%|[36m██████▏   [0m| 16/26 [00:25<00:12,  1.23s/it]Epoch: 0/10. Loss: 2.4144:  65%|[36m██████▌   [0m| 17/26 [00:25<00:10,  1.19s/it]Epoch: 0/10. Loss: 2.1778:  65%|[36m██████▌   [0m| 17/26 [00:26<00:10,  1.19s/it]Epoch: 0/10. Loss: 2.1778:  69%|[36m██████▉   [0m| 18/26 [00:26<00:09,  1.17s/it]Epoch: 0/10. Loss: 1.5849:  69%|[36m██████▉   [0m| 18/26 [00:28<00:09,  1.17s/it]Epoch: 0/10. Loss: 1.5849:  73%|[36m███████▎  [0m| 19/26 [00:28<00:08,  1.22s/it]Epoch: 0/10. Loss: 2.0180:  73%|[36m███████▎  [0m| 19/26 [00:29<00:08,  1.22s/it]Epoch: 0/10. Loss: 2.0180:  77%|[36m███████▋  [0m| 20/26 [00:29<00:06,  1.16s/it]Epoch: 0/10. Loss: 1.9722:  77%|[36m███████▋  [0m| 20/26 [00:29<00:06,  1.16s/it]Epoch: 0/10. Loss: 1.9722:  81%|[36m████████  [0m| 21/26 [00:29<00:05,  1.04s/it]Epoch: 0/10. Loss: 1.1177:  81%|[36m████████  [0m| 21/26 [00:30<00:05,  1.04s/it]Epoch: 0/10. Loss: 1.1177:  85%|[36m████████▍ [0m| 22/26 [00:30<00:04,  1.04s/it]Epoch: 0/10. Loss: 1.6684:  85%|[36m████████▍ [0m| 22/26 [00:31<00:04,  1.04s/it]Epoch: 0/10. Loss: 1.6684:  88%|[36m████████▊ [0m| 23/26 [00:31<00:02,  1.02it/s]Epoch: 0/10. Loss: 1.6497:  88%|[36m████████▊ [0m| 23/26 [00:32<00:02,  1.02it/s]Epoch: 0/10. Loss: 1.6497:  92%|[36m█████████▏[0m| 24/26 [00:32<00:01,  1.07it/s]Epoch: 0/10. Loss: 1.3376:  92%|[36m█████████▏[0m| 24/26 [00:33<00:01,  1.07it/s]Epoch: 0/10. Loss: 1.3376:  96%|[36m█████████▌[0m| 25/26 [00:33<00:00,  1.10it/s]Epoch: 0/10. Loss: 1.3532:  96%|[36m█████████▌[0m| 25/26 [00:34<00:00,  1.10it/s]Epoch: 0/10. Loss: 1.3532: 100%|[36m██████████[0m| 26/26 [00:34<00:00,  1.19it/s]Epoch: 0/10. Loss: 1.3532: 100%|[36m██████████[0m| 26/26 [00:34<00:00,  1.31s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:04,  1.34it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:05,  1.12s/it] 43%|[33m████▎     [0m| 3/7 [00:02<00:03,  1.09it/s] 57%|[33m█████▋    [0m| 4/7 [00:03<00:02,  1.00it/s] 71%|[33m███████▏  [0m| 5/7 [00:04<00:01,  1.22it/s] 86%|[33m████████▌ [0m| 6/7 [00:05<00:00,  1.20it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.52it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.25it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 1/10. Loss: 1.1792:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 1/10. Loss: 1.1792:   4%|[36m▍         [0m| 1/26 [00:00<00:24,  1.01it/s]Epoch: 1/10. Loss: 1.0280:   4%|[36m▍         [0m| 1/26 [00:02<00:24,  1.01it/s]Epoch: 1/10. Loss: 1.0280:   8%|[36m▊         [0m| 2/26 [00:02<00:24,  1.04s/it]Epoch: 1/10. Loss: 1.1182:   8%|[36m▊         [0m| 2/26 [00:02<00:24,  1.04s/it]Epoch: 1/10. Loss: 1.1182:  12%|[36m█▏        [0m| 3/26 [00:02<00:21,  1.08it/s]Epoch: 1/10. Loss: 1.1063:  12%|[36m█▏        [0m| 3/26 [00:03<00:21,  1.08it/s]Epoch: 1/10. Loss: 1.1063:  15%|[36m█▌        [0m| 4/26 [00:03<00:20,  1.05it/s]Epoch: 1/10. Loss: 1.1655:  15%|[36m█▌        [0m| 4/26 [00:04<00:20,  1.05it/s]Epoch: 1/10. Loss: 1.1655:  19%|[36m█▉        [0m| 5/26 [00:04<00:19,  1.07it/s]Epoch: 1/10. Loss: 1.2477:  19%|[36m█▉        [0m| 5/26 [00:07<00:19,  1.07it/s]Epoch: 1/10. Loss: 1.2477:  23%|[36m██▎       [0m| 6/26 [00:07<00:27,  1.40s/it]Epoch: 1/10. Loss: 1.2424:  23%|[36m██▎       [0m| 6/26 [00:08<00:27,  1.40s/it]Epoch: 1/10. Loss: 1.2424:  27%|[36m██▋       [0m| 7/26 [00:08<00:28,  1.49s/it]Epoch: 1/10. Loss: 1.1271:  27%|[36m██▋       [0m| 7/26 [00:09<00:28,  1.49s/it]Epoch: 1/10. Loss: 1.1271:  31%|[36m███       [0m| 8/26 [00:09<00:23,  1.33s/it]Epoch: 1/10. Loss: 1.1673:  31%|[36m███       [0m| 8/26 [00:11<00:23,  1.33s/it]Epoch: 1/10. Loss: 1.1673:  35%|[36m███▍      [0m| 9/26 [00:11<00:23,  1.36s/it]Epoch: 1/10. Loss: 1.0943:  35%|[36m███▍      [0m| 9/26 [00:12<00:23,  1.36s/it]Epoch: 1/10. Loss: 1.0943:  38%|[36m███▊      [0m| 10/26 [00:12<00:19,  1.23s/it]Epoch: 1/10. Loss: 1.1828:  38%|[36m███▊      [0m| 10/26 [00:13<00:19,  1.23s/it]Epoch: 1/10. Loss: 1.1828:  42%|[36m████▏     [0m| 11/26 [00:13<00:17,  1.15s/it]Epoch: 1/10. Loss: 1.0101:  42%|[36m████▏     [0m| 11/26 [00:13<00:17,  1.15s/it]Epoch: 1/10. Loss: 1.0101:  46%|[36m████▌     [0m| 12/26 [00:13<00:14,  1.05s/it]Epoch: 1/10. Loss: 1.0217:  46%|[36m████▌     [0m| 12/26 [00:14<00:14,  1.05s/it]Epoch: 1/10. Loss: 1.0217:  50%|[36m█████     [0m| 13/26 [00:14<00:13,  1.02s/it]Epoch: 1/10. Loss: 1.0745:  50%|[36m█████     [0m| 13/26 [00:15<00:13,  1.02s/it]Epoch: 1/10. Loss: 1.0745:  54%|[36m█████▍    [0m| 14/26 [00:15<00:11,  1.03it/s]Epoch: 1/10. Loss: 1.0037:  54%|[36m█████▍    [0m| 14/26 [00:16<00:11,  1.03it/s]Epoch: 1/10. Loss: 1.0037:  58%|[36m█████▊    [0m| 15/26 [00:16<00:10,  1.01it/s]Epoch: 1/10. Loss: 1.0494:  58%|[36m█████▊    [0m| 15/26 [00:17<00:10,  1.01it/s]Epoch: 1/10. Loss: 1.0494:  62%|[36m██████▏   [0m| 16/26 [00:17<00:09,  1.05it/s]Epoch: 1/10. Loss: 1.0364:  62%|[36m██████▏   [0m| 16/26 [00:18<00:09,  1.05it/s]Epoch: 1/10. Loss: 1.0364:  65%|[36m██████▌   [0m| 17/26 [00:18<00:09,  1.06s/it]Epoch: 1/10. Loss: 1.0183:  65%|[36m██████▌   [0m| 17/26 [00:19<00:09,  1.06s/it]Epoch: 1/10. Loss: 1.0183:  69%|[36m██████▉   [0m| 18/26 [00:19<00:08,  1.02s/it]Epoch: 1/10. Loss: 1.0053:  69%|[36m██████▉   [0m| 18/26 [00:20<00:08,  1.02s/it]Epoch: 1/10. Loss: 1.0053:  73%|[36m███████▎  [0m| 19/26 [00:20<00:06,  1.06it/s]Epoch: 1/10. Loss: 1.0063:  73%|[36m███████▎  [0m| 19/26 [00:22<00:06,  1.06it/s]Epoch: 1/10. Loss: 1.0063:  77%|[36m███████▋  [0m| 20/26 [00:22<00:07,  1.22s/it]Epoch: 1/10. Loss: 1.0253:  77%|[36m███████▋  [0m| 20/26 [00:23<00:07,  1.22s/it]Epoch: 1/10. Loss: 1.0253:  81%|[36m████████  [0m| 21/26 [00:23<00:05,  1.09s/it]Epoch: 1/10. Loss: 1.0588:  81%|[36m████████  [0m| 21/26 [00:24<00:05,  1.09s/it]Epoch: 1/10. Loss: 1.0588:  85%|[36m████████▍ [0m| 22/26 [00:24<00:04,  1.07s/it]Epoch: 1/10. Loss: 0.9309:  85%|[36m████████▍ [0m| 22/26 [00:24<00:04,  1.07s/it]Epoch: 1/10. Loss: 0.9309:  88%|[36m████████▊ [0m| 23/26 [00:24<00:02,  1.05it/s]Epoch: 1/10. Loss: 1.0544:  88%|[36m████████▊ [0m| 23/26 [00:25<00:02,  1.05it/s]Epoch: 1/10. Loss: 1.0544:  92%|[36m█████████▏[0m| 24/26 [00:25<00:01,  1.07it/s]Epoch: 1/10. Loss: 1.0133:  92%|[36m█████████▏[0m| 24/26 [00:26<00:01,  1.07it/s]Epoch: 1/10. Loss: 1.0133:  96%|[36m█████████▌[0m| 25/26 [00:26<00:00,  1.08it/s]Epoch: 1/10. Loss: 0.9474:  96%|[36m█████████▌[0m| 25/26 [00:27<00:00,  1.08it/s]Epoch: 1/10. Loss: 0.9474: 100%|[36m██████████[0m| 26/26 [00:27<00:00,  1.22it/s]Epoch: 1/10. Loss: 0.9474: 100%|[36m██████████[0m| 26/26 [00:27<00:00,  1.05s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:05,  1.17it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:05,  1.14s/it] 43%|[33m████▎     [0m| 3/7 [00:02<00:03,  1.07it/s] 57%|[33m█████▋    [0m| 4/7 [00:04<00:03,  1.06s/it] 71%|[33m███████▏  [0m| 5/7 [00:04<00:01,  1.16it/s] 86%|[33m████████▌ [0m| 6/7 [00:05<00:00,  1.05it/s]100%|[33m██████████[0m| 7/7 [00:06<00:00,  1.35it/s]100%|[33m██████████[0m| 7/7 [00:06<00:00,  1.15it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 2/10. Loss: 0.9732:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 2/10. Loss: 0.9732:   4%|[36m▍         [0m| 1/26 [00:00<00:21,  1.14it/s]Epoch: 2/10. Loss: 1.0017:   4%|[36m▍         [0m| 1/26 [00:03<00:21,  1.14it/s]Epoch: 2/10. Loss: 1.0017:   8%|[36m▊         [0m| 2/26 [00:03<00:47,  1.99s/it]Epoch: 2/10. Loss: 1.0180:   8%|[36m▊         [0m| 2/26 [00:04<00:47,  1.99s/it]Epoch: 2/10. Loss: 1.0180:  12%|[36m█▏        [0m| 3/26 [00:04<00:34,  1.52s/it]Epoch: 2/10. Loss: 1.0181:  12%|[36m█▏        [0m| 3/26 [00:05<00:34,  1.52s/it]Epoch: 2/10. Loss: 1.0181:  15%|[36m█▌        [0m| 4/26 [00:05<00:28,  1.30s/it]Epoch: 2/10. Loss: 0.9128:  15%|[36m█▌        [0m| 4/26 [00:07<00:28,  1.30s/it]Epoch: 2/10. Loss: 0.9128:  19%|[36m█▉        [0m| 5/26 [00:07<00:35,  1.68s/it]Epoch: 2/10. Loss: 0.9614:  19%|[36m█▉        [0m| 5/26 [00:09<00:35,  1.68s/it]Epoch: 2/10. Loss: 0.9614:  23%|[36m██▎       [0m| 6/26 [00:09<00:30,  1.51s/it]Epoch: 2/10. Loss: 1.0400:  23%|[36m██▎       [0m| 6/26 [00:10<00:30,  1.51s/it]Epoch: 2/10. Loss: 1.0400:  27%|[36m██▋       [0m| 7/26 [00:10<00:25,  1.34s/it]Epoch: 2/10. Loss: 1.0618:  27%|[36m██▋       [0m| 7/26 [00:10<00:25,  1.34s/it]Epoch: 2/10. Loss: 1.0618:  31%|[36m███       [0m| 8/26 [00:10<00:21,  1.19s/it]Epoch: 2/10. Loss: 0.9971:  31%|[36m███       [0m| 8/26 [00:12<00:21,  1.19s/it]Epoch: 2/10. Loss: 0.9971:  35%|[36m███▍      [0m| 9/26 [00:12<00:20,  1.22s/it]Epoch: 2/10. Loss: 0.9957:  35%|[36m███▍      [0m| 9/26 [00:14<00:20,  1.22s/it]Epoch: 2/10. Loss: 0.9957:  38%|[36m███▊      [0m| 10/26 [00:14<00:24,  1.52s/it]Epoch: 2/10. Loss: 1.0887:  38%|[36m███▊      [0m| 10/26 [00:15<00:24,  1.52s/it]Epoch: 2/10. Loss: 1.0887:  42%|[36m████▏     [0m| 11/26 [00:15<00:20,  1.36s/it]Epoch: 2/10. Loss: 1.0068:  42%|[36m████▏     [0m| 11/26 [00:16<00:20,  1.36s/it]Epoch: 2/10. Loss: 1.0068:  46%|[36m████▌     [0m| 12/26 [00:16<00:16,  1.21s/it]Epoch: 2/10. Loss: 1.0403:  46%|[36m████▌     [0m| 12/26 [00:17<00:16,  1.21s/it]Epoch: 2/10. Loss: 1.0403:  50%|[36m█████     [0m| 13/26 [00:17<00:14,  1.09s/it]Epoch: 2/10. Loss: 1.0203:  50%|[36m█████     [0m| 13/26 [00:18<00:14,  1.09s/it]Epoch: 2/10. Loss: 1.0203:  54%|[36m█████▍    [0m| 14/26 [00:18<00:12,  1.07s/it]Epoch: 2/10. Loss: 0.9855:  54%|[36m█████▍    [0m| 14/26 [00:19<00:12,  1.07s/it]Epoch: 2/10. Loss: 0.9855:  58%|[36m█████▊    [0m| 15/26 [00:19<00:13,  1.24s/it]Epoch: 2/10. Loss: 0.9715:  58%|[36m█████▊    [0m| 15/26 [00:20<00:13,  1.24s/it]Epoch: 2/10. Loss: 0.9715:  62%|[36m██████▏   [0m| 16/26 [00:20<00:11,  1.16s/it]Epoch: 2/10. Loss: 0.9546:  62%|[36m██████▏   [0m| 16/26 [00:21<00:11,  1.16s/it]Epoch: 2/10. Loss: 0.9546:  65%|[36m██████▌   [0m| 17/26 [00:21<00:09,  1.10s/it]Epoch: 2/10. Loss: 0.9810:  65%|[36m██████▌   [0m| 17/26 [00:22<00:09,  1.10s/it]Epoch: 2/10. Loss: 0.9810:  69%|[36m██████▉   [0m| 18/26 [00:22<00:08,  1.08s/it]Epoch: 2/10. Loss: 0.9342:  69%|[36m██████▉   [0m| 18/26 [00:23<00:08,  1.08s/it]Epoch: 2/10. Loss: 0.9342:  73%|[36m███████▎  [0m| 19/26 [00:23<00:07,  1.03s/it]Epoch: 2/10. Loss: 1.0466:  73%|[36m███████▎  [0m| 19/26 [00:24<00:07,  1.03s/it]Epoch: 2/10. Loss: 1.0466:  77%|[36m███████▋  [0m| 20/26 [00:24<00:05,  1.03it/s]Epoch: 2/10. Loss: 1.0769:  77%|[36m███████▋  [0m| 20/26 [00:25<00:05,  1.03it/s]Epoch: 2/10. Loss: 1.0769:  81%|[36m████████  [0m| 21/26 [00:25<00:04,  1.05it/s]Epoch: 2/10. Loss: 0.9847:  81%|[36m████████  [0m| 21/26 [00:26<00:04,  1.05it/s]Epoch: 2/10. Loss: 0.9847:  85%|[36m████████▍ [0m| 22/26 [00:26<00:04,  1.08s/it]Epoch: 2/10. Loss: 0.9797:  85%|[36m████████▍ [0m| 22/26 [00:27<00:04,  1.08s/it]Epoch: 2/10. Loss: 0.9797:  88%|[36m████████▊ [0m| 23/26 [00:27<00:03,  1.03s/it]Epoch: 2/10. Loss: 1.0714:  88%|[36m████████▊ [0m| 23/26 [00:28<00:03,  1.03s/it]Epoch: 2/10. Loss: 1.0714:  92%|[36m█████████▏[0m| 24/26 [00:28<00:01,  1.00it/s]Epoch: 2/10. Loss: 0.9754:  92%|[36m█████████▏[0m| 24/26 [00:30<00:01,  1.00it/s]Epoch: 2/10. Loss: 0.9754:  96%|[36m█████████▌[0m| 25/26 [00:30<00:01,  1.24s/it]Epoch: 2/10. Loss: 1.1203:  96%|[36m█████████▌[0m| 25/26 [00:31<00:01,  1.24s/it]Epoch: 2/10. Loss: 1.1203: 100%|[36m██████████[0m| 26/26 [00:31<00:00,  1.09s/it]Epoch: 2/10. Loss: 1.1203: 100%|[36m██████████[0m| 26/26 [00:31<00:00,  1.20s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:05,  1.01it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:06,  1.23s/it] 43%|[33m████▎     [0m| 3/7 [00:03<00:04,  1.05s/it] 57%|[33m█████▋    [0m| 4/7 [00:04<00:03,  1.09s/it] 71%|[33m███████▏  [0m| 5/7 [00:04<00:01,  1.12it/s] 86%|[33m████████▌ [0m| 6/7 [00:05<00:00,  1.12it/s]100%|[33m██████████[0m| 7/7 [00:06<00:00,  1.42it/s]100%|[33m██████████[0m| 7/7 [00:06<00:00,  1.14it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 3/10. Loss: 0.9702:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 3/10. Loss: 0.9702:   4%|[36m▍         [0m| 1/26 [00:00<00:22,  1.13it/s]Epoch: 3/10. Loss: 0.9337:   4%|[36m▍         [0m| 1/26 [00:01<00:22,  1.13it/s]Epoch: 3/10. Loss: 0.9337:   8%|[36m▊         [0m| 2/26 [00:01<00:20,  1.20it/s]Epoch: 3/10. Loss: 1.0231:   8%|[36m▊         [0m| 2/26 [00:02<00:20,  1.20it/s]Epoch: 3/10. Loss: 1.0231:  12%|[36m█▏        [0m| 3/26 [00:02<00:20,  1.14it/s]Epoch: 3/10. Loss: 1.1133:  12%|[36m█▏        [0m| 3/26 [00:03<00:20,  1.14it/s]Epoch: 3/10. Loss: 1.1133:  15%|[36m█▌        [0m| 4/26 [00:03<00:19,  1.14it/s]Epoch: 3/10. Loss: 1.0130:  15%|[36m█▌        [0m| 4/26 [00:04<00:19,  1.14it/s]Epoch: 3/10. Loss: 1.0130:  19%|[36m█▉        [0m| 5/26 [00:04<00:19,  1.08it/s]Epoch: 3/10. Loss: 0.9862:  19%|[36m█▉        [0m| 5/26 [00:05<00:19,  1.08it/s]Epoch: 3/10. Loss: 0.9862:  23%|[36m██▎       [0m| 6/26 [00:05<00:19,  1.01it/s]Epoch: 3/10. Loss: 1.0822:  23%|[36m██▎       [0m| 6/26 [00:07<00:19,  1.01it/s]Epoch: 3/10. Loss: 1.0822:  27%|[36m██▋       [0m| 7/26 [00:07<00:22,  1.19s/it]Epoch: 3/10. Loss: 1.0887:  27%|[36m██▋       [0m| 7/26 [00:08<00:22,  1.19s/it]Epoch: 3/10. Loss: 1.0887:  31%|[36m███       [0m| 8/26 [00:08<00:20,  1.13s/it]Epoch: 3/10. Loss: 1.0546:  31%|[36m███       [0m| 8/26 [00:09<00:20,  1.13s/it]Epoch: 3/10. Loss: 1.0546:  35%|[36m███▍      [0m| 9/26 [00:09<00:18,  1.06s/it]Epoch: 3/10. Loss: 1.0434:  35%|[36m███▍      [0m| 9/26 [00:10<00:18,  1.06s/it]Epoch: 3/10. Loss: 1.0434:  38%|[36m███▊      [0m| 10/26 [00:10<00:16,  1.05s/it]Epoch: 3/10. Loss: 1.0154:  38%|[36m███▊      [0m| 10/26 [00:11<00:16,  1.05s/it]Epoch: 3/10. Loss: 1.0154:  42%|[36m████▏     [0m| 11/26 [00:11<00:16,  1.09s/it]Epoch: 3/10. Loss: 1.0351:  42%|[36m████▏     [0m| 11/26 [00:12<00:16,  1.09s/it]Epoch: 3/10. Loss: 1.0351:  46%|[36m████▌     [0m| 12/26 [00:12<00:14,  1.03s/it]Epoch: 3/10. Loss: 0.9439:  46%|[36m████▌     [0m| 12/26 [00:13<00:14,  1.03s/it]Epoch: 3/10. Loss: 0.9439:  50%|[36m█████     [0m| 13/26 [00:13<00:12,  1.03it/s]Epoch: 3/10. Loss: 0.9905:  50%|[36m█████     [0m| 13/26 [00:14<00:12,  1.03it/s]Epoch: 3/10. Loss: 0.9905:  54%|[36m█████▍    [0m| 14/26 [00:14<00:12,  1.02s/it]Epoch: 3/10. Loss: 0.9928:  54%|[36m█████▍    [0m| 14/26 [00:15<00:12,  1.02s/it]Epoch: 3/10. Loss: 0.9928:  58%|[36m█████▊    [0m| 15/26 [00:15<00:11,  1.06s/it]Epoch: 3/10. Loss: 1.0571:  58%|[36m█████▊    [0m| 15/26 [00:16<00:11,  1.06s/it]Epoch: 3/10. Loss: 1.0571:  62%|[36m██████▏   [0m| 16/26 [00:16<00:10,  1.04s/it]Epoch: 3/10. Loss: 1.0786:  62%|[36m██████▏   [0m| 16/26 [00:17<00:10,  1.04s/it]Epoch: 3/10. Loss: 1.0786:  65%|[36m██████▌   [0m| 17/26 [00:17<00:09,  1.02s/it]Epoch: 3/10. Loss: 1.0176:  65%|[36m██████▌   [0m| 17/26 [00:18<00:09,  1.02s/it]Epoch: 3/10. Loss: 1.0176:  69%|[36m██████▉   [0m| 18/26 [00:18<00:07,  1.01it/s]Epoch: 3/10. Loss: 1.0134:  69%|[36m██████▉   [0m| 18/26 [00:19<00:07,  1.01it/s]Epoch: 3/10. Loss: 1.0134:  73%|[36m███████▎  [0m| 19/26 [00:19<00:06,  1.07it/s]Epoch: 3/10. Loss: 1.0557:  73%|[36m███████▎  [0m| 19/26 [00:19<00:06,  1.07it/s]Epoch: 3/10. Loss: 1.0557:  77%|[36m███████▋  [0m| 20/26 [00:19<00:05,  1.12it/s]Epoch: 3/10. Loss: 0.9233:  77%|[36m███████▋  [0m| 20/26 [00:20<00:05,  1.12it/s]Epoch: 3/10. Loss: 0.9233:  81%|[36m████████  [0m| 21/26 [00:20<00:04,  1.14it/s]Epoch: 3/10. Loss: 0.9769:  81%|[36m████████  [0m| 21/26 [00:21<00:04,  1.14it/s]Epoch: 3/10. Loss: 0.9769:  85%|[36m████████▍ [0m| 22/26 [00:21<00:03,  1.14it/s]Epoch: 3/10. Loss: 1.0379:  85%|[36m████████▍ [0m| 22/26 [00:22<00:03,  1.14it/s]Epoch: 3/10. Loss: 1.0379:  88%|[36m████████▊ [0m| 23/26 [00:22<00:02,  1.17it/s]Epoch: 3/10. Loss: 1.0017:  88%|[36m████████▊ [0m| 23/26 [00:23<00:02,  1.17it/s]Epoch: 3/10. Loss: 1.0017:  92%|[36m█████████▏[0m| 24/26 [00:23<00:01,  1.15it/s]Epoch: 3/10. Loss: 0.9158:  92%|[36m█████████▏[0m| 24/26 [00:24<00:01,  1.15it/s]Epoch: 3/10. Loss: 0.9158:  96%|[36m█████████▌[0m| 25/26 [00:24<00:00,  1.14it/s]Epoch: 3/10. Loss: 1.0457:  96%|[36m█████████▌[0m| 25/26 [00:24<00:00,  1.14it/s]Epoch: 3/10. Loss: 1.0457: 100%|[36m██████████[0m| 26/26 [00:24<00:00,  1.18it/s]Epoch: 3/10. Loss: 1.0457: 100%|[36m██████████[0m| 26/26 [00:24<00:00,  1.04it/s]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:04,  1.25it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:05,  1.12s/it] 43%|[33m████▎     [0m| 3/7 [00:02<00:03,  1.07it/s] 57%|[33m█████▋    [0m| 4/7 [00:04<00:03,  1.17s/it] 71%|[33m███████▏  [0m| 5/7 [00:04<00:01,  1.06it/s] 86%|[33m████████▌ [0m| 6/7 [00:05<00:00,  1.08it/s]100%|[33m██████████[0m| 7/7 [00:06<00:00,  1.38it/s]100%|[33m██████████[0m| 7/7 [00:06<00:00,  1.14it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 4/10. Loss: 0.9819:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 4/10. Loss: 0.9819:   4%|[36m▍         [0m| 1/26 [00:00<00:24,  1.03it/s]Epoch: 4/10. Loss: 0.9691:   4%|[36m▍         [0m| 1/26 [00:01<00:24,  1.03it/s]Epoch: 4/10. Loss: 0.9691:   8%|[36m▊         [0m| 2/26 [00:01<00:21,  1.12it/s]Epoch: 4/10. Loss: 1.0048:   8%|[36m▊         [0m| 2/26 [00:02<00:21,  1.12it/s]Epoch: 4/10. Loss: 1.0048:  12%|[36m█▏        [0m| 3/26 [00:02<00:20,  1.13it/s]Epoch: 4/10. Loss: 0.9618:  12%|[36m█▏        [0m| 3/26 [00:03<00:20,  1.13it/s]Epoch: 4/10. Loss: 0.9618:  15%|[36m█▌        [0m| 4/26 [00:03<00:23,  1.05s/it]Epoch: 4/10. Loss: 0.9149:  15%|[36m█▌        [0m| 4/26 [00:04<00:23,  1.05s/it]Epoch: 4/10. Loss: 0.9149:  19%|[36m█▉        [0m| 5/26 [00:04<00:21,  1.00s/it]Epoch: 4/10. Loss: 1.0343:  19%|[36m█▉        [0m| 5/26 [00:05<00:21,  1.00s/it]Epoch: 4/10. Loss: 1.0343:  23%|[36m██▎       [0m| 6/26 [00:05<00:20,  1.03s/it]Epoch: 4/10. Loss: 1.0134:  23%|[36m██▎       [0m| 6/26 [00:07<00:20,  1.03s/it]Epoch: 4/10. Loss: 1.0134:  27%|[36m██▋       [0m| 7/26 [00:07<00:23,  1.23s/it]Epoch: 4/10. Loss: 1.0653:  27%|[36m██▋       [0m| 7/26 [00:08<00:23,  1.23s/it]Epoch: 4/10. Loss: 1.0653:  31%|[36m███       [0m| 8/26 [00:08<00:20,  1.14s/it]Epoch: 4/10. Loss: 0.9135:  31%|[36m███       [0m| 8/26 [00:09<00:20,  1.14s/it]Epoch: 4/10. Loss: 0.9135:  35%|[36m███▍      [0m| 9/26 [00:09<00:17,  1.04s/it]Epoch: 4/10. Loss: 0.9568:  35%|[36m███▍      [0m| 9/26 [00:10<00:17,  1.04s/it]Epoch: 4/10. Loss: 0.9568:  38%|[36m███▊      [0m| 10/26 [00:10<00:16,  1.01s/it]Epoch: 4/10. Loss: 0.9514:  38%|[36m███▊      [0m| 10/26 [00:11<00:16,  1.01s/it]Epoch: 4/10. Loss: 0.9514:  42%|[36m████▏     [0m| 11/26 [00:11<00:14,  1.05it/s]Epoch: 4/10. Loss: 0.9632:  42%|[36m████▏     [0m| 11/26 [00:12<00:14,  1.05it/s]Epoch: 4/10. Loss: 0.9632:  46%|[36m████▌     [0m| 12/26 [00:12<00:13,  1.00it/s]Epoch: 4/10. Loss: 0.9056:  46%|[36m████▌     [0m| 12/26 [00:13<00:13,  1.00it/s]Epoch: 4/10. Loss: 0.9056:  50%|[36m█████     [0m| 13/26 [00:13<00:12,  1.02it/s]Epoch: 4/10. Loss: 0.9337:  50%|[36m█████     [0m| 13/26 [00:14<00:12,  1.02it/s]Epoch: 4/10. Loss: 0.9337:  54%|[36m█████▍    [0m| 14/26 [00:14<00:11,  1.04it/s]Epoch: 4/10. Loss: 0.9707:  54%|[36m█████▍    [0m| 14/26 [00:15<00:11,  1.04it/s]Epoch: 4/10. Loss: 0.9707:  58%|[36m█████▊    [0m| 15/26 [00:15<00:11,  1.02s/it]Epoch: 4/10. Loss: 0.9960:  58%|[36m█████▊    [0m| 15/26 [00:16<00:11,  1.02s/it]Epoch: 4/10. Loss: 0.9960:  62%|[36m██████▏   [0m| 16/26 [00:16<00:10,  1.04s/it]Epoch: 4/10. Loss: 1.0323:  62%|[36m██████▏   [0m| 16/26 [00:17<00:10,  1.04s/it]Epoch: 4/10. Loss: 1.0323:  65%|[36m██████▌   [0m| 17/26 [00:17<00:09,  1.02s/it]Epoch: 4/10. Loss: 1.0350:  65%|[36m██████▌   [0m| 17/26 [00:18<00:09,  1.02s/it]Epoch: 4/10. Loss: 1.0350:  69%|[36m██████▉   [0m| 18/26 [00:18<00:07,  1.00it/s]Epoch: 4/10. Loss: 1.0264:  69%|[36m██████▉   [0m| 18/26 [00:19<00:07,  1.00it/s]Epoch: 4/10. Loss: 1.0264:  73%|[36m███████▎  [0m| 19/26 [00:19<00:07,  1.01s/it]Epoch: 4/10. Loss: 0.9495:  73%|[36m███████▎  [0m| 19/26 [00:20<00:07,  1.01s/it]Epoch: 4/10. Loss: 0.9495:  77%|[36m███████▋  [0m| 20/26 [00:20<00:05,  1.01it/s]Epoch: 4/10. Loss: 0.9179:  77%|[36m███████▋  [0m| 20/26 [00:21<00:05,  1.01it/s]Epoch: 4/10. Loss: 0.9179:  81%|[36m████████  [0m| 21/26 [00:21<00:04,  1.04it/s]Epoch: 4/10. Loss: 0.9570:  81%|[36m████████  [0m| 21/26 [00:22<00:04,  1.04it/s]Epoch: 4/10. Loss: 0.9570:  85%|[36m████████▍ [0m| 22/26 [00:22<00:03,  1.06it/s]Epoch: 4/10. Loss: 0.9836:  85%|[36m████████▍ [0m| 22/26 [00:22<00:03,  1.06it/s]Epoch: 4/10. Loss: 0.9836:  88%|[36m████████▊ [0m| 23/26 [00:22<00:02,  1.13it/s]Epoch: 4/10. Loss: 0.9804:  88%|[36m████████▊ [0m| 23/26 [00:23<00:02,  1.13it/s]Epoch: 4/10. Loss: 0.9804:  92%|[36m█████████▏[0m| 24/26 [00:23<00:01,  1.13it/s]Epoch: 4/10. Loss: 0.9436:  92%|[36m█████████▏[0m| 24/26 [00:24<00:01,  1.13it/s]Epoch: 4/10. Loss: 0.9436:  96%|[36m█████████▌[0m| 25/26 [00:24<00:00,  1.14it/s]Epoch: 4/10. Loss: 1.0098:  96%|[36m█████████▌[0m| 25/26 [00:25<00:00,  1.14it/s]Epoch: 4/10. Loss: 1.0098: 100%|[36m██████████[0m| 26/26 [00:25<00:00,  1.24it/s]Epoch: 4/10. Loss: 1.0098: 100%|[36m██████████[0m| 26/26 [00:25<00:00,  1.03it/s]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:04,  1.27it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:05,  1.12s/it] 43%|[33m████▎     [0m| 3/7 [00:02<00:03,  1.08it/s] 57%|[33m█████▋    [0m| 4/7 [00:04<00:03,  1.09s/it] 71%|[33m███████▏  [0m| 5/7 [00:04<00:01,  1.12it/s] 86%|[33m████████▌ [0m| 6/7 [00:08<00:01,  1.77s/it]100%|[33m██████████[0m| 7/7 [00:08<00:00,  1.30s/it]100%|[33m██████████[0m| 7/7 [00:08<00:00,  1.22s/it]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 5/10. Loss: 0.9570:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 5/10. Loss: 0.9570:   4%|[36m▍         [0m| 1/26 [00:00<00:24,  1.03it/s]Epoch: 5/10. Loss: 0.9406:   4%|[36m▍         [0m| 1/26 [00:01<00:24,  1.03it/s]Epoch: 5/10. Loss: 0.9406:   8%|[36m▊         [0m| 2/26 [00:01<00:23,  1.01it/s]Epoch: 5/10. Loss: 0.8795:   8%|[36m▊         [0m| 2/26 [00:02<00:23,  1.01it/s]Epoch: 5/10. Loss: 0.8795:  12%|[36m█▏        [0m| 3/26 [00:02<00:21,  1.08it/s]Epoch: 5/10. Loss: 0.8964:  12%|[36m█▏        [0m| 3/26 [00:03<00:21,  1.08it/s]Epoch: 5/10. Loss: 0.8964:  15%|[36m█▌        [0m| 4/26 [00:03<00:22,  1.01s/it]Epoch: 5/10. Loss: 0.9310:  15%|[36m█▌        [0m| 4/26 [00:04<00:22,  1.01s/it]Epoch: 5/10. Loss: 0.9310:  19%|[36m█▉        [0m| 5/26 [00:04<00:19,  1.10it/s]Epoch: 5/10. Loss: 1.0457:  19%|[36m█▉        [0m| 5/26 [00:05<00:19,  1.10it/s]Epoch: 5/10. Loss: 1.0457:  23%|[36m██▎       [0m| 6/26 [00:05<00:17,  1.14it/s]Epoch: 5/10. Loss: 1.0357:  23%|[36m██▎       [0m| 6/26 [00:06<00:17,  1.14it/s]Epoch: 5/10. Loss: 1.0357:  27%|[36m██▋       [0m| 7/26 [00:06<00:20,  1.06s/it]Epoch: 5/10. Loss: 0.9199:  27%|[36m██▋       [0m| 7/26 [00:07<00:20,  1.06s/it]Epoch: 5/10. Loss: 0.9199:  31%|[36m███       [0m| 8/26 [00:07<00:17,  1.05it/s]Epoch: 5/10. Loss: 0.9159:  31%|[36m███       [0m| 8/26 [00:08<00:17,  1.05it/s]Epoch: 5/10. Loss: 0.9159:  35%|[36m███▍      [0m| 9/26 [00:08<00:16,  1.05it/s]Epoch: 5/10. Loss: 0.9281:  35%|[36m███▍      [0m| 9/26 [00:09<00:16,  1.05it/s]Epoch: 5/10. Loss: 0.9281:  38%|[36m███▊      [0m| 10/26 [00:09<00:15,  1.05it/s]Epoch: 5/10. Loss: 0.9653:  38%|[36m███▊      [0m| 10/26 [00:10<00:15,  1.05it/s]Epoch: 5/10. Loss: 0.9653:  42%|[36m████▏     [0m| 11/26 [00:10<00:13,  1.07it/s]Epoch: 5/10. Loss: 1.0508:  42%|[36m████▏     [0m| 11/26 [00:11<00:13,  1.07it/s]Epoch: 5/10. Loss: 1.0508:  46%|[36m████▌     [0m| 12/26 [00:11<00:13,  1.05it/s]Epoch: 5/10. Loss: 0.9171:  46%|[36m████▌     [0m| 12/26 [00:12<00:13,  1.05it/s]Epoch: 5/10. Loss: 0.9171:  50%|[36m█████     [0m| 13/26 [00:12<00:11,  1.09it/s]Epoch: 5/10. Loss: 0.9511:  50%|[36m█████     [0m| 13/26 [00:13<00:11,  1.09it/s]Epoch: 5/10. Loss: 0.9511:  54%|[36m█████▍    [0m| 14/26 [00:13<00:11,  1.04it/s]Epoch: 5/10. Loss: 1.0275:  54%|[36m█████▍    [0m| 14/26 [00:14<00:11,  1.04it/s]Epoch: 5/10. Loss: 1.0275:  58%|[36m█████▊    [0m| 15/26 [00:14<00:11,  1.00s/it]Epoch: 5/10. Loss: 0.9793:  58%|[36m█████▊    [0m| 15/26 [00:15<00:11,  1.00s/it]Epoch: 5/10. Loss: 0.9793:  62%|[36m██████▏   [0m| 16/26 [00:15<00:09,  1.01it/s]Epoch: 5/10. Loss: 0.9624:  62%|[36m██████▏   [0m| 16/26 [00:16<00:09,  1.01it/s]Epoch: 5/10. Loss: 0.9624:  65%|[36m██████▌   [0m| 17/26 [00:16<00:08,  1.04it/s]Epoch: 5/10. Loss: 0.8464:  65%|[36m██████▌   [0m| 17/26 [00:17<00:08,  1.04it/s]Epoch: 5/10. Loss: 0.8464:  69%|[36m██████▉   [0m| 18/26 [00:17<00:07,  1.04it/s]Epoch: 5/10. Loss: 0.9309:  69%|[36m██████▉   [0m| 18/26 [00:18<00:07,  1.04it/s]Epoch: 5/10. Loss: 0.9309:  73%|[36m███████▎  [0m| 19/26 [00:18<00:07,  1.00s/it]Epoch: 5/10. Loss: 0.9674:  73%|[36m███████▎  [0m| 19/26 [00:19<00:07,  1.00s/it]Epoch: 5/10. Loss: 0.9674:  77%|[36m███████▋  [0m| 20/26 [00:19<00:05,  1.08it/s]Epoch: 5/10. Loss: 0.9409:  77%|[36m███████▋  [0m| 20/26 [00:19<00:05,  1.08it/s]Epoch: 5/10. Loss: 0.9409:  81%|[36m████████  [0m| 21/26 [00:19<00:04,  1.11it/s]Epoch: 5/10. Loss: 1.0381:  81%|[36m████████  [0m| 21/26 [00:20<00:04,  1.11it/s]Epoch: 5/10. Loss: 1.0381:  85%|[36m████████▍ [0m| 22/26 [00:20<00:03,  1.11it/s]Epoch: 5/10. Loss: 0.9907:  85%|[36m████████▍ [0m| 22/26 [00:21<00:03,  1.11it/s]Epoch: 5/10. Loss: 0.9907:  88%|[36m████████▊ [0m| 23/26 [00:21<00:02,  1.14it/s]Epoch: 5/10. Loss: 0.9504:  88%|[36m████████▊ [0m| 23/26 [00:22<00:02,  1.14it/s]Epoch: 5/10. Loss: 0.9504:  92%|[36m█████████▏[0m| 24/26 [00:22<00:01,  1.16it/s]Epoch: 5/10. Loss: 0.9814:  92%|[36m█████████▏[0m| 24/26 [00:23<00:01,  1.16it/s]Epoch: 5/10. Loss: 0.9814:  96%|[36m█████████▌[0m| 25/26 [00:23<00:00,  1.13it/s]Epoch: 5/10. Loss: 0.9866:  96%|[36m█████████▌[0m| 25/26 [00:24<00:00,  1.13it/s]Epoch: 5/10. Loss: 0.9866: 100%|[36m██████████[0m| 26/26 [00:24<00:00,  1.26it/s]Epoch: 5/10. Loss: 0.9866: 100%|[36m██████████[0m| 26/26 [00:24<00:00,  1.08it/s]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:05,  1.17it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:05,  1.16s/it] 43%|[33m████▎     [0m| 3/7 [00:02<00:03,  1.04it/s] 57%|[33m█████▋    [0m| 4/7 [00:04<00:03,  1.06s/it] 71%|[33m███████▏  [0m| 5/7 [00:05<00:02,  1.26s/it] 86%|[33m████████▌ [0m| 6/7 [00:06<00:01,  1.14s/it]100%|[33m██████████[0m| 7/7 [00:07<00:00,  1.14it/s]100%|[33m██████████[0m| 7/7 [00:07<00:00,  1.00s/it]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 6/10. Loss: 0.9828:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 6/10. Loss: 0.9828:   4%|[36m▍         [0m| 1/26 [00:00<00:19,  1.26it/s]Epoch: 6/10. Loss: 1.0125:   4%|[36m▍         [0m| 1/26 [00:01<00:19,  1.26it/s]Epoch: 6/10. Loss: 1.0125:   8%|[36m▊         [0m| 2/26 [00:01<00:19,  1.23it/s]Epoch: 6/10. Loss: 0.9126:   8%|[36m▊         [0m| 2/26 [00:02<00:19,  1.23it/s]Epoch: 6/10. Loss: 0.9126:  12%|[36m█▏        [0m| 3/26 [00:02<00:22,  1.02it/s]Epoch: 6/10. Loss: 0.9227:  12%|[36m█▏        [0m| 3/26 [00:03<00:22,  1.02it/s]Epoch: 6/10. Loss: 0.9227:  15%|[36m█▌        [0m| 4/26 [00:03<00:21,  1.02it/s]Epoch: 6/10. Loss: 0.9634:  15%|[36m█▌        [0m| 4/26 [00:04<00:21,  1.02it/s]Epoch: 6/10. Loss: 0.9634:  19%|[36m█▉        [0m| 5/26 [00:04<00:19,  1.07it/s]Epoch: 6/10. Loss: 0.9581:  19%|[36m█▉        [0m| 5/26 [00:05<00:19,  1.07it/s]Epoch: 6/10. Loss: 0.9581:  23%|[36m██▎       [0m| 6/26 [00:05<00:17,  1.12it/s]Epoch: 6/10. Loss: 0.8668:  23%|[36m██▎       [0m| 6/26 [00:06<00:17,  1.12it/s]Epoch: 6/10. Loss: 0.8668:  27%|[36m██▋       [0m| 7/26 [00:06<00:16,  1.12it/s]Epoch: 6/10. Loss: 0.9700:  27%|[36m██▋       [0m| 7/26 [00:07<00:16,  1.12it/s]Epoch: 6/10. Loss: 0.9700:  31%|[36m███       [0m| 8/26 [00:07<00:15,  1.14it/s]Epoch: 6/10. Loss: 0.9761:  31%|[36m███       [0m| 8/26 [00:08<00:15,  1.14it/s]Epoch: 6/10. Loss: 0.9761:  35%|[36m███▍      [0m| 9/26 [00:08<00:15,  1.12it/s]Epoch: 6/10. Loss: 0.9371:  35%|[36m███▍      [0m| 9/26 [00:08<00:15,  1.12it/s]Epoch: 6/10. Loss: 0.9371:  38%|[36m███▊      [0m| 10/26 [00:08<00:14,  1.12it/s]Epoch: 6/10. Loss: 0.9122:  38%|[36m███▊      [0m| 10/26 [00:09<00:14,  1.12it/s]Epoch: 6/10. Loss: 0.9122:  42%|[36m████▏     [0m| 11/26 [00:09<00:13,  1.14it/s]Epoch: 6/10. Loss: 0.8788:  42%|[36m████▏     [0m| 11/26 [00:10<00:13,  1.14it/s]Epoch: 6/10. Loss: 0.8788:  46%|[36m████▌     [0m| 12/26 [00:10<00:12,  1.09it/s]Epoch: 6/10. Loss: 0.9397:  46%|[36m████▌     [0m| 12/26 [00:11<00:12,  1.09it/s]Epoch: 6/10. Loss: 0.9397:  50%|[36m█████     [0m| 13/26 [00:11<00:11,  1.09it/s]Epoch: 6/10. Loss: 0.8743:  50%|[36m█████     [0m| 13/26 [00:12<00:11,  1.09it/s]Epoch: 6/10. Loss: 0.8743:  54%|[36m█████▍    [0m| 14/26 [00:12<00:11,  1.05it/s]Epoch: 6/10. Loss: 1.0015:  54%|[36m█████▍    [0m| 14/26 [00:13<00:11,  1.05it/s]Epoch: 6/10. Loss: 1.0015:  58%|[36m█████▊    [0m| 15/26 [00:13<00:10,  1.01it/s]Epoch: 6/10. Loss: 1.0532:  58%|[36m█████▊    [0m| 15/26 [00:14<00:10,  1.01it/s]Epoch: 6/10. Loss: 1.0532:  62%|[36m██████▏   [0m| 16/26 [00:14<00:09,  1.02it/s]Epoch: 6/10. Loss: 0.8530:  62%|[36m██████▏   [0m| 16/26 [00:15<00:09,  1.02it/s]Epoch: 6/10. Loss: 0.8530:  65%|[36m██████▌   [0m| 17/26 [00:15<00:09,  1.00s/it]Epoch: 6/10. Loss: 0.9235:  65%|[36m██████▌   [0m| 17/26 [00:16<00:09,  1.00s/it]Epoch: 6/10. Loss: 0.9235:  69%|[36m██████▉   [0m| 18/26 [00:16<00:08,  1.01s/it]Epoch: 6/10. Loss: 0.9535:  69%|[36m██████▉   [0m| 18/26 [00:17<00:08,  1.01s/it]Epoch: 6/10. Loss: 0.9535:  73%|[36m███████▎  [0m| 19/26 [00:17<00:06,  1.03it/s]Epoch: 6/10. Loss: 0.9180:  73%|[36m███████▎  [0m| 19/26 [00:18<00:06,  1.03it/s]Epoch: 6/10. Loss: 0.9180:  77%|[36m███████▋  [0m| 20/26 [00:18<00:05,  1.06it/s]Epoch: 6/10. Loss: 0.9476:  77%|[36m███████▋  [0m| 20/26 [00:19<00:05,  1.06it/s]Epoch: 6/10. Loss: 0.9476:  81%|[36m████████  [0m| 21/26 [00:19<00:04,  1.01it/s]Epoch: 6/10. Loss: 0.9552:  81%|[36m████████  [0m| 21/26 [00:20<00:04,  1.01it/s]Epoch: 6/10. Loss: 0.9552:  85%|[36m████████▍ [0m| 22/26 [00:20<00:03,  1.05it/s]Epoch: 6/10. Loss: 0.9285:  85%|[36m████████▍ [0m| 22/26 [00:21<00:03,  1.05it/s]Epoch: 6/10. Loss: 0.9285:  88%|[36m████████▊ [0m| 23/26 [00:21<00:02,  1.01it/s]Epoch: 6/10. Loss: 0.9452:  88%|[36m████████▊ [0m| 23/26 [00:22<00:02,  1.01it/s]Epoch: 6/10. Loss: 0.9452:  92%|[36m█████████▏[0m| 24/26 [00:22<00:01,  1.01it/s]Epoch: 6/10. Loss: 0.9746:  92%|[36m█████████▏[0m| 24/26 [00:23<00:01,  1.01it/s]Epoch: 6/10. Loss: 0.9746:  96%|[36m█████████▌[0m| 25/26 [00:23<00:00,  1.02it/s]Epoch: 6/10. Loss: 0.9391:  96%|[36m█████████▌[0m| 25/26 [00:24<00:00,  1.02it/s]Epoch: 6/10. Loss: 0.9391: 100%|[36m██████████[0m| 26/26 [00:24<00:00,  1.12it/s]Epoch: 6/10. Loss: 0.9391: 100%|[36m██████████[0m| 26/26 [00:24<00:00,  1.07it/s]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:05,  1.19it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:05,  1.13s/it] 43%|[33m████▎     [0m| 3/7 [00:02<00:03,  1.11it/s] 57%|[33m█████▋    [0m| 4/7 [00:03<00:02,  1.02it/s] 71%|[33m███████▏  [0m| 5/7 [00:04<00:01,  1.26it/s] 86%|[33m████████▌ [0m| 6/7 [00:05<00:00,  1.26it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.60it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.29it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 7/10. Loss: 0.8856:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 7/10. Loss: 0.8856:   4%|[36m▍         [0m| 1/26 [00:00<00:23,  1.07it/s]Epoch: 7/10. Loss: 0.9200:   4%|[36m▍         [0m| 1/26 [00:01<00:23,  1.07it/s]Epoch: 7/10. Loss: 0.9200:   8%|[36m▊         [0m| 2/26 [00:01<00:19,  1.20it/s]Epoch: 7/10. Loss: 1.0289:   8%|[36m▊         [0m| 2/26 [00:02<00:19,  1.20it/s]Epoch: 7/10. Loss: 1.0289:  12%|[36m█▏        [0m| 3/26 [00:02<00:21,  1.08it/s]Epoch: 7/10. Loss: 0.9525:  12%|[36m█▏        [0m| 3/26 [00:03<00:21,  1.08it/s]Epoch: 7/10. Loss: 0.9525:  15%|[36m█▌        [0m| 4/26 [00:03<00:20,  1.09it/s]Epoch: 7/10. Loss: 0.8443:  15%|[36m█▌        [0m| 4/26 [00:04<00:20,  1.09it/s]Epoch: 7/10. Loss: 0.8443:  19%|[36m█▉        [0m| 5/26 [00:04<00:18,  1.12it/s]Epoch: 7/10. Loss: 0.9501:  19%|[36m█▉        [0m| 5/26 [00:05<00:18,  1.12it/s]Epoch: 7/10. Loss: 0.9501:  23%|[36m██▎       [0m| 6/26 [00:05<00:17,  1.11it/s]Epoch: 7/10. Loss: 0.9545:  23%|[36m██▎       [0m| 6/26 [00:06<00:17,  1.11it/s]Epoch: 7/10. Loss: 0.9545:  27%|[36m██▋       [0m| 7/26 [00:06<00:17,  1.10it/s]Epoch: 7/10. Loss: 0.9950:  27%|[36m██▋       [0m| 7/26 [00:07<00:17,  1.10it/s]Epoch: 7/10. Loss: 0.9950:  31%|[36m███       [0m| 8/26 [00:07<00:15,  1.15it/s]Epoch: 7/10. Loss: 1.0184:  31%|[36m███       [0m| 8/26 [00:08<00:15,  1.15it/s]Epoch: 7/10. Loss: 1.0184:  35%|[36m███▍      [0m| 9/26 [00:08<00:16,  1.01it/s]Epoch: 7/10. Loss: 0.8520:  35%|[36m███▍      [0m| 9/26 [00:09<00:16,  1.01it/s]Epoch: 7/10. Loss: 0.8520:  38%|[36m███▊      [0m| 10/26 [00:09<00:15,  1.02it/s]Epoch: 7/10. Loss: 0.8975:  38%|[36m███▊      [0m| 10/26 [00:10<00:15,  1.02it/s]Epoch: 7/10. Loss: 0.8975:  42%|[36m████▏     [0m| 11/26 [00:10<00:13,  1.10it/s]Epoch: 7/10. Loss: 0.9650:  42%|[36m████▏     [0m| 11/26 [00:11<00:13,  1.10it/s]Epoch: 7/10. Loss: 0.9650:  46%|[36m████▌     [0m| 12/26 [00:11<00:13,  1.07it/s]Epoch: 7/10. Loss: 0.9361:  46%|[36m████▌     [0m| 12/26 [00:12<00:13,  1.07it/s]Epoch: 7/10. Loss: 0.9361:  50%|[36m█████     [0m| 13/26 [00:12<00:14,  1.10s/it]Epoch: 7/10. Loss: 0.9047:  50%|[36m█████     [0m| 13/26 [00:13<00:14,  1.10s/it]Epoch: 7/10. Loss: 0.9047:  54%|[36m█████▍    [0m| 14/26 [00:13<00:12,  1.00s/it]Epoch: 7/10. Loss: 0.9115:  54%|[36m█████▍    [0m| 14/26 [00:14<00:12,  1.00s/it]Epoch: 7/10. Loss: 0.9115:  58%|[36m█████▊    [0m| 15/26 [00:14<00:11,  1.00s/it]Epoch: 7/10. Loss: 0.9897:  58%|[36m█████▊    [0m| 15/26 [00:15<00:11,  1.00s/it]Epoch: 7/10. Loss: 0.9897:  62%|[36m██████▏   [0m| 16/26 [00:15<00:09,  1.04it/s]Epoch: 7/10. Loss: 0.8773:  62%|[36m██████▏   [0m| 16/26 [00:16<00:09,  1.04it/s]Epoch: 7/10. Loss: 0.8773:  65%|[36m██████▌   [0m| 17/26 [00:16<00:08,  1.01it/s]Epoch: 7/10. Loss: 0.8845:  65%|[36m██████▌   [0m| 17/26 [00:18<00:08,  1.01it/s]Epoch: 7/10. Loss: 0.8845:  69%|[36m██████▉   [0m| 18/26 [00:18<00:09,  1.25s/it]Epoch: 7/10. Loss: 0.9112:  69%|[36m██████▉   [0m| 18/26 [00:20<00:09,  1.25s/it]Epoch: 7/10. Loss: 0.9112:  73%|[36m███████▎  [0m| 19/26 [00:20<00:11,  1.61s/it]Epoch: 7/10. Loss: 0.9041:  73%|[36m███████▎  [0m| 19/26 [00:21<00:11,  1.61s/it]Epoch: 7/10. Loss: 0.9041:  77%|[36m███████▋  [0m| 20/26 [00:21<00:08,  1.47s/it]Epoch: 7/10. Loss: 0.9269:  77%|[36m███████▋  [0m| 20/26 [00:22<00:08,  1.47s/it]Epoch: 7/10. Loss: 0.9269:  81%|[36m████████  [0m| 21/26 [00:22<00:06,  1.36s/it]Epoch: 7/10. Loss: 0.9665:  81%|[36m████████  [0m| 21/26 [00:23<00:06,  1.36s/it]Epoch: 7/10. Loss: 0.9665:  85%|[36m████████▍ [0m| 22/26 [00:23<00:04,  1.24s/it]Epoch: 7/10. Loss: 0.9776:  85%|[36m████████▍ [0m| 22/26 [00:25<00:04,  1.24s/it]Epoch: 7/10. Loss: 0.9776:  88%|[36m████████▊ [0m| 23/26 [00:25<00:03,  1.33s/it]Epoch: 7/10. Loss: 0.9179:  88%|[36m████████▊ [0m| 23/26 [00:26<00:03,  1.33s/it]Epoch: 7/10. Loss: 0.9179:  92%|[36m█████████▏[0m| 24/26 [00:26<00:02,  1.35s/it]Epoch: 7/10. Loss: 1.0768:  92%|[36m█████████▏[0m| 24/26 [00:27<00:02,  1.35s/it]Epoch: 7/10. Loss: 1.0768:  96%|[36m█████████▌[0m| 25/26 [00:27<00:01,  1.22s/it]Epoch: 7/10. Loss: 1.0231:  96%|[36m█████████▌[0m| 25/26 [00:28<00:01,  1.22s/it]Epoch: 7/10. Loss: 1.0231: 100%|[36m██████████[0m| 26/26 [00:28<00:00,  1.08s/it]Epoch: 7/10. Loss: 1.0231: 100%|[36m██████████[0m| 26/26 [00:28<00:00,  1.09s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:04,  1.23it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:05,  1.13s/it] 43%|[33m████▎     [0m| 3/7 [00:02<00:03,  1.10it/s] 57%|[33m█████▋    [0m| 4/7 [00:03<00:02,  1.01it/s] 71%|[33m███████▏  [0m| 5/7 [00:04<00:01,  1.21it/s] 86%|[33m████████▌ [0m| 6/7 [00:05<00:00,  1.21it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.53it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.25it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 8/10. Loss: 0.8682:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 8/10. Loss: 0.8682:   4%|[36m▍         [0m| 1/26 [00:00<00:24,  1.02it/s]Epoch: 8/10. Loss: 0.8787:   4%|[36m▍         [0m| 1/26 [00:01<00:24,  1.02it/s]Epoch: 8/10. Loss: 0.8787:   8%|[36m▊         [0m| 2/26 [00:01<00:22,  1.04it/s]Epoch: 8/10. Loss: 0.9166:   8%|[36m▊         [0m| 2/26 [00:03<00:22,  1.04it/s]Epoch: 8/10. Loss: 0.9166:  12%|[36m█▏        [0m| 3/26 [00:03<00:27,  1.19s/it]Epoch: 8/10. Loss: 0.8584:  12%|[36m█▏        [0m| 3/26 [00:04<00:27,  1.19s/it]Epoch: 8/10. Loss: 0.8584:  15%|[36m█▌        [0m| 4/26 [00:04<00:23,  1.08s/it]Epoch: 8/10. Loss: 0.9235:  15%|[36m█▌        [0m| 4/26 [00:05<00:23,  1.08s/it]Epoch: 8/10. Loss: 0.9235:  19%|[36m█▉        [0m| 5/26 [00:05<00:23,  1.14s/it]Epoch: 8/10. Loss: 0.9615:  19%|[36m█▉        [0m| 5/26 [00:07<00:23,  1.14s/it]Epoch: 8/10. Loss: 0.9615:  23%|[36m██▎       [0m| 6/26 [00:07<00:31,  1.58s/it]Epoch: 8/10. Loss: 0.8818:  23%|[36m██▎       [0m| 6/26 [00:09<00:31,  1.58s/it]Epoch: 8/10. Loss: 0.8818:  27%|[36m██▋       [0m| 7/26 [00:09<00:29,  1.54s/it]Epoch: 8/10. Loss: 0.8505:  27%|[36m██▋       [0m| 7/26 [00:10<00:29,  1.54s/it]Epoch: 8/10. Loss: 0.8505:  31%|[36m███       [0m| 8/26 [00:10<00:23,  1.33s/it]Epoch: 8/10. Loss: 0.9263:  31%|[36m███       [0m| 8/26 [00:11<00:23,  1.33s/it]Epoch: 8/10. Loss: 0.9263:  35%|[36m███▍      [0m| 9/26 [00:11<00:21,  1.24s/it]Epoch: 8/10. Loss: 0.8944:  35%|[36m███▍      [0m| 9/26 [00:12<00:21,  1.24s/it]Epoch: 8/10. Loss: 0.8944:  38%|[36m███▊      [0m| 10/26 [00:12<00:17,  1.10s/it]Epoch: 8/10. Loss: 0.8760:  38%|[36m███▊      [0m| 10/26 [00:12<00:17,  1.10s/it]Epoch: 8/10. Loss: 0.8760:  42%|[36m████▏     [0m| 11/26 [00:12<00:14,  1.00it/s]Epoch: 8/10. Loss: 0.8758:  42%|[36m████▏     [0m| 11/26 [00:13<00:14,  1.00it/s]Epoch: 8/10. Loss: 0.8758:  46%|[36m████▌     [0m| 12/26 [00:13<00:13,  1.04it/s]Epoch: 8/10. Loss: 0.8583:  46%|[36m████▌     [0m| 12/26 [00:14<00:13,  1.04it/s]Epoch: 8/10. Loss: 0.8583:  50%|[36m█████     [0m| 13/26 [00:14<00:12,  1.06it/s]Epoch: 8/10. Loss: 0.8859:  50%|[36m█████     [0m| 13/26 [00:15<00:12,  1.06it/s]Epoch: 8/10. Loss: 0.8859:  54%|[36m█████▍    [0m| 14/26 [00:15<00:11,  1.02it/s]Epoch: 8/10. Loss: 0.8849:  54%|[36m█████▍    [0m| 14/26 [00:16<00:11,  1.02it/s]Epoch: 8/10. Loss: 0.8849:  58%|[36m█████▊    [0m| 15/26 [00:16<00:10,  1.06it/s]Epoch: 8/10. Loss: 0.8349:  58%|[36m█████▊    [0m| 15/26 [00:17<00:10,  1.06it/s]Epoch: 8/10. Loss: 0.8349:  62%|[36m██████▏   [0m| 16/26 [00:17<00:09,  1.07it/s]Epoch: 8/10. Loss: 0.8948:  62%|[36m██████▏   [0m| 16/26 [00:18<00:09,  1.07it/s]Epoch: 8/10. Loss: 0.8948:  65%|[36m██████▌   [0m| 17/26 [00:18<00:08,  1.09it/s]Epoch: 8/10. Loss: 0.8652:  65%|[36m██████▌   [0m| 17/26 [00:19<00:08,  1.09it/s]Epoch: 8/10. Loss: 0.8652:  69%|[36m██████▉   [0m| 18/26 [00:19<00:07,  1.01it/s]Epoch: 8/10. Loss: 0.8954:  69%|[36m██████▉   [0m| 18/26 [00:20<00:07,  1.01it/s]Epoch: 8/10. Loss: 0.8954:  73%|[36m███████▎  [0m| 19/26 [00:20<00:06,  1.00it/s]Epoch: 8/10. Loss: 0.8385:  73%|[36m███████▎  [0m| 19/26 [00:21<00:06,  1.00it/s]Epoch: 8/10. Loss: 0.8385:  77%|[36m███████▋  [0m| 20/26 [00:21<00:06,  1.02s/it]Epoch: 8/10. Loss: 0.9103:  77%|[36m███████▋  [0m| 20/26 [00:23<00:06,  1.02s/it]Epoch: 8/10. Loss: 0.9103:  81%|[36m████████  [0m| 21/26 [00:23<00:06,  1.28s/it]Epoch: 8/10. Loss: 0.8704:  81%|[36m████████  [0m| 21/26 [00:24<00:06,  1.28s/it]Epoch: 8/10. Loss: 0.8704:  85%|[36m████████▍ [0m| 22/26 [00:24<00:04,  1.15s/it]Epoch: 8/10. Loss: 0.9214:  85%|[36m████████▍ [0m| 22/26 [00:25<00:04,  1.15s/it]Epoch: 8/10. Loss: 0.9214:  88%|[36m████████▊ [0m| 23/26 [00:25<00:03,  1.07s/it]Epoch: 8/10. Loss: 1.0576:  88%|[36m████████▊ [0m| 23/26 [00:26<00:03,  1.07s/it]Epoch: 8/10. Loss: 1.0576:  92%|[36m█████████▏[0m| 24/26 [00:26<00:02,  1.03s/it]Epoch: 8/10. Loss: 0.9018:  92%|[36m█████████▏[0m| 24/26 [00:27<00:02,  1.03s/it]Epoch: 8/10. Loss: 0.9018:  96%|[36m█████████▌[0m| 25/26 [00:27<00:01,  1.01s/it]Epoch: 8/10. Loss: 0.8400:  96%|[36m█████████▌[0m| 25/26 [00:27<00:01,  1.01s/it]Epoch: 8/10. Loss: 0.8400: 100%|[36m██████████[0m| 26/26 [00:27<00:00,  1.16it/s]Epoch: 8/10. Loss: 0.8400: 100%|[36m██████████[0m| 26/26 [00:27<00:00,  1.07s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:04,  1.41it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:06,  1.38s/it] 43%|[33m████▎     [0m| 3/7 [00:03<00:04,  1.05s/it] 57%|[33m█████▋    [0m| 4/7 [00:04<00:03,  1.08s/it] 71%|[33m███████▏  [0m| 5/7 [00:04<00:01,  1.15it/s] 86%|[33m████████▌ [0m| 6/7 [00:05<00:00,  1.16it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.48it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.17it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 9/10. Loss: 0.8775:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 9/10. Loss: 0.8775:   4%|[36m▍         [0m| 1/26 [00:00<00:20,  1.22it/s]Epoch: 9/10. Loss: 0.9143:   4%|[36m▍         [0m| 1/26 [00:01<00:20,  1.22it/s]Epoch: 9/10. Loss: 0.9143:   8%|[36m▊         [0m| 2/26 [00:01<00:20,  1.16it/s]Epoch: 9/10. Loss: 0.8255:   8%|[36m▊         [0m| 2/26 [00:02<00:20,  1.16it/s]Epoch: 9/10. Loss: 0.8255:  12%|[36m█▏        [0m| 3/26 [00:02<00:20,  1.13it/s]Epoch: 9/10. Loss: 0.9055:  12%|[36m█▏        [0m| 3/26 [00:03<00:20,  1.13it/s]Epoch: 9/10. Loss: 0.9055:  15%|[36m█▌        [0m| 4/26 [00:03<00:19,  1.14it/s]Epoch: 9/10. Loss: 0.8992:  15%|[36m█▌        [0m| 4/26 [00:04<00:19,  1.14it/s]Epoch: 9/10. Loss: 0.8992:  19%|[36m█▉        [0m| 5/26 [00:04<00:17,  1.19it/s]Epoch: 9/10. Loss: 0.8590:  19%|[36m█▉        [0m| 5/26 [00:05<00:17,  1.19it/s]Epoch: 9/10. Loss: 0.8590:  23%|[36m██▎       [0m| 6/26 [00:05<00:20,  1.03s/it]Epoch: 9/10. Loss: 0.9211:  23%|[36m██▎       [0m| 6/26 [00:06<00:20,  1.03s/it]Epoch: 9/10. Loss: 0.9211:  27%|[36m██▋       [0m| 7/26 [00:06<00:19,  1.01s/it]Epoch: 9/10. Loss: 0.8728:  27%|[36m██▋       [0m| 7/26 [00:07<00:19,  1.01s/it]Epoch: 9/10. Loss: 0.8728:  31%|[36m███       [0m| 8/26 [00:07<00:17,  1.02it/s]Epoch: 9/10. Loss: 0.8962:  31%|[36m███       [0m| 8/26 [00:08<00:17,  1.02it/s]Epoch: 9/10. Loss: 0.8962:  35%|[36m███▍      [0m| 9/26 [00:08<00:16,  1.05it/s]Epoch: 9/10. Loss: 0.8964:  35%|[36m███▍      [0m| 9/26 [00:09<00:16,  1.05it/s]Epoch: 9/10. Loss: 0.8964:  38%|[36m███▊      [0m| 10/26 [00:09<00:15,  1.01it/s]Epoch: 9/10. Loss: 0.8826:  38%|[36m███▊      [0m| 10/26 [00:10<00:15,  1.01it/s]Epoch: 9/10. Loss: 0.8826:  42%|[36m████▏     [0m| 11/26 [00:10<00:14,  1.02it/s]Epoch: 9/10. Loss: 0.9182:  42%|[36m████▏     [0m| 11/26 [00:11<00:14,  1.02it/s]Epoch: 9/10. Loss: 0.9182:  46%|[36m████▌     [0m| 12/26 [00:11<00:13,  1.04it/s]Epoch: 9/10. Loss: 0.7991:  46%|[36m████▌     [0m| 12/26 [00:12<00:13,  1.04it/s]Epoch: 9/10. Loss: 0.7991:  50%|[36m█████     [0m| 13/26 [00:12<00:12,  1.07it/s]Epoch: 9/10. Loss: 0.7998:  50%|[36m█████     [0m| 13/26 [00:13<00:12,  1.07it/s]Epoch: 9/10. Loss: 0.7998:  54%|[36m█████▍    [0m| 14/26 [00:13<00:10,  1.14it/s]Epoch: 9/10. Loss: 0.9054:  54%|[36m█████▍    [0m| 14/26 [00:13<00:10,  1.14it/s]Epoch: 9/10. Loss: 0.9054:  58%|[36m█████▊    [0m| 15/26 [00:13<00:09,  1.13it/s]Epoch: 9/10. Loss: 0.9605:  58%|[36m█████▊    [0m| 15/26 [00:15<00:09,  1.13it/s]Epoch: 9/10. Loss: 0.9605:  62%|[36m██████▏   [0m| 16/26 [00:15<00:09,  1.03it/s]Epoch: 9/10. Loss: 0.7980:  62%|[36m██████▏   [0m| 16/26 [00:16<00:09,  1.03it/s]Epoch: 9/10. Loss: 0.7980:  65%|[36m██████▌   [0m| 17/26 [00:16<00:09,  1.04s/it]Epoch: 9/10. Loss: 0.8758:  65%|[36m██████▌   [0m| 17/26 [00:17<00:09,  1.04s/it]Epoch: 9/10. Loss: 0.8758:  69%|[36m██████▉   [0m| 18/26 [00:17<00:07,  1.03it/s]Epoch: 9/10. Loss: 0.7846:  69%|[36m██████▉   [0m| 18/26 [00:18<00:07,  1.03it/s]Epoch: 9/10. Loss: 0.7846:  73%|[36m███████▎  [0m| 19/26 [00:18<00:06,  1.02it/s]Epoch: 9/10. Loss: 0.9844:  73%|[36m███████▎  [0m| 19/26 [00:19<00:06,  1.02it/s]Epoch: 9/10. Loss: 0.9844:  77%|[36m███████▋  [0m| 20/26 [00:19<00:06,  1.09s/it]Epoch: 9/10. Loss: 0.8730:  77%|[36m███████▋  [0m| 20/26 [00:20<00:06,  1.09s/it]Epoch: 9/10. Loss: 0.8730:  81%|[36m████████  [0m| 21/26 [00:20<00:05,  1.04s/it]Epoch: 9/10. Loss: 0.8779:  81%|[36m████████  [0m| 21/26 [00:21<00:05,  1.04s/it]Epoch: 9/10. Loss: 0.8779:  85%|[36m████████▍ [0m| 22/26 [00:21<00:04,  1.01s/it]Epoch: 9/10. Loss: 0.7913:  85%|[36m████████▍ [0m| 22/26 [00:22<00:04,  1.01s/it]Epoch: 9/10. Loss: 0.7913:  88%|[36m████████▊ [0m| 23/26 [00:22<00:02,  1.00it/s]Epoch: 9/10. Loss: 0.7918:  88%|[36m████████▊ [0m| 23/26 [00:23<00:02,  1.00it/s]Epoch: 9/10. Loss: 0.7918:  92%|[36m█████████▏[0m| 24/26 [00:23<00:01,  1.04it/s]Epoch: 9/10. Loss: 0.8371:  92%|[36m█████████▏[0m| 24/26 [00:24<00:01,  1.04it/s]Epoch: 9/10. Loss: 0.8371:  96%|[36m█████████▌[0m| 25/26 [00:24<00:00,  1.02it/s]Epoch: 9/10. Loss: 0.8448:  96%|[36m█████████▌[0m| 25/26 [00:25<00:00,  1.02it/s]Epoch: 9/10. Loss: 0.8448: 100%|[36m██████████[0m| 26/26 [00:25<00:00,  1.06it/s]Epoch: 9/10. Loss: 0.8448: 100%|[36m██████████[0m| 26/26 [00:25<00:00,  1.04it/s]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:04,  1.41it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:05,  1.06s/it] 43%|[33m████▎     [0m| 3/7 [00:02<00:03,  1.13it/s] 57%|[33m█████▋    [0m| 4/7 [00:03<00:02,  1.03it/s] 71%|[33m███████▏  [0m| 5/7 [00:04<00:01,  1.25it/s] 86%|[33m████████▌ [0m| 6/7 [00:05<00:00,  1.24it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.56it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.29it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 0/10. Loss: 1.4121:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 0/10. Loss: 1.4121:   4%|[36m▍         [0m| 1/26 [00:00<00:23,  1.08it/s]Epoch: 0/10. Loss: 3.1221:   4%|[36m▍         [0m| 1/26 [00:02<00:23,  1.08it/s]Epoch: 0/10. Loss: 3.1221:   8%|[36m▊         [0m| 2/26 [00:02<00:34,  1.45s/it]Epoch: 0/10. Loss: 2.0301:   8%|[36m▊         [0m| 2/26 [00:03<00:34,  1.45s/it]Epoch: 0/10. Loss: 2.0301:  12%|[36m█▏        [0m| 3/26 [00:03<00:25,  1.13s/it]Epoch: 0/10. Loss: 2.0993:  12%|[36m█▏        [0m| 3/26 [00:04<00:25,  1.13s/it]Epoch: 0/10. Loss: 2.0993:  15%|[36m█▌        [0m| 4/26 [00:04<00:23,  1.08s/it]Epoch: 0/10. Loss: 1.3078:  15%|[36m█▌        [0m| 4/26 [00:05<00:23,  1.08s/it]Epoch: 0/10. Loss: 1.3078:  19%|[36m█▉        [0m| 5/26 [00:05<00:21,  1.01s/it]Epoch: 0/10. Loss: 1.5474:  19%|[36m█▉        [0m| 5/26 [00:06<00:21,  1.01s/it]Epoch: 0/10. Loss: 1.5474:  23%|[36m██▎       [0m| 6/26 [00:06<00:18,  1.07it/s]Epoch: 0/10. Loss: 1.0172:  23%|[36m██▎       [0m| 6/26 [00:06<00:18,  1.07it/s]Epoch: 0/10. Loss: 1.0172:  27%|[36m██▋       [0m| 7/26 [00:06<00:16,  1.14it/s]Epoch: 0/10. Loss: 1.1272:  27%|[36m██▋       [0m| 7/26 [00:08<00:16,  1.14it/s]Epoch: 0/10. Loss: 1.1272:  31%|[36m███       [0m| 8/26 [00:08<00:17,  1.05it/s]Epoch: 0/10. Loss: 1.0151:  31%|[36m███       [0m| 8/26 [00:08<00:17,  1.05it/s]Epoch: 0/10. Loss: 1.0151:  35%|[36m███▍      [0m| 9/26 [00:08<00:15,  1.10it/s]Epoch: 0/10. Loss: 1.1321:  35%|[36m███▍      [0m| 9/26 [00:09<00:15,  1.10it/s]Epoch: 0/10. Loss: 1.1321:  38%|[36m███▊      [0m| 10/26 [00:09<00:14,  1.09it/s]Epoch: 0/10. Loss: 1.1294:  38%|[36m███▊      [0m| 10/26 [00:11<00:14,  1.09it/s]Epoch: 0/10. Loss: 1.1294:  42%|[36m████▏     [0m| 11/26 [00:11<00:17,  1.19s/it]Epoch: 0/10. Loss: 1.0215:  42%|[36m████▏     [0m| 11/26 [00:12<00:17,  1.19s/it]Epoch: 0/10. Loss: 1.0215:  46%|[36m████▌     [0m| 12/26 [00:12<00:15,  1.12s/it]Epoch: 0/10. Loss: 1.2931:  46%|[36m████▌     [0m| 12/26 [00:14<00:15,  1.12s/it]Epoch: 0/10. Loss: 1.2931:  50%|[36m█████     [0m| 13/26 [00:14<00:16,  1.24s/it]Epoch: 0/10. Loss: 1.1801:  50%|[36m█████     [0m| 13/26 [00:14<00:16,  1.24s/it]Epoch: 0/10. Loss: 1.1801:  54%|[36m█████▍    [0m| 14/26 [00:14<00:13,  1.09s/it]Epoch: 0/10. Loss: 1.1550:  54%|[36m█████▍    [0m| 14/26 [00:15<00:13,  1.09s/it]Epoch: 0/10. Loss: 1.1550:  58%|[36m█████▊    [0m| 15/26 [00:15<00:11,  1.05s/it]Epoch: 0/10. Loss: 1.0330:  58%|[36m█████▊    [0m| 15/26 [00:16<00:11,  1.05s/it]Epoch: 0/10. Loss: 1.0330:  62%|[36m██████▏   [0m| 16/26 [00:16<00:09,  1.02it/s]Epoch: 0/10. Loss: 1.0897:  62%|[36m██████▏   [0m| 16/26 [00:18<00:09,  1.02it/s]Epoch: 0/10. Loss: 1.0897:  65%|[36m██████▌   [0m| 17/26 [00:18<00:10,  1.16s/it]Epoch: 0/10. Loss: 1.0590:  65%|[36m██████▌   [0m| 17/26 [00:19<00:10,  1.16s/it]Epoch: 0/10. Loss: 1.0590:  69%|[36m██████▉   [0m| 18/26 [00:19<00:08,  1.08s/it]Epoch: 0/10. Loss: 1.0397:  69%|[36m██████▉   [0m| 18/26 [00:19<00:08,  1.08s/it]Epoch: 0/10. Loss: 1.0397:  73%|[36m███████▎  [0m| 19/26 [00:19<00:07,  1.00s/it]Epoch: 0/10. Loss: 0.9824:  73%|[36m███████▎  [0m| 19/26 [00:20<00:07,  1.00s/it]Epoch: 0/10. Loss: 0.9824:  77%|[36m███████▋  [0m| 20/26 [00:20<00:05,  1.05it/s]Epoch: 0/10. Loss: 0.9873:  77%|[36m███████▋  [0m| 20/26 [00:21<00:05,  1.05it/s]Epoch: 0/10. Loss: 0.9873:  81%|[36m████████  [0m| 21/26 [00:21<00:04,  1.07it/s]Epoch: 0/10. Loss: 1.1815:  81%|[36m████████  [0m| 21/26 [00:22<00:04,  1.07it/s]Epoch: 0/10. Loss: 1.1815:  85%|[36m████████▍ [0m| 22/26 [00:22<00:03,  1.00it/s]Epoch: 0/10. Loss: 0.9934:  85%|[36m████████▍ [0m| 22/26 [00:23<00:03,  1.00it/s]Epoch: 0/10. Loss: 0.9934:  88%|[36m████████▊ [0m| 23/26 [00:23<00:02,  1.10it/s]Epoch: 0/10. Loss: 1.0610:  88%|[36m████████▊ [0m| 23/26 [00:24<00:02,  1.10it/s]Epoch: 0/10. Loss: 1.0610:  92%|[36m█████████▏[0m| 24/26 [00:24<00:01,  1.08it/s]Epoch: 0/10. Loss: 1.0710:  92%|[36m█████████▏[0m| 24/26 [00:25<00:01,  1.08it/s]Epoch: 0/10. Loss: 1.0710:  96%|[36m█████████▌[0m| 25/26 [00:25<00:00,  1.09it/s]Epoch: 0/10. Loss: 0.9510:  96%|[36m█████████▌[0m| 25/26 [00:26<00:00,  1.09it/s]Epoch: 0/10. Loss: 0.9510: 100%|[36m██████████[0m| 26/26 [00:26<00:00,  1.10it/s]Epoch: 0/10. Loss: 0.9510: 100%|[36m██████████[0m| 26/26 [00:26<00:00,  1.01s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:04,  1.37it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:05,  1.08s/it] 43%|[33m████▎     [0m| 3/7 [00:02<00:03,  1.12it/s] 57%|[33m█████▋    [0m| 4/7 [00:03<00:02,  1.00it/s] 71%|[33m███████▏  [0m| 5/7 [00:04<00:01,  1.22it/s] 86%|[33m████████▌ [0m| 6/7 [00:05<00:00,  1.21it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.53it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.27it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 1/10. Loss: 0.9433:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 1/10. Loss: 0.9433:   4%|[36m▍         [0m| 1/26 [00:00<00:22,  1.13it/s]Epoch: 1/10. Loss: 1.0217:   4%|[36m▍         [0m| 1/26 [00:02<00:22,  1.13it/s]Epoch: 1/10. Loss: 1.0217:   8%|[36m▊         [0m| 2/26 [00:02<00:28,  1.18s/it]Epoch: 1/10. Loss: 0.9253:   8%|[36m▊         [0m| 2/26 [00:02<00:28,  1.18s/it]Epoch: 1/10. Loss: 0.9253:  12%|[36m█▏        [0m| 3/26 [00:02<00:22,  1.04it/s]Epoch: 1/10. Loss: 1.0630:  12%|[36m█▏        [0m| 3/26 [00:03<00:22,  1.04it/s]Epoch: 1/10. Loss: 1.0630:  15%|[36m█▌        [0m| 4/26 [00:03<00:21,  1.03it/s]Epoch: 1/10. Loss: 0.9702:  15%|[36m█▌        [0m| 4/26 [00:06<00:21,  1.03it/s]Epoch: 1/10. Loss: 0.9702:  19%|[36m█▉        [0m| 5/26 [00:06<00:28,  1.37s/it]Epoch: 1/10. Loss: 1.0176:  19%|[36m█▉        [0m| 5/26 [00:06<00:28,  1.37s/it]Epoch: 1/10. Loss: 1.0176:  23%|[36m██▎       [0m| 6/26 [00:06<00:23,  1.17s/it]Epoch: 1/10. Loss: 1.0723:  23%|[36m██▎       [0m| 6/26 [00:07<00:23,  1.17s/it]Epoch: 1/10. Loss: 1.0723:  27%|[36m██▋       [0m| 7/26 [00:07<00:22,  1.16s/it]Epoch: 1/10. Loss: 1.0540:  27%|[36m██▋       [0m| 7/26 [00:08<00:22,  1.16s/it]Epoch: 1/10. Loss: 1.0540:  31%|[36m███       [0m| 8/26 [00:08<00:18,  1.01s/it]Epoch: 1/10. Loss: 1.1624:  31%|[36m███       [0m| 8/26 [00:09<00:18,  1.01s/it]Epoch: 1/10. Loss: 1.1624:  35%|[36m███▍      [0m| 9/26 [00:09<00:16,  1.04it/s]Epoch: 1/10. Loss: 1.0582:  35%|[36m███▍      [0m| 9/26 [00:10<00:16,  1.04it/s]Epoch: 1/10. Loss: 1.0582:  38%|[36m███▊      [0m| 10/26 [00:10<00:14,  1.12it/s]Epoch: 1/10. Loss: 1.1198:  38%|[36m███▊      [0m| 10/26 [00:11<00:14,  1.12it/s]Epoch: 1/10. Loss: 1.1198:  42%|[36m████▏     [0m| 11/26 [00:11<00:13,  1.10it/s]Epoch: 1/10. Loss: 1.1182:  42%|[36m████▏     [0m| 11/26 [00:12<00:13,  1.10it/s]Epoch: 1/10. Loss: 1.1182:  46%|[36m████▌     [0m| 12/26 [00:12<00:12,  1.08it/s]Epoch: 1/10. Loss: 1.0727:  46%|[36m████▌     [0m| 12/26 [00:13<00:12,  1.08it/s]Epoch: 1/10. Loss: 1.0727:  50%|[36m█████     [0m| 13/26 [00:13<00:12,  1.08it/s]Epoch: 1/10. Loss: 1.0079:  50%|[36m█████     [0m| 13/26 [00:14<00:12,  1.08it/s]Epoch: 1/10. Loss: 1.0079:  54%|[36m█████▍    [0m| 14/26 [00:14<00:11,  1.04it/s]Epoch: 1/10. Loss: 1.0278:  54%|[36m█████▍    [0m| 14/26 [00:14<00:11,  1.04it/s]Epoch: 1/10. Loss: 1.0278:  58%|[36m█████▊    [0m| 15/26 [00:14<00:09,  1.13it/s]Epoch: 1/10. Loss: 1.1284:  58%|[36m█████▊    [0m| 15/26 [00:16<00:09,  1.13it/s]Epoch: 1/10. Loss: 1.1284:  62%|[36m██████▏   [0m| 16/26 [00:16<00:10,  1.02s/it]Epoch: 1/10. Loss: 0.9443:  62%|[36m██████▏   [0m| 16/26 [00:17<00:10,  1.02s/it]Epoch: 1/10. Loss: 0.9443:  65%|[36m██████▌   [0m| 17/26 [00:17<00:08,  1.02it/s]Epoch: 1/10. Loss: 1.3174:  65%|[36m██████▌   [0m| 17/26 [00:17<00:08,  1.02it/s]Epoch: 1/10. Loss: 1.3174:  69%|[36m██████▉   [0m| 18/26 [00:17<00:07,  1.08it/s]Epoch: 1/10. Loss: 1.0873:  69%|[36m██████▉   [0m| 18/26 [00:18<00:07,  1.08it/s]Epoch: 1/10. Loss: 1.0873:  73%|[36m███████▎  [0m| 19/26 [00:18<00:06,  1.11it/s]Epoch: 1/10. Loss: 0.9622:  73%|[36m███████▎  [0m| 19/26 [00:19<00:06,  1.11it/s]Epoch: 1/10. Loss: 0.9622:  77%|[36m███████▋  [0m| 20/26 [00:19<00:05,  1.14it/s]Epoch: 1/10. Loss: 0.9831:  77%|[36m███████▋  [0m| 20/26 [00:20<00:05,  1.14it/s]Epoch: 1/10. Loss: 0.9831:  81%|[36m████████  [0m| 21/26 [00:20<00:04,  1.15it/s]Epoch: 1/10. Loss: 0.9873:  81%|[36m████████  [0m| 21/26 [00:21<00:04,  1.15it/s]Epoch: 1/10. Loss: 0.9873:  85%|[36m████████▍ [0m| 22/26 [00:21<00:03,  1.16it/s]Epoch: 1/10. Loss: 1.0275:  85%|[36m████████▍ [0m| 22/26 [00:21<00:03,  1.16it/s]Epoch: 1/10. Loss: 1.0275:  88%|[36m████████▊ [0m| 23/26 [00:22<00:02,  1.19it/s]Epoch: 1/10. Loss: 0.9373:  88%|[36m████████▊ [0m| 23/26 [00:23<00:02,  1.19it/s]Epoch: 1/10. Loss: 0.9373:  92%|[36m█████████▏[0m| 24/26 [00:23<00:01,  1.12it/s]Epoch: 1/10. Loss: 0.9569:  92%|[36m█████████▏[0m| 24/26 [00:24<00:01,  1.12it/s]Epoch: 1/10. Loss: 0.9569:  96%|[36m█████████▌[0m| 25/26 [00:24<00:00,  1.06it/s]Epoch: 1/10. Loss: 0.9740:  96%|[36m█████████▌[0m| 25/26 [00:24<00:00,  1.06it/s]Epoch: 1/10. Loss: 0.9740: 100%|[36m██████████[0m| 26/26 [00:24<00:00,  1.21it/s]Epoch: 1/10. Loss: 0.9740: 100%|[36m██████████[0m| 26/26 [00:24<00:00,  1.06it/s]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:04,  1.37it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:05,  1.10s/it] 43%|[33m████▎     [0m| 3/7 [00:02<00:03,  1.06it/s] 57%|[33m█████▋    [0m| 4/7 [00:03<00:03,  1.02s/it] 71%|[33m███████▏  [0m| 5/7 [00:04<00:01,  1.21it/s] 86%|[33m████████▌ [0m| 6/7 [00:05<00:00,  1.20it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.52it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.25it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 2/10. Loss: 1.0049:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 2/10. Loss: 1.0049:   4%|[36m▍         [0m| 1/26 [00:00<00:21,  1.16it/s]Epoch: 2/10. Loss: 0.9517:   4%|[36m▍         [0m| 1/26 [00:01<00:21,  1.16it/s]Epoch: 2/10. Loss: 0.9517:   8%|[36m▊         [0m| 2/26 [00:01<00:19,  1.25it/s]Epoch: 2/10. Loss: 1.0111:   8%|[36m▊         [0m| 2/26 [00:03<00:19,  1.25it/s]Epoch: 2/10. Loss: 1.0111:  12%|[36m█▏        [0m| 3/26 [00:03<00:30,  1.31s/it]Epoch: 2/10. Loss: 0.9552:  12%|[36m█▏        [0m| 3/26 [00:04<00:30,  1.31s/it]Epoch: 2/10. Loss: 0.9552:  15%|[36m█▌        [0m| 4/26 [00:04<00:29,  1.35s/it]Epoch: 2/10. Loss: 1.0634:  15%|[36m█▌        [0m| 4/26 [00:05<00:29,  1.35s/it]Epoch: 2/10. Loss: 1.0634:  19%|[36m█▉        [0m| 5/26 [00:05<00:24,  1.19s/it]Epoch: 2/10. Loss: 0.9524:  19%|[36m█▉        [0m| 5/26 [00:06<00:24,  1.19s/it]Epoch: 2/10. Loss: 0.9524:  23%|[36m██▎       [0m| 6/26 [00:06<00:20,  1.05s/it]Epoch: 2/10. Loss: 1.0225:  23%|[36m██▎       [0m| 6/26 [00:07<00:20,  1.05s/it]Epoch: 2/10. Loss: 1.0225:  27%|[36m██▋       [0m| 7/26 [00:07<00:20,  1.08s/it]Epoch: 2/10. Loss: 1.0076:  27%|[36m██▋       [0m| 7/26 [00:08<00:20,  1.08s/it]Epoch: 2/10. Loss: 1.0076:  31%|[36m███       [0m| 8/26 [00:08<00:19,  1.06s/it]Epoch: 2/10. Loss: 0.9878:  31%|[36m███       [0m| 8/26 [00:09<00:19,  1.06s/it]Epoch: 2/10. Loss: 0.9878:  35%|[36m███▍      [0m| 9/26 [00:09<00:16,  1.00it/s]Epoch: 2/10. Loss: 0.9930:  35%|[36m███▍      [0m| 9/26 [00:11<00:16,  1.00it/s]Epoch: 2/10. Loss: 0.9930:  38%|[36m███▊      [0m| 10/26 [00:11<00:18,  1.14s/it]Epoch: 2/10. Loss: 1.0303:  38%|[36m███▊      [0m| 10/26 [00:11<00:18,  1.14s/it]Epoch: 2/10. Loss: 1.0303:  42%|[36m████▏     [0m| 11/26 [00:11<00:14,  1.01it/s]Epoch: 2/10. Loss: 0.9814:  42%|[36m████▏     [0m| 11/26 [00:12<00:14,  1.01it/s]Epoch: 2/10. Loss: 0.9814:  46%|[36m████▌     [0m| 12/26 [00:12<00:12,  1.09it/s]Epoch: 2/10. Loss: 0.9846:  46%|[36m████▌     [0m| 12/26 [00:13<00:12,  1.09it/s]Epoch: 2/10. Loss: 0.9846:  50%|[36m█████     [0m| 13/26 [00:13<00:13,  1.07s/it]Epoch: 2/10. Loss: 1.1349:  50%|[36m█████     [0m| 13/26 [00:15<00:13,  1.07s/it]Epoch: 2/10. Loss: 1.1349:  54%|[36m█████▍    [0m| 14/26 [00:15<00:16,  1.35s/it]Epoch: 2/10. Loss: 1.1894:  54%|[36m█████▍    [0m| 14/26 [00:16<00:16,  1.35s/it]Epoch: 2/10. Loss: 1.1894:  58%|[36m█████▊    [0m| 15/26 [00:16<00:13,  1.23s/it]Epoch: 2/10. Loss: 0.8811:  58%|[36m█████▊    [0m| 15/26 [00:17<00:13,  1.23s/it]Epoch: 2/10. Loss: 0.8811:  62%|[36m██████▏   [0m| 16/26 [00:17<00:11,  1.13s/it]Epoch: 2/10. Loss: 0.9451:  62%|[36m██████▏   [0m| 16/26 [00:19<00:11,  1.13s/it]Epoch: 2/10. Loss: 0.9451:  65%|[36m██████▌   [0m| 17/26 [00:19<00:11,  1.30s/it]Epoch: 2/10. Loss: 1.1267:  65%|[36m██████▌   [0m| 17/26 [00:20<00:11,  1.30s/it]Epoch: 2/10. Loss: 1.1267:  69%|[36m██████▉   [0m| 18/26 [00:20<00:09,  1.16s/it]Epoch: 2/10. Loss: 0.9787:  69%|[36m██████▉   [0m| 18/26 [00:21<00:09,  1.16s/it]Epoch: 2/10. Loss: 0.9787:  73%|[36m███████▎  [0m| 19/26 [00:21<00:07,  1.14s/it]Epoch: 2/10. Loss: 1.0030:  73%|[36m███████▎  [0m| 19/26 [00:22<00:07,  1.14s/it]Epoch: 2/10. Loss: 1.0030:  77%|[36m███████▋  [0m| 20/26 [00:22<00:06,  1.04s/it]Epoch: 2/10. Loss: 0.9398:  77%|[36m███████▋  [0m| 20/26 [00:23<00:06,  1.04s/it]Epoch: 2/10. Loss: 0.9398:  81%|[36m████████  [0m| 21/26 [00:23<00:04,  1.03it/s]Epoch: 2/10. Loss: 0.9171:  81%|[36m████████  [0m| 21/26 [00:24<00:04,  1.03it/s]Epoch: 2/10. Loss: 0.9171:  85%|[36m████████▍ [0m| 22/26 [00:24<00:03,  1.02it/s]Epoch: 2/10. Loss: 0.9582:  85%|[36m████████▍ [0m| 22/26 [00:24<00:03,  1.02it/s]Epoch: 2/10. Loss: 0.9582:  88%|[36m████████▊ [0m| 23/26 [00:24<00:02,  1.03it/s]Epoch: 2/10. Loss: 1.0357:  88%|[36m████████▊ [0m| 23/26 [00:25<00:02,  1.03it/s]Epoch: 2/10. Loss: 1.0357:  92%|[36m█████████▏[0m| 24/26 [00:25<00:01,  1.09it/s]Epoch: 2/10. Loss: 0.9879:  92%|[36m█████████▏[0m| 24/26 [00:26<00:01,  1.09it/s]Epoch: 2/10. Loss: 0.9879:  96%|[36m█████████▌[0m| 25/26 [00:26<00:00,  1.12it/s]Epoch: 2/10. Loss: 0.9092:  96%|[36m█████████▌[0m| 25/26 [00:27<00:00,  1.12it/s]Epoch: 2/10. Loss: 0.9092: 100%|[36m██████████[0m| 26/26 [00:27<00:00,  1.23it/s]Epoch: 2/10. Loss: 0.9092: 100%|[36m██████████[0m| 26/26 [00:27<00:00,  1.05s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:04,  1.29it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:05,  1.09s/it] 43%|[33m████▎     [0m| 3/7 [00:02<00:03,  1.12it/s] 57%|[33m█████▋    [0m| 4/7 [00:04<00:03,  1.08s/it] 71%|[33m███████▏  [0m| 5/7 [00:04<00:01,  1.15it/s] 86%|[33m████████▌ [0m| 6/7 [00:05<00:00,  1.15it/s]100%|[33m██████████[0m| 7/7 [00:06<00:00,  1.00it/s]100%|[33m██████████[0m| 7/7 [00:06<00:00,  1.04it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 3/10. Loss: 1.0448:   0%|[36m          [0m| 0/26 [00:01<?, ?it/s]Epoch: 3/10. Loss: 1.0448:   4%|[36m▍         [0m| 1/26 [00:01<00:25,  1.04s/it]Epoch: 3/10. Loss: 0.9274:   4%|[36m▍         [0m| 1/26 [00:01<00:25,  1.04s/it]Epoch: 3/10. Loss: 0.9274:   8%|[36m▊         [0m| 2/26 [00:01<00:22,  1.07it/s]Epoch: 3/10. Loss: 0.8550:   8%|[36m▊         [0m| 2/26 [00:03<00:22,  1.07it/s]Epoch: 3/10. Loss: 0.8550:  12%|[36m█▏        [0m| 3/26 [00:03<00:28,  1.24s/it]Epoch: 3/10. Loss: 0.9493:  12%|[36m█▏        [0m| 3/26 [00:04<00:28,  1.24s/it]Epoch: 3/10. Loss: 0.9493:  15%|[36m█▌        [0m| 4/26 [00:04<00:24,  1.11s/it]Epoch: 3/10. Loss: 0.9769:  15%|[36m█▌        [0m| 4/26 [00:05<00:24,  1.11s/it]Epoch: 3/10. Loss: 0.9769:  19%|[36m█▉        [0m| 5/26 [00:05<00:22,  1.08s/it]Epoch: 3/10. Loss: 0.8618:  19%|[36m█▉        [0m| 5/26 [00:06<00:22,  1.08s/it]Epoch: 3/10. Loss: 0.8618:  23%|[36m██▎       [0m| 6/26 [00:06<00:19,  1.03it/s]Epoch: 3/10. Loss: 0.8999:  23%|[36m██▎       [0m| 6/26 [00:06<00:19,  1.03it/s]Epoch: 3/10. Loss: 0.8999:  27%|[36m██▋       [0m| 7/26 [00:06<00:17,  1.10it/s]Epoch: 3/10. Loss: 0.8384:  27%|[36m██▋       [0m| 7/26 [00:07<00:17,  1.10it/s]Epoch: 3/10. Loss: 0.8384:  31%|[36m███       [0m| 8/26 [00:07<00:16,  1.11it/s]Epoch: 3/10. Loss: 0.9291:  31%|[36m███       [0m| 8/26 [00:08<00:16,  1.11it/s]Epoch: 3/10. Loss: 0.9291:  35%|[36m███▍      [0m| 9/26 [00:08<00:15,  1.10it/s]Epoch: 3/10. Loss: 0.8768:  35%|[36m███▍      [0m| 9/26 [00:09<00:15,  1.10it/s]Epoch: 3/10. Loss: 0.8768:  38%|[36m███▊      [0m| 10/26 [00:09<00:14,  1.11it/s]Epoch: 3/10. Loss: 0.8078:  38%|[36m███▊      [0m| 10/26 [00:10<00:14,  1.11it/s]Epoch: 3/10. Loss: 0.8078:  42%|[36m████▏     [0m| 11/26 [00:10<00:13,  1.07it/s]Epoch: 3/10. Loss: 1.0623:  42%|[36m████▏     [0m| 11/26 [00:11<00:13,  1.07it/s]Epoch: 3/10. Loss: 1.0623:  46%|[36m████▌     [0m| 12/26 [00:11<00:12,  1.11it/s]Epoch: 3/10. Loss: 0.8904:  46%|[36m████▌     [0m| 12/26 [00:12<00:12,  1.11it/s]Epoch: 3/10. Loss: 0.8904:  50%|[36m█████     [0m| 13/26 [00:12<00:11,  1.09it/s]Epoch: 3/10. Loss: 0.9653:  50%|[36m█████     [0m| 13/26 [00:13<00:11,  1.09it/s]Epoch: 3/10. Loss: 0.9653:  54%|[36m█████▍    [0m| 14/26 [00:13<00:10,  1.12it/s]Epoch: 3/10. Loss: 0.9070:  54%|[36m█████▍    [0m| 14/26 [00:14<00:10,  1.12it/s]Epoch: 3/10. Loss: 0.9070:  58%|[36m█████▊    [0m| 15/26 [00:14<00:09,  1.17it/s]Epoch: 3/10. Loss: 0.9149:  58%|[36m█████▊    [0m| 15/26 [00:14<00:09,  1.17it/s]Epoch: 3/10. Loss: 0.9149:  62%|[36m██████▏   [0m| 16/26 [00:14<00:08,  1.21it/s]Epoch: 3/10. Loss: 0.9562:  62%|[36m██████▏   [0m| 16/26 [00:15<00:08,  1.21it/s]Epoch: 3/10. Loss: 0.9562:  65%|[36m██████▌   [0m| 17/26 [00:15<00:07,  1.25it/s]Epoch: 3/10. Loss: 0.9154:  65%|[36m██████▌   [0m| 17/26 [00:16<00:07,  1.25it/s]Epoch: 3/10. Loss: 0.9154:  69%|[36m██████▉   [0m| 18/26 [00:16<00:06,  1.23it/s]Epoch: 3/10. Loss: 0.8923:  69%|[36m██████▉   [0m| 18/26 [00:17<00:06,  1.23it/s]Epoch: 3/10. Loss: 0.8923:  73%|[36m███████▎  [0m| 19/26 [00:17<00:06,  1.09it/s]Epoch: 3/10. Loss: 0.9905:  73%|[36m███████▎  [0m| 19/26 [00:18<00:06,  1.09it/s]Epoch: 3/10. Loss: 0.9905:  77%|[36m███████▋  [0m| 20/26 [00:18<00:05,  1.07it/s]Epoch: 3/10. Loss: 0.9005:  77%|[36m███████▋  [0m| 20/26 [00:19<00:05,  1.07it/s]Epoch: 3/10. Loss: 0.9005:  81%|[36m████████  [0m| 21/26 [00:19<00:04,  1.07it/s]Epoch: 3/10. Loss: 0.9102:  81%|[36m████████  [0m| 21/26 [00:20<00:04,  1.07it/s]Epoch: 3/10. Loss: 0.9102:  85%|[36m████████▍ [0m| 22/26 [00:20<00:03,  1.13it/s]Epoch: 3/10. Loss: 0.9383:  85%|[36m████████▍ [0m| 22/26 [00:21<00:03,  1.13it/s]Epoch: 3/10. Loss: 0.9383:  88%|[36m████████▊ [0m| 23/26 [00:21<00:02,  1.07it/s]Epoch: 3/10. Loss: 0.9092:  88%|[36m████████▊ [0m| 23/26 [00:22<00:02,  1.07it/s]Epoch: 3/10. Loss: 0.9092:  92%|[36m█████████▏[0m| 24/26 [00:22<00:01,  1.04it/s]Epoch: 3/10. Loss: 0.9462:  92%|[36m█████████▏[0m| 24/26 [00:23<00:01,  1.04it/s]Epoch: 3/10. Loss: 0.9462:  96%|[36m█████████▌[0m| 25/26 [00:23<00:00,  1.10it/s]Epoch: 3/10. Loss: 1.0246:  96%|[36m█████████▌[0m| 25/26 [00:23<00:00,  1.10it/s]Epoch: 3/10. Loss: 1.0246: 100%|[36m██████████[0m| 26/26 [00:23<00:00,  1.26it/s]Epoch: 3/10. Loss: 1.0246: 100%|[36m██████████[0m| 26/26 [00:23<00:00,  1.10it/s]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:04,  1.36it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:05,  1.14s/it] 43%|[33m████▎     [0m| 3/7 [00:02<00:03,  1.08it/s] 57%|[33m█████▋    [0m| 4/7 [00:05<00:05,  1.75s/it] 71%|[33m███████▏  [0m| 5/7 [00:06<00:02,  1.31s/it] 86%|[33m████████▌ [0m| 6/7 [00:08<00:01,  1.49s/it]100%|[33m██████████[0m| 7/7 [00:08<00:00,  1.10s/it]100%|[33m██████████[0m| 7/7 [00:08<00:00,  1.22s/it]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 4/10. Loss: 0.9176:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 4/10. Loss: 0.9176:   4%|[36m▍         [0m| 1/26 [00:00<00:20,  1.23it/s]Epoch: 4/10. Loss: 1.0287:   4%|[36m▍         [0m| 1/26 [00:01<00:20,  1.23it/s]Epoch: 4/10. Loss: 1.0287:   8%|[36m▊         [0m| 2/26 [00:01<00:19,  1.26it/s]Epoch: 4/10. Loss: 0.9436:   8%|[36m▊         [0m| 2/26 [00:03<00:19,  1.26it/s]Epoch: 4/10. Loss: 0.9436:  12%|[36m█▏        [0m| 3/26 [00:03<00:26,  1.15s/it]Epoch: 4/10. Loss: 0.8721:  12%|[36m█▏        [0m| 3/26 [00:04<00:26,  1.15s/it]Epoch: 4/10. Loss: 0.8721:  15%|[36m█▌        [0m| 4/26 [00:04<00:23,  1.08s/it]Epoch: 4/10. Loss: 1.0403:  15%|[36m█▌        [0m| 4/26 [00:04<00:23,  1.08s/it]Epoch: 4/10. Loss: 1.0403:  19%|[36m█▉        [0m| 5/26 [00:05<00:21,  1.00s/it]Epoch: 4/10. Loss: 0.9233:  19%|[36m█▉        [0m| 5/26 [00:08<00:21,  1.00s/it]Epoch: 4/10. Loss: 0.9233:  23%|[36m██▎       [0m| 6/26 [00:08<00:33,  1.70s/it]Epoch: 4/10. Loss: 0.9043:  23%|[36m██▎       [0m| 6/26 [00:08<00:33,  1.70s/it]Epoch: 4/10. Loss: 0.9043:  27%|[36m██▋       [0m| 7/26 [00:09<00:27,  1.45s/it]Epoch: 4/10. Loss: 0.9838:  27%|[36m██▋       [0m| 7/26 [00:09<00:27,  1.45s/it]Epoch: 4/10. Loss: 0.9838:  31%|[36m███       [0m| 8/26 [00:09<00:23,  1.28s/it]Epoch: 4/10. Loss: 0.9106:  31%|[36m███       [0m| 8/26 [00:11<00:23,  1.28s/it]Epoch: 4/10. Loss: 0.9106:  35%|[36m███▍      [0m| 9/26 [00:11<00:22,  1.34s/it]Epoch: 4/10. Loss: 0.9191:  35%|[36m███▍      [0m| 9/26 [00:12<00:22,  1.34s/it]Epoch: 4/10. Loss: 0.9191:  38%|[36m███▊      [0m| 10/26 [00:12<00:19,  1.25s/it]Epoch: 4/10. Loss: 0.8824:  38%|[36m███▊      [0m| 10/26 [00:13<00:19,  1.25s/it]Epoch: 4/10. Loss: 0.8824:  42%|[36m████▏     [0m| 11/26 [00:13<00:17,  1.15s/it]Epoch: 4/10. Loss: 0.8128:  42%|[36m████▏     [0m| 11/26 [00:14<00:17,  1.15s/it]Epoch: 4/10. Loss: 0.8128:  46%|[36m████▌     [0m| 12/26 [00:14<00:16,  1.17s/it]Epoch: 4/10. Loss: 0.8158:  46%|[36m████▌     [0m| 12/26 [00:15<00:16,  1.17s/it]Epoch: 4/10. Loss: 0.8158:  50%|[36m█████     [0m| 13/26 [00:15<00:13,  1.06s/it]Epoch: 4/10. Loss: 0.9032:  50%|[36m█████     [0m| 13/26 [00:16<00:13,  1.06s/it]Epoch: 4/10. Loss: 0.9032:  54%|[36m█████▍    [0m| 14/26 [00:16<00:11,  1.02it/s]Epoch: 4/10. Loss: 0.8915:  54%|[36m█████▍    [0m| 14/26 [00:17<00:11,  1.02it/s]Epoch: 4/10. Loss: 0.8915:  58%|[36m█████▊    [0m| 15/26 [00:17<00:10,  1.05it/s]Epoch: 4/10. Loss: 0.9158:  58%|[36m█████▊    [0m| 15/26 [00:17<00:10,  1.05it/s]Epoch: 4/10. Loss: 0.9158:  62%|[36m██████▏   [0m| 16/26 [00:17<00:08,  1.16it/s]Epoch: 4/10. Loss: 0.9928:  62%|[36m██████▏   [0m| 16/26 [00:18<00:08,  1.16it/s]Epoch: 4/10. Loss: 0.9928:  65%|[36m██████▌   [0m| 17/26 [00:18<00:07,  1.13it/s]Epoch: 4/10. Loss: 0.8436:  65%|[36m██████▌   [0m| 17/26 [00:19<00:07,  1.13it/s]Epoch: 4/10. Loss: 0.8436:  69%|[36m██████▉   [0m| 18/26 [00:19<00:07,  1.13it/s]Epoch: 4/10. Loss: 0.9432:  69%|[36m██████▉   [0m| 18/26 [00:20<00:07,  1.13it/s]Epoch: 4/10. Loss: 0.9432:  73%|[36m███████▎  [0m| 19/26 [00:20<00:06,  1.16it/s]Epoch: 4/10. Loss: 0.8062:  73%|[36m███████▎  [0m| 19/26 [00:21<00:06,  1.16it/s]Epoch: 4/10. Loss: 0.8062:  77%|[36m███████▋  [0m| 20/26 [00:21<00:04,  1.21it/s]Epoch: 4/10. Loss: 0.8826:  77%|[36m███████▋  [0m| 20/26 [00:21<00:04,  1.21it/s]Epoch: 4/10. Loss: 0.8826:  81%|[36m████████  [0m| 21/26 [00:21<00:03,  1.26it/s]Epoch: 4/10. Loss: 0.8584:  81%|[36m████████  [0m| 21/26 [00:22<00:03,  1.26it/s]Epoch: 4/10. Loss: 0.8584:  85%|[36m████████▍ [0m| 22/26 [00:22<00:03,  1.22it/s]Epoch: 4/10. Loss: 0.8497:  85%|[36m████████▍ [0m| 22/26 [00:23<00:03,  1.22it/s]Epoch: 4/10. Loss: 0.8497:  88%|[36m████████▊ [0m| 23/26 [00:23<00:02,  1.21it/s]Epoch: 4/10. Loss: 1.0006:  88%|[36m████████▊ [0m| 23/26 [00:24<00:02,  1.21it/s]Epoch: 4/10. Loss: 1.0006:  92%|[36m█████████▏[0m| 24/26 [00:24<00:01,  1.09it/s]Epoch: 4/10. Loss: 0.8526:  92%|[36m█████████▏[0m| 24/26 [00:25<00:01,  1.09it/s]Epoch: 4/10. Loss: 0.8526:  96%|[36m█████████▌[0m| 25/26 [00:25<00:00,  1.09it/s]Epoch: 4/10. Loss: 0.8598:  96%|[36m█████████▌[0m| 25/26 [00:26<00:00,  1.09it/s]Epoch: 4/10. Loss: 0.8598: 100%|[36m██████████[0m| 26/26 [00:26<00:00,  1.23it/s]Epoch: 4/10. Loss: 0.8598: 100%|[36m██████████[0m| 26/26 [00:26<00:00,  1.01s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:04,  1.33it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:05,  1.11s/it] 43%|[33m████▎     [0m| 3/7 [00:05<00:07,  1.94s/it] 57%|[33m█████▋    [0m| 4/7 [00:06<00:05,  1.74s/it] 71%|[33m███████▏  [0m| 5/7 [00:06<00:02,  1.29s/it] 86%|[33m████████▌ [0m| 6/7 [00:07<00:01,  1.14s/it]100%|[33m██████████[0m| 7/7 [00:08<00:00,  1.15it/s]100%|[33m██████████[0m| 7/7 [00:08<00:00,  1.16s/it]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 5/10. Loss: 0.9023:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 5/10. Loss: 0.9023:   4%|[36m▍         [0m| 1/26 [00:00<00:20,  1.20it/s]Epoch: 5/10. Loss: 0.8393:   4%|[36m▍         [0m| 1/26 [00:01<00:20,  1.20it/s]Epoch: 5/10. Loss: 0.8393:   8%|[36m▊         [0m| 2/26 [00:01<00:24,  1.00s/it]Epoch: 5/10. Loss: 0.8879:   8%|[36m▊         [0m| 2/26 [00:02<00:24,  1.00s/it]Epoch: 5/10. Loss: 0.8879:  12%|[36m█▏        [0m| 3/26 [00:02<00:22,  1.03it/s]Epoch: 5/10. Loss: 0.8697:  12%|[36m█▏        [0m| 3/26 [00:03<00:22,  1.03it/s]Epoch: 5/10. Loss: 0.8697:  15%|[36m█▌        [0m| 4/26 [00:03<00:20,  1.07it/s]Epoch: 5/10. Loss: 0.9181:  15%|[36m█▌        [0m| 4/26 [00:05<00:20,  1.07it/s]Epoch: 5/10. Loss: 0.9181:  19%|[36m█▉        [0m| 5/26 [00:05<00:26,  1.26s/it]Epoch: 5/10. Loss: 0.8855:  19%|[36m█▉        [0m| 5/26 [00:06<00:26,  1.26s/it]Epoch: 5/10. Loss: 0.8855:  23%|[36m██▎       [0m| 6/26 [00:06<00:21,  1.05s/it]Epoch: 5/10. Loss: 0.8158:  23%|[36m██▎       [0m| 6/26 [00:07<00:21,  1.05s/it]Epoch: 5/10. Loss: 0.8158:  27%|[36m██▋       [0m| 7/26 [00:07<00:18,  1.04it/s]Epoch: 5/10. Loss: 0.8691:  27%|[36m██▋       [0m| 7/26 [00:07<00:18,  1.04it/s]Epoch: 5/10. Loss: 0.8691:  31%|[36m███       [0m| 8/26 [00:07<00:17,  1.05it/s]Epoch: 5/10. Loss: 0.8758:  31%|[36m███       [0m| 8/26 [00:09<00:17,  1.05it/s]Epoch: 5/10. Loss: 0.8758:  35%|[36m███▍      [0m| 9/26 [00:09<00:17,  1.06s/it]Epoch: 5/10. Loss: 0.8379:  35%|[36m███▍      [0m| 9/26 [00:09<00:17,  1.06s/it]Epoch: 5/10. Loss: 0.8379:  38%|[36m███▊      [0m| 10/26 [00:09<00:15,  1.05it/s]Epoch: 5/10. Loss: 0.8837:  38%|[36m███▊      [0m| 10/26 [00:11<00:15,  1.05it/s]Epoch: 5/10. Loss: 0.8837:  42%|[36m████▏     [0m| 11/26 [00:11<00:15,  1.03s/it]Epoch: 5/10. Loss: 0.7670:  42%|[36m████▏     [0m| 11/26 [00:12<00:15,  1.03s/it]Epoch: 5/10. Loss: 0.7670:  46%|[36m████▌     [0m| 12/26 [00:12<00:13,  1.02it/s]Epoch: 5/10. Loss: 0.8757:  46%|[36m████▌     [0m| 12/26 [00:13<00:13,  1.02it/s]Epoch: 5/10. Loss: 0.8757:  50%|[36m█████     [0m| 13/26 [00:13<00:12,  1.01it/s]Epoch: 5/10. Loss: 0.8234:  50%|[36m█████     [0m| 13/26 [00:13<00:12,  1.01it/s]Epoch: 5/10. Loss: 0.8234:  54%|[36m█████▍    [0m| 14/26 [00:14<00:11,  1.02it/s]Epoch: 5/10. Loss: 0.9376:  54%|[36m█████▍    [0m| 14/26 [00:14<00:11,  1.02it/s]Epoch: 5/10. Loss: 0.9376:  58%|[36m█████▊    [0m| 15/26 [00:14<00:10,  1.05it/s]Epoch: 5/10. Loss: 0.8712:  58%|[36m█████▊    [0m| 15/26 [00:15<00:10,  1.05it/s]Epoch: 5/10. Loss: 0.8712:  62%|[36m██████▏   [0m| 16/26 [00:15<00:09,  1.01it/s]Epoch: 5/10. Loss: 0.9298:  62%|[36m██████▏   [0m| 16/26 [00:16<00:09,  1.01it/s]Epoch: 5/10. Loss: 0.9298:  65%|[36m██████▌   [0m| 17/26 [00:16<00:08,  1.07it/s]Epoch: 5/10. Loss: 0.9424:  65%|[36m██████▌   [0m| 17/26 [00:17<00:08,  1.07it/s]Epoch: 5/10. Loss: 0.9424:  69%|[36m██████▉   [0m| 18/26 [00:17<00:07,  1.14it/s]Epoch: 5/10. Loss: 0.8821:  69%|[36m██████▉   [0m| 18/26 [00:18<00:07,  1.14it/s]Epoch: 5/10. Loss: 0.8821:  73%|[36m███████▎  [0m| 19/26 [00:18<00:06,  1.11it/s]Epoch: 5/10. Loss: 0.9049:  73%|[36m███████▎  [0m| 19/26 [00:19<00:06,  1.11it/s]Epoch: 5/10. Loss: 0.9049:  77%|[36m███████▋  [0m| 20/26 [00:19<00:05,  1.06it/s]Epoch: 5/10. Loss: 0.8674:  77%|[36m███████▋  [0m| 20/26 [00:20<00:05,  1.06it/s]Epoch: 5/10. Loss: 0.8674:  81%|[36m████████  [0m| 21/26 [00:20<00:04,  1.09it/s]Epoch: 5/10. Loss: 0.9201:  81%|[36m████████  [0m| 21/26 [00:21<00:04,  1.09it/s]Epoch: 5/10. Loss: 0.9201:  85%|[36m████████▍ [0m| 22/26 [00:21<00:03,  1.12it/s]Epoch: 5/10. Loss: 0.8149:  85%|[36m████████▍ [0m| 22/26 [00:22<00:03,  1.12it/s]Epoch: 5/10. Loss: 0.8149:  88%|[36m████████▊ [0m| 23/26 [00:22<00:02,  1.15it/s]Epoch: 5/10. Loss: 0.7919:  88%|[36m████████▊ [0m| 23/26 [00:23<00:02,  1.15it/s]Epoch: 5/10. Loss: 0.7919:  92%|[36m█████████▏[0m| 24/26 [00:23<00:01,  1.11it/s]Epoch: 5/10. Loss: 0.8621:  92%|[36m█████████▏[0m| 24/26 [00:23<00:01,  1.11it/s]Epoch: 5/10. Loss: 0.8621:  96%|[36m█████████▌[0m| 25/26 [00:23<00:00,  1.11it/s]Epoch: 5/10. Loss: 0.7901:  96%|[36m█████████▌[0m| 25/26 [00:24<00:00,  1.11it/s]Epoch: 5/10. Loss: 0.7901: 100%|[36m██████████[0m| 26/26 [00:24<00:00,  1.27it/s]Epoch: 5/10. Loss: 0.7901: 100%|[36m██████████[0m| 26/26 [00:24<00:00,  1.06it/s]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:04,  1.28it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:05,  1.10s/it] 43%|[33m████▎     [0m| 3/7 [00:02<00:03,  1.10it/s] 57%|[33m█████▋    [0m| 4/7 [00:03<00:02,  1.00it/s] 71%|[33m███████▏  [0m| 5/7 [00:04<00:01,  1.22it/s] 86%|[33m████████▌ [0m| 6/7 [00:05<00:00,  1.20it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.52it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.25it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 6/10. Loss: 0.7742:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 6/10. Loss: 0.7742:   4%|[36m▍         [0m| 1/26 [00:00<00:20,  1.25it/s]Epoch: 6/10. Loss: 0.7706:   4%|[36m▍         [0m| 1/26 [00:01<00:20,  1.25it/s]Epoch: 6/10. Loss: 0.7706:   8%|[36m▊         [0m| 2/26 [00:01<00:19,  1.23it/s]Epoch: 6/10. Loss: 0.8321:   8%|[36m▊         [0m| 2/26 [00:02<00:19,  1.23it/s]Epoch: 6/10. Loss: 0.8321:  12%|[36m█▏        [0m| 3/26 [00:02<00:20,  1.13it/s]Epoch: 6/10. Loss: 0.8506:  12%|[36m█▏        [0m| 3/26 [00:03<00:20,  1.13it/s]Epoch: 6/10. Loss: 0.8506:  15%|[36m█▌        [0m| 4/26 [00:03<00:20,  1.07it/s]Epoch: 6/10. Loss: 0.9216:  15%|[36m█▌        [0m| 4/26 [00:04<00:20,  1.07it/s]Epoch: 6/10. Loss: 0.9216:  19%|[36m█▉        [0m| 5/26 [00:04<00:18,  1.15it/s]Epoch: 6/10. Loss: 0.8814:  19%|[36m█▉        [0m| 5/26 [00:05<00:18,  1.15it/s]Epoch: 6/10. Loss: 0.8814:  23%|[36m██▎       [0m| 6/26 [00:05<00:17,  1.17it/s]Epoch: 6/10. Loss: 0.8977:  23%|[36m██▎       [0m| 6/26 [00:06<00:17,  1.17it/s]Epoch: 6/10. Loss: 0.8977:  27%|[36m██▋       [0m| 7/26 [00:06<00:16,  1.12it/s]Epoch: 6/10. Loss: 0.8560:  27%|[36m██▋       [0m| 7/26 [00:07<00:16,  1.12it/s]Epoch: 6/10. Loss: 0.8560:  31%|[36m███       [0m| 8/26 [00:07<00:16,  1.12it/s]Epoch: 6/10. Loss: 0.9314:  31%|[36m███       [0m| 8/26 [00:07<00:16,  1.12it/s]Epoch: 6/10. Loss: 0.9314:  35%|[36m███▍      [0m| 9/26 [00:07<00:15,  1.11it/s]Epoch: 6/10. Loss: 0.8172:  35%|[36m███▍      [0m| 9/26 [00:08<00:15,  1.11it/s]Epoch: 6/10. Loss: 0.8172:  38%|[36m███▊      [0m| 10/26 [00:08<00:13,  1.18it/s]Epoch: 6/10. Loss: 0.9243:  38%|[36m███▊      [0m| 10/26 [00:09<00:13,  1.18it/s]Epoch: 6/10. Loss: 0.9243:  42%|[36m████▏     [0m| 11/26 [00:09<00:12,  1.19it/s]Epoch: 6/10. Loss: 1.0726:  42%|[36m████▏     [0m| 11/26 [00:10<00:12,  1.19it/s]Epoch: 6/10. Loss: 1.0726:  46%|[36m████▌     [0m| 12/26 [00:10<00:11,  1.17it/s]Epoch: 6/10. Loss: 0.9610:  46%|[36m████▌     [0m| 12/26 [00:11<00:11,  1.17it/s]Epoch: 6/10. Loss: 0.9610:  50%|[36m█████     [0m| 13/26 [00:11<00:10,  1.20it/s]Epoch: 6/10. Loss: 0.9079:  50%|[36m█████     [0m| 13/26 [00:12<00:10,  1.20it/s]Epoch: 6/10. Loss: 0.9079:  54%|[36m█████▍    [0m| 14/26 [00:12<00:11,  1.08it/s]Epoch: 6/10. Loss: 0.8432:  54%|[36m█████▍    [0m| 14/26 [00:13<00:11,  1.08it/s]Epoch: 6/10. Loss: 0.8432:  58%|[36m█████▊    [0m| 15/26 [00:13<00:10,  1.03it/s]Epoch: 6/10. Loss: 0.9091:  58%|[36m█████▊    [0m| 15/26 [00:14<00:10,  1.03it/s]Epoch: 6/10. Loss: 0.9091:  62%|[36m██████▏   [0m| 16/26 [00:14<00:09,  1.05it/s]Epoch: 6/10. Loss: 0.8315:  62%|[36m██████▏   [0m| 16/26 [00:15<00:09,  1.05it/s]Epoch: 6/10. Loss: 0.8315:  65%|[36m██████▌   [0m| 17/26 [00:15<00:08,  1.07it/s]Epoch: 6/10. Loss: 0.8641:  65%|[36m██████▌   [0m| 17/26 [00:16<00:08,  1.07it/s]Epoch: 6/10. Loss: 0.8641:  69%|[36m██████▉   [0m| 18/26 [00:16<00:08,  1.02s/it]Epoch: 6/10. Loss: 0.8480:  69%|[36m██████▉   [0m| 18/26 [00:17<00:08,  1.02s/it]Epoch: 6/10. Loss: 0.8480:  73%|[36m███████▎  [0m| 19/26 [00:17<00:07,  1.13s/it]Epoch: 6/10. Loss: 0.8245:  73%|[36m███████▎  [0m| 19/26 [00:18<00:07,  1.13s/it]Epoch: 6/10. Loss: 0.8245:  77%|[36m███████▋  [0m| 20/26 [00:18<00:06,  1.08s/it]Epoch: 6/10. Loss: 0.8385:  77%|[36m███████▋  [0m| 20/26 [00:19<00:06,  1.08s/it]Epoch: 6/10. Loss: 0.8385:  81%|[36m████████  [0m| 21/26 [00:19<00:04,  1.03it/s]Epoch: 6/10. Loss: 0.9257:  81%|[36m████████  [0m| 21/26 [00:20<00:04,  1.03it/s]Epoch: 6/10. Loss: 0.9257:  85%|[36m████████▍ [0m| 22/26 [00:20<00:03,  1.04it/s]Epoch: 6/10. Loss: 0.9167:  85%|[36m████████▍ [0m| 22/26 [00:21<00:03,  1.04it/s]Epoch: 6/10. Loss: 0.9167:  88%|[36m████████▊ [0m| 23/26 [00:21<00:02,  1.07it/s]Epoch: 6/10. Loss: 0.8665:  88%|[36m████████▊ [0m| 23/26 [00:22<00:02,  1.07it/s]Epoch: 6/10. Loss: 0.8665:  92%|[36m█████████▏[0m| 24/26 [00:22<00:01,  1.09it/s]Epoch: 6/10. Loss: 0.9332:  92%|[36m█████████▏[0m| 24/26 [00:23<00:01,  1.09it/s]Epoch: 6/10. Loss: 0.9332:  96%|[36m█████████▌[0m| 25/26 [00:23<00:00,  1.11it/s]Epoch: 6/10. Loss: 0.8459:  96%|[36m█████████▌[0m| 25/26 [00:23<00:00,  1.11it/s]Epoch: 6/10. Loss: 0.8459: 100%|[36m██████████[0m| 26/26 [00:23<00:00,  1.23it/s]Epoch: 6/10. Loss: 0.8459: 100%|[36m██████████[0m| 26/26 [00:23<00:00,  1.10it/s]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:01<00:07,  1.24s/it] 29%|[33m██▊       [0m| 2/7 [00:02<00:06,  1.31s/it] 43%|[33m████▎     [0m| 3/7 [00:03<00:04,  1.10s/it] 57%|[33m█████▋    [0m| 4/7 [00:04<00:03,  1.12s/it] 71%|[33m███████▏  [0m| 5/7 [00:05<00:01,  1.11it/s] 86%|[33m████████▌ [0m| 6/7 [00:06<00:01,  1.16s/it]100%|[33m██████████[0m| 7/7 [00:07<00:00,  1.13it/s]100%|[33m██████████[0m| 7/7 [00:07<00:00,  1.01s/it]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 7/10. Loss: 0.8623:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 7/10. Loss: 0.8623:   4%|[36m▍         [0m| 1/26 [00:00<00:24,  1.04it/s]Epoch: 7/10. Loss: 0.8140:   4%|[36m▍         [0m| 1/26 [00:02<00:24,  1.04it/s]Epoch: 7/10. Loss: 0.8140:   8%|[36m▊         [0m| 2/26 [00:02<00:25,  1.05s/it]Epoch: 7/10. Loss: 0.8957:   8%|[36m▊         [0m| 2/26 [00:03<00:25,  1.05s/it]Epoch: 7/10. Loss: 0.8957:  12%|[36m█▏        [0m| 3/26 [00:03<00:25,  1.12s/it]Epoch: 7/10. Loss: 0.8502:  12%|[36m█▏        [0m| 3/26 [00:04<00:25,  1.12s/it]Epoch: 7/10. Loss: 0.8502:  15%|[36m█▌        [0m| 4/26 [00:04<00:22,  1.01s/it]Epoch: 7/10. Loss: 0.8648:  15%|[36m█▌        [0m| 4/26 [00:05<00:22,  1.01s/it]Epoch: 7/10. Loss: 0.8648:  19%|[36m█▉        [0m| 5/26 [00:05<00:20,  1.02it/s]Epoch: 7/10. Loss: 0.8499:  19%|[36m█▉        [0m| 5/26 [00:06<00:20,  1.02it/s]Epoch: 7/10. Loss: 0.8499:  23%|[36m██▎       [0m| 6/26 [00:06<00:19,  1.01it/s]Epoch: 7/10. Loss: 0.9344:  23%|[36m██▎       [0m| 6/26 [00:06<00:19,  1.01it/s]Epoch: 7/10. Loss: 0.9344:  27%|[36m██▋       [0m| 7/26 [00:06<00:18,  1.04it/s]Epoch: 7/10. Loss: 0.8472:  27%|[36m██▋       [0m| 7/26 [00:07<00:18,  1.04it/s]Epoch: 7/10. Loss: 0.8472:  31%|[36m███       [0m| 8/26 [00:07<00:16,  1.07it/s]Epoch: 7/10. Loss: 1.0021:  31%|[36m███       [0m| 8/26 [00:08<00:16,  1.07it/s]Epoch: 7/10. Loss: 1.0021:  35%|[36m███▍      [0m| 9/26 [00:08<00:15,  1.10it/s]Epoch: 7/10. Loss: 0.8218:  35%|[36m███▍      [0m| 9/26 [00:09<00:15,  1.10it/s]Epoch: 7/10. Loss: 0.8218:  38%|[36m███▊      [0m| 10/26 [00:09<00:13,  1.15it/s]Epoch: 7/10. Loss: 0.9650:  38%|[36m███▊      [0m| 10/26 [00:10<00:13,  1.15it/s]Epoch: 7/10. Loss: 0.9650:  42%|[36m████▏     [0m| 11/26 [00:10<00:14,  1.06it/s]Epoch: 7/10. Loss: 0.8999:  42%|[36m████▏     [0m| 11/26 [00:13<00:14,  1.06it/s]Epoch: 7/10. Loss: 0.8999:  46%|[36m████▌     [0m| 12/26 [00:13<00:20,  1.47s/it]Epoch: 7/10. Loss: 0.8178:  46%|[36m████▌     [0m| 12/26 [00:14<00:20,  1.47s/it]Epoch: 7/10. Loss: 0.8178:  50%|[36m█████     [0m| 13/26 [00:14<00:18,  1.39s/it]Epoch: 7/10. Loss: 0.9532:  50%|[36m█████     [0m| 13/26 [00:15<00:18,  1.39s/it]Epoch: 7/10. Loss: 0.9532:  54%|[36m█████▍    [0m| 14/26 [00:15<00:14,  1.21s/it]Epoch: 7/10. Loss: 0.8601:  54%|[36m█████▍    [0m| 14/26 [00:16<00:14,  1.21s/it]Epoch: 7/10. Loss: 0.8601:  58%|[36m█████▊    [0m| 15/26 [00:16<00:12,  1.11s/it]Epoch: 7/10. Loss: 0.7920:  58%|[36m█████▊    [0m| 15/26 [00:16<00:12,  1.11s/it]Epoch: 7/10. Loss: 0.7920:  62%|[36m██████▏   [0m| 16/26 [00:16<00:10,  1.04s/it]Epoch: 7/10. Loss: 0.7695:  62%|[36m██████▏   [0m| 16/26 [00:17<00:10,  1.04s/it]Epoch: 7/10. Loss: 0.7695:  65%|[36m██████▌   [0m| 17/26 [00:17<00:08,  1.05it/s]Epoch: 7/10. Loss: 0.8303:  65%|[36m██████▌   [0m| 17/26 [00:18<00:08,  1.05it/s]Epoch: 7/10. Loss: 0.8303:  69%|[36m██████▉   [0m| 18/26 [00:18<00:07,  1.09it/s]Epoch: 7/10. Loss: 0.9213:  69%|[36m██████▉   [0m| 18/26 [00:19<00:07,  1.09it/s]Epoch: 7/10. Loss: 0.9213:  73%|[36m███████▎  [0m| 19/26 [00:19<00:06,  1.16it/s]Epoch: 7/10. Loss: 0.7560:  73%|[36m███████▎  [0m| 19/26 [00:20<00:06,  1.16it/s]Epoch: 7/10. Loss: 0.7560:  77%|[36m███████▋  [0m| 20/26 [00:20<00:04,  1.21it/s]Epoch: 7/10. Loss: 0.9440:  77%|[36m███████▋  [0m| 20/26 [00:20<00:04,  1.21it/s]Epoch: 7/10. Loss: 0.9440:  81%|[36m████████  [0m| 21/26 [00:20<00:04,  1.22it/s]Epoch: 7/10. Loss: 0.9676:  81%|[36m████████  [0m| 21/26 [00:21<00:04,  1.22it/s]Epoch: 7/10. Loss: 0.9676:  85%|[36m████████▍ [0m| 22/26 [00:21<00:03,  1.21it/s]Epoch: 7/10. Loss: 0.7908:  85%|[36m████████▍ [0m| 22/26 [00:23<00:03,  1.21it/s]Epoch: 7/10. Loss: 0.7908:  88%|[36m████████▊ [0m| 23/26 [00:23<00:02,  1.02it/s]Epoch: 7/10. Loss: 0.7160:  88%|[36m████████▊ [0m| 23/26 [00:24<00:02,  1.02it/s]Epoch: 7/10. Loss: 0.7160:  92%|[36m█████████▏[0m| 24/26 [00:24<00:01,  1.02it/s]Epoch: 7/10. Loss: 0.8664:  92%|[36m█████████▏[0m| 24/26 [00:24<00:01,  1.02it/s]Epoch: 7/10. Loss: 0.8664:  96%|[36m█████████▌[0m| 25/26 [00:24<00:00,  1.04it/s]Epoch: 7/10. Loss: 0.8516:  96%|[36m█████████▌[0m| 25/26 [00:25<00:00,  1.04it/s]Epoch: 7/10. Loss: 0.8516: 100%|[36m██████████[0m| 26/26 [00:25<00:00,  1.16it/s]Epoch: 7/10. Loss: 0.8516: 100%|[36m██████████[0m| 26/26 [00:25<00:00,  1.02it/s]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:04,  1.24it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:05,  1.15s/it] 43%|[33m████▎     [0m| 3/7 [00:02<00:03,  1.07it/s] 57%|[33m█████▋    [0m| 4/7 [00:04<00:03,  1.02s/it] 71%|[33m███████▏  [0m| 5/7 [00:04<00:01,  1.19it/s] 86%|[33m████████▌ [0m| 6/7 [00:05<00:00,  1.09it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.42it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.19it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 8/10. Loss: 0.8476:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 8/10. Loss: 0.8476:   4%|[36m▍         [0m| 1/26 [00:00<00:23,  1.05it/s]Epoch: 8/10. Loss: 0.8439:   4%|[36m▍         [0m| 1/26 [00:02<00:23,  1.05it/s]Epoch: 8/10. Loss: 0.8439:   8%|[36m▊         [0m| 2/26 [00:02<00:35,  1.46s/it]Epoch: 8/10. Loss: 0.7754:   8%|[36m▊         [0m| 2/26 [00:03<00:35,  1.46s/it]Epoch: 8/10. Loss: 0.7754:  12%|[36m█▏        [0m| 3/26 [00:03<00:26,  1.16s/it]Epoch: 8/10. Loss: 0.8411:  12%|[36m█▏        [0m| 3/26 [00:04<00:26,  1.16s/it]Epoch: 8/10. Loss: 0.8411:  15%|[36m█▌        [0m| 4/26 [00:04<00:23,  1.07s/it]Epoch: 8/10. Loss: 0.8707:  15%|[36m█▌        [0m| 4/26 [00:05<00:23,  1.07s/it]Epoch: 8/10. Loss: 0.8707:  19%|[36m█▉        [0m| 5/26 [00:05<00:21,  1.02s/it]Epoch: 8/10. Loss: 0.8126:  19%|[36m█▉        [0m| 5/26 [00:06<00:21,  1.02s/it]Epoch: 8/10. Loss: 0.8126:  23%|[36m██▎       [0m| 6/26 [00:06<00:18,  1.06it/s]Epoch: 8/10. Loss: 0.6789:  23%|[36m██▎       [0m| 6/26 [00:07<00:18,  1.06it/s]Epoch: 8/10. Loss: 0.6789:  27%|[36m██▋       [0m| 7/26 [00:07<00:16,  1.13it/s]Epoch: 8/10. Loss: 0.7602:  27%|[36m██▋       [0m| 7/26 [00:07<00:16,  1.13it/s]Epoch: 8/10. Loss: 0.7602:  31%|[36m███       [0m| 8/26 [00:07<00:15,  1.17it/s]Epoch: 8/10. Loss: 0.7597:  31%|[36m███       [0m| 8/26 [00:09<00:15,  1.17it/s]Epoch: 8/10. Loss: 0.7597:  35%|[36m███▍      [0m| 9/26 [00:09<00:17,  1.01s/it]Epoch: 8/10. Loss: 0.8283:  35%|[36m███▍      [0m| 9/26 [00:10<00:17,  1.01s/it]Epoch: 8/10. Loss: 0.8283:  38%|[36m███▊      [0m| 10/26 [00:10<00:16,  1.01s/it]Epoch: 8/10. Loss: 0.8967:  38%|[36m███▊      [0m| 10/26 [00:11<00:16,  1.01s/it]Epoch: 8/10. Loss: 0.8967:  42%|[36m████▏     [0m| 11/26 [00:11<00:14,  1.00it/s]Epoch: 8/10. Loss: 0.7946:  42%|[36m████▏     [0m| 11/26 [00:11<00:14,  1.00it/s]Epoch: 8/10. Loss: 0.7946:  46%|[36m████▌     [0m| 12/26 [00:11<00:13,  1.04it/s]Epoch: 8/10. Loss: 0.7989:  46%|[36m████▌     [0m| 12/26 [00:12<00:13,  1.04it/s]Epoch: 8/10. Loss: 0.7989:  50%|[36m█████     [0m| 13/26 [00:12<00:12,  1.07it/s]Epoch: 8/10. Loss: 0.9297:  50%|[36m█████     [0m| 13/26 [00:13<00:12,  1.07it/s]Epoch: 8/10. Loss: 0.9297:  54%|[36m█████▍    [0m| 14/26 [00:13<00:11,  1.05it/s]Epoch: 8/10. Loss: 0.7532:  54%|[36m█████▍    [0m| 14/26 [00:14<00:11,  1.05it/s]Epoch: 8/10. Loss: 0.7532:  58%|[36m█████▊    [0m| 15/26 [00:14<00:10,  1.06it/s]Epoch: 8/10. Loss: 0.8019:  58%|[36m█████▊    [0m| 15/26 [00:15<00:10,  1.06it/s]Epoch: 8/10. Loss: 0.8019:  62%|[36m██████▏   [0m| 16/26 [00:15<00:09,  1.08it/s]Epoch: 8/10. Loss: 0.8885:  62%|[36m██████▏   [0m| 16/26 [00:16<00:09,  1.08it/s]Epoch: 8/10. Loss: 0.8885:  65%|[36m██████▌   [0m| 17/26 [00:16<00:07,  1.15it/s]Epoch: 8/10. Loss: 0.8568:  65%|[36m██████▌   [0m| 17/26 [00:17<00:07,  1.15it/s]Epoch: 8/10. Loss: 0.8568:  69%|[36m██████▉   [0m| 18/26 [00:17<00:08,  1.01s/it]Epoch: 8/10. Loss: 0.9791:  69%|[36m██████▉   [0m| 18/26 [00:18<00:08,  1.01s/it]Epoch: 8/10. Loss: 0.9791:  73%|[36m███████▎  [0m| 19/26 [00:18<00:06,  1.06it/s]Epoch: 8/10. Loss: 0.9823:  73%|[36m███████▎  [0m| 19/26 [00:19<00:06,  1.06it/s]Epoch: 8/10. Loss: 0.9823:  77%|[36m███████▋  [0m| 20/26 [00:19<00:05,  1.08it/s]Epoch: 8/10. Loss: 0.9062:  77%|[36m███████▋  [0m| 20/26 [00:20<00:05,  1.08it/s]Epoch: 8/10. Loss: 0.9062:  81%|[36m████████  [0m| 21/26 [00:20<00:04,  1.12it/s]Epoch: 8/10. Loss: 0.7556:  81%|[36m████████  [0m| 21/26 [00:21<00:04,  1.12it/s]Epoch: 8/10. Loss: 0.7556:  85%|[36m████████▍ [0m| 22/26 [00:21<00:03,  1.10it/s]Epoch: 8/10. Loss: 0.9138:  85%|[36m████████▍ [0m| 22/26 [00:22<00:03,  1.10it/s]Epoch: 8/10. Loss: 0.9138:  88%|[36m████████▊ [0m| 23/26 [00:22<00:03,  1.01s/it]Epoch: 8/10. Loss: 0.8874:  88%|[36m████████▊ [0m| 23/26 [00:23<00:03,  1.01s/it]Epoch: 8/10. Loss: 0.8874:  92%|[36m█████████▏[0m| 24/26 [00:23<00:01,  1.01it/s]Epoch: 8/10. Loss: 0.8578:  92%|[36m█████████▏[0m| 24/26 [00:24<00:01,  1.01it/s]Epoch: 8/10. Loss: 0.8578:  96%|[36m█████████▌[0m| 25/26 [00:24<00:01,  1.00s/it]Epoch: 8/10. Loss: 0.9319:  96%|[36m█████████▌[0m| 25/26 [00:25<00:01,  1.00s/it]Epoch: 8/10. Loss: 0.9319: 100%|[36m██████████[0m| 26/26 [00:25<00:00,  1.10it/s]Epoch: 8/10. Loss: 0.9319: 100%|[36m██████████[0m| 26/26 [00:25<00:00,  1.04it/s]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:04,  1.26it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:05,  1.14s/it] 43%|[33m████▎     [0m| 3/7 [00:02<00:03,  1.08it/s] 57%|[33m█████▋    [0m| 4/7 [00:04<00:03,  1.02s/it] 71%|[33m███████▏  [0m| 5/7 [00:05<00:02,  1.17s/it] 86%|[33m████████▌ [0m| 6/7 [00:06<00:01,  1.07s/it]100%|[33m██████████[0m| 7/7 [00:06<00:00,  1.23it/s]100%|[33m██████████[0m| 7/7 [00:06<00:00,  1.06it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 9/10. Loss: 0.8659:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 9/10. Loss: 0.8659:   4%|[36m▍         [0m| 1/26 [00:00<00:20,  1.21it/s]Epoch: 9/10. Loss: 0.7485:   4%|[36m▍         [0m| 1/26 [00:01<00:20,  1.21it/s]Epoch: 9/10. Loss: 0.7485:   8%|[36m▊         [0m| 2/26 [00:01<00:23,  1.04it/s]Epoch: 9/10. Loss: 0.7235:   8%|[36m▊         [0m| 2/26 [00:02<00:23,  1.04it/s]Epoch: 9/10. Loss: 0.7235:  12%|[36m█▏        [0m| 3/26 [00:02<00:21,  1.07it/s]Epoch: 9/10. Loss: 0.9276:  12%|[36m█▏        [0m| 3/26 [00:03<00:21,  1.07it/s]Epoch: 9/10. Loss: 0.9276:  15%|[36m█▌        [0m| 4/26 [00:03<00:20,  1.05it/s]Epoch: 9/10. Loss: 0.7407:  15%|[36m█▌        [0m| 4/26 [00:04<00:20,  1.05it/s]Epoch: 9/10. Loss: 0.7407:  19%|[36m█▉        [0m| 5/26 [00:04<00:18,  1.15it/s]Epoch: 9/10. Loss: 0.7035:  19%|[36m█▉        [0m| 5/26 [00:05<00:18,  1.15it/s]Epoch: 9/10. Loss: 0.7035:  23%|[36m██▎       [0m| 6/26 [00:05<00:18,  1.10it/s]Epoch: 9/10. Loss: 0.8535:  23%|[36m██▎       [0m| 6/26 [00:06<00:18,  1.10it/s]Epoch: 9/10. Loss: 0.8535:  27%|[36m██▋       [0m| 7/26 [00:06<00:18,  1.06it/s]Epoch: 9/10. Loss: 0.7926:  27%|[36m██▋       [0m| 7/26 [00:08<00:18,  1.06it/s]Epoch: 9/10. Loss: 0.7926:  31%|[36m███       [0m| 8/26 [00:08<00:21,  1.22s/it]Epoch: 9/10. Loss: 0.7898:  31%|[36m███       [0m| 8/26 [00:09<00:21,  1.22s/it]Epoch: 9/10. Loss: 0.7898:  35%|[36m███▍      [0m| 9/26 [00:09<00:18,  1.09s/it]Epoch: 9/10. Loss: 0.7861:  35%|[36m███▍      [0m| 9/26 [00:10<00:18,  1.09s/it]Epoch: 9/10. Loss: 0.7861:  38%|[36m███▊      [0m| 10/26 [00:10<00:18,  1.15s/it]Epoch: 9/10. Loss: 0.7447:  38%|[36m███▊      [0m| 10/26 [00:11<00:18,  1.15s/it]Epoch: 9/10. Loss: 0.7447:  42%|[36m████▏     [0m| 11/26 [00:11<00:15,  1.02s/it]Epoch: 9/10. Loss: 0.9463:  42%|[36m████▏     [0m| 11/26 [00:11<00:15,  1.02s/it]Epoch: 9/10. Loss: 0.9463:  46%|[36m████▌     [0m| 12/26 [00:11<00:13,  1.05it/s]Epoch: 9/10. Loss: 0.8168:  46%|[36m████▌     [0m| 12/26 [00:12<00:13,  1.05it/s]Epoch: 9/10. Loss: 0.8168:  50%|[36m█████     [0m| 13/26 [00:12<00:12,  1.05it/s]Epoch: 9/10. Loss: 0.7966:  50%|[36m█████     [0m| 13/26 [00:13<00:12,  1.05it/s]Epoch: 9/10. Loss: 0.7966:  54%|[36m█████▍    [0m| 14/26 [00:13<00:11,  1.03it/s]Epoch: 9/10. Loss: 0.8287:  54%|[36m█████▍    [0m| 14/26 [00:14<00:11,  1.03it/s]Epoch: 9/10. Loss: 0.8287:  58%|[36m█████▊    [0m| 15/26 [00:14<00:10,  1.08it/s]Epoch: 9/10. Loss: 0.7738:  58%|[36m█████▊    [0m| 15/26 [00:15<00:10,  1.08it/s]Epoch: 9/10. Loss: 0.7738:  62%|[36m██████▏   [0m| 16/26 [00:15<00:08,  1.11it/s]Epoch: 9/10. Loss: 0.8102:  62%|[36m██████▏   [0m| 16/26 [00:16<00:08,  1.11it/s]Epoch: 9/10. Loss: 0.8102:  65%|[36m██████▌   [0m| 17/26 [00:16<00:07,  1.19it/s]Epoch: 9/10. Loss: 0.7927:  65%|[36m██████▌   [0m| 17/26 [00:17<00:07,  1.19it/s]Epoch: 9/10. Loss: 0.7927:  69%|[36m██████▉   [0m| 18/26 [00:17<00:07,  1.13it/s]Epoch: 9/10. Loss: 0.8075:  69%|[36m██████▉   [0m| 18/26 [00:18<00:07,  1.13it/s]Epoch: 9/10. Loss: 0.8075:  73%|[36m███████▎  [0m| 19/26 [00:18<00:06,  1.15it/s]Epoch: 9/10. Loss: 0.8605:  73%|[36m███████▎  [0m| 19/26 [00:18<00:06,  1.15it/s]Epoch: 9/10. Loss: 0.8605:  77%|[36m███████▋  [0m| 20/26 [00:18<00:05,  1.18it/s]Epoch: 9/10. Loss: 0.8409:  77%|[36m███████▋  [0m| 20/26 [00:19<00:05,  1.18it/s]Epoch: 9/10. Loss: 0.8409:  81%|[36m████████  [0m| 21/26 [00:19<00:04,  1.15it/s]Epoch: 9/10. Loss: 0.7989:  81%|[36m████████  [0m| 21/26 [00:21<00:04,  1.15it/s]Epoch: 9/10. Loss: 0.7989:  85%|[36m████████▍ [0m| 22/26 [00:21<00:04,  1.13s/it]Epoch: 9/10. Loss: 0.9034:  85%|[36m████████▍ [0m| 22/26 [00:22<00:04,  1.13s/it]Epoch: 9/10. Loss: 0.9034:  88%|[36m████████▊ [0m| 23/26 [00:22<00:03,  1.15s/it]Epoch: 9/10. Loss: 0.7932:  88%|[36m████████▊ [0m| 23/26 [00:23<00:03,  1.15s/it]Epoch: 9/10. Loss: 0.7932:  92%|[36m█████████▏[0m| 24/26 [00:23<00:02,  1.04s/it]Epoch: 9/10. Loss: 0.8612:  92%|[36m█████████▏[0m| 24/26 [00:24<00:02,  1.04s/it]Epoch: 9/10. Loss: 0.8612:  96%|[36m█████████▌[0m| 25/26 [00:24<00:01,  1.00s/it]Epoch: 9/10. Loss: 0.8540:  96%|[36m█████████▌[0m| 25/26 [00:25<00:01,  1.00s/it]Epoch: 9/10. Loss: 0.8540: 100%|[36m██████████[0m| 26/26 [00:25<00:00,  1.10it/s]Epoch: 9/10. Loss: 0.8540: 100%|[36m██████████[0m| 26/26 [00:25<00:00,  1.04it/s]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:04,  1.26it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:05,  1.17s/it] 43%|[33m████▎     [0m| 3/7 [00:02<00:03,  1.05it/s] 57%|[33m█████▋    [0m| 4/7 [00:03<00:02,  1.00it/s] 71%|[33m███████▏  [0m| 5/7 [00:04<00:01,  1.25it/s] 86%|[33m████████▌ [0m| 6/7 [00:05<00:00,  1.25it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.59it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.27it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 0/10. Loss: 1.0993:   0%|[36m          [0m| 0/26 [00:01<?, ?it/s]Epoch: 0/10. Loss: 1.0993:   4%|[36m▍         [0m| 1/26 [00:01<00:33,  1.32s/it]Epoch: 0/10. Loss: 1.7741:   4%|[36m▍         [0m| 1/26 [00:02<00:33,  1.32s/it]Epoch: 0/10. Loss: 1.7741:   8%|[36m▊         [0m| 2/26 [00:02<00:28,  1.18s/it]Epoch: 0/10. Loss: 1.2714:   8%|[36m▊         [0m| 2/26 [00:03<00:28,  1.18s/it]Epoch: 0/10. Loss: 1.2714:  12%|[36m█▏        [0m| 3/26 [00:03<00:23,  1.03s/it]Epoch: 0/10. Loss: 1.2280:  12%|[36m█▏        [0m| 3/26 [00:04<00:23,  1.03s/it]Epoch: 0/10. Loss: 1.2280:  15%|[36m█▌        [0m| 4/26 [00:04<00:22,  1.04s/it]Epoch: 0/10. Loss: 1.4206:  15%|[36m█▌        [0m| 4/26 [00:05<00:22,  1.04s/it]Epoch: 0/10. Loss: 1.4206:  19%|[36m█▉        [0m| 5/26 [00:05<00:21,  1.01s/it]Epoch: 0/10. Loss: 1.3075:  19%|[36m█▉        [0m| 5/26 [00:06<00:21,  1.01s/it]Epoch: 0/10. Loss: 1.3075:  23%|[36m██▎       [0m| 6/26 [00:06<00:20,  1.01s/it]Epoch: 0/10. Loss: 1.0878:  23%|[36m██▎       [0m| 6/26 [00:07<00:20,  1.01s/it]Epoch: 0/10. Loss: 1.0878:  27%|[36m██▋       [0m| 7/26 [00:07<00:18,  1.04it/s]Epoch: 0/10. Loss: 1.2031:  27%|[36m██▋       [0m| 7/26 [00:08<00:18,  1.04it/s]Epoch: 0/10. Loss: 1.2031:  31%|[36m███       [0m| 8/26 [00:08<00:17,  1.05it/s]Epoch: 0/10. Loss: 1.1994:  31%|[36m███       [0m| 8/26 [00:09<00:17,  1.05it/s]Epoch: 0/10. Loss: 1.1994:  35%|[36m███▍      [0m| 9/26 [00:09<00:16,  1.04it/s]Epoch: 0/10. Loss: 1.1047:  35%|[36m███▍      [0m| 9/26 [00:10<00:16,  1.04it/s]Epoch: 0/10. Loss: 1.1047:  38%|[36m███▊      [0m| 10/26 [00:10<00:16,  1.02s/it]Epoch: 0/10. Loss: 1.1588:  38%|[36m███▊      [0m| 10/26 [00:11<00:16,  1.02s/it]Epoch: 0/10. Loss: 1.1588:  42%|[36m████▏     [0m| 11/26 [00:11<00:15,  1.01s/it]Epoch: 0/10. Loss: 1.1900:  42%|[36m████▏     [0m| 11/26 [00:12<00:15,  1.01s/it]Epoch: 0/10. Loss: 1.1900:  46%|[36m████▌     [0m| 12/26 [00:12<00:13,  1.04it/s]Epoch: 0/10. Loss: 0.9883:  46%|[36m████▌     [0m| 12/26 [00:12<00:13,  1.04it/s]Epoch: 0/10. Loss: 0.9883:  50%|[36m█████     [0m| 13/26 [00:12<00:12,  1.06it/s]Epoch: 0/10. Loss: 1.1263:  50%|[36m█████     [0m| 13/26 [00:13<00:12,  1.06it/s]Epoch: 0/10. Loss: 1.1263:  54%|[36m█████▍    [0m| 14/26 [00:13<00:11,  1.03it/s]Epoch: 0/10. Loss: 1.1123:  54%|[36m█████▍    [0m| 14/26 [00:14<00:11,  1.03it/s]Epoch: 0/10. Loss: 1.1123:  58%|[36m█████▊    [0m| 15/26 [00:14<00:09,  1.10it/s]Epoch: 0/10. Loss: 1.0124:  58%|[36m█████▊    [0m| 15/26 [00:15<00:09,  1.10it/s]Epoch: 0/10. Loss: 1.0124:  62%|[36m██████▏   [0m| 16/26 [00:15<00:09,  1.03it/s]Epoch: 0/10. Loss: 1.0306:  62%|[36m██████▏   [0m| 16/26 [00:16<00:09,  1.03it/s]Epoch: 0/10. Loss: 1.0306:  65%|[36m██████▌   [0m| 17/26 [00:16<00:08,  1.02it/s]Epoch: 0/10. Loss: 1.0309:  65%|[36m██████▌   [0m| 17/26 [00:17<00:08,  1.02it/s]Epoch: 0/10. Loss: 1.0309:  69%|[36m██████▉   [0m| 18/26 [00:17<00:08,  1.00s/it]Epoch: 0/10. Loss: 1.0354:  69%|[36m██████▉   [0m| 18/26 [00:18<00:08,  1.00s/it]Epoch: 0/10. Loss: 1.0354:  73%|[36m███████▎  [0m| 19/26 [00:18<00:06,  1.09it/s]Epoch: 0/10. Loss: 1.0198:  73%|[36m███████▎  [0m| 19/26 [00:19<00:06,  1.09it/s]Epoch: 0/10. Loss: 1.0198:  77%|[36m███████▋  [0m| 20/26 [00:19<00:05,  1.05it/s]Epoch: 0/10. Loss: 1.0979:  77%|[36m███████▋  [0m| 20/26 [00:20<00:05,  1.05it/s]Epoch: 0/10. Loss: 1.0979:  81%|[36m████████  [0m| 21/26 [00:20<00:04,  1.03it/s]Epoch: 0/10. Loss: 1.0591:  81%|[36m████████  [0m| 21/26 [00:21<00:04,  1.03it/s]Epoch: 0/10. Loss: 1.0591:  85%|[36m████████▍ [0m| 22/26 [00:21<00:03,  1.03it/s]Epoch: 0/10. Loss: 1.0071:  85%|[36m████████▍ [0m| 22/26 [00:22<00:03,  1.03it/s]Epoch: 0/10. Loss: 1.0071:  88%|[36m████████▊ [0m| 23/26 [00:22<00:02,  1.07it/s]Epoch: 0/10. Loss: 1.0985:  88%|[36m████████▊ [0m| 23/26 [00:23<00:02,  1.07it/s]Epoch: 0/10. Loss: 1.0985:  92%|[36m█████████▏[0m| 24/26 [00:23<00:01,  1.04it/s]Epoch: 0/10. Loss: 1.1633:  92%|[36m█████████▏[0m| 24/26 [00:24<00:01,  1.04it/s]Epoch: 0/10. Loss: 1.1633:  96%|[36m█████████▌[0m| 25/26 [00:24<00:00,  1.11it/s]Epoch: 0/10. Loss: 0.9988:  96%|[36m█████████▌[0m| 25/26 [00:25<00:00,  1.11it/s]Epoch: 0/10. Loss: 0.9988: 100%|[36m██████████[0m| 26/26 [00:25<00:00,  1.17it/s]Epoch: 0/10. Loss: 0.9988: 100%|[36m██████████[0m| 26/26 [00:25<00:00,  1.04it/s]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:04,  1.21it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:05,  1.19s/it] 43%|[33m████▎     [0m| 3/7 [00:03<00:04,  1.09s/it] 57%|[33m█████▋    [0m| 4/7 [00:04<00:03,  1.11s/it] 71%|[33m███████▏  [0m| 5/7 [00:04<00:01,  1.12it/s] 86%|[33m████████▌ [0m| 6/7 [00:05<00:00,  1.14it/s]100%|[33m██████████[0m| 7/7 [00:06<00:00,  1.42it/s]100%|[33m██████████[0m| 7/7 [00:06<00:00,  1.15it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 1/10. Loss: 1.0862:   0%|[36m          [0m| 0/26 [00:01<?, ?it/s]Epoch: 1/10. Loss: 1.0862:   4%|[36m▍         [0m| 1/26 [00:01<00:37,  1.48s/it]Epoch: 1/10. Loss: 1.0273:   4%|[36m▍         [0m| 1/26 [00:02<00:37,  1.48s/it]Epoch: 1/10. Loss: 1.0273:   8%|[36m▊         [0m| 2/26 [00:02<00:28,  1.18s/it]Epoch: 1/10. Loss: 0.9931:   8%|[36m▊         [0m| 2/26 [00:03<00:28,  1.18s/it]Epoch: 1/10. Loss: 0.9931:  12%|[36m█▏        [0m| 3/26 [00:03<00:29,  1.27s/it]Epoch: 1/10. Loss: 1.0325:  12%|[36m█▏        [0m| 3/26 [00:04<00:29,  1.27s/it]Epoch: 1/10. Loss: 1.0325:  15%|[36m█▌        [0m| 4/26 [00:04<00:24,  1.12s/it]Epoch: 1/10. Loss: 1.0661:  15%|[36m█▌        [0m| 4/26 [00:05<00:24,  1.12s/it]Epoch: 1/10. Loss: 1.0661:  19%|[36m█▉        [0m| 5/26 [00:05<00:24,  1.15s/it]Epoch: 1/10. Loss: 1.0143:  19%|[36m█▉        [0m| 5/26 [00:06<00:24,  1.15s/it]Epoch: 1/10. Loss: 1.0143:  23%|[36m██▎       [0m| 6/26 [00:07<00:22,  1.13s/it]Epoch: 1/10. Loss: 1.1043:  23%|[36m██▎       [0m| 6/26 [00:08<00:22,  1.13s/it]Epoch: 1/10. Loss: 1.1043:  27%|[36m██▋       [0m| 7/26 [00:08<00:22,  1.20s/it]Epoch: 1/10. Loss: 1.0229:  27%|[36m██▋       [0m| 7/26 [00:09<00:22,  1.20s/it]Epoch: 1/10. Loss: 1.0229:  31%|[36m███       [0m| 8/26 [00:09<00:19,  1.08s/it]Epoch: 1/10. Loss: 1.0245:  31%|[36m███       [0m| 8/26 [00:09<00:19,  1.08s/it]Epoch: 1/10. Loss: 1.0245:  35%|[36m███▍      [0m| 9/26 [00:10<00:17,  1.00s/it]Epoch: 1/10. Loss: 0.9317:  35%|[36m███▍      [0m| 9/26 [00:10<00:17,  1.00s/it]Epoch: 1/10. Loss: 0.9317:  38%|[36m███▊      [0m| 10/26 [00:11<00:16,  1.00s/it]Epoch: 1/10. Loss: 0.9870:  38%|[36m███▊      [0m| 10/26 [00:11<00:16,  1.00s/it]Epoch: 1/10. Loss: 0.9870:  42%|[36m████▏     [0m| 11/26 [00:11<00:14,  1.02it/s]Epoch: 1/10. Loss: 1.0082:  42%|[36m████▏     [0m| 11/26 [00:12<00:14,  1.02it/s]Epoch: 1/10. Loss: 1.0082:  46%|[36m████▌     [0m| 12/26 [00:12<00:12,  1.09it/s]Epoch: 1/10. Loss: 1.0811:  46%|[36m████▌     [0m| 12/26 [00:13<00:12,  1.09it/s]Epoch: 1/10. Loss: 1.0811:  50%|[36m█████     [0m| 13/26 [00:13<00:11,  1.10it/s]Epoch: 1/10. Loss: 1.0924:  50%|[36m█████     [0m| 13/26 [00:14<00:11,  1.10it/s]Epoch: 1/10. Loss: 1.0924:  54%|[36m█████▍    [0m| 14/26 [00:14<00:11,  1.04it/s]Epoch: 1/10. Loss: 1.0385:  54%|[36m█████▍    [0m| 14/26 [00:15<00:11,  1.04it/s]Epoch: 1/10. Loss: 1.0385:  58%|[36m█████▊    [0m| 15/26 [00:15<00:10,  1.00it/s]Epoch: 1/10. Loss: 1.1042:  58%|[36m█████▊    [0m| 15/26 [00:16<00:10,  1.00it/s]Epoch: 1/10. Loss: 1.1042:  62%|[36m██████▏   [0m| 16/26 [00:16<00:09,  1.04it/s]Epoch: 1/10. Loss: 1.0352:  62%|[36m██████▏   [0m| 16/26 [00:17<00:09,  1.04it/s]Epoch: 1/10. Loss: 1.0352:  65%|[36m██████▌   [0m| 17/26 [00:17<00:08,  1.02it/s]Epoch: 1/10. Loss: 1.0361:  65%|[36m██████▌   [0m| 17/26 [00:18<00:08,  1.02it/s]Epoch: 1/10. Loss: 1.0361:  69%|[36m██████▉   [0m| 18/26 [00:18<00:07,  1.03it/s]Epoch: 1/10. Loss: 1.0625:  69%|[36m██████▉   [0m| 18/26 [00:19<00:07,  1.03it/s]Epoch: 1/10. Loss: 1.0625:  73%|[36m███████▎  [0m| 19/26 [00:19<00:06,  1.02it/s]Epoch: 1/10. Loss: 1.0572:  73%|[36m███████▎  [0m| 19/26 [00:20<00:06,  1.02it/s]Epoch: 1/10. Loss: 1.0572:  77%|[36m███████▋  [0m| 20/26 [00:20<00:06,  1.03s/it]Epoch: 1/10. Loss: 1.0845:  77%|[36m███████▋  [0m| 20/26 [00:21<00:06,  1.03s/it]Epoch: 1/10. Loss: 1.0845:  81%|[36m████████  [0m| 21/26 [00:21<00:05,  1.02s/it]Epoch: 1/10. Loss: 1.0788:  81%|[36m████████  [0m| 21/26 [00:22<00:05,  1.02s/it]Epoch: 1/10. Loss: 1.0788:  85%|[36m████████▍ [0m| 22/26 [00:22<00:04,  1.08s/it]Epoch: 1/10. Loss: 1.0428:  85%|[36m████████▍ [0m| 22/26 [00:24<00:04,  1.08s/it]Epoch: 1/10. Loss: 1.0428:  88%|[36m████████▊ [0m| 23/26 [00:24<00:03,  1.08s/it]Epoch: 1/10. Loss: 0.9833:  88%|[36m████████▊ [0m| 23/26 [00:24<00:03,  1.08s/it]Epoch: 1/10. Loss: 0.9833:  92%|[36m█████████▏[0m| 24/26 [00:24<00:01,  1.01it/s]Epoch: 1/10. Loss: 1.1830:  92%|[36m█████████▏[0m| 24/26 [00:25<00:01,  1.01it/s]Epoch: 1/10. Loss: 1.1830:  96%|[36m█████████▌[0m| 25/26 [00:25<00:00,  1.00it/s]Epoch: 1/10. Loss: 1.1864:  96%|[36m█████████▌[0m| 25/26 [00:26<00:00,  1.00it/s]Epoch: 1/10. Loss: 1.1864: 100%|[36m██████████[0m| 26/26 [00:26<00:00,  1.08it/s]Epoch: 1/10. Loss: 1.1864: 100%|[36m██████████[0m| 26/26 [00:26<00:00,  1.02s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:04,  1.33it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:05,  1.08s/it] 43%|[33m████▎     [0m| 3/7 [00:02<00:03,  1.01it/s] 57%|[33m█████▋    [0m| 4/7 [00:04<00:03,  1.03s/it] 71%|[33m███████▏  [0m| 5/7 [00:04<00:01,  1.20it/s] 86%|[33m████████▌ [0m| 6/7 [00:05<00:00,  1.21it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.54it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.25it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 2/10. Loss: 1.1271:   0%|[36m          [0m| 0/26 [00:01<?, ?it/s]Epoch: 2/10. Loss: 1.1271:   4%|[36m▍         [0m| 1/26 [00:01<00:28,  1.14s/it]Epoch: 2/10. Loss: 1.0557:   4%|[36m▍         [0m| 1/26 [00:02<00:28,  1.14s/it]Epoch: 2/10. Loss: 1.0557:   8%|[36m▊         [0m| 2/26 [00:02<00:24,  1.00s/it]Epoch: 2/10. Loss: 0.9804:   8%|[36m▊         [0m| 2/26 [00:03<00:24,  1.00s/it]Epoch: 2/10. Loss: 0.9804:  12%|[36m█▏        [0m| 3/26 [00:03<00:23,  1.04s/it]Epoch: 2/10. Loss: 1.0829:  12%|[36m█▏        [0m| 3/26 [00:04<00:23,  1.04s/it]Epoch: 2/10. Loss: 1.0829:  15%|[36m█▌        [0m| 4/26 [00:04<00:21,  1.00it/s]Epoch: 2/10. Loss: 0.9997:  15%|[36m█▌        [0m| 4/26 [00:06<00:21,  1.00it/s]Epoch: 2/10. Loss: 0.9997:  19%|[36m█▉        [0m| 5/26 [00:06<00:33,  1.61s/it]Epoch: 2/10. Loss: 1.0181:  19%|[36m█▉        [0m| 5/26 [00:09<00:33,  1.61s/it]Epoch: 2/10. Loss: 1.0181:  23%|[36m██▎       [0m| 6/26 [00:10<00:43,  2.17s/it]Epoch: 2/10. Loss: 1.0502:  23%|[36m██▎       [0m| 6/26 [00:11<00:43,  2.17s/it]Epoch: 2/10. Loss: 1.0502:  27%|[36m██▋       [0m| 7/26 [00:11<00:36,  1.92s/it]Epoch: 2/10. Loss: 1.0806:  27%|[36m██▋       [0m| 7/26 [00:12<00:36,  1.92s/it]Epoch: 2/10. Loss: 1.0806:  31%|[36m███       [0m| 8/26 [00:12<00:29,  1.64s/it]Epoch: 2/10. Loss: 1.0283:  31%|[36m███       [0m| 8/26 [00:13<00:29,  1.64s/it]Epoch: 2/10. Loss: 1.0283:  35%|[36m███▍      [0m| 9/26 [00:13<00:24,  1.42s/it]Epoch: 2/10. Loss: 1.0079:  35%|[36m███▍      [0m| 9/26 [00:14<00:24,  1.42s/it]Epoch: 2/10. Loss: 1.0079:  38%|[36m███▊      [0m| 10/26 [00:14<00:20,  1.27s/it]Epoch: 2/10. Loss: 1.0580:  38%|[36m███▊      [0m| 10/26 [00:15<00:20,  1.27s/it]Epoch: 2/10. Loss: 1.0580:  42%|[36m████▏     [0m| 11/26 [00:15<00:17,  1.19s/it]Epoch: 2/10. Loss: 1.0646:  42%|[36m████▏     [0m| 11/26 [00:16<00:17,  1.19s/it]Epoch: 2/10. Loss: 1.0646:  46%|[36m████▌     [0m| 12/26 [00:16<00:15,  1.13s/it]Epoch: 2/10. Loss: 1.0161:  46%|[36m████▌     [0m| 12/26 [00:17<00:15,  1.13s/it]Epoch: 2/10. Loss: 1.0161:  50%|[36m█████     [0m| 13/26 [00:17<00:13,  1.07s/it]Epoch: 2/10. Loss: 1.0965:  50%|[36m█████     [0m| 13/26 [00:18<00:13,  1.07s/it]Epoch: 2/10. Loss: 1.0965:  54%|[36m█████▍    [0m| 14/26 [00:18<00:12,  1.08s/it]Epoch: 2/10. Loss: 1.0486:  54%|[36m█████▍    [0m| 14/26 [00:19<00:12,  1.08s/it]Epoch: 2/10. Loss: 1.0486:  58%|[36m█████▊    [0m| 15/26 [00:19<00:11,  1.05s/it]Epoch: 2/10. Loss: 1.0789:  58%|[36m█████▊    [0m| 15/26 [00:20<00:11,  1.05s/it]Epoch: 2/10. Loss: 1.0789:  62%|[36m██████▏   [0m| 16/26 [00:20<00:10,  1.00s/it]Epoch: 2/10. Loss: 1.0095:  62%|[36m██████▏   [0m| 16/26 [00:21<00:10,  1.00s/it]Epoch: 2/10. Loss: 1.0095:  65%|[36m██████▌   [0m| 17/26 [00:21<00:08,  1.01it/s]Epoch: 2/10. Loss: 1.1048:  65%|[36m██████▌   [0m| 17/26 [00:22<00:08,  1.01it/s]Epoch: 2/10. Loss: 1.1048:  69%|[36m██████▉   [0m| 18/26 [00:22<00:07,  1.02it/s]Epoch: 2/10. Loss: 1.0718:  69%|[36m██████▉   [0m| 18/26 [00:22<00:07,  1.02it/s]Epoch: 2/10. Loss: 1.0718:  73%|[36m███████▎  [0m| 19/26 [00:22<00:06,  1.08it/s]Epoch: 2/10. Loss: 1.0912:  73%|[36m███████▎  [0m| 19/26 [00:24<00:06,  1.08it/s]Epoch: 2/10. Loss: 1.0912:  77%|[36m███████▋  [0m| 20/26 [00:24<00:05,  1.02it/s]Epoch: 2/10. Loss: 0.9632:  77%|[36m███████▋  [0m| 20/26 [00:25<00:05,  1.02it/s]Epoch: 2/10. Loss: 0.9632:  81%|[36m████████  [0m| 21/26 [00:25<00:05,  1.04s/it]Epoch: 2/10. Loss: 0.9714:  81%|[36m████████  [0m| 21/26 [00:26<00:05,  1.04s/it]Epoch: 2/10. Loss: 0.9714:  85%|[36m████████▍ [0m| 22/26 [00:26<00:03,  1.02it/s]Epoch: 2/10. Loss: 1.0672:  85%|[36m████████▍ [0m| 22/26 [00:26<00:03,  1.02it/s]Epoch: 2/10. Loss: 1.0672:  88%|[36m████████▊ [0m| 23/26 [00:26<00:02,  1.10it/s]Epoch: 2/10. Loss: 1.0093:  88%|[36m████████▊ [0m| 23/26 [00:27<00:02,  1.10it/s]Epoch: 2/10. Loss: 1.0093:  92%|[36m█████████▏[0m| 24/26 [00:27<00:01,  1.09it/s]Epoch: 2/10. Loss: 0.9732:  92%|[36m█████████▏[0m| 24/26 [00:28<00:01,  1.09it/s]Epoch: 2/10. Loss: 0.9732:  96%|[36m█████████▌[0m| 25/26 [00:28<00:00,  1.07it/s]Epoch: 2/10. Loss: 0.9903:  96%|[36m█████████▌[0m| 25/26 [00:30<00:00,  1.07it/s]Epoch: 2/10. Loss: 0.9903: 100%|[36m██████████[0m| 26/26 [00:30<00:00,  1.26s/it]Epoch: 2/10. Loss: 0.9903: 100%|[36m██████████[0m| 26/26 [00:30<00:00,  1.18s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:01<00:06,  1.15s/it] 29%|[33m██▊       [0m| 2/7 [00:02<00:06,  1.30s/it] 43%|[33m████▎     [0m| 3/7 [00:04<00:07,  1.75s/it] 57%|[33m█████▋    [0m| 4/7 [00:06<00:05,  1.79s/it] 71%|[33m███████▏  [0m| 5/7 [00:07<00:02,  1.33s/it] 86%|[33m████████▌ [0m| 6/7 [00:08<00:01,  1.17s/it]100%|[33m██████████[0m| 7/7 [00:08<00:00,  1.10it/s]100%|[33m██████████[0m| 7/7 [00:08<00:00,  1.21s/it]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 3/10. Loss: 0.9459:   0%|[36m          [0m| 0/26 [00:02<?, ?it/s]Epoch: 3/10. Loss: 0.9459:   4%|[36m▍         [0m| 1/26 [00:02<01:00,  2.43s/it]Epoch: 3/10. Loss: 0.9781:   4%|[36m▍         [0m| 1/26 [00:03<01:00,  2.43s/it]Epoch: 3/10. Loss: 0.9781:   8%|[36m▊         [0m| 2/26 [00:03<00:41,  1.74s/it]Epoch: 3/10. Loss: 1.0304:   8%|[36m▊         [0m| 2/26 [00:05<00:41,  1.74s/it]Epoch: 3/10. Loss: 1.0304:  12%|[36m█▏        [0m| 3/26 [00:05<00:42,  1.85s/it]Epoch: 3/10. Loss: 1.0254:  12%|[36m█▏        [0m| 3/26 [00:06<00:42,  1.85s/it]Epoch: 3/10. Loss: 1.0254:  15%|[36m█▌        [0m| 4/26 [00:06<00:31,  1.42s/it]Epoch: 3/10. Loss: 1.0210:  15%|[36m█▌        [0m| 4/26 [00:07<00:31,  1.42s/it]Epoch: 3/10. Loss: 1.0210:  19%|[36m█▉        [0m| 5/26 [00:07<00:26,  1.24s/it]Epoch: 3/10. Loss: 1.0075:  19%|[36m█▉        [0m| 5/26 [00:08<00:26,  1.24s/it]Epoch: 3/10. Loss: 1.0075:  23%|[36m██▎       [0m| 6/26 [00:08<00:22,  1.14s/it]Epoch: 3/10. Loss: 0.9834:  23%|[36m██▎       [0m| 6/26 [00:09<00:22,  1.14s/it]Epoch: 3/10. Loss: 0.9834:  27%|[36m██▋       [0m| 7/26 [00:09<00:19,  1.05s/it]Epoch: 3/10. Loss: 1.0773:  27%|[36m██▋       [0m| 7/26 [00:10<00:19,  1.05s/it]Epoch: 3/10. Loss: 1.0773:  31%|[36m███       [0m| 8/26 [00:10<00:18,  1.01s/it]Epoch: 3/10. Loss: 1.0417:  31%|[36m███       [0m| 8/26 [00:11<00:18,  1.01s/it]Epoch: 3/10. Loss: 1.0417:  35%|[36m███▍      [0m| 9/26 [00:11<00:17,  1.04s/it]Epoch: 3/10. Loss: 1.0432:  35%|[36m███▍      [0m| 9/26 [00:12<00:17,  1.04s/it]Epoch: 3/10. Loss: 1.0432:  38%|[36m███▊      [0m| 10/26 [00:12<00:16,  1.02s/it]Epoch: 3/10. Loss: 0.9643:  38%|[36m███▊      [0m| 10/26 [00:12<00:16,  1.02s/it]Epoch: 3/10. Loss: 0.9643:  42%|[36m████▏     [0m| 11/26 [00:12<00:14,  1.04it/s]Epoch: 3/10. Loss: 1.0382:  42%|[36m████▏     [0m| 11/26 [00:13<00:14,  1.04it/s]Epoch: 3/10. Loss: 1.0382:  46%|[36m████▌     [0m| 12/26 [00:14<00:13,  1.02it/s]Epoch: 3/10. Loss: 0.9953:  46%|[36m████▌     [0m| 12/26 [00:14<00:13,  1.02it/s]Epoch: 3/10. Loss: 0.9953:  50%|[36m█████     [0m| 13/26 [00:14<00:12,  1.04it/s]Epoch: 3/10. Loss: 1.0135:  50%|[36m█████     [0m| 13/26 [00:16<00:12,  1.04it/s]Epoch: 3/10. Loss: 1.0135:  54%|[36m█████▍    [0m| 14/26 [00:16<00:15,  1.27s/it]Epoch: 3/10. Loss: 1.0351:  54%|[36m█████▍    [0m| 14/26 [00:17<00:15,  1.27s/it]Epoch: 3/10. Loss: 1.0351:  58%|[36m█████▊    [0m| 15/26 [00:17<00:13,  1.19s/it]Epoch: 3/10. Loss: 1.0005:  58%|[36m█████▊    [0m| 15/26 [00:19<00:13,  1.19s/it]Epoch: 3/10. Loss: 1.0005:  62%|[36m██████▏   [0m| 16/26 [00:19<00:12,  1.29s/it]Epoch: 3/10. Loss: 1.1513:  62%|[36m██████▏   [0m| 16/26 [00:20<00:12,  1.29s/it]Epoch: 3/10. Loss: 1.1513:  65%|[36m██████▌   [0m| 17/26 [00:20<00:10,  1.19s/it]Epoch: 3/10. Loss: 1.0889:  65%|[36m██████▌   [0m| 17/26 [00:22<00:10,  1.19s/it]Epoch: 3/10. Loss: 1.0889:  69%|[36m██████▉   [0m| 18/26 [00:22<00:10,  1.34s/it]Epoch: 3/10. Loss: 0.9762:  69%|[36m██████▉   [0m| 18/26 [00:23<00:10,  1.34s/it]Epoch: 3/10. Loss: 0.9762:  73%|[36m███████▎  [0m| 19/26 [00:23<00:10,  1.45s/it]Epoch: 3/10. Loss: 1.0741:  73%|[36m███████▎  [0m| 19/26 [00:25<00:10,  1.45s/it]Epoch: 3/10. Loss: 1.0741:  77%|[36m███████▋  [0m| 20/26 [00:25<00:09,  1.64s/it]Epoch: 3/10. Loss: 0.9808:  77%|[36m███████▋  [0m| 20/26 [00:26<00:09,  1.64s/it]Epoch: 3/10. Loss: 0.9808:  81%|[36m████████  [0m| 21/26 [00:26<00:07,  1.45s/it]Epoch: 3/10. Loss: 0.9801:  81%|[36m████████  [0m| 21/26 [00:27<00:07,  1.45s/it]Epoch: 3/10. Loss: 0.9801:  85%|[36m████████▍ [0m| 22/26 [00:27<00:05,  1.27s/it]Epoch: 3/10. Loss: 1.0283:  85%|[36m████████▍ [0m| 22/26 [00:28<00:05,  1.27s/it]Epoch: 3/10. Loss: 1.0283:  88%|[36m████████▊ [0m| 23/26 [00:28<00:03,  1.15s/it]Epoch: 3/10. Loss: 1.0144:  88%|[36m████████▊ [0m| 23/26 [00:29<00:03,  1.15s/it]Epoch: 3/10. Loss: 1.0144:  92%|[36m█████████▏[0m| 24/26 [00:29<00:02,  1.07s/it]Epoch: 3/10. Loss: 1.0344:  92%|[36m█████████▏[0m| 24/26 [00:31<00:02,  1.07s/it]Epoch: 3/10. Loss: 1.0344:  96%|[36m█████████▌[0m| 25/26 [00:31<00:01,  1.23s/it]Epoch: 3/10. Loss: 0.9890:  96%|[36m█████████▌[0m| 25/26 [00:32<00:01,  1.23s/it]Epoch: 3/10. Loss: 0.9890: 100%|[36m██████████[0m| 26/26 [00:32<00:00,  1.21s/it]Epoch: 3/10. Loss: 0.9890: 100%|[36m██████████[0m| 26/26 [00:32<00:00,  1.24s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:01<00:07,  1.19s/it] 29%|[33m██▊       [0m| 2/7 [00:02<00:06,  1.28s/it] 43%|[33m████▎     [0m| 3/7 [00:04<00:07,  1.77s/it] 57%|[33m█████▋    [0m| 4/7 [00:06<00:05,  1.80s/it] 71%|[33m███████▏  [0m| 5/7 [00:07<00:02,  1.34s/it] 86%|[33m████████▌ [0m| 6/7 [00:08<00:01,  1.17s/it]100%|[33m██████████[0m| 7/7 [00:08<00:00,  1.12it/s]100%|[33m██████████[0m| 7/7 [00:08<00:00,  1.20s/it]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 4/10. Loss: 0.9671:   0%|[36m          [0m| 0/26 [00:01<?, ?it/s]Epoch: 4/10. Loss: 0.9671:   4%|[36m▍         [0m| 1/26 [00:01<00:41,  1.64s/it]Epoch: 4/10. Loss: 1.0444:   4%|[36m▍         [0m| 1/26 [00:02<00:41,  1.64s/it]Epoch: 4/10. Loss: 1.0444:   8%|[36m▊         [0m| 2/26 [00:02<00:28,  1.18s/it]Epoch: 4/10. Loss: 1.0307:   8%|[36m▊         [0m| 2/26 [00:03<00:28,  1.18s/it]Epoch: 4/10. Loss: 1.0307:  12%|[36m█▏        [0m| 3/26 [00:03<00:22,  1.00it/s]Epoch: 4/10. Loss: 1.1504:  12%|[36m█▏        [0m| 3/26 [00:04<00:22,  1.00it/s]Epoch: 4/10. Loss: 1.1504:  15%|[36m█▌        [0m| 4/26 [00:04<00:22,  1.03s/it]Epoch: 4/10. Loss: 1.1262:  15%|[36m█▌        [0m| 4/26 [00:05<00:22,  1.03s/it]Epoch: 4/10. Loss: 1.1262:  19%|[36m█▉        [0m| 5/26 [00:05<00:22,  1.06s/it]Epoch: 4/10. Loss: 1.0273:  19%|[36m█▉        [0m| 5/26 [00:06<00:22,  1.06s/it]Epoch: 4/10. Loss: 1.0273:  23%|[36m██▎       [0m| 6/26 [00:06<00:20,  1.03s/it]Epoch: 4/10. Loss: 1.0474:  23%|[36m██▎       [0m| 6/26 [00:07<00:20,  1.03s/it]Epoch: 4/10. Loss: 1.0474:  27%|[36m██▋       [0m| 7/26 [00:08<00:23,  1.21s/it]Epoch: 4/10. Loss: 1.0347:  27%|[36m██▋       [0m| 7/26 [00:08<00:23,  1.21s/it]Epoch: 4/10. Loss: 1.0347:  31%|[36m███       [0m| 8/26 [00:08<00:20,  1.13s/it]Epoch: 4/10. Loss: 0.9789:  31%|[36m███       [0m| 8/26 [00:09<00:20,  1.13s/it]Epoch: 4/10. Loss: 0.9789:  35%|[36m███▍      [0m| 9/26 [00:09<00:17,  1.04s/it]Epoch: 4/10. Loss: 0.9791:  35%|[36m███▍      [0m| 9/26 [00:11<00:17,  1.04s/it]Epoch: 4/10. Loss: 0.9791:  38%|[36m███▊      [0m| 10/26 [00:11<00:19,  1.22s/it]Epoch: 4/10. Loss: 1.0115:  38%|[36m███▊      [0m| 10/26 [00:12<00:19,  1.22s/it]Epoch: 4/10. Loss: 1.0115:  42%|[36m████▏     [0m| 11/26 [00:12<00:17,  1.16s/it]Epoch: 4/10. Loss: 1.0302:  42%|[36m████▏     [0m| 11/26 [00:13<00:17,  1.16s/it]Epoch: 4/10. Loss: 1.0302:  46%|[36m████▌     [0m| 12/26 [00:13<00:15,  1.09s/it]Epoch: 4/10. Loss: 1.0308:  46%|[36m████▌     [0m| 12/26 [00:14<00:15,  1.09s/it]Epoch: 4/10. Loss: 1.0308:  50%|[36m█████     [0m| 13/26 [00:14<00:14,  1.13s/it]Epoch: 4/10. Loss: 1.0195:  50%|[36m█████     [0m| 13/26 [00:15<00:14,  1.13s/it]Epoch: 4/10. Loss: 1.0195:  54%|[36m█████▍    [0m| 14/26 [00:15<00:13,  1.14s/it]Epoch: 4/10. Loss: 0.9598:  54%|[36m█████▍    [0m| 14/26 [00:16<00:13,  1.14s/it]Epoch: 4/10. Loss: 0.9598:  58%|[36m█████▊    [0m| 15/26 [00:16<00:11,  1.04s/it]Epoch: 4/10. Loss: 1.0285:  58%|[36m█████▊    [0m| 15/26 [00:17<00:11,  1.04s/it]Epoch: 4/10. Loss: 1.0285:  62%|[36m██████▏   [0m| 16/26 [00:17<00:09,  1.01it/s]Epoch: 4/10. Loss: 1.0520:  62%|[36m██████▏   [0m| 16/26 [00:18<00:09,  1.01it/s]Epoch: 4/10. Loss: 1.0520:  65%|[36m██████▌   [0m| 17/26 [00:18<00:08,  1.05it/s]Epoch: 4/10. Loss: 1.0544:  65%|[36m██████▌   [0m| 17/26 [00:19<00:08,  1.05it/s]Epoch: 4/10. Loss: 1.0544:  69%|[36m██████▉   [0m| 18/26 [00:19<00:08,  1.10s/it]Epoch: 4/10. Loss: 0.9891:  69%|[36m██████▉   [0m| 18/26 [00:20<00:08,  1.10s/it]Epoch: 4/10. Loss: 0.9891:  73%|[36m███████▎  [0m| 19/26 [00:20<00:07,  1.05s/it]Epoch: 4/10. Loss: 1.0158:  73%|[36m███████▎  [0m| 19/26 [00:21<00:07,  1.05s/it]Epoch: 4/10. Loss: 1.0158:  77%|[36m███████▋  [0m| 20/26 [00:21<00:06,  1.01s/it]Epoch: 4/10. Loss: 1.0174:  77%|[36m███████▋  [0m| 20/26 [00:22<00:06,  1.01s/it]Epoch: 4/10. Loss: 1.0174:  81%|[36m████████  [0m| 21/26 [00:22<00:04,  1.07it/s]Epoch: 4/10. Loss: 0.9378:  81%|[36m████████  [0m| 21/26 [00:23<00:04,  1.07it/s]Epoch: 4/10. Loss: 0.9378:  85%|[36m████████▍ [0m| 22/26 [00:23<00:03,  1.07it/s]Epoch: 4/10. Loss: 1.0741:  85%|[36m████████▍ [0m| 22/26 [00:24<00:03,  1.07it/s]Epoch: 4/10. Loss: 1.0741:  88%|[36m████████▊ [0m| 23/26 [00:24<00:02,  1.05it/s]Epoch: 4/10. Loss: 1.0381:  88%|[36m████████▊ [0m| 23/26 [00:25<00:02,  1.05it/s]Epoch: 4/10. Loss: 1.0381:  92%|[36m█████████▏[0m| 24/26 [00:25<00:02,  1.00s/it]Epoch: 4/10. Loss: 0.9536:  92%|[36m█████████▏[0m| 24/26 [00:26<00:02,  1.00s/it]Epoch: 4/10. Loss: 0.9536:  96%|[36m█████████▌[0m| 25/26 [00:26<00:00,  1.00it/s]Epoch: 4/10. Loss: 1.0828:  96%|[36m█████████▌[0m| 25/26 [00:27<00:00,  1.00it/s]Epoch: 4/10. Loss: 1.0828: 100%|[36m██████████[0m| 26/26 [00:27<00:00,  1.10it/s]Epoch: 4/10. Loss: 1.0828: 100%|[36m██████████[0m| 26/26 [00:27<00:00,  1.04s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:04,  1.28it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:05,  1.13s/it] 43%|[33m████▎     [0m| 3/7 [00:04<00:07,  1.75s/it] 57%|[33m█████▋    [0m| 4/7 [00:05<00:04,  1.51s/it] 71%|[33m███████▏  [0m| 5/7 [00:06<00:02,  1.15s/it] 86%|[33m████████▌ [0m| 6/7 [00:07<00:01,  1.05s/it]100%|[33m██████████[0m| 7/7 [00:07<00:00,  1.08it/s]100%|[33m██████████[0m| 7/7 [00:07<00:00,  1.12s/it]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 5/10. Loss: 0.8971:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 5/10. Loss: 0.8971:   4%|[36m▍         [0m| 1/26 [00:00<00:22,  1.13it/s]Epoch: 5/10. Loss: 1.0132:   4%|[36m▍         [0m| 1/26 [00:01<00:22,  1.13it/s]Epoch: 5/10. Loss: 1.0132:   8%|[36m▊         [0m| 2/26 [00:01<00:24,  1.01s/it]Epoch: 5/10. Loss: 1.0267:   8%|[36m▊         [0m| 2/26 [00:02<00:24,  1.01s/it]Epoch: 5/10. Loss: 1.0267:  12%|[36m█▏        [0m| 3/26 [00:02<00:23,  1.01s/it]Epoch: 5/10. Loss: 0.9681:  12%|[36m█▏        [0m| 3/26 [00:03<00:23,  1.01s/it]Epoch: 5/10. Loss: 0.9681:  15%|[36m█▌        [0m| 4/26 [00:03<00:21,  1.03it/s]Epoch: 5/10. Loss: 0.9971:  15%|[36m█▌        [0m| 4/26 [00:05<00:21,  1.03it/s]Epoch: 5/10. Loss: 0.9971:  19%|[36m█▉        [0m| 5/26 [00:05<00:27,  1.32s/it]Epoch: 5/10. Loss: 0.9995:  19%|[36m█▉        [0m| 5/26 [00:07<00:27,  1.32s/it]Epoch: 5/10. Loss: 0.9995:  23%|[36m██▎       [0m| 6/26 [00:07<00:26,  1.34s/it]Epoch: 5/10. Loss: 0.9574:  23%|[36m██▎       [0m| 6/26 [00:07<00:26,  1.34s/it]Epoch: 5/10. Loss: 0.9574:  27%|[36m██▋       [0m| 7/26 [00:07<00:21,  1.15s/it]Epoch: 5/10. Loss: 0.9180:  27%|[36m██▋       [0m| 7/26 [00:08<00:21,  1.15s/it]Epoch: 5/10. Loss: 0.9180:  31%|[36m███       [0m| 8/26 [00:08<00:19,  1.10s/it]Epoch: 5/10. Loss: 0.9543:  31%|[36m███       [0m| 8/26 [00:09<00:19,  1.10s/it]Epoch: 5/10. Loss: 0.9543:  35%|[36m███▍      [0m| 9/26 [00:09<00:18,  1.07s/it]Epoch: 5/10. Loss: 1.0560:  35%|[36m███▍      [0m| 9/26 [00:11<00:18,  1.07s/it]Epoch: 5/10. Loss: 1.0560:  38%|[36m███▊      [0m| 10/26 [00:11<00:18,  1.16s/it]Epoch: 5/10. Loss: 1.0179:  38%|[36m███▊      [0m| 10/26 [00:12<00:18,  1.16s/it]Epoch: 5/10. Loss: 1.0179:  42%|[36m████▏     [0m| 11/26 [00:12<00:17,  1.18s/it]Epoch: 5/10. Loss: 1.0192:  42%|[36m████▏     [0m| 11/26 [00:13<00:17,  1.18s/it]Epoch: 5/10. Loss: 1.0192:  46%|[36m████▌     [0m| 12/26 [00:13<00:15,  1.11s/it]Epoch: 5/10. Loss: 1.0625:  46%|[36m████▌     [0m| 12/26 [00:14<00:15,  1.11s/it]Epoch: 5/10. Loss: 1.0625:  50%|[36m█████     [0m| 13/26 [00:14<00:13,  1.06s/it]Epoch: 5/10. Loss: 1.0428:  50%|[36m█████     [0m| 13/26 [00:15<00:13,  1.06s/it]Epoch: 5/10. Loss: 1.0428:  54%|[36m█████▍    [0m| 14/26 [00:15<00:12,  1.01s/it]Epoch: 5/10. Loss: 1.0762:  54%|[36m█████▍    [0m| 14/26 [00:16<00:12,  1.01s/it]Epoch: 5/10. Loss: 1.0762:  58%|[36m█████▊    [0m| 15/26 [00:16<00:10,  1.05it/s]Epoch: 5/10. Loss: 1.0100:  58%|[36m█████▊    [0m| 15/26 [00:16<00:10,  1.05it/s]Epoch: 5/10. Loss: 1.0100:  62%|[36m██████▏   [0m| 16/26 [00:17<00:09,  1.05it/s]Epoch: 5/10. Loss: 1.0255:  62%|[36m██████▏   [0m| 16/26 [00:17<00:09,  1.05it/s]Epoch: 5/10. Loss: 1.0255:  65%|[36m██████▌   [0m| 17/26 [00:17<00:08,  1.10it/s]Epoch: 5/10. Loss: 1.0522:  65%|[36m██████▌   [0m| 17/26 [00:18<00:08,  1.10it/s]Epoch: 5/10. Loss: 1.0522:  69%|[36m██████▉   [0m| 18/26 [00:19<00:07,  1.03it/s]Epoch: 5/10. Loss: 1.0160:  69%|[36m██████▉   [0m| 18/26 [00:19<00:07,  1.03it/s]Epoch: 5/10. Loss: 1.0160:  73%|[36m███████▎  [0m| 19/26 [00:19<00:06,  1.08it/s]Epoch: 5/10. Loss: 1.0312:  73%|[36m███████▎  [0m| 19/26 [00:20<00:06,  1.08it/s]Epoch: 5/10. Loss: 1.0312:  77%|[36m███████▋  [0m| 20/26 [00:20<00:05,  1.11it/s]Epoch: 5/10. Loss: 1.0247:  77%|[36m███████▋  [0m| 20/26 [00:21<00:05,  1.11it/s]Epoch: 5/10. Loss: 1.0247:  81%|[36m████████  [0m| 21/26 [00:21<00:04,  1.11it/s]Epoch: 5/10. Loss: 1.0055:  81%|[36m████████  [0m| 21/26 [00:22<00:04,  1.11it/s]Epoch: 5/10. Loss: 1.0055:  85%|[36m████████▍ [0m| 22/26 [00:22<00:03,  1.03it/s]Epoch: 5/10. Loss: 1.0096:  85%|[36m████████▍ [0m| 22/26 [00:23<00:03,  1.03it/s]Epoch: 5/10. Loss: 1.0096:  88%|[36m████████▊ [0m| 23/26 [00:23<00:02,  1.07it/s]Epoch: 5/10. Loss: 1.0070:  88%|[36m████████▊ [0m| 23/26 [00:24<00:02,  1.07it/s]Epoch: 5/10. Loss: 1.0070:  92%|[36m█████████▏[0m| 24/26 [00:24<00:01,  1.06it/s]Epoch: 5/10. Loss: 1.0772:  92%|[36m█████████▏[0m| 24/26 [00:25<00:01,  1.06it/s]Epoch: 5/10. Loss: 1.0772:  96%|[36m█████████▌[0m| 25/26 [00:25<00:00,  1.02it/s]Epoch: 5/10. Loss: 1.0423:  96%|[36m█████████▌[0m| 25/26 [00:26<00:00,  1.02it/s]Epoch: 5/10. Loss: 1.0423: 100%|[36m██████████[0m| 26/26 [00:26<00:00,  1.04it/s]Epoch: 5/10. Loss: 1.0423: 100%|[36m██████████[0m| 26/26 [00:26<00:00,  1.02s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:04,  1.24it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:05,  1.15s/it] 43%|[33m████▎     [0m| 3/7 [00:02<00:03,  1.06it/s] 57%|[33m█████▋    [0m| 4/7 [00:04<00:03,  1.03s/it] 71%|[33m███████▏  [0m| 5/7 [00:04<00:01,  1.17it/s] 86%|[33m████████▌ [0m| 6/7 [00:05<00:00,  1.16it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.46it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.21it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 6/10. Loss: 0.9558:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 6/10. Loss: 0.9558:   4%|[36m▍         [0m| 1/26 [00:00<00:22,  1.13it/s]Epoch: 6/10. Loss: 1.0267:   4%|[36m▍         [0m| 1/26 [00:05<00:22,  1.13it/s]Epoch: 6/10. Loss: 1.0267:   8%|[36m▊         [0m| 2/26 [00:05<01:08,  2.86s/it]Epoch: 6/10. Loss: 1.0413:   8%|[36m▊         [0m| 2/26 [00:07<01:08,  2.86s/it]Epoch: 6/10. Loss: 1.0413:  12%|[36m█▏        [0m| 3/26 [00:07<00:57,  2.50s/it]Epoch: 6/10. Loss: 1.1083:  12%|[36m█▏        [0m| 3/26 [00:08<00:57,  2.50s/it]Epoch: 6/10. Loss: 1.1083:  15%|[36m█▌        [0m| 4/26 [00:08<00:40,  1.84s/it]Epoch: 6/10. Loss: 1.0270:  15%|[36m█▌        [0m| 4/26 [00:08<00:40,  1.84s/it]Epoch: 6/10. Loss: 1.0270:  19%|[36m█▉        [0m| 5/26 [00:08<00:31,  1.48s/it]Epoch: 6/10. Loss: 1.0008:  19%|[36m█▉        [0m| 5/26 [00:09<00:31,  1.48s/it]Epoch: 6/10. Loss: 1.0008:  23%|[36m██▎       [0m| 6/26 [00:09<00:25,  1.28s/it]Epoch: 6/10. Loss: 0.9996:  23%|[36m██▎       [0m| 6/26 [00:10<00:25,  1.28s/it]Epoch: 6/10. Loss: 0.9996:  27%|[36m██▋       [0m| 7/26 [00:10<00:21,  1.15s/it]Epoch: 6/10. Loss: 1.0072:  27%|[36m██▋       [0m| 7/26 [00:11<00:21,  1.15s/it]Epoch: 6/10. Loss: 1.0072:  31%|[36m███       [0m| 8/26 [00:11<00:20,  1.13s/it]Epoch: 6/10. Loss: 0.9788:  31%|[36m███       [0m| 8/26 [00:12<00:20,  1.13s/it]Epoch: 6/10. Loss: 0.9788:  35%|[36m███▍      [0m| 9/26 [00:12<00:18,  1.08s/it]Epoch: 6/10. Loss: 0.9900:  35%|[36m███▍      [0m| 9/26 [00:13<00:18,  1.08s/it]Epoch: 6/10. Loss: 0.9900:  38%|[36m███▊      [0m| 10/26 [00:13<00:16,  1.04s/it]Epoch: 6/10. Loss: 1.0178:  38%|[36m███▊      [0m| 10/26 [00:14<00:16,  1.04s/it]Epoch: 6/10. Loss: 1.0178:  42%|[36m████▏     [0m| 11/26 [00:14<00:14,  1.02it/s]Epoch: 6/10. Loss: 1.0679:  42%|[36m████▏     [0m| 11/26 [00:15<00:14,  1.02it/s]Epoch: 6/10. Loss: 1.0679:  46%|[36m████▌     [0m| 12/26 [00:15<00:13,  1.05it/s]Epoch: 6/10. Loss: 1.0233:  46%|[36m████▌     [0m| 12/26 [00:16<00:13,  1.05it/s]Epoch: 6/10. Loss: 1.0233:  50%|[36m█████     [0m| 13/26 [00:16<00:11,  1.08it/s]Epoch: 6/10. Loss: 1.0172:  50%|[36m█████     [0m| 13/26 [00:17<00:11,  1.08it/s]Epoch: 6/10. Loss: 1.0172:  54%|[36m█████▍    [0m| 14/26 [00:17<00:10,  1.12it/s]Epoch: 6/10. Loss: 1.0139:  54%|[36m█████▍    [0m| 14/26 [00:18<00:10,  1.12it/s]Epoch: 6/10. Loss: 1.0139:  58%|[36m█████▊    [0m| 15/26 [00:18<00:10,  1.04it/s]Epoch: 6/10. Loss: 0.9538:  58%|[36m█████▊    [0m| 15/26 [00:19<00:10,  1.04it/s]Epoch: 6/10. Loss: 0.9538:  62%|[36m██████▏   [0m| 16/26 [00:19<00:09,  1.00it/s]Epoch: 6/10. Loss: 1.0669:  62%|[36m██████▏   [0m| 16/26 [00:20<00:09,  1.00it/s]Epoch: 6/10. Loss: 1.0669:  65%|[36m██████▌   [0m| 17/26 [00:20<00:09,  1.03s/it]Epoch: 6/10. Loss: 1.0630:  65%|[36m██████▌   [0m| 17/26 [00:21<00:09,  1.03s/it]Epoch: 6/10. Loss: 1.0630:  69%|[36m██████▉   [0m| 18/26 [00:21<00:08,  1.01s/it]Epoch: 6/10. Loss: 1.0204:  69%|[36m██████▉   [0m| 18/26 [00:22<00:08,  1.01s/it]Epoch: 6/10. Loss: 1.0204:  73%|[36m███████▎  [0m| 19/26 [00:22<00:06,  1.03it/s]Epoch: 6/10. Loss: 1.0443:  73%|[36m███████▎  [0m| 19/26 [00:23<00:06,  1.03it/s]Epoch: 6/10. Loss: 1.0443:  77%|[36m███████▋  [0m| 20/26 [00:23<00:05,  1.02it/s]Epoch: 6/10. Loss: 1.0542:  77%|[36m███████▋  [0m| 20/26 [00:24<00:05,  1.02it/s]Epoch: 6/10. Loss: 1.0542:  81%|[36m████████  [0m| 21/26 [00:24<00:04,  1.00it/s]Epoch: 6/10. Loss: 1.0198:  81%|[36m████████  [0m| 21/26 [00:25<00:04,  1.00it/s]Epoch: 6/10. Loss: 1.0198:  85%|[36m████████▍ [0m| 22/26 [00:25<00:03,  1.07it/s]Epoch: 6/10. Loss: 0.9724:  85%|[36m████████▍ [0m| 22/26 [00:26<00:03,  1.07it/s]Epoch: 6/10. Loss: 0.9724:  88%|[36m████████▊ [0m| 23/26 [00:26<00:02,  1.02it/s]Epoch: 6/10. Loss: 1.0018:  88%|[36m████████▊ [0m| 23/26 [00:27<00:02,  1.02it/s]Epoch: 6/10. Loss: 1.0018:  92%|[36m█████████▏[0m| 24/26 [00:27<00:02,  1.04s/it]Epoch: 6/10. Loss: 1.0175:  92%|[36m█████████▏[0m| 24/26 [00:28<00:02,  1.04s/it]Epoch: 6/10. Loss: 1.0175:  96%|[36m█████████▌[0m| 25/26 [00:28<00:01,  1.06s/it]Epoch: 6/10. Loss: 1.0497:  96%|[36m█████████▌[0m| 25/26 [00:29<00:01,  1.06s/it]Epoch: 6/10. Loss: 1.0497: 100%|[36m██████████[0m| 26/26 [00:29<00:00,  1.05it/s]Epoch: 6/10. Loss: 1.0497: 100%|[36m██████████[0m| 26/26 [00:29<00:00,  1.12s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:04,  1.39it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:05,  1.06s/it] 43%|[33m████▎     [0m| 3/7 [00:02<00:03,  1.16it/s] 57%|[33m█████▋    [0m| 4/7 [00:03<00:03,  1.05s/it] 71%|[33m███████▏  [0m| 5/7 [00:04<00:01,  1.13it/s] 86%|[33m████████▌ [0m| 6/7 [00:05<00:00,  1.10it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.40it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.20it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 7/10. Loss: 1.0560:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 7/10. Loss: 1.0560:   4%|[36m▍         [0m| 1/26 [00:00<00:21,  1.14it/s]Epoch: 7/10. Loss: 1.0267:   4%|[36m▍         [0m| 1/26 [00:01<00:21,  1.14it/s]Epoch: 7/10. Loss: 1.0267:   8%|[36m▊         [0m| 2/26 [00:01<00:21,  1.13it/s]Epoch: 7/10. Loss: 1.0022:   8%|[36m▊         [0m| 2/26 [00:03<00:21,  1.13it/s]Epoch: 7/10. Loss: 1.0022:  12%|[36m█▏        [0m| 3/26 [00:03<00:24,  1.06s/it]Epoch: 7/10. Loss: 1.0133:  12%|[36m█▏        [0m| 3/26 [00:03<00:24,  1.06s/it]Epoch: 7/10. Loss: 1.0133:  15%|[36m█▌        [0m| 4/26 [00:03<00:22,  1.00s/it]Epoch: 7/10. Loss: 1.0234:  15%|[36m█▌        [0m| 4/26 [00:06<00:22,  1.00s/it]Epoch: 7/10. Loss: 1.0234:  19%|[36m█▉        [0m| 5/26 [00:06<00:32,  1.56s/it]Epoch: 7/10. Loss: 0.9754:  19%|[36m█▉        [0m| 5/26 [00:07<00:32,  1.56s/it]Epoch: 7/10. Loss: 0.9754:  23%|[36m██▎       [0m| 6/26 [00:07<00:27,  1.38s/it]Epoch: 7/10. Loss: 1.0738:  23%|[36m██▎       [0m| 6/26 [00:08<00:27,  1.38s/it]Epoch: 7/10. Loss: 1.0738:  27%|[36m██▋       [0m| 7/26 [00:08<00:24,  1.29s/it]Epoch: 7/10. Loss: 1.0333:  27%|[36m██▋       [0m| 7/26 [00:09<00:24,  1.29s/it]Epoch: 7/10. Loss: 1.0333:  31%|[36m███       [0m| 8/26 [00:09<00:21,  1.21s/it]Epoch: 7/10. Loss: 1.0275:  31%|[36m███       [0m| 8/26 [00:10<00:21,  1.21s/it]Epoch: 7/10. Loss: 1.0275:  35%|[36m███▍      [0m| 9/26 [00:10<00:19,  1.16s/it]Epoch: 7/10. Loss: 1.0014:  35%|[36m███▍      [0m| 9/26 [00:11<00:19,  1.16s/it]Epoch: 7/10. Loss: 1.0014:  38%|[36m███▊      [0m| 10/26 [00:11<00:17,  1.11s/it]Epoch: 7/10. Loss: 1.0496:  38%|[36m███▊      [0m| 10/26 [00:12<00:17,  1.11s/it]Epoch: 7/10. Loss: 1.0496:  42%|[36m████▏     [0m| 11/26 [00:12<00:16,  1.11s/it]Epoch: 7/10. Loss: 0.9729:  42%|[36m████▏     [0m| 11/26 [00:13<00:16,  1.11s/it]Epoch: 7/10. Loss: 0.9729:  46%|[36m████▌     [0m| 12/26 [00:13<00:14,  1.05s/it]Epoch: 7/10. Loss: 1.0139:  46%|[36m████▌     [0m| 12/26 [00:14<00:14,  1.05s/it]Epoch: 7/10. Loss: 1.0139:  50%|[36m█████     [0m| 13/26 [00:14<00:13,  1.03s/it]Epoch: 7/10. Loss: 1.0065:  50%|[36m█████     [0m| 13/26 [00:15<00:13,  1.03s/it]Epoch: 7/10. Loss: 1.0065:  54%|[36m█████▍    [0m| 14/26 [00:15<00:11,  1.00it/s]Epoch: 7/10. Loss: 1.0395:  54%|[36m█████▍    [0m| 14/26 [00:16<00:11,  1.00it/s]Epoch: 7/10. Loss: 1.0395:  58%|[36m█████▊    [0m| 15/26 [00:16<00:10,  1.01it/s]Epoch: 7/10. Loss: 0.9993:  58%|[36m█████▊    [0m| 15/26 [00:17<00:10,  1.01it/s]Epoch: 7/10. Loss: 0.9993:  62%|[36m██████▏   [0m| 16/26 [00:17<00:09,  1.01it/s]Epoch: 7/10. Loss: 0.9988:  62%|[36m██████▏   [0m| 16/26 [00:18<00:09,  1.01it/s]Epoch: 7/10. Loss: 0.9988:  65%|[36m██████▌   [0m| 17/26 [00:18<00:08,  1.01it/s]Epoch: 7/10. Loss: 1.0390:  65%|[36m██████▌   [0m| 17/26 [00:19<00:08,  1.01it/s]Epoch: 7/10. Loss: 1.0390:  69%|[36m██████▉   [0m| 18/26 [00:19<00:07,  1.02it/s]Epoch: 7/10. Loss: 0.9959:  69%|[36m██████▉   [0m| 18/26 [00:20<00:07,  1.02it/s]Epoch: 7/10. Loss: 0.9959:  73%|[36m███████▎  [0m| 19/26 [00:20<00:06,  1.04it/s]Epoch: 7/10. Loss: 0.9337:  73%|[36m███████▎  [0m| 19/26 [00:21<00:06,  1.04it/s]Epoch: 7/10. Loss: 0.9337:  77%|[36m███████▋  [0m| 20/26 [00:21<00:05,  1.04it/s]Epoch: 7/10. Loss: 0.9974:  77%|[36m███████▋  [0m| 20/26 [00:22<00:05,  1.04it/s]Epoch: 7/10. Loss: 0.9974:  81%|[36m████████  [0m| 21/26 [00:22<00:04,  1.02it/s]Epoch: 7/10. Loss: 0.9224:  81%|[36m████████  [0m| 21/26 [00:23<00:04,  1.02it/s]Epoch: 7/10. Loss: 0.9224:  85%|[36m████████▍ [0m| 22/26 [00:23<00:03,  1.09it/s]Epoch: 7/10. Loss: 0.9944:  85%|[36m████████▍ [0m| 22/26 [00:24<00:03,  1.09it/s]Epoch: 7/10. Loss: 0.9944:  88%|[36m████████▊ [0m| 23/26 [00:24<00:02,  1.07it/s]Epoch: 7/10. Loss: 1.0471:  88%|[36m████████▊ [0m| 23/26 [00:25<00:02,  1.07it/s]Epoch: 7/10. Loss: 1.0471:  92%|[36m█████████▏[0m| 24/26 [00:25<00:01,  1.08it/s]Epoch: 7/10. Loss: 1.0776:  92%|[36m█████████▏[0m| 24/26 [00:26<00:01,  1.08it/s]Epoch: 7/10. Loss: 1.0776:  96%|[36m█████████▌[0m| 25/26 [00:26<00:00,  1.03it/s]Epoch: 7/10. Loss: 1.0574:  96%|[36m█████████▌[0m| 25/26 [00:26<00:00,  1.03it/s]Epoch: 7/10. Loss: 1.0574: 100%|[36m██████████[0m| 26/26 [00:26<00:00,  1.12it/s]Epoch: 7/10. Loss: 1.0574: 100%|[36m██████████[0m| 26/26 [00:26<00:00,  1.03s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:05,  1.12it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:05,  1.15s/it] 43%|[33m████▎     [0m| 3/7 [00:02<00:03,  1.07it/s] 57%|[33m█████▋    [0m| 4/7 [00:04<00:03,  1.02s/it] 71%|[33m███████▏  [0m| 5/7 [00:04<00:01,  1.16it/s] 86%|[33m████████▌ [0m| 6/7 [00:05<00:00,  1.14it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.42it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.19it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 8/10. Loss: 1.0075:   0%|[36m          [0m| 0/26 [00:01<?, ?it/s]Epoch: 8/10. Loss: 1.0075:   4%|[36m▍         [0m| 1/26 [00:01<00:26,  1.05s/it]Epoch: 8/10. Loss: 1.0024:   4%|[36m▍         [0m| 1/26 [00:02<00:26,  1.05s/it]Epoch: 8/10. Loss: 1.0024:   8%|[36m▊         [0m| 2/26 [00:02<00:25,  1.07s/it]Epoch: 8/10. Loss: 1.0191:   8%|[36m▊         [0m| 2/26 [00:03<00:25,  1.07s/it]Epoch: 8/10. Loss: 1.0191:  12%|[36m█▏        [0m| 3/26 [00:03<00:24,  1.08s/it]Epoch: 8/10. Loss: 1.0149:  12%|[36m█▏        [0m| 3/26 [00:04<00:24,  1.08s/it]Epoch: 8/10. Loss: 1.0149:  15%|[36m█▌        [0m| 4/26 [00:04<00:24,  1.12s/it]Epoch: 8/10. Loss: 0.9960:  15%|[36m█▌        [0m| 4/26 [00:05<00:24,  1.12s/it]Epoch: 8/10. Loss: 0.9960:  19%|[36m█▉        [0m| 5/26 [00:06<00:27,  1.30s/it]Epoch: 8/10. Loss: 1.0553:  19%|[36m█▉        [0m| 5/26 [00:06<00:27,  1.30s/it]Epoch: 8/10. Loss: 1.0553:  23%|[36m██▎       [0m| 6/26 [00:06<00:22,  1.15s/it]Epoch: 8/10. Loss: 1.0507:  23%|[36m██▎       [0m| 6/26 [00:07<00:22,  1.15s/it]Epoch: 8/10. Loss: 1.0507:  27%|[36m██▋       [0m| 7/26 [00:07<00:20,  1.09s/it]Epoch: 8/10. Loss: 1.0031:  27%|[36m██▋       [0m| 7/26 [00:08<00:20,  1.09s/it]Epoch: 8/10. Loss: 1.0031:  31%|[36m███       [0m| 8/26 [00:08<00:19,  1.10s/it]Epoch: 8/10. Loss: 1.0625:  31%|[36m███       [0m| 8/26 [00:09<00:19,  1.10s/it]Epoch: 8/10. Loss: 1.0625:  35%|[36m███▍      [0m| 9/26 [00:09<00:17,  1.05s/it]Epoch: 8/10. Loss: 1.0215:  35%|[36m███▍      [0m| 9/26 [00:10<00:17,  1.05s/it]Epoch: 8/10. Loss: 1.0215:  38%|[36m███▊      [0m| 10/26 [00:10<00:16,  1.04s/it]Epoch: 8/10. Loss: 0.9942:  38%|[36m███▊      [0m| 10/26 [00:11<00:16,  1.04s/it]Epoch: 8/10. Loss: 0.9942:  42%|[36m████▏     [0m| 11/26 [00:11<00:14,  1.01it/s]Epoch: 8/10. Loss: 1.0615:  42%|[36m████▏     [0m| 11/26 [00:12<00:14,  1.01it/s]Epoch: 8/10. Loss: 1.0615:  46%|[36m████▌     [0m| 12/26 [00:12<00:13,  1.02it/s]Epoch: 8/10. Loss: 1.0041:  46%|[36m████▌     [0m| 12/26 [00:13<00:13,  1.02it/s]Epoch: 8/10. Loss: 1.0041:  50%|[36m█████     [0m| 13/26 [00:13<00:11,  1.12it/s]Epoch: 8/10. Loss: 1.0204:  50%|[36m█████     [0m| 13/26 [00:14<00:11,  1.12it/s]Epoch: 8/10. Loss: 1.0204:  54%|[36m█████▍    [0m| 14/26 [00:14<00:10,  1.16it/s]Epoch: 8/10. Loss: 0.9672:  54%|[36m█████▍    [0m| 14/26 [00:15<00:10,  1.16it/s]Epoch: 8/10. Loss: 0.9672:  58%|[36m█████▊    [0m| 15/26 [00:15<00:09,  1.14it/s]Epoch: 8/10. Loss: 1.0460:  58%|[36m█████▊    [0m| 15/26 [00:16<00:09,  1.14it/s]Epoch: 8/10. Loss: 1.0460:  62%|[36m██████▏   [0m| 16/26 [00:16<00:09,  1.01it/s]Epoch: 8/10. Loss: 0.9220:  62%|[36m██████▏   [0m| 16/26 [00:17<00:09,  1.01it/s]Epoch: 8/10. Loss: 0.9220:  65%|[36m██████▌   [0m| 17/26 [00:17<00:08,  1.02it/s]Epoch: 8/10. Loss: 1.0493:  65%|[36m██████▌   [0m| 17/26 [00:18<00:08,  1.02it/s]Epoch: 8/10. Loss: 1.0493:  69%|[36m██████▉   [0m| 18/26 [00:18<00:07,  1.04it/s]Epoch: 8/10. Loss: 1.0349:  69%|[36m██████▉   [0m| 18/26 [00:19<00:07,  1.04it/s]Epoch: 8/10. Loss: 1.0349:  73%|[36m███████▎  [0m| 19/26 [00:19<00:06,  1.02it/s]Epoch: 8/10. Loss: 1.0926:  73%|[36m███████▎  [0m| 19/26 [00:20<00:06,  1.02it/s]Epoch: 8/10. Loss: 1.0926:  77%|[36m███████▋  [0m| 20/26 [00:20<00:05,  1.00it/s]Epoch: 8/10. Loss: 0.9982:  77%|[36m███████▋  [0m| 20/26 [00:21<00:05,  1.00it/s]Epoch: 8/10. Loss: 0.9982:  81%|[36m████████  [0m| 21/26 [00:21<00:04,  1.02it/s]Epoch: 8/10. Loss: 1.0152:  81%|[36m████████  [0m| 21/26 [00:22<00:04,  1.02it/s]Epoch: 8/10. Loss: 1.0152:  85%|[36m████████▍ [0m| 22/26 [00:22<00:04,  1.00s/it]Epoch: 8/10. Loss: 1.0359:  85%|[36m████████▍ [0m| 22/26 [00:23<00:04,  1.00s/it]Epoch: 8/10. Loss: 1.0359:  88%|[36m████████▊ [0m| 23/26 [00:23<00:03,  1.04s/it]Epoch: 8/10. Loss: 1.0079:  88%|[36m████████▊ [0m| 23/26 [00:24<00:03,  1.04s/it]Epoch: 8/10. Loss: 1.0079:  92%|[36m█████████▏[0m| 24/26 [00:24<00:01,  1.01it/s]Epoch: 8/10. Loss: 0.9603:  92%|[36m█████████▏[0m| 24/26 [00:25<00:01,  1.01it/s]Epoch: 8/10. Loss: 0.9603:  96%|[36m█████████▌[0m| 25/26 [00:25<00:00,  1.08it/s]Epoch: 8/10. Loss: 0.9826:  96%|[36m█████████▌[0m| 25/26 [00:25<00:00,  1.08it/s]Epoch: 8/10. Loss: 0.9826: 100%|[36m██████████[0m| 26/26 [00:25<00:00,  1.14it/s]Epoch: 8/10. Loss: 0.9826: 100%|[36m██████████[0m| 26/26 [00:25<00:00,  1.00it/s]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:04,  1.30it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:05,  1.16s/it] 43%|[33m████▎     [0m| 3/7 [00:02<00:03,  1.06it/s] 57%|[33m█████▋    [0m| 4/7 [00:04<00:03,  1.24s/it] 71%|[33m███████▏  [0m| 5/7 [00:05<00:01,  1.00it/s] 86%|[33m████████▌ [0m| 6/7 [00:06<00:00,  1.03it/s]100%|[33m██████████[0m| 7/7 [00:06<00:00,  1.30it/s]100%|[33m██████████[0m| 7/7 [00:06<00:00,  1.09it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 9/10. Loss: 1.0683:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 9/10. Loss: 1.0683:   4%|[36m▍         [0m| 1/26 [00:01<00:25,  1.02s/it]Epoch: 9/10. Loss: 1.0217:   4%|[36m▍         [0m| 1/26 [00:02<00:25,  1.02s/it]Epoch: 9/10. Loss: 1.0217:   8%|[36m▊         [0m| 2/26 [00:02<00:24,  1.04s/it]Epoch: 9/10. Loss: 1.0437:   8%|[36m▊         [0m| 2/26 [00:02<00:24,  1.04s/it]Epoch: 9/10. Loss: 1.0437:  12%|[36m█▏        [0m| 3/26 [00:02<00:22,  1.02it/s]Epoch: 9/10. Loss: 1.0217:  12%|[36m█▏        [0m| 3/26 [00:03<00:22,  1.02it/s]Epoch: 9/10. Loss: 1.0217:  15%|[36m█▌        [0m| 4/26 [00:03<00:21,  1.01it/s]Epoch: 9/10. Loss: 1.0570:  15%|[36m█▌        [0m| 4/26 [00:04<00:21,  1.01it/s]Epoch: 9/10. Loss: 1.0570:  19%|[36m█▉        [0m| 5/26 [00:04<00:20,  1.05it/s]Epoch: 9/10. Loss: 1.0109:  19%|[36m█▉        [0m| 5/26 [00:05<00:20,  1.05it/s]Epoch: 9/10. Loss: 1.0109:  23%|[36m██▎       [0m| 6/26 [00:05<00:19,  1.03it/s]Epoch: 9/10. Loss: 0.9936:  23%|[36m██▎       [0m| 6/26 [00:06<00:19,  1.03it/s]Epoch: 9/10. Loss: 0.9936:  27%|[36m██▋       [0m| 7/26 [00:06<00:18,  1.03it/s]Epoch: 9/10. Loss: 1.0049:  27%|[36m██▋       [0m| 7/26 [00:07<00:18,  1.03it/s]Epoch: 9/10. Loss: 1.0049:  31%|[36m███       [0m| 8/26 [00:07<00:17,  1.04it/s]Epoch: 9/10. Loss: 1.0163:  31%|[36m███       [0m| 8/26 [00:08<00:17,  1.04it/s]Epoch: 9/10. Loss: 1.0163:  35%|[36m███▍      [0m| 9/26 [00:08<00:15,  1.09it/s]Epoch: 9/10. Loss: 0.9695:  35%|[36m███▍      [0m| 9/26 [00:09<00:15,  1.09it/s]Epoch: 9/10. Loss: 0.9695:  38%|[36m███▊      [0m| 10/26 [00:09<00:14,  1.11it/s]Epoch: 9/10. Loss: 0.9647:  38%|[36m███▊      [0m| 10/26 [00:10<00:14,  1.11it/s]Epoch: 9/10. Loss: 0.9647:  42%|[36m████▏     [0m| 11/26 [00:10<00:13,  1.14it/s]Epoch: 9/10. Loss: 1.0295:  42%|[36m████▏     [0m| 11/26 [00:11<00:13,  1.14it/s]Epoch: 9/10. Loss: 1.0295:  46%|[36m████▌     [0m| 12/26 [00:11<00:13,  1.07it/s]Epoch: 9/10. Loss: 1.0204:  46%|[36m████▌     [0m| 12/26 [00:12<00:13,  1.07it/s]Epoch: 9/10. Loss: 1.0204:  50%|[36m█████     [0m| 13/26 [00:12<00:13,  1.02s/it]Epoch: 9/10. Loss: 0.9859:  50%|[36m█████     [0m| 13/26 [00:13<00:13,  1.02s/it]Epoch: 9/10. Loss: 0.9859:  54%|[36m█████▍    [0m| 14/26 [00:13<00:11,  1.04it/s]Epoch: 9/10. Loss: 0.9995:  54%|[36m█████▍    [0m| 14/26 [00:14<00:11,  1.04it/s]Epoch: 9/10. Loss: 0.9995:  58%|[36m█████▊    [0m| 15/26 [00:14<00:10,  1.02it/s]Epoch: 9/10. Loss: 1.0248:  58%|[36m█████▊    [0m| 15/26 [00:16<00:10,  1.02it/s]Epoch: 9/10. Loss: 1.0248:  62%|[36m██████▏   [0m| 16/26 [00:16<00:14,  1.45s/it]Epoch: 9/10. Loss: 1.0312:  62%|[36m██████▏   [0m| 16/26 [00:17<00:14,  1.45s/it]Epoch: 9/10. Loss: 1.0312:  65%|[36m██████▌   [0m| 17/26 [00:17<00:11,  1.30s/it]Epoch: 9/10. Loss: 0.9953:  65%|[36m██████▌   [0m| 17/26 [00:18<00:11,  1.30s/it]Epoch: 9/10. Loss: 0.9953:  69%|[36m██████▉   [0m| 18/26 [00:19<00:09,  1.24s/it]Epoch: 9/10. Loss: 1.0131:  69%|[36m██████▉   [0m| 18/26 [00:19<00:09,  1.24s/it]Epoch: 9/10. Loss: 1.0131:  73%|[36m███████▎  [0m| 19/26 [00:19<00:07,  1.07s/it]Epoch: 9/10. Loss: 0.9688:  73%|[36m███████▎  [0m| 19/26 [00:20<00:07,  1.07s/it]Epoch: 9/10. Loss: 0.9688:  77%|[36m███████▋  [0m| 20/26 [00:20<00:06,  1.07s/it]Epoch: 9/10. Loss: 0.9753:  77%|[36m███████▋  [0m| 20/26 [00:21<00:06,  1.07s/it]Epoch: 9/10. Loss: 0.9753:  81%|[36m████████  [0m| 21/26 [00:21<00:05,  1.02s/it]Epoch: 9/10. Loss: 1.0041:  81%|[36m████████  [0m| 21/26 [00:22<00:05,  1.02s/it]Epoch: 9/10. Loss: 1.0041:  85%|[36m████████▍ [0m| 22/26 [00:22<00:04,  1.04s/it]Epoch: 9/10. Loss: 0.9664:  85%|[36m████████▍ [0m| 22/26 [00:26<00:04,  1.04s/it]Epoch: 9/10. Loss: 0.9664:  88%|[36m████████▊ [0m| 23/26 [00:26<00:05,  1.98s/it]Epoch: 9/10. Loss: 0.9520:  88%|[36m████████▊ [0m| 23/26 [00:28<00:05,  1.98s/it]Epoch: 9/10. Loss: 0.9520:  92%|[36m█████████▏[0m| 24/26 [00:28<00:03,  1.94s/it]Epoch: 9/10. Loss: 1.0063:  92%|[36m█████████▏[0m| 24/26 [00:29<00:03,  1.94s/it]Epoch: 9/10. Loss: 1.0063:  96%|[36m█████████▌[0m| 25/26 [00:29<00:01,  1.60s/it]Epoch: 9/10. Loss: 1.0173:  96%|[36m█████████▌[0m| 25/26 [00:30<00:01,  1.60s/it]Epoch: 9/10. Loss: 1.0173: 100%|[36m██████████[0m| 26/26 [00:30<00:00,  1.53s/it]Epoch: 9/10. Loss: 1.0173: 100%|[36m██████████[0m| 26/26 [00:30<00:00,  1.19s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:04,  1.24it/s] 29%|[33m██▊       [0m| 2/7 [00:04<00:11,  2.27s/it] 43%|[33m████▎     [0m| 3/7 [00:04<00:06,  1.54s/it] 57%|[33m█████▋    [0m| 4/7 [00:05<00:04,  1.41s/it] 71%|[33m███████▏  [0m| 5/7 [00:06<00:02,  1.10s/it] 86%|[33m████████▌ [0m| 6/7 [00:08<00:01,  1.43s/it]100%|[33m██████████[0m| 7/7 [00:08<00:00,  1.07s/it]100%|[33m██████████[0m| 7/7 [00:08<00:00,  1.28s/it]
/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/models/inception.py:43: FutureWarning: The default weight initialization of inception_v3 will be changed in future releases of torchvision. If you wish to keep the old behavior (which leads to long initialization times due to scipy/scipy#11299), please set init_weights=True.
  warnings.warn(
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 0/10. Loss: 1.1771:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 0/10. Loss: 1.1771:   4%|[36m▍         [0m| 1/26 [00:00<00:24,  1.03it/s]Epoch: 0/10. Loss: 3.4371:   4%|[36m▍         [0m| 1/26 [00:01<00:24,  1.03it/s]Epoch: 0/10. Loss: 3.4371:   8%|[36m▊         [0m| 2/26 [00:01<00:22,  1.05it/s]Epoch: 0/10. Loss: 1.1640:   8%|[36m▊         [0m| 2/26 [00:03<00:22,  1.05it/s]Epoch: 0/10. Loss: 1.1640:  12%|[36m█▏        [0m| 3/26 [00:03<00:33,  1.45s/it]Epoch: 0/10. Loss: 1.4019:  12%|[36m█▏        [0m| 3/26 [00:06<00:33,  1.45s/it]Epoch: 0/10. Loss: 1.4019:  15%|[36m█▌        [0m| 4/26 [00:06<00:41,  1.87s/it]Epoch: 0/10. Loss: 1.6210:  15%|[36m█▌        [0m| 4/26 [00:08<00:41,  1.87s/it]Epoch: 0/10. Loss: 1.6210:  19%|[36m█▉        [0m| 5/26 [00:08<00:39,  1.87s/it]Epoch: 0/10. Loss: 1.7260:  19%|[36m█▉        [0m| 5/26 [00:09<00:39,  1.87s/it]Epoch: 0/10. Loss: 1.7260:  23%|[36m██▎       [0m| 6/26 [00:09<00:31,  1.56s/it]Epoch: 0/10. Loss: 1.2381:  23%|[36m██▎       [0m| 6/26 [00:10<00:31,  1.56s/it]Epoch: 0/10. Loss: 1.2381:  27%|[36m██▋       [0m| 7/26 [00:10<00:26,  1.37s/it]Epoch: 0/10. Loss: 1.6453:  27%|[36m██▋       [0m| 7/26 [00:11<00:26,  1.37s/it]Epoch: 0/10. Loss: 1.6453:  31%|[36m███       [0m| 8/26 [00:11<00:21,  1.21s/it]Epoch: 0/10. Loss: 1.6786:  31%|[36m███       [0m| 8/26 [00:12<00:21,  1.21s/it]Epoch: 0/10. Loss: 1.6786:  35%|[36m███▍      [0m| 9/26 [00:12<00:19,  1.15s/it]Epoch: 0/10. Loss: 1.0610:  35%|[36m███▍      [0m| 9/26 [00:13<00:19,  1.15s/it]Epoch: 0/10. Loss: 1.0610:  38%|[36m███▊      [0m| 10/26 [00:13<00:17,  1.09s/it]Epoch: 0/10. Loss: 1.2692:  38%|[36m███▊      [0m| 10/26 [00:13<00:17,  1.09s/it]Epoch: 0/10. Loss: 1.2692:  42%|[36m████▏     [0m| 11/26 [00:14<00:15,  1.03s/it]Epoch: 0/10. Loss: 1.3412:  42%|[36m████▏     [0m| 11/26 [00:14<00:15,  1.03s/it]Epoch: 0/10. Loss: 1.3412:  46%|[36m████▌     [0m| 12/26 [00:14<00:13,  1.02it/s]Epoch: 0/10. Loss: 1.0615:  46%|[36m████▌     [0m| 12/26 [00:15<00:13,  1.02it/s]Epoch: 0/10. Loss: 1.0615:  50%|[36m█████     [0m| 13/26 [00:15<00:12,  1.06it/s]Epoch: 0/10. Loss: 1.0372:  50%|[36m█████     [0m| 13/26 [00:16<00:12,  1.06it/s]Epoch: 0/10. Loss: 1.0372:  54%|[36m█████▍    [0m| 14/26 [00:16<00:11,  1.08it/s]Epoch: 0/10. Loss: 1.2885:  54%|[36m█████▍    [0m| 14/26 [00:17<00:11,  1.08it/s]Epoch: 0/10. Loss: 1.2885:  58%|[36m█████▊    [0m| 15/26 [00:17<00:09,  1.11it/s]Epoch: 0/10. Loss: 1.1105:  58%|[36m█████▊    [0m| 15/26 [00:18<00:09,  1.11it/s]Epoch: 0/10. Loss: 1.1105:  62%|[36m██████▏   [0m| 16/26 [00:18<00:09,  1.09it/s]Epoch: 0/10. Loss: 1.0212:  62%|[36m██████▏   [0m| 16/26 [00:19<00:09,  1.09it/s]Epoch: 0/10. Loss: 1.0212:  65%|[36m██████▌   [0m| 17/26 [00:19<00:08,  1.03it/s]Epoch: 0/10. Loss: 1.1802:  65%|[36m██████▌   [0m| 17/26 [00:20<00:08,  1.03it/s]Epoch: 0/10. Loss: 1.1802:  69%|[36m██████▉   [0m| 18/26 [00:20<00:07,  1.06it/s]Epoch: 0/10. Loss: 1.2235:  69%|[36m██████▉   [0m| 18/26 [00:21<00:07,  1.06it/s]Epoch: 0/10. Loss: 1.2235:  73%|[36m███████▎  [0m| 19/26 [00:21<00:06,  1.06it/s]Epoch: 0/10. Loss: 1.0697:  73%|[36m███████▎  [0m| 19/26 [00:22<00:06,  1.06it/s]Epoch: 0/10. Loss: 1.0697:  77%|[36m███████▋  [0m| 20/26 [00:22<00:05,  1.09it/s]Epoch: 0/10. Loss: 1.0853:  77%|[36m███████▋  [0m| 20/26 [00:23<00:05,  1.09it/s]Epoch: 0/10. Loss: 1.0853:  81%|[36m████████  [0m| 21/26 [00:23<00:04,  1.03it/s]Epoch: 0/10. Loss: 1.0153:  81%|[36m████████  [0m| 21/26 [00:24<00:04,  1.03it/s]Epoch: 0/10. Loss: 1.0153:  85%|[36m████████▍ [0m| 22/26 [00:24<00:03,  1.06it/s]Epoch: 0/10. Loss: 1.0997:  85%|[36m████████▍ [0m| 22/26 [00:25<00:03,  1.06it/s]Epoch: 0/10. Loss: 1.0997:  88%|[36m████████▊ [0m| 23/26 [00:25<00:02,  1.01it/s]Epoch: 0/10. Loss: 1.1928:  88%|[36m████████▊ [0m| 23/26 [00:26<00:02,  1.01it/s]Epoch: 0/10. Loss: 1.1928:  92%|[36m█████████▏[0m| 24/26 [00:26<00:02,  1.00s/it]Epoch: 0/10. Loss: 0.9834:  92%|[36m█████████▏[0m| 24/26 [00:27<00:02,  1.00s/it]Epoch: 0/10. Loss: 0.9834:  96%|[36m█████████▌[0m| 25/26 [00:27<00:00,  1.00it/s]Epoch: 0/10. Loss: 1.0071:  96%|[36m█████████▌[0m| 25/26 [00:27<00:00,  1.00it/s]Epoch: 0/10. Loss: 1.0071: 100%|[36m██████████[0m| 26/26 [00:27<00:00,  1.11it/s]Epoch: 0/10. Loss: 1.0071: 100%|[36m██████████[0m| 26/26 [00:27<00:00,  1.07s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:02<00:14,  2.50s/it] 29%|[33m██▊       [0m| 2/7 [00:04<00:09,  1.93s/it] 43%|[33m████▎     [0m| 3/7 [00:05<00:07,  1.94s/it] 57%|[33m█████▋    [0m| 4/7 [00:07<00:04,  1.63s/it] 71%|[33m███████▏  [0m| 5/7 [00:07<00:02,  1.23s/it] 86%|[33m████████▌ [0m| 6/7 [00:10<00:01,  1.88s/it]100%|[33m██████████[0m| 7/7 [00:11<00:00,  1.54s/it]100%|[33m██████████[0m| 7/7 [00:11<00:00,  1.66s/it]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 1/10. Loss: 1.1317:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 1/10. Loss: 1.1317:   4%|[36m▍         [0m| 1/26 [00:00<00:19,  1.25it/s]Epoch: 1/10. Loss: 1.0051:   4%|[36m▍         [0m| 1/26 [00:01<00:19,  1.25it/s]Epoch: 1/10. Loss: 1.0051:   8%|[36m▊         [0m| 2/26 [00:01<00:18,  1.33it/s]Epoch: 1/10. Loss: 1.1547:   8%|[36m▊         [0m| 2/26 [00:02<00:18,  1.33it/s]Epoch: 1/10. Loss: 1.1547:  12%|[36m█▏        [0m| 3/26 [00:02<00:19,  1.17it/s]Epoch: 1/10. Loss: 0.9953:  12%|[36m█▏        [0m| 3/26 [00:03<00:19,  1.17it/s]Epoch: 1/10. Loss: 0.9953:  15%|[36m█▌        [0m| 4/26 [00:03<00:18,  1.20it/s]Epoch: 1/10. Loss: 1.1701:  15%|[36m█▌        [0m| 4/26 [00:04<00:18,  1.20it/s]Epoch: 1/10. Loss: 1.1701:  19%|[36m█▉        [0m| 5/26 [00:04<00:17,  1.23it/s]Epoch: 1/10. Loss: 1.0776:  19%|[36m█▉        [0m| 5/26 [00:05<00:17,  1.23it/s]Epoch: 1/10. Loss: 1.0776:  23%|[36m██▎       [0m| 6/26 [00:05<00:17,  1.14it/s]Epoch: 1/10. Loss: 1.1643:  23%|[36m██▎       [0m| 6/26 [00:05<00:17,  1.14it/s]Epoch: 1/10. Loss: 1.1643:  27%|[36m██▋       [0m| 7/26 [00:05<00:16,  1.13it/s]Epoch: 1/10. Loss: 1.0240:  27%|[36m██▋       [0m| 7/26 [00:06<00:16,  1.13it/s]Epoch: 1/10. Loss: 1.0240:  31%|[36m███       [0m| 8/26 [00:06<00:15,  1.18it/s]Epoch: 1/10. Loss: 0.9767:  31%|[36m███       [0m| 8/26 [00:07<00:15,  1.18it/s]Epoch: 1/10. Loss: 0.9767:  35%|[36m███▍      [0m| 9/26 [00:07<00:16,  1.06it/s]Epoch: 1/10. Loss: 1.1132:  35%|[36m███▍      [0m| 9/26 [00:10<00:16,  1.06it/s]Epoch: 1/10. Loss: 1.1132:  38%|[36m███▊      [0m| 10/26 [00:10<00:21,  1.36s/it]Epoch: 1/10. Loss: 0.9881:  38%|[36m███▊      [0m| 10/26 [00:11<00:21,  1.36s/it]Epoch: 1/10. Loss: 0.9881:  42%|[36m████▏     [0m| 11/26 [00:11<00:18,  1.23s/it]Epoch: 1/10. Loss: 1.2464:  42%|[36m████▏     [0m| 11/26 [00:12<00:18,  1.23s/it]Epoch: 1/10. Loss: 1.2464:  46%|[36m████▌     [0m| 12/26 [00:12<00:16,  1.14s/it]Epoch: 1/10. Loss: 1.0302:  46%|[36m████▌     [0m| 12/26 [00:13<00:16,  1.14s/it]Epoch: 1/10. Loss: 1.0302:  50%|[36m█████     [0m| 13/26 [00:13<00:15,  1.17s/it]Epoch: 1/10. Loss: 0.9977:  50%|[36m█████     [0m| 13/26 [00:14<00:15,  1.17s/it]Epoch: 1/10. Loss: 0.9977:  54%|[36m█████▍    [0m| 14/26 [00:14<00:13,  1.09s/it]Epoch: 1/10. Loss: 1.0371:  54%|[36m█████▍    [0m| 14/26 [00:15<00:13,  1.09s/it]Epoch: 1/10. Loss: 1.0371:  58%|[36m█████▊    [0m| 15/26 [00:15<00:11,  1.04s/it]Epoch: 1/10. Loss: 1.0259:  58%|[36m█████▊    [0m| 15/26 [00:16<00:11,  1.04s/it]Epoch: 1/10. Loss: 1.0259:  62%|[36m██████▏   [0m| 16/26 [00:16<00:09,  1.00it/s]Epoch: 1/10. Loss: 1.0800:  62%|[36m██████▏   [0m| 16/26 [00:16<00:09,  1.00it/s]Epoch: 1/10. Loss: 1.0800:  65%|[36m██████▌   [0m| 17/26 [00:16<00:08,  1.05it/s]Epoch: 1/10. Loss: 1.1827:  65%|[36m██████▌   [0m| 17/26 [00:17<00:08,  1.05it/s]Epoch: 1/10. Loss: 1.1827:  69%|[36m██████▉   [0m| 18/26 [00:17<00:07,  1.03it/s]Epoch: 1/10. Loss: 1.0677:  69%|[36m██████▉   [0m| 18/26 [00:19<00:07,  1.03it/s]Epoch: 1/10. Loss: 1.0677:  73%|[36m███████▎  [0m| 19/26 [00:19<00:07,  1.03s/it]Epoch: 1/10. Loss: 1.0565:  73%|[36m███████▎  [0m| 19/26 [00:20<00:07,  1.03s/it]Epoch: 1/10. Loss: 1.0565:  77%|[36m███████▋  [0m| 20/26 [00:20<00:06,  1.02s/it]Epoch: 1/10. Loss: 1.0975:  77%|[36m███████▋  [0m| 20/26 [00:20<00:06,  1.02s/it]Epoch: 1/10. Loss: 1.0975:  81%|[36m████████  [0m| 21/26 [00:20<00:04,  1.07it/s]Epoch: 1/10. Loss: 1.0989:  81%|[36m████████  [0m| 21/26 [00:21<00:04,  1.07it/s]Epoch: 1/10. Loss: 1.0989:  85%|[36m████████▍ [0m| 22/26 [00:21<00:03,  1.09it/s]Epoch: 1/10. Loss: 1.1320:  85%|[36m████████▍ [0m| 22/26 [00:22<00:03,  1.09it/s]Epoch: 1/10. Loss: 1.1320:  88%|[36m████████▊ [0m| 23/26 [00:22<00:02,  1.09it/s]Epoch: 1/10. Loss: 1.4527:  88%|[36m████████▊ [0m| 23/26 [00:23<00:02,  1.09it/s]Epoch: 1/10. Loss: 1.4527:  92%|[36m█████████▏[0m| 24/26 [00:23<00:01,  1.06it/s]Epoch: 1/10. Loss: 1.5390:  92%|[36m█████████▏[0m| 24/26 [00:24<00:01,  1.06it/s]Epoch: 1/10. Loss: 1.5390:  96%|[36m█████████▌[0m| 25/26 [00:24<00:00,  1.00it/s]Epoch: 1/10. Loss: 1.0211:  96%|[36m█████████▌[0m| 25/26 [00:25<00:00,  1.00it/s]Epoch: 1/10. Loss: 1.0211: 100%|[36m██████████[0m| 26/26 [00:25<00:00,  1.13it/s]Epoch: 1/10. Loss: 1.0211: 100%|[36m██████████[0m| 26/26 [00:25<00:00,  1.03it/s]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:04,  1.26it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:05,  1.09s/it] 43%|[33m████▎     [0m| 3/7 [00:02<00:03,  1.15it/s] 57%|[33m█████▋    [0m| 4/7 [00:03<00:02,  1.06it/s] 71%|[33m███████▏  [0m| 5/7 [00:04<00:01,  1.31it/s] 86%|[33m████████▌ [0m| 6/7 [00:04<00:00,  1.29it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.59it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.32it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 2/10. Loss: 1.0521:   0%|[36m          [0m| 0/26 [00:01<?, ?it/s]Epoch: 2/10. Loss: 1.0521:   4%|[36m▍         [0m| 1/26 [00:01<00:25,  1.02s/it]Epoch: 2/10. Loss: 1.1022:   4%|[36m▍         [0m| 1/26 [00:02<00:25,  1.02s/it]Epoch: 2/10. Loss: 1.1022:   8%|[36m▊         [0m| 2/26 [00:02<00:30,  1.27s/it]Epoch: 2/10. Loss: 0.9940:   8%|[36m▊         [0m| 2/26 [00:03<00:30,  1.27s/it]Epoch: 2/10. Loss: 0.9940:  12%|[36m█▏        [0m| 3/26 [00:03<00:23,  1.01s/it]Epoch: 2/10. Loss: 1.3130:  12%|[36m█▏        [0m| 3/26 [00:04<00:23,  1.01s/it]Epoch: 2/10. Loss: 1.3130:  15%|[36m█▌        [0m| 4/26 [00:04<00:22,  1.01s/it]Epoch: 2/10. Loss: 1.4031:  15%|[36m█▌        [0m| 4/26 [00:05<00:22,  1.01s/it]Epoch: 2/10. Loss: 1.4031:  19%|[36m█▉        [0m| 5/26 [00:05<00:20,  1.01it/s]Epoch: 2/10. Loss: 1.0936:  19%|[36m█▉        [0m| 5/26 [00:05<00:20,  1.01it/s]Epoch: 2/10. Loss: 1.0936:  23%|[36m██▎       [0m| 6/26 [00:05<00:18,  1.07it/s]Epoch: 2/10. Loss: 1.0082:  23%|[36m██▎       [0m| 6/26 [00:06<00:18,  1.07it/s]Epoch: 2/10. Loss: 1.0082:  27%|[36m██▋       [0m| 7/26 [00:06<00:17,  1.09it/s]Epoch: 2/10. Loss: 1.0429:  27%|[36m██▋       [0m| 7/26 [00:08<00:17,  1.09it/s]Epoch: 2/10. Loss: 1.0429:  31%|[36m███       [0m| 8/26 [00:08<00:18,  1.05s/it]Epoch: 2/10. Loss: 1.1882:  31%|[36m███       [0m| 8/26 [00:09<00:18,  1.05s/it]Epoch: 2/10. Loss: 1.1882:  35%|[36m███▍      [0m| 9/26 [00:09<00:18,  1.06s/it]Epoch: 2/10. Loss: 1.2453:  35%|[36m███▍      [0m| 9/26 [00:09<00:18,  1.06s/it]Epoch: 2/10. Loss: 1.2453:  38%|[36m███▊      [0m| 10/26 [00:09<00:15,  1.05it/s]Epoch: 2/10. Loss: 0.9323:  38%|[36m███▊      [0m| 10/26 [00:11<00:15,  1.05it/s]Epoch: 2/10. Loss: 0.9323:  42%|[36m████▏     [0m| 11/26 [00:11<00:18,  1.20s/it]Epoch: 2/10. Loss: 1.0387:  42%|[36m████▏     [0m| 11/26 [00:12<00:18,  1.20s/it]Epoch: 2/10. Loss: 1.0387:  46%|[36m████▌     [0m| 12/26 [00:12<00:15,  1.13s/it]Epoch: 2/10. Loss: 1.0132:  46%|[36m████▌     [0m| 12/26 [00:13<00:15,  1.13s/it]Epoch: 2/10. Loss: 1.0132:  50%|[36m█████     [0m| 13/26 [00:13<00:13,  1.01s/it]Epoch: 2/10. Loss: 1.0026:  50%|[36m█████     [0m| 13/26 [00:14<00:13,  1.01s/it]Epoch: 2/10. Loss: 1.0026:  54%|[36m█████▍    [0m| 14/26 [00:14<00:11,  1.02it/s]Epoch: 2/10. Loss: 1.1844:  54%|[36m█████▍    [0m| 14/26 [00:15<00:11,  1.02it/s]Epoch: 2/10. Loss: 1.1844:  58%|[36m█████▊    [0m| 15/26 [00:15<00:10,  1.02it/s]Epoch: 2/10. Loss: 1.3508:  58%|[36m█████▊    [0m| 15/26 [00:16<00:10,  1.02it/s]Epoch: 2/10. Loss: 1.3508:  62%|[36m██████▏   [0m| 16/26 [00:16<00:09,  1.05it/s]Epoch: 2/10. Loss: 1.1441:  62%|[36m██████▏   [0m| 16/26 [00:17<00:09,  1.05it/s]Epoch: 2/10. Loss: 1.1441:  65%|[36m██████▌   [0m| 17/26 [00:17<00:08,  1.05it/s]Epoch: 2/10. Loss: 1.0528:  65%|[36m██████▌   [0m| 17/26 [00:18<00:08,  1.05it/s]Epoch: 2/10. Loss: 1.0528:  69%|[36m██████▉   [0m| 18/26 [00:18<00:07,  1.09it/s]Epoch: 2/10. Loss: 1.2867:  69%|[36m██████▉   [0m| 18/26 [00:18<00:07,  1.09it/s]Epoch: 2/10. Loss: 1.2867:  73%|[36m███████▎  [0m| 19/26 [00:18<00:06,  1.12it/s]Epoch: 2/10. Loss: 1.6448:  73%|[36m███████▎  [0m| 19/26 [00:19<00:06,  1.12it/s]Epoch: 2/10. Loss: 1.6448:  77%|[36m███████▋  [0m| 20/26 [00:19<00:05,  1.06it/s]Epoch: 2/10. Loss: 1.4395:  77%|[36m███████▋  [0m| 20/26 [00:20<00:05,  1.06it/s]Epoch: 2/10. Loss: 1.4395:  81%|[36m████████  [0m| 21/26 [00:20<00:04,  1.06it/s]Epoch: 2/10. Loss: 1.2852:  81%|[36m████████  [0m| 21/26 [00:21<00:04,  1.06it/s]Epoch: 2/10. Loss: 1.2852:  85%|[36m████████▍ [0m| 22/26 [00:21<00:03,  1.04it/s]Epoch: 2/10. Loss: 1.1299:  85%|[36m████████▍ [0m| 22/26 [00:22<00:03,  1.04it/s]Epoch: 2/10. Loss: 1.1299:  88%|[36m████████▊ [0m| 23/26 [00:22<00:02,  1.02it/s]Epoch: 2/10. Loss: 1.1108:  88%|[36m████████▊ [0m| 23/26 [00:23<00:02,  1.02it/s]Epoch: 2/10. Loss: 1.1108:  92%|[36m█████████▏[0m| 24/26 [00:23<00:01,  1.04it/s]Epoch: 2/10. Loss: 1.3821:  92%|[36m█████████▏[0m| 24/26 [00:24<00:01,  1.04it/s]Epoch: 2/10. Loss: 1.3821:  96%|[36m█████████▌[0m| 25/26 [00:24<00:00,  1.05it/s]Epoch: 2/10. Loss: 1.4787:  96%|[36m█████████▌[0m| 25/26 [00:25<00:00,  1.05it/s]Epoch: 2/10. Loss: 1.4787: 100%|[36m██████████[0m| 26/26 [00:25<00:00,  1.20it/s]Epoch: 2/10. Loss: 1.4787: 100%|[36m██████████[0m| 26/26 [00:25<00:00,  1.03it/s]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:04,  1.28it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:05,  1.08s/it] 43%|[33m████▎     [0m| 3/7 [00:02<00:03,  1.15it/s] 57%|[33m█████▋    [0m| 4/7 [00:04<00:03,  1.09s/it] 71%|[33m███████▏  [0m| 5/7 [00:04<00:01,  1.11it/s] 86%|[33m████████▌ [0m| 6/7 [00:05<00:00,  1.15it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.44it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.20it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 3/10. Loss: 1.5898:   0%|[36m          [0m| 0/26 [00:01<?, ?it/s]Epoch: 3/10. Loss: 1.5898:   4%|[36m▍         [0m| 1/26 [00:01<00:28,  1.14s/it]Epoch: 3/10. Loss: 1.3027:   4%|[36m▍         [0m| 1/26 [00:01<00:28,  1.14s/it]Epoch: 3/10. Loss: 1.3027:   8%|[36m▊         [0m| 2/26 [00:01<00:22,  1.08it/s]Epoch: 3/10. Loss: 0.9604:   8%|[36m▊         [0m| 2/26 [00:02<00:22,  1.08it/s]Epoch: 3/10. Loss: 0.9604:  12%|[36m█▏        [0m| 3/26 [00:02<00:20,  1.11it/s]Epoch: 3/10. Loss: 1.2238:  12%|[36m█▏        [0m| 3/26 [00:03<00:20,  1.11it/s]Epoch: 3/10. Loss: 1.2238:  15%|[36m█▌        [0m| 4/26 [00:03<00:19,  1.10it/s]Epoch: 3/10. Loss: 1.3580:  15%|[36m█▌        [0m| 4/26 [00:04<00:19,  1.10it/s]Epoch: 3/10. Loss: 1.3580:  19%|[36m█▉        [0m| 5/26 [00:04<00:18,  1.15it/s]Epoch: 3/10. Loss: 0.9663:  19%|[36m█▉        [0m| 5/26 [00:05<00:18,  1.15it/s]Epoch: 3/10. Loss: 0.9663:  23%|[36m██▎       [0m| 6/26 [00:05<00:16,  1.20it/s]Epoch: 3/10. Loss: 1.3640:  23%|[36m██▎       [0m| 6/26 [00:06<00:16,  1.20it/s]Epoch: 3/10. Loss: 1.3640:  27%|[36m██▋       [0m| 7/26 [00:06<00:15,  1.21it/s]Epoch: 3/10. Loss: 1.0307:  27%|[36m██▋       [0m| 7/26 [00:06<00:15,  1.21it/s]Epoch: 3/10. Loss: 1.0307:  31%|[36m███       [0m| 8/26 [00:06<00:14,  1.20it/s]Epoch: 3/10. Loss: 1.0131:  31%|[36m███       [0m| 8/26 [00:07<00:14,  1.20it/s]Epoch: 3/10. Loss: 1.0131:  35%|[36m███▍      [0m| 9/26 [00:07<00:14,  1.13it/s]Epoch: 3/10. Loss: 1.2055:  35%|[36m███▍      [0m| 9/26 [00:08<00:14,  1.13it/s]Epoch: 3/10. Loss: 1.2055:  38%|[36m███▊      [0m| 10/26 [00:08<00:14,  1.14it/s]Epoch: 3/10. Loss: 1.0414:  38%|[36m███▊      [0m| 10/26 [00:09<00:14,  1.14it/s]Epoch: 3/10. Loss: 1.0414:  42%|[36m████▏     [0m| 11/26 [00:09<00:13,  1.15it/s]Epoch: 3/10. Loss: 1.0331:  42%|[36m████▏     [0m| 11/26 [00:10<00:13,  1.15it/s]Epoch: 3/10. Loss: 1.0331:  46%|[36m████▌     [0m| 12/26 [00:10<00:13,  1.05it/s]Epoch: 3/10. Loss: 0.9921:  46%|[36m████▌     [0m| 12/26 [00:11<00:13,  1.05it/s]Epoch: 3/10. Loss: 0.9921:  50%|[36m█████     [0m| 13/26 [00:11<00:12,  1.07it/s]Epoch: 3/10. Loss: 0.9669:  50%|[36m█████     [0m| 13/26 [00:12<00:12,  1.07it/s]Epoch: 3/10. Loss: 0.9669:  54%|[36m█████▍    [0m| 14/26 [00:12<00:11,  1.02it/s]Epoch: 3/10. Loss: 1.0776:  54%|[36m█████▍    [0m| 14/26 [00:13<00:11,  1.02it/s]Epoch: 3/10. Loss: 1.0776:  58%|[36m█████▊    [0m| 15/26 [00:13<00:10,  1.02it/s]Epoch: 3/10. Loss: 1.0229:  58%|[36m█████▊    [0m| 15/26 [00:14<00:10,  1.02it/s]Epoch: 3/10. Loss: 1.0229:  62%|[36m██████▏   [0m| 16/26 [00:14<00:09,  1.04it/s]Epoch: 3/10. Loss: 1.0898:  62%|[36m██████▏   [0m| 16/26 [00:15<00:09,  1.04it/s]Epoch: 3/10. Loss: 1.0898:  65%|[36m██████▌   [0m| 17/26 [00:15<00:08,  1.07it/s]Epoch: 3/10. Loss: 1.0768:  65%|[36m██████▌   [0m| 17/26 [00:16<00:08,  1.07it/s]Epoch: 3/10. Loss: 1.0768:  69%|[36m██████▉   [0m| 18/26 [00:16<00:07,  1.03it/s]Epoch: 3/10. Loss: 1.0539:  69%|[36m██████▉   [0m| 18/26 [00:17<00:07,  1.03it/s]Epoch: 3/10. Loss: 1.0539:  73%|[36m███████▎  [0m| 19/26 [00:17<00:06,  1.03it/s]Epoch: 3/10. Loss: 1.1220:  73%|[36m███████▎  [0m| 19/26 [00:18<00:06,  1.03it/s]Epoch: 3/10. Loss: 1.1220:  77%|[36m███████▋  [0m| 20/26 [00:18<00:05,  1.02it/s]Epoch: 3/10. Loss: 1.1183:  77%|[36m███████▋  [0m| 20/26 [00:19<00:05,  1.02it/s]Epoch: 3/10. Loss: 1.1183:  81%|[36m████████  [0m| 21/26 [00:19<00:05,  1.01s/it]Epoch: 3/10. Loss: 1.0089:  81%|[36m████████  [0m| 21/26 [00:21<00:05,  1.01s/it]Epoch: 3/10. Loss: 1.0089:  85%|[36m████████▍ [0m| 22/26 [00:21<00:04,  1.14s/it]Epoch: 3/10. Loss: 1.0243:  85%|[36m████████▍ [0m| 22/26 [00:21<00:04,  1.14s/it]Epoch: 3/10. Loss: 1.0243:  88%|[36m████████▊ [0m| 23/26 [00:21<00:03,  1.07s/it]Epoch: 3/10. Loss: 1.0417:  88%|[36m████████▊ [0m| 23/26 [00:22<00:03,  1.07s/it]Epoch: 3/10. Loss: 1.0417:  92%|[36m█████████▏[0m| 24/26 [00:22<00:02,  1.04s/it]Epoch: 3/10. Loss: 1.0820:  92%|[36m█████████▏[0m| 24/26 [00:23<00:02,  1.04s/it]Epoch: 3/10. Loss: 1.0820:  96%|[36m█████████▌[0m| 25/26 [00:23<00:00,  1.01it/s]Epoch: 3/10. Loss: 1.1421:  96%|[36m█████████▌[0m| 25/26 [00:24<00:00,  1.01it/s]Epoch: 3/10. Loss: 1.1421: 100%|[36m██████████[0m| 26/26 [00:24<00:00,  1.15it/s]Epoch: 3/10. Loss: 1.1421: 100%|[36m██████████[0m| 26/26 [00:24<00:00,  1.07it/s]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:01<00:10,  1.67s/it] 29%|[33m██▊       [0m| 2/7 [00:03<00:07,  1.51s/it] 43%|[33m████▎     [0m| 3/7 [00:03<00:04,  1.11s/it] 57%|[33m█████▋    [0m| 4/7 [00:04<00:03,  1.13s/it] 71%|[33m███████▏  [0m| 5/7 [00:05<00:01,  1.12it/s] 86%|[33m████████▌ [0m| 6/7 [00:06<00:00,  1.12it/s]100%|[33m██████████[0m| 7/7 [00:06<00:00,  1.41it/s]100%|[33m██████████[0m| 7/7 [00:06<00:00,  1.07it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 4/10. Loss: 1.1627:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 4/10. Loss: 1.1627:   4%|[36m▍         [0m| 1/26 [00:01<00:25,  1.01s/it]Epoch: 4/10. Loss: 1.1281:   4%|[36m▍         [0m| 1/26 [00:02<00:25,  1.01s/it]Epoch: 4/10. Loss: 1.1281:   8%|[36m▊         [0m| 2/26 [00:02<00:25,  1.06s/it]Epoch: 4/10. Loss: 0.9329:   8%|[36m▊         [0m| 2/26 [00:02<00:25,  1.06s/it]Epoch: 4/10. Loss: 0.9329:  12%|[36m█▏        [0m| 3/26 [00:02<00:21,  1.07it/s]Epoch: 4/10. Loss: 1.0398:  12%|[36m█▏        [0m| 3/26 [00:03<00:21,  1.07it/s]Epoch: 4/10. Loss: 1.0398:  15%|[36m█▌        [0m| 4/26 [00:03<00:21,  1.03it/s]Epoch: 4/10. Loss: 1.0151:  15%|[36m█▌        [0m| 4/26 [00:05<00:21,  1.03it/s]Epoch: 4/10. Loss: 1.0151:  19%|[36m█▉        [0m| 5/26 [00:05<00:24,  1.15s/it]Epoch: 4/10. Loss: 1.0915:  19%|[36m█▉        [0m| 5/26 [00:06<00:24,  1.15s/it]Epoch: 4/10. Loss: 1.0915:  23%|[36m██▎       [0m| 6/26 [00:06<00:21,  1.06s/it]Epoch: 4/10. Loss: 1.0141:  23%|[36m██▎       [0m| 6/26 [00:07<00:21,  1.06s/it]Epoch: 4/10. Loss: 1.0141:  27%|[36m██▋       [0m| 7/26 [00:07<00:19,  1.03s/it]Epoch: 4/10. Loss: 1.0306:  27%|[36m██▋       [0m| 7/26 [00:08<00:19,  1.03s/it]Epoch: 4/10. Loss: 1.0306:  31%|[36m███       [0m| 8/26 [00:08<00:18,  1.03s/it]Epoch: 4/10. Loss: 0.9852:  31%|[36m███       [0m| 8/26 [00:09<00:18,  1.03s/it]Epoch: 4/10. Loss: 0.9852:  35%|[36m███▍      [0m| 9/26 [00:09<00:16,  1.00it/s]Epoch: 4/10. Loss: 1.5046:  35%|[36m███▍      [0m| 9/26 [00:10<00:16,  1.00it/s]Epoch: 4/10. Loss: 1.5046:  38%|[36m███▊      [0m| 10/26 [00:10<00:15,  1.03it/s]Epoch: 4/10. Loss: 1.0909:  38%|[36m███▊      [0m| 10/26 [00:10<00:15,  1.03it/s]Epoch: 4/10. Loss: 1.0909:  42%|[36m████▏     [0m| 11/26 [00:10<00:13,  1.09it/s]Epoch: 4/10. Loss: 1.0188:  42%|[36m████▏     [0m| 11/26 [00:11<00:13,  1.09it/s]Epoch: 4/10. Loss: 1.0188:  46%|[36m████▌     [0m| 12/26 [00:11<00:12,  1.11it/s]Epoch: 4/10. Loss: 1.0439:  46%|[36m████▌     [0m| 12/26 [00:12<00:12,  1.11it/s]Epoch: 4/10. Loss: 1.0439:  50%|[36m█████     [0m| 13/26 [00:12<00:11,  1.14it/s]Epoch: 4/10. Loss: 1.0410:  50%|[36m█████     [0m| 13/26 [00:13<00:11,  1.14it/s]Epoch: 4/10. Loss: 1.0410:  54%|[36m█████▍    [0m| 14/26 [00:13<00:11,  1.05it/s]Epoch: 4/10. Loss: 0.9826:  54%|[36m█████▍    [0m| 14/26 [00:14<00:11,  1.05it/s]Epoch: 4/10. Loss: 0.9826:  58%|[36m█████▊    [0m| 15/26 [00:14<00:10,  1.07it/s]Epoch: 4/10. Loss: 1.0856:  58%|[36m█████▊    [0m| 15/26 [00:15<00:10,  1.07it/s]Epoch: 4/10. Loss: 1.0856:  62%|[36m██████▏   [0m| 16/26 [00:15<00:08,  1.12it/s]Epoch: 4/10. Loss: 1.0048:  62%|[36m██████▏   [0m| 16/26 [00:16<00:08,  1.12it/s]Epoch: 4/10. Loss: 1.0048:  65%|[36m██████▌   [0m| 17/26 [00:16<00:08,  1.06it/s]Epoch: 4/10. Loss: 1.0713:  65%|[36m██████▌   [0m| 17/26 [00:17<00:08,  1.06it/s]Epoch: 4/10. Loss: 1.0713:  69%|[36m██████▉   [0m| 18/26 [00:17<00:07,  1.10it/s]Epoch: 4/10. Loss: 0.9650:  69%|[36m██████▉   [0m| 18/26 [00:18<00:07,  1.10it/s]Epoch: 4/10. Loss: 0.9650:  73%|[36m███████▎  [0m| 19/26 [00:18<00:06,  1.09it/s]Epoch: 4/10. Loss: 1.1358:  73%|[36m███████▎  [0m| 19/26 [00:19<00:06,  1.09it/s]Epoch: 4/10. Loss: 1.1358:  77%|[36m███████▋  [0m| 20/26 [00:19<00:05,  1.09it/s]Epoch: 4/10. Loss: 0.9808:  77%|[36m███████▋  [0m| 20/26 [00:20<00:05,  1.09it/s]Epoch: 4/10. Loss: 0.9808:  81%|[36m████████  [0m| 21/26 [00:20<00:04,  1.11it/s]Epoch: 4/10. Loss: 1.0854:  81%|[36m████████  [0m| 21/26 [00:21<00:04,  1.11it/s]Epoch: 4/10. Loss: 1.0854:  85%|[36m████████▍ [0m| 22/26 [00:21<00:03,  1.05it/s]Epoch: 4/10. Loss: 0.9362:  85%|[36m████████▍ [0m| 22/26 [00:22<00:03,  1.05it/s]Epoch: 4/10. Loss: 0.9362:  88%|[36m████████▊ [0m| 23/26 [00:22<00:02,  1.04it/s]Epoch: 4/10. Loss: 0.9784:  88%|[36m████████▊ [0m| 23/26 [00:22<00:02,  1.04it/s]Epoch: 4/10. Loss: 0.9784:  92%|[36m█████████▏[0m| 24/26 [00:22<00:01,  1.06it/s]Epoch: 4/10. Loss: 0.9960:  92%|[36m█████████▏[0m| 24/26 [00:23<00:01,  1.06it/s]Epoch: 4/10. Loss: 0.9960:  96%|[36m█████████▌[0m| 25/26 [00:23<00:00,  1.06it/s]Epoch: 4/10. Loss: 1.7529:  96%|[36m█████████▌[0m| 25/26 [00:24<00:00,  1.06it/s]Epoch: 4/10. Loss: 1.7529: 100%|[36m██████████[0m| 26/26 [00:24<00:00,  1.14it/s]Epoch: 4/10. Loss: 1.7529: 100%|[36m██████████[0m| 26/26 [00:24<00:00,  1.05it/s]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:04,  1.27it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:05,  1.10s/it] 43%|[33m████▎     [0m| 3/7 [00:02<00:03,  1.11it/s] 57%|[33m█████▋    [0m| 4/7 [00:03<00:02,  1.01it/s] 71%|[33m███████▏  [0m| 5/7 [00:04<00:01,  1.23it/s] 86%|[33m████████▌ [0m| 6/7 [00:05<00:00,  1.22it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.52it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.26it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 5/10. Loss: 1.1829:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 5/10. Loss: 1.1829:   4%|[36m▍         [0m| 1/26 [00:00<00:19,  1.31it/s]Epoch: 5/10. Loss: 0.9605:   4%|[36m▍         [0m| 1/26 [00:01<00:19,  1.31it/s]Epoch: 5/10. Loss: 0.9605:   8%|[36m▊         [0m| 2/26 [00:01<00:24,  1.01s/it]Epoch: 5/10. Loss: 1.5467:   8%|[36m▊         [0m| 2/26 [00:02<00:24,  1.01s/it]Epoch: 5/10. Loss: 1.5467:  12%|[36m█▏        [0m| 3/26 [00:02<00:22,  1.00it/s]Epoch: 5/10. Loss: 1.2715:  12%|[36m█▏        [0m| 3/26 [00:04<00:22,  1.00it/s]Epoch: 5/10. Loss: 1.2715:  15%|[36m█▌        [0m| 4/26 [00:04<00:28,  1.31s/it]Epoch: 5/10. Loss: 1.0828:  15%|[36m█▌        [0m| 4/26 [00:05<00:28,  1.31s/it]Epoch: 5/10. Loss: 1.0828:  19%|[36m█▉        [0m| 5/26 [00:05<00:25,  1.19s/it]Epoch: 5/10. Loss: 1.1501:  19%|[36m█▉        [0m| 5/26 [00:06<00:25,  1.19s/it]Epoch: 5/10. Loss: 1.1501:  23%|[36m██▎       [0m| 6/26 [00:06<00:22,  1.10s/it]Epoch: 5/10. Loss: 1.1924:  23%|[36m██▎       [0m| 6/26 [00:07<00:22,  1.10s/it]Epoch: 5/10. Loss: 1.1924:  27%|[36m██▋       [0m| 7/26 [00:07<00:19,  1.00s/it]Epoch: 5/10. Loss: 0.9913:  27%|[36m██▋       [0m| 7/26 [00:08<00:19,  1.00s/it]Epoch: 5/10. Loss: 0.9913:  31%|[36m███       [0m| 8/26 [00:08<00:17,  1.03it/s]Epoch: 5/10. Loss: 1.0602:  31%|[36m███       [0m| 8/26 [00:09<00:17,  1.03it/s]Epoch: 5/10. Loss: 1.0602:  35%|[36m███▍      [0m| 9/26 [00:09<00:15,  1.07it/s]Epoch: 5/10. Loss: 0.9472:  35%|[36m███▍      [0m| 9/26 [00:09<00:15,  1.07it/s]Epoch: 5/10. Loss: 0.9472:  38%|[36m███▊      [0m| 10/26 [00:09<00:13,  1.15it/s]Epoch: 5/10. Loss: 1.0534:  38%|[36m███▊      [0m| 10/26 [00:11<00:13,  1.15it/s]Epoch: 5/10. Loss: 1.0534:  42%|[36m████▏     [0m| 11/26 [00:11<00:17,  1.19s/it]Epoch: 5/10. Loss: 1.2595:  42%|[36m████▏     [0m| 11/26 [00:12<00:17,  1.19s/it]Epoch: 5/10. Loss: 1.2595:  46%|[36m████▌     [0m| 12/26 [00:12<00:15,  1.10s/it]Epoch: 5/10. Loss: 1.0744:  46%|[36m████▌     [0m| 12/26 [00:13<00:15,  1.10s/it]Epoch: 5/10. Loss: 1.0744:  50%|[36m█████     [0m| 13/26 [00:13<00:13,  1.02s/it]Epoch: 5/10. Loss: 1.1459:  50%|[36m█████     [0m| 13/26 [00:14<00:13,  1.02s/it]Epoch: 5/10. Loss: 1.1459:  54%|[36m█████▍    [0m| 14/26 [00:14<00:11,  1.02it/s]Epoch: 5/10. Loss: 1.1145:  54%|[36m█████▍    [0m| 14/26 [00:15<00:11,  1.02it/s]Epoch: 5/10. Loss: 1.1145:  58%|[36m█████▊    [0m| 15/26 [00:15<00:10,  1.03it/s]Epoch: 5/10. Loss: 1.1143:  58%|[36m█████▊    [0m| 15/26 [00:16<00:10,  1.03it/s]Epoch: 5/10. Loss: 1.1143:  62%|[36m██████▏   [0m| 16/26 [00:16<00:09,  1.01it/s]Epoch: 5/10. Loss: 1.0218:  62%|[36m██████▏   [0m| 16/26 [00:17<00:09,  1.01it/s]Epoch: 5/10. Loss: 1.0218:  65%|[36m██████▌   [0m| 17/26 [00:17<00:08,  1.10it/s]Epoch: 5/10. Loss: 1.0501:  65%|[36m██████▌   [0m| 17/26 [00:17<00:08,  1.10it/s]Epoch: 5/10. Loss: 1.0501:  69%|[36m██████▉   [0m| 18/26 [00:17<00:07,  1.13it/s]Epoch: 5/10. Loss: 1.1719:  69%|[36m██████▉   [0m| 18/26 [00:18<00:07,  1.13it/s]Epoch: 5/10. Loss: 1.1719:  73%|[36m███████▎  [0m| 19/26 [00:18<00:06,  1.08it/s]Epoch: 5/10. Loss: 1.0518:  73%|[36m███████▎  [0m| 19/26 [00:20<00:06,  1.08it/s]Epoch: 5/10. Loss: 1.0518:  77%|[36m███████▋  [0m| 20/26 [00:20<00:06,  1.14s/it]Epoch: 5/10. Loss: 1.0901:  77%|[36m███████▋  [0m| 20/26 [00:21<00:06,  1.14s/it]Epoch: 5/10. Loss: 1.0901:  81%|[36m████████  [0m| 21/26 [00:21<00:05,  1.07s/it]Epoch: 5/10. Loss: 1.0787:  81%|[36m████████  [0m| 21/26 [00:23<00:05,  1.07s/it]Epoch: 5/10. Loss: 1.0787:  85%|[36m████████▍ [0m| 22/26 [00:23<00:05,  1.35s/it]Epoch: 5/10. Loss: 1.0495:  85%|[36m████████▍ [0m| 22/26 [00:24<00:05,  1.35s/it]Epoch: 5/10. Loss: 1.0495:  88%|[36m████████▊ [0m| 23/26 [00:24<00:03,  1.18s/it]Epoch: 5/10. Loss: 0.9785:  88%|[36m████████▊ [0m| 23/26 [00:25<00:03,  1.18s/it]Epoch: 5/10. Loss: 0.9785:  92%|[36m█████████▏[0m| 24/26 [00:25<00:02,  1.10s/it]Epoch: 5/10. Loss: 1.1347:  92%|[36m█████████▏[0m| 24/26 [00:26<00:02,  1.10s/it]Epoch: 5/10. Loss: 1.1347:  96%|[36m█████████▌[0m| 25/26 [00:26<00:01,  1.07s/it]Epoch: 5/10. Loss: 1.0552:  96%|[36m█████████▌[0m| 25/26 [00:26<00:01,  1.07s/it]Epoch: 5/10. Loss: 1.0552: 100%|[36m██████████[0m| 26/26 [00:26<00:00,  1.03it/s]Epoch: 5/10. Loss: 1.0552: 100%|[36m██████████[0m| 26/26 [00:26<00:00,  1.04s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:04,  1.24it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:05,  1.13s/it] 43%|[33m████▎     [0m| 3/7 [00:03<00:05,  1.44s/it] 57%|[33m█████▋    [0m| 4/7 [00:05<00:03,  1.33s/it] 71%|[33m███████▏  [0m| 5/7 [00:05<00:02,  1.08s/it] 86%|[33m████████▌ [0m| 6/7 [00:06<00:01,  1.00s/it]100%|[33m██████████[0m| 7/7 [00:08<00:00,  1.27s/it]100%|[33m██████████[0m| 7/7 [00:08<00:00,  1.20s/it]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 6/10. Loss: 1.0080:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 6/10. Loss: 1.0080:   4%|[36m▍         [0m| 1/26 [00:00<00:21,  1.14it/s]Epoch: 6/10. Loss: 1.0437:   4%|[36m▍         [0m| 1/26 [00:01<00:21,  1.14it/s]Epoch: 6/10. Loss: 1.0437:   8%|[36m▊         [0m| 2/26 [00:01<00:23,  1.03it/s]Epoch: 6/10. Loss: 0.9895:   8%|[36m▊         [0m| 2/26 [00:03<00:23,  1.03it/s]Epoch: 6/10. Loss: 0.9895:  12%|[36m█▏        [0m| 3/26 [00:03<00:26,  1.14s/it]Epoch: 6/10. Loss: 0.9982:  12%|[36m█▏        [0m| 3/26 [00:04<00:26,  1.14s/it]Epoch: 6/10. Loss: 0.9982:  15%|[36m█▌        [0m| 4/26 [00:04<00:24,  1.13s/it]Epoch: 6/10. Loss: 1.1681:  15%|[36m█▌        [0m| 4/26 [00:05<00:24,  1.13s/it]Epoch: 6/10. Loss: 1.1681:  19%|[36m█▉        [0m| 5/26 [00:05<00:22,  1.05s/it]Epoch: 6/10. Loss: 0.9786:  19%|[36m█▉        [0m| 5/26 [00:06<00:22,  1.05s/it]Epoch: 6/10. Loss: 0.9786:  23%|[36m██▎       [0m| 6/26 [00:06<00:20,  1.03s/it]Epoch: 6/10. Loss: 0.9610:  23%|[36m██▎       [0m| 6/26 [00:07<00:20,  1.03s/it]Epoch: 6/10. Loss: 0.9610:  27%|[36m██▋       [0m| 7/26 [00:07<00:19,  1.05s/it]Epoch: 6/10. Loss: 0.9886:  27%|[36m██▋       [0m| 7/26 [00:08<00:19,  1.05s/it]Epoch: 6/10. Loss: 0.9886:  31%|[36m███       [0m| 8/26 [00:08<00:17,  1.01it/s]Epoch: 6/10. Loss: 1.0530:  31%|[36m███       [0m| 8/26 [00:09<00:17,  1.01it/s]Epoch: 6/10. Loss: 1.0530:  35%|[36m███▍      [0m| 9/26 [00:09<00:16,  1.02it/s]Epoch: 6/10. Loss: 1.0588:  35%|[36m███▍      [0m| 9/26 [00:10<00:16,  1.02it/s]Epoch: 6/10. Loss: 1.0588:  38%|[36m███▊      [0m| 10/26 [00:10<00:15,  1.00it/s]Epoch: 6/10. Loss: 0.9867:  38%|[36m███▊      [0m| 10/26 [00:12<00:15,  1.00it/s]Epoch: 6/10. Loss: 0.9867:  42%|[36m████▏     [0m| 11/26 [00:12<00:22,  1.49s/it]Epoch: 6/10. Loss: 0.9749:  42%|[36m████▏     [0m| 11/26 [00:13<00:22,  1.49s/it]Epoch: 6/10. Loss: 0.9749:  46%|[36m████▌     [0m| 12/26 [00:13<00:18,  1.32s/it]Epoch: 6/10. Loss: 1.2674:  46%|[36m████▌     [0m| 12/26 [00:14<00:18,  1.32s/it]Epoch: 6/10. Loss: 1.2674:  50%|[36m█████     [0m| 13/26 [00:14<00:14,  1.13s/it]Epoch: 6/10. Loss: 0.9737:  50%|[36m█████     [0m| 13/26 [00:15<00:14,  1.13s/it]Epoch: 6/10. Loss: 0.9737:  54%|[36m█████▍    [0m| 14/26 [00:15<00:12,  1.07s/it]Epoch: 6/10. Loss: 0.9948:  54%|[36m█████▍    [0m| 14/26 [00:16<00:12,  1.07s/it]Epoch: 6/10. Loss: 0.9948:  58%|[36m█████▊    [0m| 15/26 [00:16<00:11,  1.00s/it]Epoch: 6/10. Loss: 1.0487:  58%|[36m█████▊    [0m| 15/26 [00:17<00:11,  1.00s/it]Epoch: 6/10. Loss: 1.0487:  62%|[36m██████▏   [0m| 16/26 [00:17<00:09,  1.01it/s]Epoch: 6/10. Loss: 1.0348:  62%|[36m██████▏   [0m| 16/26 [00:17<00:09,  1.01it/s]Epoch: 6/10. Loss: 1.0348:  65%|[36m██████▌   [0m| 17/26 [00:18<00:08,  1.06it/s]Epoch: 6/10. Loss: 0.9563:  65%|[36m██████▌   [0m| 17/26 [00:18<00:08,  1.06it/s]Epoch: 6/10. Loss: 0.9563:  69%|[36m██████▉   [0m| 18/26 [00:18<00:07,  1.11it/s]Epoch: 6/10. Loss: 0.9630:  69%|[36m██████▉   [0m| 18/26 [00:19<00:07,  1.11it/s]Epoch: 6/10. Loss: 0.9630:  73%|[36m███████▎  [0m| 19/26 [00:19<00:05,  1.17it/s]Epoch: 6/10. Loss: 1.1427:  73%|[36m███████▎  [0m| 19/26 [00:20<00:05,  1.17it/s]Epoch: 6/10. Loss: 1.1427:  77%|[36m███████▋  [0m| 20/26 [00:20<00:05,  1.10it/s]Epoch: 6/10. Loss: 1.0280:  77%|[36m███████▋  [0m| 20/26 [00:21<00:05,  1.10it/s]Epoch: 6/10. Loss: 1.0280:  81%|[36m████████  [0m| 21/26 [00:21<00:04,  1.08it/s]Epoch: 6/10. Loss: 1.0949:  81%|[36m████████  [0m| 21/26 [00:22<00:04,  1.08it/s]Epoch: 6/10. Loss: 1.0949:  85%|[36m████████▍ [0m| 22/26 [00:22<00:04,  1.05s/it]Epoch: 6/10. Loss: 1.1552:  85%|[36m████████▍ [0m| 22/26 [00:23<00:04,  1.05s/it]Epoch: 6/10. Loss: 1.1552:  88%|[36m████████▊ [0m| 23/26 [00:23<00:03,  1.01s/it]Epoch: 6/10. Loss: 1.0938:  88%|[36m████████▊ [0m| 23/26 [00:26<00:03,  1.01s/it]Epoch: 6/10. Loss: 1.0938:  92%|[36m█████████▏[0m| 24/26 [00:26<00:02,  1.44s/it]Epoch: 6/10. Loss: 0.9460:  92%|[36m█████████▏[0m| 24/26 [00:27<00:02,  1.44s/it]Epoch: 6/10. Loss: 0.9460:  96%|[36m█████████▌[0m| 25/26 [00:27<00:01,  1.37s/it]Epoch: 6/10. Loss: 1.0502:  96%|[36m█████████▌[0m| 25/26 [00:28<00:01,  1.37s/it]Epoch: 6/10. Loss: 1.0502: 100%|[36m██████████[0m| 26/26 [00:28<00:00,  1.14s/it]Epoch: 6/10. Loss: 1.0502: 100%|[36m██████████[0m| 26/26 [00:28<00:00,  1.08s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:04,  1.27it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:05,  1.12s/it] 43%|[33m████▎     [0m| 3/7 [00:02<00:03,  1.09it/s] 57%|[33m█████▋    [0m| 4/7 [00:03<00:03,  1.01s/it] 71%|[33m███████▏  [0m| 5/7 [00:04<00:01,  1.21it/s] 86%|[33m████████▌ [0m| 6/7 [00:05<00:00,  1.19it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.49it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.24it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 7/10. Loss: 0.9245:   0%|[36m          [0m| 0/26 [00:01<?, ?it/s]Epoch: 7/10. Loss: 0.9245:   4%|[36m▍         [0m| 1/26 [00:01<00:43,  1.74s/it]Epoch: 7/10. Loss: 1.0392:   4%|[36m▍         [0m| 1/26 [00:02<00:43,  1.74s/it]Epoch: 7/10. Loss: 1.0392:   8%|[36m▊         [0m| 2/26 [00:02<00:27,  1.14s/it]Epoch: 7/10. Loss: 1.0226:   8%|[36m▊         [0m| 2/26 [00:03<00:27,  1.14s/it]Epoch: 7/10. Loss: 1.0226:  12%|[36m█▏        [0m| 3/26 [00:03<00:23,  1.03s/it]Epoch: 7/10. Loss: 0.9505:  12%|[36m█▏        [0m| 3/26 [00:04<00:23,  1.03s/it]Epoch: 7/10. Loss: 0.9505:  15%|[36m█▌        [0m| 4/26 [00:04<00:21,  1.02it/s]Epoch: 7/10. Loss: 1.0067:  15%|[36m█▌        [0m| 4/26 [00:05<00:21,  1.02it/s]Epoch: 7/10. Loss: 1.0067:  19%|[36m█▉        [0m| 5/26 [00:05<00:23,  1.14s/it]Epoch: 7/10. Loss: 1.1501:  19%|[36m█▉        [0m| 5/26 [00:06<00:23,  1.14s/it]Epoch: 7/10. Loss: 1.1501:  23%|[36m██▎       [0m| 6/26 [00:06<00:22,  1.11s/it]Epoch: 7/10. Loss: 1.2560:  23%|[36m██▎       [0m| 6/26 [00:07<00:22,  1.11s/it]Epoch: 7/10. Loss: 1.2560:  27%|[36m██▋       [0m| 7/26 [00:07<00:18,  1.01it/s]Epoch: 7/10. Loss: 1.0976:  27%|[36m██▋       [0m| 7/26 [00:08<00:18,  1.01it/s]Epoch: 7/10. Loss: 1.0976:  31%|[36m███       [0m| 8/26 [00:08<00:17,  1.01it/s]Epoch: 7/10. Loss: 1.0547:  31%|[36m███       [0m| 8/26 [00:09<00:17,  1.01it/s]Epoch: 7/10. Loss: 1.0547:  35%|[36m███▍      [0m| 9/26 [00:09<00:15,  1.07it/s]Epoch: 7/10. Loss: 0.9366:  35%|[36m███▍      [0m| 9/26 [00:10<00:15,  1.07it/s]Epoch: 7/10. Loss: 0.9366:  38%|[36m███▊      [0m| 10/26 [00:10<00:15,  1.06it/s]Epoch: 7/10. Loss: 1.2184:  38%|[36m███▊      [0m| 10/26 [00:11<00:15,  1.06it/s]Epoch: 7/10. Loss: 1.2184:  42%|[36m████▏     [0m| 11/26 [00:11<00:15,  1.01s/it]Epoch: 7/10. Loss: 0.9947:  42%|[36m████▏     [0m| 11/26 [00:12<00:15,  1.01s/it]Epoch: 7/10. Loss: 0.9947:  46%|[36m████▌     [0m| 12/26 [00:12<00:15,  1.10s/it]Epoch: 7/10. Loss: 1.2778:  46%|[36m████▌     [0m| 12/26 [00:13<00:15,  1.10s/it]Epoch: 7/10. Loss: 1.2778:  50%|[36m█████     [0m| 13/26 [00:13<00:13,  1.02s/it]Epoch: 7/10. Loss: 0.9925:  50%|[36m█████     [0m| 13/26 [00:14<00:13,  1.02s/it]Epoch: 7/10. Loss: 0.9925:  54%|[36m█████▍    [0m| 14/26 [00:14<00:11,  1.02it/s]Epoch: 7/10. Loss: 1.0430:  54%|[36m█████▍    [0m| 14/26 [00:15<00:11,  1.02it/s]Epoch: 7/10. Loss: 1.0430:  58%|[36m█████▊    [0m| 15/26 [00:15<00:10,  1.02it/s]Epoch: 7/10. Loss: 1.1282:  58%|[36m█████▊    [0m| 15/26 [00:16<00:10,  1.02it/s]Epoch: 7/10. Loss: 1.1282:  62%|[36m██████▏   [0m| 16/26 [00:16<00:09,  1.03it/s]Epoch: 7/10. Loss: 1.0239:  62%|[36m██████▏   [0m| 16/26 [00:17<00:09,  1.03it/s]Epoch: 7/10. Loss: 1.0239:  65%|[36m██████▌   [0m| 17/26 [00:17<00:08,  1.06it/s]Epoch: 7/10. Loss: 1.0703:  65%|[36m██████▌   [0m| 17/26 [00:18<00:08,  1.06it/s]Epoch: 7/10. Loss: 1.0703:  69%|[36m██████▉   [0m| 18/26 [00:18<00:07,  1.03it/s]Epoch: 7/10. Loss: 1.1007:  69%|[36m██████▉   [0m| 18/26 [00:19<00:07,  1.03it/s]Epoch: 7/10. Loss: 1.1007:  73%|[36m███████▎  [0m| 19/26 [00:19<00:06,  1.01it/s]Epoch: 7/10. Loss: 1.2311:  73%|[36m███████▎  [0m| 19/26 [00:20<00:06,  1.01it/s]Epoch: 7/10. Loss: 1.2311:  77%|[36m███████▋  [0m| 20/26 [00:20<00:05,  1.05it/s]Epoch: 7/10. Loss: 1.0807:  77%|[36m███████▋  [0m| 20/26 [00:21<00:05,  1.05it/s]Epoch: 7/10. Loss: 1.0807:  81%|[36m████████  [0m| 21/26 [00:21<00:04,  1.07it/s]Epoch: 7/10. Loss: 1.2095:  81%|[36m████████  [0m| 21/26 [00:21<00:04,  1.07it/s]Epoch: 7/10. Loss: 1.2095:  85%|[36m████████▍ [0m| 22/26 [00:22<00:03,  1.07it/s]Epoch: 7/10. Loss: 1.0103:  85%|[36m████████▍ [0m| 22/26 [00:22<00:03,  1.07it/s]Epoch: 7/10. Loss: 1.0103:  88%|[36m████████▊ [0m| 23/26 [00:22<00:02,  1.11it/s]Epoch: 7/10. Loss: 1.0209:  88%|[36m████████▊ [0m| 23/26 [00:23<00:02,  1.11it/s]Epoch: 7/10. Loss: 1.0209:  92%|[36m█████████▏[0m| 24/26 [00:23<00:01,  1.05it/s]Epoch: 7/10. Loss: 1.1938:  92%|[36m█████████▏[0m| 24/26 [00:24<00:01,  1.05it/s]Epoch: 7/10. Loss: 1.1938:  96%|[36m█████████▌[0m| 25/26 [00:24<00:00,  1.08it/s]Epoch: 7/10. Loss: 1.0751:  96%|[36m█████████▌[0m| 25/26 [00:25<00:00,  1.08it/s]Epoch: 7/10. Loss: 1.0751: 100%|[36m██████████[0m| 26/26 [00:25<00:00,  1.20it/s]Epoch: 7/10. Loss: 1.0751: 100%|[36m██████████[0m| 26/26 [00:25<00:00,  1.02it/s]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:04,  1.25it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:05,  1.13s/it] 43%|[33m████▎     [0m| 3/7 [00:02<00:03,  1.08it/s] 57%|[33m█████▋    [0m| 4/7 [00:03<00:03,  1.01s/it] 71%|[33m███████▏  [0m| 5/7 [00:04<00:01,  1.20it/s] 86%|[33m████████▌ [0m| 6/7 [00:05<00:00,  1.18it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.48it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.23it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 8/10. Loss: 0.9817:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 8/10. Loss: 0.9817:   4%|[36m▍         [0m| 1/26 [00:00<00:24,  1.02it/s]Epoch: 8/10. Loss: 1.2982:   4%|[36m▍         [0m| 1/26 [00:01<00:24,  1.02it/s]Epoch: 8/10. Loss: 1.2982:   8%|[36m▊         [0m| 2/26 [00:01<00:22,  1.05it/s]Epoch: 8/10. Loss: 1.1688:   8%|[36m▊         [0m| 2/26 [00:02<00:22,  1.05it/s]Epoch: 8/10. Loss: 1.1688:  12%|[36m█▏        [0m| 3/26 [00:02<00:21,  1.09it/s]Epoch: 8/10. Loss: 0.9968:  12%|[36m█▏        [0m| 3/26 [00:04<00:21,  1.09it/s]Epoch: 8/10. Loss: 0.9968:  15%|[36m█▌        [0m| 4/26 [00:04<00:25,  1.14s/it]Epoch: 8/10. Loss: 1.0294:  15%|[36m█▌        [0m| 4/26 [00:05<00:25,  1.14s/it]Epoch: 8/10. Loss: 1.0294:  19%|[36m█▉        [0m| 5/26 [00:05<00:21,  1.02s/it]Epoch: 8/10. Loss: 1.1646:  19%|[36m█▉        [0m| 5/26 [00:06<00:21,  1.02s/it]Epoch: 8/10. Loss: 1.1646:  23%|[36m██▎       [0m| 6/26 [00:06<00:21,  1.06s/it]Epoch: 8/10. Loss: 1.0873:  23%|[36m██▎       [0m| 6/26 [00:07<00:21,  1.06s/it]Epoch: 8/10. Loss: 1.0873:  27%|[36m██▋       [0m| 7/26 [00:07<00:18,  1.01it/s]Epoch: 8/10. Loss: 1.0391:  27%|[36m██▋       [0m| 7/26 [00:08<00:18,  1.01it/s]Epoch: 8/10. Loss: 1.0391:  31%|[36m███       [0m| 8/26 [00:08<00:19,  1.10s/it]Epoch: 8/10. Loss: 1.0168:  31%|[36m███       [0m| 8/26 [00:09<00:19,  1.10s/it]Epoch: 8/10. Loss: 1.0168:  35%|[36m███▍      [0m| 9/26 [00:09<00:16,  1.01it/s]Epoch: 8/10. Loss: 0.9897:  35%|[36m███▍      [0m| 9/26 [00:09<00:16,  1.01it/s]Epoch: 8/10. Loss: 0.9897:  38%|[36m███▊      [0m| 10/26 [00:09<00:15,  1.06it/s]Epoch: 8/10. Loss: 1.1599:  38%|[36m███▊      [0m| 10/26 [00:10<00:15,  1.06it/s]Epoch: 8/10. Loss: 1.1599:  42%|[36m████▏     [0m| 11/26 [00:10<00:13,  1.09it/s]Epoch: 8/10. Loss: 1.1550:  42%|[36m████▏     [0m| 11/26 [00:11<00:13,  1.09it/s]Epoch: 8/10. Loss: 1.1550:  46%|[36m████▌     [0m| 12/26 [00:11<00:12,  1.11it/s]Epoch: 8/10. Loss: 0.9708:  46%|[36m████▌     [0m| 12/26 [00:12<00:12,  1.11it/s]Epoch: 8/10. Loss: 0.9708:  50%|[36m█████     [0m| 13/26 [00:12<00:11,  1.10it/s]Epoch: 8/10. Loss: 0.9540:  50%|[36m█████     [0m| 13/26 [00:13<00:11,  1.10it/s]Epoch: 8/10. Loss: 0.9540:  54%|[36m█████▍    [0m| 14/26 [00:13<00:11,  1.03it/s]Epoch: 8/10. Loss: 0.9006:  54%|[36m█████▍    [0m| 14/26 [00:15<00:11,  1.03it/s]Epoch: 8/10. Loss: 0.9006:  58%|[36m█████▊    [0m| 15/26 [00:15<00:11,  1.07s/it]Epoch: 8/10. Loss: 0.9733:  58%|[36m█████▊    [0m| 15/26 [00:15<00:11,  1.07s/it]Epoch: 8/10. Loss: 0.9733:  62%|[36m██████▏   [0m| 16/26 [00:15<00:10,  1.01s/it]Epoch: 8/10. Loss: 0.9224:  62%|[36m██████▏   [0m| 16/26 [00:17<00:10,  1.01s/it]Epoch: 8/10. Loss: 0.9224:  65%|[36m██████▌   [0m| 17/26 [00:17<00:10,  1.20s/it]Epoch: 8/10. Loss: 1.0332:  65%|[36m██████▌   [0m| 17/26 [00:18<00:10,  1.20s/it]Epoch: 8/10. Loss: 1.0332:  69%|[36m██████▉   [0m| 18/26 [00:18<00:08,  1.12s/it]Epoch: 8/10. Loss: 1.1137:  69%|[36m██████▉   [0m| 18/26 [00:19<00:08,  1.12s/it]Epoch: 8/10. Loss: 1.1137:  73%|[36m███████▎  [0m| 19/26 [00:19<00:07,  1.05s/it]Epoch: 8/10. Loss: 0.9940:  73%|[36m███████▎  [0m| 19/26 [00:20<00:07,  1.05s/it]Epoch: 8/10. Loss: 0.9940:  77%|[36m███████▋  [0m| 20/26 [00:20<00:05,  1.04it/s]Epoch: 8/10. Loss: 0.9314:  77%|[36m███████▋  [0m| 20/26 [00:21<00:05,  1.04it/s]Epoch: 8/10. Loss: 0.9314:  81%|[36m████████  [0m| 21/26 [00:21<00:05,  1.07s/it]Epoch: 8/10. Loss: 0.9967:  81%|[36m████████  [0m| 21/26 [00:22<00:05,  1.07s/it]Epoch: 8/10. Loss: 0.9967:  85%|[36m████████▍ [0m| 22/26 [00:22<00:03,  1.00it/s]Epoch: 8/10. Loss: 0.9230:  85%|[36m████████▍ [0m| 22/26 [00:23<00:03,  1.00it/s]Epoch: 8/10. Loss: 0.9230:  88%|[36m████████▊ [0m| 23/26 [00:23<00:02,  1.06it/s]Epoch: 8/10. Loss: 1.2880:  88%|[36m████████▊ [0m| 23/26 [00:23<00:02,  1.06it/s]Epoch: 8/10. Loss: 1.2880:  92%|[36m█████████▏[0m| 24/26 [00:24<00:01,  1.08it/s]Epoch: 8/10. Loss: 0.9377:  92%|[36m█████████▏[0m| 24/26 [00:24<00:01,  1.08it/s]Epoch: 8/10. Loss: 0.9377:  96%|[36m█████████▌[0m| 25/26 [00:24<00:00,  1.07it/s]Epoch: 8/10. Loss: 0.9913:  96%|[36m█████████▌[0m| 25/26 [00:26<00:00,  1.07it/s]Epoch: 8/10. Loss: 0.9913: 100%|[36m██████████[0m| 26/26 [00:26<00:00,  1.02it/s]Epoch: 8/10. Loss: 0.9913: 100%|[36m██████████[0m| 26/26 [00:26<00:00,  1.00s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:04,  1.27it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:05,  1.12s/it] 43%|[33m████▎     [0m| 3/7 [00:02<00:03,  1.09it/s] 57%|[33m█████▋    [0m| 4/7 [00:03<00:03,  1.01s/it] 71%|[33m███████▏  [0m| 5/7 [00:04<00:01,  1.20it/s] 86%|[33m████████▌ [0m| 6/7 [00:05<00:00,  1.19it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.48it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.23it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 9/10. Loss: 1.1785:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 9/10. Loss: 1.1785:   4%|[36m▍         [0m| 1/26 [00:00<00:20,  1.19it/s]Epoch: 9/10. Loss: 1.1959:   4%|[36m▍         [0m| 1/26 [00:01<00:20,  1.19it/s]Epoch: 9/10. Loss: 1.1959:   8%|[36m▊         [0m| 2/26 [00:01<00:21,  1.13it/s]Epoch: 9/10. Loss: 1.0245:   8%|[36m▊         [0m| 2/26 [00:02<00:21,  1.13it/s]Epoch: 9/10. Loss: 1.0245:  12%|[36m█▏        [0m| 3/26 [00:02<00:21,  1.08it/s]Epoch: 9/10. Loss: 0.9932:  12%|[36m█▏        [0m| 3/26 [00:03<00:21,  1.08it/s]Epoch: 9/10. Loss: 0.9932:  15%|[36m█▌        [0m| 4/26 [00:03<00:21,  1.03it/s]Epoch: 9/10. Loss: 0.9280:  15%|[36m█▌        [0m| 4/26 [00:04<00:21,  1.03it/s]Epoch: 9/10. Loss: 0.9280:  19%|[36m█▉        [0m| 5/26 [00:04<00:20,  1.04it/s]Epoch: 9/10. Loss: 0.9724:  19%|[36m█▉        [0m| 5/26 [00:05<00:20,  1.04it/s]Epoch: 9/10. Loss: 0.9724:  23%|[36m██▎       [0m| 6/26 [00:05<00:21,  1.06s/it]Epoch: 9/10. Loss: 0.9988:  23%|[36m██▎       [0m| 6/26 [00:06<00:21,  1.06s/it]Epoch: 9/10. Loss: 0.9988:  27%|[36m██▋       [0m| 7/26 [00:06<00:18,  1.02it/s]Epoch: 9/10. Loss: 1.0674:  27%|[36m██▋       [0m| 7/26 [00:08<00:18,  1.02it/s]Epoch: 9/10. Loss: 1.0674:  31%|[36m███       [0m| 8/26 [00:09<00:24,  1.38s/it]Epoch: 9/10. Loss: 0.9580:  31%|[36m███       [0m| 8/26 [00:11<00:24,  1.38s/it]Epoch: 9/10. Loss: 0.9580:  35%|[36m███▍      [0m| 9/26 [00:11<00:28,  1.69s/it]Epoch: 9/10. Loss: 1.0402:  35%|[36m███▍      [0m| 9/26 [00:12<00:28,  1.69s/it]Epoch: 9/10. Loss: 1.0402:  38%|[36m███▊      [0m| 10/26 [00:12<00:23,  1.47s/it]Epoch: 9/10. Loss: 0.9953:  38%|[36m███▊      [0m| 10/26 [00:13<00:23,  1.47s/it]Epoch: 9/10. Loss: 0.9953:  42%|[36m████▏     [0m| 11/26 [00:13<00:19,  1.29s/it]Epoch: 9/10. Loss: 0.9077:  42%|[36m████▏     [0m| 11/26 [00:14<00:19,  1.29s/it]Epoch: 9/10. Loss: 0.9077:  46%|[36m████▌     [0m| 12/26 [00:14<00:16,  1.19s/it]Epoch: 9/10. Loss: 1.0576:  46%|[36m████▌     [0m| 12/26 [00:15<00:16,  1.19s/it]Epoch: 9/10. Loss: 1.0576:  50%|[36m█████     [0m| 13/26 [00:15<00:14,  1.12s/it]Epoch: 9/10. Loss: 1.0636:  50%|[36m█████     [0m| 13/26 [00:15<00:14,  1.12s/it]Epoch: 9/10. Loss: 1.0636:  54%|[36m█████▍    [0m| 14/26 [00:15<00:12,  1.03s/it]Epoch: 9/10. Loss: 1.0090:  54%|[36m█████▍    [0m| 14/26 [00:18<00:12,  1.03s/it]Epoch: 9/10. Loss: 1.0090:  58%|[36m█████▊    [0m| 15/26 [00:18<00:16,  1.46s/it]Epoch: 9/10. Loss: 1.1751:  58%|[36m█████▊    [0m| 15/26 [00:19<00:16,  1.46s/it]Epoch: 9/10. Loss: 1.1751:  62%|[36m██████▏   [0m| 16/26 [00:19<00:14,  1.46s/it]Epoch: 9/10. Loss: 1.1840:  62%|[36m██████▏   [0m| 16/26 [00:20<00:14,  1.46s/it]Epoch: 9/10. Loss: 1.1840:  65%|[36m██████▌   [0m| 17/26 [00:20<00:11,  1.26s/it]Epoch: 9/10. Loss: 0.9642:  65%|[36m██████▌   [0m| 17/26 [00:21<00:11,  1.26s/it]Epoch: 9/10. Loss: 0.9642:  69%|[36m██████▉   [0m| 18/26 [00:21<00:09,  1.16s/it]Epoch: 9/10. Loss: 1.0871:  69%|[36m██████▉   [0m| 18/26 [00:22<00:09,  1.16s/it]Epoch: 9/10. Loss: 1.0871:  73%|[36m███████▎  [0m| 19/26 [00:22<00:07,  1.11s/it]Epoch: 9/10. Loss: 1.0587:  73%|[36m███████▎  [0m| 19/26 [00:23<00:07,  1.11s/it]Epoch: 9/10. Loss: 1.0587:  77%|[36m███████▋  [0m| 20/26 [00:23<00:06,  1.07s/it]Epoch: 9/10. Loss: 0.9336:  77%|[36m███████▋  [0m| 20/26 [00:24<00:06,  1.07s/it]Epoch: 9/10. Loss: 0.9336:  81%|[36m████████  [0m| 21/26 [00:24<00:05,  1.02s/it]Epoch: 9/10. Loss: 1.0184:  81%|[36m████████  [0m| 21/26 [00:25<00:05,  1.02s/it]Epoch: 9/10. Loss: 1.0184:  85%|[36m████████▍ [0m| 22/26 [00:25<00:03,  1.03it/s]Epoch: 9/10. Loss: 1.1539:  85%|[36m████████▍ [0m| 22/26 [00:26<00:03,  1.03it/s]Epoch: 9/10. Loss: 1.1539:  88%|[36m████████▊ [0m| 23/26 [00:26<00:02,  1.07it/s]Epoch: 9/10. Loss: 1.1946:  88%|[36m████████▊ [0m| 23/26 [00:26<00:02,  1.07it/s]Epoch: 9/10. Loss: 1.1946:  92%|[36m█████████▏[0m| 24/26 [00:26<00:01,  1.14it/s]Epoch: 9/10. Loss: 0.9807:  92%|[36m█████████▏[0m| 24/26 [00:29<00:01,  1.14it/s]Epoch: 9/10. Loss: 0.9807:  96%|[36m█████████▌[0m| 25/26 [00:29<00:01,  1.36s/it]Epoch: 9/10. Loss: 1.0653:  96%|[36m█████████▌[0m| 25/26 [00:29<00:01,  1.36s/it]Epoch: 9/10. Loss: 1.0653: 100%|[36m██████████[0m| 26/26 [00:29<00:00,  1.12s/it]Epoch: 9/10. Loss: 1.0653: 100%|[36m██████████[0m| 26/26 [00:29<00:00,  1.15s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:04,  1.27it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:05,  1.13s/it] 43%|[33m████▎     [0m| 3/7 [00:02<00:03,  1.06it/s] 57%|[33m█████▋    [0m| 4/7 [00:04<00:03,  1.09s/it] 71%|[33m███████▏  [0m| 5/7 [00:04<00:01,  1.13it/s] 86%|[33m████████▌ [0m| 6/7 [00:07<00:01,  1.63s/it]100%|[33m██████████[0m| 7/7 [00:09<00:00,  1.70s/it]100%|[33m██████████[0m| 7/7 [00:09<00:00,  1.37s/it]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 0/10. Loss: 1.0946:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 0/10. Loss: 1.0946:   4%|[36m▍         [0m| 1/26 [00:00<00:21,  1.16it/s]Epoch: 0/10. Loss: 4.8874:   4%|[36m▍         [0m| 1/26 [00:01<00:21,  1.16it/s]Epoch: 0/10. Loss: 4.8874:   8%|[36m▊         [0m| 2/26 [00:01<00:21,  1.12it/s]Epoch: 0/10. Loss: 2.8882:   8%|[36m▊         [0m| 2/26 [00:02<00:21,  1.12it/s]Epoch: 0/10. Loss: 2.8882:  12%|[36m█▏        [0m| 3/26 [00:02<00:21,  1.05it/s]Epoch: 0/10. Loss: 1.3810:  12%|[36m█▏        [0m| 3/26 [00:03<00:21,  1.05it/s]Epoch: 0/10. Loss: 1.3810:  15%|[36m█▌        [0m| 4/26 [00:03<00:19,  1.13it/s]Epoch: 0/10. Loss: 2.3888:  15%|[36m█▌        [0m| 4/26 [00:04<00:19,  1.13it/s]Epoch: 0/10. Loss: 2.3888:  19%|[36m█▉        [0m| 5/26 [00:04<00:20,  1.03it/s]Epoch: 0/10. Loss: 1.7241:  19%|[36m█▉        [0m| 5/26 [00:05<00:20,  1.03it/s]Epoch: 0/10. Loss: 1.7241:  23%|[36m██▎       [0m| 6/26 [00:05<00:18,  1.06it/s]Epoch: 0/10. Loss: 1.1558:  23%|[36m██▎       [0m| 6/26 [00:06<00:18,  1.06it/s]Epoch: 0/10. Loss: 1.1558:  27%|[36m██▋       [0m| 7/26 [00:06<00:17,  1.08it/s]Epoch: 0/10. Loss: 1.3697:  27%|[36m██▋       [0m| 7/26 [00:07<00:17,  1.08it/s]Epoch: 0/10. Loss: 1.3697:  31%|[36m███       [0m| 8/26 [00:07<00:16,  1.09it/s]Epoch: 0/10. Loss: 1.2425:  31%|[36m███       [0m| 8/26 [00:08<00:16,  1.09it/s]Epoch: 0/10. Loss: 1.2425:  35%|[36m███▍      [0m| 9/26 [00:08<00:15,  1.10it/s]Epoch: 0/10. Loss: 1.6362:  35%|[36m███▍      [0m| 9/26 [00:09<00:15,  1.10it/s]Epoch: 0/10. Loss: 1.6362:  38%|[36m███▊      [0m| 10/26 [00:09<00:15,  1.04it/s]Epoch: 0/10. Loss: 1.8657:  38%|[36m███▊      [0m| 10/26 [00:10<00:15,  1.04it/s]Epoch: 0/10. Loss: 1.8657:  42%|[36m████▏     [0m| 11/26 [00:10<00:14,  1.06it/s]Epoch: 0/10. Loss: 1.3337:  42%|[36m████▏     [0m| 11/26 [00:11<00:14,  1.06it/s]Epoch: 0/10. Loss: 1.3337:  46%|[36m████▌     [0m| 12/26 [00:11<00:14,  1.02s/it]Epoch: 0/10. Loss: 1.1580:  46%|[36m████▌     [0m| 12/26 [00:12<00:14,  1.02s/it]Epoch: 0/10. Loss: 1.1580:  50%|[36m█████     [0m| 13/26 [00:12<00:12,  1.03it/s]Epoch: 0/10. Loss: 0.9880:  50%|[36m█████     [0m| 13/26 [00:13<00:12,  1.03it/s]Epoch: 0/10. Loss: 0.9880:  54%|[36m█████▍    [0m| 14/26 [00:13<00:10,  1.10it/s]Epoch: 0/10. Loss: 1.1414:  54%|[36m█████▍    [0m| 14/26 [00:13<00:10,  1.10it/s]Epoch: 0/10. Loss: 1.1414:  58%|[36m█████▊    [0m| 15/26 [00:13<00:09,  1.14it/s]Epoch: 0/10. Loss: 1.2158:  58%|[36m█████▊    [0m| 15/26 [00:14<00:09,  1.14it/s]Epoch: 0/10. Loss: 1.2158:  62%|[36m██████▏   [0m| 16/26 [00:14<00:09,  1.09it/s]Epoch: 0/10. Loss: 1.0626:  62%|[36m██████▏   [0m| 16/26 [00:15<00:09,  1.09it/s]Epoch: 0/10. Loss: 1.0626:  65%|[36m██████▌   [0m| 17/26 [00:15<00:08,  1.12it/s]Epoch: 0/10. Loss: 1.0324:  65%|[36m██████▌   [0m| 17/26 [00:16<00:08,  1.12it/s]Epoch: 0/10. Loss: 1.0324:  69%|[36m██████▉   [0m| 18/26 [00:16<00:07,  1.07it/s]Epoch: 0/10. Loss: 1.1259:  69%|[36m██████▉   [0m| 18/26 [00:17<00:07,  1.07it/s]Epoch: 0/10. Loss: 1.1259:  73%|[36m███████▎  [0m| 19/26 [00:17<00:06,  1.09it/s]Epoch: 0/10. Loss: 1.0849:  73%|[36m███████▎  [0m| 19/26 [00:18<00:06,  1.09it/s]Epoch: 0/10. Loss: 1.0849:  77%|[36m███████▋  [0m| 20/26 [00:18<00:05,  1.05it/s]Epoch: 0/10. Loss: 0.9471:  77%|[36m███████▋  [0m| 20/26 [00:19<00:05,  1.05it/s]Epoch: 0/10. Loss: 0.9471:  81%|[36m████████  [0m| 21/26 [00:19<00:04,  1.08it/s]Epoch: 0/10. Loss: 1.0088:  81%|[36m████████  [0m| 21/26 [00:20<00:04,  1.08it/s]Epoch: 0/10. Loss: 1.0088:  85%|[36m████████▍ [0m| 22/26 [00:20<00:03,  1.06it/s]Epoch: 0/10. Loss: 1.0497:  85%|[36m████████▍ [0m| 22/26 [00:21<00:03,  1.06it/s]Epoch: 0/10. Loss: 1.0497:  88%|[36m████████▊ [0m| 23/26 [00:21<00:02,  1.05it/s]Epoch: 0/10. Loss: 0.9965:  88%|[36m████████▊ [0m| 23/26 [00:22<00:02,  1.05it/s]Epoch: 0/10. Loss: 0.9965:  92%|[36m█████████▏[0m| 24/26 [00:22<00:01,  1.08it/s]Epoch: 0/10. Loss: 1.0019:  92%|[36m█████████▏[0m| 24/26 [00:23<00:01,  1.08it/s]Epoch: 0/10. Loss: 1.0019:  96%|[36m█████████▌[0m| 25/26 [00:23<00:00,  1.07it/s]Epoch: 0/10. Loss: 1.2603:  96%|[36m█████████▌[0m| 25/26 [00:23<00:00,  1.07it/s]Epoch: 0/10. Loss: 1.2603: 100%|[36m██████████[0m| 26/26 [00:23<00:00,  1.19it/s]Epoch: 0/10. Loss: 1.2603: 100%|[36m██████████[0m| 26/26 [00:23<00:00,  1.09it/s]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:01<00:08,  1.44s/it] 29%|[33m██▊       [0m| 2/7 [00:02<00:06,  1.37s/it] 43%|[33m████▎     [0m| 3/7 [00:03<00:04,  1.02s/it] 57%|[33m█████▋    [0m| 4/7 [00:04<00:03,  1.03s/it] 71%|[33m███████▏  [0m| 5/7 [00:04<00:01,  1.22it/s] 86%|[33m████████▌ [0m| 6/7 [00:05<00:00,  1.24it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.57it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.18it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 1/10. Loss: 1.0479:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 1/10. Loss: 1.0479:   4%|[36m▍         [0m| 1/26 [00:00<00:21,  1.18it/s]Epoch: 1/10. Loss: 1.0055:   4%|[36m▍         [0m| 1/26 [00:01<00:21,  1.18it/s]Epoch: 1/10. Loss: 1.0055:   8%|[36m▊         [0m| 2/26 [00:01<00:21,  1.10it/s]Epoch: 1/10. Loss: 1.0054:   8%|[36m▊         [0m| 2/26 [00:02<00:21,  1.10it/s]Epoch: 1/10. Loss: 1.0054:  12%|[36m█▏        [0m| 3/26 [00:02<00:21,  1.07it/s]Epoch: 1/10. Loss: 1.0897:  12%|[36m█▏        [0m| 3/26 [00:03<00:21,  1.07it/s]Epoch: 1/10. Loss: 1.0897:  15%|[36m█▌        [0m| 4/26 [00:03<00:19,  1.13it/s]Epoch: 1/10. Loss: 1.1355:  15%|[36m█▌        [0m| 4/26 [00:04<00:19,  1.13it/s]Epoch: 1/10. Loss: 1.1355:  19%|[36m█▉        [0m| 5/26 [00:04<00:18,  1.11it/s]Epoch: 1/10. Loss: 0.9430:  19%|[36m█▉        [0m| 5/26 [00:05<00:18,  1.11it/s]Epoch: 1/10. Loss: 0.9430:  23%|[36m██▎       [0m| 6/26 [00:05<00:18,  1.07it/s]Epoch: 1/10. Loss: 1.0151:  23%|[36m██▎       [0m| 6/26 [00:06<00:18,  1.07it/s]Epoch: 1/10. Loss: 1.0151:  27%|[36m██▋       [0m| 7/26 [00:06<00:16,  1.13it/s]Epoch: 1/10. Loss: 0.9930:  27%|[36m██▋       [0m| 7/26 [00:07<00:16,  1.13it/s]Epoch: 1/10. Loss: 0.9930:  31%|[36m███       [0m| 8/26 [00:07<00:15,  1.15it/s]Epoch: 1/10. Loss: 1.1152:  31%|[36m███       [0m| 8/26 [00:08<00:15,  1.15it/s]Epoch: 1/10. Loss: 1.1152:  35%|[36m███▍      [0m| 9/26 [00:08<00:15,  1.11it/s]Epoch: 1/10. Loss: 0.9384:  35%|[36m███▍      [0m| 9/26 [00:09<00:15,  1.11it/s]Epoch: 1/10. Loss: 0.9384:  38%|[36m███▊      [0m| 10/26 [00:09<00:15,  1.05it/s]Epoch: 1/10. Loss: 0.9792:  38%|[36m███▊      [0m| 10/26 [00:10<00:15,  1.05it/s]Epoch: 1/10. Loss: 0.9792:  42%|[36m████▏     [0m| 11/26 [00:10<00:14,  1.06it/s]Epoch: 1/10. Loss: 0.9468:  42%|[36m████▏     [0m| 11/26 [00:11<00:14,  1.06it/s]Epoch: 1/10. Loss: 0.9468:  46%|[36m████▌     [0m| 12/26 [00:11<00:13,  1.05it/s]Epoch: 1/10. Loss: 1.0178:  46%|[36m████▌     [0m| 12/26 [00:11<00:13,  1.05it/s]Epoch: 1/10. Loss: 1.0178:  50%|[36m█████     [0m| 13/26 [00:11<00:12,  1.06it/s]Epoch: 1/10. Loss: 0.9598:  50%|[36m█████     [0m| 13/26 [00:12<00:12,  1.06it/s]Epoch: 1/10. Loss: 0.9598:  54%|[36m█████▍    [0m| 14/26 [00:12<00:10,  1.14it/s]Epoch: 1/10. Loss: 0.9721:  54%|[36m█████▍    [0m| 14/26 [00:13<00:10,  1.14it/s]Epoch: 1/10. Loss: 0.9721:  58%|[36m█████▊    [0m| 15/26 [00:13<00:09,  1.14it/s]Epoch: 1/10. Loss: 0.9505:  58%|[36m█████▊    [0m| 15/26 [00:14<00:09,  1.14it/s]Epoch: 1/10. Loss: 0.9505:  62%|[36m██████▏   [0m| 16/26 [00:14<00:08,  1.21it/s]Epoch: 1/10. Loss: 0.9505:  62%|[36m██████▏   [0m| 16/26 [00:15<00:08,  1.21it/s]Epoch: 1/10. Loss: 0.9505:  65%|[36m██████▌   [0m| 17/26 [00:15<00:07,  1.14it/s]Epoch: 1/10. Loss: 0.9186:  65%|[36m██████▌   [0m| 17/26 [00:16<00:07,  1.14it/s]Epoch: 1/10. Loss: 0.9186:  69%|[36m██████▉   [0m| 18/26 [00:16<00:07,  1.11it/s]Epoch: 1/10. Loss: 0.9238:  69%|[36m██████▉   [0m| 18/26 [00:17<00:07,  1.11it/s]Epoch: 1/10. Loss: 0.9238:  73%|[36m███████▎  [0m| 19/26 [00:17<00:06,  1.06it/s]Epoch: 1/10. Loss: 1.0571:  73%|[36m███████▎  [0m| 19/26 [00:18<00:06,  1.06it/s]Epoch: 1/10. Loss: 1.0571:  77%|[36m███████▋  [0m| 20/26 [00:18<00:05,  1.09it/s]Epoch: 1/10. Loss: 0.8824:  77%|[36m███████▋  [0m| 20/26 [00:18<00:05,  1.09it/s]Epoch: 1/10. Loss: 0.8824:  81%|[36m████████  [0m| 21/26 [00:18<00:04,  1.13it/s]Epoch: 1/10. Loss: 0.9271:  81%|[36m████████  [0m| 21/26 [00:19<00:04,  1.13it/s]Epoch: 1/10. Loss: 0.9271:  85%|[36m████████▍ [0m| 22/26 [00:19<00:03,  1.19it/s]Epoch: 1/10. Loss: 0.9441:  85%|[36m████████▍ [0m| 22/26 [00:20<00:03,  1.19it/s]Epoch: 1/10. Loss: 0.9441:  88%|[36m████████▊ [0m| 23/26 [00:20<00:02,  1.09it/s]Epoch: 1/10. Loss: 0.9227:  88%|[36m████████▊ [0m| 23/26 [00:21<00:02,  1.09it/s]Epoch: 1/10. Loss: 0.9227:  92%|[36m█████████▏[0m| 24/26 [00:21<00:01,  1.03it/s]Epoch: 1/10. Loss: 0.9108:  92%|[36m█████████▏[0m| 24/26 [00:22<00:01,  1.03it/s]Epoch: 1/10. Loss: 0.9108:  96%|[36m█████████▌[0m| 25/26 [00:22<00:00,  1.00it/s]Epoch: 1/10. Loss: 0.9198:  96%|[36m█████████▌[0m| 25/26 [00:23<00:00,  1.00it/s]Epoch: 1/10. Loss: 0.9198: 100%|[36m██████████[0m| 26/26 [00:23<00:00,  1.11it/s]Epoch: 1/10. Loss: 0.9198: 100%|[36m██████████[0m| 26/26 [00:23<00:00,  1.10it/s]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:04,  1.24it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:05,  1.14s/it] 43%|[33m████▎     [0m| 3/7 [00:02<00:03,  1.10it/s] 57%|[33m█████▋    [0m| 4/7 [00:03<00:02,  1.03it/s] 71%|[33m███████▏  [0m| 5/7 [00:04<00:01,  1.26it/s] 86%|[33m████████▌ [0m| 6/7 [00:05<00:00,  1.25it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.57it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.28it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 2/10. Loss: 0.8644:   0%|[36m          [0m| 0/26 [00:02<?, ?it/s]Epoch: 2/10. Loss: 0.8644:   4%|[36m▍         [0m| 1/26 [00:02<01:12,  2.91s/it]Epoch: 2/10. Loss: 0.8662:   4%|[36m▍         [0m| 1/26 [00:03<01:12,  2.91s/it]Epoch: 2/10. Loss: 0.8662:   8%|[36m▊         [0m| 2/26 [00:03<00:41,  1.73s/it]Epoch: 2/10. Loss: 0.9376:   8%|[36m▊         [0m| 2/26 [00:04<00:41,  1.73s/it]Epoch: 2/10. Loss: 0.9376:  12%|[36m█▏        [0m| 3/26 [00:04<00:31,  1.38s/it]Epoch: 2/10. Loss: 0.8763:  12%|[36m█▏        [0m| 3/26 [00:06<00:31,  1.38s/it]Epoch: 2/10. Loss: 0.8763:  15%|[36m█▌        [0m| 4/26 [00:06<00:30,  1.38s/it]Epoch: 2/10. Loss: 0.9601:  15%|[36m█▌        [0m| 4/26 [00:06<00:30,  1.38s/it]Epoch: 2/10. Loss: 0.9601:  19%|[36m█▉        [0m| 5/26 [00:06<00:24,  1.18s/it]Epoch: 2/10. Loss: 0.9382:  19%|[36m█▉        [0m| 5/26 [00:07<00:24,  1.18s/it]Epoch: 2/10. Loss: 0.9382:  23%|[36m██▎       [0m| 6/26 [00:07<00:22,  1.10s/it]Epoch: 2/10. Loss: 0.8472:  23%|[36m██▎       [0m| 6/26 [00:08<00:22,  1.10s/it]Epoch: 2/10. Loss: 0.8472:  27%|[36m██▋       [0m| 7/26 [00:08<00:19,  1.03s/it]Epoch: 2/10. Loss: 0.8685:  27%|[36m██▋       [0m| 7/26 [00:09<00:19,  1.03s/it]Epoch: 2/10. Loss: 0.8685:  31%|[36m███       [0m| 8/26 [00:09<00:17,  1.04it/s]Epoch: 2/10. Loss: 0.9143:  31%|[36m███       [0m| 8/26 [00:10<00:17,  1.04it/s]Epoch: 2/10. Loss: 0.9143:  35%|[36m███▍      [0m| 9/26 [00:10<00:16,  1.05it/s]Epoch: 2/10. Loss: 0.7981:  35%|[36m███▍      [0m| 9/26 [00:11<00:16,  1.05it/s]Epoch: 2/10. Loss: 0.7981:  38%|[36m███▊      [0m| 10/26 [00:11<00:15,  1.04it/s]Epoch: 2/10. Loss: 0.8572:  38%|[36m███▊      [0m| 10/26 [00:12<00:15,  1.04it/s]Epoch: 2/10. Loss: 0.8572:  42%|[36m████▏     [0m| 11/26 [00:12<00:14,  1.05it/s]Epoch: 2/10. Loss: 0.9779:  42%|[36m████▏     [0m| 11/26 [00:13<00:14,  1.05it/s]Epoch: 2/10. Loss: 0.9779:  46%|[36m████▌     [0m| 12/26 [00:13<00:13,  1.07it/s]Epoch: 2/10. Loss: 0.9751:  46%|[36m████▌     [0m| 12/26 [00:14<00:13,  1.07it/s]Epoch: 2/10. Loss: 0.9751:  50%|[36m█████     [0m| 13/26 [00:14<00:11,  1.08it/s]Epoch: 2/10. Loss: 1.0710:  50%|[36m█████     [0m| 13/26 [00:15<00:11,  1.08it/s]Epoch: 2/10. Loss: 1.0710:  54%|[36m█████▍    [0m| 14/26 [00:15<00:11,  1.06it/s]Epoch: 2/10. Loss: 0.9433:  54%|[36m█████▍    [0m| 14/26 [00:16<00:11,  1.06it/s]Epoch: 2/10. Loss: 0.9433:  58%|[36m█████▊    [0m| 15/26 [00:16<00:10,  1.07it/s]Epoch: 2/10. Loss: 0.8595:  58%|[36m█████▊    [0m| 15/26 [00:17<00:10,  1.07it/s]Epoch: 2/10. Loss: 0.8595:  62%|[36m██████▏   [0m| 16/26 [00:17<00:09,  1.07it/s]Epoch: 2/10. Loss: 0.8697:  62%|[36m██████▏   [0m| 16/26 [00:17<00:09,  1.07it/s]Epoch: 2/10. Loss: 0.8697:  65%|[36m██████▌   [0m| 17/26 [00:18<00:08,  1.08it/s]Epoch: 2/10. Loss: 0.8705:  65%|[36m██████▌   [0m| 17/26 [00:18<00:08,  1.08it/s]Epoch: 2/10. Loss: 0.8705:  69%|[36m██████▉   [0m| 18/26 [00:18<00:07,  1.08it/s]Epoch: 2/10. Loss: 0.8669:  69%|[36m██████▉   [0m| 18/26 [00:19<00:07,  1.08it/s]Epoch: 2/10. Loss: 0.8669:  73%|[36m███████▎  [0m| 19/26 [00:19<00:06,  1.08it/s]Epoch: 2/10. Loss: 0.8872:  73%|[36m███████▎  [0m| 19/26 [00:20<00:06,  1.08it/s]Epoch: 2/10. Loss: 0.8872:  77%|[36m███████▋  [0m| 20/26 [00:20<00:05,  1.06it/s]Epoch: 2/10. Loss: 0.9629:  77%|[36m███████▋  [0m| 20/26 [00:22<00:05,  1.06it/s]Epoch: 2/10. Loss: 0.9629:  81%|[36m████████  [0m| 21/26 [00:22<00:05,  1.02s/it]Epoch: 2/10. Loss: 0.8855:  81%|[36m████████  [0m| 21/26 [00:22<00:05,  1.02s/it]Epoch: 2/10. Loss: 0.8855:  85%|[36m████████▍ [0m| 22/26 [00:22<00:03,  1.07it/s]Epoch: 2/10. Loss: 0.8571:  85%|[36m████████▍ [0m| 22/26 [00:23<00:03,  1.07it/s]Epoch: 2/10. Loss: 0.8571:  88%|[36m████████▊ [0m| 23/26 [00:23<00:02,  1.08it/s]Epoch: 2/10. Loss: 0.8880:  88%|[36m████████▊ [0m| 23/26 [00:24<00:02,  1.08it/s]Epoch: 2/10. Loss: 0.8880:  92%|[36m█████████▏[0m| 24/26 [00:24<00:01,  1.10it/s]Epoch: 2/10. Loss: 0.9594:  92%|[36m█████████▏[0m| 24/26 [00:25<00:01,  1.10it/s]Epoch: 2/10. Loss: 0.9594:  96%|[36m█████████▌[0m| 25/26 [00:25<00:00,  1.14it/s]Epoch: 2/10. Loss: 0.8090:  96%|[36m█████████▌[0m| 25/26 [00:26<00:00,  1.14it/s]Epoch: 2/10. Loss: 0.8090: 100%|[36m██████████[0m| 26/26 [00:26<00:00,  1.18it/s]Epoch: 2/10. Loss: 0.8090: 100%|[36m██████████[0m| 26/26 [00:26<00:00,  1.00s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:04,  1.44it/s] 29%|[33m██▊       [0m| 2/7 [00:01<00:05,  1.05s/it] 43%|[33m████▎     [0m| 3/7 [00:02<00:03,  1.19it/s] 57%|[33m█████▋    [0m| 4/7 [00:03<00:02,  1.07it/s] 71%|[33m███████▏  [0m| 5/7 [00:04<00:01,  1.33it/s] 86%|[33m████████▌ [0m| 6/7 [00:04<00:00,  1.31it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.52it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.32it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 3/10. Loss: 0.9019:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 3/10. Loss: 0.9019:   4%|[36m▍         [0m| 1/26 [00:00<00:24,  1.03it/s]Epoch: 3/10. Loss: 0.9331:   4%|[36m▍         [0m| 1/26 [00:01<00:24,  1.03it/s]Epoch: 3/10. Loss: 0.9331:   8%|[36m▊         [0m| 2/26 [00:01<00:23,  1.03it/s]Epoch: 3/10. Loss: 0.8189:   8%|[36m▊         [0m| 2/26 [00:02<00:23,  1.03it/s]Epoch: 3/10. Loss: 0.8189:  12%|[36m█▏        [0m| 3/26 [00:02<00:22,  1.04it/s]Epoch: 3/10. Loss: 0.8926:  12%|[36m█▏        [0m| 3/26 [00:03<00:22,  1.04it/s]Epoch: 3/10. Loss: 0.8926:  15%|[36m█▌        [0m| 4/26 [00:03<00:21,  1.03it/s]Epoch: 3/10. Loss: 0.8917:  15%|[36m█▌        [0m| 4/26 [00:04<00:21,  1.03it/s]Epoch: 3/10. Loss: 0.8917:  19%|[36m█▉        [0m| 5/26 [00:04<00:19,  1.06it/s]Epoch: 3/10. Loss: 0.8286:  19%|[36m█▉        [0m| 5/26 [00:05<00:19,  1.06it/s]Epoch: 3/10. Loss: 0.8286:  23%|[36m██▎       [0m| 6/26 [00:05<00:18,  1.05it/s]Epoch: 3/10. Loss: 0.8225:  23%|[36m██▎       [0m| 6/26 [00:06<00:18,  1.05it/s]Epoch: 3/10. Loss: 0.8225:  27%|[36m██▋       [0m| 7/26 [00:06<00:18,  1.04it/s]Epoch: 3/10. Loss: 0.9361:  27%|[36m██▋       [0m| 7/26 [00:07<00:18,  1.04it/s]Epoch: 3/10. Loss: 0.9361:  31%|[36m███       [0m| 8/26 [00:07<00:16,  1.06it/s]Epoch: 3/10. Loss: 0.7316:  31%|[36m███       [0m| 8/26 [00:08<00:16,  1.06it/s]Epoch: 3/10. Loss: 0.7316:  35%|[36m███▍      [0m| 9/26 [00:08<00:16,  1.03it/s]Epoch: 3/10. Loss: 0.8176:  35%|[36m███▍      [0m| 9/26 [00:09<00:16,  1.03it/s]Epoch: 3/10. Loss: 0.8176:  38%|[36m███▊      [0m| 10/26 [00:09<00:14,  1.09it/s]Epoch: 3/10. Loss: 0.9475:  38%|[36m███▊      [0m| 10/26 [00:10<00:14,  1.09it/s]Epoch: 3/10. Loss: 0.9475:  42%|[36m████▏     [0m| 11/26 [00:10<00:13,  1.08it/s]Epoch: 3/10. Loss: 0.8436:  42%|[36m████▏     [0m| 11/26 [00:11<00:13,  1.08it/s]Epoch: 3/10. Loss: 0.8436:  46%|[36m████▌     [0m| 12/26 [00:11<00:12,  1.13it/s]Epoch: 3/10. Loss: 0.8408:  46%|[36m████▌     [0m| 12/26 [00:12<00:12,  1.13it/s]Epoch: 3/10. Loss: 0.8408:  50%|[36m█████     [0m| 13/26 [00:12<00:12,  1.05it/s]Epoch: 3/10. Loss: 1.0145:  50%|[36m█████     [0m| 13/26 [00:14<00:12,  1.05it/s]Epoch: 3/10. Loss: 1.0145:  54%|[36m█████▍    [0m| 14/26 [00:14<00:16,  1.38s/it]Epoch: 3/10. Loss: 0.8594:  54%|[36m█████▍    [0m| 14/26 [00:16<00:16,  1.38s/it]Epoch: 3/10. Loss: 0.8594:  58%|[36m█████▊    [0m| 15/26 [00:16<00:15,  1.42s/it]Epoch: 3/10. Loss: 0.8446:  58%|[36m█████▊    [0m| 15/26 [00:17<00:15,  1.42s/it]Epoch: 3/10. Loss: 0.8446:  62%|[36m██████▏   [0m| 16/26 [00:17<00:14,  1.45s/it]Epoch: 3/10. Loss: 0.8420:  62%|[36m██████▏   [0m| 16/26 [00:18<00:14,  1.45s/it]Epoch: 3/10. Loss: 0.8420:  65%|[36m██████▌   [0m| 17/26 [00:18<00:11,  1.26s/it]Epoch: 3/10. Loss: 0.9583:  65%|[36m██████▌   [0m| 17/26 [00:19<00:11,  1.26s/it]Epoch: 3/10. Loss: 0.9583:  69%|[36m██████▉   [0m| 18/26 [00:19<00:09,  1.19s/it]Epoch: 3/10. Loss: 0.9201:  69%|[36m██████▉   [0m| 18/26 [00:20<00:09,  1.19s/it]Epoch: 3/10. Loss: 0.9201:  73%|[36m███████▎  [0m| 19/26 [00:20<00:07,  1.09s/it]Epoch: 3/10. Loss: 0.9217:  73%|[36m███████▎  [0m| 19/26 [00:21<00:07,  1.09s/it]Epoch: 3/10. Loss: 0.9217:  77%|[36m███████▋  [0m| 20/26 [00:21<00:06,  1.16s/it]Epoch: 3/10. Loss: 0.9577:  77%|[36m███████▋  [0m| 20/26 [00:22<00:06,  1.16s/it]Epoch: 3/10. Loss: 0.9577:  81%|[36m████████  [0m| 21/26 [00:22<00:05,  1.08s/it]Epoch: 3/10. Loss: 0.9347:  81%|[36m████████  [0m| 21/26 [00:23<00:05,  1.08s/it]Epoch: 3/10. Loss: 0.9347:  85%|[36m████████▍ [0m| 22/26 [00:23<00:04,  1.05s/it]Epoch: 3/10. Loss: 0.8407:  85%|[36m████████▍ [0m| 22/26 [00:24<00:04,  1.05s/it]Epoch: 3/10. Loss: 0.8407:  88%|[36m████████▊ [0m| 23/26 [00:24<00:02,  1.01it/s]Epoch: 3/10. Loss: 0.8727:  88%|[36m████████▊ [0m| 23/26 [00:25<00:02,  1.01it/s]Epoch: 3/10. Loss: 0.8727:  92%|[36m█████████▏[0m| 24/26 [00:25<00:01,  1.04it/s]Epoch: 3/10. Loss: 0.8491:  92%|[36m█████████▏[0m| 24/26 [00:26<00:01,  1.04it/s]Epoch: 3/10. Loss: 0.8491:  96%|[36m█████████▌[0m| 25/26 [00:26<00:00,  1.09it/s]Epoch: 3/10. Loss: 0.8876:  96%|[36m█████████▌[0m| 25/26 [00:26<00:00,  1.09it/s]Epoch: 3/10. Loss: 0.8876: 100%|[36m██████████[0m| 26/26 [00:26<00:00,  1.20it/s]Epoch: 3/10. Loss: 0.8876: 100%|[36m██████████[0m| 26/26 [00:26<00:00,  1.03s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:04,  1.36it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:05,  1.08s/it] 43%|[33m████▎     [0m| 3/7 [00:02<00:03,  1.14it/s] 57%|[33m█████▋    [0m| 4/7 [00:03<00:02,  1.03it/s] 71%|[33m███████▏  [0m| 5/7 [00:04<00:01,  1.26it/s] 86%|[33m████████▌ [0m| 6/7 [00:05<00:00,  1.24it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.55it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.29it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 4/10. Loss: 0.8164:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 4/10. Loss: 0.8164:   4%|[36m▍         [0m| 1/26 [00:00<00:23,  1.06it/s]Epoch: 4/10. Loss: 0.8216:   4%|[36m▍         [0m| 1/26 [00:01<00:23,  1.06it/s]Epoch: 4/10. Loss: 0.8216:   8%|[36m▊         [0m| 2/26 [00:01<00:21,  1.10it/s]Epoch: 4/10. Loss: 0.8167:   8%|[36m▊         [0m| 2/26 [00:03<00:21,  1.10it/s]Epoch: 4/10. Loss: 0.8167:  12%|[36m█▏        [0m| 3/26 [00:04<00:34,  1.49s/it]Epoch: 4/10. Loss: 0.7665:  12%|[36m█▏        [0m| 3/26 [00:05<00:34,  1.49s/it]Epoch: 4/10. Loss: 0.7665:  15%|[36m█▌        [0m| 4/26 [00:05<00:30,  1.39s/it]Epoch: 4/10. Loss: 0.8235:  15%|[36m█▌        [0m| 4/26 [00:06<00:30,  1.39s/it]Epoch: 4/10. Loss: 0.8235:  19%|[36m█▉        [0m| 5/26 [00:06<00:25,  1.22s/it]Epoch: 4/10. Loss: 0.6863:  19%|[36m█▉        [0m| 5/26 [00:06<00:25,  1.22s/it]Epoch: 4/10. Loss: 0.6863:  23%|[36m██▎       [0m| 6/26 [00:06<00:21,  1.08s/it]Epoch: 4/10. Loss: 0.8299:  23%|[36m██▎       [0m| 6/26 [00:07<00:21,  1.08s/it]Epoch: 4/10. Loss: 0.8299:  27%|[36m██▋       [0m| 7/26 [00:07<00:19,  1.02s/it]Epoch: 4/10. Loss: 0.9555:  27%|[36m██▋       [0m| 7/26 [00:10<00:19,  1.02s/it]Epoch: 4/10. Loss: 0.9555:  31%|[36m███       [0m| 8/26 [00:10<00:29,  1.65s/it]Epoch: 4/10. Loss: 0.8359:  31%|[36m███       [0m| 8/26 [00:12<00:29,  1.65s/it]Epoch: 4/10. Loss: 0.8359:  35%|[36m███▍      [0m| 9/26 [00:12<00:25,  1.49s/it]Epoch: 4/10. Loss: 1.0152:  35%|[36m███▍      [0m| 9/26 [00:12<00:25,  1.49s/it]Epoch: 4/10. Loss: 1.0152:  38%|[36m███▊      [0m| 10/26 [00:12<00:20,  1.30s/it]Epoch: 4/10. Loss: 0.8556:  38%|[36m███▊      [0m| 10/26 [00:14<00:20,  1.30s/it]Epoch: 4/10. Loss: 0.8556:  42%|[36m████▏     [0m| 11/26 [00:14<00:19,  1.31s/it]Epoch: 4/10. Loss: 0.9676:  42%|[36m████▏     [0m| 11/26 [00:15<00:19,  1.31s/it]Epoch: 4/10. Loss: 0.9676:  46%|[36m████▌     [0m| 12/26 [00:15<00:16,  1.19s/it]Epoch: 4/10. Loss: 0.9574:  46%|[36m████▌     [0m| 12/26 [00:16<00:16,  1.19s/it]Epoch: 4/10. Loss: 0.9574:  50%|[36m█████     [0m| 13/26 [00:16<00:15,  1.21s/it]Epoch: 4/10. Loss: 0.8808:  50%|[36m█████     [0m| 13/26 [00:17<00:15,  1.21s/it]Epoch: 4/10. Loss: 0.8808:  54%|[36m█████▍    [0m| 14/26 [00:17<00:12,  1.08s/it]Epoch: 4/10. Loss: 0.7972:  54%|[36m█████▍    [0m| 14/26 [00:18<00:12,  1.08s/it]Epoch: 4/10. Loss: 0.7972:  58%|[36m█████▊    [0m| 15/26 [00:18<00:11,  1.01s/it]Epoch: 4/10. Loss: 0.8872:  58%|[36m█████▊    [0m| 15/26 [00:21<00:11,  1.01s/it]Epoch: 4/10. Loss: 0.8872:  62%|[36m██████▏   [0m| 16/26 [00:21<00:16,  1.63s/it]Epoch: 4/10. Loss: 0.9559:  62%|[36m██████▏   [0m| 16/26 [00:22<00:16,  1.63s/it]Epoch: 4/10. Loss: 0.9559:  65%|[36m██████▌   [0m| 17/26 [00:22<00:12,  1.42s/it]Epoch: 4/10. Loss: 0.8357:  65%|[36m██████▌   [0m| 17/26 [00:22<00:12,  1.42s/it]Epoch: 4/10. Loss: 0.8357:  69%|[36m██████▉   [0m| 18/26 [00:22<00:09,  1.24s/it]Epoch: 4/10. Loss: 0.8733:  69%|[36m██████▉   [0m| 18/26 [00:23<00:09,  1.24s/it]Epoch: 4/10. Loss: 0.8733:  73%|[36m███████▎  [0m| 19/26 [00:23<00:07,  1.14s/it]Epoch: 4/10. Loss: 0.9231:  73%|[36m███████▎  [0m| 19/26 [00:24<00:07,  1.14s/it]Epoch: 4/10. Loss: 0.9231:  77%|[36m███████▋  [0m| 20/26 [00:24<00:06,  1.11s/it]Epoch: 4/10. Loss: 0.8636:  77%|[36m███████▋  [0m| 20/26 [00:25<00:06,  1.11s/it]Epoch: 4/10. Loss: 0.8636:  81%|[36m████████  [0m| 21/26 [00:25<00:05,  1.04s/it]Epoch: 4/10. Loss: 0.9055:  81%|[36m████████  [0m| 21/26 [00:27<00:05,  1.04s/it]Epoch: 4/10. Loss: 0.9055:  85%|[36m████████▍ [0m| 22/26 [00:27<00:04,  1.20s/it]Epoch: 4/10. Loss: 0.9356:  85%|[36m████████▍ [0m| 22/26 [00:28<00:04,  1.20s/it]Epoch: 4/10. Loss: 0.9356:  88%|[36m████████▊ [0m| 23/26 [00:28<00:03,  1.13s/it]Epoch: 4/10. Loss: 0.8947:  88%|[36m████████▊ [0m| 23/26 [00:29<00:03,  1.13s/it]Epoch: 4/10. Loss: 0.8947:  92%|[36m█████████▏[0m| 24/26 [00:29<00:02,  1.04s/it]Epoch: 4/10. Loss: 0.9098:  92%|[36m█████████▏[0m| 24/26 [00:30<00:02,  1.04s/it]Epoch: 4/10. Loss: 0.9098:  96%|[36m█████████▌[0m| 25/26 [00:30<00:01,  1.03s/it]Epoch: 4/10. Loss: 0.7186:  96%|[36m█████████▌[0m| 25/26 [00:30<00:01,  1.03s/it]Epoch: 4/10. Loss: 0.7186: 100%|[36m██████████[0m| 26/26 [00:30<00:00,  1.04it/s]Epoch: 4/10. Loss: 0.7186: 100%|[36m██████████[0m| 26/26 [00:30<00:00,  1.19s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:04,  1.42it/s] 29%|[33m██▊       [0m| 2/7 [00:04<00:11,  2.34s/it] 43%|[33m████▎     [0m| 3/7 [00:05<00:06,  1.64s/it] 57%|[33m█████▋    [0m| 4/7 [00:06<00:04,  1.43s/it] 71%|[33m███████▏  [0m| 5/7 [00:06<00:02,  1.09s/it] 86%|[33m████████▌ [0m| 6/7 [00:07<00:00,  1.00it/s]100%|[33m██████████[0m| 7/7 [00:07<00:00,  1.30it/s]100%|[33m██████████[0m| 7/7 [00:07<00:00,  1.10s/it]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 5/10. Loss: 0.8187:   0%|[36m          [0m| 0/26 [00:01<?, ?it/s]Epoch: 5/10. Loss: 0.8187:   4%|[36m▍         [0m| 1/26 [00:01<00:37,  1.51s/it]Epoch: 5/10. Loss: 0.7150:   4%|[36m▍         [0m| 1/26 [00:02<00:37,  1.51s/it]Epoch: 5/10. Loss: 0.7150:   8%|[36m▊         [0m| 2/26 [00:02<00:27,  1.13s/it]Epoch: 5/10. Loss: 0.8111:   8%|[36m▊         [0m| 2/26 [00:03<00:27,  1.13s/it]Epoch: 5/10. Loss: 0.8111:  12%|[36m█▏        [0m| 3/26 [00:03<00:23,  1.03s/it]Epoch: 5/10. Loss: 0.8121:  12%|[36m█▏        [0m| 3/26 [00:04<00:23,  1.03s/it]Epoch: 5/10. Loss: 0.8121:  15%|[36m█▌        [0m| 4/26 [00:04<00:27,  1.27s/it]Epoch: 5/10. Loss: 0.8321:  15%|[36m█▌        [0m| 4/26 [00:05<00:27,  1.27s/it]Epoch: 5/10. Loss: 0.8321:  19%|[36m█▉        [0m| 5/26 [00:05<00:24,  1.15s/it]Epoch: 5/10. Loss: 0.8262:  19%|[36m█▉        [0m| 5/26 [00:06<00:24,  1.15s/it]Epoch: 5/10. Loss: 0.8262:  23%|[36m██▎       [0m| 6/26 [00:06<00:20,  1.05s/it]Epoch: 5/10. Loss: 0.8554:  23%|[36m██▎       [0m| 6/26 [00:07<00:20,  1.05s/it]Epoch: 5/10. Loss: 0.8554:  27%|[36m██▋       [0m| 7/26 [00:07<00:19,  1.03s/it]Epoch: 5/10. Loss: 0.8423:  27%|[36m██▋       [0m| 7/26 [00:08<00:19,  1.03s/it]Epoch: 5/10. Loss: 0.8423:  31%|[36m███       [0m| 8/26 [00:08<00:17,  1.04it/s]Epoch: 5/10. Loss: 0.7021:  31%|[36m███       [0m| 8/26 [00:10<00:17,  1.04it/s]Epoch: 5/10. Loss: 0.7021:  35%|[36m███▍      [0m| 9/26 [00:10<00:23,  1.36s/it]Epoch: 5/10. Loss: 0.9131:  35%|[36m███▍      [0m| 9/26 [00:11<00:23,  1.36s/it]Epoch: 5/10. Loss: 0.9131:  38%|[36m███▊      [0m| 10/26 [00:11<00:19,  1.20s/it]Epoch: 5/10. Loss: 0.7325:  38%|[36m███▊      [0m| 10/26 [00:12<00:19,  1.20s/it]Epoch: 5/10. Loss: 0.7325:  42%|[36m████▏     [0m| 11/26 [00:12<00:18,  1.20s/it]Epoch: 5/10. Loss: 0.7780:  42%|[36m████▏     [0m| 11/26 [00:13<00:18,  1.20s/it]Epoch: 5/10. Loss: 0.7780:  46%|[36m████▌     [0m| 12/26 [00:13<00:15,  1.09s/it]Epoch: 5/10. Loss: 0.9028:  46%|[36m████▌     [0m| 12/26 [00:14<00:15,  1.09s/it]Epoch: 5/10. Loss: 0.9028:  50%|[36m█████     [0m| 13/26 [00:14<00:12,  1.02it/s]Epoch: 5/10. Loss: 0.8368:  50%|[36m█████     [0m| 13/26 [00:15<00:12,  1.02it/s]Epoch: 5/10. Loss: 0.8368:  54%|[36m█████▍    [0m| 14/26 [00:15<00:11,  1.02it/s]Epoch: 5/10. Loss: 0.7892:  54%|[36m█████▍    [0m| 14/26 [00:17<00:11,  1.02it/s]Epoch: 5/10. Loss: 0.7892:  58%|[36m█████▊    [0m| 15/26 [00:17<00:14,  1.34s/it]Epoch: 5/10. Loss: 0.7723:  58%|[36m█████▊    [0m| 15/26 [00:18<00:14,  1.34s/it]Epoch: 5/10. Loss: 0.7723:  62%|[36m██████▏   [0m| 16/26 [00:18<00:12,  1.23s/it]Epoch: 5/10. Loss: 0.8797:  62%|[36m██████▏   [0m| 16/26 [00:19<00:12,  1.23s/it]Epoch: 5/10. Loss: 0.8797:  65%|[36m██████▌   [0m| 17/26 [00:19<00:10,  1.19s/it]Epoch: 5/10. Loss: 0.7719:  65%|[36m██████▌   [0m| 17/26 [00:20<00:10,  1.19s/it]Epoch: 5/10. Loss: 0.7719:  69%|[36m██████▉   [0m| 18/26 [00:20<00:08,  1.12s/it]Epoch: 5/10. Loss: 0.9166:  69%|[36m██████▉   [0m| 18/26 [00:21<00:08,  1.12s/it]Epoch: 5/10. Loss: 0.9166:  73%|[36m███████▎  [0m| 19/26 [00:21<00:07,  1.06s/it]Epoch: 5/10. Loss: 0.7434:  73%|[36m███████▎  [0m| 19/26 [00:22<00:07,  1.06s/it]Epoch: 5/10. Loss: 0.7434:  77%|[36m███████▋  [0m| 20/26 [00:22<00:06,  1.02s/it]Epoch: 5/10. Loss: 0.7732:  77%|[36m███████▋  [0m| 20/26 [00:23<00:06,  1.02s/it]Epoch: 5/10. Loss: 0.7732:  81%|[36m████████  [0m| 21/26 [00:23<00:04,  1.03it/s]Epoch: 5/10. Loss: 0.8251:  81%|[36m████████  [0m| 21/26 [00:24<00:04,  1.03it/s]Epoch: 5/10. Loss: 0.8251:  85%|[36m████████▍ [0m| 22/26 [00:24<00:03,  1.06it/s]Epoch: 5/10. Loss: 0.8129:  85%|[36m████████▍ [0m| 22/26 [00:25<00:03,  1.06it/s]Epoch: 5/10. Loss: 0.8129:  88%|[36m████████▊ [0m| 23/26 [00:25<00:02,  1.04it/s]Epoch: 5/10. Loss: 0.7377:  88%|[36m████████▊ [0m| 23/26 [00:26<00:02,  1.04it/s]Epoch: 5/10. Loss: 0.7377:  92%|[36m█████████▏[0m| 24/26 [00:26<00:01,  1.00it/s]Epoch: 5/10. Loss: 0.7573:  92%|[36m█████████▏[0m| 24/26 [00:27<00:01,  1.00it/s]Epoch: 5/10. Loss: 0.7573:  96%|[36m█████████▌[0m| 25/26 [00:27<00:00,  1.02it/s]Epoch: 5/10. Loss: 0.9492:  96%|[36m█████████▌[0m| 25/26 [00:27<00:00,  1.02it/s]Epoch: 5/10. Loss: 0.9492: 100%|[36m██████████[0m| 26/26 [00:27<00:00,  1.17it/s]Epoch: 5/10. Loss: 0.9492: 100%|[36m██████████[0m| 26/26 [00:27<00:00,  1.07s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:04,  1.40it/s] 29%|[33m██▊       [0m| 2/7 [00:01<00:05,  1.05s/it] 43%|[33m████▎     [0m| 3/7 [00:02<00:03,  1.14it/s] 57%|[33m█████▋    [0m| 4/7 [00:04<00:03,  1.24s/it] 71%|[33m███████▏  [0m| 5/7 [00:04<00:01,  1.04it/s] 86%|[33m████████▌ [0m| 6/7 [00:05<00:00,  1.09it/s]100%|[33m██████████[0m| 7/7 [00:06<00:00,  1.39it/s]100%|[33m██████████[0m| 7/7 [00:06<00:00,  1.15it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 6/10. Loss: 0.7307:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 6/10. Loss: 0.7307:   4%|[36m▍         [0m| 1/26 [00:00<00:19,  1.28it/s]Epoch: 6/10. Loss: 0.7790:   4%|[36m▍         [0m| 1/26 [00:01<00:19,  1.28it/s]Epoch: 6/10. Loss: 0.7790:   8%|[36m▊         [0m| 2/26 [00:01<00:21,  1.09it/s]Epoch: 6/10. Loss: 0.8186:   8%|[36m▊         [0m| 2/26 [00:02<00:21,  1.09it/s]Epoch: 6/10. Loss: 0.8186:  12%|[36m█▏        [0m| 3/26 [00:02<00:20,  1.14it/s]Epoch: 6/10. Loss: 0.7602:  12%|[36m█▏        [0m| 3/26 [00:03<00:20,  1.14it/s]Epoch: 6/10. Loss: 0.7602:  15%|[36m█▌        [0m| 4/26 [00:03<00:19,  1.12it/s]Epoch: 6/10. Loss: 0.7038:  15%|[36m█▌        [0m| 4/26 [00:04<00:19,  1.12it/s]Epoch: 6/10. Loss: 0.7038:  19%|[36m█▉        [0m| 5/26 [00:04<00:18,  1.15it/s]Epoch: 6/10. Loss: 0.7198:  19%|[36m█▉        [0m| 5/26 [00:05<00:18,  1.15it/s]Epoch: 6/10. Loss: 0.7198:  23%|[36m██▎       [0m| 6/26 [00:05<00:17,  1.12it/s]Epoch: 6/10. Loss: 0.8350:  23%|[36m██▎       [0m| 6/26 [00:06<00:17,  1.12it/s]Epoch: 6/10. Loss: 0.8350:  27%|[36m██▋       [0m| 7/26 [00:06<00:18,  1.01it/s]Epoch: 6/10. Loss: 0.8761:  27%|[36m██▋       [0m| 7/26 [00:07<00:18,  1.01it/s]Epoch: 6/10. Loss: 0.8761:  31%|[36m███       [0m| 8/26 [00:07<00:17,  1.04it/s]Epoch: 6/10. Loss: 0.7411:  31%|[36m███       [0m| 8/26 [00:08<00:17,  1.04it/s]Epoch: 6/10. Loss: 0.7411:  35%|[36m███▍      [0m| 9/26 [00:08<00:15,  1.08it/s]Epoch: 6/10. Loss: 0.8065:  35%|[36m███▍      [0m| 9/26 [00:09<00:15,  1.08it/s]Epoch: 6/10. Loss: 0.8065:  38%|[36m███▊      [0m| 10/26 [00:09<00:17,  1.08s/it]Epoch: 6/10. Loss: 0.6595:  38%|[36m███▊      [0m| 10/26 [00:10<00:17,  1.08s/it]Epoch: 6/10. Loss: 0.6595:  42%|[36m████▏     [0m| 11/26 [00:10<00:15,  1.00s/it]Epoch: 6/10. Loss: 0.8133:  42%|[36m████▏     [0m| 11/26 [00:12<00:15,  1.00s/it]Epoch: 6/10. Loss: 0.8133:  46%|[36m████▌     [0m| 12/26 [00:12<00:18,  1.34s/it]Epoch: 6/10. Loss: 0.7890:  46%|[36m████▌     [0m| 12/26 [00:13<00:18,  1.34s/it]Epoch: 6/10. Loss: 0.7890:  50%|[36m█████     [0m| 13/26 [00:13<00:16,  1.24s/it]Epoch: 6/10. Loss: 0.6621:  50%|[36m█████     [0m| 13/26 [00:16<00:16,  1.24s/it]Epoch: 6/10. Loss: 0.6621:  54%|[36m█████▍    [0m| 14/26 [00:16<00:19,  1.60s/it]Epoch: 6/10. Loss: 0.7890:  54%|[36m█████▍    [0m| 14/26 [00:18<00:19,  1.60s/it]Epoch: 6/10. Loss: 0.7890:  58%|[36m█████▊    [0m| 15/26 [00:18<00:20,  1.83s/it]Epoch: 6/10. Loss: 0.8524:  58%|[36m█████▊    [0m| 15/26 [00:19<00:20,  1.83s/it]Epoch: 6/10. Loss: 0.8524:  62%|[36m██████▏   [0m| 16/26 [00:19<00:15,  1.56s/it]Epoch: 6/10. Loss: 0.7977:  62%|[36m██████▏   [0m| 16/26 [00:20<00:15,  1.56s/it]Epoch: 6/10. Loss: 0.7977:  65%|[36m██████▌   [0m| 17/26 [00:20<00:11,  1.31s/it]Epoch: 6/10. Loss: 0.6629:  65%|[36m██████▌   [0m| 17/26 [00:20<00:11,  1.31s/it]Epoch: 6/10. Loss: 0.6629:  69%|[36m██████▉   [0m| 18/26 [00:20<00:09,  1.16s/it]Epoch: 6/10. Loss: 0.7680:  69%|[36m██████▉   [0m| 18/26 [00:21<00:09,  1.16s/it]Epoch: 6/10. Loss: 0.7680:  73%|[36m███████▎  [0m| 19/26 [00:21<00:07,  1.05s/it]Epoch: 6/10. Loss: 0.7931:  73%|[36m███████▎  [0m| 19/26 [00:22<00:07,  1.05s/it]Epoch: 6/10. Loss: 0.7931:  77%|[36m███████▋  [0m| 20/26 [00:22<00:06,  1.13s/it]Epoch: 6/10. Loss: 0.9079:  77%|[36m███████▋  [0m| 20/26 [00:26<00:06,  1.13s/it]Epoch: 6/10. Loss: 0.9079:  81%|[36m████████  [0m| 21/26 [00:26<00:08,  1.80s/it]Epoch: 6/10. Loss: 0.8301:  81%|[36m████████  [0m| 21/26 [00:27<00:08,  1.80s/it]Epoch: 6/10. Loss: 0.8301:  85%|[36m████████▍ [0m| 22/26 [00:27<00:06,  1.56s/it]Epoch: 6/10. Loss: 0.9240:  85%|[36m████████▍ [0m| 22/26 [00:28<00:06,  1.56s/it]Epoch: 6/10. Loss: 0.9240:  88%|[36m████████▊ [0m| 23/26 [00:28<00:04,  1.46s/it]Epoch: 6/10. Loss: 0.8497:  88%|[36m████████▊ [0m| 23/26 [00:29<00:04,  1.46s/it]Epoch: 6/10. Loss: 0.8497:  92%|[36m█████████▏[0m| 24/26 [00:29<00:02,  1.29s/it]Epoch: 6/10. Loss: 0.7029:  92%|[36m█████████▏[0m| 24/26 [00:30<00:02,  1.29s/it]Epoch: 6/10. Loss: 0.7029:  96%|[36m█████████▌[0m| 25/26 [00:30<00:01,  1.21s/it]Epoch: 6/10. Loss: 0.7740:  96%|[36m█████████▌[0m| 25/26 [00:31<00:01,  1.21s/it]Epoch: 6/10. Loss: 0.7740: 100%|[36m██████████[0m| 26/26 [00:31<00:00,  1.03s/it]Epoch: 6/10. Loss: 0.7740: 100%|[36m██████████[0m| 26/26 [00:31<00:00,  1.20s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:04,  1.39it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:05,  1.08s/it] 43%|[33m████▎     [0m| 3/7 [00:02<00:03,  1.12it/s] 57%|[33m█████▋    [0m| 4/7 [00:03<00:03,  1.00s/it] 71%|[33m███████▏  [0m| 5/7 [00:04<00:01,  1.22it/s] 86%|[33m████████▌ [0m| 6/7 [00:06<00:01,  1.24s/it]100%|[33m██████████[0m| 7/7 [00:06<00:00,  1.06it/s]100%|[33m██████████[0m| 7/7 [00:06<00:00,  1.04it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 7/10. Loss: 0.6763:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 7/10. Loss: 0.6763:   4%|[36m▍         [0m| 1/26 [00:00<00:20,  1.20it/s]Epoch: 7/10. Loss: 0.7780:   4%|[36m▍         [0m| 1/26 [00:02<00:20,  1.20it/s]Epoch: 7/10. Loss: 0.7780:   8%|[36m▊         [0m| 2/26 [00:02<00:26,  1.12s/it]Epoch: 7/10. Loss: 0.7549:   8%|[36m▊         [0m| 2/26 [00:03<00:26,  1.12s/it]Epoch: 7/10. Loss: 0.7549:  12%|[36m█▏        [0m| 3/26 [00:03<00:25,  1.09s/it]Epoch: 7/10. Loss: 0.7666:  12%|[36m█▏        [0m| 3/26 [00:04<00:25,  1.09s/it]Epoch: 7/10. Loss: 0.7666:  15%|[36m█▌        [0m| 4/26 [00:04<00:23,  1.06s/it]Epoch: 7/10. Loss: 0.7236:  15%|[36m█▌        [0m| 4/26 [00:05<00:23,  1.06s/it]Epoch: 7/10. Loss: 0.7236:  19%|[36m█▉        [0m| 5/26 [00:05<00:21,  1.00s/it]Epoch: 7/10. Loss: 0.7343:  19%|[36m█▉        [0m| 5/26 [00:05<00:21,  1.00s/it]Epoch: 7/10. Loss: 0.7343:  23%|[36m██▎       [0m| 6/26 [00:05<00:18,  1.08it/s]Epoch: 7/10. Loss: 0.7055:  23%|[36m██▎       [0m| 6/26 [00:07<00:18,  1.08it/s]Epoch: 7/10. Loss: 0.7055:  27%|[36m██▋       [0m| 7/26 [00:07<00:18,  1.01it/s]Epoch: 7/10. Loss: 0.6510:  27%|[36m██▋       [0m| 7/26 [00:07<00:18,  1.01it/s]Epoch: 7/10. Loss: 0.6510:  31%|[36m███       [0m| 8/26 [00:07<00:16,  1.07it/s]Epoch: 7/10. Loss: 0.7043:  31%|[36m███       [0m| 8/26 [00:08<00:16,  1.07it/s]Epoch: 7/10. Loss: 0.7043:  35%|[36m███▍      [0m| 9/26 [00:08<00:16,  1.05it/s]Epoch: 7/10. Loss: 0.7303:  35%|[36m███▍      [0m| 9/26 [00:09<00:16,  1.05it/s]Epoch: 7/10. Loss: 0.7303:  38%|[36m███▊      [0m| 10/26 [00:09<00:14,  1.11it/s]Epoch: 7/10. Loss: 0.7487:  38%|[36m███▊      [0m| 10/26 [00:10<00:14,  1.11it/s]Epoch: 7/10. Loss: 0.7487:  42%|[36m████▏     [0m| 11/26 [00:10<00:13,  1.12it/s]Epoch: 7/10. Loss: 0.6223:  42%|[36m████▏     [0m| 11/26 [00:11<00:13,  1.12it/s]Epoch: 7/10. Loss: 0.6223:  46%|[36m████▌     [0m| 12/26 [00:11<00:13,  1.04it/s]Epoch: 7/10. Loss: 0.7146:  46%|[36m████▌     [0m| 12/26 [00:12<00:13,  1.04it/s]Epoch: 7/10. Loss: 0.7146:  50%|[36m█████     [0m| 13/26 [00:12<00:11,  1.09it/s]Epoch: 7/10. Loss: 0.7243:  50%|[36m█████     [0m| 13/26 [00:13<00:11,  1.09it/s]Epoch: 7/10. Loss: 0.7243:  54%|[36m█████▍    [0m| 14/26 [00:13<00:10,  1.12it/s]Epoch: 7/10. Loss: 0.8120:  54%|[36m█████▍    [0m| 14/26 [00:14<00:10,  1.12it/s]Epoch: 7/10. Loss: 0.8120:  58%|[36m█████▊    [0m| 15/26 [00:14<00:10,  1.09it/s]Epoch: 7/10. Loss: 0.7702:  58%|[36m█████▊    [0m| 15/26 [00:17<00:10,  1.09it/s]Epoch: 7/10. Loss: 0.7702:  62%|[36m██████▏   [0m| 16/26 [00:17<00:14,  1.49s/it]Epoch: 7/10. Loss: 0.7330:  62%|[36m██████▏   [0m| 16/26 [00:18<00:14,  1.49s/it]Epoch: 7/10. Loss: 0.7330:  65%|[36m██████▌   [0m| 17/26 [00:18<00:12,  1.34s/it]Epoch: 7/10. Loss: 0.8189:  65%|[36m██████▌   [0m| 17/26 [00:21<00:12,  1.34s/it]Epoch: 7/10. Loss: 0.8189:  69%|[36m██████▉   [0m| 18/26 [00:21<00:14,  1.85s/it]Epoch: 7/10. Loss: 0.7769:  69%|[36m██████▉   [0m| 18/26 [00:22<00:14,  1.85s/it]Epoch: 7/10. Loss: 0.7769:  73%|[36m███████▎  [0m| 19/26 [00:22<00:11,  1.67s/it]Epoch: 7/10. Loss: 0.7866:  73%|[36m███████▎  [0m| 19/26 [00:23<00:11,  1.67s/it]Epoch: 7/10. Loss: 0.7866:  77%|[36m███████▋  [0m| 20/26 [00:23<00:08,  1.44s/it]Epoch: 7/10. Loss: 0.6512:  77%|[36m███████▋  [0m| 20/26 [00:24<00:08,  1.44s/it]Epoch: 7/10. Loss: 0.6512:  81%|[36m████████  [0m| 21/26 [00:24<00:06,  1.26s/it]Epoch: 7/10. Loss: 0.7963:  81%|[36m████████  [0m| 21/26 [00:25<00:06,  1.26s/it]Epoch: 7/10. Loss: 0.7963:  85%|[36m████████▍ [0m| 22/26 [00:25<00:04,  1.16s/it]Epoch: 7/10. Loss: 0.8217:  85%|[36m████████▍ [0m| 22/26 [00:26<00:04,  1.16s/it]Epoch: 7/10. Loss: 0.8217:  88%|[36m████████▊ [0m| 23/26 [00:26<00:03,  1.18s/it]Epoch: 7/10. Loss: 0.8498:  88%|[36m████████▊ [0m| 23/26 [00:28<00:03,  1.18s/it]Epoch: 7/10. Loss: 0.8498:  92%|[36m█████████▏[0m| 24/26 [00:28<00:03,  1.65s/it]Epoch: 7/10. Loss: 0.7659:  92%|[36m█████████▏[0m| 24/26 [00:30<00:03,  1.65s/it]Epoch: 7/10. Loss: 0.7659:  96%|[36m█████████▌[0m| 25/26 [00:30<00:01,  1.57s/it]Epoch: 7/10. Loss: 0.6988:  96%|[36m█████████▌[0m| 25/26 [00:30<00:01,  1.57s/it]Epoch: 7/10. Loss: 0.6988: 100%|[36m██████████[0m| 26/26 [00:30<00:00,  1.26s/it]Epoch: 7/10. Loss: 0.6988: 100%|[36m██████████[0m| 26/26 [00:30<00:00,  1.19s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:04,  1.35it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:05,  1.12s/it] 43%|[33m████▎     [0m| 3/7 [00:02<00:03,  1.10it/s] 57%|[33m█████▋    [0m| 4/7 [00:05<00:04,  1.49s/it] 71%|[33m███████▏  [0m| 5/7 [00:05<00:02,  1.14s/it] 86%|[33m████████▌ [0m| 6/7 [00:06<00:01,  1.10s/it]100%|[33m██████████[0m| 7/7 [00:07<00:00,  1.19it/s]100%|[33m██████████[0m| 7/7 [00:07<00:00,  1.00s/it]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 8/10. Loss: 0.7935:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 8/10. Loss: 0.7935:   4%|[36m▍         [0m| 1/26 [00:00<00:21,  1.18it/s]Epoch: 8/10. Loss: 0.8696:   4%|[36m▍         [0m| 1/26 [00:01<00:21,  1.18it/s]Epoch: 8/10. Loss: 0.8696:   8%|[36m▊         [0m| 2/26 [00:01<00:22,  1.08it/s]Epoch: 8/10. Loss: 0.7420:   8%|[36m▊         [0m| 2/26 [00:02<00:22,  1.08it/s]Epoch: 8/10. Loss: 0.7420:  12%|[36m█▏        [0m| 3/26 [00:02<00:22,  1.02it/s]Epoch: 8/10. Loss: 0.7349:  12%|[36m█▏        [0m| 3/26 [00:03<00:22,  1.02it/s]Epoch: 8/10. Loss: 0.7349:  15%|[36m█▌        [0m| 4/26 [00:03<00:20,  1.09it/s]Epoch: 8/10. Loss: 0.6956:  15%|[36m█▌        [0m| 4/26 [00:04<00:20,  1.09it/s]Epoch: 8/10. Loss: 0.6956:  19%|[36m█▉        [0m| 5/26 [00:04<00:19,  1.08it/s]Epoch: 8/10. Loss: 0.8822:  19%|[36m█▉        [0m| 5/26 [00:07<00:19,  1.08it/s]Epoch: 8/10. Loss: 0.8822:  23%|[36m██▎       [0m| 6/26 [00:07<00:29,  1.46s/it]Epoch: 8/10. Loss: 0.8054:  23%|[36m██▎       [0m| 6/26 [00:07<00:29,  1.46s/it]Epoch: 8/10. Loss: 0.8054:  27%|[36m██▋       [0m| 7/26 [00:07<00:24,  1.27s/it]Epoch: 8/10. Loss: 0.6025:  27%|[36m██▋       [0m| 7/26 [00:08<00:24,  1.27s/it]Epoch: 8/10. Loss: 0.6025:  31%|[36m███       [0m| 8/26 [00:08<00:20,  1.13s/it]Epoch: 8/10. Loss: 0.7376:  31%|[36m███       [0m| 8/26 [00:09<00:20,  1.13s/it]Epoch: 8/10. Loss: 0.7376:  35%|[36m███▍      [0m| 9/26 [00:09<00:17,  1.03s/it]Epoch: 8/10. Loss: 0.7019:  35%|[36m███▍      [0m| 9/26 [00:10<00:17,  1.03s/it]Epoch: 8/10. Loss: 0.7019:  38%|[36m███▊      [0m| 10/26 [00:10<00:15,  1.04it/s]Epoch: 8/10. Loss: 0.7513:  38%|[36m███▊      [0m| 10/26 [00:12<00:15,  1.04it/s]Epoch: 8/10. Loss: 0.7513:  42%|[36m████▏     [0m| 11/26 [00:12<00:17,  1.18s/it]Epoch: 8/10. Loss: 0.6401:  42%|[36m████▏     [0m| 11/26 [00:13<00:17,  1.18s/it]Epoch: 8/10. Loss: 0.6401:  46%|[36m████▌     [0m| 12/26 [00:13<00:15,  1.13s/it]Epoch: 8/10. Loss: 0.6914:  46%|[36m████▌     [0m| 12/26 [00:14<00:15,  1.13s/it]Epoch: 8/10. Loss: 0.6914:  50%|[36m█████     [0m| 13/26 [00:14<00:13,  1.06s/it]Epoch: 8/10. Loss: 0.8447:  50%|[36m█████     [0m| 13/26 [00:15<00:13,  1.06s/it]Epoch: 8/10. Loss: 0.8447:  54%|[36m█████▍    [0m| 14/26 [00:15<00:15,  1.30s/it]Epoch: 8/10. Loss: 0.7316:  54%|[36m█████▍    [0m| 14/26 [00:18<00:15,  1.30s/it]Epoch: 8/10. Loss: 0.7316:  58%|[36m█████▊    [0m| 15/26 [00:18<00:17,  1.64s/it]Epoch: 8/10. Loss: 0.6995:  58%|[36m█████▊    [0m| 15/26 [00:19<00:17,  1.64s/it]Epoch: 8/10. Loss: 0.6995:  62%|[36m██████▏   [0m| 16/26 [00:19<00:14,  1.43s/it]Epoch: 8/10. Loss: 0.8636:  62%|[36m██████▏   [0m| 16/26 [00:20<00:14,  1.43s/it]Epoch: 8/10. Loss: 0.8636:  65%|[36m██████▌   [0m| 17/26 [00:20<00:11,  1.29s/it]Epoch: 8/10. Loss: 0.6820:  65%|[36m██████▌   [0m| 17/26 [00:21<00:11,  1.29s/it]Epoch: 8/10. Loss: 0.6820:  69%|[36m██████▉   [0m| 18/26 [00:21<00:09,  1.19s/it]Epoch: 8/10. Loss: 0.7020:  69%|[36m██████▉   [0m| 18/26 [00:22<00:09,  1.19s/it]Epoch: 8/10. Loss: 0.7020:  73%|[36m███████▎  [0m| 19/26 [00:22<00:07,  1.09s/it]Epoch: 8/10. Loss: 0.6433:  73%|[36m███████▎  [0m| 19/26 [00:23<00:07,  1.09s/it]Epoch: 8/10. Loss: 0.6433:  77%|[36m███████▋  [0m| 20/26 [00:23<00:06,  1.12s/it]Epoch: 8/10. Loss: 0.6552:  77%|[36m███████▋  [0m| 20/26 [00:24<00:06,  1.12s/it]Epoch: 8/10. Loss: 0.6552:  81%|[36m████████  [0m| 21/26 [00:24<00:05,  1.08s/it]Epoch: 8/10. Loss: 0.7467:  81%|[36m████████  [0m| 21/26 [00:25<00:05,  1.08s/it]Epoch: 8/10. Loss: 0.7467:  85%|[36m████████▍ [0m| 22/26 [00:25<00:03,  1.01it/s]Epoch: 8/10. Loss: 0.7872:  85%|[36m████████▍ [0m| 22/26 [00:25<00:03,  1.01it/s]Epoch: 8/10. Loss: 0.7872:  88%|[36m████████▊ [0m| 23/26 [00:25<00:02,  1.09it/s]Epoch: 8/10. Loss: 0.8819:  88%|[36m████████▊ [0m| 23/26 [00:26<00:02,  1.09it/s]Epoch: 8/10. Loss: 0.8819:  92%|[36m█████████▏[0m| 24/26 [00:26<00:01,  1.08it/s]Epoch: 8/10. Loss: 0.6227:  92%|[36m█████████▏[0m| 24/26 [00:27<00:01,  1.08it/s]Epoch: 8/10. Loss: 0.6227:  96%|[36m█████████▌[0m| 25/26 [00:27<00:00,  1.05it/s]Epoch: 8/10. Loss: 0.7028:  96%|[36m█████████▌[0m| 25/26 [00:28<00:00,  1.05it/s]Epoch: 8/10. Loss: 0.7028: 100%|[36m██████████[0m| 26/26 [00:28<00:00,  1.15it/s]Epoch: 8/10. Loss: 0.7028: 100%|[36m██████████[0m| 26/26 [00:28<00:00,  1.09s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:04,  1.28it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:05,  1.13s/it] 43%|[33m████▎     [0m| 3/7 [00:02<00:03,  1.08it/s] 57%|[33m█████▋    [0m| 4/7 [00:04<00:03,  1.11s/it] 71%|[33m███████▏  [0m| 5/7 [00:04<00:01,  1.12it/s] 86%|[33m████████▌ [0m| 6/7 [00:05<00:00,  1.14it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.44it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.19it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 9/10. Loss: 0.6147:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 9/10. Loss: 0.6147:   4%|[36m▍         [0m| 1/26 [00:00<00:24,  1.00it/s]Epoch: 9/10. Loss: 0.7698:   4%|[36m▍         [0m| 1/26 [00:01<00:24,  1.00it/s]Epoch: 9/10. Loss: 0.7698:   8%|[36m▊         [0m| 2/26 [00:01<00:21,  1.12it/s]Epoch: 9/10. Loss: 0.8132:   8%|[36m▊         [0m| 2/26 [00:02<00:21,  1.12it/s]Epoch: 9/10. Loss: 0.8132:  12%|[36m█▏        [0m| 3/26 [00:02<00:20,  1.11it/s]Epoch: 9/10. Loss: 0.6926:  12%|[36m█▏        [0m| 3/26 [00:05<00:20,  1.11it/s]Epoch: 9/10. Loss: 0.6926:  15%|[36m█▌        [0m| 4/26 [00:05<00:36,  1.64s/it]Epoch: 9/10. Loss: 0.7593:  15%|[36m█▌        [0m| 4/26 [00:06<00:36,  1.64s/it]Epoch: 9/10. Loss: 0.7593:  19%|[36m█▉        [0m| 5/26 [00:06<00:28,  1.38s/it]Epoch: 9/10. Loss: 0.6246:  19%|[36m█▉        [0m| 5/26 [00:07<00:28,  1.38s/it]Epoch: 9/10. Loss: 0.6246:  23%|[36m██▎       [0m| 6/26 [00:07<00:25,  1.26s/it]Epoch: 9/10. Loss: 0.6606:  23%|[36m██▎       [0m| 6/26 [00:08<00:25,  1.26s/it]Epoch: 9/10. Loss: 0.6606:  27%|[36m██▋       [0m| 7/26 [00:08<00:22,  1.16s/it]Epoch: 9/10. Loss: 0.6613:  27%|[36m██▋       [0m| 7/26 [00:09<00:22,  1.16s/it]Epoch: 9/10. Loss: 0.6613:  31%|[36m███       [0m| 8/26 [00:09<00:19,  1.10s/it]Epoch: 9/10. Loss: 0.7241:  31%|[36m███       [0m| 8/26 [00:10<00:19,  1.10s/it]Epoch: 9/10. Loss: 0.7241:  35%|[36m███▍      [0m| 9/26 [00:10<00:17,  1.03s/it]Epoch: 9/10. Loss: 0.7631:  35%|[36m███▍      [0m| 9/26 [00:11<00:17,  1.03s/it]Epoch: 9/10. Loss: 0.7631:  38%|[36m███▊      [0m| 10/26 [00:11<00:15,  1.05it/s]Epoch: 9/10. Loss: 0.7272:  38%|[36m███▊      [0m| 10/26 [00:12<00:15,  1.05it/s]Epoch: 9/10. Loss: 0.7272:  42%|[36m████▏     [0m| 11/26 [00:12<00:14,  1.00it/s]Epoch: 9/10. Loss: 0.7204:  42%|[36m████▏     [0m| 11/26 [00:12<00:14,  1.00it/s]Epoch: 9/10. Loss: 0.7204:  46%|[36m████▌     [0m| 12/26 [00:12<00:13,  1.06it/s]Epoch: 9/10. Loss: 0.7250:  46%|[36m████▌     [0m| 12/26 [00:13<00:13,  1.06it/s]Epoch: 9/10. Loss: 0.7250:  50%|[36m█████     [0m| 13/26 [00:13<00:12,  1.07it/s]Epoch: 9/10. Loss: 0.6167:  50%|[36m█████     [0m| 13/26 [00:14<00:12,  1.07it/s]Epoch: 9/10. Loss: 0.6167:  54%|[36m█████▍    [0m| 14/26 [00:14<00:11,  1.06it/s]Epoch: 9/10. Loss: 0.6434:  54%|[36m█████▍    [0m| 14/26 [00:16<00:11,  1.06it/s]Epoch: 9/10. Loss: 0.6434:  58%|[36m█████▊    [0m| 15/26 [00:16<00:12,  1.09s/it]Epoch: 9/10. Loss: 0.7953:  58%|[36m█████▊    [0m| 15/26 [00:17<00:12,  1.09s/it]Epoch: 9/10. Loss: 0.7953:  62%|[36m██████▏   [0m| 16/26 [00:17<00:10,  1.01s/it]Epoch: 9/10. Loss: 0.6340:  62%|[36m██████▏   [0m| 16/26 [00:18<00:10,  1.01s/it]Epoch: 9/10. Loss: 0.6340:  65%|[36m██████▌   [0m| 17/26 [00:18<00:09,  1.03s/it]Epoch: 9/10. Loss: 0.6958:  65%|[36m██████▌   [0m| 17/26 [00:18<00:09,  1.03s/it]Epoch: 9/10. Loss: 0.6958:  69%|[36m██████▉   [0m| 18/26 [00:18<00:07,  1.03it/s]Epoch: 9/10. Loss: 0.6460:  69%|[36m██████▉   [0m| 18/26 [00:19<00:07,  1.03it/s]Epoch: 9/10. Loss: 0.6460:  73%|[36m███████▎  [0m| 19/26 [00:19<00:06,  1.08it/s]Epoch: 9/10. Loss: 0.6727:  73%|[36m███████▎  [0m| 19/26 [00:20<00:06,  1.08it/s]Epoch: 9/10. Loss: 0.6727:  77%|[36m███████▋  [0m| 20/26 [00:20<00:05,  1.10it/s]Epoch: 9/10. Loss: 0.6626:  77%|[36m███████▋  [0m| 20/26 [00:21<00:05,  1.10it/s]Epoch: 9/10. Loss: 0.6626:  81%|[36m████████  [0m| 21/26 [00:21<00:04,  1.08it/s]Epoch: 9/10. Loss: 0.7410:  81%|[36m████████  [0m| 21/26 [00:22<00:04,  1.08it/s]Epoch: 9/10. Loss: 0.7410:  85%|[36m████████▍ [0m| 22/26 [00:22<00:03,  1.01it/s]Epoch: 9/10. Loss: 0.7353:  85%|[36m████████▍ [0m| 22/26 [00:23<00:03,  1.01it/s]Epoch: 9/10. Loss: 0.7353:  88%|[36m████████▊ [0m| 23/26 [00:23<00:02,  1.07it/s]Epoch: 9/10. Loss: 0.7193:  88%|[36m████████▊ [0m| 23/26 [00:24<00:02,  1.07it/s]Epoch: 9/10. Loss: 0.7193:  92%|[36m█████████▏[0m| 24/26 [00:24<00:01,  1.10it/s]Epoch: 9/10. Loss: 0.6282:  92%|[36m█████████▏[0m| 24/26 [00:25<00:01,  1.10it/s]Epoch: 9/10. Loss: 0.6282:  96%|[36m█████████▌[0m| 25/26 [00:25<00:00,  1.17it/s]Epoch: 9/10. Loss: 0.6398:  96%|[36m█████████▌[0m| 25/26 [00:25<00:00,  1.17it/s]Epoch: 9/10. Loss: 0.6398: 100%|[36m██████████[0m| 26/26 [00:25<00:00,  1.31it/s]Epoch: 9/10. Loss: 0.6398: 100%|[36m██████████[0m| 26/26 [00:25<00:00,  1.01it/s]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:04,  1.45it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:07,  1.52s/it] 43%|[33m████▎     [0m| 3/7 [00:03<00:04,  1.14s/it] 57%|[33m█████▋    [0m| 4/7 [00:04<00:03,  1.20s/it] 71%|[33m███████▏  [0m| 5/7 [00:05<00:01,  1.05it/s] 86%|[33m████████▌ [0m| 6/7 [00:06<00:00,  1.09it/s]100%|[33m██████████[0m| 7/7 [00:06<00:00,  1.37it/s]100%|[33m██████████[0m| 7/7 [00:06<00:00,  1.08it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 0/10. Loss: 1.0984:   0%|[36m          [0m| 0/26 [00:01<?, ?it/s]Epoch: 0/10. Loss: 1.0984:   4%|[36m▍         [0m| 1/26 [00:01<00:25,  1.02s/it]Epoch: 0/10. Loss: 3666476.5000:   4%|[36m▍         [0m| 1/26 [00:01<00:25,  1.02s/it]Epoch: 0/10. Loss: 3666476.5000:   8%|[36m▊         [0m| 2/26 [00:01<00:22,  1.07it/s]Epoch: 0/10. Loss: 312.7737:   8%|[36m▊         [0m| 2/26 [00:02<00:22,  1.07it/s]    Epoch: 0/10. Loss: 312.7737:  12%|[36m█▏        [0m| 3/26 [00:02<00:21,  1.08it/s]Epoch: 0/10. Loss: 30680.3418:  12%|[36m█▏        [0m| 3/26 [00:03<00:21,  1.08it/s]Epoch: 0/10. Loss: 30680.3418:  15%|[36m█▌        [0m| 4/26 [00:03<00:19,  1.12it/s]Epoch: 0/10. Loss: 325122.4062:  15%|[36m█▌        [0m| 4/26 [00:04<00:19,  1.12it/s]Epoch: 0/10. Loss: 325122.4062:  19%|[36m█▉        [0m| 5/26 [00:04<00:17,  1.17it/s]Epoch: 0/10. Loss: 3502.3281:  19%|[36m█▉        [0m| 5/26 [00:05<00:17,  1.17it/s]  Epoch: 0/10. Loss: 3502.3281:  23%|[36m██▎       [0m| 6/26 [00:05<00:17,  1.16it/s]Epoch: 0/10. Loss: 3407.2229:  23%|[36m██▎       [0m| 6/26 [00:06<00:17,  1.16it/s]Epoch: 0/10. Loss: 3407.2229:  27%|[36m██▋       [0m| 7/26 [00:06<00:16,  1.16it/s]Epoch: 0/10. Loss: 946.2371:  27%|[36m██▋       [0m| 7/26 [00:07<00:16,  1.16it/s] Epoch: 0/10. Loss: 946.2371:  31%|[36m███       [0m| 8/26 [00:07<00:15,  1.13it/s]Epoch: 0/10. Loss: 714.1556:  31%|[36m███       [0m| 8/26 [00:07<00:15,  1.13it/s]Epoch: 0/10. Loss: 714.1556:  35%|[36m███▍      [0m| 9/26 [00:07<00:14,  1.20it/s]Epoch: 0/10. Loss: 2194.8574:  35%|[36m███▍      [0m| 9/26 [00:08<00:14,  1.20it/s]Epoch: 0/10. Loss: 2194.8574:  38%|[36m███▊      [0m| 10/26 [00:08<00:13,  1.19it/s]Epoch: 0/10. Loss: 189.5924:  38%|[36m███▊      [0m| 10/26 [00:09<00:13,  1.19it/s] Epoch: 0/10. Loss: 189.5924:  42%|[36m████▏     [0m| 11/26 [00:09<00:12,  1.17it/s]Epoch: 0/10. Loss: 4.7492:  42%|[36m████▏     [0m| 11/26 [00:10<00:12,  1.17it/s]  Epoch: 0/10. Loss: 4.7492:  46%|[36m████▌     [0m| 12/26 [00:10<00:12,  1.13it/s]Epoch: 0/10. Loss: 2319.2598:  46%|[36m████▌     [0m| 12/26 [00:11<00:12,  1.13it/s]Epoch: 0/10. Loss: 2319.2598:  50%|[36m█████     [0m| 13/26 [00:11<00:11,  1.15it/s]Epoch: 0/10. Loss: 54.9792:  50%|[36m█████     [0m| 13/26 [00:12<00:11,  1.15it/s]  Epoch: 0/10. Loss: 54.9792:  54%|[36m█████▍    [0m| 14/26 [00:12<00:10,  1.13it/s]Epoch: 0/10. Loss: 33.2404:  54%|[36m█████▍    [0m| 14/26 [00:13<00:10,  1.13it/s]Epoch: 0/10. Loss: 33.2404:  58%|[36m█████▊    [0m| 15/26 [00:13<00:09,  1.17it/s]Epoch: 0/10. Loss: 40.3296:  58%|[36m█████▊    [0m| 15/26 [00:13<00:09,  1.17it/s]Epoch: 0/10. Loss: 40.3296:  62%|[36m██████▏   [0m| 16/26 [00:13<00:08,  1.14it/s]Epoch: 0/10. Loss: 44.4151:  62%|[36m██████▏   [0m| 16/26 [00:14<00:08,  1.14it/s]Epoch: 0/10. Loss: 44.4151:  65%|[36m██████▌   [0m| 17/26 [00:14<00:08,  1.11it/s]Epoch: 0/10. Loss: 30.1826:  65%|[36m██████▌   [0m| 17/26 [00:15<00:08,  1.11it/s]Epoch: 0/10. Loss: 30.1826:  69%|[36m██████▉   [0m| 18/26 [00:15<00:06,  1.16it/s]Epoch: 0/10. Loss: 19.9054:  69%|[36m██████▉   [0m| 18/26 [00:18<00:06,  1.16it/s]Epoch: 0/10. Loss: 19.9054:  73%|[36m███████▎  [0m| 19/26 [00:18<00:09,  1.30s/it]Epoch: 0/10. Loss: 17.6356:  73%|[36m███████▎  [0m| 19/26 [00:19<00:09,  1.30s/it]Epoch: 0/10. Loss: 17.6356:  77%|[36m███████▋  [0m| 20/26 [00:19<00:07,  1.21s/it]Epoch: 0/10. Loss: 12.4175:  77%|[36m███████▋  [0m| 20/26 [00:20<00:07,  1.21s/it]Epoch: 0/10. Loss: 12.4175:  81%|[36m████████  [0m| 21/26 [00:20<00:05,  1.14s/it]Epoch: 0/10. Loss: 1105.1628:  81%|[36m████████  [0m| 21/26 [00:20<00:05,  1.14s/it]Epoch: 0/10. Loss: 1105.1628:  85%|[36m████████▍ [0m| 22/26 [00:20<00:04,  1.06s/it]Epoch: 0/10. Loss: 31.3798:  85%|[36m████████▍ [0m| 22/26 [00:21<00:04,  1.06s/it]  Epoch: 0/10. Loss: 31.3798:  88%|[36m████████▊ [0m| 23/26 [00:21<00:03,  1.04s/it]Epoch: 0/10. Loss: 51.5974:  88%|[36m████████▊ [0m| 23/26 [00:22<00:03,  1.04s/it]Epoch: 0/10. Loss: 51.5974:  92%|[36m█████████▏[0m| 24/26 [00:22<00:01,  1.01it/s]Epoch: 0/10. Loss: 52.3199:  92%|[36m█████████▏[0m| 24/26 [00:23<00:01,  1.01it/s]Epoch: 0/10. Loss: 52.3199:  96%|[36m█████████▌[0m| 25/26 [00:23<00:00,  1.04it/s]Epoch: 0/10. Loss: 78.9001:  96%|[36m█████████▌[0m| 25/26 [00:24<00:00,  1.04it/s]Epoch: 0/10. Loss: 78.9001: 100%|[36m██████████[0m| 26/26 [00:24<00:00,  1.14it/s]Epoch: 0/10. Loss: 78.9001: 100%|[36m██████████[0m| 26/26 [00:24<00:00,  1.07it/s]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:04,  1.42it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:05,  1.07s/it] 43%|[33m████▎     [0m| 3/7 [00:02<00:03,  1.13it/s] 57%|[33m█████▋    [0m| 4/7 [00:03<00:02,  1.02it/s] 71%|[33m███████▏  [0m| 5/7 [00:04<00:01,  1.24it/s] 86%|[33m████████▌ [0m| 6/7 [00:05<00:00,  1.21it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.51it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.27it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 1/10. Loss: 84.9909:   0%|[36m          [0m| 0/26 [00:01<?, ?it/s]Epoch: 1/10. Loss: 84.9909:   4%|[36m▍         [0m| 1/26 [00:01<00:26,  1.07s/it]Epoch: 1/10. Loss: 40.7239:   4%|[36m▍         [0m| 1/26 [00:01<00:26,  1.07s/it]Epoch: 1/10. Loss: 40.7239:   8%|[36m▊         [0m| 2/26 [00:01<00:20,  1.17it/s]Epoch: 1/10. Loss: 39.7451:   8%|[36m▊         [0m| 2/26 [00:02<00:20,  1.17it/s]Epoch: 1/10. Loss: 39.7451:  12%|[36m█▏        [0m| 3/26 [00:02<00:19,  1.17it/s]Epoch: 1/10. Loss: 27.9379:  12%|[36m█▏        [0m| 3/26 [00:03<00:19,  1.17it/s]Epoch: 1/10. Loss: 27.9379:  15%|[36m█▌        [0m| 4/26 [00:03<00:20,  1.09it/s]Epoch: 1/10. Loss: 46.1693:  15%|[36m█▌        [0m| 4/26 [00:04<00:20,  1.09it/s]Epoch: 1/10. Loss: 46.1693:  19%|[36m█▉        [0m| 5/26 [00:04<00:19,  1.09it/s]Epoch: 1/10. Loss: 118.1773:  19%|[36m█▉        [0m| 5/26 [00:05<00:19,  1.09it/s]Epoch: 1/10. Loss: 118.1773:  23%|[36m██▎       [0m| 6/26 [00:05<00:18,  1.06it/s]Epoch: 1/10. Loss: 46.9249:  23%|[36m██▎       [0m| 6/26 [00:06<00:18,  1.06it/s] Epoch: 1/10. Loss: 46.9249:  27%|[36m██▋       [0m| 7/26 [00:06<00:20,  1.06s/it]Epoch: 1/10. Loss: 10.7697:  27%|[36m██▋       [0m| 7/26 [00:08<00:20,  1.06s/it]Epoch: 1/10. Loss: 10.7697:  31%|[36m███       [0m| 8/26 [00:08<00:25,  1.40s/it]Epoch: 1/10. Loss: 35.7184:  31%|[36m███       [0m| 8/26 [00:09<00:25,  1.40s/it]Epoch: 1/10. Loss: 35.7184:  35%|[36m███▍      [0m| 9/26 [00:09<00:20,  1.22s/it]Epoch: 1/10. Loss: 41.0544:  35%|[36m███▍      [0m| 9/26 [00:10<00:20,  1.22s/it]Epoch: 1/10. Loss: 41.0544:  38%|[36m███▊      [0m| 10/26 [00:10<00:17,  1.08s/it]Epoch: 1/10. Loss: 54.7592:  38%|[36m███▊      [0m| 10/26 [00:11<00:17,  1.08s/it]Epoch: 1/10. Loss: 54.7592:  42%|[36m████▏     [0m| 11/26 [00:11<00:14,  1.00it/s]Epoch: 1/10. Loss: 60.0762:  42%|[36m████▏     [0m| 11/26 [00:12<00:14,  1.00it/s]Epoch: 1/10. Loss: 60.0762:  46%|[36m████▌     [0m| 12/26 [00:12<00:14,  1.01s/it]Epoch: 1/10. Loss: 50.5911:  46%|[36m████▌     [0m| 12/26 [00:13<00:14,  1.01s/it]Epoch: 1/10. Loss: 50.5911:  50%|[36m█████     [0m| 13/26 [00:13<00:13,  1.04s/it]Epoch: 1/10. Loss: 57.6700:  50%|[36m█████     [0m| 13/26 [00:14<00:13,  1.04s/it]Epoch: 1/10. Loss: 57.6700:  54%|[36m█████▍    [0m| 14/26 [00:14<00:11,  1.07it/s]Epoch: 1/10. Loss: 33.9680:  54%|[36m█████▍    [0m| 14/26 [00:15<00:11,  1.07it/s]Epoch: 1/10. Loss: 33.9680:  58%|[36m█████▊    [0m| 15/26 [00:15<00:10,  1.06it/s]Epoch: 1/10. Loss: 58.4570:  58%|[36m█████▊    [0m| 15/26 [00:16<00:10,  1.06it/s]Epoch: 1/10. Loss: 58.4570:  62%|[36m██████▏   [0m| 16/26 [00:16<00:09,  1.04it/s]Epoch: 1/10. Loss: 98.1453:  62%|[36m██████▏   [0m| 16/26 [00:17<00:09,  1.04it/s]Epoch: 1/10. Loss: 98.1453:  65%|[36m██████▌   [0m| 17/26 [00:17<00:08,  1.06it/s]Epoch: 1/10. Loss: 46.9933:  65%|[36m██████▌   [0m| 17/26 [00:18<00:08,  1.06it/s]Epoch: 1/10. Loss: 46.9933:  69%|[36m██████▉   [0m| 18/26 [00:18<00:07,  1.06it/s]Epoch: 1/10. Loss: 23.3331:  69%|[36m██████▉   [0m| 18/26 [00:19<00:07,  1.06it/s]Epoch: 1/10. Loss: 23.3331:  73%|[36m███████▎  [0m| 19/26 [00:19<00:06,  1.05it/s]Epoch: 1/10. Loss: 12.3361:  73%|[36m███████▎  [0m| 19/26 [00:19<00:06,  1.05it/s]Epoch: 1/10. Loss: 12.3361:  77%|[36m███████▋  [0m| 20/26 [00:19<00:05,  1.09it/s]Epoch: 1/10. Loss: 20.0760:  77%|[36m███████▋  [0m| 20/26 [00:20<00:05,  1.09it/s]Epoch: 1/10. Loss: 20.0760:  81%|[36m████████  [0m| 21/26 [00:20<00:04,  1.10it/s]Epoch: 1/10. Loss: 6.8896:  81%|[36m████████  [0m| 21/26 [00:21<00:04,  1.10it/s] Epoch: 1/10. Loss: 6.8896:  85%|[36m████████▍ [0m| 22/26 [00:21<00:03,  1.19it/s]Epoch: 1/10. Loss: 4.0846:  85%|[36m████████▍ [0m| 22/26 [00:22<00:03,  1.19it/s]Epoch: 1/10. Loss: 4.0846:  88%|[36m████████▊ [0m| 23/26 [00:22<00:02,  1.19it/s]Epoch: 1/10. Loss: 2.6796:  88%|[36m████████▊ [0m| 23/26 [00:22<00:02,  1.19it/s]Epoch: 1/10. Loss: 2.6796:  92%|[36m█████████▏[0m| 24/26 [00:22<00:01,  1.30it/s]Epoch: 1/10. Loss: 2.8415:  92%|[36m█████████▏[0m| 24/26 [00:23<00:01,  1.30it/s]Epoch: 1/10. Loss: 2.8415:  96%|[36m█████████▌[0m| 25/26 [00:23<00:00,  1.28it/s]Epoch: 1/10. Loss: 3.7030:  96%|[36m█████████▌[0m| 25/26 [00:24<00:00,  1.28it/s]Epoch: 1/10. Loss: 3.7030: 100%|[36m██████████[0m| 26/26 [00:24<00:00,  1.38it/s]Epoch: 1/10. Loss: 3.7030: 100%|[36m██████████[0m| 26/26 [00:24<00:00,  1.07it/s]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:04,  1.38it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:05,  1.07s/it] 43%|[33m████▎     [0m| 3/7 [00:02<00:03,  1.12it/s] 57%|[33m█████▋    [0m| 4/7 [00:03<00:02,  1.01it/s] 71%|[33m███████▏  [0m| 5/7 [00:04<00:01,  1.21it/s] 86%|[33m████████▌ [0m| 6/7 [00:05<00:00,  1.20it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.50it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.26it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 2/10. Loss: 3.4622:   0%|[36m          [0m| 0/26 [00:01<?, ?it/s]Epoch: 2/10. Loss: 3.4622:   4%|[36m▍         [0m| 1/26 [00:01<00:27,  1.08s/it]Epoch: 2/10. Loss: 7.8535:   4%|[36m▍         [0m| 1/26 [00:01<00:27,  1.08s/it]Epoch: 2/10. Loss: 7.8535:   8%|[36m▊         [0m| 2/26 [00:01<00:20,  1.17it/s]Epoch: 2/10. Loss: 2.1258:   8%|[36m▊         [0m| 2/26 [00:02<00:20,  1.17it/s]Epoch: 2/10. Loss: 2.1258:  12%|[36m█▏        [0m| 3/26 [00:02<00:20,  1.14it/s]Epoch: 2/10. Loss: 1.5768:  12%|[36m█▏        [0m| 3/26 [00:03<00:20,  1.14it/s]Epoch: 2/10. Loss: 1.5768:  15%|[36m█▌        [0m| 4/26 [00:03<00:19,  1.12it/s]Epoch: 2/10. Loss: 1.7668:  15%|[36m█▌        [0m| 4/26 [00:05<00:19,  1.12it/s]Epoch: 2/10. Loss: 1.7668:  19%|[36m█▉        [0m| 5/26 [00:05<00:22,  1.08s/it]Epoch: 2/10. Loss: 1.7960:  19%|[36m█▉        [0m| 5/26 [00:06<00:22,  1.08s/it]Epoch: 2/10. Loss: 1.7960:  23%|[36m██▎       [0m| 6/26 [00:06<00:22,  1.12s/it]Epoch: 2/10. Loss: 1.6177:  23%|[36m██▎       [0m| 6/26 [00:07<00:22,  1.12s/it]Epoch: 2/10. Loss: 1.6177:  27%|[36m██▋       [0m| 7/26 [00:07<00:19,  1.04s/it]Epoch: 2/10. Loss: 2.1024:  27%|[36m██▋       [0m| 7/26 [00:07<00:19,  1.04s/it]Epoch: 2/10. Loss: 2.1024:  31%|[36m███       [0m| 8/26 [00:07<00:17,  1.06it/s]Epoch: 2/10. Loss: 1.9654:  31%|[36m███       [0m| 8/26 [00:08<00:17,  1.06it/s]Epoch: 2/10. Loss: 1.9654:  35%|[36m███▍      [0m| 9/26 [00:08<00:14,  1.16it/s]Epoch: 2/10. Loss: 2.4740:  35%|[36m███▍      [0m| 9/26 [00:09<00:14,  1.16it/s]Epoch: 2/10. Loss: 2.4740:  38%|[36m███▊      [0m| 10/26 [00:09<00:13,  1.16it/s]Epoch: 2/10. Loss: 1.2178:  38%|[36m███▊      [0m| 10/26 [00:10<00:13,  1.16it/s]Epoch: 2/10. Loss: 1.2178:  42%|[36m████▏     [0m| 11/26 [00:10<00:14,  1.06it/s]Epoch: 2/10. Loss: 1.2197:  42%|[36m████▏     [0m| 11/26 [00:11<00:14,  1.06it/s]Epoch: 2/10. Loss: 1.2197:  46%|[36m████▌     [0m| 12/26 [00:11<00:12,  1.10it/s]Epoch: 2/10. Loss: 3.7567:  46%|[36m████▌     [0m| 12/26 [00:12<00:12,  1.10it/s]Epoch: 2/10. Loss: 3.7567:  50%|[36m█████     [0m| 13/26 [00:12<00:12,  1.08it/s]Epoch: 2/10. Loss: 1.2443:  50%|[36m█████     [0m| 13/26 [00:13<00:12,  1.08it/s]Epoch: 2/10. Loss: 1.2443:  54%|[36m█████▍    [0m| 14/26 [00:13<00:11,  1.04it/s]Epoch: 2/10. Loss: 1.4131:  54%|[36m█████▍    [0m| 14/26 [00:14<00:11,  1.04it/s]Epoch: 2/10. Loss: 1.4131:  58%|[36m█████▊    [0m| 15/26 [00:14<00:09,  1.12it/s]Epoch: 2/10. Loss: 1.2701:  58%|[36m█████▊    [0m| 15/26 [00:14<00:09,  1.12it/s]Epoch: 2/10. Loss: 1.2701:  62%|[36m██████▏   [0m| 16/26 [00:14<00:09,  1.11it/s]Epoch: 2/10. Loss: 1.2438:  62%|[36m██████▏   [0m| 16/26 [00:15<00:09,  1.11it/s]Epoch: 2/10. Loss: 1.2438:  65%|[36m██████▌   [0m| 17/26 [00:15<00:07,  1.13it/s]Epoch: 2/10. Loss: 1.1226:  65%|[36m██████▌   [0m| 17/26 [00:16<00:07,  1.13it/s]Epoch: 2/10. Loss: 1.1226:  69%|[36m██████▉   [0m| 18/26 [00:16<00:06,  1.14it/s]Epoch: 2/10. Loss: 1.1251:  69%|[36m██████▉   [0m| 18/26 [00:17<00:06,  1.14it/s]Epoch: 2/10. Loss: 1.1251:  73%|[36m███████▎  [0m| 19/26 [00:17<00:06,  1.09it/s]Epoch: 2/10. Loss: 1.1329:  73%|[36m███████▎  [0m| 19/26 [00:18<00:06,  1.09it/s]Epoch: 2/10. Loss: 1.1329:  77%|[36m███████▋  [0m| 20/26 [00:18<00:05,  1.09it/s]Epoch: 2/10. Loss: 1.0321:  77%|[36m███████▋  [0m| 20/26 [00:19<00:05,  1.09it/s]Epoch: 2/10. Loss: 1.0321:  81%|[36m████████  [0m| 21/26 [00:19<00:04,  1.17it/s]Epoch: 2/10. Loss: 1.0213:  81%|[36m████████  [0m| 21/26 [00:20<00:04,  1.17it/s]Epoch: 2/10. Loss: 1.0213:  85%|[36m████████▍ [0m| 22/26 [00:20<00:03,  1.13it/s]Epoch: 2/10. Loss: 1.0263:  85%|[36m████████▍ [0m| 22/26 [00:21<00:03,  1.13it/s]Epoch: 2/10. Loss: 1.0263:  88%|[36m████████▊ [0m| 23/26 [00:21<00:02,  1.14it/s]Epoch: 2/10. Loss: 1.0724:  88%|[36m████████▊ [0m| 23/26 [00:22<00:02,  1.14it/s]Epoch: 2/10. Loss: 1.0724:  92%|[36m█████████▏[0m| 24/26 [00:22<00:01,  1.10it/s]Epoch: 2/10. Loss: 2.1858:  92%|[36m█████████▏[0m| 24/26 [00:22<00:01,  1.10it/s]Epoch: 2/10. Loss: 2.1858:  96%|[36m█████████▌[0m| 25/26 [00:22<00:00,  1.14it/s]Epoch: 2/10. Loss: 0.9999:  96%|[36m█████████▌[0m| 25/26 [00:23<00:00,  1.14it/s]Epoch: 2/10. Loss: 0.9999: 100%|[36m██████████[0m| 26/26 [00:23<00:00,  1.24it/s]Epoch: 2/10. Loss: 0.9999: 100%|[36m██████████[0m| 26/26 [00:23<00:00,  1.10it/s]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:01<00:08,  1.49s/it] 29%|[33m██▊       [0m| 2/7 [00:02<00:06,  1.40s/it] 43%|[33m████▎     [0m| 3/7 [00:03<00:04,  1.08s/it] 57%|[33m█████▋    [0m| 4/7 [00:04<00:03,  1.11s/it] 71%|[33m███████▏  [0m| 5/7 [00:05<00:01,  1.11it/s] 86%|[33m████████▌ [0m| 6/7 [00:06<00:00,  1.12it/s]100%|[33m██████████[0m| 7/7 [00:06<00:00,  1.42it/s]100%|[33m██████████[0m| 7/7 [00:06<00:00,  1.09it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 3/10. Loss: 1.0479:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 3/10. Loss: 1.0479:   4%|[36m▍         [0m| 1/26 [00:00<00:19,  1.26it/s]Epoch: 3/10. Loss: 0.9833:   4%|[36m▍         [0m| 1/26 [00:01<00:19,  1.26it/s]Epoch: 3/10. Loss: 0.9833:   8%|[36m▊         [0m| 2/26 [00:01<00:20,  1.17it/s]Epoch: 3/10. Loss: 1.0130:   8%|[36m▊         [0m| 2/26 [00:02<00:20,  1.17it/s]Epoch: 3/10. Loss: 1.0130:  12%|[36m█▏        [0m| 3/26 [00:02<00:21,  1.09it/s]Epoch: 3/10. Loss: 1.0351:  12%|[36m█▏        [0m| 3/26 [00:03<00:21,  1.09it/s]Epoch: 3/10. Loss: 1.0351:  15%|[36m█▌        [0m| 4/26 [00:03<00:18,  1.19it/s]Epoch: 3/10. Loss: 0.9912:  15%|[36m█▌        [0m| 4/26 [00:04<00:18,  1.19it/s]Epoch: 3/10. Loss: 0.9912:  19%|[36m█▉        [0m| 5/26 [00:04<00:17,  1.21it/s]Epoch: 3/10. Loss: 0.9757:  19%|[36m█▉        [0m| 5/26 [00:06<00:17,  1.21it/s]Epoch: 3/10. Loss: 0.9757:  23%|[36m██▎       [0m| 6/26 [00:06<00:27,  1.39s/it]Epoch: 3/10. Loss: 0.9421:  23%|[36m██▎       [0m| 6/26 [00:07<00:27,  1.39s/it]Epoch: 3/10. Loss: 0.9421:  27%|[36m██▋       [0m| 7/26 [00:07<00:22,  1.18s/it]Epoch: 3/10. Loss: 0.9936:  27%|[36m██▋       [0m| 7/26 [00:09<00:22,  1.18s/it]Epoch: 3/10. Loss: 0.9936:  31%|[36m███       [0m| 8/26 [00:09<00:25,  1.42s/it]Epoch: 3/10. Loss: 1.1377:  31%|[36m███       [0m| 8/26 [00:10<00:25,  1.42s/it]Epoch: 3/10. Loss: 1.1377:  35%|[36m███▍      [0m| 9/26 [00:10<00:21,  1.24s/it]Epoch: 3/10. Loss: 1.0346:  35%|[36m███▍      [0m| 9/26 [00:11<00:21,  1.24s/it]Epoch: 3/10. Loss: 1.0346:  38%|[36m███▊      [0m| 10/26 [00:11<00:22,  1.39s/it]Epoch: 3/10. Loss: 1.0601:  38%|[36m███▊      [0m| 10/26 [00:12<00:22,  1.39s/it]Epoch: 3/10. Loss: 1.0601:  42%|[36m████▏     [0m| 11/26 [00:12<00:18,  1.21s/it]Epoch: 3/10. Loss: 0.9604:  42%|[36m████▏     [0m| 11/26 [00:13<00:18,  1.21s/it]Epoch: 3/10. Loss: 0.9604:  46%|[36m████▌     [0m| 12/26 [00:13<00:15,  1.11s/it]Epoch: 3/10. Loss: 1.1377:  46%|[36m████▌     [0m| 12/26 [00:14<00:15,  1.11s/it]Epoch: 3/10. Loss: 1.1377:  50%|[36m█████     [0m| 13/26 [00:14<00:14,  1.08s/it]Epoch: 3/10. Loss: 1.0464:  50%|[36m█████     [0m| 13/26 [00:15<00:14,  1.08s/it]Epoch: 3/10. Loss: 1.0464:  54%|[36m█████▍    [0m| 14/26 [00:15<00:12,  1.04s/it]Epoch: 3/10. Loss: 1.0418:  54%|[36m█████▍    [0m| 14/26 [00:16<00:12,  1.04s/it]Epoch: 3/10. Loss: 1.0418:  58%|[36m█████▊    [0m| 15/26 [00:16<00:10,  1.04it/s]Epoch: 3/10. Loss: 0.9841:  58%|[36m█████▊    [0m| 15/26 [00:17<00:10,  1.04it/s]Epoch: 3/10. Loss: 0.9841:  62%|[36m██████▏   [0m| 16/26 [00:17<00:08,  1.11it/s]Epoch: 3/10. Loss: 1.0079:  62%|[36m██████▏   [0m| 16/26 [00:17<00:08,  1.11it/s]Epoch: 3/10. Loss: 1.0079:  65%|[36m██████▌   [0m| 17/26 [00:17<00:07,  1.16it/s]Epoch: 3/10. Loss: 1.0745:  65%|[36m██████▌   [0m| 17/26 [00:18<00:07,  1.16it/s]Epoch: 3/10. Loss: 1.0745:  69%|[36m██████▉   [0m| 18/26 [00:18<00:06,  1.15it/s]Epoch: 3/10. Loss: 1.0936:  69%|[36m██████▉   [0m| 18/26 [00:19<00:06,  1.15it/s]Epoch: 3/10. Loss: 1.0936:  73%|[36m███████▎  [0m| 19/26 [00:19<00:06,  1.15it/s]Epoch: 3/10. Loss: 1.0451:  73%|[36m███████▎  [0m| 19/26 [00:20<00:06,  1.15it/s]Epoch: 3/10. Loss: 1.0451:  77%|[36m███████▋  [0m| 20/26 [00:20<00:05,  1.12it/s]Epoch: 3/10. Loss: 1.0281:  77%|[36m███████▋  [0m| 20/26 [00:21<00:05,  1.12it/s]Epoch: 3/10. Loss: 1.0281:  81%|[36m████████  [0m| 21/26 [00:21<00:04,  1.10it/s]Epoch: 3/10. Loss: 1.0195:  81%|[36m████████  [0m| 21/26 [00:22<00:04,  1.10it/s]Epoch: 3/10. Loss: 1.0195:  85%|[36m████████▍ [0m| 22/26 [00:22<00:03,  1.12it/s]Epoch: 3/10. Loss: 1.0788:  85%|[36m████████▍ [0m| 22/26 [00:23<00:03,  1.12it/s]Epoch: 3/10. Loss: 1.0788:  88%|[36m████████▊ [0m| 23/26 [00:23<00:02,  1.15it/s]Epoch: 3/10. Loss: 1.0186:  88%|[36m████████▊ [0m| 23/26 [00:23<00:02,  1.15it/s]Epoch: 3/10. Loss: 1.0186:  92%|[36m█████████▏[0m| 24/26 [00:23<00:01,  1.22it/s]Epoch: 3/10. Loss: 1.0337:  92%|[36m█████████▏[0m| 24/26 [00:24<00:01,  1.22it/s]Epoch: 3/10. Loss: 1.0337:  96%|[36m█████████▌[0m| 25/26 [00:24<00:00,  1.23it/s]Epoch: 3/10. Loss: 2.5114:  96%|[36m█████████▌[0m| 25/26 [00:25<00:00,  1.23it/s]Epoch: 3/10. Loss: 2.5114: 100%|[36m██████████[0m| 26/26 [00:25<00:00,  1.23it/s]Epoch: 3/10. Loss: 2.5114: 100%|[36m██████████[0m| 26/26 [00:25<00:00,  1.02it/s]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:04,  1.34it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:05,  1.09s/it] 43%|[33m████▎     [0m| 3/7 [00:02<00:03,  1.11it/s] 57%|[33m█████▋    [0m| 4/7 [00:03<00:02,  1.01it/s] 71%|[33m███████▏  [0m| 5/7 [00:04<00:01,  1.23it/s] 86%|[33m████████▌ [0m| 6/7 [00:06<00:01,  1.36s/it]100%|[33m██████████[0m| 7/7 [00:07<00:00,  1.02s/it]100%|[33m██████████[0m| 7/7 [00:07<00:00,  1.02s/it]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 4/10. Loss: 1.0262:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 4/10. Loss: 1.0262:   4%|[36m▍         [0m| 1/26 [00:00<00:22,  1.12it/s]Epoch: 4/10. Loss: 0.9994:   4%|[36m▍         [0m| 1/26 [00:01<00:22,  1.12it/s]Epoch: 4/10. Loss: 0.9994:   8%|[36m▊         [0m| 2/26 [00:01<00:21,  1.12it/s]Epoch: 4/10. Loss: 1.0593:   8%|[36m▊         [0m| 2/26 [00:02<00:21,  1.12it/s]Epoch: 4/10. Loss: 1.0593:  12%|[36m█▏        [0m| 3/26 [00:02<00:20,  1.12it/s]Epoch: 4/10. Loss: 1.1066:  12%|[36m█▏        [0m| 3/26 [00:03<00:20,  1.12it/s]Epoch: 4/10. Loss: 1.1066:  15%|[36m█▌        [0m| 4/26 [00:03<00:18,  1.19it/s]Epoch: 4/10. Loss: 1.0107:  15%|[36m█▌        [0m| 4/26 [00:04<00:18,  1.19it/s]Epoch: 4/10. Loss: 1.0107:  19%|[36m█▉        [0m| 5/26 [00:04<00:17,  1.20it/s]Epoch: 4/10. Loss: 1.0920:  19%|[36m█▉        [0m| 5/26 [00:05<00:17,  1.20it/s]Epoch: 4/10. Loss: 1.0920:  23%|[36m██▎       [0m| 6/26 [00:05<00:17,  1.12it/s]Epoch: 4/10. Loss: 1.1293:  23%|[36m██▎       [0m| 6/26 [00:06<00:17,  1.12it/s]Epoch: 4/10. Loss: 1.1293:  27%|[36m██▋       [0m| 7/26 [00:06<00:20,  1.05s/it]Epoch: 4/10. Loss: 1.0674:  27%|[36m██▋       [0m| 7/26 [00:07<00:20,  1.05s/it]Epoch: 4/10. Loss: 1.0674:  31%|[36m███       [0m| 8/26 [00:07<00:17,  1.02it/s]Epoch: 4/10. Loss: 1.2435:  31%|[36m███       [0m| 8/26 [00:08<00:17,  1.02it/s]Epoch: 4/10. Loss: 1.2435:  35%|[36m███▍      [0m| 9/26 [00:08<00:16,  1.06it/s]Epoch: 4/10. Loss: 1.1155:  35%|[36m███▍      [0m| 9/26 [00:09<00:16,  1.06it/s]Epoch: 4/10. Loss: 1.1155:  38%|[36m███▊      [0m| 10/26 [00:09<00:15,  1.07it/s]Epoch: 4/10. Loss: 1.0970:  38%|[36m███▊      [0m| 10/26 [00:10<00:15,  1.07it/s]Epoch: 4/10. Loss: 1.0970:  42%|[36m████▏     [0m| 11/26 [00:10<00:13,  1.13it/s]Epoch: 4/10. Loss: 1.2215:  42%|[36m████▏     [0m| 11/26 [00:10<00:13,  1.13it/s]Epoch: 4/10. Loss: 1.2215:  46%|[36m████▌     [0m| 12/26 [00:10<00:12,  1.11it/s]Epoch: 4/10. Loss: 1.1566:  46%|[36m████▌     [0m| 12/26 [00:11<00:12,  1.11it/s]Epoch: 4/10. Loss: 1.1566:  50%|[36m█████     [0m| 13/26 [00:11<00:11,  1.09it/s]Epoch: 4/10. Loss: 1.4796:  50%|[36m█████     [0m| 13/26 [00:13<00:11,  1.09it/s]Epoch: 4/10. Loss: 1.4796:  54%|[36m█████▍    [0m| 14/26 [00:13<00:12,  1.00s/it]Epoch: 4/10. Loss: 1.4743:  54%|[36m█████▍    [0m| 14/26 [00:13<00:12,  1.00s/it]Epoch: 4/10. Loss: 1.4743:  58%|[36m█████▊    [0m| 15/26 [00:13<00:10,  1.04it/s]Epoch: 4/10. Loss: 1.2158:  58%|[36m█████▊    [0m| 15/26 [00:14<00:10,  1.04it/s]Epoch: 4/10. Loss: 1.2158:  62%|[36m██████▏   [0m| 16/26 [00:14<00:08,  1.11it/s]Epoch: 4/10. Loss: 1.6299:  62%|[36m██████▏   [0m| 16/26 [00:15<00:08,  1.11it/s]Epoch: 4/10. Loss: 1.6299:  65%|[36m██████▌   [0m| 17/26 [00:15<00:07,  1.18it/s]Epoch: 4/10. Loss: 1.7037:  65%|[36m██████▌   [0m| 17/26 [00:16<00:07,  1.18it/s]Epoch: 4/10. Loss: 1.7037:  69%|[36m██████▉   [0m| 18/26 [00:16<00:06,  1.16it/s]Epoch: 4/10. Loss: 1.1586:  69%|[36m██████▉   [0m| 18/26 [00:17<00:06,  1.16it/s]Epoch: 4/10. Loss: 1.1586:  73%|[36m███████▎  [0m| 19/26 [00:17<00:05,  1.22it/s]Epoch: 4/10. Loss: 1.2894:  73%|[36m███████▎  [0m| 19/26 [00:18<00:05,  1.22it/s]Epoch: 4/10. Loss: 1.2894:  77%|[36m███████▋  [0m| 20/26 [00:18<00:05,  1.14it/s]Epoch: 4/10. Loss: 1.2264:  77%|[36m███████▋  [0m| 20/26 [00:18<00:05,  1.14it/s]Epoch: 4/10. Loss: 1.2264:  81%|[36m████████  [0m| 21/26 [00:18<00:04,  1.15it/s]Epoch: 4/10. Loss: 1.1850:  81%|[36m████████  [0m| 21/26 [00:19<00:04,  1.15it/s]Epoch: 4/10. Loss: 1.1850:  85%|[36m████████▍ [0m| 22/26 [00:19<00:03,  1.12it/s]Epoch: 4/10. Loss: 1.2344:  85%|[36m████████▍ [0m| 22/26 [00:20<00:03,  1.12it/s]Epoch: 4/10. Loss: 1.2344:  88%|[36m████████▊ [0m| 23/26 [00:20<00:02,  1.17it/s]Epoch: 4/10. Loss: 1.0292:  88%|[36m████████▊ [0m| 23/26 [00:21<00:02,  1.17it/s]Epoch: 4/10. Loss: 1.0292:  92%|[36m█████████▏[0m| 24/26 [00:21<00:01,  1.16it/s]Epoch: 4/10. Loss: 1.1486:  92%|[36m█████████▏[0m| 24/26 [00:22<00:01,  1.16it/s]Epoch: 4/10. Loss: 1.1486:  96%|[36m█████████▌[0m| 25/26 [00:22<00:01,  1.04s/it]Epoch: 4/10. Loss: 1.1099:  96%|[36m█████████▌[0m| 25/26 [00:23<00:01,  1.04s/it]Epoch: 4/10. Loss: 1.1099: 100%|[36m██████████[0m| 26/26 [00:23<00:00,  1.09it/s]Epoch: 4/10. Loss: 1.1099: 100%|[36m██████████[0m| 26/26 [00:23<00:00,  1.10it/s]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:04,  1.28it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:05,  1.11s/it] 43%|[33m████▎     [0m| 3/7 [00:02<00:03,  1.10it/s] 57%|[33m█████▋    [0m| 4/7 [00:03<00:03,  1.01s/it] 71%|[33m███████▏  [0m| 5/7 [00:04<00:01,  1.21it/s] 86%|[33m████████▌ [0m| 6/7 [00:05<00:00,  1.19it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.50it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.24it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 5/10. Loss: 1.0179:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 5/10. Loss: 1.0179:   4%|[36m▍         [0m| 1/26 [00:00<00:20,  1.24it/s]Epoch: 5/10. Loss: 1.0189:   4%|[36m▍         [0m| 1/26 [00:01<00:20,  1.24it/s]Epoch: 5/10. Loss: 1.0189:   8%|[36m▊         [0m| 2/26 [00:01<00:19,  1.26it/s]Epoch: 5/10. Loss: 1.0188:   8%|[36m▊         [0m| 2/26 [00:02<00:19,  1.26it/s]Epoch: 5/10. Loss: 1.0188:  12%|[36m█▏        [0m| 3/26 [00:02<00:21,  1.08it/s]Epoch: 5/10. Loss: 1.0364:  12%|[36m█▏        [0m| 3/26 [00:05<00:21,  1.08it/s]Epoch: 5/10. Loss: 1.0364:  15%|[36m█▌        [0m| 4/26 [00:05<00:33,  1.52s/it]Epoch: 5/10. Loss: 1.0510:  15%|[36m█▌        [0m| 4/26 [00:07<00:33,  1.52s/it]Epoch: 5/10. Loss: 1.0510:  19%|[36m█▉        [0m| 5/26 [00:07<00:38,  1.82s/it]Epoch: 5/10. Loss: 0.9883:  19%|[36m█▉        [0m| 5/26 [00:08<00:38,  1.82s/it]Epoch: 5/10. Loss: 0.9883:  23%|[36m██▎       [0m| 6/26 [00:08<00:30,  1.51s/it]Epoch: 5/10. Loss: 0.9756:  23%|[36m██▎       [0m| 6/26 [00:09<00:30,  1.51s/it]Epoch: 5/10. Loss: 0.9756:  27%|[36m██▋       [0m| 7/26 [00:09<00:24,  1.30s/it]Epoch: 5/10. Loss: 1.0183:  27%|[36m██▋       [0m| 7/26 [00:10<00:24,  1.30s/it]Epoch: 5/10. Loss: 1.0183:  31%|[36m███       [0m| 8/26 [00:10<00:20,  1.13s/it]Epoch: 5/10. Loss: 0.9427:  31%|[36m███       [0m| 8/26 [00:10<00:20,  1.13s/it]Epoch: 5/10. Loss: 0.9427:  35%|[36m███▍      [0m| 9/26 [00:10<00:18,  1.07s/it]Epoch: 5/10. Loss: 0.9636:  35%|[36m███▍      [0m| 9/26 [00:11<00:18,  1.07s/it]Epoch: 5/10. Loss: 0.9636:  38%|[36m███▊      [0m| 10/26 [00:11<00:15,  1.04it/s]Epoch: 5/10. Loss: 1.0574:  38%|[36m███▊      [0m| 10/26 [00:12<00:15,  1.04it/s]Epoch: 5/10. Loss: 1.0574:  42%|[36m████▏     [0m| 11/26 [00:12<00:13,  1.10it/s]Epoch: 5/10. Loss: 1.0154:  42%|[36m████▏     [0m| 11/26 [00:13<00:13,  1.10it/s]Epoch: 5/10. Loss: 1.0154:  46%|[36m████▌     [0m| 12/26 [00:13<00:12,  1.11it/s]Epoch: 5/10. Loss: 1.0065:  46%|[36m████▌     [0m| 12/26 [00:14<00:12,  1.11it/s]Epoch: 5/10. Loss: 1.0065:  50%|[36m█████     [0m| 13/26 [00:14<00:11,  1.09it/s]Epoch: 5/10. Loss: 1.0633:  50%|[36m█████     [0m| 13/26 [00:15<00:11,  1.09it/s]Epoch: 5/10. Loss: 1.0633:  54%|[36m█████▍    [0m| 14/26 [00:15<00:10,  1.14it/s]Epoch: 5/10. Loss: 0.9732:  54%|[36m█████▍    [0m| 14/26 [00:15<00:10,  1.14it/s]Epoch: 5/10. Loss: 0.9732:  58%|[36m█████▊    [0m| 15/26 [00:15<00:09,  1.13it/s]Epoch: 5/10. Loss: 1.0822:  58%|[36m█████▊    [0m| 15/26 [00:16<00:09,  1.13it/s]Epoch: 5/10. Loss: 1.0822:  62%|[36m██████▏   [0m| 16/26 [00:16<00:08,  1.20it/s]Epoch: 5/10. Loss: 1.0039:  62%|[36m██████▏   [0m| 16/26 [00:17<00:08,  1.20it/s]Epoch: 5/10. Loss: 1.0039:  65%|[36m██████▌   [0m| 17/26 [00:17<00:08,  1.06it/s]Epoch: 5/10. Loss: 0.9855:  65%|[36m██████▌   [0m| 17/26 [00:18<00:08,  1.06it/s]Epoch: 5/10. Loss: 0.9855:  69%|[36m██████▉   [0m| 18/26 [00:18<00:07,  1.08it/s]Epoch: 5/10. Loss: 0.9849:  69%|[36m██████▉   [0m| 18/26 [00:19<00:07,  1.08it/s]Epoch: 5/10. Loss: 0.9849:  73%|[36m███████▎  [0m| 19/26 [00:19<00:06,  1.12it/s]Epoch: 5/10. Loss: 1.0788:  73%|[36m███████▎  [0m| 19/26 [00:20<00:06,  1.12it/s]Epoch: 5/10. Loss: 1.0788:  77%|[36m███████▋  [0m| 20/26 [00:20<00:05,  1.13it/s]Epoch: 5/10. Loss: 1.0226:  77%|[36m███████▋  [0m| 20/26 [00:21<00:05,  1.13it/s]Epoch: 5/10. Loss: 1.0226:  81%|[36m████████  [0m| 21/26 [00:21<00:04,  1.15it/s]Epoch: 5/10. Loss: 1.0475:  81%|[36m████████  [0m| 21/26 [00:22<00:04,  1.15it/s]Epoch: 5/10. Loss: 1.0475:  85%|[36m████████▍ [0m| 22/26 [00:22<00:03,  1.11it/s]Epoch: 5/10. Loss: 1.0417:  85%|[36m████████▍ [0m| 22/26 [00:22<00:03,  1.11it/s]Epoch: 5/10. Loss: 1.0417:  88%|[36m████████▊ [0m| 23/26 [00:22<00:02,  1.22it/s]Epoch: 5/10. Loss: 1.0112:  88%|[36m████████▊ [0m| 23/26 [00:23<00:02,  1.22it/s]Epoch: 5/10. Loss: 1.0112:  92%|[36m█████████▏[0m| 24/26 [00:23<00:01,  1.19it/s]Epoch: 5/10. Loss: 0.9963:  92%|[36m█████████▏[0m| 24/26 [00:24<00:01,  1.19it/s]Epoch: 5/10. Loss: 0.9963:  96%|[36m█████████▌[0m| 25/26 [00:24<00:00,  1.17it/s]Epoch: 5/10. Loss: 1.0086:  96%|[36m█████████▌[0m| 25/26 [00:25<00:00,  1.17it/s]Epoch: 5/10. Loss: 1.0086: 100%|[36m██████████[0m| 26/26 [00:25<00:00,  1.22it/s]Epoch: 5/10. Loss: 1.0086: 100%|[36m██████████[0m| 26/26 [00:25<00:00,  1.02it/s]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:04,  1.31it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:05,  1.10s/it] 43%|[33m████▎     [0m| 3/7 [00:02<00:03,  1.06it/s] 57%|[33m█████▋    [0m| 4/7 [00:04<00:03,  1.04s/it] 71%|[33m███████▏  [0m| 5/7 [00:04<00:01,  1.18it/s] 86%|[33m████████▌ [0m| 6/7 [00:05<00:00,  1.17it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.48it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.22it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 6/10. Loss: 1.0067:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 6/10. Loss: 1.0067:   4%|[36m▍         [0m| 1/26 [00:00<00:24,  1.03it/s]Epoch: 6/10. Loss: 1.0116:   4%|[36m▍         [0m| 1/26 [00:01<00:24,  1.03it/s]Epoch: 6/10. Loss: 1.0116:   8%|[36m▊         [0m| 2/26 [00:01<00:23,  1.02it/s]Epoch: 6/10. Loss: 1.1287:   8%|[36m▊         [0m| 2/26 [00:02<00:23,  1.02it/s]Epoch: 6/10. Loss: 1.1287:  12%|[36m█▏        [0m| 3/26 [00:02<00:21,  1.07it/s]Epoch: 6/10. Loss: 0.9613:  12%|[36m█▏        [0m| 3/26 [00:03<00:21,  1.07it/s]Epoch: 6/10. Loss: 0.9613:  15%|[36m█▌        [0m| 4/26 [00:03<00:19,  1.13it/s]Epoch: 6/10. Loss: 0.9772:  15%|[36m█▌        [0m| 4/26 [00:04<00:19,  1.13it/s]Epoch: 6/10. Loss: 0.9772:  19%|[36m█▉        [0m| 5/26 [00:04<00:19,  1.09it/s]Epoch: 6/10. Loss: 0.9569:  19%|[36m█▉        [0m| 5/26 [00:05<00:19,  1.09it/s]Epoch: 6/10. Loss: 0.9569:  23%|[36m██▎       [0m| 6/26 [00:05<00:17,  1.13it/s]Epoch: 6/10. Loss: 1.0444:  23%|[36m██▎       [0m| 6/26 [00:06<00:17,  1.13it/s]Epoch: 6/10. Loss: 1.0444:  27%|[36m██▋       [0m| 7/26 [00:06<00:17,  1.11it/s]Epoch: 6/10. Loss: 1.0751:  27%|[36m██▋       [0m| 7/26 [00:07<00:17,  1.11it/s]Epoch: 6/10. Loss: 1.0751:  31%|[36m███       [0m| 8/26 [00:07<00:16,  1.09it/s]Epoch: 6/10. Loss: 1.0783:  31%|[36m███       [0m| 8/26 [00:08<00:16,  1.09it/s]Epoch: 6/10. Loss: 1.0783:  35%|[36m███▍      [0m| 9/26 [00:08<00:14,  1.14it/s]Epoch: 6/10. Loss: 0.9939:  35%|[36m███▍      [0m| 9/26 [00:09<00:14,  1.14it/s]Epoch: 6/10. Loss: 0.9939:  38%|[36m███▊      [0m| 10/26 [00:09<00:14,  1.13it/s]Epoch: 6/10. Loss: 6.8058:  38%|[36m███▊      [0m| 10/26 [00:10<00:14,  1.13it/s]Epoch: 6/10. Loss: 6.8058:  42%|[36m████▏     [0m| 11/26 [00:10<00:14,  1.01it/s]Epoch: 6/10. Loss: 1.0581:  42%|[36m████▏     [0m| 11/26 [00:11<00:14,  1.01it/s]Epoch: 6/10. Loss: 1.0581:  46%|[36m████▌     [0m| 12/26 [00:11<00:13,  1.06it/s]Epoch: 6/10. Loss: 1.0164:  46%|[36m████▌     [0m| 12/26 [00:11<00:13,  1.06it/s]Epoch: 6/10. Loss: 1.0164:  50%|[36m█████     [0m| 13/26 [00:11<00:12,  1.07it/s]Epoch: 6/10. Loss: 0.9844:  50%|[36m█████     [0m| 13/26 [00:12<00:12,  1.07it/s]Epoch: 6/10. Loss: 0.9844:  54%|[36m█████▍    [0m| 14/26 [00:12<00:10,  1.15it/s]Epoch: 6/10. Loss: 1.0732:  54%|[36m█████▍    [0m| 14/26 [00:14<00:10,  1.15it/s]Epoch: 6/10. Loss: 1.0732:  58%|[36m█████▊    [0m| 15/26 [00:14<00:11,  1.03s/it]Epoch: 6/10. Loss: 0.9814:  58%|[36m█████▊    [0m| 15/26 [00:14<00:11,  1.03s/it]Epoch: 6/10. Loss: 0.9814:  62%|[36m██████▏   [0m| 16/26 [00:14<00:09,  1.06it/s]Epoch: 6/10. Loss: 1.0552:  62%|[36m██████▏   [0m| 16/26 [00:15<00:09,  1.06it/s]Epoch: 6/10. Loss: 1.0552:  65%|[36m██████▌   [0m| 17/26 [00:15<00:08,  1.11it/s]Epoch: 6/10. Loss: 0.9619:  65%|[36m██████▌   [0m| 17/26 [00:16<00:08,  1.11it/s]Epoch: 6/10. Loss: 0.9619:  69%|[36m██████▉   [0m| 18/26 [00:16<00:07,  1.06it/s]Epoch: 6/10. Loss: 0.9804:  69%|[36m██████▉   [0m| 18/26 [00:17<00:07,  1.06it/s]Epoch: 6/10. Loss: 0.9804:  73%|[36m███████▎  [0m| 19/26 [00:17<00:06,  1.10it/s]Epoch: 6/10. Loss: 1.1101:  73%|[36m███████▎  [0m| 19/26 [00:18<00:06,  1.10it/s]Epoch: 6/10. Loss: 1.1101:  77%|[36m███████▋  [0m| 20/26 [00:18<00:05,  1.02it/s]Epoch: 6/10. Loss: 0.9928:  77%|[36m███████▋  [0m| 20/26 [00:19<00:05,  1.02it/s]Epoch: 6/10. Loss: 0.9928:  81%|[36m████████  [0m| 21/26 [00:19<00:04,  1.06it/s]Epoch: 6/10. Loss: 1.0106:  81%|[36m████████  [0m| 21/26 [00:20<00:04,  1.06it/s]Epoch: 6/10. Loss: 1.0106:  85%|[36m████████▍ [0m| 22/26 [00:20<00:03,  1.10it/s]Epoch: 6/10. Loss: 0.9554:  85%|[36m████████▍ [0m| 22/26 [00:21<00:03,  1.10it/s]Epoch: 6/10. Loss: 0.9554:  88%|[36m████████▊ [0m| 23/26 [00:21<00:02,  1.18it/s]Epoch: 6/10. Loss: 1.0933:  88%|[36m████████▊ [0m| 23/26 [00:22<00:02,  1.18it/s]Epoch: 6/10. Loss: 1.0933:  92%|[36m█████████▏[0m| 24/26 [00:22<00:01,  1.13it/s]Epoch: 6/10. Loss: 1.0110:  92%|[36m█████████▏[0m| 24/26 [00:22<00:01,  1.13it/s]Epoch: 6/10. Loss: 1.0110:  96%|[36m█████████▌[0m| 25/26 [00:22<00:00,  1.20it/s]Epoch: 6/10. Loss: 1.0228:  96%|[36m█████████▌[0m| 25/26 [00:23<00:00,  1.20it/s]Epoch: 6/10. Loss: 1.0228: 100%|[36m██████████[0m| 26/26 [00:23<00:00,  1.33it/s]Epoch: 6/10. Loss: 1.0228: 100%|[36m██████████[0m| 26/26 [00:23<00:00,  1.11it/s]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:05,  1.04it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:05,  1.20s/it] 43%|[33m████▎     [0m| 3/7 [00:03<00:03,  1.03it/s] 57%|[33m█████▋    [0m| 4/7 [00:04<00:03,  1.05s/it] 71%|[33m███████▏  [0m| 5/7 [00:04<00:01,  1.13it/s] 86%|[33m████████▌ [0m| 6/7 [00:05<00:00,  1.12it/s]100%|[33m██████████[0m| 7/7 [00:06<00:00,  1.41it/s]100%|[33m██████████[0m| 7/7 [00:06<00:00,  1.16it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 7/10. Loss: 1.0288:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 7/10. Loss: 1.0288:   4%|[36m▍         [0m| 1/26 [00:00<00:21,  1.16it/s]Epoch: 7/10. Loss: 0.9339:   4%|[36m▍         [0m| 1/26 [00:01<00:21,  1.16it/s]Epoch: 7/10. Loss: 0.9339:   8%|[36m▊         [0m| 2/26 [00:01<00:21,  1.14it/s]Epoch: 7/10. Loss: 0.9938:   8%|[36m▊         [0m| 2/26 [00:02<00:21,  1.14it/s]Epoch: 7/10. Loss: 0.9938:  12%|[36m█▏        [0m| 3/26 [00:02<00:20,  1.11it/s]Epoch: 7/10. Loss: 0.9643:  12%|[36m█▏        [0m| 3/26 [00:03<00:20,  1.11it/s]Epoch: 7/10. Loss: 0.9643:  15%|[36m█▌        [0m| 4/26 [00:03<00:19,  1.14it/s]Epoch: 7/10. Loss: 1.0423:  15%|[36m█▌        [0m| 4/26 [00:04<00:19,  1.14it/s]Epoch: 7/10. Loss: 1.0423:  19%|[36m█▉        [0m| 5/26 [00:04<00:18,  1.13it/s]Epoch: 7/10. Loss: 1.0410:  19%|[36m█▉        [0m| 5/26 [00:05<00:18,  1.13it/s]Epoch: 7/10. Loss: 1.0410:  23%|[36m██▎       [0m| 6/26 [00:05<00:18,  1.09it/s]Epoch: 7/10. Loss: 1.0847:  23%|[36m██▎       [0m| 6/26 [00:06<00:18,  1.09it/s]Epoch: 7/10. Loss: 1.0847:  27%|[36m██▋       [0m| 7/26 [00:06<00:16,  1.12it/s]Epoch: 7/10. Loss: 1.0386:  27%|[36m██▋       [0m| 7/26 [00:07<00:16,  1.12it/s]Epoch: 7/10. Loss: 1.0386:  31%|[36m███       [0m| 8/26 [00:07<00:16,  1.11it/s]Epoch: 7/10. Loss: 1.0776:  31%|[36m███       [0m| 8/26 [00:08<00:16,  1.11it/s]Epoch: 7/10. Loss: 1.0776:  35%|[36m███▍      [0m| 9/26 [00:08<00:15,  1.08it/s]Epoch: 7/10. Loss: 1.0119:  35%|[36m███▍      [0m| 9/26 [00:08<00:15,  1.08it/s]Epoch: 7/10. Loss: 1.0119:  38%|[36m███▊      [0m| 10/26 [00:08<00:13,  1.16it/s]Epoch: 7/10. Loss: 1.0257:  38%|[36m███▊      [0m| 10/26 [00:11<00:13,  1.16it/s]Epoch: 7/10. Loss: 1.0257:  42%|[36m████▏     [0m| 11/26 [00:11<00:22,  1.47s/it]Epoch: 7/10. Loss: 1.0505:  42%|[36m████▏     [0m| 11/26 [00:12<00:22,  1.47s/it]Epoch: 7/10. Loss: 1.0505:  46%|[36m████▌     [0m| 12/26 [00:12<00:18,  1.32s/it]Epoch: 7/10. Loss: 1.0652:  46%|[36m████▌     [0m| 12/26 [00:13<00:18,  1.32s/it]Epoch: 7/10. Loss: 1.0652:  50%|[36m█████     [0m| 13/26 [00:13<00:14,  1.13s/it]Epoch: 7/10. Loss: 1.0182:  50%|[36m█████     [0m| 13/26 [00:14<00:14,  1.13s/it]Epoch: 7/10. Loss: 1.0182:  54%|[36m█████▍    [0m| 14/26 [00:14<00:13,  1.10s/it]Epoch: 7/10. Loss: 1.0682:  54%|[36m█████▍    [0m| 14/26 [00:15<00:13,  1.10s/it]Epoch: 7/10. Loss: 1.0682:  58%|[36m█████▊    [0m| 15/26 [00:15<00:11,  1.00s/it]Epoch: 7/10. Loss: 0.9727:  58%|[36m█████▊    [0m| 15/26 [00:15<00:11,  1.00s/it]Epoch: 7/10. Loss: 0.9727:  62%|[36m██████▏   [0m| 16/26 [00:15<00:09,  1.07it/s]Epoch: 7/10. Loss: 1.0637:  62%|[36m██████▏   [0m| 16/26 [00:17<00:09,  1.07it/s]Epoch: 7/10. Loss: 1.0637:  65%|[36m██████▌   [0m| 17/26 [00:17<00:10,  1.12s/it]Epoch: 7/10. Loss: 1.0198:  65%|[36m██████▌   [0m| 17/26 [00:18<00:10,  1.12s/it]Epoch: 7/10. Loss: 1.0198:  69%|[36m██████▉   [0m| 18/26 [00:18<00:08,  1.02s/it]Epoch: 7/10. Loss: 1.0353:  69%|[36m██████▉   [0m| 18/26 [00:19<00:08,  1.02s/it]Epoch: 7/10. Loss: 1.0353:  73%|[36m███████▎  [0m| 19/26 [00:19<00:06,  1.02it/s]Epoch: 7/10. Loss: 1.0054:  73%|[36m███████▎  [0m| 19/26 [00:20<00:06,  1.02it/s]Epoch: 7/10. Loss: 1.0054:  77%|[36m███████▋  [0m| 20/26 [00:20<00:05,  1.00it/s]Epoch: 7/10. Loss: 1.0540:  77%|[36m███████▋  [0m| 20/26 [00:21<00:05,  1.00it/s]Epoch: 7/10. Loss: 1.0540:  81%|[36m████████  [0m| 21/26 [00:21<00:04,  1.08it/s]Epoch: 7/10. Loss: 0.9688:  81%|[36m████████  [0m| 21/26 [00:21<00:04,  1.08it/s]Epoch: 7/10. Loss: 0.9688:  85%|[36m████████▍ [0m| 22/26 [00:21<00:03,  1.08it/s]Epoch: 7/10. Loss: 0.9907:  85%|[36m████████▍ [0m| 22/26 [00:25<00:03,  1.08it/s]Epoch: 7/10. Loss: 0.9907:  88%|[36m████████▊ [0m| 23/26 [00:25<00:05,  1.67s/it]Epoch: 7/10. Loss: 1.0005:  88%|[36m████████▊ [0m| 23/26 [00:26<00:05,  1.67s/it]Epoch: 7/10. Loss: 1.0005:  92%|[36m█████████▏[0m| 24/26 [00:26<00:03,  1.51s/it]Epoch: 7/10. Loss: 0.9702:  92%|[36m█████████▏[0m| 24/26 [00:27<00:03,  1.51s/it]Epoch: 7/10. Loss: 0.9702:  96%|[36m█████████▌[0m| 25/26 [00:27<00:01,  1.30s/it]Epoch: 7/10. Loss: 0.9965:  96%|[36m█████████▌[0m| 25/26 [00:28<00:01,  1.30s/it]Epoch: 7/10. Loss: 0.9965: 100%|[36m██████████[0m| 26/26 [00:28<00:00,  1.13s/it]Epoch: 7/10. Loss: 0.9965: 100%|[36m██████████[0m| 26/26 [00:28<00:00,  1.08s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:04,  1.31it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:05,  1.09s/it] 43%|[33m████▎     [0m| 3/7 [00:02<00:03,  1.11it/s] 57%|[33m█████▋    [0m| 4/7 [00:03<00:02,  1.01it/s] 71%|[33m███████▏  [0m| 5/7 [00:04<00:01,  1.21it/s] 86%|[33m████████▌ [0m| 6/7 [00:05<00:00,  1.18it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.49it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.25it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 8/10. Loss: 1.0153:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 8/10. Loss: 1.0153:   4%|[36m▍         [0m| 1/26 [00:00<00:19,  1.27it/s]Epoch: 8/10. Loss: 1.0673:   4%|[36m▍         [0m| 1/26 [00:01<00:19,  1.27it/s]Epoch: 8/10. Loss: 1.0673:   8%|[36m▊         [0m| 2/26 [00:01<00:20,  1.15it/s]Epoch: 8/10. Loss: 0.9912:   8%|[36m▊         [0m| 2/26 [00:02<00:20,  1.15it/s]Epoch: 8/10. Loss: 0.9912:  12%|[36m█▏        [0m| 3/26 [00:02<00:19,  1.17it/s]Epoch: 8/10. Loss: 1.0604:  12%|[36m█▏        [0m| 3/26 [00:03<00:19,  1.17it/s]Epoch: 8/10. Loss: 1.0604:  15%|[36m█▌        [0m| 4/26 [00:03<00:19,  1.11it/s]Epoch: 8/10. Loss: 1.0702:  15%|[36m█▌        [0m| 4/26 [00:04<00:19,  1.11it/s]Epoch: 8/10. Loss: 1.0702:  19%|[36m█▉        [0m| 5/26 [00:04<00:19,  1.10it/s]Epoch: 8/10. Loss: 1.0562:  19%|[36m█▉        [0m| 5/26 [00:05<00:19,  1.10it/s]Epoch: 8/10. Loss: 1.0562:  23%|[36m██▎       [0m| 6/26 [00:05<00:17,  1.14it/s]Epoch: 8/10. Loss: 0.9727:  23%|[36m██▎       [0m| 6/26 [00:06<00:17,  1.14it/s]Epoch: 8/10. Loss: 0.9727:  27%|[36m██▋       [0m| 7/26 [00:06<00:16,  1.12it/s]Epoch: 8/10. Loss: 1.0279:  27%|[36m██▋       [0m| 7/26 [00:07<00:16,  1.12it/s]Epoch: 8/10. Loss: 1.0279:  31%|[36m███       [0m| 8/26 [00:07<00:16,  1.12it/s]Epoch: 8/10. Loss: 1.0442:  31%|[36m███       [0m| 8/26 [00:07<00:16,  1.12it/s]Epoch: 8/10. Loss: 1.0442:  35%|[36m███▍      [0m| 9/26 [00:07<00:15,  1.13it/s]Epoch: 8/10. Loss: 0.9803:  35%|[36m███▍      [0m| 9/26 [00:08<00:15,  1.13it/s]Epoch: 8/10. Loss: 0.9803:  38%|[36m███▊      [0m| 10/26 [00:08<00:13,  1.14it/s]Epoch: 8/10. Loss: 1.0425:  38%|[36m███▊      [0m| 10/26 [00:09<00:13,  1.14it/s]Epoch: 8/10. Loss: 1.0425:  42%|[36m████▏     [0m| 11/26 [00:09<00:12,  1.16it/s]Epoch: 8/10. Loss: 1.0218:  42%|[36m████▏     [0m| 11/26 [00:10<00:12,  1.16it/s]Epoch: 8/10. Loss: 1.0218:  46%|[36m████▌     [0m| 12/26 [00:10<00:12,  1.15it/s]Epoch: 8/10. Loss: 1.0009:  46%|[36m████▌     [0m| 12/26 [00:11<00:12,  1.15it/s]Epoch: 8/10. Loss: 1.0009:  50%|[36m█████     [0m| 13/26 [00:11<00:11,  1.12it/s]Epoch: 8/10. Loss: 0.9657:  50%|[36m█████     [0m| 13/26 [00:12<00:11,  1.12it/s]Epoch: 8/10. Loss: 0.9657:  54%|[36m█████▍    [0m| 14/26 [00:12<00:10,  1.15it/s]Epoch: 8/10. Loss: 0.9713:  54%|[36m█████▍    [0m| 14/26 [00:13<00:10,  1.15it/s]Epoch: 8/10. Loss: 0.9713:  58%|[36m█████▊    [0m| 15/26 [00:13<00:09,  1.16it/s]Epoch: 8/10. Loss: 0.9550:  58%|[36m█████▊    [0m| 15/26 [00:13<00:09,  1.16it/s]Epoch: 8/10. Loss: 0.9550:  62%|[36m██████▏   [0m| 16/26 [00:13<00:08,  1.18it/s]Epoch: 8/10. Loss: 1.0349:  62%|[36m██████▏   [0m| 16/26 [00:14<00:08,  1.18it/s]Epoch: 8/10. Loss: 1.0349:  65%|[36m██████▌   [0m| 17/26 [00:14<00:07,  1.19it/s]Epoch: 8/10. Loss: 1.0578:  65%|[36m██████▌   [0m| 17/26 [00:15<00:07,  1.19it/s]Epoch: 8/10. Loss: 1.0578:  69%|[36m██████▉   [0m| 18/26 [00:15<00:06,  1.15it/s]Epoch: 8/10. Loss: 0.9295:  69%|[36m██████▉   [0m| 18/26 [00:16<00:06,  1.15it/s]Epoch: 8/10. Loss: 0.9295:  73%|[36m███████▎  [0m| 19/26 [00:16<00:06,  1.12it/s]Epoch: 8/10. Loss: 0.9440:  73%|[36m███████▎  [0m| 19/26 [00:17<00:06,  1.12it/s]Epoch: 8/10. Loss: 0.9440:  77%|[36m███████▋  [0m| 20/26 [00:17<00:05,  1.15it/s]Epoch: 8/10. Loss: 1.0122:  77%|[36m███████▋  [0m| 20/26 [00:18<00:05,  1.15it/s]Epoch: 8/10. Loss: 1.0122:  81%|[36m████████  [0m| 21/26 [00:18<00:04,  1.17it/s]Epoch: 8/10. Loss: 1.0170:  81%|[36m████████  [0m| 21/26 [00:19<00:04,  1.17it/s]Epoch: 8/10. Loss: 1.0170:  85%|[36m████████▍ [0m| 22/26 [00:19<00:03,  1.15it/s]Epoch: 8/10. Loss: 0.9547:  85%|[36m████████▍ [0m| 22/26 [00:20<00:03,  1.15it/s]Epoch: 8/10. Loss: 0.9547:  88%|[36m████████▊ [0m| 23/26 [00:20<00:02,  1.14it/s]Epoch: 8/10. Loss: 1.0077:  88%|[36m████████▊ [0m| 23/26 [00:21<00:02,  1.14it/s]Epoch: 8/10. Loss: 1.0077:  92%|[36m█████████▏[0m| 24/26 [00:21<00:01,  1.13it/s]Epoch: 8/10. Loss: 1.0427:  92%|[36m█████████▏[0m| 24/26 [00:21<00:01,  1.13it/s]Epoch: 8/10. Loss: 1.0427:  96%|[36m█████████▌[0m| 25/26 [00:21<00:00,  1.11it/s]Epoch: 8/10. Loss: 1.1565:  96%|[36m█████████▌[0m| 25/26 [00:22<00:00,  1.11it/s]Epoch: 8/10. Loss: 1.1565: 100%|[36m██████████[0m| 26/26 [00:22<00:00,  1.23it/s]Epoch: 8/10. Loss: 1.1565: 100%|[36m██████████[0m| 26/26 [00:22<00:00,  1.15it/s]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:04,  1.31it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:05,  1.09s/it] 43%|[33m████▎     [0m| 3/7 [00:02<00:03,  1.11it/s] 57%|[33m█████▋    [0m| 4/7 [00:03<00:02,  1.01it/s] 71%|[33m███████▏  [0m| 5/7 [00:04<00:01,  1.22it/s] 86%|[33m████████▌ [0m| 6/7 [00:05<00:00,  1.19it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.53it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.26it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 9/10. Loss: 1.0505:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 9/10. Loss: 1.0505:   4%|[36m▍         [0m| 1/26 [00:00<00:19,  1.28it/s]Epoch: 9/10. Loss: 0.9901:   4%|[36m▍         [0m| 1/26 [00:01<00:19,  1.28it/s]Epoch: 9/10. Loss: 0.9901:   8%|[36m▊         [0m| 2/26 [00:01<00:17,  1.34it/s]Epoch: 9/10. Loss: 1.0265:   8%|[36m▊         [0m| 2/26 [00:02<00:17,  1.34it/s]Epoch: 9/10. Loss: 1.0265:  12%|[36m█▏        [0m| 3/26 [00:02<00:17,  1.34it/s]Epoch: 9/10. Loss: 1.0080:  12%|[36m█▏        [0m| 3/26 [00:03<00:17,  1.34it/s]Epoch: 9/10. Loss: 1.0080:  15%|[36m█▌        [0m| 4/26 [00:03<00:18,  1.21it/s]Epoch: 9/10. Loss: 1.0517:  15%|[36m█▌        [0m| 4/26 [00:04<00:18,  1.21it/s]Epoch: 9/10. Loss: 1.0517:  19%|[36m█▉        [0m| 5/26 [00:04<00:17,  1.17it/s]Epoch: 9/10. Loss: 1.0328:  19%|[36m█▉        [0m| 5/26 [00:04<00:17,  1.17it/s]Epoch: 9/10. Loss: 1.0328:  23%|[36m██▎       [0m| 6/26 [00:04<00:16,  1.21it/s]Epoch: 9/10. Loss: 0.9737:  23%|[36m██▎       [0m| 6/26 [00:05<00:16,  1.21it/s]Epoch: 9/10. Loss: 0.9737:  27%|[36m██▋       [0m| 7/26 [00:05<00:16,  1.17it/s]Epoch: 9/10. Loss: 1.0459:  27%|[36m██▋       [0m| 7/26 [00:06<00:16,  1.17it/s]Epoch: 9/10. Loss: 1.0459:  31%|[36m███       [0m| 8/26 [00:06<00:15,  1.14it/s]Epoch: 9/10. Loss: 0.9694:  31%|[36m███       [0m| 8/26 [00:07<00:15,  1.14it/s]Epoch: 9/10. Loss: 0.9694:  35%|[36m███▍      [0m| 9/26 [00:07<00:14,  1.14it/s]Epoch: 9/10. Loss: 0.9916:  35%|[36m███▍      [0m| 9/26 [00:08<00:14,  1.14it/s]Epoch: 9/10. Loss: 0.9916:  38%|[36m███▊      [0m| 10/26 [00:08<00:13,  1.15it/s]Epoch: 9/10. Loss: 1.0035:  38%|[36m███▊      [0m| 10/26 [00:09<00:13,  1.15it/s]Epoch: 9/10. Loss: 1.0035:  42%|[36m████▏     [0m| 11/26 [00:09<00:13,  1.15it/s]Epoch: 9/10. Loss: 1.0137:  42%|[36m████▏     [0m| 11/26 [00:10<00:13,  1.15it/s]Epoch: 9/10. Loss: 1.0137:  46%|[36m████▌     [0m| 12/26 [00:10<00:11,  1.20it/s]Epoch: 9/10. Loss: 1.0363:  46%|[36m████▌     [0m| 12/26 [00:10<00:11,  1.20it/s]Epoch: 9/10. Loss: 1.0363:  50%|[36m█████     [0m| 13/26 [00:10<00:10,  1.25it/s]Epoch: 9/10. Loss: 1.0207:  50%|[36m█████     [0m| 13/26 [00:11<00:10,  1.25it/s]Epoch: 9/10. Loss: 1.0207:  54%|[36m█████▍    [0m| 14/26 [00:11<00:11,  1.09it/s]Epoch: 9/10. Loss: 1.0156:  54%|[36m█████▍    [0m| 14/26 [00:12<00:11,  1.09it/s]Epoch: 9/10. Loss: 1.0156:  58%|[36m█████▊    [0m| 15/26 [00:12<00:09,  1.19it/s]Epoch: 9/10. Loss: 1.0108:  58%|[36m█████▊    [0m| 15/26 [00:13<00:09,  1.19it/s]Epoch: 9/10. Loss: 1.0108:  62%|[36m██████▏   [0m| 16/26 [00:13<00:08,  1.12it/s]Epoch: 9/10. Loss: 1.0521:  62%|[36m██████▏   [0m| 16/26 [00:14<00:08,  1.12it/s]Epoch: 9/10. Loss: 1.0521:  65%|[36m██████▌   [0m| 17/26 [00:14<00:07,  1.14it/s]Epoch: 9/10. Loss: 1.0798:  65%|[36m██████▌   [0m| 17/26 [00:15<00:07,  1.14it/s]Epoch: 9/10. Loss: 1.0798:  69%|[36m██████▉   [0m| 18/26 [00:15<00:07,  1.11it/s]Epoch: 9/10. Loss: 1.0176:  69%|[36m██████▉   [0m| 18/26 [00:16<00:07,  1.11it/s]Epoch: 9/10. Loss: 1.0176:  73%|[36m███████▎  [0m| 19/26 [00:16<00:06,  1.12it/s]Epoch: 9/10. Loss: 0.9584:  73%|[36m███████▎  [0m| 19/26 [00:17<00:06,  1.12it/s]Epoch: 9/10. Loss: 0.9584:  77%|[36m███████▋  [0m| 20/26 [00:17<00:05,  1.18it/s]Epoch: 9/10. Loss: 0.9745:  77%|[36m███████▋  [0m| 20/26 [00:18<00:05,  1.18it/s]Epoch: 9/10. Loss: 0.9745:  81%|[36m████████  [0m| 21/26 [00:18<00:04,  1.12it/s]Epoch: 9/10. Loss: 1.0185:  81%|[36m████████  [0m| 21/26 [00:18<00:04,  1.12it/s]Epoch: 9/10. Loss: 1.0185:  85%|[36m████████▍ [0m| 22/26 [00:18<00:03,  1.15it/s]Epoch: 9/10. Loss: 1.0531:  85%|[36m████████▍ [0m| 22/26 [00:19<00:03,  1.15it/s]Epoch: 9/10. Loss: 1.0531:  88%|[36m████████▊ [0m| 23/26 [00:19<00:02,  1.16it/s]Epoch: 9/10. Loss: 1.0496:  88%|[36m████████▊ [0m| 23/26 [00:20<00:02,  1.16it/s]Epoch: 9/10. Loss: 1.0496:  92%|[36m█████████▏[0m| 24/26 [00:20<00:01,  1.13it/s]Epoch: 9/10. Loss: 0.9681:  92%|[36m█████████▏[0m| 24/26 [00:21<00:01,  1.13it/s]Epoch: 9/10. Loss: 0.9681:  96%|[36m█████████▌[0m| 25/26 [00:21<00:00,  1.17it/s]Epoch: 9/10. Loss: 0.9553:  96%|[36m█████████▌[0m| 25/26 [00:22<00:00,  1.17it/s]Epoch: 9/10. Loss: 0.9553: 100%|[36m██████████[0m| 26/26 [00:22<00:00,  1.29it/s]Epoch: 9/10. Loss: 0.9553: 100%|[36m██████████[0m| 26/26 [00:22<00:00,  1.18it/s]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:04,  1.30it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:05,  1.11s/it] 43%|[33m████▎     [0m| 3/7 [00:02<00:03,  1.09it/s] 57%|[33m█████▋    [0m| 4/7 [00:03<00:03,  1.02s/it] 71%|[33m███████▏  [0m| 5/7 [00:04<00:01,  1.19it/s] 86%|[33m████████▌ [0m| 6/7 [00:05<00:00,  1.16it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.49it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.23it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 0/10. Loss: 7.1319:   0%|[36m          [0m| 0/26 [00:01<?, ?it/s]Epoch: 0/10. Loss: 7.1319:   4%|[36m▍         [0m| 1/26 [00:01<00:26,  1.08s/it]Epoch: 0/10. Loss: 3.1436:   4%|[36m▍         [0m| 1/26 [00:02<00:26,  1.08s/it]Epoch: 0/10. Loss: 3.1436:   8%|[36m▊         [0m| 2/26 [00:02<00:24,  1.01s/it]Epoch: 0/10. Loss: 1.3593:   8%|[36m▊         [0m| 2/26 [00:03<00:24,  1.01s/it]Epoch: 0/10. Loss: 1.3593:  12%|[36m█▏        [0m| 3/26 [00:03<00:27,  1.22s/it]Epoch: 0/10. Loss: 1.4694:  12%|[36m█▏        [0m| 3/26 [00:04<00:27,  1.22s/it]Epoch: 0/10. Loss: 1.4694:  15%|[36m█▌        [0m| 4/26 [00:04<00:23,  1.06s/it]Epoch: 0/10. Loss: 1.1767:  15%|[36m█▌        [0m| 4/26 [00:05<00:23,  1.06s/it]Epoch: 0/10. Loss: 1.1767:  19%|[36m█▉        [0m| 5/26 [00:05<00:20,  1.04it/s]Epoch: 0/10. Loss: 1.0667:  19%|[36m█▉        [0m| 5/26 [00:06<00:20,  1.04it/s]Epoch: 0/10. Loss: 1.0667:  23%|[36m██▎       [0m| 6/26 [00:06<00:19,  1.03it/s]Epoch: 0/10. Loss: 1.2620:  23%|[36m██▎       [0m| 6/26 [00:06<00:19,  1.03it/s]Epoch: 0/10. Loss: 1.2620:  27%|[36m██▋       [0m| 7/26 [00:06<00:17,  1.06it/s]Epoch: 0/10. Loss: 1.0893:  27%|[36m██▋       [0m| 7/26 [00:07<00:17,  1.06it/s]Epoch: 0/10. Loss: 1.0893:  31%|[36m███       [0m| 8/26 [00:07<00:16,  1.06it/s]Epoch: 0/10. Loss: 1.0777:  31%|[36m███       [0m| 8/26 [00:08<00:16,  1.06it/s]Epoch: 0/10. Loss: 1.0777:  35%|[36m███▍      [0m| 9/26 [00:08<00:15,  1.09it/s]Epoch: 0/10. Loss: 1.1250:  35%|[36m███▍      [0m| 9/26 [00:09<00:15,  1.09it/s]Epoch: 0/10. Loss: 1.1250:  38%|[36m███▊      [0m| 10/26 [00:09<00:15,  1.05it/s]Epoch: 0/10. Loss: 1.1584:  38%|[36m███▊      [0m| 10/26 [00:10<00:15,  1.05it/s]Epoch: 0/10. Loss: 1.1584:  42%|[36m████▏     [0m| 11/26 [00:10<00:14,  1.02it/s]Epoch: 0/10. Loss: 0.9564:  42%|[36m████▏     [0m| 11/26 [00:11<00:14,  1.02it/s]Epoch: 0/10. Loss: 0.9564:  46%|[36m████▌     [0m| 12/26 [00:11<00:13,  1.02it/s]Epoch: 0/10. Loss: 0.9879:  46%|[36m████▌     [0m| 12/26 [00:12<00:13,  1.02it/s]Epoch: 0/10. Loss: 0.9879:  50%|[36m█████     [0m| 13/26 [00:12<00:12,  1.04it/s]Epoch: 0/10. Loss: 1.0369:  50%|[36m█████     [0m| 13/26 [00:13<00:12,  1.04it/s]Epoch: 0/10. Loss: 1.0369:  54%|[36m█████▍    [0m| 14/26 [00:13<00:11,  1.05it/s]Epoch: 0/10. Loss: 0.9955:  54%|[36m█████▍    [0m| 14/26 [00:14<00:11,  1.05it/s]Epoch: 0/10. Loss: 0.9955:  58%|[36m█████▊    [0m| 15/26 [00:14<00:10,  1.02it/s]Epoch: 0/10. Loss: 0.9781:  58%|[36m█████▊    [0m| 15/26 [00:15<00:10,  1.02it/s]Epoch: 0/10. Loss: 0.9781:  62%|[36m██████▏   [0m| 16/26 [00:15<00:09,  1.07it/s]Epoch: 0/10. Loss: 1.0146:  62%|[36m██████▏   [0m| 16/26 [00:16<00:09,  1.07it/s]Epoch: 0/10. Loss: 1.0146:  65%|[36m██████▌   [0m| 17/26 [00:16<00:08,  1.08it/s]Epoch: 0/10. Loss: 1.1063:  65%|[36m██████▌   [0m| 17/26 [00:17<00:08,  1.08it/s]Epoch: 0/10. Loss: 1.1063:  69%|[36m██████▉   [0m| 18/26 [00:17<00:07,  1.08it/s]Epoch: 0/10. Loss: 1.0467:  69%|[36m██████▉   [0m| 18/26 [00:18<00:07,  1.08it/s]Epoch: 0/10. Loss: 1.0467:  73%|[36m███████▎  [0m| 19/26 [00:18<00:06,  1.06it/s]Epoch: 0/10. Loss: 0.9642:  73%|[36m███████▎  [0m| 19/26 [00:19<00:06,  1.06it/s]Epoch: 0/10. Loss: 0.9642:  77%|[36m███████▋  [0m| 20/26 [00:19<00:05,  1.03it/s]Epoch: 0/10. Loss: 0.9915:  77%|[36m███████▋  [0m| 20/26 [00:20<00:05,  1.03it/s]Epoch: 0/10. Loss: 0.9915:  81%|[36m████████  [0m| 21/26 [00:20<00:04,  1.04it/s]Epoch: 0/10. Loss: 1.0929:  81%|[36m████████  [0m| 21/26 [00:21<00:04,  1.04it/s]Epoch: 0/10. Loss: 1.0929:  85%|[36m████████▍ [0m| 22/26 [00:21<00:04,  1.01s/it]Epoch: 0/10. Loss: 1.0971:  85%|[36m████████▍ [0m| 22/26 [00:22<00:04,  1.01s/it]Epoch: 0/10. Loss: 1.0971:  88%|[36m████████▊ [0m| 23/26 [00:22<00:02,  1.01it/s]Epoch: 0/10. Loss: 0.9617:  88%|[36m████████▊ [0m| 23/26 [00:23<00:02,  1.01it/s]Epoch: 0/10. Loss: 0.9617:  92%|[36m█████████▏[0m| 24/26 [00:23<00:01,  1.01it/s]Epoch: 0/10. Loss: 0.9925:  92%|[36m█████████▏[0m| 24/26 [00:24<00:01,  1.01it/s]Epoch: 0/10. Loss: 0.9925:  96%|[36m█████████▌[0m| 25/26 [00:24<00:01,  1.05s/it]Epoch: 0/10. Loss: 1.0784:  96%|[36m█████████▌[0m| 25/26 [00:25<00:01,  1.05s/it]Epoch: 0/10. Loss: 1.0784: 100%|[36m██████████[0m| 26/26 [00:25<00:00,  1.10it/s]Epoch: 0/10. Loss: 1.0784: 100%|[36m██████████[0m| 26/26 [00:25<00:00,  1.03it/s]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:05,  1.18it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:07,  1.57s/it] 43%|[33m████▎     [0m| 3/7 [00:03<00:04,  1.19s/it] 57%|[33m█████▋    [0m| 4/7 [00:05<00:03,  1.30s/it] 71%|[33m███████▏  [0m| 5/7 [00:05<00:02,  1.07s/it] 86%|[33m████████▌ [0m| 6/7 [00:06<00:01,  1.02s/it]100%|[33m██████████[0m| 7/7 [00:07<00:00,  1.27it/s]100%|[33m██████████[0m| 7/7 [00:07<00:00,  1.00s/it]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 1/10. Loss: 1.0739:   0%|[36m          [0m| 0/26 [00:01<?, ?it/s]Epoch: 1/10. Loss: 1.0739:   4%|[36m▍         [0m| 1/26 [00:01<00:27,  1.09s/it]Epoch: 1/10. Loss: 0.9435:   4%|[36m▍         [0m| 1/26 [00:01<00:27,  1.09s/it]Epoch: 1/10. Loss: 0.9435:   8%|[36m▊         [0m| 2/26 [00:01<00:22,  1.06it/s]Epoch: 1/10. Loss: 0.9806:   8%|[36m▊         [0m| 2/26 [00:02<00:22,  1.06it/s]Epoch: 1/10. Loss: 0.9806:  12%|[36m█▏        [0m| 3/26 [00:02<00:21,  1.07it/s]Epoch: 1/10. Loss: 1.0179:  12%|[36m█▏        [0m| 3/26 [00:03<00:21,  1.07it/s]Epoch: 1/10. Loss: 1.0179:  15%|[36m█▌        [0m| 4/26 [00:03<00:22,  1.01s/it]Epoch: 1/10. Loss: 1.1097:  15%|[36m█▌        [0m| 4/26 [00:05<00:22,  1.01s/it]Epoch: 1/10. Loss: 1.1097:  19%|[36m█▉        [0m| 5/26 [00:05<00:21,  1.03s/it]Epoch: 1/10. Loss: 1.0182:  19%|[36m█▉        [0m| 5/26 [00:06<00:21,  1.03s/it]Epoch: 1/10. Loss: 1.0182:  23%|[36m██▎       [0m| 6/26 [00:06<00:20,  1.02s/it]Epoch: 1/10. Loss: 0.9382:  23%|[36m██▎       [0m| 6/26 [00:06<00:20,  1.02s/it]Epoch: 1/10. Loss: 0.9382:  27%|[36m██▋       [0m| 7/26 [00:06<00:18,  1.01it/s]Epoch: 1/10. Loss: 1.0189:  27%|[36m██▋       [0m| 7/26 [00:07<00:18,  1.01it/s]Epoch: 1/10. Loss: 1.0189:  31%|[36m███       [0m| 8/26 [00:07<00:16,  1.08it/s]Epoch: 1/10. Loss: 1.0919:  31%|[36m███       [0m| 8/26 [00:08<00:16,  1.08it/s]Epoch: 1/10. Loss: 1.0919:  35%|[36m███▍      [0m| 9/26 [00:08<00:15,  1.08it/s]Epoch: 1/10. Loss: 1.0732:  35%|[36m███▍      [0m| 9/26 [00:09<00:15,  1.08it/s]Epoch: 1/10. Loss: 1.0732:  38%|[36m███▊      [0m| 10/26 [00:09<00:15,  1.01it/s]Epoch: 1/10. Loss: 1.0246:  38%|[36m███▊      [0m| 10/26 [00:10<00:15,  1.01it/s]Epoch: 1/10. Loss: 1.0246:  42%|[36m████▏     [0m| 11/26 [00:10<00:14,  1.05it/s]Epoch: 1/10. Loss: 1.0522:  42%|[36m████▏     [0m| 11/26 [00:13<00:14,  1.05it/s]Epoch: 1/10. Loss: 1.0522:  46%|[36m████▌     [0m| 12/26 [00:13<00:22,  1.60s/it]Epoch: 1/10. Loss: 1.0722:  46%|[36m████▌     [0m| 12/26 [00:14<00:22,  1.60s/it]Epoch: 1/10. Loss: 1.0722:  50%|[36m█████     [0m| 13/26 [00:14<00:18,  1.40s/it]Epoch: 1/10. Loss: 0.9792:  50%|[36m█████     [0m| 13/26 [00:15<00:18,  1.40s/it]Epoch: 1/10. Loss: 0.9792:  54%|[36m█████▍    [0m| 14/26 [00:15<00:15,  1.30s/it]Epoch: 1/10. Loss: 0.9124:  54%|[36m█████▍    [0m| 14/26 [00:16<00:15,  1.30s/it]Epoch: 1/10. Loss: 0.9124:  58%|[36m█████▊    [0m| 15/26 [00:16<00:13,  1.19s/it]Epoch: 1/10. Loss: 0.9295:  58%|[36m█████▊    [0m| 15/26 [00:17<00:13,  1.19s/it]Epoch: 1/10. Loss: 0.9295:  62%|[36m██████▏   [0m| 16/26 [00:17<00:11,  1.11s/it]Epoch: 1/10. Loss: 1.0121:  62%|[36m██████▏   [0m| 16/26 [00:19<00:11,  1.11s/it]Epoch: 1/10. Loss: 1.0121:  65%|[36m██████▌   [0m| 17/26 [00:19<00:11,  1.26s/it]Epoch: 1/10. Loss: 1.0480:  65%|[36m██████▌   [0m| 17/26 [00:22<00:11,  1.26s/it]Epoch: 1/10. Loss: 1.0480:  69%|[36m██████▉   [0m| 18/26 [00:22<00:15,  1.91s/it]Epoch: 1/10. Loss: 1.0039:  69%|[36m██████▉   [0m| 18/26 [00:23<00:15,  1.91s/it]Epoch: 1/10. Loss: 1.0039:  73%|[36m███████▎  [0m| 19/26 [00:23<00:11,  1.58s/it]Epoch: 1/10. Loss: 0.9266:  73%|[36m███████▎  [0m| 19/26 [00:24<00:11,  1.58s/it]Epoch: 1/10. Loss: 0.9266:  77%|[36m███████▋  [0m| 20/26 [00:24<00:08,  1.40s/it]Epoch: 1/10. Loss: 1.0805:  77%|[36m███████▋  [0m| 20/26 [00:25<00:08,  1.40s/it]Epoch: 1/10. Loss: 1.0805:  81%|[36m████████  [0m| 21/26 [00:25<00:06,  1.25s/it]Epoch: 1/10. Loss: 0.9586:  81%|[36m████████  [0m| 21/26 [00:27<00:06,  1.25s/it]Epoch: 1/10. Loss: 0.9586:  85%|[36m████████▍ [0m| 22/26 [00:27<00:05,  1.48s/it]Epoch: 1/10. Loss: 0.9718:  85%|[36m████████▍ [0m| 22/26 [00:28<00:05,  1.48s/it]Epoch: 1/10. Loss: 0.9718:  88%|[36m████████▊ [0m| 23/26 [00:28<00:04,  1.34s/it]Epoch: 1/10. Loss: 1.0533:  88%|[36m████████▊ [0m| 23/26 [00:29<00:04,  1.34s/it]Epoch: 1/10. Loss: 1.0533:  92%|[36m█████████▏[0m| 24/26 [00:29<00:02,  1.20s/it]Epoch: 1/10. Loss: 0.9846:  92%|[36m█████████▏[0m| 24/26 [00:30<00:02,  1.20s/it]Epoch: 1/10. Loss: 0.9846:  96%|[36m█████████▌[0m| 25/26 [00:30<00:01,  1.08s/it]Epoch: 1/10. Loss: 0.9072:  96%|[36m█████████▌[0m| 25/26 [00:30<00:01,  1.08s/it]Epoch: 1/10. Loss: 0.9072: 100%|[36m██████████[0m| 26/26 [00:30<00:00,  1.05it/s]Epoch: 1/10. Loss: 0.9072: 100%|[36m██████████[0m| 26/26 [00:30<00:00,  1.18s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:04,  1.21it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:05,  1.19s/it] 43%|[33m████▎     [0m| 3/7 [00:04<00:06,  1.53s/it] 57%|[33m█████▋    [0m| 4/7 [00:05<00:04,  1.41s/it] 71%|[33m███████▏  [0m| 5/7 [00:06<00:02,  1.11s/it] 86%|[33m████████▌ [0m| 6/7 [00:06<00:01,  1.05s/it]100%|[33m██████████[0m| 7/7 [00:07<00:00,  1.23it/s]100%|[33m██████████[0m| 7/7 [00:07<00:00,  1.04s/it]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 2/10. Loss: 0.9451:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 2/10. Loss: 0.9451:   4%|[36m▍         [0m| 1/26 [00:00<00:20,  1.20it/s]Epoch: 2/10. Loss: 0.9680:   4%|[36m▍         [0m| 1/26 [00:03<00:20,  1.20it/s]Epoch: 2/10. Loss: 0.9680:   8%|[36m▊         [0m| 2/26 [00:03<00:45,  1.90s/it]Epoch: 2/10. Loss: 0.9108:   8%|[36m▊         [0m| 2/26 [00:04<00:45,  1.90s/it]Epoch: 2/10. Loss: 0.9108:  12%|[36m█▏        [0m| 3/26 [00:04<00:36,  1.57s/it]Epoch: 2/10. Loss: 0.9375:  12%|[36m█▏        [0m| 3/26 [00:05<00:36,  1.57s/it]Epoch: 2/10. Loss: 0.9375:  15%|[36m█▌        [0m| 4/26 [00:05<00:29,  1.33s/it]Epoch: 2/10. Loss: 1.0303:  15%|[36m█▌        [0m| 4/26 [00:07<00:29,  1.33s/it]Epoch: 2/10. Loss: 1.0303:  19%|[36m█▉        [0m| 5/26 [00:07<00:31,  1.52s/it]Epoch: 2/10. Loss: 0.9692:  19%|[36m█▉        [0m| 5/26 [00:09<00:31,  1.52s/it]Epoch: 2/10. Loss: 0.9692:  23%|[36m██▎       [0m| 6/26 [00:09<00:33,  1.68s/it]Epoch: 2/10. Loss: 1.0055:  23%|[36m██▎       [0m| 6/26 [00:11<00:33,  1.68s/it]Epoch: 2/10. Loss: 1.0055:  27%|[36m██▋       [0m| 7/26 [00:11<00:34,  1.84s/it]Epoch: 2/10. Loss: 0.9550:  27%|[36m██▋       [0m| 7/26 [00:12<00:34,  1.84s/it]Epoch: 2/10. Loss: 0.9550:  31%|[36m███       [0m| 8/26 [00:12<00:27,  1.51s/it]Epoch: 2/10. Loss: 0.9482:  31%|[36m███       [0m| 8/26 [00:13<00:27,  1.51s/it]Epoch: 2/10. Loss: 0.9482:  35%|[36m███▍      [0m| 9/26 [00:13<00:24,  1.47s/it]Epoch: 2/10. Loss: 0.9833:  35%|[36m███▍      [0m| 9/26 [00:14<00:24,  1.47s/it]Epoch: 2/10. Loss: 0.9833:  38%|[36m███▊      [0m| 10/26 [00:14<00:20,  1.30s/it]Epoch: 2/10. Loss: 0.9510:  38%|[36m███▊      [0m| 10/26 [00:15<00:20,  1.30s/it]Epoch: 2/10. Loss: 0.9510:  42%|[36m████▏     [0m| 11/26 [00:15<00:17,  1.16s/it]Epoch: 2/10. Loss: 1.0388:  42%|[36m████▏     [0m| 11/26 [00:16<00:17,  1.16s/it]Epoch: 2/10. Loss: 1.0388:  46%|[36m████▌     [0m| 12/26 [00:16<00:14,  1.05s/it]Epoch: 2/10. Loss: 1.0679:  46%|[36m████▌     [0m| 12/26 [00:17<00:14,  1.05s/it]Epoch: 2/10. Loss: 1.0679:  50%|[36m█████     [0m| 13/26 [00:18<00:15,  1.22s/it]Epoch: 2/10. Loss: 0.9756:  50%|[36m█████     [0m| 13/26 [00:21<00:15,  1.22s/it]Epoch: 2/10. Loss: 0.9756:  54%|[36m█████▍    [0m| 14/26 [00:21<00:21,  1.83s/it]Epoch: 2/10. Loss: 0.8707:  54%|[36m█████▍    [0m| 14/26 [00:22<00:21,  1.83s/it]Epoch: 2/10. Loss: 0.8707:  58%|[36m█████▊    [0m| 15/26 [00:22<00:16,  1.53s/it]Epoch: 2/10. Loss: 0.9376:  58%|[36m█████▊    [0m| 15/26 [00:22<00:16,  1.53s/it]Epoch: 2/10. Loss: 0.9376:  62%|[36m██████▏   [0m| 16/26 [00:23<00:13,  1.35s/it]Epoch: 2/10. Loss: 0.9642:  62%|[36m██████▏   [0m| 16/26 [00:23<00:13,  1.35s/it]Epoch: 2/10. Loss: 0.9642:  65%|[36m██████▌   [0m| 17/26 [00:24<00:11,  1.25s/it]Epoch: 2/10. Loss: 0.9664:  65%|[36m██████▌   [0m| 17/26 [00:27<00:11,  1.25s/it]Epoch: 2/10. Loss: 0.9664:  69%|[36m██████▉   [0m| 18/26 [00:27<00:14,  1.80s/it]Epoch: 2/10. Loss: 0.8751:  69%|[36m██████▉   [0m| 18/26 [00:28<00:14,  1.80s/it]Epoch: 2/10. Loss: 0.8751:  73%|[36m███████▎  [0m| 19/26 [00:28<00:11,  1.63s/it]Epoch: 2/10. Loss: 0.9289:  73%|[36m███████▎  [0m| 19/26 [00:29<00:11,  1.63s/it]Epoch: 2/10. Loss: 0.9289:  77%|[36m███████▋  [0m| 20/26 [00:29<00:09,  1.52s/it]Epoch: 2/10. Loss: 0.9605:  77%|[36m███████▋  [0m| 20/26 [00:30<00:09,  1.52s/it]Epoch: 2/10. Loss: 0.9605:  81%|[36m████████  [0m| 21/26 [00:30<00:07,  1.45s/it]Epoch: 2/10. Loss: 0.9590:  81%|[36m████████  [0m| 21/26 [00:31<00:07,  1.45s/it]Epoch: 2/10. Loss: 0.9590:  85%|[36m████████▍ [0m| 22/26 [00:31<00:05,  1.27s/it]Epoch: 2/10. Loss: 0.8410:  85%|[36m████████▍ [0m| 22/26 [00:32<00:05,  1.27s/it]Epoch: 2/10. Loss: 0.8410:  88%|[36m████████▊ [0m| 23/26 [00:32<00:03,  1.17s/it]Epoch: 2/10. Loss: 0.9417:  88%|[36m████████▊ [0m| 23/26 [00:34<00:03,  1.17s/it]Epoch: 2/10. Loss: 0.9417:  92%|[36m█████████▏[0m| 24/26 [00:34<00:02,  1.28s/it]Epoch: 2/10. Loss: 0.9076:  92%|[36m█████████▏[0m| 24/26 [00:35<00:02,  1.28s/it]Epoch: 2/10. Loss: 0.9076:  96%|[36m█████████▌[0m| 25/26 [00:35<00:01,  1.26s/it]Epoch: 2/10. Loss: 0.8879:  96%|[36m█████████▌[0m| 25/26 [00:36<00:01,  1.26s/it]Epoch: 2/10. Loss: 0.8879: 100%|[36m██████████[0m| 26/26 [00:36<00:00,  1.07s/it]Epoch: 2/10. Loss: 0.8879: 100%|[36m██████████[0m| 26/26 [00:36<00:00,  1.39s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:04,  1.35it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:05,  1.07s/it] 43%|[33m████▎     [0m| 3/7 [00:02<00:03,  1.11it/s] 57%|[33m█████▋    [0m| 4/7 [00:03<00:03,  1.02s/it] 71%|[33m███████▏  [0m| 5/7 [00:04<00:01,  1.15it/s] 86%|[33m████████▌ [0m| 6/7 [00:05<00:00,  1.12it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.42it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.21it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 3/10. Loss: 0.9353:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 3/10. Loss: 0.9353:   4%|[36m▍         [0m| 1/26 [00:00<00:22,  1.09it/s]Epoch: 3/10. Loss: 0.9294:   4%|[36m▍         [0m| 1/26 [00:01<00:22,  1.09it/s]Epoch: 3/10. Loss: 0.9294:   8%|[36m▊         [0m| 2/26 [00:01<00:21,  1.13it/s]Epoch: 3/10. Loss: 0.8630:   8%|[36m▊         [0m| 2/26 [00:02<00:21,  1.13it/s]Epoch: 3/10. Loss: 0.8630:  12%|[36m█▏        [0m| 3/26 [00:02<00:22,  1.03it/s]Epoch: 3/10. Loss: 0.9397:  12%|[36m█▏        [0m| 3/26 [00:03<00:22,  1.03it/s]Epoch: 3/10. Loss: 0.9397:  15%|[36m█▌        [0m| 4/26 [00:03<00:21,  1.04it/s]Epoch: 3/10. Loss: 0.8868:  15%|[36m█▌        [0m| 4/26 [00:04<00:21,  1.04it/s]Epoch: 3/10. Loss: 0.8868:  19%|[36m█▉        [0m| 5/26 [00:04<00:19,  1.06it/s]Epoch: 3/10. Loss: 0.9634:  19%|[36m█▉        [0m| 5/26 [00:05<00:19,  1.06it/s]Epoch: 3/10. Loss: 0.9634:  23%|[36m██▎       [0m| 6/26 [00:05<00:20,  1.03s/it]Epoch: 3/10. Loss: 0.8611:  23%|[36m██▎       [0m| 6/26 [00:06<00:20,  1.03s/it]Epoch: 3/10. Loss: 0.8611:  27%|[36m██▋       [0m| 7/26 [00:06<00:18,  1.01it/s]Epoch: 3/10. Loss: 0.9480:  27%|[36m██▋       [0m| 7/26 [00:07<00:18,  1.01it/s]Epoch: 3/10. Loss: 0.9480:  31%|[36m███       [0m| 8/26 [00:07<00:16,  1.08it/s]Epoch: 3/10. Loss: 0.9741:  31%|[36m███       [0m| 8/26 [00:08<00:16,  1.08it/s]Epoch: 3/10. Loss: 0.9741:  35%|[36m███▍      [0m| 9/26 [00:08<00:16,  1.05it/s]Epoch: 3/10. Loss: 0.9173:  35%|[36m███▍      [0m| 9/26 [00:09<00:16,  1.05it/s]Epoch: 3/10. Loss: 0.9173:  38%|[36m███▊      [0m| 10/26 [00:09<00:15,  1.04it/s]Epoch: 3/10. Loss: 0.9049:  38%|[36m███▊      [0m| 10/26 [00:10<00:15,  1.04it/s]Epoch: 3/10. Loss: 0.9049:  42%|[36m████▏     [0m| 11/26 [00:10<00:14,  1.03it/s]Epoch: 3/10. Loss: 1.0188:  42%|[36m████▏     [0m| 11/26 [00:11<00:14,  1.03it/s]Epoch: 3/10. Loss: 1.0188:  46%|[36m████▌     [0m| 12/26 [00:11<00:13,  1.01it/s]Epoch: 3/10. Loss: 0.8790:  46%|[36m████▌     [0m| 12/26 [00:12<00:13,  1.01it/s]Epoch: 3/10. Loss: 0.8790:  50%|[36m█████     [0m| 13/26 [00:12<00:12,  1.00it/s]Epoch: 3/10. Loss: 0.9486:  50%|[36m█████     [0m| 13/26 [00:13<00:12,  1.00it/s]Epoch: 3/10. Loss: 0.9486:  54%|[36m█████▍    [0m| 14/26 [00:13<00:12,  1.03s/it]Epoch: 3/10. Loss: 0.8561:  54%|[36m█████▍    [0m| 14/26 [00:14<00:12,  1.03s/it]Epoch: 3/10. Loss: 0.8561:  58%|[36m█████▊    [0m| 15/26 [00:14<00:11,  1.00s/it]Epoch: 3/10. Loss: 0.9631:  58%|[36m█████▊    [0m| 15/26 [00:15<00:11,  1.00s/it]Epoch: 3/10. Loss: 0.9631:  62%|[36m██████▏   [0m| 16/26 [00:15<00:10,  1.00s/it]Epoch: 3/10. Loss: 0.9570:  62%|[36m██████▏   [0m| 16/26 [00:18<00:10,  1.00s/it]Epoch: 3/10. Loss: 0.9570:  65%|[36m██████▌   [0m| 17/26 [00:18<00:14,  1.59s/it]Epoch: 3/10. Loss: 0.8635:  65%|[36m██████▌   [0m| 17/26 [00:23<00:14,  1.59s/it]Epoch: 3/10. Loss: 0.8635:  69%|[36m██████▉   [0m| 18/26 [00:23<00:20,  2.53s/it]Epoch: 3/10. Loss: 0.8428:  69%|[36m██████▉   [0m| 18/26 [00:24<00:20,  2.53s/it]Epoch: 3/10. Loss: 0.8428:  73%|[36m███████▎  [0m| 19/26 [00:24<00:14,  2.05s/it]Epoch: 3/10. Loss: 0.9246:  73%|[36m███████▎  [0m| 19/26 [00:25<00:14,  2.05s/it]Epoch: 3/10. Loss: 0.9246:  77%|[36m███████▋  [0m| 20/26 [00:25<00:11,  1.94s/it]Epoch: 3/10. Loss: 1.0035:  77%|[36m███████▋  [0m| 20/26 [00:26<00:11,  1.94s/it]Epoch: 3/10. Loss: 1.0035:  81%|[36m████████  [0m| 21/26 [00:26<00:08,  1.62s/it]Epoch: 3/10. Loss: 0.8789:  81%|[36m████████  [0m| 21/26 [00:27<00:08,  1.62s/it]Epoch: 3/10. Loss: 0.8789:  85%|[36m████████▍ [0m| 22/26 [00:27<00:05,  1.42s/it]Epoch: 3/10. Loss: 0.8457:  85%|[36m████████▍ [0m| 22/26 [00:28<00:05,  1.42s/it]Epoch: 3/10. Loss: 0.8457:  88%|[36m████████▊ [0m| 23/26 [00:28<00:03,  1.29s/it]Epoch: 3/10. Loss: 0.8894:  88%|[36m████████▊ [0m| 23/26 [00:29<00:03,  1.29s/it]Epoch: 3/10. Loss: 0.8894:  92%|[36m█████████▏[0m| 24/26 [00:29<00:02,  1.19s/it]Epoch: 3/10. Loss: 0.8528:  92%|[36m█████████▏[0m| 24/26 [00:30<00:02,  1.19s/it]Epoch: 3/10. Loss: 0.8528:  96%|[36m█████████▌[0m| 25/26 [00:30<00:01,  1.12s/it]Epoch: 3/10. Loss: 0.8508:  96%|[36m█████████▌[0m| 25/26 [00:31<00:01,  1.12s/it]Epoch: 3/10. Loss: 0.8508: 100%|[36m██████████[0m| 26/26 [00:31<00:00,  1.00it/s]Epoch: 3/10. Loss: 0.8508: 100%|[36m██████████[0m| 26/26 [00:31<00:00,  1.21s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:04,  1.34it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:05,  1.09s/it] 43%|[33m████▎     [0m| 3/7 [00:02<00:03,  1.11it/s] 57%|[33m█████▋    [0m| 4/7 [00:04<00:03,  1.14s/it] 71%|[33m███████▏  [0m| 5/7 [00:04<00:01,  1.07it/s] 86%|[33m████████▌ [0m| 6/7 [00:05<00:00,  1.07it/s]100%|[33m██████████[0m| 7/7 [00:06<00:00,  1.36it/s]100%|[33m██████████[0m| 7/7 [00:06<00:00,  1.15it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 4/10. Loss: 0.9265:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 4/10. Loss: 0.9265:   4%|[36m▍         [0m| 1/26 [00:01<00:25,  1.01s/it]Epoch: 4/10. Loss: 0.9436:   4%|[36m▍         [0m| 1/26 [00:02<00:25,  1.01s/it]Epoch: 4/10. Loss: 0.9436:   8%|[36m▊         [0m| 2/26 [00:02<00:25,  1.07s/it]Epoch: 4/10. Loss: 0.8672:   8%|[36m▊         [0m| 2/26 [00:03<00:25,  1.07s/it]Epoch: 4/10. Loss: 0.8672:  12%|[36m█▏        [0m| 3/26 [00:03<00:24,  1.08s/it]Epoch: 4/10. Loss: 0.8898:  12%|[36m█▏        [0m| 3/26 [00:04<00:24,  1.08s/it]Epoch: 4/10. Loss: 0.8898:  15%|[36m█▌        [0m| 4/26 [00:04<00:24,  1.13s/it]Epoch: 4/10. Loss: 0.8401:  15%|[36m█▌        [0m| 4/26 [00:07<00:24,  1.13s/it]Epoch: 4/10. Loss: 0.8401:  19%|[36m█▉        [0m| 5/26 [00:07<00:36,  1.73s/it]Epoch: 4/10. Loss: 0.7501:  19%|[36m█▉        [0m| 5/26 [00:08<00:36,  1.73s/it]Epoch: 4/10. Loss: 0.7501:  23%|[36m██▎       [0m| 6/26 [00:08<00:31,  1.57s/it]Epoch: 4/10. Loss: 0.9179:  23%|[36m██▎       [0m| 6/26 [00:09<00:31,  1.57s/it]Epoch: 4/10. Loss: 0.9179:  27%|[36m██▋       [0m| 7/26 [00:09<00:28,  1.51s/it]Epoch: 4/10. Loss: 0.9740:  27%|[36m██▋       [0m| 7/26 [00:11<00:28,  1.51s/it]Epoch: 4/10. Loss: 0.9740:  31%|[36m███       [0m| 8/26 [00:11<00:26,  1.47s/it]Epoch: 4/10. Loss: 0.9678:  31%|[36m███       [0m| 8/26 [00:12<00:26,  1.47s/it]Epoch: 4/10. Loss: 0.9678:  35%|[36m███▍      [0m| 9/26 [00:12<00:21,  1.27s/it]Epoch: 4/10. Loss: 0.9406:  35%|[36m███▍      [0m| 9/26 [00:12<00:21,  1.27s/it]Epoch: 4/10. Loss: 0.9406:  38%|[36m███▊      [0m| 10/26 [00:12<00:17,  1.11s/it]Epoch: 4/10. Loss: 0.9823:  38%|[36m███▊      [0m| 10/26 [00:14<00:17,  1.11s/it]Epoch: 4/10. Loss: 0.9823:  42%|[36m████▏     [0m| 11/26 [00:14<00:18,  1.24s/it]Epoch: 4/10. Loss: 0.9503:  42%|[36m████▏     [0m| 11/26 [00:15<00:18,  1.24s/it]Epoch: 4/10. Loss: 0.9503:  46%|[36m████▌     [0m| 12/26 [00:15<00:15,  1.12s/it]Epoch: 4/10. Loss: 0.8919:  46%|[36m████▌     [0m| 12/26 [00:15<00:15,  1.12s/it]Epoch: 4/10. Loss: 0.8919:  50%|[36m█████     [0m| 13/26 [00:16<00:13,  1.02s/it]Epoch: 4/10. Loss: 0.8161:  50%|[36m█████     [0m| 13/26 [00:17<00:13,  1.02s/it]Epoch: 4/10. Loss: 0.8161:  54%|[36m█████▍    [0m| 14/26 [00:17<00:12,  1.07s/it]Epoch: 4/10. Loss: 0.8715:  54%|[36m█████▍    [0m| 14/26 [00:17<00:12,  1.07s/it]Epoch: 4/10. Loss: 0.8715:  58%|[36m█████▊    [0m| 15/26 [00:18<00:10,  1.00it/s]Epoch: 4/10. Loss: 0.9444:  58%|[36m█████▊    [0m| 15/26 [00:19<00:10,  1.00it/s]Epoch: 4/10. Loss: 0.9444:  62%|[36m██████▏   [0m| 16/26 [00:19<00:12,  1.22s/it]Epoch: 4/10. Loss: 0.7939:  62%|[36m██████▏   [0m| 16/26 [00:20<00:12,  1.22s/it]Epoch: 4/10. Loss: 0.7939:  65%|[36m██████▌   [0m| 17/26 [00:20<00:09,  1.11s/it]Epoch: 4/10. Loss: 0.8765:  65%|[36m██████▌   [0m| 17/26 [00:21<00:09,  1.11s/it]Epoch: 4/10. Loss: 0.8765:  69%|[36m██████▉   [0m| 18/26 [00:21<00:09,  1.13s/it]Epoch: 4/10. Loss: 0.8736:  69%|[36m██████▉   [0m| 18/26 [00:22<00:09,  1.13s/it]Epoch: 4/10. Loss: 0.8736:  73%|[36m███████▎  [0m| 19/26 [00:22<00:07,  1.09s/it]Epoch: 4/10. Loss: 0.8269:  73%|[36m███████▎  [0m| 19/26 [00:23<00:07,  1.09s/it]Epoch: 4/10. Loss: 0.8269:  77%|[36m███████▋  [0m| 20/26 [00:23<00:06,  1.00s/it]Epoch: 4/10. Loss: 0.8053:  77%|[36m███████▋  [0m| 20/26 [00:24<00:06,  1.00s/it]Epoch: 4/10. Loss: 0.8053:  81%|[36m████████  [0m| 21/26 [00:24<00:05,  1.01s/it]Epoch: 4/10. Loss: 0.8564:  81%|[36m████████  [0m| 21/26 [00:25<00:05,  1.01s/it]Epoch: 4/10. Loss: 0.8564:  85%|[36m████████▍ [0m| 22/26 [00:25<00:04,  1.08s/it]Epoch: 4/10. Loss: 1.0353:  85%|[36m████████▍ [0m| 22/26 [00:26<00:04,  1.08s/it]Epoch: 4/10. Loss: 1.0353:  88%|[36m████████▊ [0m| 23/26 [00:26<00:03,  1.05s/it]Epoch: 4/10. Loss: 0.9078:  88%|[36m████████▊ [0m| 23/26 [00:30<00:03,  1.05s/it]Epoch: 4/10. Loss: 0.9078:  92%|[36m█████████▏[0m| 24/26 [00:30<00:03,  1.73s/it]Epoch: 4/10. Loss: 0.9091:  92%|[36m█████████▏[0m| 24/26 [00:31<00:03,  1.73s/it]Epoch: 4/10. Loss: 0.9091:  96%|[36m█████████▌[0m| 25/26 [00:31<00:01,  1.53s/it]Epoch: 4/10. Loss: 0.9249:  96%|[36m█████████▌[0m| 25/26 [00:31<00:01,  1.53s/it]Epoch: 4/10. Loss: 0.9249: 100%|[36m██████████[0m| 26/26 [00:31<00:00,  1.31s/it]Epoch: 4/10. Loss: 0.9249: 100%|[36m██████████[0m| 26/26 [00:31<00:00,  1.23s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:04,  1.30it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:05,  1.12s/it] 43%|[33m████▎     [0m| 3/7 [00:03<00:05,  1.27s/it] 57%|[33m█████▋    [0m| 4/7 [00:06<00:05,  1.87s/it] 71%|[33m███████▏  [0m| 5/7 [00:06<00:02,  1.40s/it] 86%|[33m████████▌ [0m| 6/7 [00:07<00:01,  1.24s/it]100%|[33m██████████[0m| 7/7 [00:08<00:00,  1.06it/s]100%|[33m██████████[0m| 7/7 [00:08<00:00,  1.17s/it]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 5/10. Loss: 0.8708:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 5/10. Loss: 0.8708:   4%|[36m▍         [0m| 1/26 [00:00<00:24,  1.02it/s]Epoch: 5/10. Loss: 0.9313:   4%|[36m▍         [0m| 1/26 [00:01<00:24,  1.02it/s]Epoch: 5/10. Loss: 0.9313:   8%|[36m▊         [0m| 2/26 [00:01<00:22,  1.08it/s]Epoch: 5/10. Loss: 0.9179:   8%|[36m▊         [0m| 2/26 [00:02<00:22,  1.08it/s]Epoch: 5/10. Loss: 0.9179:  12%|[36m█▏        [0m| 3/26 [00:02<00:20,  1.14it/s]Epoch: 5/10. Loss: 0.7610:  12%|[36m█▏        [0m| 3/26 [00:04<00:20,  1.14it/s]Epoch: 5/10. Loss: 0.7610:  15%|[36m█▌        [0m| 4/26 [00:04<00:27,  1.25s/it]Epoch: 5/10. Loss: 0.9055:  15%|[36m█▌        [0m| 4/26 [00:05<00:27,  1.25s/it]Epoch: 5/10. Loss: 0.9055:  19%|[36m█▉        [0m| 5/26 [00:05<00:23,  1.12s/it]Epoch: 5/10. Loss: 0.7688:  19%|[36m█▉        [0m| 5/26 [00:06<00:23,  1.12s/it]Epoch: 5/10. Loss: 0.7688:  23%|[36m██▎       [0m| 6/26 [00:06<00:22,  1.15s/it]Epoch: 5/10. Loss: 0.9399:  23%|[36m██▎       [0m| 6/26 [00:07<00:22,  1.15s/it]Epoch: 5/10. Loss: 0.9399:  27%|[36m██▋       [0m| 7/26 [00:07<00:19,  1.04s/it]Epoch: 5/10. Loss: 0.8582:  27%|[36m██▋       [0m| 7/26 [00:08<00:19,  1.04s/it]Epoch: 5/10. Loss: 0.8582:  31%|[36m███       [0m| 8/26 [00:08<00:18,  1.01s/it]Epoch: 5/10. Loss: 0.8759:  31%|[36m███       [0m| 8/26 [00:09<00:18,  1.01s/it]Epoch: 5/10. Loss: 0.8759:  35%|[36m███▍      [0m| 9/26 [00:09<00:16,  1.05it/s]Epoch: 5/10. Loss: 0.9868:  35%|[36m███▍      [0m| 9/26 [00:10<00:16,  1.05it/s]Epoch: 5/10. Loss: 0.9868:  38%|[36m███▊      [0m| 10/26 [00:10<00:15,  1.00it/s]Epoch: 5/10. Loss: 0.8886:  38%|[36m███▊      [0m| 10/26 [00:11<00:15,  1.00it/s]Epoch: 5/10. Loss: 0.8886:  42%|[36m████▏     [0m| 11/26 [00:11<00:15,  1.00s/it]Epoch: 5/10. Loss: 0.9106:  42%|[36m████▏     [0m| 11/26 [00:12<00:15,  1.00s/it]Epoch: 5/10. Loss: 0.9106:  46%|[36m████▌     [0m| 12/26 [00:12<00:14,  1.01s/it]Epoch: 5/10. Loss: 0.9381:  46%|[36m████▌     [0m| 12/26 [00:13<00:14,  1.01s/it]Epoch: 5/10. Loss: 0.9381:  50%|[36m█████     [0m| 13/26 [00:13<00:12,  1.02it/s]Epoch: 5/10. Loss: 0.9350:  50%|[36m█████     [0m| 13/26 [00:14<00:12,  1.02it/s]Epoch: 5/10. Loss: 0.9350:  54%|[36m█████▍    [0m| 14/26 [00:14<00:11,  1.08it/s]Epoch: 5/10. Loss: 0.7570:  54%|[36m█████▍    [0m| 14/26 [00:15<00:11,  1.08it/s]Epoch: 5/10. Loss: 0.7570:  58%|[36m█████▊    [0m| 15/26 [00:15<00:10,  1.04it/s]Epoch: 5/10. Loss: 0.8671:  58%|[36m█████▊    [0m| 15/26 [00:17<00:10,  1.04it/s]Epoch: 5/10. Loss: 0.8671:  62%|[36m██████▏   [0m| 16/26 [00:17<00:14,  1.43s/it]Epoch: 5/10. Loss: 0.9451:  62%|[36m██████▏   [0m| 16/26 [00:18<00:14,  1.43s/it]Epoch: 5/10. Loss: 0.9451:  65%|[36m██████▌   [0m| 17/26 [00:18<00:12,  1.35s/it]Epoch: 5/10. Loss: 0.9093:  65%|[36m██████▌   [0m| 17/26 [00:19<00:12,  1.35s/it]Epoch: 5/10. Loss: 0.9093:  69%|[36m██████▉   [0m| 18/26 [00:19<00:09,  1.22s/it]Epoch: 5/10. Loss: 0.8747:  69%|[36m██████▉   [0m| 18/26 [00:20<00:09,  1.22s/it]Epoch: 5/10. Loss: 0.8747:  73%|[36m███████▎  [0m| 19/26 [00:20<00:08,  1.19s/it]Epoch: 5/10. Loss: 0.8851:  73%|[36m███████▎  [0m| 19/26 [00:23<00:08,  1.19s/it]Epoch: 5/10. Loss: 0.8851:  77%|[36m███████▋  [0m| 20/26 [00:23<00:10,  1.74s/it]Epoch: 5/10. Loss: 0.9951:  77%|[36m███████▋  [0m| 20/26 [00:25<00:10,  1.74s/it]Epoch: 5/10. Loss: 0.9951:  81%|[36m████████  [0m| 21/26 [00:25<00:07,  1.58s/it]Epoch: 5/10. Loss: 0.8926:  81%|[36m████████  [0m| 21/26 [00:25<00:07,  1.58s/it]Epoch: 5/10. Loss: 0.8926:  85%|[36m████████▍ [0m| 22/26 [00:25<00:05,  1.35s/it]Epoch: 5/10. Loss: 0.9010:  85%|[36m████████▍ [0m| 22/26 [00:26<00:05,  1.35s/it]Epoch: 5/10. Loss: 0.9010:  88%|[36m████████▊ [0m| 23/26 [00:26<00:03,  1.23s/it]Epoch: 5/10. Loss: 0.8739:  88%|[36m████████▊ [0m| 23/26 [00:27<00:03,  1.23s/it]Epoch: 5/10. Loss: 0.8739:  92%|[36m█████████▏[0m| 24/26 [00:27<00:02,  1.15s/it]Epoch: 5/10. Loss: 0.9751:  92%|[36m█████████▏[0m| 24/26 [00:28<00:02,  1.15s/it]Epoch: 5/10. Loss: 0.9751:  96%|[36m█████████▌[0m| 25/26 [00:28<00:01,  1.07s/it]Epoch: 5/10. Loss: 0.8652:  96%|[36m█████████▌[0m| 25/26 [00:29<00:01,  1.07s/it]Epoch: 5/10. Loss: 0.8652: 100%|[36m██████████[0m| 26/26 [00:29<00:00,  1.05it/s]Epoch: 5/10. Loss: 0.8652: 100%|[36m██████████[0m| 26/26 [00:29<00:00,  1.13s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:04,  1.35it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:05,  1.08s/it] 43%|[33m████▎     [0m| 3/7 [00:02<00:03,  1.13it/s] 57%|[33m█████▋    [0m| 4/7 [00:03<00:02,  1.01it/s] 71%|[33m███████▏  [0m| 5/7 [00:04<00:01,  1.18it/s] 86%|[33m████████▌ [0m| 6/7 [00:06<00:01,  1.14s/it]100%|[33m██████████[0m| 7/7 [00:06<00:00,  1.13it/s]100%|[33m██████████[0m| 7/7 [00:06<00:00,  1.07it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 6/10. Loss: 0.9869:   0%|[36m          [0m| 0/26 [00:01<?, ?it/s]Epoch: 6/10. Loss: 0.9869:   4%|[36m▍         [0m| 1/26 [00:01<00:28,  1.13s/it]Epoch: 6/10. Loss: 0.9715:   4%|[36m▍         [0m| 1/26 [00:02<00:28,  1.13s/it]Epoch: 6/10. Loss: 0.9715:   8%|[36m▊         [0m| 2/26 [00:02<00:27,  1.14s/it]Epoch: 6/10. Loss: 0.9319:   8%|[36m▊         [0m| 2/26 [00:03<00:27,  1.14s/it]Epoch: 6/10. Loss: 0.9319:  12%|[36m█▏        [0m| 3/26 [00:03<00:24,  1.07s/it]Epoch: 6/10. Loss: 0.9177:  12%|[36m█▏        [0m| 3/26 [00:04<00:24,  1.07s/it]Epoch: 6/10. Loss: 0.9177:  15%|[36m█▌        [0m| 4/26 [00:04<00:24,  1.11s/it]Epoch: 6/10. Loss: 0.8764:  15%|[36m█▌        [0m| 4/26 [00:05<00:24,  1.11s/it]Epoch: 6/10. Loss: 0.8764:  19%|[36m█▉        [0m| 5/26 [00:06<00:26,  1.28s/it]Epoch: 6/10. Loss: 0.8064:  19%|[36m█▉        [0m| 5/26 [00:06<00:26,  1.28s/it]Epoch: 6/10. Loss: 0.8064:  23%|[36m██▎       [0m| 6/26 [00:06<00:23,  1.15s/it]Epoch: 6/10. Loss: 0.7777:  23%|[36m██▎       [0m| 6/26 [00:07<00:23,  1.15s/it]Epoch: 6/10. Loss: 0.7777:  27%|[36m██▋       [0m| 7/26 [00:07<00:20,  1.06s/it]Epoch: 6/10. Loss: 1.0101:  27%|[36m██▋       [0m| 7/26 [00:08<00:20,  1.06s/it]Epoch: 6/10. Loss: 1.0101:  31%|[36m███       [0m| 8/26 [00:08<00:18,  1.01s/it]Epoch: 6/10. Loss: 0.9435:  31%|[36m███       [0m| 8/26 [00:10<00:18,  1.01s/it]Epoch: 6/10. Loss: 0.9435:  35%|[36m███▍      [0m| 9/26 [00:10<00:21,  1.25s/it]Epoch: 6/10. Loss: 0.8313:  35%|[36m███▍      [0m| 9/26 [00:11<00:21,  1.25s/it]Epoch: 6/10. Loss: 0.8313:  38%|[36m███▊      [0m| 10/26 [00:11<00:18,  1.16s/it]Epoch: 6/10. Loss: 0.8997:  38%|[36m███▊      [0m| 10/26 [00:12<00:18,  1.16s/it]Epoch: 6/10. Loss: 0.8997:  42%|[36m████▏     [0m| 11/26 [00:12<00:16,  1.07s/it]Epoch: 6/10. Loss: 0.8889:  42%|[36m████▏     [0m| 11/26 [00:13<00:16,  1.07s/it]Epoch: 6/10. Loss: 0.8889:  46%|[36m████▌     [0m| 12/26 [00:13<00:13,  1.01it/s]Epoch: 6/10. Loss: 0.8328:  46%|[36m████▌     [0m| 12/26 [00:14<00:13,  1.01it/s]Epoch: 6/10. Loss: 0.8328:  50%|[36m█████     [0m| 13/26 [00:14<00:12,  1.01it/s]Epoch: 6/10. Loss: 0.7259:  50%|[36m█████     [0m| 13/26 [00:14<00:12,  1.01it/s]Epoch: 6/10. Loss: 0.7259:  54%|[36m█████▍    [0m| 14/26 [00:14<00:10,  1.09it/s]Epoch: 6/10. Loss: 0.8390:  54%|[36m█████▍    [0m| 14/26 [00:16<00:10,  1.09it/s]Epoch: 6/10. Loss: 0.8390:  58%|[36m█████▊    [0m| 15/26 [00:16<00:11,  1.03s/it]Epoch: 6/10. Loss: 0.9007:  58%|[36m█████▊    [0m| 15/26 [00:16<00:11,  1.03s/it]Epoch: 6/10. Loss: 0.9007:  62%|[36m██████▏   [0m| 16/26 [00:16<00:09,  1.05it/s]Epoch: 6/10. Loss: 0.6997:  62%|[36m██████▏   [0m| 16/26 [00:17<00:09,  1.05it/s]Epoch: 6/10. Loss: 0.6997:  65%|[36m██████▌   [0m| 17/26 [00:17<00:08,  1.04it/s]Epoch: 6/10. Loss: 0.8466:  65%|[36m██████▌   [0m| 17/26 [00:18<00:08,  1.04it/s]Epoch: 6/10. Loss: 0.8466:  69%|[36m██████▉   [0m| 18/26 [00:18<00:07,  1.06it/s]Epoch: 6/10. Loss: 0.7621:  69%|[36m██████▉   [0m| 18/26 [00:19<00:07,  1.06it/s]Epoch: 6/10. Loss: 0.7621:  73%|[36m███████▎  [0m| 19/26 [00:19<00:06,  1.05it/s]Epoch: 6/10. Loss: 0.9687:  73%|[36m███████▎  [0m| 19/26 [00:20<00:06,  1.05it/s]Epoch: 6/10. Loss: 0.9687:  77%|[36m███████▋  [0m| 20/26 [00:20<00:05,  1.00it/s]Epoch: 6/10. Loss: 0.9881:  77%|[36m███████▋  [0m| 20/26 [00:21<00:05,  1.00it/s]Epoch: 6/10. Loss: 0.9881:  81%|[36m████████  [0m| 21/26 [00:21<00:04,  1.02it/s]Epoch: 6/10. Loss: 0.7529:  81%|[36m████████  [0m| 21/26 [00:22<00:04,  1.02it/s]Epoch: 6/10. Loss: 0.7529:  85%|[36m████████▍ [0m| 22/26 [00:22<00:03,  1.02it/s]Epoch: 6/10. Loss: 0.8808:  85%|[36m████████▍ [0m| 22/26 [00:25<00:03,  1.02it/s]Epoch: 6/10. Loss: 0.8808:  88%|[36m████████▊ [0m| 23/26 [00:25<00:04,  1.46s/it]Epoch: 6/10. Loss: 0.8718:  88%|[36m████████▊ [0m| 23/26 [00:26<00:04,  1.46s/it]Epoch: 6/10. Loss: 0.8718:  92%|[36m█████████▏[0m| 24/26 [00:26<00:02,  1.49s/it]Epoch: 6/10. Loss: 0.8592:  92%|[36m█████████▏[0m| 24/26 [00:28<00:02,  1.49s/it]Epoch: 6/10. Loss: 0.8592:  96%|[36m█████████▌[0m| 25/26 [00:28<00:01,  1.53s/it]Epoch: 6/10. Loss: 0.9803:  96%|[36m█████████▌[0m| 25/26 [00:29<00:01,  1.53s/it]Epoch: 6/10. Loss: 0.9803: 100%|[36m██████████[0m| 26/26 [00:29<00:00,  1.29s/it]Epoch: 6/10. Loss: 0.9803: 100%|[36m██████████[0m| 26/26 [00:29<00:00,  1.13s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:04,  1.33it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:05,  1.09s/it] 43%|[33m████▎     [0m| 3/7 [00:02<00:03,  1.12it/s] 57%|[33m█████▋    [0m| 4/7 [00:03<00:02,  1.01it/s] 71%|[33m███████▏  [0m| 5/7 [00:04<00:01,  1.18it/s] 86%|[33m████████▌ [0m| 6/7 [00:05<00:00,  1.06it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.34it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.18it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 7/10. Loss: 0.8073:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 7/10. Loss: 0.8073:   4%|[36m▍         [0m| 1/26 [00:00<00:20,  1.22it/s]Epoch: 7/10. Loss: 0.9137:   4%|[36m▍         [0m| 1/26 [00:01<00:20,  1.22it/s]Epoch: 7/10. Loss: 0.9137:   8%|[36m▊         [0m| 2/26 [00:01<00:19,  1.25it/s]Epoch: 7/10. Loss: 0.8520:   8%|[36m▊         [0m| 2/26 [00:02<00:19,  1.25it/s]Epoch: 7/10. Loss: 0.8520:  12%|[36m█▏        [0m| 3/26 [00:02<00:20,  1.11it/s]Epoch: 7/10. Loss: 0.7770:  12%|[36m█▏        [0m| 3/26 [00:03<00:20,  1.11it/s]Epoch: 7/10. Loss: 0.7770:  15%|[36m█▌        [0m| 4/26 [00:03<00:21,  1.04it/s]Epoch: 7/10. Loss: 0.9475:  15%|[36m█▌        [0m| 4/26 [00:04<00:21,  1.04it/s]Epoch: 7/10. Loss: 0.9475:  19%|[36m█▉        [0m| 5/26 [00:04<00:19,  1.07it/s]Epoch: 7/10. Loss: 0.9596:  19%|[36m█▉        [0m| 5/26 [00:05<00:19,  1.07it/s]Epoch: 7/10. Loss: 0.9596:  23%|[36m██▎       [0m| 6/26 [00:05<00:18,  1.08it/s]Epoch: 7/10. Loss: 0.9023:  23%|[36m██▎       [0m| 6/26 [00:06<00:18,  1.08it/s]Epoch: 7/10. Loss: 0.9023:  27%|[36m██▋       [0m| 7/26 [00:06<00:17,  1.06it/s]Epoch: 7/10. Loss: 0.9280:  27%|[36m██▋       [0m| 7/26 [00:07<00:17,  1.06it/s]Epoch: 7/10. Loss: 0.9280:  31%|[36m███       [0m| 8/26 [00:07<00:16,  1.11it/s]Epoch: 7/10. Loss: 1.0061:  31%|[36m███       [0m| 8/26 [00:08<00:16,  1.11it/s]Epoch: 7/10. Loss: 1.0061:  35%|[36m███▍      [0m| 9/26 [00:08<00:16,  1.01it/s]Epoch: 7/10. Loss: 0.8271:  35%|[36m███▍      [0m| 9/26 [00:09<00:16,  1.01it/s]Epoch: 7/10. Loss: 0.8271:  38%|[36m███▊      [0m| 10/26 [00:09<00:14,  1.08it/s]Epoch: 7/10. Loss: 0.8319:  38%|[36m███▊      [0m| 10/26 [00:10<00:14,  1.08it/s]Epoch: 7/10. Loss: 0.8319:  42%|[36m████▏     [0m| 11/26 [00:10<00:14,  1.04it/s]Epoch: 7/10. Loss: 0.9721:  42%|[36m████▏     [0m| 11/26 [00:11<00:14,  1.04it/s]Epoch: 7/10. Loss: 0.9721:  46%|[36m████▌     [0m| 12/26 [00:11<00:12,  1.08it/s]Epoch: 7/10. Loss: 0.9036:  46%|[36m████▌     [0m| 12/26 [00:12<00:12,  1.08it/s]Epoch: 7/10. Loss: 0.9036:  50%|[36m█████     [0m| 13/26 [00:12<00:12,  1.06it/s]Epoch: 7/10. Loss: 0.9114:  50%|[36m█████     [0m| 13/26 [00:13<00:12,  1.06it/s]Epoch: 7/10. Loss: 0.9114:  54%|[36m█████▍    [0m| 14/26 [00:13<00:11,  1.04it/s]Epoch: 7/10. Loss: 0.9006:  54%|[36m█████▍    [0m| 14/26 [00:13<00:11,  1.04it/s]Epoch: 7/10. Loss: 0.9006:  58%|[36m█████▊    [0m| 15/26 [00:13<00:10,  1.08it/s]Epoch: 7/10. Loss: 0.9150:  58%|[36m█████▊    [0m| 15/26 [00:15<00:10,  1.08it/s]Epoch: 7/10. Loss: 0.9150:  62%|[36m██████▏   [0m| 16/26 [00:15<00:11,  1.11s/it]Epoch: 7/10. Loss: 0.8046:  62%|[36m██████▏   [0m| 16/26 [00:16<00:11,  1.11s/it]Epoch: 7/10. Loss: 0.8046:  65%|[36m██████▌   [0m| 17/26 [00:16<00:09,  1.07s/it]Epoch: 7/10. Loss: 0.9370:  65%|[36m██████▌   [0m| 17/26 [00:17<00:09,  1.07s/it]Epoch: 7/10. Loss: 0.9370:  69%|[36m██████▉   [0m| 18/26 [00:17<00:08,  1.08s/it]Epoch: 7/10. Loss: 0.7999:  69%|[36m██████▉   [0m| 18/26 [00:18<00:08,  1.08s/it]Epoch: 7/10. Loss: 0.7999:  73%|[36m███████▎  [0m| 19/26 [00:18<00:07,  1.08s/it]Epoch: 7/10. Loss: 0.8240:  73%|[36m███████▎  [0m| 19/26 [00:19<00:07,  1.08s/it]Epoch: 7/10. Loss: 0.8240:  77%|[36m███████▋  [0m| 20/26 [00:19<00:06,  1.06s/it]Epoch: 7/10. Loss: 0.9005:  77%|[36m███████▋  [0m| 20/26 [00:20<00:06,  1.06s/it]Epoch: 7/10. Loss: 0.9005:  81%|[36m████████  [0m| 21/26 [00:20<00:05,  1.07s/it]Epoch: 7/10. Loss: 0.8783:  81%|[36m████████  [0m| 21/26 [00:21<00:05,  1.07s/it]Epoch: 7/10. Loss: 0.8783:  85%|[36m████████▍ [0m| 22/26 [00:22<00:04,  1.12s/it]Epoch: 7/10. Loss: 1.0005:  85%|[36m████████▍ [0m| 22/26 [00:23<00:04,  1.12s/it]Epoch: 7/10. Loss: 1.0005:  88%|[36m████████▊ [0m| 23/26 [00:23<00:03,  1.11s/it]Epoch: 7/10. Loss: 0.8372:  88%|[36m████████▊ [0m| 23/26 [00:24<00:03,  1.11s/it]Epoch: 7/10. Loss: 0.8372:  92%|[36m█████████▏[0m| 24/26 [00:24<00:02,  1.19s/it]Epoch: 7/10. Loss: 0.8734:  92%|[36m█████████▏[0m| 24/26 [00:25<00:02,  1.19s/it]Epoch: 7/10. Loss: 0.8734:  96%|[36m█████████▌[0m| 25/26 [00:25<00:01,  1.14s/it]Epoch: 7/10. Loss: 0.7805:  96%|[36m█████████▌[0m| 25/26 [00:26<00:01,  1.14s/it]Epoch: 7/10. Loss: 0.7805: 100%|[36m██████████[0m| 26/26 [00:26<00:00,  1.07s/it]Epoch: 7/10. Loss: 0.7805: 100%|[36m██████████[0m| 26/26 [00:26<00:00,  1.02s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:04,  1.21it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:05,  1.16s/it] 43%|[33m████▎     [0m| 3/7 [00:03<00:04,  1.20s/it] 57%|[33m█████▋    [0m| 4/7 [00:05<00:05,  1.69s/it] 71%|[33m███████▏  [0m| 5/7 [00:06<00:02,  1.29s/it] 86%|[33m████████▌ [0m| 6/7 [00:07<00:01,  1.17s/it]100%|[33m██████████[0m| 7/7 [00:07<00:00,  1.11it/s]100%|[33m██████████[0m| 7/7 [00:07<00:00,  1.11s/it]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 8/10. Loss: 0.8382:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 8/10. Loss: 0.8382:   4%|[36m▍         [0m| 1/26 [00:01<00:25,  1.00s/it]Epoch: 8/10. Loss: 0.9112:   4%|[36m▍         [0m| 1/26 [00:01<00:25,  1.00s/it]Epoch: 8/10. Loss: 0.9112:   8%|[36m▊         [0m| 2/26 [00:01<00:21,  1.11it/s]Epoch: 8/10. Loss: 0.8557:   8%|[36m▊         [0m| 2/26 [00:02<00:21,  1.11it/s]Epoch: 8/10. Loss: 0.8557:  12%|[36m█▏        [0m| 3/26 [00:02<00:21,  1.06it/s]Epoch: 8/10. Loss: 0.8528:  12%|[36m█▏        [0m| 3/26 [00:03<00:21,  1.06it/s]Epoch: 8/10. Loss: 0.8528:  15%|[36m█▌        [0m| 4/26 [00:03<00:20,  1.07it/s]Epoch: 8/10. Loss: 0.7674:  15%|[36m█▌        [0m| 4/26 [00:05<00:20,  1.07it/s]Epoch: 8/10. Loss: 0.7674:  19%|[36m█▉        [0m| 5/26 [00:05<00:27,  1.30s/it]Epoch: 8/10. Loss: 0.7971:  19%|[36m█▉        [0m| 5/26 [00:06<00:27,  1.30s/it]Epoch: 8/10. Loss: 0.7971:  23%|[36m██▎       [0m| 6/26 [00:06<00:25,  1.25s/it]Epoch: 8/10. Loss: 0.8389:  23%|[36m██▎       [0m| 6/26 [00:07<00:25,  1.25s/it]Epoch: 8/10. Loss: 0.8389:  27%|[36m██▋       [0m| 7/26 [00:07<00:21,  1.16s/it]Epoch: 8/10. Loss: 0.8332:  27%|[36m██▋       [0m| 7/26 [00:08<00:21,  1.16s/it]Epoch: 8/10. Loss: 0.8332:  31%|[36m███       [0m| 8/26 [00:08<00:19,  1.08s/it]Epoch: 8/10. Loss: 0.8516:  31%|[36m███       [0m| 8/26 [00:09<00:19,  1.08s/it]Epoch: 8/10. Loss: 0.8516:  35%|[36m███▍      [0m| 9/26 [00:09<00:18,  1.08s/it]Epoch: 8/10. Loss: 0.7884:  35%|[36m███▍      [0m| 9/26 [00:11<00:18,  1.08s/it]Epoch: 8/10. Loss: 0.7884:  38%|[36m███▊      [0m| 10/26 [00:11<00:21,  1.35s/it]Epoch: 8/10. Loss: 0.7747:  38%|[36m███▊      [0m| 10/26 [00:12<00:21,  1.35s/it]Epoch: 8/10. Loss: 0.7747:  42%|[36m████▏     [0m| 11/26 [00:12<00:18,  1.21s/it]Epoch: 8/10. Loss: 0.7227:  42%|[36m████▏     [0m| 11/26 [00:13<00:18,  1.21s/it]Epoch: 8/10. Loss: 0.7227:  46%|[36m████▌     [0m| 12/26 [00:13<00:15,  1.12s/it]Epoch: 8/10. Loss: 0.8379:  46%|[36m████▌     [0m| 12/26 [00:14<00:15,  1.12s/it]Epoch: 8/10. Loss: 0.8379:  50%|[36m█████     [0m| 13/26 [00:14<00:14,  1.09s/it]Epoch: 8/10. Loss: 0.8825:  50%|[36m█████     [0m| 13/26 [00:15<00:14,  1.09s/it]Epoch: 8/10. Loss: 0.8825:  54%|[36m█████▍    [0m| 14/26 [00:15<00:12,  1.03s/it]Epoch: 8/10. Loss: 0.7713:  54%|[36m█████▍    [0m| 14/26 [00:16<00:12,  1.03s/it]Epoch: 8/10. Loss: 0.7713:  58%|[36m█████▊    [0m| 15/26 [00:16<00:11,  1.03s/it]Epoch: 8/10. Loss: 0.8551:  58%|[36m█████▊    [0m| 15/26 [00:18<00:11,  1.03s/it]Epoch: 8/10. Loss: 0.8551:  62%|[36m██████▏   [0m| 16/26 [00:18<00:14,  1.44s/it]Epoch: 8/10. Loss: 0.7628:  62%|[36m██████▏   [0m| 16/26 [00:21<00:14,  1.44s/it]Epoch: 8/10. Loss: 0.7628:  65%|[36m██████▌   [0m| 17/26 [00:21<00:15,  1.70s/it]Epoch: 8/10. Loss: 0.8158:  65%|[36m██████▌   [0m| 17/26 [00:22<00:15,  1.70s/it]Epoch: 8/10. Loss: 0.8158:  69%|[36m██████▉   [0m| 18/26 [00:22<00:11,  1.45s/it]Epoch: 8/10. Loss: 0.7825:  69%|[36m██████▉   [0m| 18/26 [00:22<00:11,  1.45s/it]Epoch: 8/10. Loss: 0.7825:  73%|[36m███████▎  [0m| 19/26 [00:23<00:09,  1.30s/it]Epoch: 8/10. Loss: 0.9635:  73%|[36m███████▎  [0m| 19/26 [00:24<00:09,  1.30s/it]Epoch: 8/10. Loss: 0.9635:  77%|[36m███████▋  [0m| 20/26 [00:24<00:07,  1.23s/it]Epoch: 8/10. Loss: 0.9145:  77%|[36m███████▋  [0m| 20/26 [00:24<00:07,  1.23s/it]Epoch: 8/10. Loss: 0.9145:  81%|[36m████████  [0m| 21/26 [00:24<00:05,  1.11s/it]Epoch: 8/10. Loss: 0.9042:  81%|[36m████████  [0m| 21/26 [00:25<00:05,  1.11s/it]Epoch: 8/10. Loss: 0.9042:  85%|[36m████████▍ [0m| 22/26 [00:25<00:04,  1.06s/it]Epoch: 8/10. Loss: 0.8196:  85%|[36m████████▍ [0m| 22/26 [00:27<00:04,  1.06s/it]Epoch: 8/10. Loss: 0.8196:  88%|[36m████████▊ [0m| 23/26 [00:27<00:03,  1.14s/it]Epoch: 8/10. Loss: 0.8346:  88%|[36m████████▊ [0m| 23/26 [00:28<00:03,  1.14s/it]Epoch: 8/10. Loss: 0.8346:  92%|[36m█████████▏[0m| 24/26 [00:28<00:02,  1.09s/it]Epoch: 8/10. Loss: 0.8027:  92%|[36m█████████▏[0m| 24/26 [00:29<00:02,  1.09s/it]Epoch: 8/10. Loss: 0.8027:  96%|[36m█████████▌[0m| 25/26 [00:29<00:01,  1.09s/it]Epoch: 8/10. Loss: 0.7551:  96%|[36m█████████▌[0m| 25/26 [00:29<00:01,  1.09s/it]Epoch: 8/10. Loss: 0.7551: 100%|[36m██████████[0m| 26/26 [00:29<00:00,  1.04it/s]Epoch: 8/10. Loss: 0.7551: 100%|[36m██████████[0m| 26/26 [00:29<00:00,  1.15s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:04,  1.29it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:05,  1.10s/it] 43%|[33m████▎     [0m| 3/7 [00:02<00:03,  1.07it/s] 57%|[33m█████▋    [0m| 4/7 [00:04<00:03,  1.16s/it] 71%|[33m███████▏  [0m| 5/7 [00:04<00:01,  1.06it/s] 86%|[33m████████▌ [0m| 6/7 [00:05<00:00,  1.08it/s]100%|[33m██████████[0m| 7/7 [00:06<00:00,  1.37it/s]100%|[33m██████████[0m| 7/7 [00:06<00:00,  1.14it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 9/10. Loss: 0.7808:   0%|[36m          [0m| 0/26 [00:01<?, ?it/s]Epoch: 9/10. Loss: 0.7808:   4%|[36m▍         [0m| 1/26 [00:01<00:36,  1.47s/it]Epoch: 9/10. Loss: 0.8063:   4%|[36m▍         [0m| 1/26 [00:02<00:36,  1.47s/it]Epoch: 9/10. Loss: 0.8063:   8%|[36m▊         [0m| 2/26 [00:02<00:25,  1.07s/it]Epoch: 9/10. Loss: 0.8132:   8%|[36m▊         [0m| 2/26 [00:03<00:25,  1.07s/it]Epoch: 9/10. Loss: 0.8132:  12%|[36m█▏        [0m| 3/26 [00:03<00:23,  1.02s/it]Epoch: 9/10. Loss: 0.7621:  12%|[36m█▏        [0m| 3/26 [00:04<00:23,  1.02s/it]Epoch: 9/10. Loss: 0.7621:  15%|[36m█▌        [0m| 4/26 [00:04<00:20,  1.06it/s]Epoch: 9/10. Loss: 0.8202:  15%|[36m█▌        [0m| 4/26 [00:04<00:20,  1.06it/s]Epoch: 9/10. Loss: 0.8202:  19%|[36m█▉        [0m| 5/26 [00:05<00:20,  1.04it/s]Epoch: 9/10. Loss: 0.8779:  19%|[36m█▉        [0m| 5/26 [00:05<00:20,  1.04it/s]Epoch: 9/10. Loss: 0.8779:  23%|[36m██▎       [0m| 6/26 [00:05<00:19,  1.05it/s]Epoch: 9/10. Loss: 0.8211:  23%|[36m██▎       [0m| 6/26 [00:06<00:19,  1.05it/s]Epoch: 9/10. Loss: 0.8211:  27%|[36m██▋       [0m| 7/26 [00:06<00:18,  1.03it/s]Epoch: 9/10. Loss: 0.7564:  27%|[36m██▋       [0m| 7/26 [00:07<00:18,  1.03it/s]Epoch: 9/10. Loss: 0.7564:  31%|[36m███       [0m| 8/26 [00:07<00:17,  1.06it/s]Epoch: 9/10. Loss: 0.7501:  31%|[36m███       [0m| 8/26 [00:08<00:17,  1.06it/s]Epoch: 9/10. Loss: 0.7501:  35%|[36m███▍      [0m| 9/26 [00:08<00:14,  1.15it/s]Epoch: 9/10. Loss: 0.7568:  35%|[36m███▍      [0m| 9/26 [00:11<00:14,  1.15it/s]Epoch: 9/10. Loss: 0.7568:  38%|[36m███▊      [0m| 10/26 [00:11<00:21,  1.36s/it]Epoch: 9/10. Loss: 0.9086:  38%|[36m███▊      [0m| 10/26 [00:11<00:21,  1.36s/it]Epoch: 9/10. Loss: 0.9086:  42%|[36m████▏     [0m| 11/26 [00:12<00:18,  1.24s/it]Epoch: 9/10. Loss: 0.8833:  42%|[36m████▏     [0m| 11/26 [00:13<00:18,  1.24s/it]Epoch: 9/10. Loss: 0.8833:  46%|[36m████▌     [0m| 12/26 [00:13<00:16,  1.20s/it]Epoch: 9/10. Loss: 0.8375:  46%|[36m████▌     [0m| 12/26 [00:14<00:16,  1.20s/it]Epoch: 9/10. Loss: 0.8375:  50%|[36m█████     [0m| 13/26 [00:14<00:14,  1.15s/it]Epoch: 9/10. Loss: 0.8111:  50%|[36m█████     [0m| 13/26 [00:15<00:14,  1.15s/it]Epoch: 9/10. Loss: 0.8111:  54%|[36m█████▍    [0m| 14/26 [00:15<00:13,  1.10s/it]Epoch: 9/10. Loss: 0.8900:  54%|[36m█████▍    [0m| 14/26 [00:16<00:13,  1.10s/it]Epoch: 9/10. Loss: 0.8900:  58%|[36m█████▊    [0m| 15/26 [00:16<00:11,  1.08s/it]Epoch: 9/10. Loss: 0.8839:  58%|[36m█████▊    [0m| 15/26 [00:17<00:11,  1.08s/it]Epoch: 9/10. Loss: 0.8839:  62%|[36m██████▏   [0m| 16/26 [00:17<00:10,  1.08s/it]Epoch: 9/10. Loss: 0.8314:  62%|[36m██████▏   [0m| 16/26 [00:18<00:10,  1.08s/it]Epoch: 9/10. Loss: 0.8314:  65%|[36m██████▌   [0m| 17/26 [00:18<00:09,  1.05s/it]Epoch: 9/10. Loss: 0.7633:  65%|[36m██████▌   [0m| 17/26 [00:19<00:09,  1.05s/it]Epoch: 9/10. Loss: 0.7633:  69%|[36m██████▉   [0m| 18/26 [00:19<00:08,  1.03s/it]Epoch: 9/10. Loss: 0.8354:  69%|[36m██████▉   [0m| 18/26 [00:20<00:08,  1.03s/it]Epoch: 9/10. Loss: 0.8354:  73%|[36m███████▎  [0m| 19/26 [00:20<00:07,  1.03s/it]Epoch: 9/10. Loss: 0.9202:  73%|[36m███████▎  [0m| 19/26 [00:21<00:07,  1.03s/it]Epoch: 9/10. Loss: 0.9202:  77%|[36m███████▋  [0m| 20/26 [00:21<00:07,  1.22s/it]Epoch: 9/10. Loss: 0.7975:  77%|[36m███████▋  [0m| 20/26 [00:22<00:07,  1.22s/it]Epoch: 9/10. Loss: 0.7975:  81%|[36m████████  [0m| 21/26 [00:22<00:05,  1.16s/it]Epoch: 9/10. Loss: 0.9267:  81%|[36m████████  [0m| 21/26 [00:23<00:05,  1.16s/it]Epoch: 9/10. Loss: 0.9267:  85%|[36m████████▍ [0m| 22/26 [00:23<00:04,  1.12s/it]Epoch: 9/10. Loss: 0.7658:  85%|[36m████████▍ [0m| 22/26 [00:24<00:04,  1.12s/it]Epoch: 9/10. Loss: 0.7658:  88%|[36m████████▊ [0m| 23/26 [00:24<00:03,  1.08s/it]Epoch: 9/10. Loss: 0.8873:  88%|[36m████████▊ [0m| 23/26 [00:26<00:03,  1.08s/it]Epoch: 9/10. Loss: 0.8873:  92%|[36m█████████▏[0m| 24/26 [00:26<00:02,  1.32s/it]Epoch: 9/10. Loss: 0.8460:  92%|[36m█████████▏[0m| 24/26 [00:27<00:02,  1.32s/it]Epoch: 9/10. Loss: 0.8460:  96%|[36m█████████▌[0m| 25/26 [00:27<00:01,  1.19s/it]Epoch: 9/10. Loss: 0.8343:  96%|[36m█████████▌[0m| 25/26 [00:28<00:01,  1.19s/it]Epoch: 9/10. Loss: 0.8343: 100%|[36m██████████[0m| 26/26 [00:28<00:00,  1.01s/it]Epoch: 9/10. Loss: 0.8343: 100%|[36m██████████[0m| 26/26 [00:28<00:00,  1.09s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:04,  1.28it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:05,  1.10s/it] 43%|[33m████▎     [0m| 3/7 [00:04<00:05,  1.47s/it] 57%|[33m█████▋    [0m| 4/7 [00:05<00:04,  1.35s/it] 71%|[33m███████▏  [0m| 5/7 [00:05<00:02,  1.07s/it] 86%|[33m████████▌ [0m| 6/7 [00:06<00:01,  1.04s/it]100%|[33m██████████[0m| 7/7 [00:07<00:00,  1.24it/s]100%|[33m██████████[0m| 7/7 [00:07<00:00,  1.01s/it]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 0/10. Loss: 1.0964:   0%|[36m          [0m| 0/26 [00:01<?, ?it/s]Epoch: 0/10. Loss: 1.0964:   4%|[36m▍         [0m| 1/26 [00:01<00:29,  1.17s/it]Epoch: 0/10. Loss: 3.5332:   4%|[36m▍         [0m| 1/26 [00:02<00:29,  1.17s/it]Epoch: 0/10. Loss: 3.5332:   8%|[36m▊         [0m| 2/26 [00:02<00:24,  1.03s/it]Epoch: 0/10. Loss: 3.1345:   8%|[36m▊         [0m| 2/26 [00:02<00:24,  1.03s/it]Epoch: 0/10. Loss: 3.1345:  12%|[36m█▏        [0m| 3/26 [00:02<00:20,  1.11it/s]Epoch: 0/10. Loss: 2.1252:  12%|[36m█▏        [0m| 3/26 [00:03<00:20,  1.11it/s]Epoch: 0/10. Loss: 2.1252:  15%|[36m█▌        [0m| 4/26 [00:03<00:18,  1.17it/s]Epoch: 0/10. Loss: 1.4695:  15%|[36m█▌        [0m| 4/26 [00:04<00:18,  1.17it/s]Epoch: 0/10. Loss: 1.4695:  19%|[36m█▉        [0m| 5/26 [00:04<00:18,  1.14it/s]Epoch: 0/10. Loss: 1.4312:  19%|[36m█▉        [0m| 5/26 [00:05<00:18,  1.14it/s]Epoch: 0/10. Loss: 1.4312:  23%|[36m██▎       [0m| 6/26 [00:05<00:17,  1.11it/s]Epoch: 0/10. Loss: 1.4643:  23%|[36m██▎       [0m| 6/26 [00:06<00:17,  1.11it/s]Epoch: 0/10. Loss: 1.4643:  27%|[36m██▋       [0m| 7/26 [00:06<00:17,  1.11it/s]Epoch: 0/10. Loss: 1.4513:  27%|[36m██▋       [0m| 7/26 [00:07<00:17,  1.11it/s]Epoch: 0/10. Loss: 1.4513:  31%|[36m███       [0m| 8/26 [00:07<00:15,  1.14it/s]Epoch: 0/10. Loss: 1.4732:  31%|[36m███       [0m| 8/26 [00:08<00:15,  1.14it/s]Epoch: 0/10. Loss: 1.4732:  35%|[36m███▍      [0m| 9/26 [00:08<00:14,  1.14it/s]Epoch: 0/10. Loss: 1.4377:  35%|[36m███▍      [0m| 9/26 [00:08<00:14,  1.14it/s]Epoch: 0/10. Loss: 1.4377:  38%|[36m███▊      [0m| 10/26 [00:08<00:13,  1.16it/s]Epoch: 0/10. Loss: 1.2317:  38%|[36m███▊      [0m| 10/26 [00:09<00:13,  1.16it/s]Epoch: 0/10. Loss: 1.2317:  42%|[36m████▏     [0m| 11/26 [00:09<00:12,  1.18it/s]Epoch: 0/10. Loss: 1.2301:  42%|[36m████▏     [0m| 11/26 [00:10<00:12,  1.18it/s]Epoch: 0/10. Loss: 1.2301:  46%|[36m████▌     [0m| 12/26 [00:10<00:12,  1.14it/s]Epoch: 0/10. Loss: 1.1985:  46%|[36m████▌     [0m| 12/26 [00:11<00:12,  1.14it/s]Epoch: 0/10. Loss: 1.1985:  50%|[36m█████     [0m| 13/26 [00:11<00:12,  1.03it/s]Epoch: 0/10. Loss: 1.6062:  50%|[36m█████     [0m| 13/26 [00:12<00:12,  1.03it/s]Epoch: 0/10. Loss: 1.6062:  54%|[36m█████▍    [0m| 14/26 [00:12<00:11,  1.02it/s]Epoch: 0/10. Loss: 1.1788:  54%|[36m█████▍    [0m| 14/26 [00:13<00:11,  1.02it/s]Epoch: 0/10. Loss: 1.1788:  58%|[36m█████▊    [0m| 15/26 [00:13<00:10,  1.02it/s]Epoch: 0/10. Loss: 1.0648:  58%|[36m█████▊    [0m| 15/26 [00:14<00:10,  1.02it/s]Epoch: 0/10. Loss: 1.0648:  62%|[36m██████▏   [0m| 16/26 [00:14<00:09,  1.03it/s]Epoch: 0/10. Loss: 1.1886:  62%|[36m██████▏   [0m| 16/26 [00:15<00:09,  1.03it/s]Epoch: 0/10. Loss: 1.1886:  65%|[36m██████▌   [0m| 17/26 [00:15<00:08,  1.08it/s]Epoch: 0/10. Loss: 1.3332:  65%|[36m██████▌   [0m| 17/26 [00:16<00:08,  1.08it/s]Epoch: 0/10. Loss: 1.3332:  69%|[36m██████▉   [0m| 18/26 [00:16<00:07,  1.06it/s]Epoch: 0/10. Loss: 1.2041:  69%|[36m██████▉   [0m| 18/26 [00:17<00:07,  1.06it/s]Epoch: 0/10. Loss: 1.2041:  73%|[36m███████▎  [0m| 19/26 [00:17<00:06,  1.02it/s]Epoch: 0/10. Loss: 1.1262:  73%|[36m███████▎  [0m| 19/26 [00:19<00:06,  1.02it/s]Epoch: 0/10. Loss: 1.1262:  77%|[36m███████▋  [0m| 20/26 [00:19<00:06,  1.12s/it]Epoch: 0/10. Loss: 1.1175:  77%|[36m███████▋  [0m| 20/26 [00:20<00:06,  1.12s/it]Epoch: 0/10. Loss: 1.1175:  81%|[36m████████  [0m| 21/26 [00:20<00:05,  1.05s/it]Epoch: 0/10. Loss: 1.0074:  81%|[36m████████  [0m| 21/26 [00:21<00:05,  1.05s/it]Epoch: 0/10. Loss: 1.0074:  85%|[36m████████▍ [0m| 22/26 [00:21<00:04,  1.04s/it]Epoch: 0/10. Loss: 0.9980:  85%|[36m████████▍ [0m| 22/26 [00:21<00:04,  1.04s/it]Epoch: 0/10. Loss: 0.9980:  88%|[36m████████▊ [0m| 23/26 [00:21<00:02,  1.02it/s]Epoch: 0/10. Loss: 0.9893:  88%|[36m████████▊ [0m| 23/26 [00:22<00:02,  1.02it/s]Epoch: 0/10. Loss: 0.9893:  92%|[36m█████████▏[0m| 24/26 [00:22<00:01,  1.06it/s]Epoch: 0/10. Loss: 1.0677:  92%|[36m█████████▏[0m| 24/26 [00:23<00:01,  1.06it/s]Epoch: 0/10. Loss: 1.0677:  96%|[36m█████████▌[0m| 25/26 [00:23<00:00,  1.12it/s]Epoch: 0/10. Loss: 1.0577:  96%|[36m█████████▌[0m| 25/26 [00:24<00:00,  1.12it/s]Epoch: 0/10. Loss: 1.0577: 100%|[36m██████████[0m| 26/26 [00:24<00:00,  1.28it/s]Epoch: 0/10. Loss: 1.0577: 100%|[36m██████████[0m| 26/26 [00:24<00:00,  1.08it/s]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:04,  1.34it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:05,  1.07s/it] 43%|[33m████▎     [0m| 3/7 [00:02<00:03,  1.15it/s] 57%|[33m█████▋    [0m| 4/7 [00:04<00:03,  1.17s/it] 71%|[33m███████▏  [0m| 5/7 [00:04<00:01,  1.10it/s] 86%|[33m████████▌ [0m| 6/7 [00:05<00:00,  1.14it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.47it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.20it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 1/10. Loss: 0.9943:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 1/10. Loss: 0.9943:   4%|[36m▍         [0m| 1/26 [00:00<00:21,  1.15it/s]Epoch: 1/10. Loss: 1.0767:   4%|[36m▍         [0m| 1/26 [00:01<00:21,  1.15it/s]Epoch: 1/10. Loss: 1.0767:   8%|[36m▊         [0m| 2/26 [00:01<00:19,  1.23it/s]Epoch: 1/10. Loss: 1.0589:   8%|[36m▊         [0m| 2/26 [00:02<00:19,  1.23it/s]Epoch: 1/10. Loss: 1.0589:  12%|[36m█▏        [0m| 3/26 [00:02<00:19,  1.18it/s]Epoch: 1/10. Loss: 1.0537:  12%|[36m█▏        [0m| 3/26 [00:03<00:19,  1.18it/s]Epoch: 1/10. Loss: 1.0537:  15%|[36m█▌        [0m| 4/26 [00:03<00:19,  1.13it/s]Epoch: 1/10. Loss: 1.0287:  15%|[36m█▌        [0m| 4/26 [00:04<00:19,  1.13it/s]Epoch: 1/10. Loss: 1.0287:  19%|[36m█▉        [0m| 5/26 [00:04<00:18,  1.12it/s]Epoch: 1/10. Loss: 1.1582:  19%|[36m█▉        [0m| 5/26 [00:05<00:18,  1.12it/s]Epoch: 1/10. Loss: 1.1582:  23%|[36m██▎       [0m| 6/26 [00:05<00:17,  1.14it/s]Epoch: 1/10. Loss: 1.0320:  23%|[36m██▎       [0m| 6/26 [00:06<00:17,  1.14it/s]Epoch: 1/10. Loss: 1.0320:  27%|[36m██▋       [0m| 7/26 [00:06<00:18,  1.05it/s]Epoch: 1/10. Loss: 0.9832:  27%|[36m██▋       [0m| 7/26 [00:07<00:18,  1.05it/s]Epoch: 1/10. Loss: 0.9832:  31%|[36m███       [0m| 8/26 [00:07<00:17,  1.03it/s]Epoch: 1/10. Loss: 0.9847:  31%|[36m███       [0m| 8/26 [00:08<00:17,  1.03it/s]Epoch: 1/10. Loss: 0.9847:  35%|[36m███▍      [0m| 9/26 [00:08<00:16,  1.06it/s]Epoch: 1/10. Loss: 0.9946:  35%|[36m███▍      [0m| 9/26 [00:09<00:16,  1.06it/s]Epoch: 1/10. Loss: 0.9946:  38%|[36m███▊      [0m| 10/26 [00:09<00:15,  1.05it/s]Epoch: 1/10. Loss: 1.0676:  38%|[36m███▊      [0m| 10/26 [00:10<00:15,  1.05it/s]Epoch: 1/10. Loss: 1.0676:  42%|[36m████▏     [0m| 11/26 [00:10<00:14,  1.03it/s]Epoch: 1/10. Loss: 1.0459:  42%|[36m████▏     [0m| 11/26 [00:11<00:14,  1.03it/s]Epoch: 1/10. Loss: 1.0459:  46%|[36m████▌     [0m| 12/26 [00:11<00:14,  1.06s/it]Epoch: 1/10. Loss: 1.0029:  46%|[36m████▌     [0m| 12/26 [00:12<00:14,  1.06s/it]Epoch: 1/10. Loss: 1.0029:  50%|[36m█████     [0m| 13/26 [00:12<00:13,  1.03s/it]Epoch: 1/10. Loss: 1.0583:  50%|[36m█████     [0m| 13/26 [00:13<00:13,  1.03s/it]Epoch: 1/10. Loss: 1.0583:  54%|[36m█████▍    [0m| 14/26 [00:13<00:12,  1.02s/it]Epoch: 1/10. Loss: 1.0263:  54%|[36m█████▍    [0m| 14/26 [00:14<00:12,  1.02s/it]Epoch: 1/10. Loss: 1.0263:  58%|[36m█████▊    [0m| 15/26 [00:14<00:11,  1.03s/it]Epoch: 1/10. Loss: 1.0809:  58%|[36m█████▊    [0m| 15/26 [00:15<00:11,  1.03s/it]Epoch: 1/10. Loss: 1.0809:  62%|[36m██████▏   [0m| 16/26 [00:15<00:09,  1.03it/s]Epoch: 1/10. Loss: 0.9911:  62%|[36m██████▏   [0m| 16/26 [00:16<00:09,  1.03it/s]Epoch: 1/10. Loss: 0.9911:  65%|[36m██████▌   [0m| 17/26 [00:16<00:08,  1.05it/s]Epoch: 1/10. Loss: 1.0933:  65%|[36m██████▌   [0m| 17/26 [00:18<00:08,  1.05it/s]Epoch: 1/10. Loss: 1.0933:  69%|[36m██████▉   [0m| 18/26 [00:18<00:10,  1.27s/it]Epoch: 1/10. Loss: 1.0782:  69%|[36m██████▉   [0m| 18/26 [00:19<00:10,  1.27s/it]Epoch: 1/10. Loss: 1.0782:  73%|[36m███████▎  [0m| 19/26 [00:19<00:07,  1.13s/it]Epoch: 1/10. Loss: 1.0510:  73%|[36m███████▎  [0m| 19/26 [00:19<00:07,  1.13s/it]Epoch: 1/10. Loss: 1.0510:  77%|[36m███████▋  [0m| 20/26 [00:19<00:06,  1.04s/it]Epoch: 1/10. Loss: 1.1047:  77%|[36m███████▋  [0m| 20/26 [00:21<00:06,  1.04s/it]Epoch: 1/10. Loss: 1.1047:  81%|[36m████████  [0m| 21/26 [00:21<00:05,  1.07s/it]Epoch: 1/10. Loss: 1.0065:  81%|[36m████████  [0m| 21/26 [00:22<00:05,  1.07s/it]Epoch: 1/10. Loss: 1.0065:  85%|[36m████████▍ [0m| 22/26 [00:22<00:04,  1.05s/it]Epoch: 1/10. Loss: 0.9783:  85%|[36m████████▍ [0m| 22/26 [00:23<00:04,  1.05s/it]Epoch: 1/10. Loss: 0.9783:  88%|[36m████████▊ [0m| 23/26 [00:23<00:03,  1.09s/it]Epoch: 1/10. Loss: 0.9571:  88%|[36m████████▊ [0m| 23/26 [00:23<00:03,  1.09s/it]Epoch: 1/10. Loss: 0.9571:  92%|[36m█████████▏[0m| 24/26 [00:23<00:01,  1.00it/s]Epoch: 1/10. Loss: 1.0633:  92%|[36m█████████▏[0m| 24/26 [00:26<00:01,  1.00it/s]Epoch: 1/10. Loss: 1.0633:  96%|[36m█████████▌[0m| 25/26 [00:26<00:01,  1.47s/it]Epoch: 1/10. Loss: 0.9960:  96%|[36m█████████▌[0m| 25/26 [00:27<00:01,  1.47s/it]Epoch: 1/10. Loss: 0.9960: 100%|[36m██████████[0m| 26/26 [00:27<00:00,  1.22s/it]Epoch: 1/10. Loss: 0.9960: 100%|[36m██████████[0m| 26/26 [00:27<00:00,  1.05s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:01<00:06,  1.09s/it] 29%|[33m██▊       [0m| 2/7 [00:02<00:07,  1.55s/it] 43%|[33m████▎     [0m| 3/7 [00:03<00:04,  1.12s/it] 57%|[33m█████▋    [0m| 4/7 [00:04<00:03,  1.09s/it] 71%|[33m███████▏  [0m| 5/7 [00:05<00:01,  1.16it/s] 86%|[33m████████▌ [0m| 6/7 [00:05<00:00,  1.15it/s]100%|[33m██████████[0m| 7/7 [00:06<00:00,  1.48it/s]100%|[33m██████████[0m| 7/7 [00:06<00:00,  1.12it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 2/10. Loss: 1.0170:   0%|[36m          [0m| 0/26 [00:01<?, ?it/s]Epoch: 2/10. Loss: 1.0170:   4%|[36m▍         [0m| 1/26 [00:01<00:25,  1.03s/it]Epoch: 2/10. Loss: 0.9964:   4%|[36m▍         [0m| 1/26 [00:01<00:25,  1.03s/it]Epoch: 2/10. Loss: 0.9964:   8%|[36m▊         [0m| 2/26 [00:01<00:22,  1.06it/s]Epoch: 2/10. Loss: 0.9319:   8%|[36m▊         [0m| 2/26 [00:02<00:22,  1.06it/s]Epoch: 2/10. Loss: 0.9319:  12%|[36m█▏        [0m| 3/26 [00:02<00:21,  1.06it/s]Epoch: 2/10. Loss: 0.9369:  12%|[36m█▏        [0m| 3/26 [00:04<00:21,  1.06it/s]Epoch: 2/10. Loss: 0.9369:  15%|[36m█▌        [0m| 4/26 [00:04<00:29,  1.34s/it]Epoch: 2/10. Loss: 1.1183:  15%|[36m█▌        [0m| 4/26 [00:05<00:29,  1.34s/it]Epoch: 2/10. Loss: 1.1183:  19%|[36m█▉        [0m| 5/26 [00:05<00:26,  1.24s/it]Epoch: 2/10. Loss: 0.9576:  19%|[36m█▉        [0m| 5/26 [00:06<00:26,  1.24s/it]Epoch: 2/10. Loss: 0.9576:  23%|[36m██▎       [0m| 6/26 [00:06<00:23,  1.16s/it]Epoch: 2/10. Loss: 0.9659:  23%|[36m██▎       [0m| 6/26 [00:07<00:23,  1.16s/it]Epoch: 2/10. Loss: 0.9659:  27%|[36m██▋       [0m| 7/26 [00:07<00:19,  1.04s/it]Epoch: 2/10. Loss: 1.1287:  27%|[36m██▋       [0m| 7/26 [00:08<00:19,  1.04s/it]Epoch: 2/10. Loss: 1.1287:  31%|[36m███       [0m| 8/26 [00:08<00:17,  1.03it/s]Epoch: 2/10. Loss: 1.0189:  31%|[36m███       [0m| 8/26 [00:09<00:17,  1.03it/s]Epoch: 2/10. Loss: 1.0189:  35%|[36m███▍      [0m| 9/26 [00:09<00:16,  1.06it/s]Epoch: 2/10. Loss: 1.0211:  35%|[36m███▍      [0m| 9/26 [00:10<00:16,  1.06it/s]Epoch: 2/10. Loss: 1.0211:  38%|[36m███▊      [0m| 10/26 [00:10<00:15,  1.05it/s]Epoch: 2/10. Loss: 1.0445:  38%|[36m███▊      [0m| 10/26 [00:11<00:15,  1.05it/s]Epoch: 2/10. Loss: 1.0445:  42%|[36m████▏     [0m| 11/26 [00:11<00:14,  1.03it/s]Epoch: 2/10. Loss: 0.9972:  42%|[36m████▏     [0m| 11/26 [00:12<00:14,  1.03it/s]Epoch: 2/10. Loss: 0.9972:  46%|[36m████▌     [0m| 12/26 [00:12<00:12,  1.08it/s]Epoch: 2/10. Loss: 1.0422:  46%|[36m████▌     [0m| 12/26 [00:13<00:12,  1.08it/s]Epoch: 2/10. Loss: 1.0422:  50%|[36m█████     [0m| 13/26 [00:13<00:11,  1.10it/s]Epoch: 2/10. Loss: 1.0236:  50%|[36m█████     [0m| 13/26 [00:13<00:11,  1.10it/s]Epoch: 2/10. Loss: 1.0236:  54%|[36m█████▍    [0m| 14/26 [00:13<00:10,  1.15it/s]Epoch: 2/10. Loss: 1.0378:  54%|[36m█████▍    [0m| 14/26 [00:14<00:10,  1.15it/s]Epoch: 2/10. Loss: 1.0378:  58%|[36m█████▊    [0m| 15/26 [00:14<00:09,  1.13it/s]Epoch: 2/10. Loss: 1.0294:  58%|[36m█████▊    [0m| 15/26 [00:15<00:09,  1.13it/s]Epoch: 2/10. Loss: 1.0294:  62%|[36m██████▏   [0m| 16/26 [00:15<00:08,  1.16it/s]Epoch: 2/10. Loss: 1.0021:  62%|[36m██████▏   [0m| 16/26 [00:16<00:08,  1.16it/s]Epoch: 2/10. Loss: 1.0021:  65%|[36m██████▌   [0m| 17/26 [00:16<00:07,  1.19it/s]Epoch: 2/10. Loss: 1.0303:  65%|[36m██████▌   [0m| 17/26 [00:17<00:07,  1.19it/s]Epoch: 2/10. Loss: 1.0303:  69%|[36m██████▉   [0m| 18/26 [00:17<00:07,  1.09it/s]Epoch: 2/10. Loss: 0.9797:  69%|[36m██████▉   [0m| 18/26 [00:18<00:07,  1.09it/s]Epoch: 2/10. Loss: 0.9797:  73%|[36m███████▎  [0m| 19/26 [00:18<00:06,  1.01it/s]Epoch: 2/10. Loss: 1.0179:  73%|[36m███████▎  [0m| 19/26 [00:19<00:06,  1.01it/s]Epoch: 2/10. Loss: 1.0179:  77%|[36m███████▋  [0m| 20/26 [00:19<00:05,  1.02it/s]Epoch: 2/10. Loss: 0.9485:  77%|[36m███████▋  [0m| 20/26 [00:20<00:05,  1.02it/s]Epoch: 2/10. Loss: 0.9485:  81%|[36m████████  [0m| 21/26 [00:20<00:04,  1.01it/s]Epoch: 2/10. Loss: 1.0249:  81%|[36m████████  [0m| 21/26 [00:21<00:04,  1.01it/s]Epoch: 2/10. Loss: 1.0249:  85%|[36m████████▍ [0m| 22/26 [00:21<00:03,  1.07it/s]Epoch: 2/10. Loss: 0.9656:  85%|[36m████████▍ [0m| 22/26 [00:22<00:03,  1.07it/s]Epoch: 2/10. Loss: 0.9656:  88%|[36m████████▊ [0m| 23/26 [00:22<00:02,  1.08it/s]Epoch: 2/10. Loss: 0.9612:  88%|[36m████████▊ [0m| 23/26 [00:23<00:02,  1.08it/s]Epoch: 2/10. Loss: 0.9612:  92%|[36m█████████▏[0m| 24/26 [00:23<00:01,  1.11it/s]Epoch: 2/10. Loss: 0.9613:  92%|[36m█████████▏[0m| 24/26 [00:23<00:01,  1.11it/s]Epoch: 2/10. Loss: 0.9613:  96%|[36m█████████▌[0m| 25/26 [00:24<00:00,  1.12it/s]Epoch: 2/10. Loss: 1.0218:  96%|[36m█████████▌[0m| 25/26 [00:24<00:00,  1.12it/s]Epoch: 2/10. Loss: 1.0218: 100%|[36m██████████[0m| 26/26 [00:24<00:00,  1.24it/s]Epoch: 2/10. Loss: 1.0218: 100%|[36m██████████[0m| 26/26 [00:24<00:00,  1.06it/s]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:04,  1.44it/s] 29%|[33m██▊       [0m| 2/7 [00:01<00:05,  1.02s/it] 43%|[33m████▎     [0m| 3/7 [00:02<00:03,  1.21it/s] 57%|[33m█████▋    [0m| 4/7 [00:03<00:02,  1.10it/s] 71%|[33m███████▏  [0m| 5/7 [00:04<00:01,  1.34it/s] 86%|[33m████████▌ [0m| 6/7 [00:04<00:00,  1.31it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.65it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.37it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 3/10. Loss: 0.9579:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 3/10. Loss: 0.9579:   4%|[36m▍         [0m| 1/26 [00:00<00:24,  1.00it/s]Epoch: 3/10. Loss: 0.9449:   4%|[36m▍         [0m| 1/26 [00:01<00:24,  1.00it/s]Epoch: 3/10. Loss: 0.9449:   8%|[36m▊         [0m| 2/26 [00:01<00:21,  1.14it/s]Epoch: 3/10. Loss: 0.9353:   8%|[36m▊         [0m| 2/26 [00:02<00:21,  1.14it/s]Epoch: 3/10. Loss: 0.9353:  12%|[36m█▏        [0m| 3/26 [00:02<00:20,  1.12it/s]Epoch: 3/10. Loss: 1.0775:  12%|[36m█▏        [0m| 3/26 [00:03<00:20,  1.12it/s]Epoch: 3/10. Loss: 1.0775:  15%|[36m█▌        [0m| 4/26 [00:03<00:18,  1.19it/s]Epoch: 3/10. Loss: 1.0510:  15%|[36m█▌        [0m| 4/26 [00:04<00:18,  1.19it/s]Epoch: 3/10. Loss: 1.0510:  19%|[36m█▉        [0m| 5/26 [00:04<00:20,  1.01it/s]Epoch: 3/10. Loss: 0.9872:  19%|[36m█▉        [0m| 5/26 [00:05<00:20,  1.01it/s]Epoch: 3/10. Loss: 0.9872:  23%|[36m██▎       [0m| 6/26 [00:05<00:19,  1.02it/s]Epoch: 3/10. Loss: 0.9520:  23%|[36m██▎       [0m| 6/26 [00:06<00:19,  1.02it/s]Epoch: 3/10. Loss: 0.9520:  27%|[36m██▋       [0m| 7/26 [00:06<00:17,  1.08it/s]Epoch: 3/10. Loss: 1.0619:  27%|[36m██▋       [0m| 7/26 [00:07<00:17,  1.08it/s]Epoch: 3/10. Loss: 1.0619:  31%|[36m███       [0m| 8/26 [00:07<00:16,  1.09it/s]Epoch: 3/10. Loss: 0.9451:  31%|[36m███       [0m| 8/26 [00:08<00:16,  1.09it/s]Epoch: 3/10. Loss: 0.9451:  35%|[36m███▍      [0m| 9/26 [00:08<00:16,  1.02it/s]Epoch: 3/10. Loss: 0.9524:  35%|[36m███▍      [0m| 9/26 [00:09<00:16,  1.02it/s]Epoch: 3/10. Loss: 0.9524:  38%|[36m███▊      [0m| 10/26 [00:09<00:14,  1.07it/s]Epoch: 3/10. Loss: 1.0265:  38%|[36m███▊      [0m| 10/26 [00:10<00:14,  1.07it/s]Epoch: 3/10. Loss: 1.0265:  42%|[36m████▏     [0m| 11/26 [00:10<00:13,  1.11it/s]Epoch: 3/10. Loss: 0.9425:  42%|[36m████▏     [0m| 11/26 [00:10<00:13,  1.11it/s]Epoch: 3/10. Loss: 0.9425:  46%|[36m████▌     [0m| 12/26 [00:10<00:12,  1.15it/s]Epoch: 3/10. Loss: 0.9517:  46%|[36m████▌     [0m| 12/26 [00:11<00:12,  1.15it/s]Epoch: 3/10. Loss: 0.9517:  50%|[36m█████     [0m| 13/26 [00:11<00:10,  1.20it/s]Epoch: 3/10. Loss: 1.0215:  50%|[36m█████     [0m| 13/26 [00:12<00:10,  1.20it/s]Epoch: 3/10. Loss: 1.0215:  54%|[36m█████▍    [0m| 14/26 [00:12<00:10,  1.19it/s]Epoch: 3/10. Loss: 0.9877:  54%|[36m█████▍    [0m| 14/26 [00:13<00:10,  1.19it/s]Epoch: 3/10. Loss: 0.9877:  58%|[36m█████▊    [0m| 15/26 [00:13<00:10,  1.09it/s]Epoch: 3/10. Loss: 0.9781:  58%|[36m█████▊    [0m| 15/26 [00:14<00:10,  1.09it/s]Epoch: 3/10. Loss: 0.9781:  62%|[36m██████▏   [0m| 16/26 [00:14<00:09,  1.10it/s]Epoch: 3/10. Loss: 1.0762:  62%|[36m██████▏   [0m| 16/26 [00:15<00:09,  1.10it/s]Epoch: 3/10. Loss: 1.0762:  65%|[36m██████▌   [0m| 17/26 [00:15<00:08,  1.12it/s]Epoch: 3/10. Loss: 1.0007:  65%|[36m██████▌   [0m| 17/26 [00:16<00:08,  1.12it/s]Epoch: 3/10. Loss: 1.0007:  69%|[36m██████▉   [0m| 18/26 [00:16<00:07,  1.04it/s]Epoch: 3/10. Loss: 0.9647:  69%|[36m██████▉   [0m| 18/26 [00:17<00:07,  1.04it/s]Epoch: 3/10. Loss: 0.9647:  73%|[36m███████▎  [0m| 19/26 [00:17<00:06,  1.01it/s]Epoch: 3/10. Loss: 0.9967:  73%|[36m███████▎  [0m| 19/26 [00:18<00:06,  1.01it/s]Epoch: 3/10. Loss: 0.9967:  77%|[36m███████▋  [0m| 20/26 [00:18<00:06,  1.03s/it]Epoch: 3/10. Loss: 1.0202:  77%|[36m███████▋  [0m| 20/26 [00:21<00:06,  1.03s/it]Epoch: 3/10. Loss: 1.0202:  81%|[36m████████  [0m| 21/26 [00:21<00:07,  1.46s/it]Epoch: 3/10. Loss: 0.9929:  81%|[36m████████  [0m| 21/26 [00:22<00:07,  1.46s/it]Epoch: 3/10. Loss: 0.9929:  85%|[36m████████▍ [0m| 22/26 [00:22<00:05,  1.31s/it]Epoch: 3/10. Loss: 0.9873:  85%|[36m████████▍ [0m| 22/26 [00:23<00:05,  1.31s/it]Epoch: 3/10. Loss: 0.9873:  88%|[36m████████▊ [0m| 23/26 [00:23<00:03,  1.23s/it]Epoch: 3/10. Loss: 0.9867:  88%|[36m████████▊ [0m| 23/26 [00:24<00:03,  1.23s/it]Epoch: 3/10. Loss: 0.9867:  92%|[36m█████████▏[0m| 24/26 [00:24<00:02,  1.18s/it]Epoch: 3/10. Loss: 0.9796:  92%|[36m█████████▏[0m| 24/26 [00:25<00:02,  1.18s/it]Epoch: 3/10. Loss: 0.9796:  96%|[36m█████████▌[0m| 25/26 [00:25<00:01,  1.22s/it]Epoch: 3/10. Loss: 0.9481:  96%|[36m█████████▌[0m| 25/26 [00:26<00:01,  1.22s/it]Epoch: 3/10. Loss: 0.9481: 100%|[36m██████████[0m| 26/26 [00:26<00:00,  1.03s/it]Epoch: 3/10. Loss: 0.9481: 100%|[36m██████████[0m| 26/26 [00:26<00:00,  1.01s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:04,  1.40it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:05,  1.06s/it] 43%|[33m████▎     [0m| 3/7 [00:02<00:03,  1.17it/s] 57%|[33m█████▋    [0m| 4/7 [00:03<00:02,  1.07it/s] 71%|[33m███████▏  [0m| 5/7 [00:04<00:01,  1.28it/s] 86%|[33m████████▌ [0m| 6/7 [00:05<00:00,  1.25it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.58it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.32it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 4/10. Loss: 0.9851:   0%|[36m          [0m| 0/26 [00:01<?, ?it/s]Epoch: 4/10. Loss: 0.9851:   4%|[36m▍         [0m| 1/26 [00:01<00:26,  1.07s/it]Epoch: 4/10. Loss: 1.0419:   4%|[36m▍         [0m| 1/26 [00:02<00:26,  1.07s/it]Epoch: 4/10. Loss: 1.0419:   8%|[36m▊         [0m| 2/26 [00:02<00:36,  1.50s/it]Epoch: 4/10. Loss: 0.9841:   8%|[36m▊         [0m| 2/26 [00:03<00:36,  1.50s/it]Epoch: 4/10. Loss: 0.9841:  12%|[36m█▏        [0m| 3/26 [00:03<00:27,  1.18s/it]Epoch: 4/10. Loss: 0.9487:  12%|[36m█▏        [0m| 3/26 [00:04<00:27,  1.18s/it]Epoch: 4/10. Loss: 0.9487:  15%|[36m█▌        [0m| 4/26 [00:04<00:24,  1.10s/it]Epoch: 4/10. Loss: 0.9386:  15%|[36m█▌        [0m| 4/26 [00:05<00:24,  1.10s/it]Epoch: 4/10. Loss: 0.9386:  19%|[36m█▉        [0m| 5/26 [00:05<00:21,  1.04s/it]Epoch: 4/10. Loss: 0.9372:  19%|[36m█▉        [0m| 5/26 [00:06<00:21,  1.04s/it]Epoch: 4/10. Loss: 0.9372:  23%|[36m██▎       [0m| 6/26 [00:06<00:21,  1.09s/it]Epoch: 4/10. Loss: 0.9522:  23%|[36m██▎       [0m| 6/26 [00:10<00:21,  1.09s/it]Epoch: 4/10. Loss: 0.9522:  27%|[36m██▋       [0m| 7/26 [00:11<00:40,  2.12s/it]Epoch: 4/10. Loss: 0.9331:  27%|[36m██▋       [0m| 7/26 [00:12<00:40,  2.12s/it]Epoch: 4/10. Loss: 0.9331:  31%|[36m███       [0m| 8/26 [00:12<00:35,  1.95s/it]Epoch: 4/10. Loss: 0.9548:  31%|[36m███       [0m| 8/26 [00:15<00:35,  1.95s/it]Epoch: 4/10. Loss: 0.9548:  35%|[36m███▍      [0m| 9/26 [00:15<00:38,  2.27s/it]Epoch: 4/10. Loss: 0.9788:  35%|[36m███▍      [0m| 9/26 [00:16<00:38,  2.27s/it]Epoch: 4/10. Loss: 0.9788:  38%|[36m███▊      [0m| 10/26 [00:16<00:31,  1.97s/it]Epoch: 4/10. Loss: 0.9625:  38%|[36m███▊      [0m| 10/26 [00:18<00:31,  1.97s/it]Epoch: 4/10. Loss: 0.9625:  42%|[36m████▏     [0m| 11/26 [00:18<00:25,  1.73s/it]Epoch: 4/10. Loss: 0.8264:  42%|[36m████▏     [0m| 11/26 [00:18<00:25,  1.73s/it]Epoch: 4/10. Loss: 0.8264:  46%|[36m████▌     [0m| 12/26 [00:18<00:20,  1.43s/it]Epoch: 4/10. Loss: 0.8966:  46%|[36m████▌     [0m| 12/26 [00:19<00:20,  1.43s/it]Epoch: 4/10. Loss: 0.8966:  50%|[36m█████     [0m| 13/26 [00:19<00:17,  1.34s/it]Epoch: 4/10. Loss: 0.9199:  50%|[36m█████     [0m| 13/26 [00:20<00:17,  1.34s/it]Epoch: 4/10. Loss: 0.9199:  54%|[36m█████▍    [0m| 14/26 [00:20<00:14,  1.21s/it]Epoch: 4/10. Loss: 0.9041:  54%|[36m█████▍    [0m| 14/26 [00:21<00:14,  1.21s/it]Epoch: 4/10. Loss: 0.9041:  58%|[36m█████▊    [0m| 15/26 [00:21<00:12,  1.13s/it]Epoch: 4/10. Loss: 0.9226:  58%|[36m█████▊    [0m| 15/26 [00:22<00:12,  1.13s/it]Epoch: 4/10. Loss: 0.9226:  62%|[36m██████▏   [0m| 16/26 [00:22<00:10,  1.08s/it]Epoch: 4/10. Loss: 0.9266:  62%|[36m██████▏   [0m| 16/26 [00:23<00:10,  1.08s/it]Epoch: 4/10. Loss: 0.9266:  65%|[36m██████▌   [0m| 17/26 [00:23<00:09,  1.01s/it]Epoch: 4/10. Loss: 0.9398:  65%|[36m██████▌   [0m| 17/26 [00:24<00:09,  1.01s/it]Epoch: 4/10. Loss: 0.9398:  69%|[36m██████▉   [0m| 18/26 [00:24<00:07,  1.03it/s]Epoch: 4/10. Loss: 0.9680:  69%|[36m██████▉   [0m| 18/26 [00:25<00:07,  1.03it/s]Epoch: 4/10. Loss: 0.9680:  73%|[36m███████▎  [0m| 19/26 [00:25<00:06,  1.07it/s]Epoch: 4/10. Loss: 0.9448:  73%|[36m███████▎  [0m| 19/26 [00:26<00:06,  1.07it/s]Epoch: 4/10. Loss: 0.9448:  77%|[36m███████▋  [0m| 20/26 [00:26<00:05,  1.09it/s]Epoch: 4/10. Loss: 0.8741:  77%|[36m███████▋  [0m| 20/26 [00:27<00:05,  1.09it/s]Epoch: 4/10. Loss: 0.8741:  81%|[36m████████  [0m| 21/26 [00:27<00:04,  1.08it/s]Epoch: 4/10. Loss: 0.8801:  81%|[36m████████  [0m| 21/26 [00:27<00:04,  1.08it/s]Epoch: 4/10. Loss: 0.8801:  85%|[36m████████▍ [0m| 22/26 [00:27<00:03,  1.12it/s]Epoch: 4/10. Loss: 0.9561:  85%|[36m████████▍ [0m| 22/26 [00:28<00:03,  1.12it/s]Epoch: 4/10. Loss: 0.9561:  88%|[36m████████▊ [0m| 23/26 [00:28<00:02,  1.15it/s]Epoch: 4/10. Loss: 0.8935:  88%|[36m████████▊ [0m| 23/26 [00:29<00:02,  1.15it/s]Epoch: 4/10. Loss: 0.8935:  92%|[36m█████████▏[0m| 24/26 [00:29<00:01,  1.19it/s]Epoch: 4/10. Loss: 0.9489:  92%|[36m█████████▏[0m| 24/26 [00:30<00:01,  1.19it/s]Epoch: 4/10. Loss: 0.9489:  96%|[36m█████████▌[0m| 25/26 [00:30<00:00,  1.16it/s]Epoch: 4/10. Loss: 0.9132:  96%|[36m█████████▌[0m| 25/26 [00:30<00:00,  1.16it/s]Epoch: 4/10. Loss: 0.9132: 100%|[36m██████████[0m| 26/26 [00:31<00:00,  1.30it/s]Epoch: 4/10. Loss: 0.9132: 100%|[36m██████████[0m| 26/26 [00:31<00:00,  1.19s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:04,  1.42it/s] 29%|[33m██▊       [0m| 2/7 [00:01<00:05,  1.04s/it] 43%|[33m████▎     [0m| 3/7 [00:02<00:03,  1.18it/s] 57%|[33m█████▋    [0m| 4/7 [00:03<00:02,  1.05it/s] 71%|[33m███████▏  [0m| 5/7 [00:04<00:01,  1.27it/s] 86%|[33m████████▌ [0m| 6/7 [00:05<00:00,  1.24it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.57it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.31it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 5/10. Loss: 0.8861:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 5/10. Loss: 0.8861:   4%|[36m▍         [0m| 1/26 [00:00<00:24,  1.01it/s]Epoch: 5/10. Loss: 0.8879:   4%|[36m▍         [0m| 1/26 [00:01<00:24,  1.01it/s]Epoch: 5/10. Loss: 0.8879:   8%|[36m▊         [0m| 2/26 [00:01<00:23,  1.04it/s]Epoch: 5/10. Loss: 0.8372:   8%|[36m▊         [0m| 2/26 [00:02<00:23,  1.04it/s]Epoch: 5/10. Loss: 0.8372:  12%|[36m█▏        [0m| 3/26 [00:02<00:19,  1.19it/s]Epoch: 5/10. Loss: 0.8505:  12%|[36m█▏        [0m| 3/26 [00:03<00:19,  1.19it/s]Epoch: 5/10. Loss: 0.8505:  15%|[36m█▌        [0m| 4/26 [00:03<00:19,  1.10it/s]Epoch: 5/10. Loss: 0.9112:  15%|[36m█▌        [0m| 4/26 [00:04<00:19,  1.10it/s]Epoch: 5/10. Loss: 0.9112:  19%|[36m█▉        [0m| 5/26 [00:04<00:20,  1.03it/s]Epoch: 5/10. Loss: 0.8372:  19%|[36m█▉        [0m| 5/26 [00:05<00:20,  1.03it/s]Epoch: 5/10. Loss: 0.8372:  23%|[36m██▎       [0m| 6/26 [00:05<00:18,  1.09it/s]Epoch: 5/10. Loss: 0.9368:  23%|[36m██▎       [0m| 6/26 [00:06<00:18,  1.09it/s]Epoch: 5/10. Loss: 0.9368:  27%|[36m██▋       [0m| 7/26 [00:06<00:17,  1.06it/s]Epoch: 5/10. Loss: 0.8716:  27%|[36m██▋       [0m| 7/26 [00:07<00:17,  1.06it/s]Epoch: 5/10. Loss: 0.8716:  31%|[36m███       [0m| 8/26 [00:07<00:16,  1.11it/s]Epoch: 5/10. Loss: 0.9527:  31%|[36m███       [0m| 8/26 [00:08<00:16,  1.11it/s]Epoch: 5/10. Loss: 0.9527:  35%|[36m███▍      [0m| 9/26 [00:08<00:14,  1.14it/s]Epoch: 5/10. Loss: 0.9351:  35%|[36m███▍      [0m| 9/26 [00:08<00:14,  1.14it/s]Epoch: 5/10. Loss: 0.9351:  38%|[36m███▊      [0m| 10/26 [00:08<00:13,  1.17it/s]Epoch: 5/10. Loss: 0.9159:  38%|[36m███▊      [0m| 10/26 [00:09<00:13,  1.17it/s]Epoch: 5/10. Loss: 0.9159:  42%|[36m████▏     [0m| 11/26 [00:09<00:13,  1.13it/s]Epoch: 5/10. Loss: 1.0498:  42%|[36m████▏     [0m| 11/26 [00:10<00:13,  1.13it/s]Epoch: 5/10. Loss: 1.0498:  46%|[36m████▌     [0m| 12/26 [00:10<00:13,  1.07it/s]Epoch: 5/10. Loss: 0.9159:  46%|[36m████▌     [0m| 12/26 [00:11<00:13,  1.07it/s]Epoch: 5/10. Loss: 0.9159:  50%|[36m█████     [0m| 13/26 [00:11<00:11,  1.09it/s]Epoch: 5/10. Loss: 0.9044:  50%|[36m█████     [0m| 13/26 [00:12<00:11,  1.09it/s]Epoch: 5/10. Loss: 0.9044:  54%|[36m█████▍    [0m| 14/26 [00:12<00:10,  1.09it/s]Epoch: 5/10. Loss: 0.8734:  54%|[36m█████▍    [0m| 14/26 [00:13<00:10,  1.09it/s]Epoch: 5/10. Loss: 0.8734:  58%|[36m█████▊    [0m| 15/26 [00:13<00:10,  1.06it/s]Epoch: 5/10. Loss: 0.9190:  58%|[36m█████▊    [0m| 15/26 [00:14<00:10,  1.06it/s]Epoch: 5/10. Loss: 0.9190:  62%|[36m██████▏   [0m| 16/26 [00:14<00:09,  1.06it/s]Epoch: 5/10. Loss: 0.9850:  62%|[36m██████▏   [0m| 16/26 [00:15<00:09,  1.06it/s]Epoch: 5/10. Loss: 0.9850:  65%|[36m██████▌   [0m| 17/26 [00:15<00:08,  1.12it/s]Epoch: 5/10. Loss: 0.9079:  65%|[36m██████▌   [0m| 17/26 [00:16<00:08,  1.12it/s]Epoch: 5/10. Loss: 0.9079:  69%|[36m██████▉   [0m| 18/26 [00:16<00:07,  1.05it/s]Epoch: 5/10. Loss: 0.9357:  69%|[36m██████▉   [0m| 18/26 [00:17<00:07,  1.05it/s]Epoch: 5/10. Loss: 0.9357:  73%|[36m███████▎  [0m| 19/26 [00:17<00:06,  1.10it/s]Epoch: 5/10. Loss: 0.8902:  73%|[36m███████▎  [0m| 19/26 [00:18<00:06,  1.10it/s]Epoch: 5/10. Loss: 0.8902:  77%|[36m███████▋  [0m| 20/26 [00:18<00:05,  1.12it/s]Epoch: 5/10. Loss: 0.8998:  77%|[36m███████▋  [0m| 20/26 [00:19<00:05,  1.12it/s]Epoch: 5/10. Loss: 0.8998:  81%|[36m████████  [0m| 21/26 [00:19<00:04,  1.02it/s]Epoch: 5/10. Loss: 0.9225:  81%|[36m████████  [0m| 21/26 [00:20<00:04,  1.02it/s]Epoch: 5/10. Loss: 0.9225:  85%|[36m████████▍ [0m| 22/26 [00:20<00:03,  1.09it/s]Epoch: 5/10. Loss: 0.8886:  85%|[36m████████▍ [0m| 22/26 [00:20<00:03,  1.09it/s]Epoch: 5/10. Loss: 0.8886:  88%|[36m████████▊ [0m| 23/26 [00:20<00:02,  1.18it/s]Epoch: 5/10. Loss: 0.8955:  88%|[36m████████▊ [0m| 23/26 [00:21<00:02,  1.18it/s]Epoch: 5/10. Loss: 0.8955:  92%|[36m█████████▏[0m| 24/26 [00:21<00:01,  1.15it/s]Epoch: 5/10. Loss: 0.8929:  92%|[36m█████████▏[0m| 24/26 [00:22<00:01,  1.15it/s]Epoch: 5/10. Loss: 0.8929:  96%|[36m█████████▌[0m| 25/26 [00:22<00:00,  1.09it/s]Epoch: 5/10. Loss: 0.9685:  96%|[36m█████████▌[0m| 25/26 [00:23<00:00,  1.09it/s]Epoch: 5/10. Loss: 0.9685: 100%|[36m██████████[0m| 26/26 [00:23<00:00,  1.18it/s]Epoch: 5/10. Loss: 0.9685: 100%|[36m██████████[0m| 26/26 [00:23<00:00,  1.11it/s]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:04,  1.35it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:05,  1.09s/it] 43%|[33m████▎     [0m| 3/7 [00:02<00:03,  1.14it/s] 57%|[33m█████▋    [0m| 4/7 [00:03<00:02,  1.02it/s] 71%|[33m███████▏  [0m| 5/7 [00:04<00:01,  1.25it/s] 86%|[33m████████▌ [0m| 6/7 [00:05<00:00,  1.24it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.57it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.29it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 6/10. Loss: 0.7909:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 6/10. Loss: 0.7909:   4%|[36m▍         [0m| 1/26 [00:00<00:19,  1.29it/s]Epoch: 6/10. Loss: 0.9123:   4%|[36m▍         [0m| 1/26 [00:01<00:19,  1.29it/s]Epoch: 6/10. Loss: 0.9123:   8%|[36m▊         [0m| 2/26 [00:01<00:20,  1.16it/s]Epoch: 6/10. Loss: 0.9100:   8%|[36m▊         [0m| 2/26 [00:02<00:20,  1.16it/s]Epoch: 6/10. Loss: 0.9100:  12%|[36m█▏        [0m| 3/26 [00:02<00:18,  1.21it/s]Epoch: 6/10. Loss: 0.8947:  12%|[36m█▏        [0m| 3/26 [00:03<00:18,  1.21it/s]Epoch: 6/10. Loss: 0.8947:  15%|[36m█▌        [0m| 4/26 [00:03<00:18,  1.17it/s]Epoch: 6/10. Loss: 0.8378:  15%|[36m█▌        [0m| 4/26 [00:04<00:18,  1.17it/s]Epoch: 6/10. Loss: 0.8378:  19%|[36m█▉        [0m| 5/26 [00:04<00:19,  1.09it/s]Epoch: 6/10. Loss: 0.8906:  19%|[36m█▉        [0m| 5/26 [00:05<00:19,  1.09it/s]Epoch: 6/10. Loss: 0.8906:  23%|[36m██▎       [0m| 6/26 [00:05<00:17,  1.16it/s]Epoch: 6/10. Loss: 0.9187:  23%|[36m██▎       [0m| 6/26 [00:05<00:17,  1.16it/s]Epoch: 6/10. Loss: 0.9187:  27%|[36m██▋       [0m| 7/26 [00:05<00:15,  1.19it/s]Epoch: 6/10. Loss: 0.9001:  27%|[36m██▋       [0m| 7/26 [00:06<00:15,  1.19it/s]Epoch: 6/10. Loss: 0.9001:  31%|[36m███       [0m| 8/26 [00:06<00:16,  1.12it/s]Epoch: 6/10. Loss: 0.8722:  31%|[36m███       [0m| 8/26 [00:07<00:16,  1.12it/s]Epoch: 6/10. Loss: 0.8722:  35%|[36m███▍      [0m| 9/26 [00:07<00:15,  1.08it/s]Epoch: 6/10. Loss: 0.8813:  35%|[36m███▍      [0m| 9/26 [00:08<00:15,  1.08it/s]Epoch: 6/10. Loss: 0.8813:  38%|[36m███▊      [0m| 10/26 [00:08<00:14,  1.09it/s]Epoch: 6/10. Loss: 0.9157:  38%|[36m███▊      [0m| 10/26 [00:09<00:14,  1.09it/s]Epoch: 6/10. Loss: 0.9157:  42%|[36m████▏     [0m| 11/26 [00:09<00:13,  1.12it/s]Epoch: 6/10. Loss: 0.8925:  42%|[36m████▏     [0m| 11/26 [00:10<00:13,  1.12it/s]Epoch: 6/10. Loss: 0.8925:  46%|[36m████▌     [0m| 12/26 [00:10<00:12,  1.11it/s]Epoch: 6/10. Loss: 0.9347:  46%|[36m████▌     [0m| 12/26 [00:11<00:12,  1.11it/s]Epoch: 6/10. Loss: 0.9347:  50%|[36m█████     [0m| 13/26 [00:11<00:11,  1.13it/s]Epoch: 6/10. Loss: 0.9328:  50%|[36m█████     [0m| 13/26 [00:12<00:11,  1.13it/s]Epoch: 6/10. Loss: 0.9328:  54%|[36m█████▍    [0m| 14/26 [00:12<00:10,  1.13it/s]Epoch: 6/10. Loss: 0.9004:  54%|[36m█████▍    [0m| 14/26 [00:13<00:10,  1.13it/s]Epoch: 6/10. Loss: 0.9004:  58%|[36m█████▊    [0m| 15/26 [00:13<00:09,  1.14it/s]Epoch: 6/10. Loss: 0.9357:  58%|[36m█████▊    [0m| 15/26 [00:15<00:09,  1.14it/s]Epoch: 6/10. Loss: 0.9357:  62%|[36m██████▏   [0m| 16/26 [00:15<00:12,  1.26s/it]Epoch: 6/10. Loss: 0.8222:  62%|[36m██████▏   [0m| 16/26 [00:16<00:12,  1.26s/it]Epoch: 6/10. Loss: 0.8222:  65%|[36m██████▌   [0m| 17/26 [00:16<00:10,  1.17s/it]Epoch: 6/10. Loss: 0.8505:  65%|[36m██████▌   [0m| 17/26 [00:17<00:10,  1.17s/it]Epoch: 6/10. Loss: 0.8505:  69%|[36m██████▉   [0m| 18/26 [00:17<00:09,  1.13s/it]Epoch: 6/10. Loss: 0.8774:  69%|[36m██████▉   [0m| 18/26 [00:18<00:09,  1.13s/it]Epoch: 6/10. Loss: 0.8774:  73%|[36m███████▎  [0m| 19/26 [00:18<00:07,  1.05s/it]Epoch: 6/10. Loss: 0.9063:  73%|[36m███████▎  [0m| 19/26 [00:20<00:07,  1.05s/it]Epoch: 6/10. Loss: 0.9063:  77%|[36m███████▋  [0m| 20/26 [00:20<00:09,  1.51s/it]Epoch: 6/10. Loss: 0.8069:  77%|[36m███████▋  [0m| 20/26 [00:22<00:09,  1.51s/it]Epoch: 6/10. Loss: 0.8069:  81%|[36m████████  [0m| 21/26 [00:22<00:07,  1.45s/it]Epoch: 6/10. Loss: 0.8287:  81%|[36m████████  [0m| 21/26 [00:23<00:07,  1.45s/it]Epoch: 6/10. Loss: 0.8287:  85%|[36m████████▍ [0m| 22/26 [00:23<00:05,  1.40s/it]Epoch: 6/10. Loss: 0.7606:  85%|[36m████████▍ [0m| 22/26 [00:24<00:05,  1.40s/it]Epoch: 6/10. Loss: 0.7606:  88%|[36m████████▊ [0m| 23/26 [00:24<00:03,  1.23s/it]Epoch: 6/10. Loss: 0.9671:  88%|[36m████████▊ [0m| 23/26 [00:25<00:03,  1.23s/it]Epoch: 6/10. Loss: 0.9671:  92%|[36m█████████▏[0m| 24/26 [00:25<00:02,  1.13s/it]Epoch: 6/10. Loss: 0.8320:  92%|[36m█████████▏[0m| 24/26 [00:26<00:02,  1.13s/it]Epoch: 6/10. Loss: 0.8320:  96%|[36m█████████▌[0m| 25/26 [00:26<00:01,  1.09s/it]Epoch: 6/10. Loss: 0.8210:  96%|[36m█████████▌[0m| 25/26 [00:26<00:01,  1.09s/it]Epoch: 6/10. Loss: 0.8210: 100%|[36m██████████[0m| 26/26 [00:26<00:00,  1.06it/s]Epoch: 6/10. Loss: 0.8210: 100%|[36m██████████[0m| 26/26 [00:26<00:00,  1.03s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:04,  1.35it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:05,  1.10s/it] 43%|[33m████▎     [0m| 3/7 [00:02<00:03,  1.10it/s] 57%|[33m█████▋    [0m| 4/7 [00:03<00:02,  1.00it/s] 71%|[33m███████▏  [0m| 5/7 [00:04<00:01,  1.23it/s] 86%|[33m████████▌ [0m| 6/7 [00:05<00:00,  1.20it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.53it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.26it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 7/10. Loss: 0.7737:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 7/10. Loss: 0.7737:   4%|[36m▍         [0m| 1/26 [00:00<00:24,  1.00it/s]Epoch: 7/10. Loss: 0.7507:   4%|[36m▍         [0m| 1/26 [00:01<00:24,  1.00it/s]Epoch: 7/10. Loss: 0.7507:   8%|[36m▊         [0m| 2/26 [00:01<00:22,  1.05it/s]Epoch: 7/10. Loss: 0.8437:   8%|[36m▊         [0m| 2/26 [00:02<00:22,  1.05it/s]Epoch: 7/10. Loss: 0.8437:  12%|[36m█▏        [0m| 3/26 [00:02<00:21,  1.07it/s]Epoch: 7/10. Loss: 0.7625:  12%|[36m█▏        [0m| 3/26 [00:03<00:21,  1.07it/s]Epoch: 7/10. Loss: 0.7625:  15%|[36m█▌        [0m| 4/26 [00:03<00:19,  1.11it/s]Epoch: 7/10. Loss: 0.8564:  15%|[36m█▌        [0m| 4/26 [00:04<00:19,  1.11it/s]Epoch: 7/10. Loss: 0.8564:  19%|[36m█▉        [0m| 5/26 [00:04<00:19,  1.07it/s]Epoch: 7/10. Loss: 0.7125:  19%|[36m█▉        [0m| 5/26 [00:08<00:19,  1.07it/s]Epoch: 7/10. Loss: 0.7125:  23%|[36m██▎       [0m| 6/26 [00:08<00:38,  1.93s/it]Epoch: 7/10. Loss: 0.8214:  23%|[36m██▎       [0m| 6/26 [00:10<00:38,  1.93s/it]Epoch: 7/10. Loss: 0.8214:  27%|[36m██▋       [0m| 7/26 [00:10<00:39,  2.08s/it]Epoch: 7/10. Loss: 0.8837:  27%|[36m██▋       [0m| 7/26 [00:11<00:39,  2.08s/it]Epoch: 7/10. Loss: 0.8837:  31%|[36m███       [0m| 8/26 [00:11<00:29,  1.67s/it]Epoch: 7/10. Loss: 0.7684:  31%|[36m███       [0m| 8/26 [00:12<00:29,  1.67s/it]Epoch: 7/10. Loss: 0.7684:  35%|[36m███▍      [0m| 9/26 [00:12<00:25,  1.48s/it]Epoch: 7/10. Loss: 0.9114:  35%|[36m███▍      [0m| 9/26 [00:15<00:25,  1.48s/it]Epoch: 7/10. Loss: 0.9114:  38%|[36m███▊      [0m| 10/26 [00:15<00:28,  1.79s/it]Epoch: 7/10. Loss: 0.7572:  38%|[36m███▊      [0m| 10/26 [00:16<00:28,  1.79s/it]Epoch: 7/10. Loss: 0.7572:  42%|[36m████▏     [0m| 11/26 [00:16<00:22,  1.50s/it]Epoch: 7/10. Loss: 0.8237:  42%|[36m████▏     [0m| 11/26 [00:17<00:22,  1.50s/it]Epoch: 7/10. Loss: 0.8237:  46%|[36m████▌     [0m| 12/26 [00:17<00:18,  1.34s/it]Epoch: 7/10. Loss: 0.8491:  46%|[36m████▌     [0m| 12/26 [00:18<00:18,  1.34s/it]Epoch: 7/10. Loss: 0.8491:  50%|[36m█████     [0m| 13/26 [00:18<00:15,  1.22s/it]Epoch: 7/10. Loss: 0.8503:  50%|[36m█████     [0m| 13/26 [00:19<00:15,  1.22s/it]Epoch: 7/10. Loss: 0.8503:  54%|[36m█████▍    [0m| 14/26 [00:19<00:13,  1.16s/it]Epoch: 7/10. Loss: 0.9133:  54%|[36m█████▍    [0m| 14/26 [00:19<00:13,  1.16s/it]Epoch: 7/10. Loss: 0.9133:  58%|[36m█████▊    [0m| 15/26 [00:19<00:11,  1.05s/it]Epoch: 7/10. Loss: 0.8686:  58%|[36m█████▊    [0m| 15/26 [00:20<00:11,  1.05s/it]Epoch: 7/10. Loss: 0.8686:  62%|[36m██████▏   [0m| 16/26 [00:20<00:09,  1.01it/s]Epoch: 7/10. Loss: 0.8346:  62%|[36m██████▏   [0m| 16/26 [00:22<00:09,  1.01it/s]Epoch: 7/10. Loss: 0.8346:  65%|[36m██████▌   [0m| 17/26 [00:22<00:10,  1.18s/it]Epoch: 7/10. Loss: 0.9514:  65%|[36m██████▌   [0m| 17/26 [00:23<00:10,  1.18s/it]Epoch: 7/10. Loss: 0.9514:  69%|[36m██████▉   [0m| 18/26 [00:23<00:08,  1.11s/it]Epoch: 7/10. Loss: 0.9176:  69%|[36m██████▉   [0m| 18/26 [00:24<00:08,  1.11s/it]Epoch: 7/10. Loss: 0.9176:  73%|[36m███████▎  [0m| 19/26 [00:24<00:07,  1.05s/it]Epoch: 7/10. Loss: 0.8448:  73%|[36m███████▎  [0m| 19/26 [00:25<00:07,  1.05s/it]Epoch: 7/10. Loss: 0.8448:  77%|[36m███████▋  [0m| 20/26 [00:25<00:06,  1.05s/it]Epoch: 7/10. Loss: 0.7549:  77%|[36m███████▋  [0m| 20/26 [00:26<00:06,  1.05s/it]Epoch: 7/10. Loss: 0.7549:  81%|[36m████████  [0m| 21/26 [00:26<00:04,  1.02it/s]Epoch: 7/10. Loss: 0.8663:  81%|[36m████████  [0m| 21/26 [00:26<00:04,  1.02it/s]Epoch: 7/10. Loss: 0.8663:  85%|[36m████████▍ [0m| 22/26 [00:26<00:03,  1.11it/s]Epoch: 7/10. Loss: 0.8913:  85%|[36m████████▍ [0m| 22/26 [00:27<00:03,  1.11it/s]Epoch: 7/10. Loss: 0.8913:  88%|[36m████████▊ [0m| 23/26 [00:27<00:02,  1.17it/s]Epoch: 7/10. Loss: 0.7927:  88%|[36m████████▊ [0m| 23/26 [00:28<00:02,  1.17it/s]Epoch: 7/10. Loss: 0.7927:  92%|[36m█████████▏[0m| 24/26 [00:28<00:01,  1.17it/s]Epoch: 7/10. Loss: 0.8980:  92%|[36m█████████▏[0m| 24/26 [00:29<00:01,  1.17it/s]Epoch: 7/10. Loss: 0.8980:  96%|[36m█████████▌[0m| 25/26 [00:29<00:00,  1.11it/s]Epoch: 7/10. Loss: 0.7965:  96%|[36m█████████▌[0m| 25/26 [00:29<00:00,  1.11it/s]Epoch: 7/10. Loss: 0.7965: 100%|[36m██████████[0m| 26/26 [00:29<00:00,  1.28it/s]Epoch: 7/10. Loss: 0.7965: 100%|[36m██████████[0m| 26/26 [00:29<00:00,  1.15s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:04,  1.32it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:05,  1.12s/it] 43%|[33m████▎     [0m| 3/7 [00:02<00:03,  1.10it/s] 57%|[33m█████▋    [0m| 4/7 [00:03<00:02,  1.01it/s] 71%|[33m███████▏  [0m| 5/7 [00:04<00:01,  1.22it/s] 86%|[33m████████▌ [0m| 6/7 [00:05<00:00,  1.20it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.51it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.25it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 8/10. Loss: 0.7744:   0%|[36m          [0m| 0/26 [00:01<?, ?it/s]Epoch: 8/10. Loss: 0.7744:   4%|[36m▍         [0m| 1/26 [00:01<00:34,  1.40s/it]Epoch: 8/10. Loss: 0.8413:   4%|[36m▍         [0m| 1/26 [00:02<00:34,  1.40s/it]Epoch: 8/10. Loss: 0.8413:   8%|[36m▊         [0m| 2/26 [00:02<00:26,  1.10s/it]Epoch: 8/10. Loss: 0.8336:   8%|[36m▊         [0m| 2/26 [00:03<00:26,  1.10s/it]Epoch: 8/10. Loss: 0.8336:  12%|[36m█▏        [0m| 3/26 [00:03<00:23,  1.01s/it]Epoch: 8/10. Loss: 0.8771:  12%|[36m█▏        [0m| 3/26 [00:03<00:23,  1.01s/it]Epoch: 8/10. Loss: 0.8771:  15%|[36m█▌        [0m| 4/26 [00:04<00:20,  1.07it/s]Epoch: 8/10. Loss: 0.8847:  15%|[36m█▌        [0m| 4/26 [00:04<00:20,  1.07it/s]Epoch: 8/10. Loss: 0.8847:  19%|[36m█▉        [0m| 5/26 [00:04<00:18,  1.11it/s]Epoch: 8/10. Loss: 0.7956:  19%|[36m█▉        [0m| 5/26 [00:05<00:18,  1.11it/s]Epoch: 8/10. Loss: 0.7956:  23%|[36m██▎       [0m| 6/26 [00:05<00:17,  1.14it/s]Epoch: 8/10. Loss: 0.9544:  23%|[36m██▎       [0m| 6/26 [00:06<00:17,  1.14it/s]Epoch: 8/10. Loss: 0.9544:  27%|[36m██▋       [0m| 7/26 [00:06<00:17,  1.08it/s]Epoch: 8/10. Loss: 0.7623:  27%|[36m██▋       [0m| 7/26 [00:07<00:17,  1.08it/s]Epoch: 8/10. Loss: 0.7623:  31%|[36m███       [0m| 8/26 [00:07<00:15,  1.14it/s]Epoch: 8/10. Loss: 0.8235:  31%|[36m███       [0m| 8/26 [00:08<00:15,  1.14it/s]Epoch: 8/10. Loss: 0.8235:  35%|[36m███▍      [0m| 9/26 [00:08<00:15,  1.10it/s]Epoch: 8/10. Loss: 0.9490:  35%|[36m███▍      [0m| 9/26 [00:09<00:15,  1.10it/s]Epoch: 8/10. Loss: 0.9490:  38%|[36m███▊      [0m| 10/26 [00:09<00:14,  1.13it/s]Epoch: 8/10. Loss: 0.8727:  38%|[36m███▊      [0m| 10/26 [00:10<00:14,  1.13it/s]Epoch: 8/10. Loss: 0.8727:  42%|[36m████▏     [0m| 11/26 [00:10<00:13,  1.11it/s]Epoch: 8/10. Loss: 0.8626:  42%|[36m████▏     [0m| 11/26 [00:11<00:13,  1.11it/s]Epoch: 8/10. Loss: 0.8626:  46%|[36m████▌     [0m| 12/26 [00:11<00:12,  1.12it/s]Epoch: 8/10. Loss: 0.7654:  46%|[36m████▌     [0m| 12/26 [00:11<00:12,  1.12it/s]Epoch: 8/10. Loss: 0.7654:  50%|[36m█████     [0m| 13/26 [00:11<00:11,  1.14it/s]Epoch: 8/10. Loss: 0.8758:  50%|[36m█████     [0m| 13/26 [00:12<00:11,  1.14it/s]Epoch: 8/10. Loss: 0.8758:  54%|[36m█████▍    [0m| 14/26 [00:12<00:10,  1.14it/s]Epoch: 8/10. Loss: 0.8999:  54%|[36m█████▍    [0m| 14/26 [00:13<00:10,  1.14it/s]Epoch: 8/10. Loss: 0.8999:  58%|[36m█████▊    [0m| 15/26 [00:13<00:10,  1.08it/s]Epoch: 8/10. Loss: 0.9220:  58%|[36m█████▊    [0m| 15/26 [00:14<00:10,  1.08it/s]Epoch: 8/10. Loss: 0.9220:  62%|[36m██████▏   [0m| 16/26 [00:14<00:09,  1.07it/s]Epoch: 8/10. Loss: 0.9146:  62%|[36m██████▏   [0m| 16/26 [00:15<00:09,  1.07it/s]Epoch: 8/10. Loss: 0.9146:  65%|[36m██████▌   [0m| 17/26 [00:15<00:08,  1.09it/s]Epoch: 8/10. Loss: 0.7737:  65%|[36m██████▌   [0m| 17/26 [00:16<00:08,  1.09it/s]Epoch: 8/10. Loss: 0.7737:  69%|[36m██████▉   [0m| 18/26 [00:16<00:07,  1.12it/s]Epoch: 8/10. Loss: 0.8829:  69%|[36m██████▉   [0m| 18/26 [00:17<00:07,  1.12it/s]Epoch: 8/10. Loss: 0.8829:  73%|[36m███████▎  [0m| 19/26 [00:17<00:06,  1.11it/s]Epoch: 8/10. Loss: 0.9101:  73%|[36m███████▎  [0m| 19/26 [00:18<00:06,  1.11it/s]Epoch: 8/10. Loss: 0.9101:  77%|[36m███████▋  [0m| 20/26 [00:18<00:05,  1.16it/s]Epoch: 8/10. Loss: 1.0615:  77%|[36m███████▋  [0m| 20/26 [00:18<00:05,  1.16it/s]Epoch: 8/10. Loss: 1.0615:  81%|[36m████████  [0m| 21/26 [00:18<00:04,  1.22it/s]Epoch: 8/10. Loss: 0.8887:  81%|[36m████████  [0m| 21/26 [00:20<00:04,  1.22it/s]Epoch: 8/10. Loss: 0.8887:  85%|[36m████████▍ [0m| 22/26 [00:20<00:03,  1.12it/s]Epoch: 8/10. Loss: 0.9043:  85%|[36m████████▍ [0m| 22/26 [00:20<00:03,  1.12it/s]Epoch: 8/10. Loss: 0.9043:  88%|[36m████████▊ [0m| 23/26 [00:20<00:02,  1.12it/s]Epoch: 8/10. Loss: 0.8571:  88%|[36m████████▊ [0m| 23/26 [00:21<00:02,  1.12it/s]Epoch: 8/10. Loss: 0.8571:  92%|[36m█████████▏[0m| 24/26 [00:21<00:01,  1.16it/s]Epoch: 8/10. Loss: 0.8458:  92%|[36m█████████▏[0m| 24/26 [00:22<00:01,  1.16it/s]Epoch: 8/10. Loss: 0.8458:  96%|[36m█████████▌[0m| 25/26 [00:22<00:00,  1.10it/s]Epoch: 8/10. Loss: 0.8204:  96%|[36m█████████▌[0m| 25/26 [00:23<00:00,  1.10it/s]Epoch: 8/10. Loss: 0.8204: 100%|[36m██████████[0m| 26/26 [00:23<00:00,  1.14it/s]Epoch: 8/10. Loss: 0.8204: 100%|[36m██████████[0m| 26/26 [00:23<00:00,  1.11it/s]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:04,  1.32it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:05,  1.10s/it] 43%|[33m████▎     [0m| 3/7 [00:02<00:03,  1.10it/s] 57%|[33m█████▋    [0m| 4/7 [00:03<00:03,  1.01s/it] 71%|[33m███████▏  [0m| 5/7 [00:04<00:01,  1.20it/s] 86%|[33m████████▌ [0m| 6/7 [00:05<00:00,  1.19it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.49it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.24it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 9/10. Loss: 0.7784:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 9/10. Loss: 0.7784:   4%|[36m▍         [0m| 1/26 [00:00<00:18,  1.35it/s]Epoch: 9/10. Loss: 0.9454:   4%|[36m▍         [0m| 1/26 [00:01<00:18,  1.35it/s]Epoch: 9/10. Loss: 0.9454:   8%|[36m▊         [0m| 2/26 [00:01<00:19,  1.25it/s]Epoch: 9/10. Loss: 0.9417:   8%|[36m▊         [0m| 2/26 [00:02<00:19,  1.25it/s]Epoch: 9/10. Loss: 0.9417:  12%|[36m█▏        [0m| 3/26 [00:02<00:18,  1.27it/s]Epoch: 9/10. Loss: 0.8922:  12%|[36m█▏        [0m| 3/26 [00:03<00:18,  1.27it/s]Epoch: 9/10. Loss: 0.8922:  15%|[36m█▌        [0m| 4/26 [00:03<00:18,  1.21it/s]Epoch: 9/10. Loss: 0.9190:  15%|[36m█▌        [0m| 4/26 [00:04<00:18,  1.21it/s]Epoch: 9/10. Loss: 0.9190:  19%|[36m█▉        [0m| 5/26 [00:04<00:18,  1.16it/s]Epoch: 9/10. Loss: 0.8425:  19%|[36m█▉        [0m| 5/26 [00:05<00:18,  1.16it/s]Epoch: 9/10. Loss: 0.8425:  23%|[36m██▎       [0m| 6/26 [00:05<00:18,  1.07it/s]Epoch: 9/10. Loss: 0.9166:  23%|[36m██▎       [0m| 6/26 [00:06<00:18,  1.07it/s]Epoch: 9/10. Loss: 0.9166:  27%|[36m██▋       [0m| 7/26 [00:06<00:18,  1.05it/s]Epoch: 9/10. Loss: 0.8312:  27%|[36m██▋       [0m| 7/26 [00:07<00:18,  1.05it/s]Epoch: 9/10. Loss: 0.8312:  31%|[36m███       [0m| 8/26 [00:07<00:16,  1.11it/s]Epoch: 9/10. Loss: 0.8177:  31%|[36m███       [0m| 8/26 [00:08<00:16,  1.11it/s]Epoch: 9/10. Loss: 0.8177:  35%|[36m███▍      [0m| 9/26 [00:08<00:16,  1.06it/s]Epoch: 9/10. Loss: 0.7631:  35%|[36m███▍      [0m| 9/26 [00:08<00:16,  1.06it/s]Epoch: 9/10. Loss: 0.7631:  38%|[36m███▊      [0m| 10/26 [00:08<00:14,  1.12it/s]Epoch: 9/10. Loss: 0.8814:  38%|[36m███▊      [0m| 10/26 [00:09<00:14,  1.12it/s]Epoch: 9/10. Loss: 0.8814:  42%|[36m████▏     [0m| 11/26 [00:09<00:13,  1.11it/s]Epoch: 9/10. Loss: 1.0128:  42%|[36m████▏     [0m| 11/26 [00:10<00:13,  1.11it/s]Epoch: 9/10. Loss: 1.0128:  46%|[36m████▌     [0m| 12/26 [00:10<00:12,  1.14it/s]Epoch: 9/10. Loss: 0.7107:  46%|[36m████▌     [0m| 12/26 [00:11<00:12,  1.14it/s]Epoch: 9/10. Loss: 0.7107:  50%|[36m█████     [0m| 13/26 [00:11<00:11,  1.14it/s]Epoch: 9/10. Loss: 0.7657:  50%|[36m█████     [0m| 13/26 [00:12<00:11,  1.14it/s]Epoch: 9/10. Loss: 0.7657:  54%|[36m█████▍    [0m| 14/26 [00:12<00:10,  1.14it/s]Epoch: 9/10. Loss: 1.0009:  54%|[36m█████▍    [0m| 14/26 [00:13<00:10,  1.14it/s]Epoch: 9/10. Loss: 1.0009:  58%|[36m█████▊    [0m| 15/26 [00:13<00:09,  1.11it/s]Epoch: 9/10. Loss: 0.8978:  58%|[36m█████▊    [0m| 15/26 [00:14<00:09,  1.11it/s]Epoch: 9/10. Loss: 0.8978:  62%|[36m██████▏   [0m| 16/26 [00:14<00:08,  1.13it/s]Epoch: 9/10. Loss: 0.8531:  62%|[36m██████▏   [0m| 16/26 [00:14<00:08,  1.13it/s]Epoch: 9/10. Loss: 0.8531:  65%|[36m██████▌   [0m| 17/26 [00:14<00:07,  1.19it/s]Epoch: 9/10. Loss: 0.9845:  65%|[36m██████▌   [0m| 17/26 [00:15<00:07,  1.19it/s]Epoch: 9/10. Loss: 0.9845:  69%|[36m██████▉   [0m| 18/26 [00:15<00:07,  1.13it/s]Epoch: 9/10. Loss: 0.9445:  69%|[36m██████▉   [0m| 18/26 [00:16<00:07,  1.13it/s]Epoch: 9/10. Loss: 0.9445:  73%|[36m███████▎  [0m| 19/26 [00:16<00:06,  1.05it/s]Epoch: 9/10. Loss: 0.8196:  73%|[36m███████▎  [0m| 19/26 [00:17<00:06,  1.05it/s]Epoch: 9/10. Loss: 0.8196:  77%|[36m███████▋  [0m| 20/26 [00:17<00:05,  1.05it/s]Epoch: 9/10. Loss: 0.9050:  77%|[36m███████▋  [0m| 20/26 [00:18<00:05,  1.05it/s]Epoch: 9/10. Loss: 0.9050:  81%|[36m████████  [0m| 21/26 [00:18<00:04,  1.05it/s]Epoch: 9/10. Loss: 0.9801:  81%|[36m████████  [0m| 21/26 [00:19<00:04,  1.05it/s]Epoch: 9/10. Loss: 0.9801:  85%|[36m████████▍ [0m| 22/26 [00:19<00:03,  1.03it/s]Epoch: 9/10. Loss: 0.7124:  85%|[36m████████▍ [0m| 22/26 [00:21<00:03,  1.03it/s]Epoch: 9/10. Loss: 0.7124:  88%|[36m████████▊ [0m| 23/26 [00:21<00:03,  1.04s/it]Epoch: 9/10. Loss: 0.9000:  88%|[36m████████▊ [0m| 23/26 [00:21<00:03,  1.04s/it]Epoch: 9/10. Loss: 0.9000:  92%|[36m█████████▏[0m| 24/26 [00:21<00:01,  1.02it/s]Epoch: 9/10. Loss: 0.8362:  92%|[36m█████████▏[0m| 24/26 [00:22<00:01,  1.02it/s]Epoch: 9/10. Loss: 0.8362:  96%|[36m█████████▌[0m| 25/26 [00:22<00:00,  1.05it/s]Epoch: 9/10. Loss: 0.7887:  96%|[36m█████████▌[0m| 25/26 [00:23<00:00,  1.05it/s]Epoch: 9/10. Loss: 0.7887: 100%|[36m██████████[0m| 26/26 [00:23<00:00,  1.12it/s]Epoch: 9/10. Loss: 0.7887: 100%|[36m██████████[0m| 26/26 [00:23<00:00,  1.10it/s]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:04,  1.26it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:05,  1.11s/it] 43%|[33m████▎     [0m| 3/7 [00:02<00:03,  1.09it/s] 57%|[33m█████▋    [0m| 4/7 [00:03<00:02,  1.00it/s] 71%|[33m███████▏  [0m| 5/7 [00:04<00:01,  1.23it/s] 86%|[33m████████▌ [0m| 6/7 [00:05<00:00,  1.06it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.36it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.18it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 0/10. Loss: 1.2835:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 0/10. Loss: 1.2835:   4%|[36m▍         [0m| 1/26 [00:00<00:22,  1.12it/s]Epoch: 0/10. Loss: 11.5854:   4%|[36m▍         [0m| 1/26 [00:01<00:22,  1.12it/s]Epoch: 0/10. Loss: 11.5854:   8%|[36m▊         [0m| 2/26 [00:01<00:22,  1.06it/s]Epoch: 0/10. Loss: 4.4599:   8%|[36m▊         [0m| 2/26 [00:02<00:22,  1.06it/s] Epoch: 0/10. Loss: 4.4599:  12%|[36m█▏        [0m| 3/26 [00:02<00:19,  1.17it/s]Epoch: 0/10. Loss: 1.8490:  12%|[36m█▏        [0m| 3/26 [00:03<00:19,  1.17it/s]Epoch: 0/10. Loss: 1.8490:  15%|[36m█▌        [0m| 4/26 [00:03<00:22,  1.03s/it]Epoch: 0/10. Loss: 3.0600:  15%|[36m█▌        [0m| 4/26 [00:05<00:22,  1.03s/it]Epoch: 0/10. Loss: 3.0600:  19%|[36m█▉        [0m| 5/26 [00:05<00:25,  1.20s/it]Epoch: 0/10. Loss: 1.8638:  19%|[36m█▉        [0m| 5/26 [00:06<00:25,  1.20s/it]Epoch: 0/10. Loss: 1.8638:  23%|[36m██▎       [0m| 6/26 [00:06<00:22,  1.11s/it]Epoch: 0/10. Loss: 3.0261:  23%|[36m██▎       [0m| 6/26 [00:07<00:22,  1.11s/it]Epoch: 0/10. Loss: 3.0261:  27%|[36m██▋       [0m| 7/26 [00:07<00:21,  1.14s/it]Epoch: 0/10. Loss: 4.0362:  27%|[36m██▋       [0m| 7/26 [00:08<00:21,  1.14s/it]Epoch: 0/10. Loss: 4.0362:  31%|[36m███       [0m| 8/26 [00:08<00:20,  1.13s/it]Epoch: 0/10. Loss: 1.7704:  31%|[36m███       [0m| 8/26 [00:09<00:20,  1.13s/it]Epoch: 0/10. Loss: 1.7704:  35%|[36m███▍      [0m| 9/26 [00:09<00:17,  1.06s/it]Epoch: 0/10. Loss: 1.3719:  35%|[36m███▍      [0m| 9/26 [00:10<00:17,  1.06s/it]Epoch: 0/10. Loss: 1.3719:  38%|[36m███▊      [0m| 10/26 [00:10<00:17,  1.12s/it]Epoch: 0/10. Loss: 1.7320:  38%|[36m███▊      [0m| 10/26 [00:11<00:17,  1.12s/it]Epoch: 0/10. Loss: 1.7320:  42%|[36m████▏     [0m| 11/26 [00:11<00:16,  1.08s/it]Epoch: 0/10. Loss: 1.4577:  42%|[36m████▏     [0m| 11/26 [00:13<00:16,  1.08s/it]Epoch: 0/10. Loss: 1.4577:  46%|[36m████▌     [0m| 12/26 [00:13<00:19,  1.39s/it]Epoch: 0/10. Loss: 1.3310:  46%|[36m████▌     [0m| 12/26 [00:14<00:19,  1.39s/it]Epoch: 0/10. Loss: 1.3310:  50%|[36m█████     [0m| 13/26 [00:14<00:16,  1.25s/it]Epoch: 0/10. Loss: 1.4275:  50%|[36m█████     [0m| 13/26 [00:16<00:16,  1.25s/it]Epoch: 0/10. Loss: 1.4275:  54%|[36m█████▍    [0m| 14/26 [00:17<00:18,  1.53s/it]Epoch: 0/10. Loss: 1.3336:  54%|[36m█████▍    [0m| 14/26 [00:17<00:18,  1.53s/it]Epoch: 0/10. Loss: 1.3336:  58%|[36m█████▊    [0m| 15/26 [00:17<00:14,  1.36s/it]Epoch: 0/10. Loss: 1.3081:  58%|[36m█████▊    [0m| 15/26 [00:18<00:14,  1.36s/it]Epoch: 0/10. Loss: 1.3081:  62%|[36m██████▏   [0m| 16/26 [00:18<00:12,  1.21s/it]Epoch: 0/10. Loss: 1.1241:  62%|[36m██████▏   [0m| 16/26 [00:19<00:12,  1.21s/it]Epoch: 0/10. Loss: 1.1241:  65%|[36m██████▌   [0m| 17/26 [00:19<00:10,  1.13s/it]Epoch: 0/10. Loss: 1.7004:  65%|[36m██████▌   [0m| 17/26 [00:22<00:10,  1.13s/it]Epoch: 0/10. Loss: 1.7004:  69%|[36m██████▉   [0m| 18/26 [00:22<00:12,  1.53s/it]Epoch: 0/10. Loss: 1.2407:  69%|[36m██████▉   [0m| 18/26 [00:23<00:12,  1.53s/it]Epoch: 0/10. Loss: 1.2407:  73%|[36m███████▎  [0m| 19/26 [00:23<00:09,  1.34s/it]Epoch: 0/10. Loss: 1.5800:  73%|[36m███████▎  [0m| 19/26 [00:23<00:09,  1.34s/it]Epoch: 0/10. Loss: 1.5800:  77%|[36m███████▋  [0m| 20/26 [00:23<00:07,  1.19s/it]Epoch: 0/10. Loss: 1.8751:  77%|[36m███████▋  [0m| 20/26 [00:25<00:07,  1.19s/it]Epoch: 0/10. Loss: 1.8751:  81%|[36m████████  [0m| 21/26 [00:25<00:06,  1.27s/it]Epoch: 0/10. Loss: 1.1810:  81%|[36m████████  [0m| 21/26 [00:26<00:06,  1.27s/it]Epoch: 0/10. Loss: 1.1810:  85%|[36m████████▍ [0m| 22/26 [00:26<00:04,  1.23s/it]Epoch: 0/10. Loss: 1.0616:  85%|[36m████████▍ [0m| 22/26 [00:27<00:04,  1.23s/it]Epoch: 0/10. Loss: 1.0616:  88%|[36m████████▊ [0m| 23/26 [00:27<00:03,  1.14s/it]Epoch: 0/10. Loss: 1.2783:  88%|[36m████████▊ [0m| 23/26 [00:28<00:03,  1.14s/it]Epoch: 0/10. Loss: 1.2783:  92%|[36m█████████▏[0m| 24/26 [00:28<00:02,  1.03s/it]Epoch: 0/10. Loss: 1.4298:  92%|[36m█████████▏[0m| 24/26 [00:28<00:02,  1.03s/it]Epoch: 0/10. Loss: 1.4298:  96%|[36m█████████▌[0m| 25/26 [00:28<00:00,  1.08it/s]Epoch: 0/10. Loss: 1.1161:  96%|[36m█████████▌[0m| 25/26 [00:29<00:00,  1.08it/s]Epoch: 0/10. Loss: 1.1161: 100%|[36m██████████[0m| 26/26 [00:29<00:00,  1.16it/s]Epoch: 0/10. Loss: 1.1161: 100%|[36m██████████[0m| 26/26 [00:29<00:00,  1.14s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:04,  1.25it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:05,  1.14s/it] 43%|[33m████▎     [0m| 3/7 [00:02<00:03,  1.06it/s] 57%|[33m█████▋    [0m| 4/7 [00:04<00:03,  1.05s/it] 71%|[33m███████▏  [0m| 5/7 [00:04<00:01,  1.15it/s] 86%|[33m████████▌ [0m| 6/7 [00:05<00:00,  1.13it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.42it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.19it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 1/10. Loss: 1.0293:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 1/10. Loss: 1.0293:   4%|[36m▍         [0m| 1/26 [00:00<00:18,  1.35it/s]Epoch: 1/10. Loss: 1.2660:   4%|[36m▍         [0m| 1/26 [00:01<00:18,  1.35it/s]Epoch: 1/10. Loss: 1.2660:   8%|[36m▊         [0m| 2/26 [00:01<00:20,  1.17it/s]Epoch: 1/10. Loss: 1.1965:   8%|[36m▊         [0m| 2/26 [00:03<00:20,  1.17it/s]Epoch: 1/10. Loss: 1.1965:  12%|[36m█▏        [0m| 3/26 [00:03<00:30,  1.31s/it]Epoch: 1/10. Loss: 1.4248:  12%|[36m█▏        [0m| 3/26 [00:04<00:30,  1.31s/it]Epoch: 1/10. Loss: 1.4248:  15%|[36m█▌        [0m| 4/26 [00:04<00:26,  1.23s/it]Epoch: 1/10. Loss: 1.1737:  15%|[36m█▌        [0m| 4/26 [00:05<00:26,  1.23s/it]Epoch: 1/10. Loss: 1.1737:  19%|[36m█▉        [0m| 5/26 [00:05<00:23,  1.13s/it]Epoch: 1/10. Loss: 1.0111:  19%|[36m█▉        [0m| 5/26 [00:06<00:23,  1.13s/it]Epoch: 1/10. Loss: 1.0111:  23%|[36m██▎       [0m| 6/26 [00:06<00:20,  1.04s/it]Epoch: 1/10. Loss: 1.2072:  23%|[36m██▎       [0m| 6/26 [00:07<00:20,  1.04s/it]Epoch: 1/10. Loss: 1.2072:  27%|[36m██▋       [0m| 7/26 [00:07<00:18,  1.04it/s]Epoch: 1/10. Loss: 1.1973:  27%|[36m██▋       [0m| 7/26 [00:08<00:18,  1.04it/s]Epoch: 1/10. Loss: 1.1973:  31%|[36m███       [0m| 8/26 [00:08<00:16,  1.09it/s]Epoch: 1/10. Loss: 0.9955:  31%|[36m███       [0m| 8/26 [00:09<00:16,  1.09it/s]Epoch: 1/10. Loss: 0.9955:  35%|[36m███▍      [0m| 9/26 [00:09<00:16,  1.04it/s]Epoch: 1/10. Loss: 0.9904:  35%|[36m███▍      [0m| 9/26 [00:10<00:16,  1.04it/s]Epoch: 1/10. Loss: 0.9904:  38%|[36m███▊      [0m| 10/26 [00:10<00:15,  1.05it/s]Epoch: 1/10. Loss: 1.4500:  38%|[36m███▊      [0m| 10/26 [00:11<00:15,  1.05it/s]Epoch: 1/10. Loss: 1.4500:  42%|[36m████▏     [0m| 11/26 [00:11<00:15,  1.01s/it]Epoch: 1/10. Loss: 1.0025:  42%|[36m████▏     [0m| 11/26 [00:14<00:15,  1.01s/it]Epoch: 1/10. Loss: 1.0025:  46%|[36m████▌     [0m| 12/26 [00:14<00:23,  1.69s/it]Epoch: 1/10. Loss: 1.0122:  46%|[36m████▌     [0m| 12/26 [00:16<00:23,  1.69s/it]Epoch: 1/10. Loss: 1.0122:  50%|[36m█████     [0m| 13/26 [00:16<00:23,  1.83s/it]Epoch: 1/10. Loss: 1.0599:  50%|[36m█████     [0m| 13/26 [00:17<00:23,  1.83s/it]Epoch: 1/10. Loss: 1.0599:  54%|[36m█████▍    [0m| 14/26 [00:17<00:18,  1.57s/it]Epoch: 1/10. Loss: 1.0079:  54%|[36m█████▍    [0m| 14/26 [00:18<00:18,  1.57s/it]Epoch: 1/10. Loss: 1.0079:  58%|[36m█████▊    [0m| 15/26 [00:18<00:15,  1.41s/it]Epoch: 1/10. Loss: 1.0647:  58%|[36m█████▊    [0m| 15/26 [00:19<00:15,  1.41s/it]Epoch: 1/10. Loss: 1.0647:  62%|[36m██████▏   [0m| 16/26 [00:19<00:12,  1.24s/it]Epoch: 1/10. Loss: 1.0272:  62%|[36m██████▏   [0m| 16/26 [00:20<00:12,  1.24s/it]Epoch: 1/10. Loss: 1.0272:  65%|[36m██████▌   [0m| 17/26 [00:20<00:10,  1.17s/it]Epoch: 1/10. Loss: 0.9586:  65%|[36m██████▌   [0m| 17/26 [00:21<00:10,  1.17s/it]Epoch: 1/10. Loss: 0.9586:  69%|[36m██████▉   [0m| 18/26 [00:21<00:08,  1.09s/it]Epoch: 1/10. Loss: 0.9739:  69%|[36m██████▉   [0m| 18/26 [00:22<00:08,  1.09s/it]Epoch: 1/10. Loss: 0.9739:  73%|[36m███████▎  [0m| 19/26 [00:22<00:08,  1.22s/it]Epoch: 1/10. Loss: 0.9719:  73%|[36m███████▎  [0m| 19/26 [00:24<00:08,  1.22s/it]Epoch: 1/10. Loss: 0.9719:  77%|[36m███████▋  [0m| 20/26 [00:24<00:08,  1.36s/it]Epoch: 1/10. Loss: 1.1750:  77%|[36m███████▋  [0m| 20/26 [00:25<00:08,  1.36s/it]Epoch: 1/10. Loss: 1.1750:  81%|[36m████████  [0m| 21/26 [00:25<00:06,  1.29s/it]Epoch: 1/10. Loss: 1.0301:  81%|[36m████████  [0m| 21/26 [00:27<00:06,  1.29s/it]Epoch: 1/10. Loss: 1.0301:  85%|[36m████████▍ [0m| 22/26 [00:27<00:05,  1.30s/it]Epoch: 1/10. Loss: 0.9958:  85%|[36m████████▍ [0m| 22/26 [00:28<00:05,  1.30s/it]Epoch: 1/10. Loss: 0.9958:  88%|[36m████████▊ [0m| 23/26 [00:28<00:03,  1.22s/it]Epoch: 1/10. Loss: 0.9629:  88%|[36m████████▊ [0m| 23/26 [00:28<00:03,  1.22s/it]Epoch: 1/10. Loss: 0.9629:  92%|[36m█████████▏[0m| 24/26 [00:28<00:02,  1.13s/it]Epoch: 1/10. Loss: 1.3413:  92%|[36m█████████▏[0m| 24/26 [00:29<00:02,  1.13s/it]Epoch: 1/10. Loss: 1.3413:  96%|[36m█████████▌[0m| 25/26 [00:29<00:01,  1.07s/it]Epoch: 1/10. Loss: 0.9496:  96%|[36m█████████▌[0m| 25/26 [00:30<00:01,  1.07s/it]Epoch: 1/10. Loss: 0.9496: 100%|[36m██████████[0m| 26/26 [00:30<00:00,  1.07it/s]Epoch: 1/10. Loss: 0.9496: 100%|[36m██████████[0m| 26/26 [00:30<00:00,  1.17s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:01<00:10,  1.69s/it] 29%|[33m██▊       [0m| 2/7 [00:03<00:07,  1.57s/it] 43%|[33m████▎     [0m| 3/7 [00:03<00:04,  1.18s/it] 57%|[33m█████▋    [0m| 4/7 [00:05<00:03,  1.17s/it] 71%|[33m███████▏  [0m| 5/7 [00:05<00:01,  1.05it/s] 86%|[33m████████▌ [0m| 6/7 [00:06<00:00,  1.06it/s]100%|[33m██████████[0m| 7/7 [00:06<00:00,  1.35it/s]100%|[33m██████████[0m| 7/7 [00:06<00:00,  1.02it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 2/10. Loss: 1.0062:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 2/10. Loss: 1.0062:   4%|[36m▍         [0m| 1/26 [00:00<00:22,  1.12it/s]Epoch: 2/10. Loss: 0.9746:   4%|[36m▍         [0m| 1/26 [00:02<00:22,  1.12it/s]Epoch: 2/10. Loss: 0.9746:   8%|[36m▊         [0m| 2/26 [00:02<00:24,  1.04s/it]Epoch: 2/10. Loss: 1.0674:   8%|[36m▊         [0m| 2/26 [00:02<00:24,  1.04s/it]Epoch: 2/10. Loss: 1.0674:  12%|[36m█▏        [0m| 3/26 [00:02<00:21,  1.08it/s]Epoch: 2/10. Loss: 1.0372:  12%|[36m█▏        [0m| 3/26 [00:03<00:21,  1.08it/s]Epoch: 2/10. Loss: 1.0372:  15%|[36m█▌        [0m| 4/26 [00:03<00:20,  1.10it/s]Epoch: 2/10. Loss: 0.8792:  15%|[36m█▌        [0m| 4/26 [00:04<00:20,  1.10it/s]Epoch: 2/10. Loss: 0.8792:  19%|[36m█▉        [0m| 5/26 [00:04<00:20,  1.02it/s]Epoch: 2/10. Loss: 0.9959:  19%|[36m█▉        [0m| 5/26 [00:05<00:20,  1.02it/s]Epoch: 2/10. Loss: 0.9959:  23%|[36m██▎       [0m| 6/26 [00:05<00:19,  1.05it/s]Epoch: 2/10. Loss: 1.0503:  23%|[36m██▎       [0m| 6/26 [00:06<00:19,  1.05it/s]Epoch: 2/10. Loss: 1.0503:  27%|[36m██▋       [0m| 7/26 [00:06<00:17,  1.07it/s]Epoch: 2/10. Loss: 1.9167:  27%|[36m██▋       [0m| 7/26 [00:07<00:17,  1.07it/s]Epoch: 2/10. Loss: 1.9167:  31%|[36m███       [0m| 8/26 [00:07<00:16,  1.12it/s]Epoch: 2/10. Loss: 1.0656:  31%|[36m███       [0m| 8/26 [00:08<00:16,  1.12it/s]Epoch: 2/10. Loss: 1.0656:  35%|[36m███▍      [0m| 9/26 [00:08<00:15,  1.10it/s]Epoch: 2/10. Loss: 1.0617:  35%|[36m███▍      [0m| 9/26 [00:09<00:15,  1.10it/s]Epoch: 2/10. Loss: 1.0617:  38%|[36m███▊      [0m| 10/26 [00:09<00:14,  1.12it/s]Epoch: 2/10. Loss: 0.9640:  38%|[36m███▊      [0m| 10/26 [00:10<00:14,  1.12it/s]Epoch: 2/10. Loss: 0.9640:  42%|[36m████▏     [0m| 11/26 [00:10<00:13,  1.10it/s]Epoch: 2/10. Loss: 0.9534:  42%|[36m████▏     [0m| 11/26 [00:11<00:13,  1.10it/s]Epoch: 2/10. Loss: 0.9534:  46%|[36m████▌     [0m| 12/26 [00:11<00:12,  1.09it/s]Epoch: 2/10. Loss: 0.9743:  46%|[36m████▌     [0m| 12/26 [00:11<00:12,  1.09it/s]Epoch: 2/10. Loss: 0.9743:  50%|[36m█████     [0m| 13/26 [00:11<00:11,  1.13it/s]Epoch: 2/10. Loss: 1.0887:  50%|[36m█████     [0m| 13/26 [00:12<00:11,  1.13it/s]Epoch: 2/10. Loss: 1.0887:  54%|[36m█████▍    [0m| 14/26 [00:12<00:10,  1.18it/s]Epoch: 2/10. Loss: 1.0838:  54%|[36m█████▍    [0m| 14/26 [00:13<00:10,  1.18it/s]Epoch: 2/10. Loss: 1.0838:  58%|[36m█████▊    [0m| 15/26 [00:13<00:09,  1.12it/s]Epoch: 2/10. Loss: 0.9670:  58%|[36m█████▊    [0m| 15/26 [00:14<00:09,  1.12it/s]Epoch: 2/10. Loss: 0.9670:  62%|[36m██████▏   [0m| 16/26 [00:14<00:08,  1.13it/s]Epoch: 2/10. Loss: 1.2894:  62%|[36m██████▏   [0m| 16/26 [00:15<00:08,  1.13it/s]Epoch: 2/10. Loss: 1.2894:  65%|[36m██████▌   [0m| 17/26 [00:15<00:08,  1.03it/s]Epoch: 2/10. Loss: 1.0179:  65%|[36m██████▌   [0m| 17/26 [00:16<00:08,  1.03it/s]Epoch: 2/10. Loss: 1.0179:  69%|[36m██████▉   [0m| 18/26 [00:16<00:07,  1.05it/s]Epoch: 2/10. Loss: 1.0441:  69%|[36m██████▉   [0m| 18/26 [00:17<00:07,  1.05it/s]Epoch: 2/10. Loss: 1.0441:  73%|[36m███████▎  [0m| 19/26 [00:17<00:06,  1.08it/s]Epoch: 2/10. Loss: 1.1334:  73%|[36m███████▎  [0m| 19/26 [00:18<00:06,  1.08it/s]Epoch: 2/10. Loss: 1.1334:  77%|[36m███████▋  [0m| 20/26 [00:18<00:05,  1.06it/s]Epoch: 2/10. Loss: 1.2017:  77%|[36m███████▋  [0m| 20/26 [00:19<00:05,  1.06it/s]Epoch: 2/10. Loss: 1.2017:  81%|[36m████████  [0m| 21/26 [00:19<00:04,  1.08it/s]Epoch: 2/10. Loss: 1.0682:  81%|[36m████████  [0m| 21/26 [00:20<00:04,  1.08it/s]Epoch: 2/10. Loss: 1.0682:  85%|[36m████████▍ [0m| 22/26 [00:20<00:03,  1.07it/s]Epoch: 2/10. Loss: 0.9495:  85%|[36m████████▍ [0m| 22/26 [00:21<00:03,  1.07it/s]Epoch: 2/10. Loss: 0.9495:  88%|[36m████████▊ [0m| 23/26 [00:21<00:02,  1.05it/s]Epoch: 2/10. Loss: 0.9996:  88%|[36m████████▊ [0m| 23/26 [00:22<00:02,  1.05it/s]Epoch: 2/10. Loss: 0.9996:  92%|[36m█████████▏[0m| 24/26 [00:22<00:01,  1.09it/s]Epoch: 2/10. Loss: 1.0666:  92%|[36m█████████▏[0m| 24/26 [00:23<00:01,  1.09it/s]Epoch: 2/10. Loss: 1.0666:  96%|[36m█████████▌[0m| 25/26 [00:23<00:00,  1.09it/s]Epoch: 2/10. Loss: 1.0058:  96%|[36m█████████▌[0m| 25/26 [00:23<00:00,  1.09it/s]Epoch: 2/10. Loss: 1.0058: 100%|[36m██████████[0m| 26/26 [00:23<00:00,  1.21it/s]Epoch: 2/10. Loss: 1.0058: 100%|[36m██████████[0m| 26/26 [00:23<00:00,  1.10it/s]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:04,  1.20it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:05,  1.18s/it] 43%|[33m████▎     [0m| 3/7 [00:03<00:03,  1.01it/s] 57%|[33m█████▋    [0m| 4/7 [00:04<00:03,  1.07s/it] 71%|[33m███████▏  [0m| 5/7 [00:04<00:01,  1.12it/s] 86%|[33m████████▌ [0m| 6/7 [00:05<00:00,  1.11it/s]100%|[33m██████████[0m| 7/7 [00:06<00:00,  1.08it/s]100%|[33m██████████[0m| 7/7 [00:06<00:00,  1.05it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 3/10. Loss: 0.9818:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 3/10. Loss: 0.9818:   4%|[36m▍         [0m| 1/26 [00:00<00:24,  1.03it/s]Epoch: 3/10. Loss: 0.9939:   4%|[36m▍         [0m| 1/26 [00:01<00:24,  1.03it/s]Epoch: 3/10. Loss: 0.9939:   8%|[36m▊         [0m| 2/26 [00:01<00:22,  1.05it/s]Epoch: 3/10. Loss: 1.3984:   8%|[36m▊         [0m| 2/26 [00:05<00:22,  1.05it/s]Epoch: 3/10. Loss: 1.3984:  12%|[36m█▏        [0m| 3/26 [00:05<00:48,  2.10s/it]Epoch: 3/10. Loss: 1.0689:  12%|[36m█▏        [0m| 3/26 [00:06<00:48,  2.10s/it]Epoch: 3/10. Loss: 1.0689:  15%|[36m█▌        [0m| 4/26 [00:06<00:37,  1.71s/it]Epoch: 3/10. Loss: 0.9887:  15%|[36m█▌        [0m| 4/26 [00:07<00:37,  1.71s/it]Epoch: 3/10. Loss: 0.9887:  19%|[36m█▉        [0m| 5/26 [00:07<00:29,  1.40s/it]Epoch: 3/10. Loss: 0.9542:  19%|[36m█▉        [0m| 5/26 [00:08<00:29,  1.40s/it]Epoch: 3/10. Loss: 0.9542:  23%|[36m██▎       [0m| 6/26 [00:08<00:25,  1.26s/it]Epoch: 3/10. Loss: 1.0343:  23%|[36m██▎       [0m| 6/26 [00:09<00:25,  1.26s/it]Epoch: 3/10. Loss: 1.0343:  27%|[36m██▋       [0m| 7/26 [00:09<00:22,  1.19s/it]Epoch: 3/10. Loss: 0.9705:  27%|[36m██▋       [0m| 7/26 [00:10<00:22,  1.19s/it]Epoch: 3/10. Loss: 0.9705:  31%|[36m███       [0m| 8/26 [00:10<00:23,  1.31s/it]Epoch: 3/10. Loss: 1.0199:  31%|[36m███       [0m| 8/26 [00:11<00:23,  1.31s/it]Epoch: 3/10. Loss: 1.0199:  35%|[36m███▍      [0m| 9/26 [00:11<00:20,  1.19s/it]Epoch: 3/10. Loss: 0.9696:  35%|[36m███▍      [0m| 9/26 [00:12<00:20,  1.19s/it]Epoch: 3/10. Loss: 0.9696:  38%|[36m███▊      [0m| 10/26 [00:12<00:17,  1.08s/it]Epoch: 3/10. Loss: 0.9586:  38%|[36m███▊      [0m| 10/26 [00:13<00:17,  1.08s/it]Epoch: 3/10. Loss: 0.9586:  42%|[36m████▏     [0m| 11/26 [00:13<00:15,  1.04s/it]Epoch: 3/10. Loss: 0.9558:  42%|[36m████▏     [0m| 11/26 [00:14<00:15,  1.04s/it]Epoch: 3/10. Loss: 0.9558:  46%|[36m████▌     [0m| 12/26 [00:14<00:13,  1.01it/s]Epoch: 3/10. Loss: 1.7187:  46%|[36m████▌     [0m| 12/26 [00:15<00:13,  1.01it/s]Epoch: 3/10. Loss: 1.7187:  50%|[36m█████     [0m| 13/26 [00:15<00:12,  1.03it/s]Epoch: 3/10. Loss: 1.0001:  50%|[36m█████     [0m| 13/26 [00:16<00:12,  1.03it/s]Epoch: 3/10. Loss: 1.0001:  54%|[36m█████▍    [0m| 14/26 [00:16<00:10,  1.10it/s]Epoch: 3/10. Loss: 1.0346:  54%|[36m█████▍    [0m| 14/26 [00:17<00:10,  1.10it/s]Epoch: 3/10. Loss: 1.0346:  58%|[36m█████▊    [0m| 15/26 [00:17<00:12,  1.09s/it]Epoch: 3/10. Loss: 0.9643:  58%|[36m█████▊    [0m| 15/26 [00:18<00:12,  1.09s/it]Epoch: 3/10. Loss: 0.9643:  62%|[36m██████▏   [0m| 16/26 [00:18<00:10,  1.07s/it]Epoch: 3/10. Loss: 0.9359:  62%|[36m██████▏   [0m| 16/26 [00:19<00:10,  1.07s/it]Epoch: 3/10. Loss: 0.9359:  65%|[36m██████▌   [0m| 17/26 [00:19<00:09,  1.01s/it]Epoch: 3/10. Loss: 1.0384:  65%|[36m██████▌   [0m| 17/26 [00:21<00:09,  1.01s/it]Epoch: 3/10. Loss: 1.0384:  69%|[36m██████▉   [0m| 18/26 [00:21<00:09,  1.19s/it]Epoch: 3/10. Loss: 0.9826:  69%|[36m██████▉   [0m| 18/26 [00:22<00:09,  1.19s/it]Epoch: 3/10. Loss: 0.9826:  73%|[36m███████▎  [0m| 19/26 [00:22<00:07,  1.11s/it]Epoch: 3/10. Loss: 0.9134:  73%|[36m███████▎  [0m| 19/26 [00:22<00:07,  1.11s/it]Epoch: 3/10. Loss: 0.9134:  77%|[36m███████▋  [0m| 20/26 [00:22<00:06,  1.03s/it]Epoch: 3/10. Loss: 1.0669:  77%|[36m███████▋  [0m| 20/26 [00:23<00:06,  1.03s/it]Epoch: 3/10. Loss: 1.0669:  81%|[36m████████  [0m| 21/26 [00:23<00:05,  1.00s/it]Epoch: 3/10. Loss: 1.0888:  81%|[36m████████  [0m| 21/26 [00:25<00:05,  1.00s/it]Epoch: 3/10. Loss: 1.0888:  85%|[36m████████▍ [0m| 22/26 [00:25<00:04,  1.03s/it]Epoch: 3/10. Loss: 1.0431:  85%|[36m████████▍ [0m| 22/26 [00:25<00:04,  1.03s/it]Epoch: 3/10. Loss: 1.0431:  88%|[36m████████▊ [0m| 23/26 [00:25<00:03,  1.00s/it]Epoch: 3/10. Loss: 1.0227:  88%|[36m████████▊ [0m| 23/26 [00:29<00:03,  1.00s/it]Epoch: 3/10. Loss: 1.0227:  92%|[36m█████████▏[0m| 24/26 [00:29<00:03,  1.80s/it]Epoch: 3/10. Loss: 1.1185:  92%|[36m█████████▏[0m| 24/26 [00:30<00:03,  1.80s/it]Epoch: 3/10. Loss: 1.1185:  96%|[36m█████████▌[0m| 25/26 [00:30<00:01,  1.57s/it]Epoch: 3/10. Loss: 0.9948:  96%|[36m█████████▌[0m| 25/26 [00:31<00:01,  1.57s/it]Epoch: 3/10. Loss: 0.9948: 100%|[36m██████████[0m| 26/26 [00:31<00:00,  1.29s/it]Epoch: 3/10. Loss: 0.9948: 100%|[36m██████████[0m| 26/26 [00:31<00:00,  1.20s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:02<00:14,  2.37s/it] 29%|[33m██▊       [0m| 2/7 [00:04<00:10,  2.03s/it] 43%|[33m████▎     [0m| 3/7 [00:04<00:05,  1.39s/it] 57%|[33m█████▋    [0m| 4/7 [00:05<00:03,  1.28s/it] 71%|[33m███████▏  [0m| 5/7 [00:06<00:01,  1.01it/s] 86%|[33m████████▌ [0m| 6/7 [00:07<00:00,  1.07it/s]100%|[33m██████████[0m| 7/7 [00:07<00:00,  1.20it/s]100%|[33m██████████[0m| 7/7 [00:07<00:00,  1.12s/it]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 4/10. Loss: 1.0687:   0%|[36m          [0m| 0/26 [00:01<?, ?it/s]Epoch: 4/10. Loss: 1.0687:   4%|[36m▍         [0m| 1/26 [00:01<00:29,  1.19s/it]Epoch: 4/10. Loss: 1.0585:   4%|[36m▍         [0m| 1/26 [00:02<00:29,  1.19s/it]Epoch: 4/10. Loss: 1.0585:   8%|[36m▊         [0m| 2/26 [00:02<00:24,  1.00s/it]Epoch: 4/10. Loss: 0.9756:   8%|[36m▊         [0m| 2/26 [00:03<00:24,  1.00s/it]Epoch: 4/10. Loss: 0.9756:  12%|[36m█▏        [0m| 3/26 [00:03<00:24,  1.06s/it]Epoch: 4/10. Loss: 0.9487:  12%|[36m█▏        [0m| 3/26 [00:04<00:24,  1.06s/it]Epoch: 4/10. Loss: 0.9487:  15%|[36m█▌        [0m| 4/26 [00:04<00:21,  1.02it/s]Epoch: 4/10. Loss: 0.9547:  15%|[36m█▌        [0m| 4/26 [00:05<00:21,  1.02it/s]Epoch: 4/10. Loss: 0.9547:  19%|[36m█▉        [0m| 5/26 [00:05<00:21,  1.02s/it]Epoch: 4/10. Loss: 1.0051:  19%|[36m█▉        [0m| 5/26 [00:06<00:21,  1.02s/it]Epoch: 4/10. Loss: 1.0051:  23%|[36m██▎       [0m| 6/26 [00:06<00:19,  1.03it/s]Epoch: 4/10. Loss: 1.1061:  23%|[36m██▎       [0m| 6/26 [00:07<00:19,  1.03it/s]Epoch: 4/10. Loss: 1.1061:  27%|[36m██▋       [0m| 7/26 [00:07<00:18,  1.01it/s]Epoch: 4/10. Loss: 1.0580:  27%|[36m██▋       [0m| 7/26 [00:07<00:18,  1.01it/s]Epoch: 4/10. Loss: 1.0580:  31%|[36m███       [0m| 8/26 [00:07<00:16,  1.07it/s]Epoch: 4/10. Loss: 0.9355:  31%|[36m███       [0m| 8/26 [00:08<00:16,  1.07it/s]Epoch: 4/10. Loss: 0.9355:  35%|[36m███▍      [0m| 9/26 [00:08<00:15,  1.10it/s]Epoch: 4/10. Loss: 0.9424:  35%|[36m███▍      [0m| 9/26 [00:09<00:15,  1.10it/s]Epoch: 4/10. Loss: 0.9424:  38%|[36m███▊      [0m| 10/26 [00:09<00:15,  1.04it/s]Epoch: 4/10. Loss: 1.0636:  38%|[36m███▊      [0m| 10/26 [00:10<00:15,  1.04it/s]Epoch: 4/10. Loss: 1.0636:  42%|[36m████▏     [0m| 11/26 [00:10<00:14,  1.07it/s]Epoch: 4/10. Loss: 1.1512:  42%|[36m████▏     [0m| 11/26 [00:11<00:14,  1.07it/s]Epoch: 4/10. Loss: 1.1512:  46%|[36m████▌     [0m| 12/26 [00:11<00:12,  1.09it/s]Epoch: 4/10. Loss: 0.9083:  46%|[36m████▌     [0m| 12/26 [00:12<00:12,  1.09it/s]Epoch: 4/10. Loss: 0.9083:  50%|[36m█████     [0m| 13/26 [00:12<00:12,  1.06it/s]Epoch: 4/10. Loss: 0.8837:  50%|[36m█████     [0m| 13/26 [00:13<00:12,  1.06it/s]Epoch: 4/10. Loss: 0.8837:  54%|[36m█████▍    [0m| 14/26 [00:13<00:11,  1.02it/s]Epoch: 4/10. Loss: 0.9316:  54%|[36m█████▍    [0m| 14/26 [00:14<00:11,  1.02it/s]Epoch: 4/10. Loss: 0.9316:  58%|[36m█████▊    [0m| 15/26 [00:14<00:10,  1.02it/s]Epoch: 4/10. Loss: 1.0996:  58%|[36m█████▊    [0m| 15/26 [00:15<00:10,  1.02it/s]Epoch: 4/10. Loss: 1.0996:  62%|[36m██████▏   [0m| 16/26 [00:15<00:09,  1.00it/s]Epoch: 4/10. Loss: 0.9349:  62%|[36m██████▏   [0m| 16/26 [00:16<00:09,  1.00it/s]Epoch: 4/10. Loss: 0.9349:  65%|[36m██████▌   [0m| 17/26 [00:16<00:09,  1.00s/it]Epoch: 4/10. Loss: 0.8629:  65%|[36m██████▌   [0m| 17/26 [00:17<00:09,  1.00s/it]Epoch: 4/10. Loss: 0.8629:  69%|[36m██████▉   [0m| 18/26 [00:17<00:07,  1.03it/s]Epoch: 4/10. Loss: 1.0194:  69%|[36m██████▉   [0m| 18/26 [00:18<00:07,  1.03it/s]Epoch: 4/10. Loss: 1.0194:  73%|[36m███████▎  [0m| 19/26 [00:18<00:06,  1.06it/s]Epoch: 4/10. Loss: 0.8370:  73%|[36m███████▎  [0m| 19/26 [00:19<00:06,  1.06it/s]Epoch: 4/10. Loss: 0.8370:  77%|[36m███████▋  [0m| 20/26 [00:19<00:05,  1.09it/s]Epoch: 4/10. Loss: 0.9321:  77%|[36m███████▋  [0m| 20/26 [00:21<00:05,  1.09it/s]Epoch: 4/10. Loss: 0.9321:  81%|[36m████████  [0m| 21/26 [00:21<00:06,  1.27s/it]Epoch: 4/10. Loss: 1.0236:  81%|[36m████████  [0m| 21/26 [00:22<00:06,  1.27s/it]Epoch: 4/10. Loss: 1.0236:  85%|[36m████████▍ [0m| 22/26 [00:22<00:04,  1.19s/it]Epoch: 4/10. Loss: 0.9408:  85%|[36m████████▍ [0m| 22/26 [00:23<00:04,  1.19s/it]Epoch: 4/10. Loss: 0.9408:  88%|[36m████████▊ [0m| 23/26 [00:23<00:03,  1.12s/it]Epoch: 4/10. Loss: 0.9508:  88%|[36m████████▊ [0m| 23/26 [00:24<00:03,  1.12s/it]Epoch: 4/10. Loss: 0.9508:  92%|[36m█████████▏[0m| 24/26 [00:24<00:02,  1.08s/it]Epoch: 4/10. Loss: 1.0287:  92%|[36m█████████▏[0m| 24/26 [00:25<00:02,  1.08s/it]Epoch: 4/10. Loss: 1.0287:  96%|[36m█████████▌[0m| 25/26 [00:25<00:01,  1.07s/it]Epoch: 4/10. Loss: 0.9404:  96%|[36m█████████▌[0m| 25/26 [00:25<00:01,  1.07s/it]Epoch: 4/10. Loss: 0.9404: 100%|[36m██████████[0m| 26/26 [00:26<00:00,  1.06it/s]Epoch: 4/10. Loss: 0.9404: 100%|[36m██████████[0m| 26/26 [00:26<00:00,  1.00s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:04,  1.32it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:05,  1.10s/it] 43%|[33m████▎     [0m| 3/7 [00:02<00:03,  1.11it/s] 57%|[33m█████▋    [0m| 4/7 [00:03<00:03,  1.01s/it] 71%|[33m███████▏  [0m| 5/7 [00:05<00:02,  1.07s/it] 86%|[33m████████▌ [0m| 6/7 [00:06<00:01,  1.06s/it]100%|[33m██████████[0m| 7/7 [00:06<00:00,  1.22it/s]100%|[33m██████████[0m| 7/7 [00:06<00:00,  1.08it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 5/10. Loss: 0.9571:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 5/10. Loss: 0.9571:   4%|[36m▍         [0m| 1/26 [00:00<00:23,  1.04it/s]Epoch: 5/10. Loss: 0.9381:   4%|[36m▍         [0m| 1/26 [00:01<00:23,  1.04it/s]Epoch: 5/10. Loss: 0.9381:   8%|[36m▊         [0m| 2/26 [00:01<00:22,  1.07it/s]Epoch: 5/10. Loss: 0.9462:   8%|[36m▊         [0m| 2/26 [00:02<00:22,  1.07it/s]Epoch: 5/10. Loss: 0.9462:  12%|[36m█▏        [0m| 3/26 [00:02<00:21,  1.07it/s]Epoch: 5/10. Loss: 0.9264:  12%|[36m█▏        [0m| 3/26 [00:03<00:21,  1.07it/s]Epoch: 5/10. Loss: 0.9264:  15%|[36m█▌        [0m| 4/26 [00:03<00:19,  1.11it/s]Epoch: 5/10. Loss: 0.9071:  15%|[36m█▌        [0m| 4/26 [00:04<00:19,  1.11it/s]Epoch: 5/10. Loss: 0.9071:  19%|[36m█▉        [0m| 5/26 [00:04<00:18,  1.17it/s]Epoch: 5/10. Loss: 1.0559:  19%|[36m█▉        [0m| 5/26 [00:05<00:18,  1.17it/s]Epoch: 5/10. Loss: 1.0559:  23%|[36m██▎       [0m| 6/26 [00:05<00:18,  1.06it/s]Epoch: 5/10. Loss: 0.9599:  23%|[36m██▎       [0m| 6/26 [00:06<00:18,  1.06it/s]Epoch: 5/10. Loss: 0.9599:  27%|[36m██▋       [0m| 7/26 [00:06<00:18,  1.01it/s]Epoch: 5/10. Loss: 0.8430:  27%|[36m██▋       [0m| 7/26 [00:07<00:18,  1.01it/s]Epoch: 5/10. Loss: 0.8430:  31%|[36m███       [0m| 8/26 [00:07<00:18,  1.02s/it]Epoch: 5/10. Loss: 1.0352:  31%|[36m███       [0m| 8/26 [00:08<00:18,  1.02s/it]Epoch: 5/10. Loss: 1.0352:  35%|[36m███▍      [0m| 9/26 [00:08<00:17,  1.01s/it]Epoch: 5/10. Loss: 0.9499:  35%|[36m███▍      [0m| 9/26 [00:09<00:17,  1.01s/it]Epoch: 5/10. Loss: 0.9499:  38%|[36m███▊      [0m| 10/26 [00:09<00:15,  1.02it/s]Epoch: 5/10. Loss: 0.9795:  38%|[36m███▊      [0m| 10/26 [00:10<00:15,  1.02it/s]Epoch: 5/10. Loss: 0.9795:  42%|[36m████▏     [0m| 11/26 [00:10<00:14,  1.00it/s]Epoch: 5/10. Loss: 0.9510:  42%|[36m████▏     [0m| 11/26 [00:11<00:14,  1.00it/s]Epoch: 5/10. Loss: 0.9510:  46%|[36m████▌     [0m| 12/26 [00:11<00:13,  1.00it/s]Epoch: 5/10. Loss: 1.0331:  46%|[36m████▌     [0m| 12/26 [00:12<00:13,  1.00it/s]Epoch: 5/10. Loss: 1.0331:  50%|[36m█████     [0m| 13/26 [00:12<00:12,  1.06it/s]Epoch: 5/10. Loss: 0.9504:  50%|[36m█████     [0m| 13/26 [00:13<00:12,  1.06it/s]Epoch: 5/10. Loss: 0.9504:  54%|[36m█████▍    [0m| 14/26 [00:13<00:10,  1.11it/s]Epoch: 5/10. Loss: 0.9146:  54%|[36m█████▍    [0m| 14/26 [00:14<00:10,  1.11it/s]Epoch: 5/10. Loss: 0.9146:  58%|[36m█████▊    [0m| 15/26 [00:14<00:10,  1.10it/s]Epoch: 5/10. Loss: 0.9769:  58%|[36m█████▊    [0m| 15/26 [00:15<00:10,  1.10it/s]Epoch: 5/10. Loss: 0.9769:  62%|[36m██████▏   [0m| 16/26 [00:15<00:11,  1.16s/it]Epoch: 5/10. Loss: 0.9462:  62%|[36m██████▏   [0m| 16/26 [00:16<00:11,  1.16s/it]Epoch: 5/10. Loss: 0.9462:  65%|[36m██████▌   [0m| 17/26 [00:16<00:09,  1.10s/it]Epoch: 5/10. Loss: 0.8790:  65%|[36m██████▌   [0m| 17/26 [00:18<00:09,  1.10s/it]Epoch: 5/10. Loss: 0.8790:  69%|[36m██████▉   [0m| 18/26 [00:18<00:09,  1.22s/it]Epoch: 5/10. Loss: 0.9281:  69%|[36m██████▉   [0m| 18/26 [00:21<00:09,  1.22s/it]Epoch: 5/10. Loss: 0.9281:  73%|[36m███████▎  [0m| 19/26 [00:21<00:12,  1.76s/it]Epoch: 5/10. Loss: 0.9221:  73%|[36m███████▎  [0m| 19/26 [00:23<00:12,  1.76s/it]Epoch: 5/10. Loss: 0.9221:  77%|[36m███████▋  [0m| 20/26 [00:23<00:10,  1.75s/it]Epoch: 5/10. Loss: 0.9187:  77%|[36m███████▋  [0m| 20/26 [00:23<00:10,  1.75s/it]Epoch: 5/10. Loss: 0.9187:  81%|[36m████████  [0m| 21/26 [00:23<00:07,  1.46s/it]Epoch: 5/10. Loss: 0.9313:  81%|[36m████████  [0m| 21/26 [00:24<00:07,  1.46s/it]Epoch: 5/10. Loss: 0.9313:  85%|[36m████████▍ [0m| 22/26 [00:24<00:05,  1.27s/it]Epoch: 5/10. Loss: 0.9523:  85%|[36m████████▍ [0m| 22/26 [00:25<00:05,  1.27s/it]Epoch: 5/10. Loss: 0.9523:  88%|[36m████████▊ [0m| 23/26 [00:25<00:03,  1.16s/it]Epoch: 5/10. Loss: 0.8680:  88%|[36m████████▊ [0m| 23/26 [00:26<00:03,  1.16s/it]Epoch: 5/10. Loss: 0.8680:  92%|[36m█████████▏[0m| 24/26 [00:26<00:02,  1.13s/it]Epoch: 5/10. Loss: 0.9200:  92%|[36m█████████▏[0m| 24/26 [00:27<00:02,  1.13s/it]Epoch: 5/10. Loss: 0.9200:  96%|[36m█████████▌[0m| 25/26 [00:27<00:01,  1.03s/it]Epoch: 5/10. Loss: 0.9433:  96%|[36m█████████▌[0m| 25/26 [00:28<00:01,  1.03s/it]Epoch: 5/10. Loss: 0.9433: 100%|[36m██████████[0m| 26/26 [00:28<00:00,  1.14it/s]Epoch: 5/10. Loss: 0.9433: 100%|[36m██████████[0m| 26/26 [00:28<00:00,  1.08s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:01<00:06,  1.11s/it] 29%|[33m██▊       [0m| 2/7 [00:02<00:06,  1.24s/it] 43%|[33m████▎     [0m| 3/7 [00:03<00:03,  1.01it/s] 57%|[33m█████▋    [0m| 4/7 [00:04<00:03,  1.05s/it] 71%|[33m███████▏  [0m| 5/7 [00:04<00:01,  1.17it/s] 86%|[33m████████▌ [0m| 6/7 [00:05<00:00,  1.16it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.45it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.17it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 6/10. Loss: 0.9033:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 6/10. Loss: 0.9033:   4%|[36m▍         [0m| 1/26 [00:00<00:24,  1.03it/s]Epoch: 6/10. Loss: 0.8235:   4%|[36m▍         [0m| 1/26 [00:01<00:24,  1.03it/s]Epoch: 6/10. Loss: 0.8235:   8%|[36m▊         [0m| 2/26 [00:01<00:19,  1.21it/s]Epoch: 6/10. Loss: 0.9701:   8%|[36m▊         [0m| 2/26 [00:02<00:19,  1.21it/s]Epoch: 6/10. Loss: 0.9701:  12%|[36m█▏        [0m| 3/26 [00:02<00:20,  1.12it/s]Epoch: 6/10. Loss: 0.9246:  12%|[36m█▏        [0m| 3/26 [00:03<00:20,  1.12it/s]Epoch: 6/10. Loss: 0.9246:  15%|[36m█▌        [0m| 4/26 [00:03<00:21,  1.03it/s]Epoch: 6/10. Loss: 0.9227:  15%|[36m█▌        [0m| 4/26 [00:04<00:21,  1.03it/s]Epoch: 6/10. Loss: 0.9227:  19%|[36m█▉        [0m| 5/26 [00:04<00:19,  1.07it/s]Epoch: 6/10. Loss: 0.9080:  19%|[36m█▉        [0m| 5/26 [00:05<00:19,  1.07it/s]Epoch: 6/10. Loss: 0.9080:  23%|[36m██▎       [0m| 6/26 [00:05<00:18,  1.09it/s]Epoch: 6/10. Loss: 0.9155:  23%|[36m██▎       [0m| 6/26 [00:06<00:18,  1.09it/s]Epoch: 6/10. Loss: 0.9155:  27%|[36m██▋       [0m| 7/26 [00:06<00:18,  1.04it/s]Epoch: 6/10. Loss: 0.8560:  27%|[36m██▋       [0m| 7/26 [00:07<00:18,  1.04it/s]Epoch: 6/10. Loss: 0.8560:  31%|[36m███       [0m| 8/26 [00:07<00:16,  1.07it/s]Epoch: 6/10. Loss: 0.8830:  31%|[36m███       [0m| 8/26 [00:08<00:16,  1.07it/s]Epoch: 6/10. Loss: 0.8830:  35%|[36m███▍      [0m| 9/26 [00:08<00:15,  1.09it/s]Epoch: 6/10. Loss: 0.9439:  35%|[36m███▍      [0m| 9/26 [00:09<00:15,  1.09it/s]Epoch: 6/10. Loss: 0.9439:  38%|[36m███▊      [0m| 10/26 [00:09<00:15,  1.07it/s]Epoch: 6/10. Loss: 0.8748:  38%|[36m███▊      [0m| 10/26 [00:10<00:15,  1.07it/s]Epoch: 6/10. Loss: 0.8748:  42%|[36m████▏     [0m| 11/26 [00:10<00:13,  1.09it/s]Epoch: 6/10. Loss: 0.7725:  42%|[36m████▏     [0m| 11/26 [00:11<00:13,  1.09it/s]Epoch: 6/10. Loss: 0.7725:  46%|[36m████▌     [0m| 12/26 [00:11<00:15,  1.08s/it]Epoch: 6/10. Loss: 0.8825:  46%|[36m████▌     [0m| 12/26 [00:12<00:15,  1.08s/it]Epoch: 6/10. Loss: 0.8825:  50%|[36m█████     [0m| 13/26 [00:12<00:13,  1.07s/it]Epoch: 6/10. Loss: 0.9739:  50%|[36m█████     [0m| 13/26 [00:13<00:13,  1.07s/it]Epoch: 6/10. Loss: 0.9739:  54%|[36m█████▍    [0m| 14/26 [00:13<00:12,  1.04s/it]Epoch: 6/10. Loss: 0.8489:  54%|[36m█████▍    [0m| 14/26 [00:14<00:12,  1.04s/it]Epoch: 6/10. Loss: 0.8489:  58%|[36m█████▊    [0m| 15/26 [00:14<00:11,  1.02s/it]Epoch: 6/10. Loss: 0.9106:  58%|[36m█████▊    [0m| 15/26 [00:15<00:11,  1.02s/it]Epoch: 6/10. Loss: 0.9106:  62%|[36m██████▏   [0m| 16/26 [00:15<00:09,  1.02it/s]Epoch: 6/10. Loss: 0.8939:  62%|[36m██████▏   [0m| 16/26 [00:17<00:09,  1.02it/s]Epoch: 6/10. Loss: 0.8939:  65%|[36m██████▌   [0m| 17/26 [00:17<00:10,  1.18s/it]Epoch: 6/10. Loss: 0.8792:  65%|[36m██████▌   [0m| 17/26 [00:18<00:10,  1.18s/it]Epoch: 6/10. Loss: 0.8792:  69%|[36m██████▉   [0m| 18/26 [00:18<00:09,  1.14s/it]Epoch: 6/10. Loss: 1.1051:  69%|[36m██████▉   [0m| 18/26 [00:19<00:09,  1.14s/it]Epoch: 6/10. Loss: 1.1051:  73%|[36m███████▎  [0m| 19/26 [00:19<00:07,  1.06s/it]Epoch: 6/10. Loss: 0.8372:  73%|[36m███████▎  [0m| 19/26 [00:20<00:07,  1.06s/it]Epoch: 6/10. Loss: 0.8372:  77%|[36m███████▋  [0m| 20/26 [00:20<00:06,  1.03s/it]Epoch: 6/10. Loss: 1.1641:  77%|[36m███████▋  [0m| 20/26 [00:21<00:06,  1.03s/it]Epoch: 6/10. Loss: 1.1641:  81%|[36m████████  [0m| 21/26 [00:21<00:05,  1.16s/it]Epoch: 6/10. Loss: 0.9821:  81%|[36m████████  [0m| 21/26 [00:22<00:05,  1.16s/it]Epoch: 6/10. Loss: 0.9821:  85%|[36m████████▍ [0m| 22/26 [00:22<00:04,  1.25s/it]Epoch: 6/10. Loss: 1.0422:  85%|[36m████████▍ [0m| 22/26 [00:24<00:04,  1.25s/it]Epoch: 6/10. Loss: 1.0422:  88%|[36m████████▊ [0m| 23/26 [00:24<00:04,  1.34s/it]Epoch: 6/10. Loss: 1.0518:  88%|[36m████████▊ [0m| 23/26 [00:25<00:04,  1.34s/it]Epoch: 6/10. Loss: 1.0518:  92%|[36m█████████▏[0m| 24/26 [00:25<00:02,  1.20s/it]Epoch: 6/10. Loss: 0.9541:  92%|[36m█████████▏[0m| 24/26 [00:26<00:02,  1.20s/it]Epoch: 6/10. Loss: 0.9541:  96%|[36m█████████▌[0m| 25/26 [00:26<00:01,  1.11s/it]Epoch: 6/10. Loss: 0.9223:  96%|[36m█████████▌[0m| 25/26 [00:26<00:01,  1.11s/it]Epoch: 6/10. Loss: 0.9223: 100%|[36m██████████[0m| 26/26 [00:26<00:00,  1.01it/s]Epoch: 6/10. Loss: 0.9223: 100%|[36m██████████[0m| 26/26 [00:26<00:00,  1.04s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:04,  1.27it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:05,  1.13s/it] 43%|[33m████▎     [0m| 3/7 [00:02<00:03,  1.08it/s] 57%|[33m█████▋    [0m| 4/7 [00:04<00:03,  1.11s/it] 71%|[33m███████▏  [0m| 5/7 [00:04<00:01,  1.11it/s] 86%|[33m████████▌ [0m| 6/7 [00:05<00:00,  1.09it/s]100%|[33m██████████[0m| 7/7 [00:06<00:00,  1.37it/s]100%|[33m██████████[0m| 7/7 [00:06<00:00,  1.15it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 7/10. Loss: 0.8074:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 7/10. Loss: 0.8074:   4%|[36m▍         [0m| 1/26 [00:00<00:24,  1.01it/s]Epoch: 7/10. Loss: 0.8863:   4%|[36m▍         [0m| 1/26 [00:01<00:24,  1.01it/s]Epoch: 7/10. Loss: 0.8863:   8%|[36m▊         [0m| 2/26 [00:01<00:22,  1.06it/s]Epoch: 7/10. Loss: 0.8989:   8%|[36m▊         [0m| 2/26 [00:02<00:22,  1.06it/s]Epoch: 7/10. Loss: 0.8989:  12%|[36m█▏        [0m| 3/26 [00:02<00:21,  1.09it/s]Epoch: 7/10. Loss: 0.9732:  12%|[36m█▏        [0m| 3/26 [00:03<00:21,  1.09it/s]Epoch: 7/10. Loss: 0.9732:  15%|[36m█▌        [0m| 4/26 [00:03<00:19,  1.10it/s]Epoch: 7/10. Loss: 1.1918:  15%|[36m█▌        [0m| 4/26 [00:04<00:19,  1.10it/s]Epoch: 7/10. Loss: 1.1918:  19%|[36m█▉        [0m| 5/26 [00:04<00:19,  1.07it/s]Epoch: 7/10. Loss: 1.2489:  19%|[36m█▉        [0m| 5/26 [00:05<00:19,  1.07it/s]Epoch: 7/10. Loss: 1.2489:  23%|[36m██▎       [0m| 6/26 [00:05<00:18,  1.11it/s]Epoch: 7/10. Loss: 0.9628:  23%|[36m██▎       [0m| 6/26 [00:06<00:18,  1.11it/s]Epoch: 7/10. Loss: 0.9628:  27%|[36m██▋       [0m| 7/26 [00:06<00:17,  1.11it/s]Epoch: 7/10. Loss: 0.8568:  27%|[36m██▋       [0m| 7/26 [00:07<00:17,  1.11it/s]Epoch: 7/10. Loss: 0.8568:  31%|[36m███       [0m| 8/26 [00:07<00:15,  1.15it/s]Epoch: 7/10. Loss: 1.1566:  31%|[36m███       [0m| 8/26 [00:07<00:15,  1.15it/s]Epoch: 7/10. Loss: 1.1566:  35%|[36m███▍      [0m| 9/26 [00:07<00:13,  1.27it/s]Epoch: 7/10. Loss: 1.1787:  35%|[36m███▍      [0m| 9/26 [00:09<00:13,  1.27it/s]Epoch: 7/10. Loss: 1.1787:  38%|[36m███▊      [0m| 10/26 [00:09<00:14,  1.08it/s]Epoch: 7/10. Loss: 0.9162:  38%|[36m███▊      [0m| 10/26 [00:10<00:14,  1.08it/s]Epoch: 7/10. Loss: 0.9162:  42%|[36m████▏     [0m| 11/26 [00:10<00:14,  1.05it/s]Epoch: 7/10. Loss: 0.9025:  42%|[36m████▏     [0m| 11/26 [00:10<00:14,  1.05it/s]Epoch: 7/10. Loss: 0.9025:  46%|[36m████▌     [0m| 12/26 [00:10<00:13,  1.06it/s]Epoch: 7/10. Loss: 0.9980:  46%|[36m████▌     [0m| 12/26 [00:11<00:13,  1.06it/s]Epoch: 7/10. Loss: 0.9980:  50%|[36m█████     [0m| 13/26 [00:11<00:12,  1.04it/s]Epoch: 7/10. Loss: 0.9450:  50%|[36m█████     [0m| 13/26 [00:12<00:12,  1.04it/s]Epoch: 7/10. Loss: 0.9450:  54%|[36m█████▍    [0m| 14/26 [00:12<00:11,  1.05it/s]Epoch: 7/10. Loss: 0.9321:  54%|[36m█████▍    [0m| 14/26 [00:13<00:11,  1.05it/s]Epoch: 7/10. Loss: 0.9321:  58%|[36m█████▊    [0m| 15/26 [00:13<00:10,  1.07it/s]Epoch: 7/10. Loss: 0.8865:  58%|[36m█████▊    [0m| 15/26 [00:14<00:10,  1.07it/s]Epoch: 7/10. Loss: 0.8865:  62%|[36m██████▏   [0m| 16/26 [00:14<00:09,  1.09it/s]Epoch: 7/10. Loss: 0.8567:  62%|[36m██████▏   [0m| 16/26 [00:15<00:09,  1.09it/s]Epoch: 7/10. Loss: 0.8567:  65%|[36m██████▌   [0m| 17/26 [00:15<00:08,  1.10it/s]Epoch: 7/10. Loss: 0.8407:  65%|[36m██████▌   [0m| 17/26 [00:16<00:08,  1.10it/s]Epoch: 7/10. Loss: 0.8407:  69%|[36m██████▉   [0m| 18/26 [00:16<00:07,  1.09it/s]Epoch: 7/10. Loss: 1.0880:  69%|[36m██████▉   [0m| 18/26 [00:17<00:07,  1.09it/s]Epoch: 7/10. Loss: 1.0880:  73%|[36m███████▎  [0m| 19/26 [00:17<00:06,  1.02it/s]Epoch: 7/10. Loss: 1.1656:  73%|[36m███████▎  [0m| 19/26 [00:18<00:06,  1.02it/s]Epoch: 7/10. Loss: 1.1656:  77%|[36m███████▋  [0m| 20/26 [00:18<00:05,  1.03it/s]Epoch: 7/10. Loss: 0.8839:  77%|[36m███████▋  [0m| 20/26 [00:19<00:05,  1.03it/s]Epoch: 7/10. Loss: 0.8839:  81%|[36m████████  [0m| 21/26 [00:19<00:04,  1.05it/s]Epoch: 7/10. Loss: 0.8883:  81%|[36m████████  [0m| 21/26 [00:22<00:04,  1.05it/s]Epoch: 7/10. Loss: 0.8883:  85%|[36m████████▍ [0m| 22/26 [00:22<00:06,  1.54s/it]Epoch: 7/10. Loss: 0.8655:  85%|[36m████████▍ [0m| 22/26 [00:23<00:06,  1.54s/it]Epoch: 7/10. Loss: 0.8655:  88%|[36m████████▊ [0m| 23/26 [00:23<00:04,  1.37s/it]Epoch: 7/10. Loss: 1.0121:  88%|[36m████████▊ [0m| 23/26 [00:24<00:04,  1.37s/it]Epoch: 7/10. Loss: 1.0121:  92%|[36m█████████▏[0m| 24/26 [00:24<00:02,  1.26s/it]Epoch: 7/10. Loss: 0.8930:  92%|[36m█████████▏[0m| 24/26 [00:27<00:02,  1.26s/it]Epoch: 7/10. Loss: 0.8930:  96%|[36m█████████▌[0m| 25/26 [00:27<00:01,  1.85s/it]Epoch: 7/10. Loss: 0.9139:  96%|[36m█████████▌[0m| 25/26 [00:32<00:01,  1.85s/it]Epoch: 7/10. Loss: 0.9139: 100%|[36m██████████[0m| 26/26 [00:32<00:00,  2.68s/it]Epoch: 7/10. Loss: 0.9139: 100%|[36m██████████[0m| 26/26 [00:32<00:00,  1.24s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:01<00:11,  1.86s/it] 29%|[33m██▊       [0m| 2/7 [00:03<00:07,  1.60s/it] 43%|[33m████▎     [0m| 3/7 [00:03<00:04,  1.19s/it] 57%|[33m█████▋    [0m| 4/7 [00:05<00:03,  1.18s/it] 71%|[33m███████▏  [0m| 5/7 [00:06<00:02,  1.14s/it] 86%|[33m████████▌ [0m| 6/7 [00:07<00:01,  1.05s/it]100%|[33m██████████[0m| 7/7 [00:08<00:00,  1.09s/it]100%|[33m██████████[0m| 7/7 [00:08<00:00,  1.18s/it]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 8/10. Loss: 0.8983:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 8/10. Loss: 0.8983:   4%|[36m▍         [0m| 1/26 [00:00<00:19,  1.26it/s]Epoch: 8/10. Loss: 0.9614:   4%|[36m▍         [0m| 1/26 [00:01<00:19,  1.26it/s]Epoch: 8/10. Loss: 0.9614:   8%|[36m▊         [0m| 2/26 [00:01<00:20,  1.17it/s]Epoch: 8/10. Loss: 0.8576:   8%|[36m▊         [0m| 2/26 [00:02<00:20,  1.17it/s]Epoch: 8/10. Loss: 0.8576:  12%|[36m█▏        [0m| 3/26 [00:02<00:20,  1.14it/s]Epoch: 8/10. Loss: 0.9172:  12%|[36m█▏        [0m| 3/26 [00:03<00:20,  1.14it/s]Epoch: 8/10. Loss: 0.9172:  15%|[36m█▌        [0m| 4/26 [00:03<00:21,  1.04it/s]Epoch: 8/10. Loss: 1.0402:  15%|[36m█▌        [0m| 4/26 [00:04<00:21,  1.04it/s]Epoch: 8/10. Loss: 1.0402:  19%|[36m█▉        [0m| 5/26 [00:04<00:19,  1.09it/s]Epoch: 8/10. Loss: 0.9917:  19%|[36m█▉        [0m| 5/26 [00:05<00:19,  1.09it/s]Epoch: 8/10. Loss: 0.9917:  23%|[36m██▎       [0m| 6/26 [00:05<00:18,  1.07it/s]Epoch: 8/10. Loss: 0.9267:  23%|[36m██▎       [0m| 6/26 [00:06<00:18,  1.07it/s]Epoch: 8/10. Loss: 0.9267:  27%|[36m██▋       [0m| 7/26 [00:06<00:17,  1.08it/s]Epoch: 8/10. Loss: 1.0325:  27%|[36m██▋       [0m| 7/26 [00:07<00:17,  1.08it/s]Epoch: 8/10. Loss: 1.0325:  31%|[36m███       [0m| 8/26 [00:07<00:16,  1.10it/s]Epoch: 8/10. Loss: 0.9495:  31%|[36m███       [0m| 8/26 [00:08<00:16,  1.10it/s]Epoch: 8/10. Loss: 0.9495:  35%|[36m███▍      [0m| 9/26 [00:08<00:15,  1.12it/s]Epoch: 8/10. Loss: 0.8669:  35%|[36m███▍      [0m| 9/26 [00:09<00:15,  1.12it/s]Epoch: 8/10. Loss: 0.8669:  38%|[36m███▊      [0m| 10/26 [00:09<00:15,  1.01it/s]Epoch: 8/10. Loss: 0.8797:  38%|[36m███▊      [0m| 10/26 [00:10<00:15,  1.01it/s]Epoch: 8/10. Loss: 0.8797:  42%|[36m████▏     [0m| 11/26 [00:10<00:14,  1.05it/s]Epoch: 8/10. Loss: 0.8828:  42%|[36m████▏     [0m| 11/26 [00:12<00:14,  1.05it/s]Epoch: 8/10. Loss: 0.8828:  46%|[36m████▌     [0m| 12/26 [00:12<00:18,  1.29s/it]Epoch: 8/10. Loss: 0.8380:  46%|[36m████▌     [0m| 12/26 [00:13<00:18,  1.29s/it]Epoch: 8/10. Loss: 0.8380:  50%|[36m█████     [0m| 13/26 [00:13<00:14,  1.14s/it]Epoch: 8/10. Loss: 0.8545:  50%|[36m█████     [0m| 13/26 [00:14<00:14,  1.14s/it]Epoch: 8/10. Loss: 0.8545:  54%|[36m█████▍    [0m| 14/26 [00:14<00:13,  1.11s/it]Epoch: 8/10. Loss: 0.8523:  54%|[36m█████▍    [0m| 14/26 [00:14<00:13,  1.11s/it]Epoch: 8/10. Loss: 0.8523:  58%|[36m█████▊    [0m| 15/26 [00:14<00:11,  1.02s/it]Epoch: 8/10. Loss: 0.8264:  58%|[36m█████▊    [0m| 15/26 [00:15<00:11,  1.02s/it]Epoch: 8/10. Loss: 0.8264:  62%|[36m██████▏   [0m| 16/26 [00:15<00:09,  1.09it/s]Epoch: 8/10. Loss: 0.8855:  62%|[36m██████▏   [0m| 16/26 [00:16<00:09,  1.09it/s]Epoch: 8/10. Loss: 0.8855:  65%|[36m██████▌   [0m| 17/26 [00:16<00:08,  1.02it/s]Epoch: 8/10. Loss: 0.9357:  65%|[36m██████▌   [0m| 17/26 [00:17<00:08,  1.02it/s]Epoch: 8/10. Loss: 0.9357:  69%|[36m██████▉   [0m| 18/26 [00:17<00:07,  1.03it/s]Epoch: 8/10. Loss: 0.9664:  69%|[36m██████▉   [0m| 18/26 [00:18<00:07,  1.03it/s]Epoch: 8/10. Loss: 0.9664:  73%|[36m███████▎  [0m| 19/26 [00:18<00:06,  1.03it/s]Epoch: 8/10. Loss: 0.7913:  73%|[36m███████▎  [0m| 19/26 [00:19<00:06,  1.03it/s]Epoch: 8/10. Loss: 0.7913:  77%|[36m███████▋  [0m| 20/26 [00:19<00:05,  1.04it/s]Epoch: 8/10. Loss: 0.7618:  77%|[36m███████▋  [0m| 20/26 [00:20<00:05,  1.04it/s]Epoch: 8/10. Loss: 0.7618:  81%|[36m████████  [0m| 21/26 [00:20<00:04,  1.08it/s]Epoch: 8/10. Loss: 0.7717:  81%|[36m████████  [0m| 21/26 [00:21<00:04,  1.08it/s]Epoch: 8/10. Loss: 0.7717:  85%|[36m████████▍ [0m| 22/26 [00:21<00:04,  1.06s/it]Epoch: 8/10. Loss: 0.8710:  85%|[36m████████▍ [0m| 22/26 [00:22<00:04,  1.06s/it]Epoch: 8/10. Loss: 0.8710:  88%|[36m████████▊ [0m| 23/26 [00:22<00:03,  1.00s/it]Epoch: 8/10. Loss: 0.7562:  88%|[36m████████▊ [0m| 23/26 [00:24<00:03,  1.00s/it]Epoch: 8/10. Loss: 0.7562:  92%|[36m█████████▏[0m| 24/26 [00:24<00:02,  1.22s/it]Epoch: 8/10. Loss: 0.9303:  92%|[36m█████████▏[0m| 24/26 [00:25<00:02,  1.22s/it]Epoch: 8/10. Loss: 0.9303:  96%|[36m█████████▌[0m| 25/26 [00:25<00:01,  1.14s/it]Epoch: 8/10. Loss: 0.8152:  96%|[36m█████████▌[0m| 25/26 [00:26<00:01,  1.14s/it]Epoch: 8/10. Loss: 0.8152: 100%|[36m██████████[0m| 26/26 [00:26<00:00,  1.00s/it]Epoch: 8/10. Loss: 0.8152: 100%|[36m██████████[0m| 26/26 [00:26<00:00,  1.00s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:04,  1.38it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:05,  1.09s/it] 43%|[33m████▎     [0m| 3/7 [00:02<00:03,  1.12it/s] 57%|[33m█████▋    [0m| 4/7 [00:03<00:02,  1.02it/s] 71%|[33m███████▏  [0m| 5/7 [00:04<00:01,  1.25it/s] 86%|[33m████████▌ [0m| 6/7 [00:05<00:00,  1.25it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.53it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.28it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 9/10. Loss: 1.0189:   0%|[36m          [0m| 0/26 [00:01<?, ?it/s]Epoch: 9/10. Loss: 1.0189:   4%|[36m▍         [0m| 1/26 [00:01<00:37,  1.48s/it]Epoch: 9/10. Loss: 0.7979:   4%|[36m▍         [0m| 1/26 [00:02<00:37,  1.48s/it]Epoch: 9/10. Loss: 0.7979:   8%|[36m▊         [0m| 2/26 [00:02<00:28,  1.17s/it]Epoch: 9/10. Loss: 0.8869:   8%|[36m▊         [0m| 2/26 [00:04<00:28,  1.17s/it]Epoch: 9/10. Loss: 0.8869:  12%|[36m█▏        [0m| 3/26 [00:04<00:36,  1.57s/it]Epoch: 9/10. Loss: 0.8169:  12%|[36m█▏        [0m| 3/26 [00:05<00:36,  1.57s/it]Epoch: 9/10. Loss: 0.8169:  15%|[36m█▌        [0m| 4/26 [00:05<00:29,  1.32s/it]Epoch: 9/10. Loss: 0.8038:  15%|[36m█▌        [0m| 4/26 [00:06<00:29,  1.32s/it]Epoch: 9/10. Loss: 0.8038:  19%|[36m█▉        [0m| 5/26 [00:06<00:27,  1.29s/it]Epoch: 9/10. Loss: 0.8216:  19%|[36m█▉        [0m| 5/26 [00:07<00:27,  1.29s/it]Epoch: 9/10. Loss: 0.8216:  23%|[36m██▎       [0m| 6/26 [00:07<00:22,  1.14s/it]Epoch: 9/10. Loss: 0.9729:  23%|[36m██▎       [0m| 6/26 [00:08<00:22,  1.14s/it]Epoch: 9/10. Loss: 0.9729:  27%|[36m██▋       [0m| 7/26 [00:08<00:23,  1.21s/it]Epoch: 9/10. Loss: 0.9475:  27%|[36m██▋       [0m| 7/26 [00:09<00:23,  1.21s/it]Epoch: 9/10. Loss: 0.9475:  31%|[36m███       [0m| 8/26 [00:09<00:21,  1.18s/it]Epoch: 9/10. Loss: 0.8539:  31%|[36m███       [0m| 8/26 [00:11<00:21,  1.18s/it]Epoch: 9/10. Loss: 0.8539:  35%|[36m███▍      [0m| 9/26 [00:11<00:19,  1.14s/it]Epoch: 9/10. Loss: 1.0486:  35%|[36m███▍      [0m| 9/26 [00:11<00:19,  1.14s/it]Epoch: 9/10. Loss: 1.0486:  38%|[36m███▊      [0m| 10/26 [00:11<00:16,  1.04s/it]Epoch: 9/10. Loss: 0.8422:  38%|[36m███▊      [0m| 10/26 [00:12<00:16,  1.04s/it]Epoch: 9/10. Loss: 0.8422:  42%|[36m████▏     [0m| 11/26 [00:12<00:14,  1.06it/s]Epoch: 9/10. Loss: 0.8560:  42%|[36m████▏     [0m| 11/26 [00:13<00:14,  1.06it/s]Epoch: 9/10. Loss: 0.8560:  46%|[36m████▌     [0m| 12/26 [00:13<00:13,  1.01it/s]Epoch: 9/10. Loss: 0.7458:  46%|[36m████▌     [0m| 12/26 [00:14<00:13,  1.01it/s]Epoch: 9/10. Loss: 0.7458:  50%|[36m█████     [0m| 13/26 [00:14<00:12,  1.06it/s]Epoch: 9/10. Loss: 0.9129:  50%|[36m█████     [0m| 13/26 [00:15<00:12,  1.06it/s]Epoch: 9/10. Loss: 0.9129:  54%|[36m█████▍    [0m| 14/26 [00:15<00:11,  1.02it/s]Epoch: 9/10. Loss: 0.8524:  54%|[36m█████▍    [0m| 14/26 [00:16<00:11,  1.02it/s]Epoch: 9/10. Loss: 0.8524:  58%|[36m█████▊    [0m| 15/26 [00:16<00:10,  1.07it/s]Epoch: 9/10. Loss: 0.8260:  58%|[36m█████▊    [0m| 15/26 [00:17<00:10,  1.07it/s]Epoch: 9/10. Loss: 0.8260:  62%|[36m██████▏   [0m| 16/26 [00:17<00:09,  1.09it/s]Epoch: 9/10. Loss: 0.9007:  62%|[36m██████▏   [0m| 16/26 [00:18<00:09,  1.09it/s]Epoch: 9/10. Loss: 0.9007:  65%|[36m██████▌   [0m| 17/26 [00:18<00:08,  1.10it/s]Epoch: 9/10. Loss: 0.8550:  65%|[36m██████▌   [0m| 17/26 [00:18<00:08,  1.10it/s]Epoch: 9/10. Loss: 0.8550:  69%|[36m██████▉   [0m| 18/26 [00:18<00:07,  1.13it/s]Epoch: 9/10. Loss: 0.9865:  69%|[36m██████▉   [0m| 18/26 [00:19<00:07,  1.13it/s]Epoch: 9/10. Loss: 0.9865:  73%|[36m███████▎  [0m| 19/26 [00:19<00:06,  1.13it/s]Epoch: 9/10. Loss: 0.8006:  73%|[36m███████▎  [0m| 19/26 [00:20<00:06,  1.13it/s]Epoch: 9/10. Loss: 0.8006:  77%|[36m███████▋  [0m| 20/26 [00:20<00:05,  1.09it/s]Epoch: 9/10. Loss: 0.7945:  77%|[36m███████▋  [0m| 20/26 [00:21<00:05,  1.09it/s]Epoch: 9/10. Loss: 0.7945:  81%|[36m████████  [0m| 21/26 [00:21<00:04,  1.14it/s]Epoch: 9/10. Loss: 0.8279:  81%|[36m████████  [0m| 21/26 [00:22<00:04,  1.14it/s]Epoch: 9/10. Loss: 0.8279:  85%|[36m████████▍ [0m| 22/26 [00:22<00:03,  1.09it/s]Epoch: 9/10. Loss: 0.8928:  85%|[36m████████▍ [0m| 22/26 [00:23<00:03,  1.09it/s]Epoch: 9/10. Loss: 0.8928:  88%|[36m████████▊ [0m| 23/26 [00:23<00:02,  1.01it/s]Epoch: 9/10. Loss: 0.8961:  88%|[36m████████▊ [0m| 23/26 [00:24<00:02,  1.01it/s]Epoch: 9/10. Loss: 0.8961:  92%|[36m█████████▏[0m| 24/26 [00:24<00:01,  1.01it/s]Epoch: 9/10. Loss: 0.8143:  92%|[36m█████████▏[0m| 24/26 [00:25<00:01,  1.01it/s]Epoch: 9/10. Loss: 0.8143:  96%|[36m█████████▌[0m| 25/26 [00:25<00:01,  1.04s/it]Epoch: 9/10. Loss: 0.7562:  96%|[36m█████████▌[0m| 25/26 [00:27<00:01,  1.04s/it]Epoch: 9/10. Loss: 0.7562: 100%|[36m██████████[0m| 26/26 [00:27<00:00,  1.26s/it]Epoch: 9/10. Loss: 0.7562: 100%|[36m██████████[0m| 26/26 [00:27<00:00,  1.07s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:04,  1.32it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:05,  1.19s/it] 43%|[33m████▎     [0m| 3/7 [00:02<00:03,  1.06it/s] 57%|[33m█████▋    [0m| 4/7 [00:04<00:03,  1.01s/it] 71%|[33m███████▏  [0m| 5/7 [00:04<00:01,  1.21it/s] 86%|[33m████████▌ [0m| 6/7 [00:05<00:00,  1.20it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.49it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.23it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 0/10. Loss: 1.2693:   0%|[36m          [0m| 0/26 [00:01<?, ?it/s]Epoch: 0/10. Loss: 1.2693:   4%|[36m▍         [0m| 1/26 [00:01<00:27,  1.09s/it]Epoch: 0/10. Loss: 3.5258:   4%|[36m▍         [0m| 1/26 [00:01<00:27,  1.09s/it]Epoch: 0/10. Loss: 3.5258:   8%|[36m▊         [0m| 2/26 [00:01<00:22,  1.06it/s]Epoch: 0/10. Loss: 3.4403:   8%|[36m▊         [0m| 2/26 [00:03<00:22,  1.06it/s]Epoch: 0/10. Loss: 3.4403:  12%|[36m█▏        [0m| 3/26 [00:03<00:25,  1.09s/it]Epoch: 0/10. Loss: 4.0726:  12%|[36m█▏        [0m| 3/26 [00:04<00:25,  1.09s/it]Epoch: 0/10. Loss: 4.0726:  15%|[36m█▌        [0m| 4/26 [00:04<00:27,  1.26s/it]Epoch: 0/10. Loss: 0.9390:  15%|[36m█▌        [0m| 4/26 [00:05<00:27,  1.26s/it]Epoch: 0/10. Loss: 0.9390:  19%|[36m█▉        [0m| 5/26 [00:05<00:25,  1.21s/it]Epoch: 0/10. Loss: 1.3274:  19%|[36m█▉        [0m| 5/26 [00:06<00:25,  1.21s/it]Epoch: 0/10. Loss: 1.3274:  23%|[36m██▎       [0m| 6/26 [00:06<00:21,  1.09s/it]Epoch: 0/10. Loss: 2.6088:  23%|[36m██▎       [0m| 6/26 [00:07<00:21,  1.09s/it]Epoch: 0/10. Loss: 2.6088:  27%|[36m██▋       [0m| 7/26 [00:07<00:19,  1.02s/it]Epoch: 0/10. Loss: 2.2932:  27%|[36m██▋       [0m| 7/26 [00:08<00:19,  1.02s/it]Epoch: 0/10. Loss: 2.2932:  31%|[36m███       [0m| 8/26 [00:08<00:18,  1.01s/it]Epoch: 0/10. Loss: 2.3982:  31%|[36m███       [0m| 8/26 [00:09<00:18,  1.01s/it]Epoch: 0/10. Loss: 2.3982:  35%|[36m███▍      [0m| 9/26 [00:09<00:16,  1.06it/s]Epoch: 0/10. Loss: 1.2415:  35%|[36m███▍      [0m| 9/26 [00:10<00:16,  1.06it/s]Epoch: 0/10. Loss: 1.2415:  38%|[36m███▊      [0m| 10/26 [00:10<00:15,  1.06it/s]Epoch: 0/10. Loss: 1.0580:  38%|[36m███▊      [0m| 10/26 [00:11<00:15,  1.06it/s]Epoch: 0/10. Loss: 1.0580:  42%|[36m████▏     [0m| 11/26 [00:11<00:15,  1.03s/it]Epoch: 0/10. Loss: 1.2556:  42%|[36m████▏     [0m| 11/26 [00:12<00:15,  1.03s/it]Epoch: 0/10. Loss: 1.2556:  46%|[36m████▌     [0m| 12/26 [00:12<00:14,  1.02s/it]Epoch: 0/10. Loss: 1.0308:  46%|[36m████▌     [0m| 12/26 [00:13<00:14,  1.02s/it]Epoch: 0/10. Loss: 1.0308:  50%|[36m█████     [0m| 13/26 [00:13<00:12,  1.01it/s]Epoch: 0/10. Loss: 1.3563:  50%|[36m█████     [0m| 13/26 [00:14<00:12,  1.01it/s]Epoch: 0/10. Loss: 1.3563:  54%|[36m█████▍    [0m| 14/26 [00:14<00:11,  1.02it/s]Epoch: 0/10. Loss: 1.4436:  54%|[36m█████▍    [0m| 14/26 [00:15<00:11,  1.02it/s]Epoch: 0/10. Loss: 1.4436:  58%|[36m█████▊    [0m| 15/26 [00:15<00:10,  1.09it/s]Epoch: 0/10. Loss: 1.3733:  58%|[36m█████▊    [0m| 15/26 [00:15<00:10,  1.09it/s]Epoch: 0/10. Loss: 1.3733:  62%|[36m██████▏   [0m| 16/26 [00:15<00:08,  1.19it/s]Epoch: 0/10. Loss: 1.0770:  62%|[36m██████▏   [0m| 16/26 [00:16<00:08,  1.19it/s]Epoch: 0/10. Loss: 1.0770:  65%|[36m██████▌   [0m| 17/26 [00:16<00:07,  1.16it/s]Epoch: 0/10. Loss: 1.1609:  65%|[36m██████▌   [0m| 17/26 [00:17<00:07,  1.16it/s]Epoch: 0/10. Loss: 1.1609:  69%|[36m██████▉   [0m| 18/26 [00:17<00:07,  1.12it/s]Epoch: 0/10. Loss: 1.1009:  69%|[36m██████▉   [0m| 18/26 [00:18<00:07,  1.12it/s]Epoch: 0/10. Loss: 1.1009:  73%|[36m███████▎  [0m| 19/26 [00:18<00:06,  1.13it/s]Epoch: 0/10. Loss: 1.2199:  73%|[36m███████▎  [0m| 19/26 [00:19<00:06,  1.13it/s]Epoch: 0/10. Loss: 1.2199:  77%|[36m███████▋  [0m| 20/26 [00:19<00:05,  1.06it/s]Epoch: 0/10. Loss: 1.0429:  77%|[36m███████▋  [0m| 20/26 [00:20<00:05,  1.06it/s]Epoch: 0/10. Loss: 1.0429:  81%|[36m████████  [0m| 21/26 [00:20<00:04,  1.10it/s]Epoch: 0/10. Loss: 0.9992:  81%|[36m████████  [0m| 21/26 [00:21<00:04,  1.10it/s]Epoch: 0/10. Loss: 0.9992:  85%|[36m████████▍ [0m| 22/26 [00:21<00:03,  1.13it/s]Epoch: 0/10. Loss: 1.0161:  85%|[36m████████▍ [0m| 22/26 [00:22<00:03,  1.13it/s]Epoch: 0/10. Loss: 1.0161:  88%|[36m████████▊ [0m| 23/26 [00:22<00:02,  1.12it/s]Epoch: 0/10. Loss: 1.0257:  88%|[36m████████▊ [0m| 23/26 [00:23<00:02,  1.12it/s]Epoch: 0/10. Loss: 1.0257:  92%|[36m█████████▏[0m| 24/26 [00:23<00:01,  1.08it/s]Epoch: 0/10. Loss: 0.9986:  92%|[36m█████████▏[0m| 24/26 [00:24<00:01,  1.08it/s]Epoch: 0/10. Loss: 0.9986:  96%|[36m█████████▌[0m| 25/26 [00:24<00:00,  1.13it/s]Epoch: 0/10. Loss: 1.2195:  96%|[36m█████████▌[0m| 25/26 [00:24<00:00,  1.13it/s]Epoch: 0/10. Loss: 1.2195: 100%|[36m██████████[0m| 26/26 [00:24<00:00,  1.26it/s]Epoch: 0/10. Loss: 1.2195: 100%|[36m██████████[0m| 26/26 [00:24<00:00,  1.06it/s]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:04,  1.39it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:06,  1.31s/it] 43%|[33m████▎     [0m| 3/7 [00:03<00:03,  1.01it/s] 57%|[33m█████▋    [0m| 4/7 [00:07<00:07,  2.35s/it] 71%|[33m███████▏  [0m| 5/7 [00:08<00:03,  1.73s/it] 86%|[33m████████▌ [0m| 6/7 [00:08<00:01,  1.41s/it]100%|[33m██████████[0m| 7/7 [00:09<00:00,  1.05s/it]100%|[33m██████████[0m| 7/7 [00:09<00:00,  1.32s/it]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 1/10. Loss: 1.0584:   0%|[36m          [0m| 0/26 [00:01<?, ?it/s]Epoch: 1/10. Loss: 1.0584:   4%|[36m▍         [0m| 1/26 [00:01<00:29,  1.18s/it]Epoch: 1/10. Loss: 0.9854:   4%|[36m▍         [0m| 1/26 [00:02<00:29,  1.18s/it]Epoch: 1/10. Loss: 0.9854:   8%|[36m▊         [0m| 2/26 [00:02<00:24,  1.01s/it]Epoch: 1/10. Loss: 1.1364:   8%|[36m▊         [0m| 2/26 [00:03<00:24,  1.01s/it]Epoch: 1/10. Loss: 1.1364:  12%|[36m█▏        [0m| 3/26 [00:03<00:22,  1.01it/s]Epoch: 1/10. Loss: 1.0701:  12%|[36m█▏        [0m| 3/26 [00:04<00:22,  1.01it/s]Epoch: 1/10. Loss: 1.0701:  15%|[36m█▌        [0m| 4/26 [00:04<00:21,  1.00it/s]Epoch: 1/10. Loss: 0.9687:  15%|[36m█▌        [0m| 4/26 [00:04<00:21,  1.00it/s]Epoch: 1/10. Loss: 0.9687:  19%|[36m█▉        [0m| 5/26 [00:05<00:20,  1.01it/s]Epoch: 1/10. Loss: 1.0131:  19%|[36m█▉        [0m| 5/26 [00:07<00:20,  1.01it/s]Epoch: 1/10. Loss: 1.0131:  23%|[36m██▎       [0m| 6/26 [00:07<00:28,  1.41s/it]Epoch: 1/10. Loss: 1.0554:  23%|[36m██▎       [0m| 6/26 [00:08<00:28,  1.41s/it]Epoch: 1/10. Loss: 1.0554:  27%|[36m██▋       [0m| 7/26 [00:08<00:24,  1.28s/it]Epoch: 1/10. Loss: 1.0184:  27%|[36m██▋       [0m| 7/26 [00:10<00:24,  1.28s/it]Epoch: 1/10. Loss: 1.0184:  31%|[36m███       [0m| 8/26 [00:10<00:27,  1.51s/it]Epoch: 1/10. Loss: 1.0672:  31%|[36m███       [0m| 8/26 [00:11<00:27,  1.51s/it]Epoch: 1/10. Loss: 1.0672:  35%|[36m███▍      [0m| 9/26 [00:11<00:22,  1.31s/it]Epoch: 1/10. Loss: 1.0251:  35%|[36m███▍      [0m| 9/26 [00:11<00:22,  1.31s/it]Epoch: 1/10. Loss: 1.0251:  38%|[36m███▊      [0m| 10/26 [00:11<00:18,  1.16s/it]Epoch: 1/10. Loss: 1.0132:  38%|[36m███▊      [0m| 10/26 [00:12<00:18,  1.16s/it]Epoch: 1/10. Loss: 1.0132:  42%|[36m████▏     [0m| 11/26 [00:12<00:16,  1.10s/it]Epoch: 1/10. Loss: 0.9840:  42%|[36m████▏     [0m| 11/26 [00:13<00:16,  1.10s/it]Epoch: 1/10. Loss: 0.9840:  46%|[36m████▌     [0m| 12/26 [00:13<00:15,  1.08s/it]Epoch: 1/10. Loss: 0.8647:  46%|[36m████▌     [0m| 12/26 [00:14<00:15,  1.08s/it]Epoch: 1/10. Loss: 0.8647:  50%|[36m█████     [0m| 13/26 [00:14<00:12,  1.00it/s]Epoch: 1/10. Loss: 1.0216:  50%|[36m█████     [0m| 13/26 [00:17<00:12,  1.00it/s]Epoch: 1/10. Loss: 1.0216:  54%|[36m█████▍    [0m| 14/26 [00:17<00:17,  1.44s/it]Epoch: 1/10. Loss: 1.0332:  54%|[36m█████▍    [0m| 14/26 [00:18<00:17,  1.44s/it]Epoch: 1/10. Loss: 1.0332:  58%|[36m█████▊    [0m| 15/26 [00:18<00:14,  1.32s/it]Epoch: 1/10. Loss: 0.9711:  58%|[36m█████▊    [0m| 15/26 [00:19<00:14,  1.32s/it]Epoch: 1/10. Loss: 0.9711:  62%|[36m██████▏   [0m| 16/26 [00:19<00:11,  1.16s/it]Epoch: 1/10. Loss: 1.1363:  62%|[36m██████▏   [0m| 16/26 [00:19<00:11,  1.16s/it]Epoch: 1/10. Loss: 1.1363:  65%|[36m██████▌   [0m| 17/26 [00:19<00:09,  1.07s/it]Epoch: 1/10. Loss: 1.0875:  65%|[36m██████▌   [0m| 17/26 [00:20<00:09,  1.07s/it]Epoch: 1/10. Loss: 1.0875:  69%|[36m██████▉   [0m| 18/26 [00:20<00:08,  1.06s/it]Epoch: 1/10. Loss: 1.0369:  69%|[36m██████▉   [0m| 18/26 [00:22<00:08,  1.06s/it]Epoch: 1/10. Loss: 1.0369:  73%|[36m███████▎  [0m| 19/26 [00:22<00:07,  1.07s/it]Epoch: 1/10. Loss: 0.9964:  73%|[36m███████▎  [0m| 19/26 [00:22<00:07,  1.07s/it]Epoch: 1/10. Loss: 0.9964:  77%|[36m███████▋  [0m| 20/26 [00:22<00:05,  1.02it/s]Epoch: 1/10. Loss: 1.1129:  77%|[36m███████▋  [0m| 20/26 [00:23<00:05,  1.02it/s]Epoch: 1/10. Loss: 1.1129:  81%|[36m████████  [0m| 21/26 [00:23<00:04,  1.04it/s]Epoch: 1/10. Loss: 0.9809:  81%|[36m████████  [0m| 21/26 [00:24<00:04,  1.04it/s]Epoch: 1/10. Loss: 0.9809:  85%|[36m████████▍ [0m| 22/26 [00:24<00:03,  1.09it/s]Epoch: 1/10. Loss: 1.1821:  85%|[36m████████▍ [0m| 22/26 [00:25<00:03,  1.09it/s]Epoch: 1/10. Loss: 1.1821:  88%|[36m████████▊ [0m| 23/26 [00:25<00:03,  1.06s/it]Epoch: 1/10. Loss: 0.9815:  88%|[36m████████▊ [0m| 23/26 [00:26<00:03,  1.06s/it]Epoch: 1/10. Loss: 0.9815:  92%|[36m█████████▏[0m| 24/26 [00:26<00:02,  1.03s/it]Epoch: 1/10. Loss: 0.9806:  92%|[36m█████████▏[0m| 24/26 [00:27<00:02,  1.03s/it]Epoch: 1/10. Loss: 0.9806:  96%|[36m█████████▌[0m| 25/26 [00:27<00:00,  1.01it/s]Epoch: 1/10. Loss: 0.9756:  96%|[36m█████████▌[0m| 25/26 [00:28<00:00,  1.01it/s]Epoch: 1/10. Loss: 0.9756: 100%|[36m██████████[0m| 26/26 [00:28<00:00,  1.12it/s]Epoch: 1/10. Loss: 0.9756: 100%|[36m██████████[0m| 26/26 [00:28<00:00,  1.09s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:04,  1.36it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:05,  1.06s/it] 43%|[33m████▎     [0m| 3/7 [00:03<00:05,  1.41s/it] 57%|[33m█████▋    [0m| 4/7 [00:04<00:03,  1.29s/it] 71%|[33m███████▏  [0m| 5/7 [00:05<00:02,  1.08s/it] 86%|[33m████████▌ [0m| 6/7 [00:06<00:00,  1.01it/s]100%|[33m██████████[0m| 7/7 [00:06<00:00,  1.30it/s]100%|[33m██████████[0m| 7/7 [00:06<00:00,  1.03it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 2/10. Loss: 1.0201:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 2/10. Loss: 1.0201:   4%|[36m▍         [0m| 1/26 [00:00<00:21,  1.15it/s]Epoch: 2/10. Loss: 1.0760:   4%|[36m▍         [0m| 1/26 [00:03<00:21,  1.15it/s]Epoch: 2/10. Loss: 1.0760:   8%|[36m▊         [0m| 2/26 [00:03<00:45,  1.92s/it]Epoch: 2/10. Loss: 0.9683:   8%|[36m▊         [0m| 2/26 [00:04<00:45,  1.92s/it]Epoch: 2/10. Loss: 0.9683:  12%|[36m█▏        [0m| 3/26 [00:04<00:34,  1.48s/it]Epoch: 2/10. Loss: 0.9246:  12%|[36m█▏        [0m| 3/26 [00:05<00:34,  1.48s/it]Epoch: 2/10. Loss: 0.9246:  15%|[36m█▌        [0m| 4/26 [00:05<00:26,  1.22s/it]Epoch: 2/10. Loss: 0.9060:  15%|[36m█▌        [0m| 4/26 [00:06<00:26,  1.22s/it]Epoch: 2/10. Loss: 0.9060:  19%|[36m█▉        [0m| 5/26 [00:06<00:23,  1.12s/it]Epoch: 2/10. Loss: 0.9448:  19%|[36m█▉        [0m| 5/26 [00:08<00:23,  1.12s/it]Epoch: 2/10. Loss: 0.9448:  23%|[36m██▎       [0m| 6/26 [00:08<00:31,  1.57s/it]Epoch: 2/10. Loss: 1.0841:  23%|[36m██▎       [0m| 6/26 [00:09<00:31,  1.57s/it]Epoch: 2/10. Loss: 1.0841:  27%|[36m██▋       [0m| 7/26 [00:09<00:27,  1.47s/it]Epoch: 2/10. Loss: 0.9835:  27%|[36m██▋       [0m| 7/26 [00:10<00:27,  1.47s/it]Epoch: 2/10. Loss: 0.9835:  31%|[36m███       [0m| 8/26 [00:10<00:22,  1.23s/it]Epoch: 2/10. Loss: 0.9592:  31%|[36m███       [0m| 8/26 [00:11<00:22,  1.23s/it]Epoch: 2/10. Loss: 0.9592:  35%|[36m███▍      [0m| 9/26 [00:11<00:19,  1.15s/it]Epoch: 2/10. Loss: 0.9522:  35%|[36m███▍      [0m| 9/26 [00:12<00:19,  1.15s/it]Epoch: 2/10. Loss: 0.9522:  38%|[36m███▊      [0m| 10/26 [00:12<00:17,  1.10s/it]Epoch: 2/10. Loss: 0.9374:  38%|[36m███▊      [0m| 10/26 [00:15<00:17,  1.10s/it]Epoch: 2/10. Loss: 0.9374:  42%|[36m████▏     [0m| 11/26 [00:15<00:25,  1.68s/it]Epoch: 2/10. Loss: 0.8831:  42%|[36m████▏     [0m| 11/26 [00:17<00:25,  1.68s/it]Epoch: 2/10. Loss: 0.8831:  46%|[36m████▌     [0m| 12/26 [00:17<00:25,  1.84s/it]Epoch: 2/10. Loss: 0.8588:  46%|[36m████▌     [0m| 12/26 [00:20<00:25,  1.84s/it]Epoch: 2/10. Loss: 0.8588:  50%|[36m█████     [0m| 13/26 [00:20<00:27,  2.11s/it]Epoch: 2/10. Loss: 0.9381:  50%|[36m█████     [0m| 13/26 [00:21<00:27,  2.11s/it]Epoch: 2/10. Loss: 0.9381:  54%|[36m█████▍    [0m| 14/26 [00:21<00:22,  1.84s/it]Epoch: 2/10. Loss: 1.0615:  54%|[36m█████▍    [0m| 14/26 [00:23<00:22,  1.84s/it]Epoch: 2/10. Loss: 1.0615:  58%|[36m█████▊    [0m| 15/26 [00:23<00:18,  1.70s/it]Epoch: 2/10. Loss: 0.9945:  58%|[36m█████▊    [0m| 15/26 [00:24<00:18,  1.70s/it]Epoch: 2/10. Loss: 0.9945:  62%|[36m██████▏   [0m| 16/26 [00:24<00:14,  1.46s/it]Epoch: 2/10. Loss: 1.0029:  62%|[36m██████▏   [0m| 16/26 [00:25<00:14,  1.46s/it]Epoch: 2/10. Loss: 1.0029:  65%|[36m██████▌   [0m| 17/26 [00:25<00:12,  1.39s/it]Epoch: 2/10. Loss: 1.0420:  65%|[36m██████▌   [0m| 17/26 [00:26<00:12,  1.39s/it]Epoch: 2/10. Loss: 1.0420:  69%|[36m██████▉   [0m| 18/26 [00:26<00:09,  1.22s/it]Epoch: 2/10. Loss: 0.9595:  69%|[36m██████▉   [0m| 18/26 [00:26<00:09,  1.22s/it]Epoch: 2/10. Loss: 0.9595:  73%|[36m███████▎  [0m| 19/26 [00:26<00:07,  1.06s/it]Epoch: 2/10. Loss: 0.9679:  73%|[36m███████▎  [0m| 19/26 [00:27<00:07,  1.06s/it]Epoch: 2/10. Loss: 0.9679:  77%|[36m███████▋  [0m| 20/26 [00:27<00:06,  1.01s/it]Epoch: 2/10. Loss: 0.8546:  77%|[36m███████▋  [0m| 20/26 [00:28<00:06,  1.01s/it]Epoch: 2/10. Loss: 0.8546:  81%|[36m████████  [0m| 21/26 [00:28<00:04,  1.02it/s]Epoch: 2/10. Loss: 0.9876:  81%|[36m████████  [0m| 21/26 [00:30<00:04,  1.02it/s]Epoch: 2/10. Loss: 0.9876:  85%|[36m████████▍ [0m| 22/26 [00:30<00:05,  1.30s/it]Epoch: 2/10. Loss: 0.9156:  85%|[36m████████▍ [0m| 22/26 [00:31<00:05,  1.30s/it]Epoch: 2/10. Loss: 0.9156:  88%|[36m████████▊ [0m| 23/26 [00:31<00:03,  1.25s/it]Epoch: 2/10. Loss: 1.0783:  88%|[36m████████▊ [0m| 23/26 [00:32<00:03,  1.25s/it]Epoch: 2/10. Loss: 1.0783:  92%|[36m█████████▏[0m| 24/26 [00:32<00:02,  1.10s/it]Epoch: 2/10. Loss: 0.9036:  92%|[36m█████████▏[0m| 24/26 [00:33<00:02,  1.10s/it]Epoch: 2/10. Loss: 0.9036:  96%|[36m█████████▌[0m| 25/26 [00:33<00:01,  1.05s/it]Epoch: 2/10. Loss: 0.9096:  96%|[36m█████████▌[0m| 25/26 [00:34<00:01,  1.05s/it]Epoch: 2/10. Loss: 0.9096: 100%|[36m██████████[0m| 26/26 [00:34<00:00,  1.08it/s]Epoch: 2/10. Loss: 0.9096: 100%|[36m██████████[0m| 26/26 [00:34<00:00,  1.31s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:02<00:14,  2.44s/it] 29%|[33m██▊       [0m| 2/7 [00:03<00:08,  1.79s/it] 43%|[33m████▎     [0m| 3/7 [00:04<00:05,  1.30s/it] 57%|[33m█████▋    [0m| 4/7 [00:05<00:03,  1.24s/it] 71%|[33m███████▏  [0m| 5/7 [00:06<00:01,  1.02it/s] 86%|[33m████████▌ [0m| 6/7 [00:07<00:01,  1.20s/it]100%|[33m██████████[0m| 7/7 [00:08<00:00,  1.04it/s]100%|[33m██████████[0m| 7/7 [00:08<00:00,  1.18s/it]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 3/10. Loss: 0.9224:   0%|[36m          [0m| 0/26 [00:01<?, ?it/s]Epoch: 3/10. Loss: 0.9224:   4%|[36m▍         [0m| 1/26 [00:01<00:38,  1.52s/it]Epoch: 3/10. Loss: 0.9848:   4%|[36m▍         [0m| 1/26 [00:02<00:38,  1.52s/it]Epoch: 3/10. Loss: 0.9848:   8%|[36m▊         [0m| 2/26 [00:02<00:29,  1.22s/it]Epoch: 3/10. Loss: 0.9050:   8%|[36m▊         [0m| 2/26 [00:03<00:29,  1.22s/it]Epoch: 3/10. Loss: 0.9050:  12%|[36m█▏        [0m| 3/26 [00:03<00:25,  1.10s/it]Epoch: 3/10. Loss: 0.9327:  12%|[36m█▏        [0m| 3/26 [00:04<00:25,  1.10s/it]Epoch: 3/10. Loss: 0.9327:  15%|[36m█▌        [0m| 4/26 [00:04<00:22,  1.04s/it]Epoch: 3/10. Loss: 0.9568:  15%|[36m█▌        [0m| 4/26 [00:05<00:22,  1.04s/it]Epoch: 3/10. Loss: 0.9568:  19%|[36m█▉        [0m| 5/26 [00:05<00:22,  1.06s/it]Epoch: 3/10. Loss: 0.8346:  19%|[36m█▉        [0m| 5/26 [00:06<00:22,  1.06s/it]Epoch: 3/10. Loss: 0.8346:  23%|[36m██▎       [0m| 6/26 [00:06<00:20,  1.04s/it]Epoch: 3/10. Loss: 0.8948:  23%|[36m██▎       [0m| 6/26 [00:07<00:20,  1.04s/it]Epoch: 3/10. Loss: 0.8948:  27%|[36m██▋       [0m| 7/26 [00:07<00:17,  1.06it/s]Epoch: 3/10. Loss: 0.9046:  27%|[36m██▋       [0m| 7/26 [00:08<00:17,  1.06it/s]Epoch: 3/10. Loss: 0.9046:  31%|[36m███       [0m| 8/26 [00:08<00:16,  1.10it/s]Epoch: 3/10. Loss: 0.9480:  31%|[36m███       [0m| 8/26 [00:08<00:16,  1.10it/s]Epoch: 3/10. Loss: 0.9480:  35%|[36m███▍      [0m| 9/26 [00:08<00:14,  1.13it/s]Epoch: 3/10. Loss: 0.8560:  35%|[36m███▍      [0m| 9/26 [00:09<00:14,  1.13it/s]Epoch: 3/10. Loss: 0.8560:  38%|[36m███▊      [0m| 10/26 [00:09<00:14,  1.13it/s]Epoch: 3/10. Loss: 0.9829:  38%|[36m███▊      [0m| 10/26 [00:10<00:14,  1.13it/s]Epoch: 3/10. Loss: 0.9829:  42%|[36m████▏     [0m| 11/26 [00:10<00:13,  1.12it/s]Epoch: 3/10. Loss: 0.9017:  42%|[36m████▏     [0m| 11/26 [00:12<00:13,  1.12it/s]Epoch: 3/10. Loss: 0.9017:  46%|[36m████▌     [0m| 12/26 [00:12<00:14,  1.06s/it]Epoch: 3/10. Loss: 0.8685:  46%|[36m████▌     [0m| 12/26 [00:12<00:14,  1.06s/it]Epoch: 3/10. Loss: 0.8685:  50%|[36m█████     [0m| 13/26 [00:12<00:12,  1.02it/s]Epoch: 3/10. Loss: 0.9114:  50%|[36m█████     [0m| 13/26 [00:13<00:12,  1.02it/s]Epoch: 3/10. Loss: 0.9114:  54%|[36m█████▍    [0m| 14/26 [00:13<00:11,  1.06it/s]Epoch: 3/10. Loss: 0.9356:  54%|[36m█████▍    [0m| 14/26 [00:14<00:11,  1.06it/s]Epoch: 3/10. Loss: 0.9356:  58%|[36m█████▊    [0m| 15/26 [00:14<00:10,  1.06it/s]Epoch: 3/10. Loss: 0.9188:  58%|[36m█████▊    [0m| 15/26 [00:15<00:10,  1.06it/s]Epoch: 3/10. Loss: 0.9188:  62%|[36m██████▏   [0m| 16/26 [00:15<00:09,  1.06it/s]Epoch: 3/10. Loss: 0.9856:  62%|[36m██████▏   [0m| 16/26 [00:16<00:09,  1.06it/s]Epoch: 3/10. Loss: 0.9856:  65%|[36m██████▌   [0m| 17/26 [00:16<00:08,  1.03it/s]Epoch: 3/10. Loss: 0.8190:  65%|[36m██████▌   [0m| 17/26 [00:17<00:08,  1.03it/s]Epoch: 3/10. Loss: 0.8190:  69%|[36m██████▉   [0m| 18/26 [00:17<00:07,  1.03it/s]Epoch: 3/10. Loss: 0.9113:  69%|[36m██████▉   [0m| 18/26 [00:18<00:07,  1.03it/s]Epoch: 3/10. Loss: 0.9113:  73%|[36m███████▎  [0m| 19/26 [00:18<00:06,  1.02it/s]Epoch: 3/10. Loss: 0.8889:  73%|[36m███████▎  [0m| 19/26 [00:19<00:06,  1.02it/s]Epoch: 3/10. Loss: 0.8889:  77%|[36m███████▋  [0m| 20/26 [00:19<00:05,  1.05it/s]Epoch: 3/10. Loss: 0.9335:  77%|[36m███████▋  [0m| 20/26 [00:20<00:05,  1.05it/s]Epoch: 3/10. Loss: 0.9335:  81%|[36m████████  [0m| 21/26 [00:20<00:04,  1.12it/s]Epoch: 3/10. Loss: 0.7955:  81%|[36m████████  [0m| 21/26 [00:21<00:04,  1.12it/s]Epoch: 3/10. Loss: 0.7955:  85%|[36m████████▍ [0m| 22/26 [00:21<00:03,  1.07it/s]Epoch: 3/10. Loss: 0.8877:  85%|[36m████████▍ [0m| 22/26 [00:22<00:03,  1.07it/s]Epoch: 3/10. Loss: 0.8877:  88%|[36m████████▊ [0m| 23/26 [00:22<00:02,  1.10it/s]Epoch: 3/10. Loss: 0.8495:  88%|[36m████████▊ [0m| 23/26 [00:23<00:02,  1.10it/s]Epoch: 3/10. Loss: 0.8495:  92%|[36m█████████▏[0m| 24/26 [00:23<00:01,  1.02it/s]Epoch: 3/10. Loss: 0.8532:  92%|[36m█████████▏[0m| 24/26 [00:24<00:01,  1.02it/s]Epoch: 3/10. Loss: 0.8532:  96%|[36m█████████▌[0m| 25/26 [00:24<00:00,  1.10it/s]Epoch: 3/10. Loss: 0.8104:  96%|[36m█████████▌[0m| 25/26 [00:24<00:00,  1.10it/s]Epoch: 3/10. Loss: 0.8104: 100%|[36m██████████[0m| 26/26 [00:24<00:00,  1.20it/s]Epoch: 3/10. Loss: 0.8104: 100%|[36m██████████[0m| 26/26 [00:24<00:00,  1.05it/s]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:04,  1.30it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:05,  1.08s/it] 43%|[33m████▎     [0m| 3/7 [00:02<00:03,  1.17it/s] 57%|[33m█████▋    [0m| 4/7 [00:03<00:02,  1.07it/s] 71%|[33m███████▏  [0m| 5/7 [00:04<00:01,  1.33it/s] 86%|[33m████████▌ [0m| 6/7 [00:04<00:00,  1.32it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.67it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.35it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 4/10. Loss: 0.8856:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 4/10. Loss: 0.8856:   4%|[36m▍         [0m| 1/26 [00:00<00:23,  1.06it/s]Epoch: 4/10. Loss: 0.8117:   4%|[36m▍         [0m| 1/26 [00:01<00:23,  1.06it/s]Epoch: 4/10. Loss: 0.8117:   8%|[36m▊         [0m| 2/26 [00:01<00:21,  1.12it/s]Epoch: 4/10. Loss: 0.8904:   8%|[36m▊         [0m| 2/26 [00:02<00:21,  1.12it/s]Epoch: 4/10. Loss: 0.8904:  12%|[36m█▏        [0m| 3/26 [00:02<00:20,  1.13it/s]Epoch: 4/10. Loss: 0.8520:  12%|[36m█▏        [0m| 3/26 [00:03<00:20,  1.13it/s]Epoch: 4/10. Loss: 0.8520:  15%|[36m█▌        [0m| 4/26 [00:03<00:20,  1.07it/s]Epoch: 4/10. Loss: 0.7736:  15%|[36m█▌        [0m| 4/26 [00:04<00:20,  1.07it/s]Epoch: 4/10. Loss: 0.7736:  19%|[36m█▉        [0m| 5/26 [00:04<00:19,  1.07it/s]Epoch: 4/10. Loss: 0.8642:  19%|[36m█▉        [0m| 5/26 [00:05<00:19,  1.07it/s]Epoch: 4/10. Loss: 0.8642:  23%|[36m██▎       [0m| 6/26 [00:05<00:18,  1.08it/s]Epoch: 4/10. Loss: 0.8492:  23%|[36m██▎       [0m| 6/26 [00:06<00:18,  1.08it/s]Epoch: 4/10. Loss: 0.8492:  27%|[36m██▋       [0m| 7/26 [00:06<00:17,  1.08it/s]Epoch: 4/10. Loss: 0.8927:  27%|[36m██▋       [0m| 7/26 [00:07<00:17,  1.08it/s]Epoch: 4/10. Loss: 0.8927:  31%|[36m███       [0m| 8/26 [00:07<00:16,  1.12it/s]Epoch: 4/10. Loss: 0.8049:  31%|[36m███       [0m| 8/26 [00:08<00:16,  1.12it/s]Epoch: 4/10. Loss: 0.8049:  35%|[36m███▍      [0m| 9/26 [00:08<00:15,  1.11it/s]Epoch: 4/10. Loss: 0.7901:  35%|[36m███▍      [0m| 9/26 [00:09<00:15,  1.11it/s]Epoch: 4/10. Loss: 0.7901:  38%|[36m███▊      [0m| 10/26 [00:09<00:14,  1.13it/s]Epoch: 4/10. Loss: 1.0358:  38%|[36m███▊      [0m| 10/26 [00:09<00:14,  1.13it/s]Epoch: 4/10. Loss: 1.0358:  42%|[36m████▏     [0m| 11/26 [00:10<00:13,  1.10it/s]Epoch: 4/10. Loss: 0.8475:  42%|[36m████▏     [0m| 11/26 [00:10<00:13,  1.10it/s]Epoch: 4/10. Loss: 0.8475:  46%|[36m████▌     [0m| 12/26 [00:10<00:12,  1.14it/s]Epoch: 4/10. Loss: 0.8889:  46%|[36m████▌     [0m| 12/26 [00:11<00:12,  1.14it/s]Epoch: 4/10. Loss: 0.8889:  50%|[36m█████     [0m| 13/26 [00:11<00:10,  1.21it/s]Epoch: 4/10. Loss: 0.8966:  50%|[36m█████     [0m| 13/26 [00:12<00:10,  1.21it/s]Epoch: 4/10. Loss: 0.8966:  54%|[36m█████▍    [0m| 14/26 [00:12<00:09,  1.22it/s]Epoch: 4/10. Loss: 0.8304:  54%|[36m█████▍    [0m| 14/26 [00:13<00:09,  1.22it/s]Epoch: 4/10. Loss: 0.8304:  58%|[36m█████▊    [0m| 15/26 [00:13<00:09,  1.17it/s]Epoch: 4/10. Loss: 0.8061:  58%|[36m█████▊    [0m| 15/26 [00:14<00:09,  1.17it/s]Epoch: 4/10. Loss: 0.8061:  62%|[36m██████▏   [0m| 16/26 [00:14<00:08,  1.15it/s]Epoch: 4/10. Loss: 0.8857:  62%|[36m██████▏   [0m| 16/26 [00:15<00:08,  1.15it/s]Epoch: 4/10. Loss: 0.8857:  65%|[36m██████▌   [0m| 17/26 [00:15<00:08,  1.09it/s]Epoch: 4/10. Loss: 0.8599:  65%|[36m██████▌   [0m| 17/26 [00:16<00:08,  1.09it/s]Epoch: 4/10. Loss: 0.8599:  69%|[36m██████▉   [0m| 18/26 [00:16<00:07,  1.09it/s]Epoch: 4/10. Loss: 0.8422:  69%|[36m██████▉   [0m| 18/26 [00:17<00:07,  1.09it/s]Epoch: 4/10. Loss: 0.8422:  73%|[36m███████▎  [0m| 19/26 [00:17<00:06,  1.08it/s]Epoch: 4/10. Loss: 0.8004:  73%|[36m███████▎  [0m| 19/26 [00:18<00:06,  1.08it/s]Epoch: 4/10. Loss: 0.8004:  77%|[36m███████▋  [0m| 20/26 [00:18<00:05,  1.06it/s]Epoch: 4/10. Loss: 0.8914:  77%|[36m███████▋  [0m| 20/26 [00:18<00:05,  1.06it/s]Epoch: 4/10. Loss: 0.8914:  81%|[36m████████  [0m| 21/26 [00:18<00:04,  1.14it/s]Epoch: 4/10. Loss: 0.8492:  81%|[36m████████  [0m| 21/26 [00:19<00:04,  1.14it/s]Epoch: 4/10. Loss: 0.8492:  85%|[36m████████▍ [0m| 22/26 [00:19<00:03,  1.12it/s]Epoch: 4/10. Loss: 0.8525:  85%|[36m████████▍ [0m| 22/26 [00:20<00:03,  1.12it/s]Epoch: 4/10. Loss: 0.8525:  88%|[36m████████▊ [0m| 23/26 [00:20<00:02,  1.16it/s]Epoch: 4/10. Loss: 0.8851:  88%|[36m████████▊ [0m| 23/26 [00:21<00:02,  1.16it/s]Epoch: 4/10. Loss: 0.8851:  92%|[36m█████████▏[0m| 24/26 [00:21<00:01,  1.13it/s]Epoch: 4/10. Loss: 0.8259:  92%|[36m█████████▏[0m| 24/26 [00:22<00:01,  1.13it/s]Epoch: 4/10. Loss: 0.8259:  96%|[36m█████████▌[0m| 25/26 [00:22<00:00,  1.05it/s]Epoch: 4/10. Loss: 0.9374:  96%|[36m█████████▌[0m| 25/26 [00:23<00:00,  1.05it/s]Epoch: 4/10. Loss: 0.9374: 100%|[36m██████████[0m| 26/26 [00:23<00:00,  1.08it/s]Epoch: 4/10. Loss: 0.9374: 100%|[36m██████████[0m| 26/26 [00:23<00:00,  1.11it/s]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:04,  1.33it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:05,  1.08s/it] 43%|[33m████▎     [0m| 3/7 [00:02<00:03,  1.15it/s] 57%|[33m█████▋    [0m| 4/7 [00:03<00:02,  1.06it/s] 71%|[33m███████▏  [0m| 5/7 [00:04<00:01,  1.30it/s] 86%|[33m████████▌ [0m| 6/7 [00:04<00:00,  1.30it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.64it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.33it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 5/10. Loss: 0.7722:   0%|[36m          [0m| 0/26 [00:01<?, ?it/s]Epoch: 5/10. Loss: 0.7722:   4%|[36m▍         [0m| 1/26 [00:01<00:26,  1.05s/it]Epoch: 5/10. Loss: 0.7514:   4%|[36m▍         [0m| 1/26 [00:01<00:26,  1.05s/it]Epoch: 5/10. Loss: 0.7514:   8%|[36m▊         [0m| 2/26 [00:01<00:23,  1.02it/s]Epoch: 5/10. Loss: 0.9341:   8%|[36m▊         [0m| 2/26 [00:02<00:23,  1.02it/s]Epoch: 5/10. Loss: 0.9341:  12%|[36m█▏        [0m| 3/26 [00:02<00:22,  1.02it/s]Epoch: 5/10. Loss: 0.8370:  12%|[36m█▏        [0m| 3/26 [00:03<00:22,  1.02it/s]Epoch: 5/10. Loss: 0.8370:  15%|[36m█▌        [0m| 4/26 [00:03<00:20,  1.07it/s]Epoch: 5/10. Loss: 0.7553:  15%|[36m█▌        [0m| 4/26 [00:04<00:20,  1.07it/s]Epoch: 5/10. Loss: 0.7553:  19%|[36m█▉        [0m| 5/26 [00:04<00:19,  1.06it/s]Epoch: 5/10. Loss: 0.8252:  19%|[36m█▉        [0m| 5/26 [00:05<00:19,  1.06it/s]Epoch: 5/10. Loss: 0.8252:  23%|[36m██▎       [0m| 6/26 [00:05<00:19,  1.04it/s]Epoch: 5/10. Loss: 0.8301:  23%|[36m██▎       [0m| 6/26 [00:06<00:19,  1.04it/s]Epoch: 5/10. Loss: 0.8301:  27%|[36m██▋       [0m| 7/26 [00:06<00:17,  1.06it/s]Epoch: 5/10. Loss: 0.8853:  27%|[36m██▋       [0m| 7/26 [00:07<00:17,  1.06it/s]Epoch: 5/10. Loss: 0.8853:  31%|[36m███       [0m| 8/26 [00:07<00:15,  1.13it/s]Epoch: 5/10. Loss: 0.8222:  31%|[36m███       [0m| 8/26 [00:08<00:15,  1.13it/s]Epoch: 5/10. Loss: 0.8222:  35%|[36m███▍      [0m| 9/26 [00:08<00:15,  1.13it/s]Epoch: 5/10. Loss: 0.8346:  35%|[36m███▍      [0m| 9/26 [00:09<00:15,  1.13it/s]Epoch: 5/10. Loss: 0.8346:  38%|[36m███▊      [0m| 10/26 [00:09<00:15,  1.04it/s]Epoch: 5/10. Loss: 0.9226:  38%|[36m███▊      [0m| 10/26 [00:10<00:15,  1.04it/s]Epoch: 5/10. Loss: 0.9226:  42%|[36m████▏     [0m| 11/26 [00:10<00:13,  1.09it/s]Epoch: 5/10. Loss: 0.8420:  42%|[36m████▏     [0m| 11/26 [00:10<00:13,  1.09it/s]Epoch: 5/10. Loss: 0.8420:  46%|[36m████▌     [0m| 12/26 [00:10<00:11,  1.18it/s]Epoch: 5/10. Loss: 0.7246:  46%|[36m████▌     [0m| 12/26 [00:11<00:11,  1.18it/s]Epoch: 5/10. Loss: 0.7246:  50%|[36m█████     [0m| 13/26 [00:11<00:10,  1.23it/s]Epoch: 5/10. Loss: 0.9225:  50%|[36m█████     [0m| 13/26 [00:12<00:10,  1.23it/s]Epoch: 5/10. Loss: 0.9225:  54%|[36m█████▍    [0m| 14/26 [00:12<00:09,  1.25it/s]Epoch: 5/10. Loss: 0.7754:  54%|[36m█████▍    [0m| 14/26 [00:13<00:09,  1.25it/s]Epoch: 5/10. Loss: 0.7754:  58%|[36m█████▊    [0m| 15/26 [00:13<00:09,  1.16it/s]Epoch: 5/10. Loss: 0.8415:  58%|[36m█████▊    [0m| 15/26 [00:14<00:09,  1.16it/s]Epoch: 5/10. Loss: 0.8415:  62%|[36m██████▏   [0m| 16/26 [00:14<00:08,  1.16it/s]Epoch: 5/10. Loss: 0.8698:  62%|[36m██████▏   [0m| 16/26 [00:15<00:08,  1.16it/s]Epoch: 5/10. Loss: 0.8698:  65%|[36m██████▌   [0m| 17/26 [00:15<00:07,  1.14it/s]Epoch: 5/10. Loss: 0.8607:  65%|[36m██████▌   [0m| 17/26 [00:16<00:07,  1.14it/s]Epoch: 5/10. Loss: 0.8607:  69%|[36m██████▉   [0m| 18/26 [00:16<00:07,  1.10it/s]Epoch: 5/10. Loss: 0.9308:  69%|[36m██████▉   [0m| 18/26 [00:17<00:07,  1.10it/s]Epoch: 5/10. Loss: 0.9308:  73%|[36m███████▎  [0m| 19/26 [00:17<00:06,  1.07it/s]Epoch: 5/10. Loss: 0.8871:  73%|[36m███████▎  [0m| 19/26 [00:17<00:06,  1.07it/s]Epoch: 5/10. Loss: 0.8871:  77%|[36m███████▋  [0m| 20/26 [00:17<00:05,  1.13it/s]Epoch: 5/10. Loss: 0.8008:  77%|[36m███████▋  [0m| 20/26 [00:19<00:05,  1.13it/s]Epoch: 5/10. Loss: 0.8008:  81%|[36m████████  [0m| 21/26 [00:19<00:04,  1.04it/s]Epoch: 5/10. Loss: 0.8934:  81%|[36m████████  [0m| 21/26 [00:20<00:04,  1.04it/s]Epoch: 5/10. Loss: 0.8934:  85%|[36m████████▍ [0m| 22/26 [00:20<00:03,  1.02it/s]Epoch: 5/10. Loss: 1.0308:  85%|[36m████████▍ [0m| 22/26 [00:20<00:03,  1.02it/s]Epoch: 5/10. Loss: 1.0308:  88%|[36m████████▊ [0m| 23/26 [00:20<00:02,  1.06it/s]Epoch: 5/10. Loss: 0.8160:  88%|[36m████████▊ [0m| 23/26 [00:22<00:02,  1.06it/s]Epoch: 5/10. Loss: 0.8160:  92%|[36m█████████▏[0m| 24/26 [00:22<00:01,  1.01it/s]Epoch: 5/10. Loss: 0.7767:  92%|[36m█████████▏[0m| 24/26 [00:23<00:01,  1.01it/s]Epoch: 5/10. Loss: 0.7767:  96%|[36m█████████▌[0m| 25/26 [00:23<00:00,  1.03it/s]Epoch: 5/10. Loss: 0.8494:  96%|[36m█████████▌[0m| 25/26 [00:23<00:00,  1.03it/s]Epoch: 5/10. Loss: 0.8494: 100%|[36m██████████[0m| 26/26 [00:23<00:00,  1.15it/s]Epoch: 5/10. Loss: 0.8494: 100%|[36m██████████[0m| 26/26 [00:23<00:00,  1.10it/s]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:04,  1.27it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:05,  1.09s/it] 43%|[33m████▎     [0m| 3/7 [00:02<00:03,  1.15it/s] 57%|[33m█████▋    [0m| 4/7 [00:03<00:02,  1.05it/s] 71%|[33m███████▏  [0m| 5/7 [00:04<00:01,  1.30it/s] 86%|[33m████████▌ [0m| 6/7 [00:05<00:00,  1.29it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.64it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.33it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 6/10. Loss: 0.8551:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 6/10. Loss: 0.8551:   4%|[36m▍         [0m| 1/26 [00:00<00:18,  1.35it/s]Epoch: 6/10. Loss: 0.8342:   4%|[36m▍         [0m| 1/26 [00:01<00:18,  1.35it/s]Epoch: 6/10. Loss: 0.8342:   8%|[36m▊         [0m| 2/26 [00:01<00:19,  1.24it/s]Epoch: 6/10. Loss: 0.7710:   8%|[36m▊         [0m| 2/26 [00:02<00:19,  1.24it/s]Epoch: 6/10. Loss: 0.7710:  12%|[36m█▏        [0m| 3/26 [00:02<00:20,  1.12it/s]Epoch: 6/10. Loss: 0.8191:  12%|[36m█▏        [0m| 3/26 [00:03<00:20,  1.12it/s]Epoch: 6/10. Loss: 0.8191:  15%|[36m█▌        [0m| 4/26 [00:03<00:19,  1.12it/s]Epoch: 6/10. Loss: 0.8258:  15%|[36m█▌        [0m| 4/26 [00:04<00:19,  1.12it/s]Epoch: 6/10. Loss: 0.8258:  19%|[36m█▉        [0m| 5/26 [00:04<00:18,  1.11it/s]Epoch: 6/10. Loss: 0.8480:  19%|[36m█▉        [0m| 5/26 [00:05<00:18,  1.11it/s]Epoch: 6/10. Loss: 0.8480:  23%|[36m██▎       [0m| 6/26 [00:05<00:18,  1.11it/s]Epoch: 6/10. Loss: 0.8585:  23%|[36m██▎       [0m| 6/26 [00:06<00:18,  1.11it/s]Epoch: 6/10. Loss: 0.8585:  27%|[36m██▋       [0m| 7/26 [00:06<00:16,  1.13it/s]Epoch: 6/10. Loss: 0.7292:  27%|[36m██▋       [0m| 7/26 [00:06<00:16,  1.13it/s]Epoch: 6/10. Loss: 0.7292:  31%|[36m███       [0m| 8/26 [00:06<00:15,  1.15it/s]Epoch: 6/10. Loss: 0.7154:  31%|[36m███       [0m| 8/26 [00:07<00:15,  1.15it/s]Epoch: 6/10. Loss: 0.7154:  35%|[36m███▍      [0m| 9/26 [00:07<00:14,  1.18it/s]Epoch: 6/10. Loss: 0.7248:  35%|[36m███▍      [0m| 9/26 [00:08<00:14,  1.18it/s]Epoch: 6/10. Loss: 0.7248:  38%|[36m███▊      [0m| 10/26 [00:08<00:14,  1.09it/s]Epoch: 6/10. Loss: 0.8109:  38%|[36m███▊      [0m| 10/26 [00:09<00:14,  1.09it/s]Epoch: 6/10. Loss: 0.8109:  42%|[36m████▏     [0m| 11/26 [00:09<00:13,  1.10it/s]Epoch: 6/10. Loss: 0.8645:  42%|[36m████▏     [0m| 11/26 [00:10<00:13,  1.10it/s]Epoch: 6/10. Loss: 0.8645:  46%|[36m████▌     [0m| 12/26 [00:10<00:12,  1.13it/s]Epoch: 6/10. Loss: 0.8024:  46%|[36m████▌     [0m| 12/26 [00:11<00:12,  1.13it/s]Epoch: 6/10. Loss: 0.8024:  50%|[36m█████     [0m| 13/26 [00:11<00:11,  1.13it/s]Epoch: 6/10. Loss: 0.8032:  50%|[36m█████     [0m| 13/26 [00:12<00:11,  1.13it/s]Epoch: 6/10. Loss: 0.8032:  54%|[36m█████▍    [0m| 14/26 [00:12<00:11,  1.09it/s]Epoch: 6/10. Loss: 0.7009:  54%|[36m█████▍    [0m| 14/26 [00:13<00:11,  1.09it/s]Epoch: 6/10. Loss: 0.7009:  58%|[36m█████▊    [0m| 15/26 [00:13<00:10,  1.06it/s]Epoch: 6/10. Loss: 0.9305:  58%|[36m█████▊    [0m| 15/26 [00:14<00:10,  1.06it/s]Epoch: 6/10. Loss: 0.9305:  62%|[36m██████▏   [0m| 16/26 [00:14<00:09,  1.04it/s]Epoch: 6/10. Loss: 0.8601:  62%|[36m██████▏   [0m| 16/26 [00:15<00:09,  1.04it/s]Epoch: 6/10. Loss: 0.8601:  65%|[36m██████▌   [0m| 17/26 [00:15<00:08,  1.01it/s]Epoch: 6/10. Loss: 0.9162:  65%|[36m██████▌   [0m| 17/26 [00:16<00:08,  1.01it/s]Epoch: 6/10. Loss: 0.9162:  69%|[36m██████▉   [0m| 18/26 [00:16<00:07,  1.03it/s]Epoch: 6/10. Loss: 0.8360:  69%|[36m██████▉   [0m| 18/26 [00:17<00:07,  1.03it/s]Epoch: 6/10. Loss: 0.8360:  73%|[36m███████▎  [0m| 19/26 [00:17<00:06,  1.06it/s]Epoch: 6/10. Loss: 0.8804:  73%|[36m███████▎  [0m| 19/26 [00:18<00:06,  1.06it/s]Epoch: 6/10. Loss: 0.8804:  77%|[36m███████▋  [0m| 20/26 [00:18<00:05,  1.04it/s]Epoch: 6/10. Loss: 0.8520:  77%|[36m███████▋  [0m| 20/26 [00:19<00:05,  1.04it/s]Epoch: 6/10. Loss: 0.8520:  81%|[36m████████  [0m| 21/26 [00:19<00:04,  1.10it/s]Epoch: 6/10. Loss: 0.8147:  81%|[36m████████  [0m| 21/26 [00:19<00:04,  1.10it/s]Epoch: 6/10. Loss: 0.8147:  85%|[36m████████▍ [0m| 22/26 [00:19<00:03,  1.12it/s]Epoch: 6/10. Loss: 0.8382:  85%|[36m████████▍ [0m| 22/26 [00:20<00:03,  1.12it/s]Epoch: 6/10. Loss: 0.8382:  88%|[36m████████▊ [0m| 23/26 [00:20<00:02,  1.16it/s]Epoch: 6/10. Loss: 0.8635:  88%|[36m████████▊ [0m| 23/26 [00:21<00:02,  1.16it/s]Epoch: 6/10. Loss: 0.8635:  92%|[36m█████████▏[0m| 24/26 [00:21<00:01,  1.12it/s]Epoch: 6/10. Loss: 0.8018:  92%|[36m█████████▏[0m| 24/26 [00:22<00:01,  1.12it/s]Epoch: 6/10. Loss: 0.8018:  96%|[36m█████████▌[0m| 25/26 [00:22<00:00,  1.07it/s]Epoch: 6/10. Loss: 0.8082:  96%|[36m█████████▌[0m| 25/26 [00:23<00:00,  1.07it/s]Epoch: 6/10. Loss: 0.8082: 100%|[36m██████████[0m| 26/26 [00:23<00:00,  1.14it/s]Epoch: 6/10. Loss: 0.8082: 100%|[36m██████████[0m| 26/26 [00:23<00:00,  1.11it/s]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:04,  1.29it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:05,  1.09s/it] 43%|[33m████▎     [0m| 3/7 [00:02<00:03,  1.15it/s] 57%|[33m█████▋    [0m| 4/7 [00:03<00:02,  1.05it/s] 71%|[33m███████▏  [0m| 5/7 [00:04<00:01,  1.28it/s] 86%|[33m████████▌ [0m| 6/7 [00:05<00:00,  1.28it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.62it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.32it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 7/10. Loss: 0.7458:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 7/10. Loss: 0.7458:   4%|[36m▍         [0m| 1/26 [00:00<00:21,  1.15it/s]Epoch: 7/10. Loss: 0.9000:   4%|[36m▍         [0m| 1/26 [00:01<00:21,  1.15it/s]Epoch: 7/10. Loss: 0.9000:   8%|[36m▊         [0m| 2/26 [00:01<00:24,  1.00s/it]Epoch: 7/10. Loss: 0.7739:   8%|[36m▊         [0m| 2/26 [00:02<00:24,  1.00s/it]Epoch: 7/10. Loss: 0.7739:  12%|[36m█▏        [0m| 3/26 [00:02<00:22,  1.00it/s]Epoch: 7/10. Loss: 0.7753:  12%|[36m█▏        [0m| 3/26 [00:03<00:22,  1.00it/s]Epoch: 7/10. Loss: 0.7753:  15%|[36m█▌        [0m| 4/26 [00:03<00:21,  1.03it/s]Epoch: 7/10. Loss: 0.7364:  15%|[36m█▌        [0m| 4/26 [00:04<00:21,  1.03it/s]Epoch: 7/10. Loss: 0.7364:  19%|[36m█▉        [0m| 5/26 [00:04<00:19,  1.06it/s]Epoch: 7/10. Loss: 0.7065:  19%|[36m█▉        [0m| 5/26 [00:05<00:19,  1.06it/s]Epoch: 7/10. Loss: 0.7065:  23%|[36m██▎       [0m| 6/26 [00:05<00:18,  1.08it/s]Epoch: 7/10. Loss: 0.7598:  23%|[36m██▎       [0m| 6/26 [00:06<00:18,  1.08it/s]Epoch: 7/10. Loss: 0.7598:  27%|[36m██▋       [0m| 7/26 [00:06<00:17,  1.12it/s]Epoch: 7/10. Loss: 0.7917:  27%|[36m██▋       [0m| 7/26 [00:07<00:17,  1.12it/s]Epoch: 7/10. Loss: 0.7917:  31%|[36m███       [0m| 8/26 [00:07<00:15,  1.14it/s]Epoch: 7/10. Loss: 0.7795:  31%|[36m███       [0m| 8/26 [00:08<00:15,  1.14it/s]Epoch: 7/10. Loss: 0.7795:  35%|[36m███▍      [0m| 9/26 [00:08<00:16,  1.05it/s]Epoch: 7/10. Loss: 0.7637:  35%|[36m███▍      [0m| 9/26 [00:09<00:16,  1.05it/s]Epoch: 7/10. Loss: 0.7637:  38%|[36m███▊      [0m| 10/26 [00:09<00:14,  1.08it/s]Epoch: 7/10. Loss: 0.7436:  38%|[36m███▊      [0m| 10/26 [00:10<00:14,  1.08it/s]Epoch: 7/10. Loss: 0.7436:  42%|[36m████▏     [0m| 11/26 [00:10<00:14,  1.04it/s]Epoch: 7/10. Loss: 0.7879:  42%|[36m████▏     [0m| 11/26 [00:11<00:14,  1.04it/s]Epoch: 7/10. Loss: 0.7879:  46%|[36m████▌     [0m| 12/26 [00:11<00:13,  1.08it/s]Epoch: 7/10. Loss: 0.8111:  46%|[36m████▌     [0m| 12/26 [00:12<00:13,  1.08it/s]Epoch: 7/10. Loss: 0.8111:  50%|[36m█████     [0m| 13/26 [00:12<00:12,  1.07it/s]Epoch: 7/10. Loss: 0.7827:  50%|[36m█████     [0m| 13/26 [00:13<00:12,  1.07it/s]Epoch: 7/10. Loss: 0.7827:  54%|[36m█████▍    [0m| 14/26 [00:13<00:11,  1.09it/s]Epoch: 7/10. Loss: 0.7657:  54%|[36m█████▍    [0m| 14/26 [00:13<00:11,  1.09it/s]Epoch: 7/10. Loss: 0.7657:  58%|[36m█████▊    [0m| 15/26 [00:13<00:10,  1.10it/s]Epoch: 7/10. Loss: 0.8634:  58%|[36m█████▊    [0m| 15/26 [00:14<00:10,  1.10it/s]Epoch: 7/10. Loss: 0.8634:  62%|[36m██████▏   [0m| 16/26 [00:14<00:09,  1.10it/s]Epoch: 7/10. Loss: 0.7305:  62%|[36m██████▏   [0m| 16/26 [00:15<00:09,  1.10it/s]Epoch: 7/10. Loss: 0.7305:  65%|[36m██████▌   [0m| 17/26 [00:15<00:08,  1.10it/s]Epoch: 7/10. Loss: 0.8014:  65%|[36m██████▌   [0m| 17/26 [00:16<00:08,  1.10it/s]Epoch: 7/10. Loss: 0.8014:  69%|[36m██████▉   [0m| 18/26 [00:16<00:07,  1.10it/s]Epoch: 7/10. Loss: 0.7377:  69%|[36m██████▉   [0m| 18/26 [00:17<00:07,  1.10it/s]Epoch: 7/10. Loss: 0.7377:  73%|[36m███████▎  [0m| 19/26 [00:17<00:06,  1.09it/s]Epoch: 7/10. Loss: 0.7750:  73%|[36m███████▎  [0m| 19/26 [00:18<00:06,  1.09it/s]Epoch: 7/10. Loss: 0.7750:  77%|[36m███████▋  [0m| 20/26 [00:18<00:05,  1.11it/s]Epoch: 7/10. Loss: 0.7933:  77%|[36m███████▋  [0m| 20/26 [00:19<00:05,  1.11it/s]Epoch: 7/10. Loss: 0.7933:  81%|[36m████████  [0m| 21/26 [00:19<00:04,  1.08it/s]Epoch: 7/10. Loss: 0.7821:  81%|[36m████████  [0m| 21/26 [00:20<00:04,  1.08it/s]Epoch: 7/10. Loss: 0.7821:  85%|[36m████████▍ [0m| 22/26 [00:20<00:03,  1.11it/s]Epoch: 7/10. Loss: 0.7371:  85%|[36m████████▍ [0m| 22/26 [00:21<00:03,  1.11it/s]Epoch: 7/10. Loss: 0.7371:  88%|[36m████████▊ [0m| 23/26 [00:21<00:02,  1.05it/s]Epoch: 7/10. Loss: 0.7106:  88%|[36m████████▊ [0m| 23/26 [00:22<00:02,  1.05it/s]Epoch: 7/10. Loss: 0.7106:  92%|[36m█████████▏[0m| 24/26 [00:22<00:01,  1.06it/s]Epoch: 7/10. Loss: 0.7107:  92%|[36m█████████▏[0m| 24/26 [00:23<00:01,  1.06it/s]Epoch: 7/10. Loss: 0.7107:  96%|[36m█████████▌[0m| 25/26 [00:23<00:00,  1.08it/s]Epoch: 7/10. Loss: 0.7199:  96%|[36m█████████▌[0m| 25/26 [00:23<00:00,  1.08it/s]Epoch: 7/10. Loss: 0.7199: 100%|[36m██████████[0m| 26/26 [00:23<00:00,  1.22it/s]Epoch: 7/10. Loss: 0.7199: 100%|[36m██████████[0m| 26/26 [00:23<00:00,  1.10it/s]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:04,  1.29it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:05,  1.11s/it] 43%|[33m████▎     [0m| 3/7 [00:02<00:03,  1.13it/s] 57%|[33m█████▋    [0m| 4/7 [00:03<00:02,  1.02it/s] 71%|[33m███████▏  [0m| 5/7 [00:04<00:01,  1.28it/s] 86%|[33m████████▌ [0m| 6/7 [00:05<00:00,  1.28it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.63it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.31it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 8/10. Loss: 0.7323:   0%|[36m          [0m| 0/26 [00:01<?, ?it/s]Epoch: 8/10. Loss: 0.7323:   4%|[36m▍         [0m| 1/26 [00:01<00:27,  1.10s/it]Epoch: 8/10. Loss: 0.6157:   4%|[36m▍         [0m| 1/26 [00:01<00:27,  1.10s/it]Epoch: 8/10. Loss: 0.6157:   8%|[36m▊         [0m| 2/26 [00:01<00:22,  1.07it/s]Epoch: 8/10. Loss: 0.9222:   8%|[36m▊         [0m| 2/26 [00:02<00:22,  1.07it/s]Epoch: 8/10. Loss: 0.9222:  12%|[36m█▏        [0m| 3/26 [00:02<00:20,  1.14it/s]Epoch: 8/10. Loss: 0.6617:  12%|[36m█▏        [0m| 3/26 [00:03<00:20,  1.14it/s]Epoch: 8/10. Loss: 0.6617:  15%|[36m█▌        [0m| 4/26 [00:03<00:18,  1.17it/s]Epoch: 8/10. Loss: 0.7921:  15%|[36m█▌        [0m| 4/26 [00:04<00:18,  1.17it/s]Epoch: 8/10. Loss: 0.7921:  19%|[36m█▉        [0m| 5/26 [00:04<00:18,  1.15it/s]Epoch: 8/10. Loss: 0.6271:  19%|[36m█▉        [0m| 5/26 [00:05<00:18,  1.15it/s]Epoch: 8/10. Loss: 0.6271:  23%|[36m██▎       [0m| 6/26 [00:05<00:17,  1.13it/s]Epoch: 8/10. Loss: 0.7100:  23%|[36m██▎       [0m| 6/26 [00:06<00:17,  1.13it/s]Epoch: 8/10. Loss: 0.7100:  27%|[36m██▋       [0m| 7/26 [00:06<00:17,  1.08it/s]Epoch: 8/10. Loss: 0.6894:  27%|[36m██▋       [0m| 7/26 [00:07<00:17,  1.08it/s]Epoch: 8/10. Loss: 0.6894:  31%|[36m███       [0m| 8/26 [00:07<00:15,  1.13it/s]Epoch: 8/10. Loss: 0.7691:  31%|[36m███       [0m| 8/26 [00:08<00:15,  1.13it/s]Epoch: 8/10. Loss: 0.7691:  35%|[36m███▍      [0m| 9/26 [00:08<00:15,  1.13it/s]Epoch: 8/10. Loss: 0.8329:  35%|[36m███▍      [0m| 9/26 [00:09<00:15,  1.13it/s]Epoch: 8/10. Loss: 0.8329:  38%|[36m███▊      [0m| 10/26 [00:10<00:19,  1.22s/it]Epoch: 8/10. Loss: 0.8066:  38%|[36m███▊      [0m| 10/26 [00:10<00:19,  1.22s/it]Epoch: 8/10. Loss: 0.8066:  42%|[36m████▏     [0m| 11/26 [00:10<00:16,  1.09s/it]Epoch: 8/10. Loss: 0.7444:  42%|[36m████▏     [0m| 11/26 [00:11<00:16,  1.09s/it]Epoch: 8/10. Loss: 0.7444:  46%|[36m████▌     [0m| 12/26 [00:11<00:14,  1.04s/it]Epoch: 8/10. Loss: 0.7907:  46%|[36m████▌     [0m| 12/26 [00:12<00:14,  1.04s/it]Epoch: 8/10. Loss: 0.7907:  50%|[36m█████     [0m| 13/26 [00:12<00:12,  1.00it/s]Epoch: 8/10. Loss: 0.7011:  50%|[36m█████     [0m| 13/26 [00:13<00:12,  1.00it/s]Epoch: 8/10. Loss: 0.7011:  54%|[36m█████▍    [0m| 14/26 [00:13<00:11,  1.03it/s]Epoch: 8/10. Loss: 0.8771:  54%|[36m█████▍    [0m| 14/26 [00:14<00:11,  1.03it/s]Epoch: 8/10. Loss: 0.8771:  58%|[36m█████▊    [0m| 15/26 [00:14<00:10,  1.05it/s]Epoch: 8/10. Loss: 0.7184:  58%|[36m█████▊    [0m| 15/26 [00:15<00:10,  1.05it/s]Epoch: 8/10. Loss: 0.7184:  62%|[36m██████▏   [0m| 16/26 [00:15<00:09,  1.07it/s]Epoch: 8/10. Loss: 0.6935:  62%|[36m██████▏   [0m| 16/26 [00:16<00:09,  1.07it/s]Epoch: 8/10. Loss: 0.6935:  65%|[36m██████▌   [0m| 17/26 [00:16<00:08,  1.12it/s]Epoch: 8/10. Loss: 0.8095:  65%|[36m██████▌   [0m| 17/26 [00:19<00:08,  1.12it/s]Epoch: 8/10. Loss: 0.8095:  69%|[36m██████▉   [0m| 18/26 [00:19<00:12,  1.56s/it]Epoch: 8/10. Loss: 0.8139:  69%|[36m██████▉   [0m| 18/26 [00:20<00:12,  1.56s/it]Epoch: 8/10. Loss: 0.8139:  73%|[36m███████▎  [0m| 19/26 [00:20<00:11,  1.58s/it]Epoch: 8/10. Loss: 0.8361:  73%|[36m███████▎  [0m| 19/26 [00:21<00:11,  1.58s/it]Epoch: 8/10. Loss: 0.8361:  77%|[36m███████▋  [0m| 20/26 [00:21<00:08,  1.39s/it]Epoch: 8/10. Loss: 0.6965:  77%|[36m███████▋  [0m| 20/26 [00:22<00:08,  1.39s/it]Epoch: 8/10. Loss: 0.6965:  81%|[36m████████  [0m| 21/26 [00:22<00:06,  1.28s/it]Epoch: 8/10. Loss: 0.7775:  81%|[36m████████  [0m| 21/26 [00:23<00:06,  1.28s/it]Epoch: 8/10. Loss: 0.7775:  85%|[36m████████▍ [0m| 22/26 [00:23<00:04,  1.17s/it]Epoch: 8/10. Loss: 0.9887:  85%|[36m████████▍ [0m| 22/26 [00:24<00:04,  1.17s/it]Epoch: 8/10. Loss: 0.9887:  88%|[36m████████▊ [0m| 23/26 [00:24<00:03,  1.08s/it]Epoch: 8/10. Loss: 0.8311:  88%|[36m████████▊ [0m| 23/26 [00:25<00:03,  1.08s/it]Epoch: 8/10. Loss: 0.8311:  92%|[36m█████████▏[0m| 24/26 [00:25<00:02,  1.04s/it]Epoch: 8/10. Loss: 0.7521:  92%|[36m█████████▏[0m| 24/26 [00:26<00:02,  1.04s/it]Epoch: 8/10. Loss: 0.7521:  96%|[36m█████████▌[0m| 25/26 [00:26<00:00,  1.02it/s]Epoch: 8/10. Loss: 0.9312:  96%|[36m█████████▌[0m| 25/26 [00:27<00:00,  1.02it/s]Epoch: 8/10. Loss: 0.9312: 100%|[36m██████████[0m| 26/26 [00:27<00:00,  1.12it/s]Epoch: 8/10. Loss: 0.9312: 100%|[36m██████████[0m| 26/26 [00:27<00:00,  1.04s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:04,  1.32it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:05,  1.10s/it] 43%|[33m████▎     [0m| 3/7 [00:02<00:03,  1.11it/s] 57%|[33m█████▋    [0m| 4/7 [00:03<00:02,  1.01it/s] 71%|[33m███████▏  [0m| 5/7 [00:04<00:01,  1.24it/s] 86%|[33m████████▌ [0m| 6/7 [00:05<00:00,  1.24it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.57it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.28it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 9/10. Loss: 0.8104:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 9/10. Loss: 0.8104:   4%|[36m▍         [0m| 1/26 [00:00<00:22,  1.12it/s]Epoch: 9/10. Loss: 0.6651:   4%|[36m▍         [0m| 1/26 [00:01<00:22,  1.12it/s]Epoch: 9/10. Loss: 0.6651:   8%|[36m▊         [0m| 2/26 [00:01<00:19,  1.25it/s]Epoch: 9/10. Loss: 0.8016:   8%|[36m▊         [0m| 2/26 [00:02<00:19,  1.25it/s]Epoch: 9/10. Loss: 0.8016:  12%|[36m█▏        [0m| 3/26 [00:02<00:21,  1.09it/s]Epoch: 9/10. Loss: 0.7296:  12%|[36m█▏        [0m| 3/26 [00:03<00:21,  1.09it/s]Epoch: 9/10. Loss: 0.7296:  15%|[36m█▌        [0m| 4/26 [00:03<00:19,  1.12it/s]Epoch: 9/10. Loss: 0.6716:  15%|[36m█▌        [0m| 4/26 [00:04<00:19,  1.12it/s]Epoch: 9/10. Loss: 0.6716:  19%|[36m█▉        [0m| 5/26 [00:04<00:18,  1.13it/s]Epoch: 9/10. Loss: 0.6658:  19%|[36m█▉        [0m| 5/26 [00:05<00:18,  1.13it/s]Epoch: 9/10. Loss: 0.6658:  23%|[36m██▎       [0m| 6/26 [00:05<00:17,  1.15it/s]Epoch: 9/10. Loss: 0.7530:  23%|[36m██▎       [0m| 6/26 [00:06<00:17,  1.15it/s]Epoch: 9/10. Loss: 0.7530:  27%|[36m██▋       [0m| 7/26 [00:06<00:16,  1.17it/s]Epoch: 9/10. Loss: 0.7255:  27%|[36m██▋       [0m| 7/26 [00:06<00:16,  1.17it/s]Epoch: 9/10. Loss: 0.7255:  31%|[36m███       [0m| 8/26 [00:06<00:15,  1.15it/s]Epoch: 9/10. Loss: 0.7967:  31%|[36m███       [0m| 8/26 [00:08<00:15,  1.15it/s]Epoch: 9/10. Loss: 0.7967:  35%|[36m███▍      [0m| 9/26 [00:08<00:15,  1.07it/s]Epoch: 9/10. Loss: 0.7189:  35%|[36m███▍      [0m| 9/26 [00:08<00:15,  1.07it/s]Epoch: 9/10. Loss: 0.7189:  38%|[36m███▊      [0m| 10/26 [00:08<00:14,  1.13it/s]Epoch: 9/10. Loss: 0.7708:  38%|[36m███▊      [0m| 10/26 [00:09<00:14,  1.13it/s]Epoch: 9/10. Loss: 0.7708:  42%|[36m████▏     [0m| 11/26 [00:09<00:13,  1.08it/s]Epoch: 9/10. Loss: 0.8407:  42%|[36m████▏     [0m| 11/26 [00:10<00:13,  1.08it/s]Epoch: 9/10. Loss: 0.8407:  46%|[36m████▌     [0m| 12/26 [00:10<00:12,  1.12it/s]Epoch: 9/10. Loss: 0.7176:  46%|[36m████▌     [0m| 12/26 [00:11<00:12,  1.12it/s]Epoch: 9/10. Loss: 0.7176:  50%|[36m█████     [0m| 13/26 [00:11<00:11,  1.14it/s]Epoch: 9/10. Loss: 0.6949:  50%|[36m█████     [0m| 13/26 [00:12<00:11,  1.14it/s]Epoch: 9/10. Loss: 0.6949:  54%|[36m█████▍    [0m| 14/26 [00:12<00:10,  1.12it/s]Epoch: 9/10. Loss: 0.6857:  54%|[36m█████▍    [0m| 14/26 [00:13<00:10,  1.12it/s]Epoch: 9/10. Loss: 0.6857:  58%|[36m█████▊    [0m| 15/26 [00:13<00:10,  1.09it/s]Epoch: 9/10. Loss: 0.7518:  58%|[36m█████▊    [0m| 15/26 [00:14<00:10,  1.09it/s]Epoch: 9/10. Loss: 0.7518:  62%|[36m██████▏   [0m| 16/26 [00:14<00:09,  1.07it/s]Epoch: 9/10. Loss: 0.8121:  62%|[36m██████▏   [0m| 16/26 [00:15<00:09,  1.07it/s]Epoch: 9/10. Loss: 0.8121:  65%|[36m██████▌   [0m| 17/26 [00:15<00:08,  1.09it/s]Epoch: 9/10. Loss: 0.7750:  65%|[36m██████▌   [0m| 17/26 [00:16<00:08,  1.09it/s]Epoch: 9/10. Loss: 0.7750:  69%|[36m██████▉   [0m| 18/26 [00:16<00:07,  1.09it/s]Epoch: 9/10. Loss: 0.7072:  69%|[36m██████▉   [0m| 18/26 [00:17<00:07,  1.09it/s]Epoch: 9/10. Loss: 0.7072:  73%|[36m███████▎  [0m| 19/26 [00:17<00:06,  1.11it/s]Epoch: 9/10. Loss: 0.7362:  73%|[36m███████▎  [0m| 19/26 [00:18<00:06,  1.11it/s]Epoch: 9/10. Loss: 0.7362:  77%|[36m███████▋  [0m| 20/26 [00:18<00:05,  1.04it/s]Epoch: 9/10. Loss: 0.8462:  77%|[36m███████▋  [0m| 20/26 [00:19<00:05,  1.04it/s]Epoch: 9/10. Loss: 0.8462:  81%|[36m████████  [0m| 21/26 [00:19<00:04,  1.04it/s]Epoch: 9/10. Loss: 0.7411:  81%|[36m████████  [0m| 21/26 [00:19<00:04,  1.04it/s]Epoch: 9/10. Loss: 0.7411:  85%|[36m████████▍ [0m| 22/26 [00:20<00:03,  1.05it/s]Epoch: 9/10. Loss: 0.8010:  85%|[36m████████▍ [0m| 22/26 [00:20<00:03,  1.05it/s]Epoch: 9/10. Loss: 0.8010:  88%|[36m████████▊ [0m| 23/26 [00:20<00:02,  1.06it/s]Epoch: 9/10. Loss: 0.7468:  88%|[36m████████▊ [0m| 23/26 [00:21<00:02,  1.06it/s]Epoch: 9/10. Loss: 0.7468:  92%|[36m█████████▏[0m| 24/26 [00:21<00:01,  1.10it/s]Epoch: 9/10. Loss: 0.8038:  92%|[36m█████████▏[0m| 24/26 [00:22<00:01,  1.10it/s]Epoch: 9/10. Loss: 0.8038:  96%|[36m█████████▌[0m| 25/26 [00:22<00:00,  1.09it/s]Epoch: 9/10. Loss: 0.8141:  96%|[36m█████████▌[0m| 25/26 [00:23<00:00,  1.09it/s]Epoch: 9/10. Loss: 0.8141: 100%|[36m██████████[0m| 26/26 [00:23<00:00,  1.16it/s]Epoch: 9/10. Loss: 0.8141: 100%|[36m██████████[0m| 26/26 [00:23<00:00,  1.11it/s]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:04,  1.29it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:05,  1.13s/it] 43%|[33m████▎     [0m| 3/7 [00:02<00:03,  1.11it/s] 57%|[33m█████▋    [0m| 4/7 [00:03<00:02,  1.03it/s] 71%|[33m███████▏  [0m| 5/7 [00:04<00:01,  1.28it/s] 86%|[33m████████▌ [0m| 6/7 [00:05<00:00,  1.28it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.62it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.30it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 0/10. Loss: 1.1005:   0%|[36m          [0m| 0/26 [00:01<?, ?it/s]Epoch: 0/10. Loss: 1.1005:   4%|[36m▍         [0m| 1/26 [00:01<00:30,  1.20s/it]Epoch: 0/10. Loss: 2.7560:   4%|[36m▍         [0m| 1/26 [00:02<00:30,  1.20s/it]Epoch: 0/10. Loss: 2.7560:   8%|[36m▊         [0m| 2/26 [00:02<00:26,  1.11s/it]Epoch: 0/10. Loss: 1.4820:   8%|[36m▊         [0m| 2/26 [00:03<00:26,  1.11s/it]Epoch: 0/10. Loss: 1.4820:  12%|[36m█▏        [0m| 3/26 [00:03<00:23,  1.00s/it]Epoch: 0/10. Loss: 2.3315:  12%|[36m█▏        [0m| 3/26 [00:03<00:23,  1.00s/it]Epoch: 0/10. Loss: 2.3315:  15%|[36m█▌        [0m| 4/26 [00:03<00:20,  1.06it/s]Epoch: 0/10. Loss: 1.5575:  15%|[36m█▌        [0m| 4/26 [00:04<00:20,  1.06it/s]Epoch: 0/10. Loss: 1.5575:  19%|[36m█▉        [0m| 5/26 [00:04<00:18,  1.12it/s]Epoch: 0/10. Loss: 1.1800:  19%|[36m█▉        [0m| 5/26 [00:07<00:18,  1.12it/s]Epoch: 0/10. Loss: 1.1800:  23%|[36m██▎       [0m| 6/26 [00:07<00:33,  1.69s/it]Epoch: 0/10. Loss: 1.1568:  23%|[36m██▎       [0m| 6/26 [00:08<00:33,  1.69s/it]Epoch: 0/10. Loss: 1.1568:  27%|[36m██▋       [0m| 7/26 [00:08<00:27,  1.44s/it]Epoch: 0/10. Loss: 1.1263:  27%|[36m██▋       [0m| 7/26 [00:09<00:27,  1.44s/it]Epoch: 0/10. Loss: 1.1263:  31%|[36m███       [0m| 8/26 [00:10<00:23,  1.32s/it]Epoch: 0/10. Loss: 1.0590:  31%|[36m███       [0m| 8/26 [00:10<00:23,  1.32s/it]Epoch: 0/10. Loss: 1.0590:  35%|[36m███▍      [0m| 9/26 [00:10<00:20,  1.19s/it]Epoch: 0/10. Loss: 1.0596:  35%|[36m███▍      [0m| 9/26 [00:11<00:20,  1.19s/it]Epoch: 0/10. Loss: 1.0596:  38%|[36m███▊      [0m| 10/26 [00:11<00:18,  1.14s/it]Epoch: 0/10. Loss: 1.0536:  38%|[36m███▊      [0m| 10/26 [00:12<00:18,  1.14s/it]Epoch: 0/10. Loss: 1.0536:  42%|[36m████▏     [0m| 11/26 [00:12<00:16,  1.07s/it]Epoch: 0/10. Loss: 1.0450:  42%|[36m████▏     [0m| 11/26 [00:13<00:16,  1.07s/it]Epoch: 0/10. Loss: 1.0450:  46%|[36m████▌     [0m| 12/26 [00:13<00:14,  1.07s/it]Epoch: 0/10. Loss: 1.0777:  46%|[36m████▌     [0m| 12/26 [00:14<00:14,  1.07s/it]Epoch: 0/10. Loss: 1.0777:  50%|[36m█████     [0m| 13/26 [00:14<00:13,  1.03s/it]Epoch: 0/10. Loss: 1.0121:  50%|[36m█████     [0m| 13/26 [00:15<00:13,  1.03s/it]Epoch: 0/10. Loss: 1.0121:  54%|[36m█████▍    [0m| 14/26 [00:15<00:12,  1.01s/it]Epoch: 0/10. Loss: 1.1222:  54%|[36m█████▍    [0m| 14/26 [00:16<00:12,  1.01s/it]Epoch: 0/10. Loss: 1.1222:  58%|[36m█████▊    [0m| 15/26 [00:16<00:10,  1.02it/s]Epoch: 0/10. Loss: 1.0478:  58%|[36m█████▊    [0m| 15/26 [00:17<00:10,  1.02it/s]Epoch: 0/10. Loss: 1.0478:  62%|[36m██████▏   [0m| 16/26 [00:17<00:09,  1.01it/s]Epoch: 0/10. Loss: 1.0174:  62%|[36m██████▏   [0m| 16/26 [00:18<00:09,  1.01it/s]Epoch: 0/10. Loss: 1.0174:  65%|[36m██████▌   [0m| 17/26 [00:18<00:08,  1.01it/s]Epoch: 0/10. Loss: 0.9660:  65%|[36m██████▌   [0m| 17/26 [00:19<00:08,  1.01it/s]Epoch: 0/10. Loss: 0.9660:  69%|[36m██████▉   [0m| 18/26 [00:19<00:07,  1.06it/s]Epoch: 0/10. Loss: 1.0900:  69%|[36m██████▉   [0m| 18/26 [00:20<00:07,  1.06it/s]Epoch: 0/10. Loss: 1.0900:  73%|[36m███████▎  [0m| 19/26 [00:20<00:06,  1.06it/s]Epoch: 0/10. Loss: 1.0438:  73%|[36m███████▎  [0m| 19/26 [00:21<00:06,  1.06it/s]Epoch: 0/10. Loss: 1.0438:  77%|[36m███████▋  [0m| 20/26 [00:21<00:05,  1.06it/s]Epoch: 0/10. Loss: 1.1051:  77%|[36m███████▋  [0m| 20/26 [00:22<00:05,  1.06it/s]Epoch: 0/10. Loss: 1.1051:  81%|[36m████████  [0m| 21/26 [00:22<00:04,  1.05it/s]Epoch: 0/10. Loss: 1.0528:  81%|[36m████████  [0m| 21/26 [00:23<00:04,  1.05it/s]Epoch: 0/10. Loss: 1.0528:  85%|[36m████████▍ [0m| 22/26 [00:23<00:03,  1.06it/s]Epoch: 0/10. Loss: 0.9507:  85%|[36m████████▍ [0m| 22/26 [00:24<00:03,  1.06it/s]Epoch: 0/10. Loss: 0.9507:  88%|[36m████████▊ [0m| 23/26 [00:24<00:02,  1.05it/s]Epoch: 0/10. Loss: 0.9921:  88%|[36m████████▊ [0m| 23/26 [00:25<00:02,  1.05it/s]Epoch: 0/10. Loss: 0.9921:  92%|[36m█████████▏[0m| 24/26 [00:25<00:02,  1.00s/it]Epoch: 0/10. Loss: 1.1497:  92%|[36m█████████▏[0m| 24/26 [00:26<00:02,  1.00s/it]Epoch: 0/10. Loss: 1.1497:  96%|[36m█████████▌[0m| 25/26 [00:26<00:00,  1.01it/s]Epoch: 0/10. Loss: 0.9791:  96%|[36m█████████▌[0m| 25/26 [00:27<00:00,  1.01it/s]Epoch: 0/10. Loss: 0.9791: 100%|[36m██████████[0m| 26/26 [00:27<00:00,  1.12it/s]Epoch: 0/10. Loss: 0.9791: 100%|[36m██████████[0m| 26/26 [00:27<00:00,  1.04s/it]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:04,  1.24it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:05,  1.16s/it] 43%|[33m████▎     [0m| 3/7 [00:02<00:03,  1.08it/s] 57%|[33m█████▋    [0m| 4/7 [00:03<00:03,  1.00s/it] 71%|[33m███████▏  [0m| 5/7 [00:04<00:01,  1.24it/s] 86%|[33m████████▌ [0m| 6/7 [00:05<00:00,  1.23it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.56it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.26it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 1/10. Loss: 1.0433:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 1/10. Loss: 1.0433:   4%|[36m▍         [0m| 1/26 [00:00<00:22,  1.11it/s]Epoch: 1/10. Loss: 1.0453:   4%|[36m▍         [0m| 1/26 [00:01<00:22,  1.11it/s]Epoch: 1/10. Loss: 1.0453:   8%|[36m▊         [0m| 2/26 [00:01<00:20,  1.17it/s]Epoch: 1/10. Loss: 0.9400:   8%|[36m▊         [0m| 2/26 [00:02<00:20,  1.17it/s]Epoch: 1/10. Loss: 0.9400:  12%|[36m█▏        [0m| 3/26 [00:02<00:18,  1.21it/s]Epoch: 1/10. Loss: 1.0691:  12%|[36m█▏        [0m| 3/26 [00:03<00:18,  1.21it/s]Epoch: 1/10. Loss: 1.0691:  15%|[36m█▌        [0m| 4/26 [00:03<00:18,  1.19it/s]Epoch: 1/10. Loss: 1.1678:  15%|[36m█▌        [0m| 4/26 [00:04<00:18,  1.19it/s]Epoch: 1/10. Loss: 1.1678:  19%|[36m█▉        [0m| 5/26 [00:04<00:19,  1.10it/s]Epoch: 1/10. Loss: 1.0089:  19%|[36m█▉        [0m| 5/26 [00:05<00:19,  1.10it/s]Epoch: 1/10. Loss: 1.0089:  23%|[36m██▎       [0m| 6/26 [00:05<00:18,  1.10it/s]Epoch: 1/10. Loss: 0.9967:  23%|[36m██▎       [0m| 6/26 [00:06<00:18,  1.10it/s]Epoch: 1/10. Loss: 0.9967:  27%|[36m██▋       [0m| 7/26 [00:06<00:18,  1.00it/s]Epoch: 1/10. Loss: 1.0380:  27%|[36m██▋       [0m| 7/26 [00:07<00:18,  1.00it/s]Epoch: 1/10. Loss: 1.0380:  31%|[36m███       [0m| 8/26 [00:07<00:18,  1.04s/it]Epoch: 1/10. Loss: 1.0628:  31%|[36m███       [0m| 8/26 [00:08<00:18,  1.04s/it]Epoch: 1/10. Loss: 1.0628:  35%|[36m███▍      [0m| 9/26 [00:08<00:16,  1.01it/s]Epoch: 1/10. Loss: 1.0224:  35%|[36m███▍      [0m| 9/26 [00:09<00:16,  1.01it/s]Epoch: 1/10. Loss: 1.0224:  38%|[36m███▊      [0m| 10/26 [00:09<00:15,  1.03it/s]Epoch: 1/10. Loss: 1.0556:  38%|[36m███▊      [0m| 10/26 [00:10<00:15,  1.03it/s]Epoch: 1/10. Loss: 1.0556:  42%|[36m████▏     [0m| 11/26 [00:10<00:14,  1.03it/s]Epoch: 1/10. Loss: 0.9479:  42%|[36m████▏     [0m| 11/26 [00:11<00:14,  1.03it/s]Epoch: 1/10. Loss: 0.9479:  46%|[36m████▌     [0m| 12/26 [00:11<00:13,  1.03it/s]Epoch: 1/10. Loss: 0.9565:  46%|[36m████▌     [0m| 12/26 [00:12<00:13,  1.03it/s]Epoch: 1/10. Loss: 0.9565:  50%|[36m█████     [0m| 13/26 [00:12<00:12,  1.05it/s]Epoch: 1/10. Loss: 0.9769:  50%|[36m█████     [0m| 13/26 [00:13<00:12,  1.05it/s]Epoch: 1/10. Loss: 0.9769:  54%|[36m█████▍    [0m| 14/26 [00:13<00:11,  1.02it/s]Epoch: 1/10. Loss: 1.0483:  54%|[36m█████▍    [0m| 14/26 [00:14<00:11,  1.02it/s]Epoch: 1/10. Loss: 1.0483:  58%|[36m█████▊    [0m| 15/26 [00:14<00:10,  1.03it/s]Epoch: 1/10. Loss: 0.9322:  58%|[36m█████▊    [0m| 15/26 [00:15<00:10,  1.03it/s]Epoch: 1/10. Loss: 0.9322:  62%|[36m██████▏   [0m| 16/26 [00:15<00:09,  1.07it/s]Epoch: 1/10. Loss: 0.8902:  62%|[36m██████▏   [0m| 16/26 [00:16<00:09,  1.07it/s]Epoch: 1/10. Loss: 0.8902:  65%|[36m██████▌   [0m| 17/26 [00:16<00:08,  1.05it/s]Epoch: 1/10. Loss: 1.1196:  65%|[36m██████▌   [0m| 17/26 [00:17<00:08,  1.05it/s]Epoch: 1/10. Loss: 1.1196:  69%|[36m██████▉   [0m| 18/26 [00:17<00:07,  1.04it/s]Epoch: 1/10. Loss: 0.9999:  69%|[36m██████▉   [0m| 18/26 [00:17<00:07,  1.04it/s]Epoch: 1/10. Loss: 0.9999:  73%|[36m███████▎  [0m| 19/26 [00:17<00:06,  1.09it/s]Epoch: 1/10. Loss: 0.9103:  73%|[36m███████▎  [0m| 19/26 [00:18<00:06,  1.09it/s]Epoch: 1/10. Loss: 0.9103:  77%|[36m███████▋  [0m| 20/26 [00:18<00:05,  1.09it/s]Epoch: 1/10. Loss: 1.0143:  77%|[36m███████▋  [0m| 20/26 [00:19<00:05,  1.09it/s]Epoch: 1/10. Loss: 1.0143:  81%|[36m████████  [0m| 21/26 [00:19<00:04,  1.04it/s]Epoch: 1/10. Loss: 1.0093:  81%|[36m████████  [0m| 21/26 [00:20<00:04,  1.04it/s]Epoch: 1/10. Loss: 1.0093:  85%|[36m████████▍ [0m| 22/26 [00:20<00:03,  1.03it/s]Epoch: 1/10. Loss: 1.2086:  85%|[36m████████▍ [0m| 22/26 [00:21<00:03,  1.03it/s]Epoch: 1/10. Loss: 1.2086:  88%|[36m████████▊ [0m| 23/26 [00:21<00:02,  1.09it/s]Epoch: 1/10. Loss: 0.9628:  88%|[36m████████▊ [0m| 23/26 [00:22<00:02,  1.09it/s]Epoch: 1/10. Loss: 0.9628:  92%|[36m█████████▏[0m| 24/26 [00:22<00:01,  1.07it/s]Epoch: 1/10. Loss: 1.0152:  92%|[36m█████████▏[0m| 24/26 [00:23<00:01,  1.07it/s]Epoch: 1/10. Loss: 1.0152:  96%|[36m█████████▌[0m| 25/26 [00:23<00:00,  1.07it/s]Epoch: 1/10. Loss: 0.9821:  96%|[36m█████████▌[0m| 25/26 [00:24<00:00,  1.07it/s]Epoch: 1/10. Loss: 0.9821: 100%|[36m██████████[0m| 26/26 [00:24<00:00,  1.17it/s]Epoch: 1/10. Loss: 0.9821: 100%|[36m██████████[0m| 26/26 [00:24<00:00,  1.07it/s]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:04,  1.24it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:05,  1.11s/it] 43%|[33m████▎     [0m| 3/7 [00:02<00:03,  1.13it/s] 57%|[33m█████▋    [0m| 4/7 [00:03<00:02,  1.04it/s] 71%|[33m███████▏  [0m| 5/7 [00:04<00:01,  1.28it/s] 86%|[33m████████▌ [0m| 6/7 [00:05<00:00,  1.27it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.60it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.30it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 2/10. Loss: 1.0188:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 2/10. Loss: 1.0188:   4%|[36m▍         [0m| 1/26 [00:00<00:24,  1.04it/s]Epoch: 2/10. Loss: 0.9303:   4%|[36m▍         [0m| 1/26 [00:01<00:24,  1.04it/s]Epoch: 2/10. Loss: 0.9303:   8%|[36m▊         [0m| 2/26 [00:01<00:23,  1.03it/s]Epoch: 2/10. Loss: 1.0444:   8%|[36m▊         [0m| 2/26 [00:02<00:23,  1.03it/s]Epoch: 2/10. Loss: 1.0444:  12%|[36m█▏        [0m| 3/26 [00:02<00:21,  1.07it/s]Epoch: 2/10. Loss: 1.2211:  12%|[36m█▏        [0m| 3/26 [00:03<00:21,  1.07it/s]Epoch: 2/10. Loss: 1.2211:  15%|[36m█▌        [0m| 4/26 [00:03<00:21,  1.04it/s]Epoch: 2/10. Loss: 1.0181:  15%|[36m█▌        [0m| 4/26 [00:04<00:21,  1.04it/s]Epoch: 2/10. Loss: 1.0181:  19%|[36m█▉        [0m| 5/26 [00:04<00:19,  1.06it/s]Epoch: 2/10. Loss: 0.9717:  19%|[36m█▉        [0m| 5/26 [00:05<00:19,  1.06it/s]Epoch: 2/10. Loss: 0.9717:  23%|[36m██▎       [0m| 6/26 [00:05<00:18,  1.06it/s]Epoch: 2/10. Loss: 0.9701:  23%|[36m██▎       [0m| 6/26 [00:06<00:18,  1.06it/s]Epoch: 2/10. Loss: 0.9701:  27%|[36m██▋       [0m| 7/26 [00:06<00:18,  1.05it/s]Epoch: 2/10. Loss: 1.0269:  27%|[36m██▋       [0m| 7/26 [00:07<00:18,  1.05it/s]Epoch: 2/10. Loss: 1.0269:  31%|[36m███       [0m| 8/26 [00:07<00:17,  1.02it/s]Epoch: 2/10. Loss: 1.0294:  31%|[36m███       [0m| 8/26 [00:08<00:17,  1.02it/s]Epoch: 2/10. Loss: 1.0294:  35%|[36m███▍      [0m| 9/26 [00:08<00:16,  1.05it/s]Epoch: 2/10. Loss: 0.9763:  35%|[36m███▍      [0m| 9/26 [00:09<00:16,  1.05it/s]Epoch: 2/10. Loss: 0.9763:  38%|[36m███▊      [0m| 10/26 [00:09<00:15,  1.02it/s]Epoch: 2/10. Loss: 0.9137:  38%|[36m███▊      [0m| 10/26 [00:10<00:15,  1.02it/s]Epoch: 2/10. Loss: 0.9137:  42%|[36m████▏     [0m| 11/26 [00:10<00:14,  1.01it/s]Epoch: 2/10. Loss: 1.0370:  42%|[36m████▏     [0m| 11/26 [00:11<00:14,  1.01it/s]Epoch: 2/10. Loss: 1.0370:  46%|[36m████▌     [0m| 12/26 [00:11<00:13,  1.04it/s]Epoch: 2/10. Loss: 0.8874:  46%|[36m████▌     [0m| 12/26 [00:12<00:13,  1.04it/s]Epoch: 2/10. Loss: 0.8874:  50%|[36m█████     [0m| 13/26 [00:12<00:12,  1.01it/s]Epoch: 2/10. Loss: 1.0456:  50%|[36m█████     [0m| 13/26 [00:13<00:12,  1.01it/s]Epoch: 2/10. Loss: 1.0456:  54%|[36m█████▍    [0m| 14/26 [00:13<00:11,  1.05it/s]Epoch: 2/10. Loss: 1.0269:  54%|[36m█████▍    [0m| 14/26 [00:14<00:11,  1.05it/s]Epoch: 2/10. Loss: 1.0269:  58%|[36m█████▊    [0m| 15/26 [00:14<00:10,  1.07it/s]Epoch: 2/10. Loss: 0.9628:  58%|[36m█████▊    [0m| 15/26 [00:15<00:10,  1.07it/s]Epoch: 2/10. Loss: 0.9628:  62%|[36m██████▏   [0m| 16/26 [00:15<00:09,  1.09it/s]Epoch: 2/10. Loss: 0.9982:  62%|[36m██████▏   [0m| 16/26 [00:16<00:09,  1.09it/s]Epoch: 2/10. Loss: 0.9982:  65%|[36m██████▌   [0m| 17/26 [00:16<00:08,  1.04it/s]Epoch: 2/10. Loss: 1.0127:  65%|[36m██████▌   [0m| 17/26 [00:17<00:08,  1.04it/s]Epoch: 2/10. Loss: 1.0127:  69%|[36m██████▉   [0m| 18/26 [00:17<00:07,  1.06it/s]Epoch: 2/10. Loss: 1.0500:  69%|[36m██████▉   [0m| 18/26 [00:18<00:07,  1.06it/s]Epoch: 2/10. Loss: 1.0500:  73%|[36m███████▎  [0m| 19/26 [00:18<00:06,  1.01it/s]Epoch: 2/10. Loss: 1.0539:  73%|[36m███████▎  [0m| 19/26 [00:19<00:06,  1.01it/s]Epoch: 2/10. Loss: 1.0539:  77%|[36m███████▋  [0m| 20/26 [00:19<00:05,  1.03it/s]Epoch: 2/10. Loss: 0.9850:  77%|[36m███████▋  [0m| 20/26 [00:20<00:05,  1.03it/s]Epoch: 2/10. Loss: 0.9850:  81%|[36m████████  [0m| 21/26 [00:20<00:04,  1.05it/s]Epoch: 2/10. Loss: 0.9977:  81%|[36m████████  [0m| 21/26 [00:21<00:04,  1.05it/s]Epoch: 2/10. Loss: 0.9977:  85%|[36m████████▍ [0m| 22/26 [00:21<00:03,  1.06it/s]Epoch: 2/10. Loss: 0.9437:  85%|[36m████████▍ [0m| 22/26 [00:21<00:03,  1.06it/s]Epoch: 2/10. Loss: 0.9437:  88%|[36m████████▊ [0m| 23/26 [00:21<00:02,  1.10it/s]Epoch: 2/10. Loss: 0.9669:  88%|[36m████████▊ [0m| 23/26 [00:22<00:02,  1.10it/s]Epoch: 2/10. Loss: 0.9669:  92%|[36m█████████▏[0m| 24/26 [00:22<00:01,  1.11it/s]Epoch: 2/10. Loss: 0.9805:  92%|[36m█████████▏[0m| 24/26 [00:23<00:01,  1.11it/s]Epoch: 2/10. Loss: 0.9805:  96%|[36m█████████▌[0m| 25/26 [00:23<00:00,  1.05it/s]Epoch: 2/10. Loss: 0.9610:  96%|[36m█████████▌[0m| 25/26 [00:24<00:00,  1.05it/s]Epoch: 2/10. Loss: 0.9610: 100%|[36m██████████[0m| 26/26 [00:24<00:00,  1.21it/s]Epoch: 2/10. Loss: 0.9610: 100%|[36m██████████[0m| 26/26 [00:24<00:00,  1.07it/s]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:04,  1.27it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:05,  1.09s/it] 43%|[33m████▎     [0m| 3/7 [00:02<00:03,  1.14it/s] 57%|[33m█████▋    [0m| 4/7 [00:03<00:02,  1.04it/s] 71%|[33m███████▏  [0m| 5/7 [00:04<00:01,  1.27it/s] 86%|[33m████████▌ [0m| 6/7 [00:05<00:00,  1.26it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.58it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.30it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 3/10. Loss: 0.9176:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 3/10. Loss: 0.9176:   4%|[36m▍         [0m| 1/26 [00:01<00:25,  1.03s/it]Epoch: 3/10. Loss: 0.9742:   4%|[36m▍         [0m| 1/26 [00:01<00:25,  1.03s/it]Epoch: 3/10. Loss: 0.9742:   8%|[36m▊         [0m| 2/26 [00:01<00:22,  1.06it/s]Epoch: 3/10. Loss: 0.9320:   8%|[36m▊         [0m| 2/26 [00:02<00:22,  1.06it/s]Epoch: 3/10. Loss: 0.9320:  12%|[36m█▏        [0m| 3/26 [00:02<00:21,  1.06it/s]Epoch: 3/10. Loss: 0.9960:  12%|[36m█▏        [0m| 3/26 [00:03<00:21,  1.06it/s]Epoch: 3/10. Loss: 0.9960:  15%|[36m█▌        [0m| 4/26 [00:03<00:20,  1.05it/s]Epoch: 3/10. Loss: 0.9511:  15%|[36m█▌        [0m| 4/26 [00:04<00:20,  1.05it/s]Epoch: 3/10. Loss: 0.9511:  19%|[36m█▉        [0m| 5/26 [00:04<00:19,  1.09it/s]Epoch: 3/10. Loss: 1.0369:  19%|[36m█▉        [0m| 5/26 [00:05<00:19,  1.09it/s]Epoch: 3/10. Loss: 1.0369:  23%|[36m██▎       [0m| 6/26 [00:05<00:19,  1.05it/s]Epoch: 3/10. Loss: 1.0160:  23%|[36m██▎       [0m| 6/26 [00:06<00:19,  1.05it/s]Epoch: 3/10. Loss: 1.0160:  27%|[36m██▋       [0m| 7/26 [00:06<00:17,  1.07it/s]Epoch: 3/10. Loss: 1.0580:  27%|[36m██▋       [0m| 7/26 [00:07<00:17,  1.07it/s]Epoch: 3/10. Loss: 1.0580:  31%|[36m███       [0m| 8/26 [00:07<00:17,  1.06it/s]Epoch: 3/10. Loss: 1.0640:  31%|[36m███       [0m| 8/26 [00:08<00:17,  1.06it/s]Epoch: 3/10. Loss: 1.0640:  35%|[36m███▍      [0m| 9/26 [00:08<00:15,  1.13it/s]Epoch: 3/10. Loss: 0.9970:  35%|[36m███▍      [0m| 9/26 [00:09<00:15,  1.13it/s]Epoch: 3/10. Loss: 0.9970:  38%|[36m███▊      [0m| 10/26 [00:09<00:14,  1.10it/s]Epoch: 3/10. Loss: 1.0557:  38%|[36m███▊      [0m| 10/26 [00:09<00:14,  1.10it/s]Epoch: 3/10. Loss: 1.0557:  42%|[36m████▏     [0m| 11/26 [00:10<00:12,  1.17it/s]Epoch: 3/10. Loss: 0.9209:  42%|[36m████▏     [0m| 11/26 [00:10<00:12,  1.17it/s]Epoch: 3/10. Loss: 0.9209:  46%|[36m████▌     [0m| 12/26 [00:10<00:12,  1.14it/s]Epoch: 3/10. Loss: 0.8825:  46%|[36m████▌     [0m| 12/26 [00:11<00:12,  1.14it/s]Epoch: 3/10. Loss: 0.8825:  50%|[36m█████     [0m| 13/26 [00:11<00:11,  1.13it/s]Epoch: 3/10. Loss: 0.8948:  50%|[36m█████     [0m| 13/26 [00:12<00:11,  1.13it/s]Epoch: 3/10. Loss: 0.8948:  54%|[36m█████▍    [0m| 14/26 [00:12<00:10,  1.11it/s]Epoch: 3/10. Loss: 1.0405:  54%|[36m█████▍    [0m| 14/26 [00:13<00:10,  1.11it/s]Epoch: 3/10. Loss: 1.0405:  58%|[36m█████▊    [0m| 15/26 [00:13<00:09,  1.12it/s]Epoch: 3/10. Loss: 0.9799:  58%|[36m█████▊    [0m| 15/26 [00:14<00:09,  1.12it/s]Epoch: 3/10. Loss: 0.9799:  62%|[36m██████▏   [0m| 16/26 [00:14<00:09,  1.06it/s]Epoch: 3/10. Loss: 1.0101:  62%|[36m██████▏   [0m| 16/26 [00:15<00:09,  1.06it/s]Epoch: 3/10. Loss: 1.0101:  65%|[36m██████▌   [0m| 17/26 [00:15<00:09,  1.01s/it]Epoch: 3/10. Loss: 0.9410:  65%|[36m██████▌   [0m| 17/26 [00:16<00:09,  1.01s/it]Epoch: 3/10. Loss: 0.9410:  69%|[36m██████▉   [0m| 18/26 [00:16<00:08,  1.00s/it]Epoch: 3/10. Loss: 0.9960:  69%|[36m██████▉   [0m| 18/26 [00:18<00:08,  1.00s/it]Epoch: 3/10. Loss: 0.9960:  73%|[36m███████▎  [0m| 19/26 [00:18<00:08,  1.23s/it]Epoch: 3/10. Loss: 1.0024:  73%|[36m███████▎  [0m| 19/26 [00:19<00:08,  1.23s/it]Epoch: 3/10. Loss: 1.0024:  77%|[36m███████▋  [0m| 20/26 [00:19<00:06,  1.13s/it]Epoch: 3/10. Loss: 0.9837:  77%|[36m███████▋  [0m| 20/26 [00:20<00:06,  1.13s/it]Epoch: 3/10. Loss: 0.9837:  81%|[36m████████  [0m| 21/26 [00:20<00:05,  1.09s/it]Epoch: 3/10. Loss: 1.0195:  81%|[36m████████  [0m| 21/26 [00:21<00:05,  1.09s/it]Epoch: 3/10. Loss: 1.0195:  85%|[36m████████▍ [0m| 22/26 [00:21<00:04,  1.07s/it]Epoch: 3/10. Loss: 0.9611:  85%|[36m████████▍ [0m| 22/26 [00:22<00:04,  1.07s/it]Epoch: 3/10. Loss: 0.9611:  88%|[36m████████▊ [0m| 23/26 [00:22<00:03,  1.08s/it]Epoch: 3/10. Loss: 0.9866:  88%|[36m████████▊ [0m| 23/26 [00:23<00:03,  1.08s/it]Epoch: 3/10. Loss: 0.9866:  92%|[36m█████████▏[0m| 24/26 [00:23<00:02,  1.03s/it]Epoch: 3/10. Loss: 0.9440:  92%|[36m█████████▏[0m| 24/26 [00:24<00:02,  1.03s/it]Epoch: 3/10. Loss: 0.9440:  96%|[36m█████████▌[0m| 25/26 [00:24<00:01,  1.04s/it]Epoch: 3/10. Loss: 0.9381:  96%|[36m█████████▌[0m| 25/26 [00:25<00:01,  1.04s/it]Epoch: 3/10. Loss: 0.9381: 100%|[36m██████████[0m| 26/26 [00:25<00:00,  1.08it/s]Epoch: 3/10. Loss: 0.9381: 100%|[36m██████████[0m| 26/26 [00:25<00:00,  1.03it/s]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:04,  1.26it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:05,  1.09s/it] 43%|[33m████▎     [0m| 3/7 [00:02<00:03,  1.15it/s] 57%|[33m█████▋    [0m| 4/7 [00:03<00:02,  1.05it/s] 71%|[33m███████▏  [0m| 5/7 [00:04<00:01,  1.30it/s] 86%|[33m████████▌ [0m| 6/7 [00:05<00:00,  1.27it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.61it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.32it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 4/10. Loss: 1.1673:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 4/10. Loss: 1.1673:   4%|[36m▍         [0m| 1/26 [00:00<00:24,  1.04it/s]Epoch: 4/10. Loss: 0.9187:   4%|[36m▍         [0m| 1/26 [00:01<00:24,  1.04it/s]Epoch: 4/10. Loss: 0.9187:   8%|[36m▊         [0m| 2/26 [00:01<00:23,  1.03it/s]Epoch: 4/10. Loss: 0.9600:   8%|[36m▊         [0m| 2/26 [00:02<00:23,  1.03it/s]Epoch: 4/10. Loss: 0.9600:  12%|[36m█▏        [0m| 3/26 [00:02<00:22,  1.03it/s]Epoch: 4/10. Loss: 1.0174:  12%|[36m█▏        [0m| 3/26 [00:03<00:22,  1.03it/s]Epoch: 4/10. Loss: 1.0174:  15%|[36m█▌        [0m| 4/26 [00:03<00:20,  1.05it/s]Epoch: 4/10. Loss: 0.9459:  15%|[36m█▌        [0m| 4/26 [00:04<00:20,  1.05it/s]Epoch: 4/10. Loss: 0.9459:  19%|[36m█▉        [0m| 5/26 [00:04<00:20,  1.05it/s]Epoch: 4/10. Loss: 0.9017:  19%|[36m█▉        [0m| 5/26 [00:05<00:20,  1.05it/s]Epoch: 4/10. Loss: 0.9017:  23%|[36m██▎       [0m| 6/26 [00:05<00:18,  1.07it/s]Epoch: 4/10. Loss: 0.9083:  23%|[36m██▎       [0m| 6/26 [00:06<00:18,  1.07it/s]Epoch: 4/10. Loss: 0.9083:  27%|[36m██▋       [0m| 7/26 [00:06<00:18,  1.04it/s]Epoch: 4/10. Loss: 0.9382:  27%|[36m██▋       [0m| 7/26 [00:07<00:18,  1.04it/s]Epoch: 4/10. Loss: 0.9382:  31%|[36m███       [0m| 8/26 [00:07<00:17,  1.04it/s]Epoch: 4/10. Loss: 0.9835:  31%|[36m███       [0m| 8/26 [00:08<00:17,  1.04it/s]Epoch: 4/10. Loss: 0.9835:  35%|[36m███▍      [0m| 9/26 [00:08<00:16,  1.01it/s]Epoch: 4/10. Loss: 1.0672:  35%|[36m███▍      [0m| 9/26 [00:09<00:16,  1.01it/s]Epoch: 4/10. Loss: 1.0672:  38%|[36m███▊      [0m| 10/26 [00:09<00:15,  1.01it/s]Epoch: 4/10. Loss: 0.9450:  38%|[36m███▊      [0m| 10/26 [00:10<00:15,  1.01it/s]Epoch: 4/10. Loss: 0.9450:  42%|[36m████▏     [0m| 11/26 [00:10<00:14,  1.02it/s]Epoch: 4/10. Loss: 0.9207:  42%|[36m████▏     [0m| 11/26 [00:11<00:14,  1.02it/s]Epoch: 4/10. Loss: 0.9207:  46%|[36m████▌     [0m| 12/26 [00:11<00:13,  1.01it/s]Epoch: 4/10. Loss: 1.0438:  46%|[36m████▌     [0m| 12/26 [00:12<00:13,  1.01it/s]Epoch: 4/10. Loss: 1.0438:  50%|[36m█████     [0m| 13/26 [00:12<00:11,  1.10it/s]Epoch: 4/10. Loss: 0.9507:  50%|[36m█████     [0m| 13/26 [00:13<00:11,  1.10it/s]Epoch: 4/10. Loss: 0.9507:  54%|[36m█████▍    [0m| 14/26 [00:13<00:10,  1.13it/s]Epoch: 4/10. Loss: 1.0299:  54%|[36m█████▍    [0m| 14/26 [00:14<00:10,  1.13it/s]Epoch: 4/10. Loss: 1.0299:  58%|[36m█████▊    [0m| 15/26 [00:14<00:10,  1.06it/s]Epoch: 4/10. Loss: 1.0133:  58%|[36m█████▊    [0m| 15/26 [00:15<00:10,  1.06it/s]Epoch: 4/10. Loss: 1.0133:  62%|[36m██████▏   [0m| 16/26 [00:15<00:08,  1.13it/s]Epoch: 4/10. Loss: 0.9363:  62%|[36m██████▏   [0m| 16/26 [00:15<00:08,  1.13it/s]Epoch: 4/10. Loss: 0.9363:  65%|[36m██████▌   [0m| 17/26 [00:15<00:07,  1.14it/s]Epoch: 4/10. Loss: 0.9436:  65%|[36m██████▌   [0m| 17/26 [00:17<00:07,  1.14it/s]Epoch: 4/10. Loss: 0.9436:  69%|[36m██████▉   [0m| 18/26 [00:17<00:07,  1.02it/s]Epoch: 4/10. Loss: 0.9777:  69%|[36m██████▉   [0m| 18/26 [00:18<00:07,  1.02it/s]Epoch: 4/10. Loss: 0.9777:  73%|[36m███████▎  [0m| 19/26 [00:18<00:06,  1.05it/s]Epoch: 4/10. Loss: 1.0043:  73%|[36m███████▎  [0m| 19/26 [00:18<00:06,  1.05it/s]Epoch: 4/10. Loss: 1.0043:  77%|[36m███████▋  [0m| 20/26 [00:18<00:05,  1.05it/s]Epoch: 4/10. Loss: 1.0059:  77%|[36m███████▋  [0m| 20/26 [00:19<00:05,  1.05it/s]Epoch: 4/10. Loss: 1.0059:  81%|[36m████████  [0m| 21/26 [00:19<00:04,  1.04it/s]Epoch: 4/10. Loss: 0.9548:  81%|[36m████████  [0m| 21/26 [00:20<00:04,  1.04it/s]Epoch: 4/10. Loss: 0.9548:  85%|[36m████████▍ [0m| 22/26 [00:20<00:03,  1.03it/s]Epoch: 4/10. Loss: 0.9425:  85%|[36m████████▍ [0m| 22/26 [00:21<00:03,  1.03it/s]Epoch: 4/10. Loss: 0.9425:  88%|[36m████████▊ [0m| 23/26 [00:21<00:02,  1.04it/s]Epoch: 4/10. Loss: 0.9402:  88%|[36m████████▊ [0m| 23/26 [00:22<00:02,  1.04it/s]Epoch: 4/10. Loss: 0.9402:  92%|[36m█████████▏[0m| 24/26 [00:22<00:01,  1.06it/s]Epoch: 4/10. Loss: 0.9425:  92%|[36m█████████▏[0m| 24/26 [00:23<00:01,  1.06it/s]Epoch: 4/10. Loss: 0.9425:  96%|[36m█████████▌[0m| 25/26 [00:23<00:00,  1.07it/s]Epoch: 4/10. Loss: 0.9473:  96%|[36m█████████▌[0m| 25/26 [00:24<00:00,  1.07it/s]Epoch: 4/10. Loss: 0.9473: 100%|[36m██████████[0m| 26/26 [00:24<00:00,  1.17it/s]Epoch: 4/10. Loss: 0.9473: 100%|[36m██████████[0m| 26/26 [00:24<00:00,  1.07it/s]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:04,  1.26it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:05,  1.11s/it] 43%|[33m████▎     [0m| 3/7 [00:02<00:03,  1.13it/s] 57%|[33m█████▋    [0m| 4/7 [00:03<00:02,  1.03it/s] 71%|[33m███████▏  [0m| 5/7 [00:04<00:01,  1.26it/s] 86%|[33m████████▌ [0m| 6/7 [00:07<00:01,  1.48s/it]100%|[33m██████████[0m| 7/7 [00:07<00:00,  1.26s/it]100%|[33m██████████[0m| 7/7 [00:07<00:00,  1.13s/it]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 5/10. Loss: 0.9987:   0%|[36m          [0m| 0/26 [00:01<?, ?it/s]Epoch: 5/10. Loss: 0.9987:   4%|[36m▍         [0m| 1/26 [00:01<00:28,  1.14s/it]Epoch: 5/10. Loss: 0.9363:   4%|[36m▍         [0m| 1/26 [00:02<00:28,  1.14s/it]Epoch: 5/10. Loss: 0.9363:   8%|[36m▊         [0m| 2/26 [00:02<00:26,  1.10s/it]Epoch: 5/10. Loss: 0.9328:   8%|[36m▊         [0m| 2/26 [00:03<00:26,  1.10s/it]Epoch: 5/10. Loss: 0.9328:  12%|[36m█▏        [0m| 3/26 [00:03<00:23,  1.01s/it]Epoch: 5/10. Loss: 0.8524:  12%|[36m█▏        [0m| 3/26 [00:04<00:23,  1.01s/it]Epoch: 5/10. Loss: 0.8524:  15%|[36m█▌        [0m| 4/26 [00:04<00:22,  1.02s/it]Epoch: 5/10. Loss: 0.9333:  15%|[36m█▌        [0m| 4/26 [00:05<00:22,  1.02s/it]Epoch: 5/10. Loss: 0.9333:  19%|[36m█▉        [0m| 5/26 [00:05<00:21,  1.00s/it]Epoch: 5/10. Loss: 0.8895:  19%|[36m█▉        [0m| 5/26 [00:06<00:21,  1.00s/it]Epoch: 5/10. Loss: 0.8895:  23%|[36m██▎       [0m| 6/26 [00:06<00:20,  1.00s/it]Epoch: 5/10. Loss: 0.9245:  23%|[36m██▎       [0m| 6/26 [00:06<00:20,  1.00s/it]Epoch: 5/10. Loss: 0.9245:  27%|[36m██▋       [0m| 7/26 [00:07<00:18,  1.03it/s]Epoch: 5/10. Loss: 0.9541:  27%|[36m██▋       [0m| 7/26 [00:07<00:18,  1.03it/s]Epoch: 5/10. Loss: 0.9541:  31%|[36m███       [0m| 8/26 [00:07<00:16,  1.11it/s]Epoch: 5/10. Loss: 0.9104:  31%|[36m███       [0m| 8/26 [00:09<00:16,  1.11it/s]Epoch: 5/10. Loss: 0.9104:  35%|[36m███▍      [0m| 9/26 [00:09<00:17,  1.03s/it]Epoch: 5/10. Loss: 1.0407:  35%|[36m███▍      [0m| 9/26 [00:09<00:17,  1.03s/it]Epoch: 5/10. Loss: 1.0407:  38%|[36m███▊      [0m| 10/26 [00:09<00:15,  1.01it/s]Epoch: 5/10. Loss: 0.9580:  38%|[36m███▊      [0m| 10/26 [00:10<00:15,  1.01it/s]Epoch: 5/10. Loss: 0.9580:  42%|[36m████▏     [0m| 11/26 [00:10<00:14,  1.02it/s]Epoch: 5/10. Loss: 0.8812:  42%|[36m████▏     [0m| 11/26 [00:11<00:14,  1.02it/s]Epoch: 5/10. Loss: 0.8812:  46%|[36m████▌     [0m| 12/26 [00:11<00:13,  1.01it/s]Epoch: 5/10. Loss: 0.9487:  46%|[36m████▌     [0m| 12/26 [00:12<00:13,  1.01it/s]Epoch: 5/10. Loss: 0.9487:  50%|[36m█████     [0m| 13/26 [00:12<00:12,  1.03it/s]Epoch: 5/10. Loss: 1.0183:  50%|[36m█████     [0m| 13/26 [00:13<00:12,  1.03it/s]Epoch: 5/10. Loss: 1.0183:  54%|[36m█████▍    [0m| 14/26 [00:13<00:11,  1.04it/s]Epoch: 5/10. Loss: 1.0015:  54%|[36m█████▍    [0m| 14/26 [00:14<00:11,  1.04it/s]Epoch: 5/10. Loss: 1.0015:  58%|[36m█████▊    [0m| 15/26 [00:14<00:10,  1.09it/s]Epoch: 5/10. Loss: 0.9283:  58%|[36m█████▊    [0m| 15/26 [00:15<00:10,  1.09it/s]Epoch: 5/10. Loss: 0.9283:  62%|[36m██████▏   [0m| 16/26 [00:15<00:09,  1.07it/s]Epoch: 5/10. Loss: 0.9735:  62%|[36m██████▏   [0m| 16/26 [00:16<00:09,  1.07it/s]Epoch: 5/10. Loss: 0.9735:  65%|[36m██████▌   [0m| 17/26 [00:16<00:08,  1.06it/s]Epoch: 5/10. Loss: 0.9660:  65%|[36m██████▌   [0m| 17/26 [00:17<00:08,  1.06it/s]Epoch: 5/10. Loss: 0.9660:  69%|[36m██████▉   [0m| 18/26 [00:17<00:07,  1.08it/s]Epoch: 5/10. Loss: 0.9971:  69%|[36m██████▉   [0m| 18/26 [00:18<00:07,  1.08it/s]Epoch: 5/10. Loss: 0.9971:  73%|[36m███████▎  [0m| 19/26 [00:18<00:06,  1.12it/s]Epoch: 5/10. Loss: 0.9855:  73%|[36m███████▎  [0m| 19/26 [00:19<00:06,  1.12it/s]Epoch: 5/10. Loss: 0.9855:  77%|[36m███████▋  [0m| 20/26 [00:19<00:05,  1.06it/s]Epoch: 5/10. Loss: 0.9690:  77%|[36m███████▋  [0m| 20/26 [00:20<00:05,  1.06it/s]Epoch: 5/10. Loss: 0.9690:  81%|[36m████████  [0m| 21/26 [00:20<00:04,  1.05it/s]Epoch: 5/10. Loss: 0.9474:  81%|[36m████████  [0m| 21/26 [00:21<00:04,  1.05it/s]Epoch: 5/10. Loss: 0.9474:  85%|[36m████████▍ [0m| 22/26 [00:21<00:03,  1.05it/s]Epoch: 5/10. Loss: 0.9212:  85%|[36m████████▍ [0m| 22/26 [00:22<00:03,  1.05it/s]Epoch: 5/10. Loss: 0.9212:  88%|[36m████████▊ [0m| 23/26 [00:22<00:02,  1.05it/s]Epoch: 5/10. Loss: 0.8824:  88%|[36m████████▊ [0m| 23/26 [00:23<00:02,  1.05it/s]Epoch: 5/10. Loss: 0.8824:  92%|[36m█████████▏[0m| 24/26 [00:23<00:01,  1.03it/s]Epoch: 5/10. Loss: 0.9433:  92%|[36m█████████▏[0m| 24/26 [00:24<00:01,  1.03it/s]Epoch: 5/10. Loss: 0.9433:  96%|[36m█████████▌[0m| 25/26 [00:24<00:00,  1.05it/s]Epoch: 5/10. Loss: 0.9006:  96%|[36m█████████▌[0m| 25/26 [00:24<00:00,  1.05it/s]Epoch: 5/10. Loss: 0.9006: 100%|[36m██████████[0m| 26/26 [00:24<00:00,  1.17it/s]Epoch: 5/10. Loss: 0.9006: 100%|[36m██████████[0m| 26/26 [00:24<00:00,  1.05it/s]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:04,  1.25it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:05,  1.09s/it] 43%|[33m████▎     [0m| 3/7 [00:02<00:03,  1.15it/s] 57%|[33m█████▋    [0m| 4/7 [00:03<00:02,  1.05it/s] 71%|[33m███████▏  [0m| 5/7 [00:04<00:01,  1.29it/s] 86%|[33m████████▌ [0m| 6/7 [00:05<00:00,  1.06it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.37it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.21it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 6/10. Loss: 0.9211:   0%|[36m          [0m| 0/26 [00:01<?, ?it/s]Epoch: 6/10. Loss: 0.9211:   4%|[36m▍         [0m| 1/26 [00:01<00:28,  1.15s/it]Epoch: 6/10. Loss: 0.9124:   4%|[36m▍         [0m| 1/26 [00:01<00:28,  1.15s/it]Epoch: 6/10. Loss: 0.9124:   8%|[36m▊         [0m| 2/26 [00:01<00:22,  1.05it/s]Epoch: 6/10. Loss: 0.8775:   8%|[36m▊         [0m| 2/26 [00:02<00:22,  1.05it/s]Epoch: 6/10. Loss: 0.8775:  12%|[36m█▏        [0m| 3/26 [00:02<00:21,  1.07it/s]Epoch: 6/10. Loss: 0.9212:  12%|[36m█▏        [0m| 3/26 [00:03<00:21,  1.07it/s]Epoch: 6/10. Loss: 0.9212:  15%|[36m█▌        [0m| 4/26 [00:03<00:21,  1.02it/s]Epoch: 6/10. Loss: 0.9344:  15%|[36m█▌        [0m| 4/26 [00:05<00:21,  1.02it/s]Epoch: 6/10. Loss: 0.9344:  19%|[36m█▉        [0m| 5/26 [00:05<00:21,  1.03s/it]Epoch: 6/10. Loss: 0.9151:  19%|[36m█▉        [0m| 5/26 [00:06<00:21,  1.03s/it]Epoch: 6/10. Loss: 0.9151:  23%|[36m██▎       [0m| 6/26 [00:06<00:20,  1.02s/it]Epoch: 6/10. Loss: 0.9724:  23%|[36m██▎       [0m| 6/26 [00:06<00:20,  1.02s/it]Epoch: 6/10. Loss: 0.9724:  27%|[36m██▋       [0m| 7/26 [00:06<00:18,  1.01it/s]Epoch: 6/10. Loss: 0.9876:  27%|[36m██▋       [0m| 7/26 [00:07<00:18,  1.01it/s]Epoch: 6/10. Loss: 0.9876:  31%|[36m███       [0m| 8/26 [00:07<00:17,  1.06it/s]Epoch: 6/10. Loss: 0.9167:  31%|[36m███       [0m| 8/26 [00:08<00:17,  1.06it/s]Epoch: 6/10. Loss: 0.9167:  35%|[36m███▍      [0m| 9/26 [00:08<00:17,  1.00s/it]Epoch: 6/10. Loss: 0.9311:  35%|[36m███▍      [0m| 9/26 [00:09<00:17,  1.00s/it]Epoch: 6/10. Loss: 0.9311:  38%|[36m███▊      [0m| 10/26 [00:09<00:15,  1.01it/s]Epoch: 6/10. Loss: 1.0443:  38%|[36m███▊      [0m| 10/26 [00:10<00:15,  1.01it/s]Epoch: 6/10. Loss: 1.0443:  42%|[36m████▏     [0m| 11/26 [00:10<00:15,  1.01s/it]Epoch: 6/10. Loss: 0.8897:  42%|[36m████▏     [0m| 11/26 [00:11<00:15,  1.01s/it]Epoch: 6/10. Loss: 0.8897:  46%|[36m████▌     [0m| 12/26 [00:11<00:13,  1.04it/s]Epoch: 6/10. Loss: 0.8784:  46%|[36m████▌     [0m| 12/26 [00:12<00:13,  1.04it/s]Epoch: 6/10. Loss: 0.8784:  50%|[36m█████     [0m| 13/26 [00:12<00:12,  1.07it/s]Epoch: 6/10. Loss: 1.0349:  50%|[36m█████     [0m| 13/26 [00:13<00:12,  1.07it/s]Epoch: 6/10. Loss: 1.0349:  54%|[36m█████▍    [0m| 14/26 [00:13<00:11,  1.06it/s]Epoch: 6/10. Loss: 0.9267:  54%|[36m█████▍    [0m| 14/26 [00:14<00:11,  1.06it/s]Epoch: 6/10. Loss: 0.9267:  58%|[36m█████▊    [0m| 15/26 [00:14<00:10,  1.04it/s]Epoch: 6/10. Loss: 0.8537:  58%|[36m█████▊    [0m| 15/26 [00:15<00:10,  1.04it/s]Epoch: 6/10. Loss: 0.8537:  62%|[36m██████▏   [0m| 16/26 [00:15<00:09,  1.07it/s]Epoch: 6/10. Loss: 0.9328:  62%|[36m██████▏   [0m| 16/26 [00:16<00:09,  1.07it/s]Epoch: 6/10. Loss: 0.9328:  65%|[36m██████▌   [0m| 17/26 [00:16<00:08,  1.06it/s]Epoch: 6/10. Loss: 0.9560:  65%|[36m██████▌   [0m| 17/26 [00:17<00:08,  1.06it/s]Epoch: 6/10. Loss: 0.9560:  69%|[36m██████▉   [0m| 18/26 [00:17<00:07,  1.08it/s]Epoch: 6/10. Loss: 0.9315:  69%|[36m██████▉   [0m| 18/26 [00:18<00:07,  1.08it/s]Epoch: 6/10. Loss: 0.9315:  73%|[36m███████▎  [0m| 19/26 [00:18<00:06,  1.10it/s]Epoch: 6/10. Loss: 0.9183:  73%|[36m███████▎  [0m| 19/26 [00:19<00:06,  1.10it/s]Epoch: 6/10. Loss: 0.9183:  77%|[36m███████▋  [0m| 20/26 [00:19<00:05,  1.04it/s]Epoch: 6/10. Loss: 0.8505:  77%|[36m███████▋  [0m| 20/26 [00:20<00:05,  1.04it/s]Epoch: 6/10. Loss: 0.8505:  81%|[36m████████  [0m| 21/26 [00:20<00:04,  1.05it/s]Epoch: 6/10. Loss: 0.8490:  81%|[36m████████  [0m| 21/26 [00:21<00:04,  1.05it/s]Epoch: 6/10. Loss: 0.8490:  85%|[36m████████▍ [0m| 22/26 [00:21<00:03,  1.00it/s]Epoch: 6/10. Loss: 0.8311:  85%|[36m████████▍ [0m| 22/26 [00:22<00:03,  1.00it/s]Epoch: 6/10. Loss: 0.8311:  88%|[36m████████▊ [0m| 23/26 [00:22<00:03,  1.02s/it]Epoch: 6/10. Loss: 0.8558:  88%|[36m████████▊ [0m| 23/26 [00:23<00:03,  1.02s/it]Epoch: 6/10. Loss: 0.8558:  92%|[36m█████████▏[0m| 24/26 [00:23<00:01,  1.02it/s]Epoch: 6/10. Loss: 0.8790:  92%|[36m█████████▏[0m| 24/26 [00:24<00:01,  1.02it/s]Epoch: 6/10. Loss: 0.8790:  96%|[36m█████████▌[0m| 25/26 [00:24<00:00,  1.09it/s]Epoch: 6/10. Loss: 0.8529:  96%|[36m█████████▌[0m| 25/26 [00:24<00:00,  1.09it/s]Epoch: 6/10. Loss: 0.8529: 100%|[36m██████████[0m| 26/26 [00:24<00:00,  1.19it/s]Epoch: 6/10. Loss: 0.8529: 100%|[36m██████████[0m| 26/26 [00:24<00:00,  1.05it/s]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:01<00:08,  1.37s/it] 29%|[33m██▊       [0m| 2/7 [00:02<00:06,  1.33s/it] 43%|[33m████▎     [0m| 3/7 [00:03<00:04,  1.01s/it] 57%|[33m█████▋    [0m| 4/7 [00:04<00:03,  1.04s/it] 71%|[33m███████▏  [0m| 5/7 [00:04<00:01,  1.20it/s] 86%|[33m████████▌ [0m| 6/7 [00:05<00:00,  1.20it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.52it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.17it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 7/10. Loss: 0.7808:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 7/10. Loss: 0.7808:   4%|[36m▍         [0m| 1/26 [00:00<00:23,  1.05it/s]Epoch: 7/10. Loss: 0.8573:   4%|[36m▍         [0m| 1/26 [00:01<00:23,  1.05it/s]Epoch: 7/10. Loss: 0.8573:   8%|[36m▊         [0m| 2/26 [00:01<00:23,  1.03it/s]Epoch: 7/10. Loss: 0.8298:   8%|[36m▊         [0m| 2/26 [00:02<00:23,  1.03it/s]Epoch: 7/10. Loss: 0.8298:  12%|[36m█▏        [0m| 3/26 [00:02<00:22,  1.02it/s]Epoch: 7/10. Loss: 0.8719:  12%|[36m█▏        [0m| 3/26 [00:03<00:22,  1.02it/s]Epoch: 7/10. Loss: 0.8719:  15%|[36m█▌        [0m| 4/26 [00:03<00:19,  1.15it/s]Epoch: 7/10. Loss: 0.8456:  15%|[36m█▌        [0m| 4/26 [00:04<00:19,  1.15it/s]Epoch: 7/10. Loss: 0.8456:  19%|[36m█▉        [0m| 5/26 [00:04<00:19,  1.07it/s]Epoch: 7/10. Loss: 0.8559:  19%|[36m█▉        [0m| 5/26 [00:05<00:19,  1.07it/s]Epoch: 7/10. Loss: 0.8559:  23%|[36m██▎       [0m| 6/26 [00:05<00:18,  1.08it/s]Epoch: 7/10. Loss: 0.7927:  23%|[36m██▎       [0m| 6/26 [00:06<00:18,  1.08it/s]Epoch: 7/10. Loss: 0.7927:  27%|[36m██▋       [0m| 7/26 [00:06<00:17,  1.07it/s]Epoch: 7/10. Loss: 0.9355:  27%|[36m██▋       [0m| 7/26 [00:07<00:17,  1.07it/s]Epoch: 7/10. Loss: 0.9355:  31%|[36m███       [0m| 8/26 [00:07<00:16,  1.11it/s]Epoch: 7/10. Loss: 0.8715:  31%|[36m███       [0m| 8/26 [00:08<00:16,  1.11it/s]Epoch: 7/10. Loss: 0.8715:  35%|[36m███▍      [0m| 9/26 [00:08<00:16,  1.05it/s]Epoch: 7/10. Loss: 0.8207:  35%|[36m███▍      [0m| 9/26 [00:09<00:16,  1.05it/s]Epoch: 7/10. Loss: 0.8207:  38%|[36m███▊      [0m| 10/26 [00:09<00:14,  1.09it/s]Epoch: 7/10. Loss: 0.7828:  38%|[36m███▊      [0m| 10/26 [00:10<00:14,  1.09it/s]Epoch: 7/10. Loss: 0.7828:  42%|[36m████▏     [0m| 11/26 [00:10<00:13,  1.13it/s]Epoch: 7/10. Loss: 0.8849:  42%|[36m████▏     [0m| 11/26 [00:10<00:13,  1.13it/s]Epoch: 7/10. Loss: 0.8849:  46%|[36m████▌     [0m| 12/26 [00:11<00:12,  1.12it/s]Epoch: 7/10. Loss: 0.8516:  46%|[36m████▌     [0m| 12/26 [00:11<00:12,  1.12it/s]Epoch: 7/10. Loss: 0.8516:  50%|[36m█████     [0m| 13/26 [00:11<00:11,  1.10it/s]Epoch: 7/10. Loss: 0.9241:  50%|[36m█████     [0m| 13/26 [00:12<00:11,  1.10it/s]Epoch: 7/10. Loss: 0.9241:  54%|[36m█████▍    [0m| 14/26 [00:12<00:10,  1.11it/s]Epoch: 7/10. Loss: 0.8141:  54%|[36m█████▍    [0m| 14/26 [00:13<00:10,  1.11it/s]Epoch: 7/10. Loss: 0.8141:  58%|[36m█████▊    [0m| 15/26 [00:13<00:10,  1.08it/s]Epoch: 7/10. Loss: 0.8203:  58%|[36m█████▊    [0m| 15/26 [00:14<00:10,  1.08it/s]Epoch: 7/10. Loss: 0.8203:  62%|[36m██████▏   [0m| 16/26 [00:14<00:09,  1.04it/s]Epoch: 7/10. Loss: 0.8715:  62%|[36m██████▏   [0m| 16/26 [00:15<00:09,  1.04it/s]Epoch: 7/10. Loss: 0.8715:  65%|[36m██████▌   [0m| 17/26 [00:15<00:08,  1.05it/s]Epoch: 7/10. Loss: 0.9683:  65%|[36m██████▌   [0m| 17/26 [00:16<00:08,  1.05it/s]Epoch: 7/10. Loss: 0.9683:  69%|[36m██████▉   [0m| 18/26 [00:16<00:07,  1.02it/s]Epoch: 7/10. Loss: 0.8604:  69%|[36m██████▉   [0m| 18/26 [00:17<00:07,  1.02it/s]Epoch: 7/10. Loss: 0.8604:  73%|[36m███████▎  [0m| 19/26 [00:17<00:06,  1.06it/s]Epoch: 7/10. Loss: 0.8438:  73%|[36m███████▎  [0m| 19/26 [00:18<00:06,  1.06it/s]Epoch: 7/10. Loss: 0.8438:  77%|[36m███████▋  [0m| 20/26 [00:18<00:05,  1.04it/s]Epoch: 7/10. Loss: 0.8869:  77%|[36m███████▋  [0m| 20/26 [00:19<00:05,  1.04it/s]Epoch: 7/10. Loss: 0.8869:  81%|[36m████████  [0m| 21/26 [00:19<00:04,  1.06it/s]Epoch: 7/10. Loss: 0.9338:  81%|[36m████████  [0m| 21/26 [00:20<00:04,  1.06it/s]Epoch: 7/10. Loss: 0.9338:  85%|[36m████████▍ [0m| 22/26 [00:20<00:03,  1.03it/s]Epoch: 7/10. Loss: 0.8738:  85%|[36m████████▍ [0m| 22/26 [00:21<00:03,  1.03it/s]Epoch: 7/10. Loss: 0.8738:  88%|[36m████████▊ [0m| 23/26 [00:21<00:02,  1.02it/s]Epoch: 7/10. Loss: 0.8883:  88%|[36m████████▊ [0m| 23/26 [00:22<00:02,  1.02it/s]Epoch: 7/10. Loss: 0.8883:  92%|[36m█████████▏[0m| 24/26 [00:22<00:02,  1.02s/it]Epoch: 7/10. Loss: 0.8106:  92%|[36m█████████▏[0m| 24/26 [00:23<00:02,  1.02s/it]Epoch: 7/10. Loss: 0.8106:  96%|[36m█████████▌[0m| 25/26 [00:23<00:01,  1.01s/it]Epoch: 7/10. Loss: 0.8573:  96%|[36m█████████▌[0m| 25/26 [00:24<00:01,  1.01s/it]Epoch: 7/10. Loss: 0.8573: 100%|[36m██████████[0m| 26/26 [00:24<00:00,  1.11it/s]Epoch: 7/10. Loss: 0.8573: 100%|[36m██████████[0m| 26/26 [00:24<00:00,  1.07it/s]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:04,  1.44it/s] 29%|[33m██▊       [0m| 2/7 [00:01<00:05,  1.04s/it] 43%|[33m████▎     [0m| 3/7 [00:02<00:03,  1.16it/s] 57%|[33m█████▋    [0m| 4/7 [00:03<00:02,  1.04it/s] 71%|[33m███████▏  [0m| 5/7 [00:04<00:01,  1.27it/s] 86%|[33m████████▌ [0m| 6/7 [00:05<00:00,  1.24it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.55it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.30it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 8/10. Loss: 0.8278:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 8/10. Loss: 0.8278:   4%|[36m▍         [0m| 1/26 [00:00<00:23,  1.08it/s]Epoch: 8/10. Loss: 0.7756:   4%|[36m▍         [0m| 1/26 [00:01<00:23,  1.08it/s]Epoch: 8/10. Loss: 0.7756:   8%|[36m▊         [0m| 2/26 [00:01<00:22,  1.07it/s]Epoch: 8/10. Loss: 0.7874:   8%|[36m▊         [0m| 2/26 [00:02<00:22,  1.07it/s]Epoch: 8/10. Loss: 0.7874:  12%|[36m█▏        [0m| 3/26 [00:02<00:22,  1.02it/s]Epoch: 8/10. Loss: 0.9738:  12%|[36m█▏        [0m| 3/26 [00:03<00:22,  1.02it/s]Epoch: 8/10. Loss: 0.9738:  15%|[36m█▌        [0m| 4/26 [00:03<00:20,  1.06it/s]Epoch: 8/10. Loss: 0.9110:  15%|[36m█▌        [0m| 4/26 [00:04<00:20,  1.06it/s]Epoch: 8/10. Loss: 0.9110:  19%|[36m█▉        [0m| 5/26 [00:04<00:19,  1.09it/s]Epoch: 8/10. Loss: 0.8430:  19%|[36m█▉        [0m| 5/26 [00:05<00:19,  1.09it/s]Epoch: 8/10. Loss: 0.8430:  23%|[36m██▎       [0m| 6/26 [00:05<00:20,  1.02s/it]Epoch: 8/10. Loss: 0.8313:  23%|[36m██▎       [0m| 6/26 [00:06<00:20,  1.02s/it]Epoch: 8/10. Loss: 0.8313:  27%|[36m██▋       [0m| 7/26 [00:06<00:18,  1.03it/s]Epoch: 8/10. Loss: 0.8608:  27%|[36m██▋       [0m| 7/26 [00:07<00:18,  1.03it/s]Epoch: 8/10. Loss: 0.8608:  31%|[36m███       [0m| 8/26 [00:07<00:16,  1.09it/s]Epoch: 8/10. Loss: 0.8574:  31%|[36m███       [0m| 8/26 [00:08<00:16,  1.09it/s]Epoch: 8/10. Loss: 0.8574:  35%|[36m███▍      [0m| 9/26 [00:08<00:15,  1.11it/s]Epoch: 8/10. Loss: 0.7661:  35%|[36m███▍      [0m| 9/26 [00:09<00:15,  1.11it/s]Epoch: 8/10. Loss: 0.7661:  38%|[36m███▊      [0m| 10/26 [00:09<00:14,  1.09it/s]Epoch: 8/10. Loss: 0.8963:  38%|[36m███▊      [0m| 10/26 [00:10<00:14,  1.09it/s]Epoch: 8/10. Loss: 0.8963:  42%|[36m████▏     [0m| 11/26 [00:10<00:13,  1.10it/s]Epoch: 8/10. Loss: 0.9555:  42%|[36m████▏     [0m| 11/26 [00:11<00:13,  1.10it/s]Epoch: 8/10. Loss: 0.9555:  46%|[36m████▌     [0m| 12/26 [00:11<00:13,  1.07it/s]Epoch: 8/10. Loss: 0.9406:  46%|[36m████▌     [0m| 12/26 [00:12<00:13,  1.07it/s]Epoch: 8/10. Loss: 0.9406:  50%|[36m█████     [0m| 13/26 [00:12<00:12,  1.03it/s]Epoch: 8/10. Loss: 0.9320:  50%|[36m█████     [0m| 13/26 [00:13<00:12,  1.03it/s]Epoch: 8/10. Loss: 0.9320:  54%|[36m█████▍    [0m| 14/26 [00:13<00:11,  1.06it/s]Epoch: 8/10. Loss: 0.8461:  54%|[36m█████▍    [0m| 14/26 [00:14<00:11,  1.06it/s]Epoch: 8/10. Loss: 0.8461:  58%|[36m█████▊    [0m| 15/26 [00:14<00:10,  1.05it/s]Epoch: 8/10. Loss: 0.8353:  58%|[36m█████▊    [0m| 15/26 [00:14<00:10,  1.05it/s]Epoch: 8/10. Loss: 0.8353:  62%|[36m██████▏   [0m| 16/26 [00:15<00:09,  1.08it/s]Epoch: 8/10. Loss: 0.8507:  62%|[36m██████▏   [0m| 16/26 [00:16<00:09,  1.08it/s]Epoch: 8/10. Loss: 0.8507:  65%|[36m██████▌   [0m| 17/26 [00:16<00:08,  1.02it/s]Epoch: 8/10. Loss: 0.8529:  65%|[36m██████▌   [0m| 17/26 [00:17<00:08,  1.02it/s]Epoch: 8/10. Loss: 0.8529:  69%|[36m██████▉   [0m| 18/26 [00:17<00:08,  1.01s/it]Epoch: 8/10. Loss: 0.9355:  69%|[36m██████▉   [0m| 18/26 [00:18<00:08,  1.01s/it]Epoch: 8/10. Loss: 0.9355:  73%|[36m███████▎  [0m| 19/26 [00:18<00:07,  1.14s/it]Epoch: 8/10. Loss: 0.8924:  73%|[36m███████▎  [0m| 19/26 [00:19<00:07,  1.14s/it]Epoch: 8/10. Loss: 0.8924:  77%|[36m███████▋  [0m| 20/26 [00:19<00:06,  1.07s/it]Epoch: 8/10. Loss: 0.8727:  77%|[36m███████▋  [0m| 20/26 [00:20<00:06,  1.07s/it]Epoch: 8/10. Loss: 0.8727:  81%|[36m████████  [0m| 21/26 [00:20<00:04,  1.01it/s]Epoch: 8/10. Loss: 0.8463:  81%|[36m████████  [0m| 21/26 [00:21<00:04,  1.01it/s]Epoch: 8/10. Loss: 0.8463:  85%|[36m████████▍ [0m| 22/26 [00:21<00:04,  1.03s/it]Epoch: 8/10. Loss: 0.8750:  85%|[36m████████▍ [0m| 22/26 [00:22<00:04,  1.03s/it]Epoch: 8/10. Loss: 0.8750:  88%|[36m████████▊ [0m| 23/26 [00:22<00:02,  1.02it/s]Epoch: 8/10. Loss: 0.8530:  88%|[36m████████▊ [0m| 23/26 [00:23<00:02,  1.02it/s]Epoch: 8/10. Loss: 0.8530:  92%|[36m█████████▏[0m| 24/26 [00:23<00:01,  1.01it/s]Epoch: 8/10. Loss: 0.7519:  92%|[36m█████████▏[0m| 24/26 [00:24<00:01,  1.01it/s]Epoch: 8/10. Loss: 0.7519:  96%|[36m█████████▌[0m| 25/26 [00:24<00:00,  1.07it/s]Epoch: 8/10. Loss: 0.7327:  96%|[36m█████████▌[0m| 25/26 [00:24<00:00,  1.07it/s]Epoch: 8/10. Loss: 0.7327: 100%|[36m██████████[0m| 26/26 [00:24<00:00,  1.20it/s]Epoch: 8/10. Loss: 0.7327: 100%|[36m██████████[0m| 26/26 [00:24<00:00,  1.05it/s]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:04,  1.37it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:05,  1.07s/it] 43%|[33m████▎     [0m| 3/7 [00:03<00:04,  1.23s/it] 57%|[33m█████▋    [0m| 4/7 [00:04<00:03,  1.19s/it] 71%|[33m███████▏  [0m| 5/7 [00:05<00:01,  1.06it/s] 86%|[33m████████▌ [0m| 6/7 [00:05<00:00,  1.10it/s]100%|[33m██████████[0m| 7/7 [00:06<00:00,  1.39it/s]100%|[33m██████████[0m| 7/7 [00:06<00:00,  1.12it/s]
  0%|[36m          [0m| 0/26 [00:00<?, ?it/s]/data2/shared/apps/conda/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  warnings.warn(
Epoch: 9/10. Loss: 0.8214:   0%|[36m          [0m| 0/26 [00:00<?, ?it/s]Epoch: 9/10. Loss: 0.8214:   4%|[36m▍         [0m| 1/26 [00:00<00:24,  1.00it/s]Epoch: 9/10. Loss: 0.8154:   4%|[36m▍         [0m| 1/26 [00:01<00:24,  1.00it/s]Epoch: 9/10. Loss: 0.8154:   8%|[36m▊         [0m| 2/26 [00:01<00:22,  1.07it/s]Epoch: 9/10. Loss: 0.7835:   8%|[36m▊         [0m| 2/26 [00:02<00:22,  1.07it/s]Epoch: 9/10. Loss: 0.7835:  12%|[36m█▏        [0m| 3/26 [00:02<00:21,  1.09it/s]Epoch: 9/10. Loss: 0.8297:  12%|[36m█▏        [0m| 3/26 [00:03<00:21,  1.09it/s]Epoch: 9/10. Loss: 0.8297:  15%|[36m█▌        [0m| 4/26 [00:03<00:19,  1.11it/s]Epoch: 9/10. Loss: 0.7459:  15%|[36m█▌        [0m| 4/26 [00:04<00:19,  1.11it/s]Epoch: 9/10. Loss: 0.7459:  19%|[36m█▉        [0m| 5/26 [00:04<00:18,  1.13it/s]Epoch: 9/10. Loss: 0.8327:  19%|[36m█▉        [0m| 5/26 [00:05<00:18,  1.13it/s]Epoch: 9/10. Loss: 0.8327:  23%|[36m██▎       [0m| 6/26 [00:05<00:18,  1.11it/s]Epoch: 9/10. Loss: 0.7291:  23%|[36m██▎       [0m| 6/26 [00:06<00:18,  1.11it/s]Epoch: 9/10. Loss: 0.7291:  27%|[36m██▋       [0m| 7/26 [00:06<00:17,  1.11it/s]Epoch: 9/10. Loss: 0.7727:  27%|[36m██▋       [0m| 7/26 [00:07<00:17,  1.11it/s]Epoch: 9/10. Loss: 0.7727:  31%|[36m███       [0m| 8/26 [00:07<00:16,  1.12it/s]Epoch: 9/10. Loss: 0.8033:  31%|[36m███       [0m| 8/26 [00:08<00:16,  1.12it/s]Epoch: 9/10. Loss: 0.8033:  35%|[36m███▍      [0m| 9/26 [00:08<00:15,  1.08it/s]Epoch: 9/10. Loss: 0.8578:  35%|[36m███▍      [0m| 9/26 [00:09<00:15,  1.08it/s]Epoch: 9/10. Loss: 0.8578:  38%|[36m███▊      [0m| 10/26 [00:09<00:15,  1.02it/s]Epoch: 9/10. Loss: 0.8600:  38%|[36m███▊      [0m| 10/26 [00:10<00:15,  1.02it/s]Epoch: 9/10. Loss: 0.8600:  42%|[36m████▏     [0m| 11/26 [00:10<00:14,  1.03it/s]Epoch: 9/10. Loss: 0.8931:  42%|[36m████▏     [0m| 11/26 [00:11<00:14,  1.03it/s]Epoch: 9/10. Loss: 0.8931:  46%|[36m████▌     [0m| 12/26 [00:11<00:13,  1.06it/s]Epoch: 9/10. Loss: 0.9560:  46%|[36m████▌     [0m| 12/26 [00:12<00:13,  1.06it/s]Epoch: 9/10. Loss: 0.9560:  50%|[36m█████     [0m| 13/26 [00:12<00:12,  1.08it/s]Epoch: 9/10. Loss: 0.8650:  50%|[36m█████     [0m| 13/26 [00:12<00:12,  1.08it/s]Epoch: 9/10. Loss: 0.8650:  54%|[36m█████▍    [0m| 14/26 [00:12<00:10,  1.13it/s]Epoch: 9/10. Loss: 0.8128:  54%|[36m█████▍    [0m| 14/26 [00:13<00:10,  1.13it/s]Epoch: 9/10. Loss: 0.8128:  58%|[36m█████▊    [0m| 15/26 [00:13<00:09,  1.11it/s]Epoch: 9/10. Loss: 0.7742:  58%|[36m█████▊    [0m| 15/26 [00:14<00:09,  1.11it/s]Epoch: 9/10. Loss: 0.7742:  62%|[36m██████▏   [0m| 16/26 [00:14<00:09,  1.05it/s]Epoch: 9/10. Loss: 0.8269:  62%|[36m██████▏   [0m| 16/26 [00:15<00:09,  1.05it/s]Epoch: 9/10. Loss: 0.8269:  65%|[36m██████▌   [0m| 17/26 [00:15<00:08,  1.08it/s]Epoch: 9/10. Loss: 0.8099:  65%|[36m██████▌   [0m| 17/26 [00:16<00:08,  1.08it/s]Epoch: 9/10. Loss: 0.8099:  69%|[36m██████▉   [0m| 18/26 [00:16<00:07,  1.08it/s]Epoch: 9/10. Loss: 0.7393:  69%|[36m██████▉   [0m| 18/26 [00:17<00:07,  1.08it/s]Epoch: 9/10. Loss: 0.7393:  73%|[36m███████▎  [0m| 19/26 [00:17<00:06,  1.10it/s]Epoch: 9/10. Loss: 0.8544:  73%|[36m███████▎  [0m| 19/26 [00:18<00:06,  1.10it/s]Epoch: 9/10. Loss: 0.8544:  77%|[36m███████▋  [0m| 20/26 [00:18<00:05,  1.10it/s]Epoch: 9/10. Loss: 0.8944:  77%|[36m███████▋  [0m| 20/26 [00:19<00:05,  1.10it/s]Epoch: 9/10. Loss: 0.8944:  81%|[36m████████  [0m| 21/26 [00:19<00:04,  1.10it/s]Epoch: 9/10. Loss: 0.8398:  81%|[36m████████  [0m| 21/26 [00:20<00:04,  1.10it/s]Epoch: 9/10. Loss: 0.8398:  85%|[36m████████▍ [0m| 22/26 [00:20<00:03,  1.09it/s]Epoch: 9/10. Loss: 0.8571:  85%|[36m████████▍ [0m| 22/26 [00:21<00:03,  1.09it/s]Epoch: 9/10. Loss: 0.8571:  88%|[36m████████▊ [0m| 23/26 [00:21<00:02,  1.06it/s]Epoch: 9/10. Loss: 0.7568:  88%|[36m████████▊ [0m| 23/26 [00:22<00:02,  1.06it/s]Epoch: 9/10. Loss: 0.7568:  92%|[36m█████████▏[0m| 24/26 [00:22<00:01,  1.01it/s]Epoch: 9/10. Loss: 0.7425:  92%|[36m█████████▏[0m| 24/26 [00:23<00:01,  1.01it/s]Epoch: 9/10. Loss: 0.7425:  96%|[36m█████████▌[0m| 25/26 [00:23<00:00,  1.01it/s]Epoch: 9/10. Loss: 0.8350:  96%|[36m█████████▌[0m| 25/26 [00:23<00:00,  1.01it/s]Epoch: 9/10. Loss: 0.8350: 100%|[36m██████████[0m| 26/26 [00:24<00:00,  1.12it/s]Epoch: 9/10. Loss: 0.8350: 100%|[36m██████████[0m| 26/26 [00:24<00:00,  1.08it/s]
  0%|[33m          [0m| 0/7 [00:00<?, ?it/s] 14%|[33m█▍        [0m| 1/7 [00:00<00:04,  1.42it/s] 29%|[33m██▊       [0m| 2/7 [00:02<00:05,  1.07s/it] 43%|[33m████▎     [0m| 3/7 [00:02<00:03,  1.13it/s] 57%|[33m█████▋    [0m| 4/7 [00:03<00:02,  1.02it/s] 71%|[33m███████▏  [0m| 5/7 [00:04<00:01,  1.23it/s] 86%|[33m████████▌ [0m| 6/7 [00:05<00:00,  1.20it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.50it/s]100%|[33m██████████[0m| 7/7 [00:05<00:00,  1.27it/s]
